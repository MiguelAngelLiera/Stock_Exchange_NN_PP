@article{DWT-NARNN,
  title={A Hybrid Model Combining Discrete Wavelet Transform and Nonlinear Autoregressive Neural Network for Stock Price Prediction: An Application in the Egyptian Exchange},
  author={Asmaa Y. Fathi and Ihab A. El-Khodary1 and Muhammad Saafan},
  journal={Revue d'Intelligence Artificielle},
  volume={37},
  number={1},
  month={2},
  year={2023},
  pages={15--21},
  doi={10.18280/ria.370103},
}

@article{Wavelet_Analysis,
  title={Exploring the power of wavelet analysis},
  author={Galli, A. W. and Heydt, G. T. and Ribeiro, P. F.},
  journal={IEEE Spectrum},
  volume={9},
  number={4},
  pages={0--41},
  year={1996},
  doi={10.1109/67.539845},
}

@article{ML_SP,
  title={Machine Learning to Predict Stock Prices},
  author={Roshan Adusumilli},
  journal={Towards Data Science},
  year={2019},
  url={https://towardsdatascience.com/predicting-stock-prices-using-a-keras-lstm-model-4225457f0233},
}

@article{mulresolution_sigmal_desc_DWT_Mallat,
  title={A theory for multiresolution signal decomposition: The wavelet representation},
  author={S. G. Mallat},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={11},
  number={7},
  pages={674--693},
  year={1989},
  doi={10.1109/34.192463},
}

@article{LSTM,
  title={Long Short-Term Memory},
  author={Sepp Hochreiter and Jürgen Schmidhuber},
  journal={Neural Computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  doi={10.1162/neco.1997.9.8.1735},
}

@article{Learning_to_Forget,
  title={Learning to Forget: Continual Prediction with LSTM},
  author={Gers, Felix A and Schmidhuber, J{\"u}rgen and Cummins, Fred},
  journal={Neural Computation},
  volume={12},
  number={10},
  pages={2451--2471},
  year={2000},
  doi={10.1162/089976600300015015},
}

@article{GRU,
  title={Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation},
  author={Kyunghyun Cho and Bart van Merrienboer and Caglar Gulcehre and Dzmitry Bahdanau and Fethi Bougares, Holger Schwenk and Yoshua Bengio},
  journal={Association for Computational Linguistics},
  year={2014},
  eprint={arXiv:1406.1078},
}

@article{kilic2023hybrid,
  title={Hybrid wavelet-neural network models for time series},
  author={K{\i}l{\i}\c{c}, Deniz Kenan and U\u{g}ur, {\"O}m{\"u}r},
  journal={Applied Soft Computing},
  volume={144},
  year={2023},
  pages={110469},
  issn={1568-4946},
  doi={10.1016/j.asoc.2023.110469},
  url={https://www.sciencedirect.com/science/article/pii/S1568494623004878},
}

@article{KILIC2023110469,
title = {Hybrid wavelet-neural network models for time series},
journal = {Applied Soft Computing},
volume = {144},
pages = {110469},
year = {2023},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2023.110469},
url = {https://www.sciencedirect.com/science/article/pii/S1568494623004878},
author = {Deniz Kenan Kılıç and Ömür Uğur},
keywords = {Nonlinear models, Long short-term memory (LSTM), Recurrent neural network (RNN), Time series analysis, Multiresolution analysis (MRA), Wavenet, Wavelet neural network (WNN)},
abstract = {The use of wavelet analysis contributes to better modeling for financial time series in the sense of both frequency and time. In this study, S&P500 and NASDAQ data are separated into several components utilizing multiresolution analysis (MRA). Subsequently, using an appropriate neural network structure, each component is modeled. In addition, wavelets are used as an activation function in long short-term memory (LSTM) networks to form a hybrid model. The hybrid model is merged with MRA as a proposed method in this paper. Four distinct strategies are employed: LSTM, LSTM+MRA, hybrid LSTM-Wavenet, and hybrid LSTM-Wavenet+MRA. Results show that the use of MRA and wavelets as an activation function together reduces the error the most.}
}

@article{an_introduction_to_wavelets,
  author={Amara Graps},
  journal={IEEE Computational Science and Engineering}, 
  title={An introduction to wavelets}, 
  year={1995},
  volume={2},
  number={2},
  pages={50-61},
  keywords={Wavelet analysis;Performance analysis;Mathematics;Prototypes;Image coding;Fourier series;Geology;Collaboration;Signal resolution;Signal analysis},
  doi={10.1109/99.388960}
}

@misc{wavalet_tutorial_Polizar,
    title        = {The Wavelet Tutorial. Part IV. Multiresolution Analysis: The Discrete Wavelet Transform},
    author       = {Robi Polikar},
    url = {https://web.archive.org/web/20180430090402/http://users.rowan.edu/~polikar/WAVELETS/WTtutorial.html},
    year         = {1999},
}

@inbook{ten_lec_wavelets_Daubechies_1,

title = {1. The What, Why, and How of Wavelets},
booktitle = {Ten Lectures on Wavelets},
author = {Ingrid Daubechies},
chapter = {},
pages = {1-16},
year = {1992},
doi = {10.1137/1.9781611970104.ch1},
URL = {https://epubs.siam.org/doi/abs/10.1137/1.9781611970104.ch1},
eprint = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611970104.ch1},
    abstract = { The wavelet transform is a tool that cuts up data or functions or operators into different frequency components, and then studies each component with a resolution matched to its scale. Forerunners of this technique were invented independently in pure mathematics (Calderón's resolution of the identity in harmonic analysis—see e.g., Calderón (1964)), physics (coherent states for the (ax + b)-group in quantum mechanics, first constructed by Aslaksen and Klauder (1968), and linked to the hydrogen atom Hamiltonian by Paul (1985)) and engineering (QMF filters by Esteban and Galland (1977), and later QMF filters with exact reconstruction property by Smith and Barnwell (1986), Vetterli (1986) in electrical engineering; wavelets were proposed for the analysis of seismic data by J. Morlet (1983)). The last five years have seen a synthesis between all these different approaches, which has been very fertile for all the fields concerned. Let us stay for a moment within the signal analysis framework. (The discussion can easily be translated to other fields.) The wavelet transform of a signal evolving in time (e.g., the amplitude of the pressure on an eardrum, for acoustical applications) depends on two variables: scale (or frequency) and time; wavelets provide a tool for time-frequency localization. The first section tells us what time-frequency localization means and why it is of interest. The remaining sections describe different types of wavelets. }
}

%redes neuronales

@misc{adam_kingma,
      title={Adam: A Method for Stochastic Optimization}, 
      author={Diederik P. Kingma and Jimmy Ba},
      year={2017},
      eprint={1412.6980},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@misc{understanding_lstm_Olah,
    author       = {Christopher Colah},
    title        = {Understanding LSTM Networks},
    howpublished = {colah's blog},
    year         = {2015},
    url         = {https://colah.github.io/posts/2015-08-Understanding-LSTMs/?source=post_page-----b3996e6a0296--------------------------------},
}


@misc{understanding_backpropagation_Kostadinov,
    author       = {Simeon Kostadinov},
    title        = {Understanding Backpropagation Algorithm},
    howpublished = {Medium},
    year         = {2019},
    url         = {https://towardsdatascience.com/understanding-backpropagation-algorithm-7bb3aa2f95fd},
}

@misc{LSTM_gradients_Rahuljha,
    author       = {Rahuljha},
    title        = {LSTM Gradients: Detailed mathematical derivation of gradients for LSTM cells},
    howpublished = {Medium},
    year         = {2020},
    url         = {https://towardsdatascience.com/lstm-gradients-b3996e6a0296},
}

@misc{LSTM_fbp_calc_grad_Mallya,
    author       = {Arun Mallya},
    title        = {LSTM Forward and Backward Pass},
    howpublished = {Medium},
    year         = {},
    url         = {https://arunmallya.github.io/writeups/nn/lstm/index.html#/}
}

@misc{forward_and_Backprop_GRU_Mihir,
    author       = {Mihir},
    title        = {Forward and Backpropagation in GRUs — Derived $|$ Deep Learning},
    howpublished = {Medium},
    year         = {2019},
    url         = {https://medium.com/@mihirkhandekar/forward-and-backpropagation-in-grus-derived-deep-learning-5764f374f3f5},
}

@misc{GRU_units_in_R_Fichou,
    author       = {Dimitri Fichou},
    title        = {GRU units},
    howpublished = {The Comprehensive R Archive Network},
    year         = {2023},
    url         = {https://cran.r-project.org/web/packages/rnn/vignettes/GRU_units.html},
}

@article{pywavelets,
  title={PyWavelets: A Python package for wavelet analysis},
  author={Gregory R. Lee and Ralf Gommers and Filip Waselewski and KaiWohlfahrt and Aaron O’Leary},
  journal={Journal of Open Source Software},
  volume={4},
  number={36},
  pages={1237},
  year={2019},
  doi={10.21105/joss.01237},
  url={https://doi.org/10.21105/joss.01237}
}

@misc{oportunidades_Actinver,
    title = {Existen oportunidades en Bolsa, dice Actinver},
    author = {Claudia Tejeda},
    howpublished = {El Economista},
    year = {2020},
    month = {9},
    day = {25},
    url = {https://www.eleconomista.com.mx/mercados/Existen-oportunidades-en-Bolsa-dice-Activer-20200924-0115.html}
}

@misc{STFT,
    author = {M Ahmadizadeh},
    year = {2014},
    title = {An Introduction to Short-Time Fourier Transform (STFT)},
    url = {https://sharif.edu/~ahmadizadeh/courses/advstdyn/Short-Time%20Fourier%20Transform.pdf},
    note = {Sharif University of Technology}
}

@article{GRU_vs_LSTM,
    author       = {Prudhviraju Srivatsavaya},
    title        = {LSTM vs GRU},
    journal={Towards Data Science},
    year         = {2023},
    url         = {https://medium.com/@prudhviraju.srivatsavaya/lstm-vs-gru-c1209b8ecb5a},
}

@book{haykin2008neural,
  author    = {Simon Haykin},
  title     = {Neural Networks and Learning Machines},
  year      = {2008},
  publisher = {Prentice Hall},
  edition   = {3rd},
}

@book{hertz1991introduction,
  author    = {John A. Hertz and Richard G. Palmer and Anders Krogh},
  title     = {Introduction to the Theory of Neural Computation},
  year      = {1991},
  publisher = {Addison Wesley},
}

@article{CorrOancea2014,
  author       = {Bogdan Oancea and
                  Stefan Cristian Ciucu},
  title        = {Time series forecasting using neural networks},
  journal      = {CoRR},
  volume       = {abs/1401.1333},
  year         = {2014},
  url          = {http://arxiv.org/abs/1401.1333},
  eprinttype    = {arXiv},
  eprint       = {1401.1333},
  timestamp    = {Mon, 13 Aug 2018 16:48:38 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/OanceaC14.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{electric_ARMA_ARIMA,
author = {Pasapitch Chujai and Nittaya Kerdprasop and Kittisak Kerdprasop},
year = {2013},
month = {03},
pages = {295-300},
title = {Time series analysis of household electric consumption with ARIMA and ARMA models},
volume = {2202},
journal = {Lecture Notes in Engineering and Computer Science}
}

@misc{Marco_TSF_Att,
author = {Marco Del Pra},
year = {2020},
month = {11},
title = {Time Series Forecasting with Deep Learning and Attention Mechanism},
howpublished = {Medium},
url = {https://towardsdatascience.com/time-series-forecasting-with-deep-learning-and-attention-mechanism-2d001fc871fc}
}

@article{altay2005stock,
  author    = {Ece Altay and Mehmet H. Satman},
  title     = {Stock Market Forecasting: Artificial Neural Network and Linear Regression Comparison in an Emerging Market},
  journal   = {Journal of Financial Management \& Analysis},
  volume    = {18},
  number    = {2},
  pages     = {18--33},
  year      = {2005}
}

@article{YANG202218_SVM1,
title = {Adaptability of Financial Time Series Prediction Based on BiLSTM},
journal = {Procedia Computer Science},
volume = {199},
pages = {18-25},
year = {2022},
note = {The 8th International Conference on Information Technology and Quantitative Management (ITQM 2020 \& 2021): Developing Global Digital Economy after COVID-19},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922000035},
author = {Mo Yang and Jing Wang},
keywords = {BiLSTM, Financial Time Series, Deep learning, Machine Learning},
abstract = {Accurate prediction of financial market can promote the steady development of financial market, but the high frequency and high noise of financial time series make accurate prediction a challenging task. In this paper, bidirectional long short-term memory neural network (BiLSTM) in deep learning is applied in financial time series, and BiLSTM has one more layer of reverse structure to try to mine more effective information. The prediction performances of unidirectional long short-term memory neural network (LSTM), support vector regression (SVR) and differential autoregressive moving average model (ARIMA) are compared. The results show that BiLSTM model has the highest prediction accuracy, which can fully capture the past and future data information simultaneously, take the reverse relationship of data into account, and predict the long-term and short-term dynamic trends of financial time series effectively.}
}

@article{parray2020time,
  author    = {I. R. Parray and S. S. Khurana and M. Kumar and A. A. Altalbe},
  title     = {Time Series Data Analysis of Stock Price Movement Using Machine Learning Techniques},
  journal   = {Soft Computing},
  volume    = {24},
  pages     = {16509--16517},
  year      = {2020},
  doi       = {10.1007/s00500-020-04957-x},
  url       = {http://dx.doi.org/10.1007/s00500-020-04957-x}
}

@Article{arboles1,
AUTHOR = {M. Nabipour and P. Nayyeri and H. Jabani and A. Mosavi and E. Salwana and Shahab S.},
TITLE = {Deep Learning for Stock Market Prediction},
JOURNAL = {Entropy},
VOLUME = {22},
YEAR = {2020},
NUMBER = {8},
ARTICLE-NUMBER = {840},
URL = {https://www.mdpi.com/1099-4300/22/8/840},
PubMedID = {33286613},
ISSN = {1099-4300},
ABSTRACT = {The prediction of stock groups values has always been attractive and challenging for shareholders due to its inherent dynamics, non-linearity, and complex nature. This paper concentrates on the future prediction of stock market groups. Four groups named diversified financials, petroleum, non-metallic minerals, and basic metals from Tehran stock exchange were chosen for experimental evaluations. Data were collected for the groups based on 10 years of historical records. The value predictions are created for 1, 2, 5, 10, 15, 20, and 30 days in advance. Various machine learning algorithms were utilized for prediction of future values of stock market groups. We employed decision tree, bagging, random forest, adaptive boosting (Adaboost), gradient boosting, and eXtreme gradient boosting (XGBoost), and artificial neural networks (ANN), recurrent neural network (RNN) and long short-term memory (LSTM). Ten technical indicators were selected as the inputs into each of the prediction models. Finally, the results of the predictions were presented for each technique based on four metrics. Among all algorithms used in this paper, LSTM shows more accurate results with the highest model fitting ability. In addition, for tree-based models, there is often an intense competition between Adaboost, Gradient Boosting, and XGBoost.},
DOI = {10.3390/e22080840}
}

@article{khan2020predicting_randomforest22,
  author    = {Wasiat Khan and Usman Malik and Mustansar Ali Ghazanfar and Muhammad Awais Azam and Khaled H. Alyoubi and Ahmed S. Alfakeeh},
  title     = {Predicting Stock Market Trends Using Machine Learning Algorithms via Public Sentiment and Political Situation Analysis},
  journal   = {Soft Computing},
  volume    = {24},
  pages     = {11019--11043},
  year      = {2020},
  doi       = {10.1007/s00500-019-04347-y},
  url       = {https://doi.org/10.1007/s00500-019-04347-y}
}

@InProceedings{randomforest1,
author="Nagaraj Naik
and Biju R. Mohan",
editor="Macintyre, John
and Iliadis, Lazaros
and Maglogiannis, Ilias
and Jayne, Chrisina",
title="Stock Price Movements Classification Using Machine and Deep Learning Techniques-The Case Study of Indian Stock Market",
booktitle="Engineering Applications of Neural Networks",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="445--452",
abstract="Stock price movements forecasting is an important topic for traders and stock analyst. Timely prediction in stock yields can get more profits and returns. The predicting stock price movement on a daily basis is a difficult task due to more ups and down in the financial market. Therefore, there is a need for a more powerful predictive model to predict the stock prices. Most of the existing work is based on machine learning techniques and considered very few technical indicators to predict the stock prices. In this paper, we have extracted 33 technical indicators based on daily stock price such as open, high, low and close price. This paper addresses the two problems, first is the technical indicator feature selection and identification of the relevant technical indicators by using Boruta feature selection technique. The second is an accurate prediction model for stock price movements. To predict stock price movements we have proposed machine learning techniques and deep learning based model. The performance of the deep learning model is better than the machine learning techniques. The experimental results are significant improves the classification accuracy rate by 5{\%} to 6{\%}. National Stock Exchange, India (NSE) stocks are considered for the experiment.",
isbn="978-3-030-20257-6"
}

@article{kolmogorov,
author = {Hossein Hassani and Emmanuel Silva},
year = {2015},
month = {08},
pages = {590-609},
title = {A Kolmogorov-Smirnov Based Test for Comparing the Predictive Accuracy of Two Sets of Forecasts},
volume = {3},
journal = {Econometrics},
doi = {10.3390/econometrics3030590}
}

@article{graphNN,
  author    = {Xiao Li and Jian Wang and Jie Tan and others},
  title     = {A graph neural network-based stock forecasting method utilizing multi-source heterogeneous data fusion},
  journal   = {Multimedia Tools and Applications},
  volume    = {81},
  pages     = {43753--43775},
  year      = {2022},
  doi       = {10.1007/s11042-022-13231-1},
  url       = {https://doi.org/10.1007/s11042-022-13231-1}
}