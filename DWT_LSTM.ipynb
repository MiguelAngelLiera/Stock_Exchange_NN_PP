{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se analizaran los datos de Grupo Financiero Inbursa, desde el 7-02-2001 hasta 4-02-2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, pywt, csv, numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import src.utilerias.reader as rd\n",
    "import src.utilerias.utilerias as utls\n",
    "import src.utilerias.seniales.dwt.dwt_multinivel as m_dwt\n",
    "# Llamamos a la funci√≥n antes de ejecutar el script\n",
    "utls.eliminar_archivos_registro(\"logs/dwt_lstm\")\n",
    "#utls.clear_tensorboard_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import src.modelos.DWT_Auto_regresivo.entrenamiento.entrenamientos as entr\n",
    "# from src.modelos.DWT_Auto_regresivo.NARNN import NARNN\n",
    "criterion = nn.MSELoss()\n",
    "redes = {\"red_A1\" : 'models/red_A1.pth',\n",
    "         \"red_D1\" : 'models/red_D1.pth',\n",
    "         \"red_D2\" : 'models/red_D2.pth',\n",
    "         \"red_D3\" : 'models/red_D3.pth',\n",
    "         \"red_D4\" : 'models/red_D4.pth',\n",
    "         \"red_D5\" : 'models/red_D5.pth'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud de la entrada: 260\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Abrir el archivo CSV en modo lectura\n",
    "\n",
    "# DATOS = 'cierre.csv'#Grupo Financiero Inbursa\n",
    "# DATOS = 'Datos hist√≥ricos COMI 03012016_27122020.csv' #Datos originales\n",
    "DATOS = 'datos/Datos hist√≥ricos COMI 3ene16-31dic2020 semanal.csv' #Datos semanales\n",
    "# DATOS = 'Datos hist√≥ricos COMI_prueba 30jun19-31dic2020.csv' #Datos semanales de prueba\n",
    "# DATOS = 'Datos hist√≥ricos COMI3ene2016_27dic2020_diario.csv' #Datos originales diarios de prueba\n",
    "# DATOS = 'Datos hist√≥ricos COMI_prueba 30jun19-31dic2020_DIARIO.csv' #Datos diarios de prueba\n",
    "\n",
    "cierre = rd.leer_archivo(DATOS)\n",
    "#se convierten todos los valores a flotantes\n",
    "cierre = cierre.astype(float)\n",
    "\n",
    "# Crear un gr√°fico de l√≠nea con los valores de x, y\n",
    "print(f\"Longitud de la entrada: {len(cierre)}\")\n",
    "plt.figure(figsize=(18, 3))\n",
    "plt.plot(cierre, label=f\"Datos de Analisis: {DATOS}\", color='#176B87')\n",
    "plt.xlabel('D√≠as')\n",
    "plt.ylabel('Precios de cierre diario')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eleccion de Mother Wavelet\n",
    "\n",
    "Se elige las mother wavelets dependiendo de las caracteristicas de la serie de tiempo que se va a analizar. Para series que impliquen cambios no smoothos y repentinos es recomendable usar Haar ya que responde bien a estos cambios repentinos.\n",
    "\n",
    "Se elige bior3.5 debido a las caracteristicas de las fluctuaciones entre periodos con altas cantidades de inversiones y periodos en los que no.\n",
    "\n",
    "En general, el mother wavelet debe de ser una funcion de las caracteristicas de la serie original para que esta pueda ser reconstruida o analizada "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud de la entrada de cA: 135\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2400x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Se descompone la lista de precios de cierre del intervalo mencionado anteriormente a partir de la dwt con la funci√≥n bior3.5\n",
    "# print(pywt.wavelist()) imprime la lista de wavelets de la biblioteca\n",
    "wavelet = 'bior3.5'\n",
    "mode = pywt.Modes.constant #antireflect, smooth\n",
    "wavelet = pywt.Wavelet(wavelet)\n",
    "(cA, cD) = pywt.dwt(cierre.tolist(), wavelet, mode=mode)\n",
    "print(f\"Longitud de la entrada de cA: {len(cA)}\")\n",
    "\n",
    "plt.figure(figsize=(24, 3))\n",
    "aprox_coef = True\n",
    "index = 1\n",
    "\n",
    "for _ in [cA, cD]:\n",
    "    plt.subplot(1, 2, index)\n",
    "    plt.plot( _, color='#1363DF' if aprox_coef else '#256D85')\n",
    "    plt.title('Coeficientes de Aproximaci√≥n' if aprox_coef else 'Coeficientes de Detalle')\n",
    "    aprox_coef = False\n",
    "    index = index + 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Divide the weekly closing stock prices into a training dataset (70%) and a testing dataset (30%). \n",
    "Se realiza la separacion del conjunto de entrenamiento y el de prueba\n",
    "<img src=\"/imagenes/DWT-NARNN_step1.png\" alt=\"Descripci√≥n de la imagen\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2400x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Se realiza el proceso 5 veces\n",
    "cierre_e = cierre[:int(len(cierre) * 0.7)]#cierre entrenamiento len 182\n",
    "cierre_p = cierre[int(len(cierre) * 0.7):]#cierre prueba len 78\n",
    "\n",
    "plt.figure(figsize=(24, 3))\n",
    "index = 1\n",
    "\n",
    "for _ in [cierre_e, cierre_p]:\n",
    "    plt.subplot(1, 2, index)\n",
    "    plt.plot(range(len(_)), _, color='#1363DF' if aprox_coef else '#256D85')\n",
    "    plt.title('Coeficientes de Aproximaci√≥n' if aprox_coef else 'Coeficientes de Detalle')\n",
    "    aprox_coef = False\n",
    "    index = index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decompose the training dataset by the DWT, \n",
    "utilizing the biorthogonal 3.5 mother wavelet, into \n",
    "approximation coefficients A(t) and detail coefficients D(t), as \n",
    "discussed  in  section  2.1.  Set  the  decomposition  level  to  five \n",
    "[12] and extract six components D1, D2, D3, D4, D5, and A5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3200x800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mode = 'constant'\n",
    "components = m_dwt.multilevel_dwt(cierre, wavelet, 5, mode)\n",
    "components_e = m_dwt.multilevel_dwt(cierre_e, wavelet, 5, mode) # componentes de entrenamiento \n",
    "components_p = m_dwt.multilevel_dwt(cierre_p, wavelet, 5, mode) #componentes de prueba\n",
    "# N = len(cierre_p)\n",
    "# print(f\"Longitud de la entrada de A_5: {len(components_p[0])}\")\n",
    "\n",
    "plt.figure(figsize=(32, 8))\n",
    "aprox_coef = True\n",
    "index = 1\n",
    "\n",
    "for _ in components_p:\n",
    "    plt.subplot(2, 3, index)\n",
    "    plt.plot(range(len(_)), _, color='#DA0C81' if aprox_coef else '#610C9F')\n",
    "    plt.title('Componentes de Aproximaci√≥n' if aprox_coef else 'Componentes de Detalle')\n",
    "    aprox_coef = False\n",
    "    index = index + 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "o_data = 0 #original data\n",
    "for c in components_p:\n",
    "    o_data =  o_data + c\n",
    "\n",
    "plt.plot(range(len(o_data)),o_data, color='#DA0C81')\n",
    "plt.plot(range(len(cierre_p)),o_data, color='#610C9F')\n",
    "plt.title('Reconstrucci√≥n a partir de los componentes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coeffs_p_rec_dec = []\n",
    "# components_p_rec_dec.append(pywt.downcoef('a',components_p_rec[0], wavelet, mode=mode,level=5))\n",
    "# coeffs_p_rec_dec.append(pywt.downcoef('d',coeffs_p_rec[1], wavelet, mode=mode,level=5))\n",
    "# coeffs_p_rec_dec.append(pywt.downcoef('d',coeffs_p_rec[2], wavelet, mode=mode,level=4))\n",
    "# coeffs_p_rec_dec.append(pywt.downcoef('d',coeffs_p_rec[3], wavelet, mode=mode,level=3))\n",
    "# coeffs_p_rec_dec.append(pywt.downcoef('d',coeffs_p_rec[4], wavelet, mode=mode,level=2))\n",
    "# coeffs_p_rec_dec.append(pywt.downcoef('d',coeffs_p_rec[5], wavelet, mode=mode,level=1))\n",
    "\n",
    "# plt.figure(figsize=(32, 8))\n",
    "# aprox_coef = True\n",
    "# index = 1\n",
    "\n",
    "# for _ in coeffs_p_rec_dec:\n",
    "#     plt.subplot(2, 3, index)\n",
    "#     plt.plot(range(len(_)), _, color='#DA0C81' if aprox_coef else '#610C9F')\n",
    "#     plt.title('Coeficientes de Aproximaci√≥n' if aprox_coef else 'Coeficientes de Detalle')\n",
    "#     aprox_coef = False\n",
    "#     index = index + 1\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def take(rec, take=0):\n",
    "#     rec_len = len(rec)\n",
    "#     if take > 0 and take < rec_len:\n",
    "#         left_bound = right_bound = (rec_len-take) // 2\n",
    "#         if (rec_len-take) % 2:\n",
    "#             # right_bound must never be zero for indexing to work\n",
    "#             right_bound = right_bound + 1\n",
    "\n",
    "#         return rec[left_bound:-right_bound]\n",
    "    \n",
    "# #print(take([0,1,2,3,4,5,6,7,8,9],take = 2))\n",
    "\n",
    "# A4 = pywt.upcoef('a', coeffs_p[0], wavelet, level = 5, take = 390) + pywt.upcoef('d', coeffs_p[1], wavelet, level = 5, take = 390)\n",
    "# A3 = take(A4, take = 222) + pywt.upcoef('d', coeffs_p[2], wavelet, level = 4, take = 222)\n",
    "# A2 = take(A3, take = 138) + pywt.upcoef('d', coeffs_p[3], wavelet, level = 3, take = 138)\n",
    "# A1 = take(A2, take = 98) + pywt.upcoef('d', coeffs_p[4], wavelet, level = 2, take = 98)\n",
    "# c_final = take(A1, take = 78) + pywt.upcoef('d', coeffs_p[5], wavelet, level = 1, take = 78)\n",
    "# #c_final = coeffs_p_rec[0]+ coeffs_p_rec[1] + coeffs_p_rec[2] + coeffs_p_rec[3] + coeffs_p_rec[4] + coeffs_p_rec[5]\n",
    "# print(c_final)\n",
    "# plt.figure(figsize=(32, 8))\n",
    "# aprox_coef = True\n",
    "# index = 1\n",
    "\n",
    "\n",
    "# plt.plot(range(len(c_final)), c_final, color='#DA0C81' if aprox_coef else '#610C9F')\n",
    "# aprox_coef = False\n",
    "# #plt.plot(range(len(cierre_p)), cierre_p, color='#DA0C81' if aprox_coef else '#610C9F')\n",
    "# plt.title('Coeficientes de Aproximaci√≥n' if aprox_coef else 'Coeficientes de Detalle')\n",
    "\n",
    "# index = index + 1\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Normalize the decomposed components using the Min-Max normalization method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se normalizan cada uno de los elementos de los vectores contenidos en las descomposicion de la serie de tiempo original\n",
    "components_e_n = [utls.normalizar(vect) for vect in components_e] # componentes de entrenamiento normalizados\n",
    "components_p_n = [utls.normalizar(vect) for vect in components_p] # componentes de prueba normalizados len 78\n",
    "\n",
    "#Se concatenan los ultimo 8 elementos del conjunto de entrenamiento para predecir el primero del conjunto de prueba\n",
    "for i in range(len(components_p_n)):\n",
    "    components_p_n[i] = np.concatenate((components_e_n[i][-8:],components_p_n[i]))\n",
    "\n",
    "#Estos 6 arreglos representan la descomposici√≥n de la se√±al original. Se tendr√°n que armar 6 redes que predigan cada una de estas\n",
    "#componentes, Las entradas correspondientes a cada una son las 8 semanas anteriores para calcular la novena\n",
    "\n",
    "#entrenamiento,prueba,validacion = utls.generar_conjuntos(coeffs_n,False,5)\n",
    "#la de abajo es una prueba\n",
    "#entrenamiento,prueba,validacion = utls.generar_conjuntos([[1,2,3,4,5,6,7,8,9,10],[1,2,3,4,5,6,7,8,9,10]],False,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Build  six  NARNNs,  with  the  topology  shown  in Figure 3, to forecast each decomposed component. The number of feedback delays in the TDL is set to eight, i.e., the preceding  eight  weeks'  closing  prices  are  utilized  to  forecast the ninth-week closing price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modelos.LSTM.LSTM import red_LSTM\n",
    "#red_A5 = NARNN(input_dim=8, hidden_dim=0, output_dim=1, num_layers=0)\n",
    "red_A5 = red_LSTM(input_dim =8,output_dim = 1)\n",
    "# red_A5.load_state_dict(torch.load('redes/DWT_Auto_regresivo/red_A5.pth'))\n",
    "# red_A5.eval()\n",
    "\n",
    "red_D5 = red_LSTM(input_dim =8,output_dim = 1)\n",
    "# red_D1.load_state_dict(torch.load('models/red_D1_n.pth'))\n",
    "# red_D1.eval()\n",
    "\n",
    "red_D4 = red_LSTM(input_dim =8,output_dim = 1)\n",
    "# red_D2.load_state_dict(torch.load('models/red_D2_n.pth'))\n",
    "# red_D2.eval()\n",
    "\n",
    "red_D3 = red_LSTM(input_dim =8,output_dim = 1)\n",
    "# red_D3.load_state_dict(torch.load('models/red_D3_n1.pth'))\n",
    "# red_D3.eval()\n",
    "\n",
    "red_D2= red_LSTM(input_dim =8,output_dim = 1)\n",
    "# red_D4.load_state_dict(torch.load('models/red_D4_n1.pth'))\n",
    "# red_D4.eval()\n",
    "\n",
    "red_D1 = red_LSTM(input_dim =8,output_dim = 1)\n",
    "# red_D5.load_state_dict(torch.load(redes[\"red_D5\"]))\n",
    "# red_D5.eval()\n",
    "\n",
    "networks = [red_A5,red_D5,red_D4,red_D3,red_D2,red_D1]\n",
    "\n",
    "#entradas ya procesadas\n",
    "entrenamiento_8_1 = [[],[],[],[],[],[]]\n",
    "X_entrenamiento_n = [[],[],[],[],[],[]]\n",
    "y_entrenamiento_n = [[],[],[],[],[],[]]\n",
    "X_prueba_n = [[],[],[],[],[],[]]\n",
    "y_prueba_n = [[],[],[],[],[],[]]\n",
    "prueba_8_1 = [[],[],[],[],[],[]]\n",
    "serie_c = [[],[],[],[],[],[]]\n",
    "coeffs_n_prueba_8_1 = [[],[],[],[],[],[]]\n",
    "\n",
    "# A cada uno de los conjuntos de entrenamiento se les da una forma de entrada en especifico,\n",
    "# que es un arreglo de 8 y uno de un solo elemento para representar la salida\n",
    "for e in range(6):\n",
    "    # entrenamiento_8_1[e] = utls.corrimiento_t_1(entrenamiento[e],9)\n",
    "    # prueba_8_1[e] = utls.corrimiento_t_1(prueba[e],9)\n",
    "    # serie_c[e] = utls.corrimiento_t_1(coeffs_n[e],9)\n",
    "    # coeffs_n_prueba_8_1[e] = utls.corrimiento_t_1(coeffs_n_prueba[e],9)\n",
    "\n",
    "    subarreglos = []\n",
    "    #print(\"aaaaaaa: \" + str(a))\n",
    "    for i in range(len(components_e_n[e])-8):\n",
    "        X_entrenamiento_n[e].append(components_e_n[e][i:i+8])\n",
    "        y_entrenamiento_n[e].append(components_e_n[e][i+8])\n",
    "    for i in range(len(components_p_n[e])-8):\n",
    "        X_prueba_n[e].append(components_p_n[e][i:i+8])\n",
    "        y_prueba_n[e].append(components_p_n[e][i+8])\n",
    "    X_entrenamiento_n[e], y_entrenamiento_n[e] = np.array(X_entrenamiento_n[e]), np.array(y_entrenamiento_n[e])\n",
    "    X_prueba_n[e], y_prueba_n[e] = np.array(X_prueba_n[e]), np.array(y_prueba_n[e])\n",
    "\n",
    "    #Se le da una tercera dimension al conjunto de entradas de entrenamiento\n",
    "    X_entrenamiento_n[e] = np.reshape(X_entrenamiento_n[e], (X_entrenamiento_n[e].shape[0], X_entrenamiento_n[e].shape[1], 1))\n",
    "    X_prueba_n[e] = np.reshape(X_prueba_n[e], (X_prueba_n[e].shape[0], X_prueba_n[e].shape[1], 1))\n",
    "    \n",
    "\n",
    "    # entrenamiento_8_1[e] = utls.corrimiento_t_1(components_e_n[e],9)\n",
    "    # prueba_8_1[e] = utls.corrimiento_t_1(components_p_n[e],9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Divide the training dataset into three parts: 70% for training, 15% for validation, and 15% as test data. Then train the six NARNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se define el n√∫mero de epocas\n",
    "EPOCAS = 10\n",
    "\n",
    "\n",
    "# imagen_pesos = np.concatenate([parametro.detach().cpu().numpy().flatten() for parametro in red_A5.parameters()])\n",
    "# print(imagen_pesos.shape)\n",
    "# imagen_pesos = imagen_pesos.reshape((1, -1, 1, 1))\n",
    "# print(imagen_pesos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "6/6 [==============================] - 6s 9ms/step - loss: 0.5073\n",
      "Epoch 2/60\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4797\n",
      "Epoch 3/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4502\n",
      "Epoch 4/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4191\n",
      "Epoch 5/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3859\n",
      "Epoch 6/60\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3523\n",
      "Epoch 7/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3092\n",
      "Epoch 8/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2642\n",
      "Epoch 9/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2238\n",
      "Epoch 10/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1745\n",
      "Epoch 11/60\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1243\n",
      "Epoch 12/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0725\n",
      "Epoch 13/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0391\n",
      "Epoch 14/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0201\n",
      "Epoch 15/60\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0202\n",
      "Epoch 16/60\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0180\n",
      "Epoch 17/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0204\n",
      "Epoch 18/60\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0186\n",
      "Epoch 19/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0164\n",
      "Epoch 20/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0176\n",
      "Epoch 21/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0155\n",
      "Epoch 22/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0154\n",
      "Epoch 23/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0175\n",
      "Epoch 24/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0169\n",
      "Epoch 25/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0144\n",
      "Epoch 26/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0167\n",
      "Epoch 27/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0160\n",
      "Epoch 28/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0176\n",
      "Epoch 29/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0184\n",
      "Epoch 30/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0169\n",
      "Epoch 31/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0170\n",
      "Epoch 32/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0138\n",
      "Epoch 33/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0148\n",
      "Epoch 34/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0169\n",
      "Epoch 35/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0141\n",
      "Epoch 36/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0148\n",
      "Epoch 37/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0154\n",
      "Epoch 38/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0154\n",
      "Epoch 39/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0153\n",
      "Epoch 40/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0148\n",
      "Epoch 41/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0139\n",
      "Epoch 42/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0144\n",
      "Epoch 43/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0144\n",
      "Epoch 44/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0135\n",
      "Epoch 45/60\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0135\n",
      "Epoch 46/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0150\n",
      "Epoch 47/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0160\n",
      "Epoch 48/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0127\n",
      "Epoch 49/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0133\n",
      "Epoch 50/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0147\n",
      "Epoch 51/60\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0140\n",
      "Epoch 52/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0144\n",
      "Epoch 53/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0140\n",
      "Epoch 54/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0123\n",
      "Epoch 55/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0148\n",
      "Epoch 56/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0155\n",
      "Epoch 57/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0129\n",
      "Epoch 58/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0137\n",
      "Epoch 59/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0132\n",
      "Epoch 60/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0134\n",
      "[0.5073407292366028, 0.4797179102897644, 0.4502358138561249, 0.41914477944374084, 0.3859056532382965, 0.352272093296051, 0.3091524839401245, 0.26415199041366577, 0.22378572821617126, 0.17448389530181885, 0.12429483979940414, 0.07246271520853043, 0.039141587913036346, 0.020097730681300163, 0.0202390868216753, 0.017959509044885635, 0.020369263365864754, 0.018627412617206573, 0.016383666545152664, 0.01759045012295246, 0.01547134481370449, 0.015350118279457092, 0.01747078076004982, 0.016936879605054855, 0.014392129145562649, 0.01674618571996689, 0.016041269525885582, 0.017615724354982376, 0.0183853842318058, 0.016892055049538612, 0.01695709489285946, 0.013833926990628242, 0.014815256930887699, 0.016889449208974838, 0.014137495309114456, 0.014756472781300545, 0.015448578633368015, 0.015441536903381348, 0.015349778346717358, 0.014799767173826694, 0.013852511532604694, 0.014365552924573421, 0.014437451958656311, 0.013486034236848354, 0.013500220142304897, 0.015049940906465054, 0.015963029116392136, 0.012701747007668018, 0.013290471397340298, 0.014658309519290924, 0.014005213044583797, 0.014364998787641525, 0.013990669511258602, 0.01230333000421524, 0.0147627592086792, 0.015483316034078598, 0.012918146327137947, 0.013694158755242825, 0.013206086121499538, 0.013443905860185623]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam #¬øPor qu√© con SGD no sirve?\n",
    "#entr.entrena_LM(networks[0],0,entrenamiento_8_1,EPOCAS,lr=0.01,Œª =0.1)\n",
    "networks[0].compile(optimizer=Adam(learning_rate=0.0001),loss='mean_squared_error')# mejor, , SGD(learning_rate=0.1)\n",
    "x = X_entrenamiento_n[0]\n",
    "y = y_entrenamiento_n[0]\n",
    "history = networks[0].fit(X_entrenamiento_n[0],y_entrenamiento_n[0],epochs=60,batch_size=32)#batch_size=32\n",
    "# torch.save(red_A5.state_dict(), 'models/red_A5_datos_originales.pth') #Salvamos el estado actual del modelo\n",
    "losses = history.history['loss']\n",
    "print(losses)\n",
    "plt.plot(range(len(losses)),losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entr.entrena_LM(red_D5,1,entrenamiento_8_1,EPOCAS)\n",
    "#torch.save(red_D5.state_dict(), 'models/red_D5_datos_originales.pth') \n",
    "#entr.entrena_LM(red_D4,2,entrenamiento_8_1,EPOCAS)\n",
    "#torch.save(red_D4.state_dict(), 'models/red_D4_datos_originales.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entr.entrena_LM(red_D3,3,entrenamiento_8_1,EPOCAS)\n",
    "# torch.save(red_D3.state_dict(), 'models/red_D3_datos_originales.pth') \n",
    "\n",
    "# entr.entrena_LM(red_D2,4,entrenamiento_8_1,EPOCAS)\n",
    "# torch.save(red_D2.state_dict(), 'models/red_D2_datos_originales.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entr.entrena_LM(red_D5,5,entrenamiento_8_1,EPOCAS)\n",
    "# torch.save(red_D2.state_dict(), 'models/red_D1_datos_originales.pth')\n",
    "#entradas ya procesadas\n",
    "# entrenamiento_8_1 = [[],[],[],[],[],[]]\n",
    "\n",
    "# A cada uno de los conjuntos de entrenamiento se les da una forma de entrada en especifico,\n",
    "# que es un arreglo de 8 y uno de un solo elemento para representar la salida\n",
    "# for e in range(6):\n",
    "#     entrenamiento_8_1[e] = utls.corrimiento_t_1(entrenamiento[e],9)\n",
    "\n",
    "#pruebas_ordenadas = []\n",
    "\n",
    "# for e in range(6):\n",
    "#     entrenamiento_8_1[e] = utls.corrimiento_t_1(entrenamiento[e],9)\n",
    "\n",
    "#for c_pruebas in entrenamiento:#entre\n",
    "    #print(\"corrimiento: \" + str(utls.corrimiento_t_1(c_pruebas,9)))\n",
    " #   pruebas_ordenadas.append(utls.corrimiento_t_1(c_pruebas,9))#prueba[0] es el conjunto de prueba para cada red\n",
    "#pruebas = forma_entrada(prueba[0],9)#prueba[0] es el conjunto de prueba para A1\n",
    "#print(utls.genera_prediccion_1(pruebas_ordenadas[0],red_A1))\n",
    "#print(len(utls.genera_prediccion(pruebas_ordenadas[0],red_A1).detach().numpy().tolist()[0]))\n",
    "#print(entrenamiento[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicci√≥n del conjunto de entrenamiento\n",
    "usando los datos originales para la recurrencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 3ms/step\n",
      "6/6 [==============================] - 2s 3ms/step\n",
      "6/6 [==============================] - 2s 3ms/step\n",
      "6/6 [==============================] - 2s 3ms/step\n",
      "6/6 [==============================] - 2s 3ms/step\n",
      "6/6 [==============================] - 2s 3ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Se grafica el conjunto de entrenamiento\n",
    "perdidas = []\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "aprox_coef = True\n",
    "index = 1\n",
    "\n",
    "for _ in range(len(components_e_n)):\n",
    "    #prediccion = utls.genera_prediccion_1(entrenamiento_8_1[_],networks[_],8)\n",
    "    prediccion = networks[_].predict(X_entrenamiento_n[_])\n",
    "    prediccion = np.reshape(prediccion, (prediccion.shape[0]))\n",
    "    #perdidas.append(criterion(prediccion, torch.tensor(components_e_n[_])))\n",
    "    plt.subplot(2, 3, index)\n",
    "    plt.plot(components_e_n[_], color = '#451952') #color='#DA0C81' if aprox_coef else '#610C9F')\n",
    "    plt.plot(prediccion, label = f\"Perdida: {float(1)}\", color='#AE445A')#label=f\"Datos de Analisis: {DATOS}\",\n",
    "    plt.title('Coeficientes de Aproximaci√≥n' if aprox_coef else 'Coeficientes de Detalle')\n",
    "    aprox_coef = False\n",
    "    plt.legend()\n",
    "    index = index + 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#print(\"Perdidas: \" + str(perdidas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicci√≥n del conjunto de prueba\n",
    "usando los datos originales para la recurrencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perdidas: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "perdidas = []\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "aprox_coef = True\n",
    "index = 1\n",
    "\n",
    "for _ in range(len(components_p_n)):\n",
    "    #prediccion = utls.genera_prediccion_1(prueba_8_1[_],networks[_],8)\n",
    "    prediccion = networks[_].predict(X_prueba_n[_])\n",
    "    prediccion = np.reshape(prediccion, (prediccion.shape[0]))\n",
    "    #perdidas.append(criterion(prediccion, torch.tensor(components_p_n[_])))\n",
    "    plt.subplot(2, 3, index)\n",
    "    plt.plot(components_p_n[_]) #color='#DA0C81' if aprox_coef else '#610C9F')\n",
    "    plt.plot(prediccion, label = f\"Perdida: {1}\" ,color='#DA0C81')#label=f\"Datos de Analisis: {DATOS}\",#float(perdidas[_])\n",
    "    \n",
    "    plt.title('Coeficientes de Aproximaci√≥n' if aprox_coef else 'Coeficientes de Detalle')\n",
    "    aprox_coef = False\n",
    "    plt.legend()\n",
    "    index = index + 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Perdidas: \" + str(perdidas))\n",
    "\n",
    "#Se grafica el conjunto de pruebas\n",
    "# plt.plot(range(len(prueba[0])), prueba[0])\n",
    "# plt.plot(range(len(prueba[0])), utls.genera_prediccion_1(prueba_8_1[0],red_A1,8).detach().numpy())\n",
    "# plt.show(\n",
    "\n",
    "#plt.plot(range(108), entrenamiento[0][:-8])\n",
    "#plt.plot(range(108), [utls.desnormalizar(vect) for vect in utls.genera_prediccion(pruebas_ordenadas[0],red_A1).detach().numpy().tolist()[0]])\n",
    "# Mostrar el gr√°fico\n",
    "#plt.show()\n",
    "#investigar bien la dwt y predecir la red con los corrimientos de 1, usando los datos que predice o solo los datos que le doy\n",
    "#Lo que hace es generar una prediccion cada noveno d√≠a, con los datos que ya se le dan del entrenamiento, es preciso ajustar los parametros hasta que ambas series\n",
    "#sean iguales\n",
    "#print(prueba[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(entrenamiento_8_1[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generamos el entrenamiento predictivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_entrenamiento: [0.04942463 0.10789186 0.1371961  0.13733737 0.1338857  0.1268411\n",
      " 0.14756061 0.19604423 0.21688968 0.21009695 0.20267785 0.19463237\n",
      " 0.19407352 0.2010013  0.19663821 0.18098423 0.16539041 0.14985674\n",
      " 0.15043111 0.16711353 0.20227035 0.2559016  0.2926882  0.31263018\n",
      " 0.31093888 0.28761432 0.28016165 0.28858086 0.28246282 0.26180754\n",
      " 0.28012129 0.33740406 0.34822982 0.31259855 0.3435871  0.44119547\n",
      " 0.52109532 0.58328665 0.60892345 0.59800572 0.59453019 0.59849685\n",
      " 0.62135434 0.66310268 0.69287243 0.71066362 0.72168206 0.72592776\n",
      " 0.74043182 0.76519426 0.7447891  0.67921634 0.67460177 0.73094536\n",
      " 0.74672101 0.72192869 0.71992867 0.74072095 0.7362455  0.70650233\n",
      " 0.69794515 0.71057397 0.72096215 0.7291097  0.76742596 0.83591094\n",
      " 0.85101034 0.81272415 0.78639403 0.77201997 0.80331706 0.88028528\n",
      " 0.89870517 0.85857672 0.83087626 0.81560377 0.81169921 0.81916255\n",
      " 0.82182756 0.81969424 0.81786284 0.81633338 0.80055561 0.77052952\n",
      " 0.74265868 0.7169431  0.71970513 0.75094478 0.74027814 0.68770522\n",
      " 0.66876956 0.68347116 0.68770522 0.68147172 0.68926184 0.71107557\n",
      " 0.73491086 0.76076771 0.77111708 0.76595899 0.74833235 0.71823718\n",
      " 0.70894166 0.7204458  0.77061548 0.8594507  0.90654108 0.91188662\n",
      " 0.90433557 0.88388791 0.90321535 0.96231788 0.98205882 0.96243818\n",
      " 0.93025121 0.8854979  0.85970257 0.85286521 0.85858545 0.8768633\n",
      " 0.8806464  0.86993474 0.84651354 0.81038281 0.80261112 0.82319849\n",
      " 0.83972043 0.85217693 0.86156268 0.86787767 0.87019631 0.8685186\n",
      " 0.85298804 0.82360463 0.80325089 0.79192683 0.78650231 0.78697733\n",
      " 0.78743624 0.78787905 0.7954532  0.81015868 0.76684732 0.66551912\n",
      " 0.6360738  0.67851138 0.69659673 0.69032987 0.69704731 0.71674905\n",
      " 0.74905071 0.79395226 0.85474473 0.93142809 0.9627244  0.94863365\n",
      " 0.93071459 0.90896722 0.88163797 0.84872682 0.87526069 0.96123957\n",
      " 0.99250211 0.96904832 0.97154761 1.         0.98006365 0.91173857\n",
      " 0.89108579 0.91810533 0.94501652 0.97181936 0.98290672 0.97827858]\n",
      "0\n",
      "ejemplar: [[0.05029815]\n",
      " [0.00860651]\n",
      " [0.        ]\n",
      " [0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.049424632939554\n",
      "Predicci√≥n : [[0.21258116]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.05029815]\n",
      "  [0.00860651]\n",
      "  [0.        ]\n",
      "  [0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02662005089223385\n",
      "Predicci√≥n post entrenamiento : [[0.17842343]]\n",
      "PERDIDAAAA despues: 0.016640691086649895\n",
      "loss en el callback: 0.02473936416208744, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "ejemplar: [[0.00860651]\n",
      " [0.        ]\n",
      " [0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.21258116]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.10789185692558968\n",
      "Predicci√≥n : [[0.17355043]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.00860651]\n",
      "  [0.        ]\n",
      "  [0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.21258116]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0043110474944114685\n",
      "Predicci√≥n post entrenamiento : [[0.16460806]]\n",
      "PERDIDAAAA despues: 0.0032167278695851564\n",
      "loss en el callback: 0.002205262193456292, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "ejemplar: [[0.        ]\n",
      " [0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.21258116]\n",
      " [0.17355043]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.13719610119365802\n",
      "Predicci√≥n : [[0.16914523]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[[0.        ]\n",
      "  [0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.21258116]\n",
      "  [0.17355043]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010207471204921603\n",
      "Predicci√≥n post entrenamiento : [[0.16252737]]\n",
      "PERDIDAAAA despues: 0.0006416734540835023\n",
      "loss en el callback: 0.0018594895955175161, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "ejemplar: [[0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.21258116]\n",
      " [0.17355043]\n",
      " [0.16914523]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.13733736574375907\n",
      "Predicci√≥n : [[0.17202005]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[[0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.21258116]\n",
      "  [0.17355043]\n",
      "  [0.16914523]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012028879718855023\n",
      "Predicci√≥n post entrenamiento : [[0.1694654]]\n",
      "PERDIDAAAA despues: 0.0010322097223252058\n",
      "loss en el callback: 0.0006072982214391232, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "ejemplar: [[0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.21258116]\n",
      " [0.17355043]\n",
      " [0.16914523]\n",
      " [0.17202005]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.13388569841244483\n",
      "Predicci√≥n : [[0.17828411]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[[0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.21258116]\n",
      "  [0.17355043]\n",
      "  [0.16914523]\n",
      "  [0.17202005]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001971218967810273\n",
      "Predicci√≥n post entrenamiento : [[0.17230299]]\n",
      "PERDIDAAAA despues: 0.0014758885372430086\n",
      "loss en el callback: 0.00394177483394742, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "ejemplar: [[0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.21258116]\n",
      " [0.17355043]\n",
      " [0.16914523]\n",
      " [0.17202005]\n",
      " [0.17828411]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.12684109919971556\n",
      "Predicci√≥n : [[0.18370114]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[[0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.21258116]\n",
      "  [0.17355043]\n",
      "  [0.16914523]\n",
      "  [0.17202005]\n",
      "  [0.17828411]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003233064664527774\n",
      "Predicci√≥n post entrenamiento : [[0.180261]]\n",
      "PERDIDAAAA despues: 0.0028536859899759293\n",
      "loss en el callback: 0.002448691288009286, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "ejemplar: [[0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.21258116]\n",
      " [0.17355043]\n",
      " [0.16914523]\n",
      " [0.17202005]\n",
      " [0.17828411]\n",
      " [0.18370114]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14756061137847282\n",
      "Predicci√≥n : [[0.19798017]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[[0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.21258116]\n",
      "  [0.17355043]\n",
      "  [0.16914523]\n",
      "  [0.17202005]\n",
      "  [0.17828411]\n",
      "  [0.18370114]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002542131347581744\n",
      "Predicci√≥n post entrenamiento : [[0.19579901]]\n",
      "PERDIDAAAA despues: 0.0023269429802894592\n",
      "loss en el callback: 0.0012435612734407187, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "ejemplar: [[0.0202993 ]\n",
      " [0.21258116]\n",
      " [0.17355043]\n",
      " [0.16914523]\n",
      " [0.17202005]\n",
      " [0.17828411]\n",
      " [0.18370114]\n",
      " [0.19798017]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19604423494871648\n",
      "Predicci√≥n : [[0.21986505]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[[0.0202993 ]\n",
      "  [0.21258116]\n",
      "  [0.17355043]\n",
      "  [0.16914523]\n",
      "  [0.17202005]\n",
      "  [0.17828411]\n",
      "  [0.18370114]\n",
      "  [0.19798017]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000567431328818202\n",
      "Predicci√≥n post entrenamiento : [[0.2189535]]\n",
      "PERDIDAAAA despues: 0.0005248346133157611\n",
      "loss en el callback: 0.0002893427445087582, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "ejemplar: [[0.21258116]\n",
      " [0.17355043]\n",
      " [0.16914523]\n",
      " [0.17202005]\n",
      " [0.17828411]\n",
      " [0.18370114]\n",
      " [0.19798017]\n",
      " [0.21986505]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.21688968214535215\n",
      "Predicci√≥n : [[0.24921082]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[[0.21258116]\n",
      "  [0.17355043]\n",
      "  [0.16914523]\n",
      "  [0.17202005]\n",
      "  [0.17828411]\n",
      "  [0.18370114]\n",
      "  [0.19798017]\n",
      "  [0.21986505]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010446561500430107\n",
      "Predicci√≥n post entrenamiento : [[0.2489119]]\n",
      "PERDIDAAAA despues: 0.0010254227090626955\n",
      "loss en el callback: 3.91576650144998e-05, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "ejemplar: [[0.17355043]\n",
      " [0.16914523]\n",
      " [0.17202005]\n",
      " [0.17828411]\n",
      " [0.18370114]\n",
      " [0.19798017]\n",
      " [0.21986505]\n",
      " [0.24921082]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2100969529683796\n",
      "Predicci√≥n : [[0.24309684]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[[0.17355043]\n",
      "  [0.16914523]\n",
      "  [0.17202005]\n",
      "  [0.17828411]\n",
      "  [0.18370114]\n",
      "  [0.19798017]\n",
      "  [0.21986505]\n",
      "  [0.24921082]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010889925761148334\n",
      "Predicci√≥n post entrenamiento : [[0.23924826]]\n",
      "PERDIDAAAA despues: 0.0008497986127622426\n",
      "loss en el callback: 0.005300301592797041, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "ejemplar: [[0.16914523]\n",
      " [0.17202005]\n",
      " [0.17828411]\n",
      " [0.18370114]\n",
      " [0.19798017]\n",
      " [0.21986505]\n",
      " [0.24921082]\n",
      " [0.24309684]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2026778474621132\n",
      "Predicci√≥n : [[0.24208374]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[[0.16914523]\n",
      "  [0.17202005]\n",
      "  [0.17828411]\n",
      "  [0.18370114]\n",
      "  [0.19798017]\n",
      "  [0.21986505]\n",
      "  [0.24921082]\n",
      "  [0.24309684]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015528247458860278\n",
      "Predicci√≥n post entrenamiento : [[0.23816895]]\n",
      "PERDIDAAAA despues: 0.0012596187880262733\n",
      "loss en el callback: 0.006309946067631245, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "ejemplar: [[0.17202005]\n",
      " [0.17828411]\n",
      " [0.18370114]\n",
      " [0.19798017]\n",
      " [0.21986505]\n",
      " [0.24921082]\n",
      " [0.24309684]\n",
      " [0.24208374]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19463236562655295\n",
      "Predicci√≥n : [[0.2437247]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[[0.17202005]\n",
      "  [0.17828411]\n",
      "  [0.18370114]\n",
      "  [0.19798017]\n",
      "  [0.21986505]\n",
      "  [0.24921082]\n",
      "  [0.24309684]\n",
      "  [0.24208374]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0024100576993077993\n",
      "Predicci√≥n post entrenamiento : [[0.24113701]]\n",
      "PERDIDAAAA despues: 0.0021626821253448725\n",
      "loss en el callback: 0.003878867020830512, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "ejemplar: [[0.17828411]\n",
      " [0.18370114]\n",
      " [0.19798017]\n",
      " [0.21986505]\n",
      " [0.24921082]\n",
      " [0.24309684]\n",
      " [0.24208374]\n",
      " [0.2437247 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19407351685692253\n",
      "Predicci√≥n : [[0.24828002]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[[0.17828411]\n",
      "  [0.18370114]\n",
      "  [0.19798017]\n",
      "  [0.21986505]\n",
      "  [0.24921082]\n",
      "  [0.24309684]\n",
      "  [0.24208374]\n",
      "  [0.2437247 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002938345307484269\n",
      "Predicci√≥n post entrenamiento : [[0.2472265]]\n",
      "PERDIDAAAA despues: 0.0028252406045794487\n",
      "loss en el callback: 0.0009689155267551541, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "ejemplar: [[0.18370114]\n",
      " [0.19798017]\n",
      " [0.21986505]\n",
      " [0.24921082]\n",
      " [0.24309684]\n",
      " [0.24208374]\n",
      " [0.2437247 ]\n",
      " [0.24828002]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.20100130115322212\n",
      "Predicci√≥n : [[0.25535172]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[[0.18370114]\n",
      "  [0.19798017]\n",
      "  [0.21986505]\n",
      "  [0.24921082]\n",
      "  [0.24309684]\n",
      "  [0.24208374]\n",
      "  [0.2437247 ]\n",
      "  [0.24828002]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002953968243673444\n",
      "Predicci√≥n post entrenamiento : [[0.25577715]]\n",
      "PERDIDAAAA despues: 0.0030003937426954508\n",
      "loss en el callback: 0.0002537842665333301, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "ejemplar: [[0.19798017]\n",
      " [0.21986505]\n",
      " [0.24921082]\n",
      " [0.24309684]\n",
      " [0.24208374]\n",
      " [0.2437247 ]\n",
      " [0.24828002]\n",
      " [0.25535172]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19663820581116015\n",
      "Predicci√≥n : [[0.265042]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[[0.19798017]\n",
      "  [0.21986505]\n",
      "  [0.24921082]\n",
      "  [0.24309684]\n",
      "  [0.24208374]\n",
      "  [0.2437247 ]\n",
      "  [0.24828002]\n",
      "  [0.25535172]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004679079167544842\n",
      "Predicci√≥n post entrenamiento : [[0.26358584]]\n",
      "PERDIDAAAA despues: 0.004481984302401543\n",
      "loss en el callback: 0.002480370458215475, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "ejemplar: [[0.21986505]\n",
      " [0.24921082]\n",
      " [0.24309684]\n",
      " [0.24208374]\n",
      " [0.2437247 ]\n",
      " [0.24828002]\n",
      " [0.25535172]\n",
      " [0.26504201]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1809842308307365\n",
      "Predicci√≥n : [[0.27195856]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[[0.21986505]\n",
      "  [0.24921082]\n",
      "  [0.24309684]\n",
      "  [0.24208374]\n",
      "  [0.2437247 ]\n",
      "  [0.24828002]\n",
      "  [0.25535172]\n",
      "  [0.26504201]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008276328444480896\n",
      "Predicci√≥n post entrenamiento : [[0.26866886]]\n",
      "PERDIDAAAA despues: 0.00768859451636672\n",
      "loss en el callback: 0.011076985858380795, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "ejemplar: [[0.24921082]\n",
      " [0.24309684]\n",
      " [0.24208374]\n",
      " [0.2437247 ]\n",
      " [0.24828002]\n",
      " [0.25535172]\n",
      " [0.26504201]\n",
      " [0.27195856]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1653904097109329\n",
      "Predicci√≥n : [[0.27407187]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[[0.24921082]\n",
      "  [0.24309684]\n",
      "  [0.24208374]\n",
      "  [0.2437247 ]\n",
      "  [0.24828002]\n",
      "  [0.25535172]\n",
      "  [0.26504201]\n",
      "  [0.27195856]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01181165874004364\n",
      "Predicci√≥n post entrenamiento : [[0.27040267]]\n",
      "PERDIDAAAA despues: 0.011027573607861996\n",
      "loss en el callback: 0.015103031881153584, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "ejemplar: [[0.24309684]\n",
      " [0.24208374]\n",
      " [0.2437247 ]\n",
      " [0.24828002]\n",
      " [0.25535172]\n",
      " [0.26504201]\n",
      " [0.27195856]\n",
      " [0.27407187]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14985674245174896\n",
      "Predicci√≥n : [[0.27056807]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[[0.24309684]\n",
      "  [0.24208374]\n",
      "  [0.2437247 ]\n",
      "  [0.24828002]\n",
      "  [0.25535172]\n",
      "  [0.26504201]\n",
      "  [0.27195856]\n",
      "  [0.27407187]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014571224339306355\n",
      "Predicci√≥n post entrenamiento : [[0.26749614]]\n",
      "PERDIDAAAA despues: 0.013839026913046837\n",
      "loss en el callback: 0.013871538452804089, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "ejemplar: [[0.24208374]\n",
      " [0.2437247 ]\n",
      " [0.24828002]\n",
      " [0.25535172]\n",
      " [0.26504201]\n",
      " [0.27195856]\n",
      " [0.27407187]\n",
      " [0.27056807]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.15043111479831345\n",
      "Predicci√≥n : [[0.26960182]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[[0.24208374]\n",
      "  [0.2437247 ]\n",
      "  [0.24828002]\n",
      "  [0.25535172]\n",
      "  [0.26504201]\n",
      "  [0.27195856]\n",
      "  [0.27407187]\n",
      "  [0.27056807]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014201657846570015\n",
      "Predicci√≥n post entrenamiento : [[0.26620927]]\n",
      "PERDIDAAAA despues: 0.013404582627117634\n",
      "loss en el callback: 0.01609293930232525, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "ejemplar: [[0.2437247 ]\n",
      " [0.24828002]\n",
      " [0.25535172]\n",
      " [0.26504201]\n",
      " [0.27195856]\n",
      " [0.27407187]\n",
      " [0.27056807]\n",
      " [0.26960182]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.16711352675062616\n",
      "Predicci√≥n : [[0.26941928]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[[0.2437247 ]\n",
      "  [0.24828002]\n",
      "  [0.25535172]\n",
      "  [0.26504201]\n",
      "  [0.27195856]\n",
      "  [0.27407187]\n",
      "  [0.27056807]\n",
      "  [0.26960182]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010466467589139938\n",
      "Predicci√≥n post entrenamiento : [[0.2669225]]\n",
      "PERDIDAAAA despues: 0.009961831383407116\n",
      "loss en el callback: 0.010950843803584576, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "ejemplar: [[0.24828002]\n",
      " [0.25535172]\n",
      " [0.26504201]\n",
      " [0.27195856]\n",
      " [0.27407187]\n",
      " [0.27056807]\n",
      " [0.26960182]\n",
      " [0.26941928]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2022703535675908\n",
      "Predicci√≥n : [[0.27072895]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[[0.24828002]\n",
      "  [0.25535172]\n",
      "  [0.26504201]\n",
      "  [0.27195856]\n",
      "  [0.27407187]\n",
      "  [0.27056807]\n",
      "  [0.26960182]\n",
      "  [0.26941928]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004686578176915646\n",
      "Predicci√≥n post entrenamiento : [[0.26907519]]\n",
      "PERDIDAAAA despues: 0.004462884739041328\n",
      "loss en el callback: 0.005354931578040123, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "ejemplar: [[0.25535172]\n",
      " [0.26504201]\n",
      " [0.27195856]\n",
      " [0.27407187]\n",
      " [0.27056807]\n",
      " [0.26960182]\n",
      " [0.26941928]\n",
      " [0.27072895]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.25590159524920725\n",
      "Predicci√≥n : [[0.2727819]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[[0.25535172]\n",
      "  [0.26504201]\n",
      "  [0.27195856]\n",
      "  [0.27407187]\n",
      "  [0.27056807]\n",
      "  [0.26960182]\n",
      "  [0.26941928]\n",
      "  [0.27072895]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00028494466096162796\n",
      "Predicci√≥n post entrenamiento : [[0.27186358]]\n",
      "PERDIDAAAA despues: 0.0002547846524976194\n",
      "loss en el callback: 0.0014889384619891644, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "ejemplar: [[0.26504201]\n",
      " [0.27195856]\n",
      " [0.27407187]\n",
      " [0.27056807]\n",
      " [0.26960182]\n",
      " [0.26941928]\n",
      " [0.27072895]\n",
      " [0.27278191]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.292688203599549\n",
      "Predicci√≥n : [[0.27474615]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[[0.26504201]\n",
      "  [0.27195856]\n",
      "  [0.27407187]\n",
      "  [0.27056807]\n",
      "  [0.26960182]\n",
      "  [0.26941928]\n",
      "  [0.27072895]\n",
      "  [0.27278191]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00032191682839766145\n",
      "Predicci√≥n post entrenamiento : [[0.27551958]]\n",
      "PERDIDAAAA despues: 0.0002947612083517015\n",
      "loss en el callback: 0.001563476980663836, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "ejemplar: [[0.27195856]\n",
      " [0.27407187]\n",
      " [0.27056807]\n",
      " [0.26960182]\n",
      " [0.26941928]\n",
      " [0.27072895]\n",
      " [0.27278191]\n",
      " [0.27474615]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31263017861861575\n",
      "Predicci√≥n : [[0.2767495]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[[0.27195856]\n",
      "  [0.27407187]\n",
      "  [0.27056807]\n",
      "  [0.26960182]\n",
      "  [0.26941928]\n",
      "  [0.27072895]\n",
      "  [0.27278191]\n",
      "  [0.27474615]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012874235399067402\n",
      "Predicci√≥n post entrenamiento : [[0.27718273]]\n",
      "PERDIDAAAA despues: 0.0012565215583890676\n",
      "loss en el callback: 0.00045521045103669167, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "ejemplar: [[0.27407187]\n",
      " [0.27056807]\n",
      " [0.26960182]\n",
      " [0.26941928]\n",
      " [0.27072895]\n",
      " [0.27278191]\n",
      " [0.27474615]\n",
      " [0.27674949]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3109388849116374\n",
      "Predicci√≥n : [[0.2770906]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[[0.27407187]\n",
      "  [0.27056807]\n",
      "  [0.26960182]\n",
      "  [0.26941928]\n",
      "  [0.27072895]\n",
      "  [0.27278191]\n",
      "  [0.27474615]\n",
      "  [0.27674949]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011457063956186175\n",
      "Predicci√≥n post entrenamiento : [[0.2776461]]\n",
      "PERDIDAAAA despues: 0.0011084105353802443\n",
      "loss en el callback: 0.0008437150972895324, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "ejemplar: [[0.27056807]\n",
      " [0.26960182]\n",
      " [0.26941928]\n",
      " [0.27072895]\n",
      " [0.27278191]\n",
      " [0.27474615]\n",
      " [0.27674949]\n",
      " [0.27709061]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2876143224786136\n",
      "Predicci√≥n : [[0.27713856]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[[0.27056807]\n",
      "  [0.26960182]\n",
      "  [0.26941928]\n",
      "  [0.27072895]\n",
      "  [0.27278191]\n",
      "  [0.27474615]\n",
      "  [0.27674949]\n",
      "  [0.27709061]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00010974143515340984\n",
      "Predicci√≥n post entrenamiento : [[0.27734876]]\n",
      "PERDIDAAAA despues: 0.00010538170317886397\n",
      "loss en el callback: 0.00012394468649290502, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "ejemplar: [[0.26960182]\n",
      " [0.26941928]\n",
      " [0.27072895]\n",
      " [0.27278191]\n",
      " [0.27474615]\n",
      " [0.27674949]\n",
      " [0.27709061]\n",
      " [0.27713856]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.280161647237227\n",
      "Predicci√≥n : [[0.27767858]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[[0.26960182]\n",
      "  [0.26941928]\n",
      "  [0.27072895]\n",
      "  [0.27278191]\n",
      "  [0.27474615]\n",
      "  [0.27674949]\n",
      "  [0.27709061]\n",
      "  [0.27713856]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.165636023069965e-06\n",
      "Predicci√≥n post entrenamiento : [[0.2774612]]\n",
      "PERDIDAAAA despues: 7.292419468285516e-06\n",
      "loss en el callback: 0.00015146635996643454, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "ejemplar: [[0.26941928]\n",
      " [0.27072895]\n",
      " [0.27278191]\n",
      " [0.27474615]\n",
      " [0.27674949]\n",
      " [0.27709061]\n",
      " [0.27713856]\n",
      " [0.27767858]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2885808591874776\n",
      "Predicci√≥n : [[0.2782066]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[[0.26941928]\n",
      "  [0.27072895]\n",
      "  [0.27278191]\n",
      "  [0.27474615]\n",
      "  [0.27674949]\n",
      "  [0.27709061]\n",
      "  [0.27713856]\n",
      "  [0.27767858]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001076256376109086\n",
      "Predicci√≥n post entrenamiento : [[0.27871668]]\n",
      "PERDIDAAAA despues: 9.73020723904483e-05\n",
      "loss en el callback: 0.0008454836788587272, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "ejemplar: [[0.27072895]\n",
      " [0.27278191]\n",
      " [0.27474615]\n",
      " [0.27674949]\n",
      " [0.27709061]\n",
      " [0.27713856]\n",
      " [0.27767858]\n",
      " [0.27820659]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2824628234730068\n",
      "Predicci√≥n : [[0.27975988]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[[0.27072895]\n",
      "  [0.27278191]\n",
      "  [0.27474615]\n",
      "  [0.27674949]\n",
      "  [0.27709061]\n",
      "  [0.27713856]\n",
      "  [0.27767858]\n",
      "  [0.27820659]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.305946382984985e-06\n",
      "Predicci√≥n post entrenamiento : [[0.2808222]]\n",
      "PERDIDAAAA despues: 2.6917246032098774e-06\n",
      "loss en el callback: 0.006308142561465502, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "ejemplar: [[0.27278191]\n",
      " [0.27474615]\n",
      " [0.27674949]\n",
      " [0.27709061]\n",
      " [0.27713856]\n",
      " [0.27767858]\n",
      " [0.27820659]\n",
      " [0.27975988]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.26180754009381474\n",
      "Predicci√≥n : [[0.28185436]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[[0.27278191]\n",
      "  [0.27474615]\n",
      "  [0.27674949]\n",
      "  [0.27709061]\n",
      "  [0.27713856]\n",
      "  [0.27767858]\n",
      "  [0.27820659]\n",
      "  [0.27975988]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00040187541162595153\n",
      "Predicci√≥n post entrenamiento : [[0.2810205]]\n",
      "PERDIDAAAA despues: 0.00036913788062520325\n",
      "loss en el callback: 0.002335282741114497, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "ejemplar: [[0.27474615]\n",
      " [0.27674949]\n",
      " [0.27709061]\n",
      " [0.27713856]\n",
      " [0.27767858]\n",
      " [0.27820659]\n",
      " [0.27975988]\n",
      " [0.28185436]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2801212859371977\n",
      "Predicci√≥n : [[0.28185663]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[[0.27474615]\n",
      "  [0.27674949]\n",
      "  [0.27709061]\n",
      "  [0.27713856]\n",
      "  [0.27767858]\n",
      "  [0.27820659]\n",
      "  [0.27975988]\n",
      "  [0.28185436]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.011369017258403e-06\n",
      "Predicci√≥n post entrenamiento : [[0.28159016]]\n",
      "PERDIDAAAA despues: 2.157570406779996e-06\n",
      "loss en el callback: 0.00028143401141278446, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "ejemplar: [[0.27674949]\n",
      " [0.27709061]\n",
      " [0.27713856]\n",
      " [0.27767858]\n",
      " [0.27820659]\n",
      " [0.27975988]\n",
      " [0.28185436]\n",
      " [0.28185663]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3374040610031557\n",
      "Predicci√≥n : [[0.28221124]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[[0.27674949]\n",
      "  [0.27709061]\n",
      "  [0.27713856]\n",
      "  [0.27767858]\n",
      "  [0.27820659]\n",
      "  [0.27975988]\n",
      "  [0.28185436]\n",
      "  [0.28185663]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0030462483409792185\n",
      "Predicci√≥n post entrenamiento : [[0.28306633]]\n",
      "PERDIDAAAA despues: 0.002952589886263013\n",
      "loss en el callback: 0.003019918454810977, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "ejemplar: [[0.27709061]\n",
      " [0.27713856]\n",
      " [0.27767858]\n",
      " [0.27820659]\n",
      " [0.27975988]\n",
      " [0.28185436]\n",
      " [0.28185663]\n",
      " [0.28221124]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3482298154676272\n",
      "Predicci√≥n : [[0.28342703]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[[0.27709061]\n",
      "  [0.27713856]\n",
      "  [0.27767858]\n",
      "  [0.27820659]\n",
      "  [0.27975988]\n",
      "  [0.28185436]\n",
      "  [0.28185663]\n",
      "  [0.28221124]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004199402406811714\n",
      "Predicci√≥n post entrenamiento : [[0.2845106]]\n",
      "PERDIDAAAA despues: 0.004060138016939163\n",
      "loss en el callback: 0.005094009451568127, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "ejemplar: [[0.27713856]\n",
      " [0.27767858]\n",
      " [0.27820659]\n",
      " [0.27975988]\n",
      " [0.28185436]\n",
      " [0.28185663]\n",
      " [0.28221124]\n",
      " [0.28342703]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31259854933061226\n",
      "Predicci√≥n : [[0.28495443]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[[0.27713856]\n",
      "  [0.27767858]\n",
      "  [0.27820659]\n",
      "  [0.27975988]\n",
      "  [0.28185436]\n",
      "  [0.28185663]\n",
      "  [0.28221124]\n",
      "  [0.28342703]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007641977863386273\n",
      "Predicci√≥n post entrenamiento : [[0.2857818]]\n",
      "PERDIDAAAA despues: 0.0007191383629105985\n",
      "loss en el callback: 0.003868374042212963, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "ejemplar: [[0.27767858]\n",
      " [0.27820659]\n",
      " [0.27975988]\n",
      " [0.28185436]\n",
      " [0.28185663]\n",
      " [0.28221124]\n",
      " [0.28342703]\n",
      " [0.28495443]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.34358710169603873\n",
      "Predicci√≥n : [[0.28639844]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[[0.27767858]\n",
      "  [0.27820659]\n",
      "  [0.27975988]\n",
      "  [0.28185436]\n",
      "  [0.28185663]\n",
      "  [0.28221124]\n",
      "  [0.28342703]\n",
      "  [0.28495443]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0032705427147448063\n",
      "Predicci√≥n post entrenamiento : [[0.28761902]]\n",
      "PERDIDAAAA despues: 0.003132425481453538\n",
      "loss en el callback: 0.010690171271562576, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "ejemplar: [[0.27820659]\n",
      " [0.27975988]\n",
      " [0.28185436]\n",
      " [0.28185663]\n",
      " [0.28221124]\n",
      " [0.28342703]\n",
      " [0.28495443]\n",
      " [0.28639844]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.4411954725639069\n",
      "Predicci√≥n : [[0.28833163]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[[0.27820659]\n",
      "  [0.27975988]\n",
      "  [0.28185436]\n",
      "  [0.28185663]\n",
      "  [0.28221124]\n",
      "  [0.28342703]\n",
      "  [0.28495443]\n",
      "  [0.28639844]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.023367350921034813\n",
      "Predicci√≥n post entrenamiento : [[0.29055536]]\n",
      "PERDIDAAAA despues: 0.022692440077662468\n",
      "loss en el callback: 0.02715151198208332, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "ejemplar: [[0.27975988]\n",
      " [0.28185436]\n",
      " [0.28185663]\n",
      " [0.28221124]\n",
      " [0.28342703]\n",
      " [0.28495443]\n",
      " [0.28639844]\n",
      " [0.28833163]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5210953230441133\n",
      "Predicci√≥n : [[0.2913906]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[[0.27975988]\n",
      "  [0.28185436]\n",
      "  [0.28185663]\n",
      "  [0.28221124]\n",
      "  [0.28342703]\n",
      "  [0.28495443]\n",
      "  [0.28639844]\n",
      "  [0.28833163]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05276426672935486\n",
      "Predicci√≥n post entrenamiento : [[0.29450932]]\n",
      "PERDIDAAAA despues: 0.0513412207365036\n",
      "loss en el callback: 0.05724237486720085, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "ejemplar: [[0.28185436]\n",
      " [0.28185663]\n",
      " [0.28221124]\n",
      " [0.28342703]\n",
      " [0.28495443]\n",
      " [0.28639844]\n",
      " [0.28833163]\n",
      " [0.2913906 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5832866531366584\n",
      "Predicci√≥n : [[0.29526842]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[[0.28185436]\n",
      "  [0.28185663]\n",
      "  [0.28221124]\n",
      "  [0.28342703]\n",
      "  [0.28495443]\n",
      "  [0.28639844]\n",
      "  [0.28833163]\n",
      "  [0.2913906 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08295449614524841\n",
      "Predicci√≥n post entrenamiento : [[0.29885566]]\n",
      "PERDIDAAAA despues: 0.08090098202228546\n",
      "loss en el callback: 0.07853399217128754, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "ejemplar: [[0.28185663]\n",
      " [0.28221124]\n",
      " [0.28342703]\n",
      " [0.28495443]\n",
      " [0.28639844]\n",
      " [0.28833163]\n",
      " [0.2913906 ]\n",
      " [0.29526842]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6089234523540271\n",
      "Predicci√≥n : [[0.29943573]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[[0.28185663]\n",
      "  [0.28221124]\n",
      "  [0.28342703]\n",
      "  [0.28495443]\n",
      "  [0.28639844]\n",
      "  [0.28833163]\n",
      "  [0.2913906 ]\n",
      "  [0.29526842]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09578263759613037\n",
      "Predicci√≥n post entrenamiento : [[0.30338937]]\n",
      "PERDIDAAAA despues: 0.09335106611251831\n",
      "loss en el callback: 0.10710698366165161, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "ejemplar: [[0.28221124]\n",
      " [0.28342703]\n",
      " [0.28495443]\n",
      " [0.28639844]\n",
      " [0.28833163]\n",
      " [0.2913906 ]\n",
      " [0.29526842]\n",
      " [0.29943573]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.59800572069622\n",
      "Predicci√≥n : [[0.30429694]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[[0.28221124]\n",
      "  [0.28342703]\n",
      "  [0.28495443]\n",
      "  [0.28639844]\n",
      "  [0.28833163]\n",
      "  [0.2913906 ]\n",
      "  [0.29526842]\n",
      "  [0.29943573]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08626484125852585\n",
      "Predicci√≥n post entrenamiento : [[0.3079017]]\n",
      "PERDIDAAAA despues: 0.08416033536195755\n",
      "loss en el callback: 0.07785782217979431, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "ejemplar: [[0.28342703]\n",
      " [0.28495443]\n",
      " [0.28639844]\n",
      " [0.28833163]\n",
      " [0.2913906 ]\n",
      " [0.29526842]\n",
      " [0.29943573]\n",
      " [0.30429694]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5945301858653699\n",
      "Predicci√≥n : [[0.30917397]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[[0.28342703]\n",
      "  [0.28495443]\n",
      "  [0.28639844]\n",
      "  [0.28833163]\n",
      "  [0.2913906 ]\n",
      "  [0.29526842]\n",
      "  [0.29943573]\n",
      "  [0.30429694]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0814281553030014\n",
      "Predicci√≥n post entrenamiento : [[0.31266552]]\n",
      "PERDIDAAAA despues: 0.0794476792216301\n",
      "loss en el callback: 0.06852271407842636, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "ejemplar: [[0.28495443]\n",
      " [0.28639844]\n",
      " [0.28833163]\n",
      " [0.2913906 ]\n",
      " [0.29526842]\n",
      " [0.29943573]\n",
      " [0.30429694]\n",
      " [0.30917397]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5984968478614763\n",
      "Predicci√≥n : [[0.31422898]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[[0.28495443]\n",
      "  [0.28639844]\n",
      "  [0.28833163]\n",
      "  [0.2913906 ]\n",
      "  [0.29526842]\n",
      "  [0.29943573]\n",
      "  [0.30429694]\n",
      "  [0.30917397]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08080822229385376\n",
      "Predicci√≥n post entrenamiento : [[0.31748143]]\n",
      "PERDIDAAAA despues: 0.07896967232227325\n",
      "loss en el callback: 0.0767456516623497, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "ejemplar: [[0.28639844]\n",
      " [0.28833163]\n",
      " [0.2913906 ]\n",
      " [0.29526842]\n",
      " [0.29943573]\n",
      " [0.30429694]\n",
      " [0.30917397]\n",
      " [0.31422898]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6213543446734934\n",
      "Predicci√≥n : [[0.3193769]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[[0.28639844]\n",
      "  [0.28833163]\n",
      "  [0.2913906 ]\n",
      "  [0.29526842]\n",
      "  [0.29943573]\n",
      "  [0.30429694]\n",
      "  [0.30917397]\n",
      "  [0.31422898]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0911903828382492\n",
      "Predicci√≥n post entrenamiento : [[0.3227573]]\n",
      "PERDIDAAAA despues: 0.08916018903255463\n",
      "loss en el callback: 0.13711561262607574, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "ejemplar: [[0.28833163]\n",
      " [0.2913906 ]\n",
      " [0.29526842]\n",
      " [0.29943573]\n",
      " [0.30429694]\n",
      " [0.30917397]\n",
      " [0.31422898]\n",
      " [0.31937689]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.663102676301421\n",
      "Predicci√≥n : [[0.3251192]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[[0.28833163]\n",
      "  [0.2913906 ]\n",
      "  [0.29526842]\n",
      "  [0.29943573]\n",
      "  [0.30429694]\n",
      "  [0.30917397]\n",
      "  [0.31422898]\n",
      "  [0.31937689]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11423283815383911\n",
      "Predicci√≥n post entrenamiento : [[0.32906067]]\n",
      "PERDIDAAAA despues: 0.11158406734466553\n",
      "loss en el callback: 0.10912469029426575, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "ejemplar: [[0.2913906 ]\n",
      " [0.29526842]\n",
      " [0.29943573]\n",
      " [0.30429694]\n",
      " [0.30917397]\n",
      " [0.31422898]\n",
      " [0.31937689]\n",
      " [0.3251192 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6928724338328028\n",
      "Predicci√≥n : [[0.3319045]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[[0.2913906 ]\n",
      "  [0.29526842]\n",
      "  [0.29943573]\n",
      "  [0.30429694]\n",
      "  [0.30917397]\n",
      "  [0.31422898]\n",
      "  [0.31937689]\n",
      "  [0.3251192 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13029782474040985\n",
      "Predicci√≥n post entrenamiento : [[0.33573377]]\n",
      "PERDIDAAAA despues: 0.1275480091571808\n",
      "loss en el callback: 0.08597061783075333, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "ejemplar: [[0.29526842]\n",
      " [0.29943573]\n",
      " [0.30429694]\n",
      " [0.30917397]\n",
      " [0.31422898]\n",
      " [0.31937689]\n",
      " [0.3251192 ]\n",
      " [0.3319045 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.710663617267639\n",
      "Predicci√≥n : [[0.3389215]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[[0.29526842]\n",
      "  [0.29943573]\n",
      "  [0.30429694]\n",
      "  [0.30917397]\n",
      "  [0.31422898]\n",
      "  [0.31937689]\n",
      "  [0.3251192 ]\n",
      "  [0.3319045 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13819220662117004\n",
      "Predicci√≥n post entrenamiento : [[0.34299654]]\n",
      "PERDIDAAAA despues: 0.1351790875196457\n",
      "loss en el callback: 0.1500077247619629, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "ejemplar: [[0.29943573]\n",
      " [0.30429694]\n",
      " [0.30917397]\n",
      " [0.31422898]\n",
      " [0.31937689]\n",
      " [0.3251192 ]\n",
      " [0.3319045 ]\n",
      " [0.33892149]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7216820581308059\n",
      "Predicci√≥n : [[0.3464365]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[[0.29943573]\n",
      "  [0.30429694]\n",
      "  [0.30917397]\n",
      "  [0.31422898]\n",
      "  [0.31937689]\n",
      "  [0.3251192 ]\n",
      "  [0.3319045 ]\n",
      "  [0.33892149]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14080923795700073\n",
      "Predicci√≥n post entrenamiento : [[0.35058814]]\n",
      "PERDIDAAAA despues: 0.13771070539951324\n",
      "loss en el callback: 0.16104666888713837, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "ejemplar: [[0.30429694]\n",
      " [0.30917397]\n",
      " [0.31422898]\n",
      " [0.31937689]\n",
      " [0.3251192 ]\n",
      " [0.3319045 ]\n",
      " [0.33892149]\n",
      " [0.3464365 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7259277564223031\n",
      "Predicci√≥n : [[0.35430065]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[[0.30429694]\n",
      "  [0.30917397]\n",
      "  [0.31422898]\n",
      "  [0.31937689]\n",
      "  [0.3251192 ]\n",
      "  [0.3319045 ]\n",
      "  [0.33892149]\n",
      "  [0.3464365 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13810671865940094\n",
      "Predicci√≥n post entrenamiento : [[0.35825774]]\n",
      "PERDIDAAAA despues: 0.1351812481880188\n",
      "loss en el callback: 0.132473886013031, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "ejemplar: [[0.30917397]\n",
      " [0.31422898]\n",
      " [0.31937689]\n",
      " [0.3251192 ]\n",
      " [0.3319045 ]\n",
      " [0.33892149]\n",
      " [0.3464365 ]\n",
      " [0.35430065]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7404318224413275\n",
      "Predicci√≥n : [[0.36217442]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[[0.30917397]\n",
      "  [0.31422898]\n",
      "  [0.31937689]\n",
      "  [0.3251192 ]\n",
      "  [0.3319045 ]\n",
      "  [0.33892149]\n",
      "  [0.3464365 ]\n",
      "  [0.35430065]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14307868480682373\n",
      "Predicci√≥n post entrenamiento : [[0.36625826]]\n",
      "PERDIDAAAA despues: 0.14000587165355682\n",
      "loss en el callback: 0.13785336911678314, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "ejemplar: [[0.31422898]\n",
      " [0.31937689]\n",
      " [0.3251192 ]\n",
      " [0.3319045 ]\n",
      " [0.33892149]\n",
      " [0.3464365 ]\n",
      " [0.35430065]\n",
      " [0.36217442]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7651942561878792\n",
      "Predicci√≥n : [[0.37046266]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[[0.31422898]\n",
      "  [0.31937689]\n",
      "  [0.3251192 ]\n",
      "  [0.3319045 ]\n",
      "  [0.33892149]\n",
      "  [0.3464365 ]\n",
      "  [0.35430065]\n",
      "  [0.36217442]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.15581302344799042\n",
      "Predicci√≥n post entrenamiento : [[0.37457058]]\n",
      "PERDIDAAAA despues: 0.15258684754371643\n",
      "loss en el callback: 0.1604689359664917, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "ejemplar: [[0.31937689]\n",
      " [0.3251192 ]\n",
      " [0.3319045 ]\n",
      " [0.33892149]\n",
      " [0.3464365 ]\n",
      " [0.35430065]\n",
      " [0.36217442]\n",
      " [0.37046266]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7447890964420396\n",
      "Predicci√≥n : [[0.37912205]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[[0.31937689]\n",
      "  [0.3251192 ]\n",
      "  [0.3319045 ]\n",
      "  [0.33892149]\n",
      "  [0.3464365 ]\n",
      "  [0.35430065]\n",
      "  [0.36217442]\n",
      "  [0.37046266]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13371241092681885\n",
      "Predicci√≥n post entrenamiento : [[0.3828469]]\n",
      "PERDIDAAAA despues: 0.13100217282772064\n",
      "loss en el callback: 0.15197236835956573, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "ejemplar: [[0.3251192 ]\n",
      " [0.3319045 ]\n",
      " [0.33892149]\n",
      " [0.3464365 ]\n",
      " [0.35430065]\n",
      " [0.36217442]\n",
      " [0.37046266]\n",
      " [0.37912205]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6792163432038085\n",
      "Predicci√≥n : [[0.38783076]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[[0.3251192 ]\n",
      "  [0.3319045 ]\n",
      "  [0.33892149]\n",
      "  [0.3464365 ]\n",
      "  [0.35430065]\n",
      "  [0.36217442]\n",
      "  [0.37046266]\n",
      "  [0.37912205]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08490554243326187\n",
      "Predicci√≥n post entrenamiento : [[0.39062753]]\n",
      "PERDIDAAAA despues: 0.08328349143266678\n",
      "loss en el callback: 0.06862388551235199, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "ejemplar: [[0.3319045 ]\n",
      " [0.33892149]\n",
      " [0.3464365 ]\n",
      " [0.35430065]\n",
      " [0.36217442]\n",
      " [0.37046266]\n",
      " [0.37912205]\n",
      " [0.38783076]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6746017659154131\n",
      "Predicci√≥n : [[0.3960133]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[[0.3319045 ]\n",
      "  [0.33892149]\n",
      "  [0.3464365 ]\n",
      "  [0.35430065]\n",
      "  [0.36217442]\n",
      "  [0.37046266]\n",
      "  [0.37912205]\n",
      "  [0.38783076]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07761155068874359\n",
      "Predicci√≥n post entrenamiento : [[0.39863935]]\n",
      "PERDIDAAAA despues: 0.07615526765584946\n",
      "loss en el callback: 0.0705878958106041, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "ejemplar: [[0.33892149]\n",
      " [0.3464365 ]\n",
      " [0.35430065]\n",
      " [0.36217442]\n",
      " [0.37046266]\n",
      " [0.37912205]\n",
      " [0.38783076]\n",
      " [0.39601329]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7309453645768532\n",
      "Predicci√≥n : [[0.40427133]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[[0.33892149]\n",
      "  [0.3464365 ]\n",
      "  [0.35430065]\n",
      "  [0.36217442]\n",
      "  [0.37046266]\n",
      "  [0.37912205]\n",
      "  [0.38783076]\n",
      "  [0.39601329]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10671591013669968\n",
      "Predicci√≥n post entrenamiento : [[0.40742868]]\n",
      "PERDIDAAAA despues: 0.10466303676366806\n",
      "loss en el callback: 0.0977804884314537, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "ejemplar: [[0.3464365 ]\n",
      " [0.35430065]\n",
      " [0.36217442]\n",
      " [0.37046266]\n",
      " [0.37912205]\n",
      " [0.38783076]\n",
      " [0.39601329]\n",
      " [0.40427133]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7467210055914982\n",
      "Predicci√≥n : [[0.41331255]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[[0.3464365 ]\n",
      "  [0.35430065]\n",
      "  [0.36217442]\n",
      "  [0.37046266]\n",
      "  [0.37912205]\n",
      "  [0.38783076]\n",
      "  [0.39601329]\n",
      "  [0.40427133]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11116120964288712\n",
      "Predicci√≥n post entrenamiento : [[0.4165892]]\n",
      "PERDIDAAAA despues: 0.10898702591657639\n",
      "loss en el callback: 0.12340915948152542, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "ejemplar: [[0.35430065]\n",
      " [0.36217442]\n",
      " [0.37046266]\n",
      " [0.37912205]\n",
      " [0.38783076]\n",
      " [0.39601329]\n",
      " [0.40427133]\n",
      " [0.41331255]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7219286889593481\n",
      "Predicci√≥n : [[0.4226599]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[[0.35430065]\n",
      "  [0.36217442]\n",
      "  [0.37046266]\n",
      "  [0.37912205]\n",
      "  [0.38783076]\n",
      "  [0.39601329]\n",
      "  [0.40427133]\n",
      "  [0.41331255]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0895618200302124\n",
      "Predicci√≥n post entrenamiento : [[0.42529204]]\n",
      "PERDIDAAAA despues: 0.0879933163523674\n",
      "loss en el callback: 0.06504945456981659, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "ejemplar: [[0.36217442]\n",
      " [0.37046266]\n",
      " [0.37912205]\n",
      " [0.38783076]\n",
      " [0.39601329]\n",
      " [0.40427133]\n",
      " [0.41331255]\n",
      " [0.4226599 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7199286701160912\n",
      "Predicci√≥n : [[0.4315063]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[[0.36217442]\n",
      "  [0.37046266]\n",
      "  [0.37912205]\n",
      "  [0.38783076]\n",
      "  [0.39601329]\n",
      "  [0.40427133]\n",
      "  [0.41331255]\n",
      "  [0.4226599 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08318746834993362\n",
      "Predicci√≥n post entrenamiento : [[0.4340919]]\n",
      "PERDIDAAAA despues: 0.08170267194509506\n",
      "loss en el callback: 0.06948836147785187, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "ejemplar: [[0.37046266]\n",
      " [0.37912205]\n",
      " [0.38783076]\n",
      " [0.39601329]\n",
      " [0.40427133]\n",
      " [0.41331255]\n",
      " [0.4226599 ]\n",
      " [0.43150631]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7407209490617273\n",
      "Predicci√≥n : [[0.44048235]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[[0.37046266]\n",
      "  [0.37912205]\n",
      "  [0.38783076]\n",
      "  [0.39601329]\n",
      "  [0.40427133]\n",
      "  [0.41331255]\n",
      "  [0.4226599 ]\n",
      "  [0.43150631]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09014320373535156\n",
      "Predicci√≥n post entrenamiento : [[0.44344714]]\n",
      "PERDIDAAAA despues: 0.08837170153856277\n",
      "loss en el callback: 0.11738581955432892, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "ejemplar: [[0.37912205]\n",
      " [0.38783076]\n",
      " [0.39601329]\n",
      " [0.40427133]\n",
      " [0.41331255]\n",
      " [0.4226599 ]\n",
      " [0.43150631]\n",
      " [0.44048235]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.736245501831604\n",
      "Predicci√≥n : [[0.44994912]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[[0.37912205]\n",
      "  [0.38783076]\n",
      "  [0.39601329]\n",
      "  [0.40427133]\n",
      "  [0.41331255]\n",
      "  [0.4226599 ]\n",
      "  [0.43150631]\n",
      "  [0.44048235]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0819656252861023\n",
      "Predicci√≥n post entrenamiento : [[0.45190942]]\n",
      "PERDIDAAAA despues: 0.08084701001644135\n",
      "loss en el callback: 0.03143743798136711, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "ejemplar: [[0.38783076]\n",
      " [0.39601329]\n",
      " [0.40427133]\n",
      " [0.41331255]\n",
      " [0.4226599 ]\n",
      " [0.43150631]\n",
      " [0.44048235]\n",
      " [0.44994912]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7065023284257214\n",
      "Predicci√≥n : [[0.45845568]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[[0.38783076]\n",
      "  [0.39601329]\n",
      "  [0.40427133]\n",
      "  [0.41331255]\n",
      "  [0.4226599 ]\n",
      "  [0.43150631]\n",
      "  [0.44048235]\n",
      "  [0.44994912]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.061527132987976074\n",
      "Predicci√≥n post entrenamiento : [[0.46045136]]\n",
      "PERDIDAAAA despues: 0.060541070997714996\n",
      "loss en el callback: 0.04654509574174881, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "ejemplar: [[0.39601329]\n",
      " [0.40427133]\n",
      " [0.41331255]\n",
      " [0.4226599 ]\n",
      " [0.43150631]\n",
      " [0.44048235]\n",
      " [0.44994912]\n",
      " [0.45845568]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6979451506854685\n",
      "Predicci√≥n : [[0.46704388]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[[0.39601329]\n",
      "  [0.40427133]\n",
      "  [0.41331255]\n",
      "  [0.4226599 ]\n",
      "  [0.43150631]\n",
      "  [0.44048235]\n",
      "  [0.44994912]\n",
      "  [0.45845568]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0533154122531414\n",
      "Predicci√≥n post entrenamiento : [[0.4692276]]\n",
      "PERDIDAAAA despues: 0.0523117259144783\n",
      "loss en el callback: 0.066862553358078, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "ejemplar: [[0.40427133]\n",
      " [0.41331255]\n",
      " [0.4226599 ]\n",
      " [0.43150631]\n",
      " [0.44048235]\n",
      " [0.44994912]\n",
      " [0.45845568]\n",
      " [0.46704388]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7105739686108449\n",
      "Predicci√≥n : [[0.4760093]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[[0.40427133]\n",
      "  [0.41331255]\n",
      "  [0.4226599 ]\n",
      "  [0.43150631]\n",
      "  [0.44048235]\n",
      "  [0.44994912]\n",
      "  [0.45845568]\n",
      "  [0.46704388]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05502058193087578\n",
      "Predicci√≥n post entrenamiento : [[0.47831616]]\n",
      "PERDIDAAAA despues: 0.0539436936378479\n",
      "loss en el callback: 0.06372126191854477, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "ejemplar: [[0.41331255]\n",
      " [0.4226599 ]\n",
      " [0.43150631]\n",
      " [0.44048235]\n",
      " [0.44994912]\n",
      " [0.45845568]\n",
      " [0.46704388]\n",
      " [0.47600931]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7209621522504839\n",
      "Predicci√≥n : [[0.48529586]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[[0.41331255]\n",
      "  [0.4226599 ]\n",
      "  [0.43150631]\n",
      "  [0.44048235]\n",
      "  [0.44994912]\n",
      "  [0.45845568]\n",
      "  [0.46704388]\n",
      "  [0.47600931]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0555386058986187\n",
      "Predicci√≥n post entrenamiento : [[0.4874114]]\n",
      "PERDIDAAAA despues: 0.05454595759510994\n",
      "loss en el callback: 0.059483446180820465, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "ejemplar: [[0.4226599 ]\n",
      " [0.43150631]\n",
      " [0.44048235]\n",
      " [0.44994912]\n",
      " [0.45845568]\n",
      " [0.46704388]\n",
      " [0.47600931]\n",
      " [0.48529586]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7291097016043858\n",
      "Predicci√≥n : [[0.49441516]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[[0.4226599 ]\n",
      "  [0.43150631]\n",
      "  [0.44048235]\n",
      "  [0.44994912]\n",
      "  [0.45845568]\n",
      "  [0.46704388]\n",
      "  [0.47600931]\n",
      "  [0.48529586]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.055081527680158615\n",
      "Predicci√≥n post entrenamiento : [[0.49584836]]\n",
      "PERDIDAAAA despues: 0.05441085621714592\n",
      "loss en el callback: 0.021900083869695663, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "ejemplar: [[0.43150631]\n",
      " [0.44048235]\n",
      " [0.44994912]\n",
      " [0.45845568]\n",
      " [0.46704388]\n",
      " [0.47600931]\n",
      " [0.48529586]\n",
      " [0.49441516]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7674259644168786\n",
      "Predicci√≥n : [[0.50279284]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[[0.43150631]\n",
      "  [0.44048235]\n",
      "  [0.44994912]\n",
      "  [0.45845568]\n",
      "  [0.46704388]\n",
      "  [0.47600931]\n",
      "  [0.48529586]\n",
      "  [0.49441516]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07003068923950195\n",
      "Predicci√≥n post entrenamiento : [[0.5052039]]\n",
      "PERDIDAAAA despues: 0.06876040250062943\n",
      "loss en el callback: 0.0791209414601326, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "ejemplar: [[0.44048235]\n",
      " [0.44994912]\n",
      " [0.45845568]\n",
      " [0.46704388]\n",
      " [0.47600931]\n",
      " [0.48529586]\n",
      " [0.49441516]\n",
      " [0.50279284]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8359109406879621\n",
      "Predicci√≥n : [[0.51220155]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[[0.44048235]\n",
      "  [0.44994912]\n",
      "  [0.45845568]\n",
      "  [0.46704388]\n",
      "  [0.47600931]\n",
      "  [0.48529586]\n",
      "  [0.49441516]\n",
      "  [0.50279284]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10478775203227997\n",
      "Predicci√≥n post entrenamiento : [[0.51430446]]\n",
      "PERDIDAAAA despues: 0.10343071073293686\n",
      "loss en el callback: 0.04240316152572632, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "ejemplar: [[0.44994912]\n",
      " [0.45845568]\n",
      " [0.46704388]\n",
      " [0.47600931]\n",
      " [0.48529586]\n",
      " [0.49441516]\n",
      " [0.50279284]\n",
      " [0.51220155]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8510103358824123\n",
      "Predicci√≥n : [[0.52132475]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[[0.44994912]\n",
      "  [0.45845568]\n",
      "  [0.46704388]\n",
      "  [0.47600931]\n",
      "  [0.48529586]\n",
      "  [0.49441516]\n",
      "  [0.50279284]\n",
      "  [0.51220155]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10869257152080536\n",
      "Predicci√≥n post entrenamiento : [[0.5240418]]\n",
      "PERDIDAAAA despues: 0.10690843313932419\n",
      "loss en el callback: 0.09188228845596313, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "ejemplar: [[0.45845568]\n",
      " [0.46704388]\n",
      " [0.47600931]\n",
      " [0.48529586]\n",
      " [0.49441516]\n",
      " [0.50279284]\n",
      " [0.51220155]\n",
      " [0.52132475]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8127241500002294\n",
      "Predicci√≥n : [[0.5309611]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[[0.45845568]\n",
      "  [0.46704388]\n",
      "  [0.47600931]\n",
      "  [0.48529586]\n",
      "  [0.49441516]\n",
      "  [0.50279284]\n",
      "  [0.51220155]\n",
      "  [0.52132475]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07939042896032333\n",
      "Predicci√≥n post entrenamiento : [[0.5328833]]\n",
      "PERDIDAAAA despues: 0.07831092178821564\n",
      "loss en el callback: 0.04261251538991928, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "ejemplar: [[0.46704388]\n",
      " [0.47600931]\n",
      " [0.48529586]\n",
      " [0.49441516]\n",
      " [0.50279284]\n",
      " [0.51220155]\n",
      " [0.52132475]\n",
      " [0.5309611 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7863940290280375\n",
      "Predicci√≥n : [[0.53993523]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[[0.46704388]\n",
      "  [0.47600931]\n",
      "  [0.48529586]\n",
      "  [0.49441516]\n",
      "  [0.50279284]\n",
      "  [0.51220155]\n",
      "  [0.52132475]\n",
      "  [0.5309611 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06074192374944687\n",
      "Predicci√≥n post entrenamiento : [[0.5418318]]\n",
      "PERDIDAAAA despues: 0.05981067568063736\n",
      "loss en el callback: 0.04260483756661415, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "ejemplar: [[0.47600931]\n",
      " [0.48529586]\n",
      " [0.49441516]\n",
      " [0.50279284]\n",
      " [0.51220155]\n",
      " [0.52132475]\n",
      " [0.5309611 ]\n",
      " [0.53993523]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7720199729658365\n",
      "Predicci√≥n : [[0.54902047]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[[0.47600931]\n",
      "  [0.48529586]\n",
      "  [0.49441516]\n",
      "  [0.50279284]\n",
      "  [0.51220155]\n",
      "  [0.52132475]\n",
      "  [0.5309611 ]\n",
      "  [0.53993523]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04972878471016884\n",
      "Predicci√≥n post entrenamiento : [[0.55054855]]\n",
      "PERDIDAAAA despues: 0.04904959350824356\n",
      "loss en el callback: 0.02999335154891014, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "ejemplar: [[0.48529586]\n",
      " [0.49441516]\n",
      " [0.50279284]\n",
      " [0.51220155]\n",
      " [0.52132475]\n",
      " [0.5309611 ]\n",
      " [0.53993523]\n",
      " [0.54902047]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8033170564228299\n",
      "Predicci√≥n : [[0.55779713]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[[0.48529586]\n",
      "  [0.49441516]\n",
      "  [0.50279284]\n",
      "  [0.51220155]\n",
      "  [0.52132475]\n",
      "  [0.5309611 ]\n",
      "  [0.53993523]\n",
      "  [0.54902047]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06028003990650177\n",
      "Predicci√≥n post entrenamiento : [[0.5594647]]\n",
      "PERDIDAAAA despues: 0.059463981539011\n",
      "loss en el callback: 0.031202606856822968, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "ejemplar: [[0.49441516]\n",
      " [0.50279284]\n",
      " [0.51220155]\n",
      " [0.52132475]\n",
      " [0.5309611 ]\n",
      " [0.53993523]\n",
      " [0.54902047]\n",
      " [0.55779713]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8802852793990171\n",
      "Predicci√≥n : [[0.56669575]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[[0.49441516]\n",
      "  [0.50279284]\n",
      "  [0.51220155]\n",
      "  [0.52132475]\n",
      "  [0.5309611 ]\n",
      "  [0.53993523]\n",
      "  [0.54902047]\n",
      "  [0.55779713]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09833838045597076\n",
      "Predicci√≥n post entrenamiento : [[0.5690831]]\n",
      "PERDIDAAAA despues: 0.09684678912162781\n",
      "loss en el callback: 0.07316067814826965, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "ejemplar: [[0.50279284]\n",
      " [0.51220155]\n",
      " [0.52132475]\n",
      " [0.5309611 ]\n",
      " [0.53993523]\n",
      " [0.54902047]\n",
      " [0.55779713]\n",
      " [0.56669575]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8987051676996881\n",
      "Predicci√≥n : [[0.57633483]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[[0.50279284]\n",
      "  [0.51220155]\n",
      "  [0.52132475]\n",
      "  [0.5309611 ]\n",
      "  [0.53993523]\n",
      "  [0.54902047]\n",
      "  [0.55779713]\n",
      "  [0.56669575]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10392264276742935\n",
      "Predicci√≥n post entrenamiento : [[0.57897735]]\n",
      "PERDIDAAAA despues: 0.1022258922457695\n",
      "loss en el callback: 0.10600128769874573, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "ejemplar: [[0.51220155]\n",
      " [0.52132475]\n",
      " [0.5309611 ]\n",
      " [0.53993523]\n",
      " [0.54902047]\n",
      " [0.55779713]\n",
      " [0.56669575]\n",
      " [0.57633483]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8585767213248423\n",
      "Predicci√≥n : [[0.58644503]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[[0.51220155]\n",
      "  [0.52132475]\n",
      "  [0.5309611 ]\n",
      "  [0.53993523]\n",
      "  [0.54902047]\n",
      "  [0.55779713]\n",
      "  [0.56669575]\n",
      "  [0.57633483]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07405564934015274\n",
      "Predicci√≥n post entrenamiento : [[0.5889558]]\n",
      "PERDIDAAAA despues: 0.07269542664289474\n",
      "loss en el callback: 0.12051752954721451, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "ejemplar: [[0.52132475]\n",
      " [0.5309611 ]\n",
      " [0.53993523]\n",
      " [0.54902047]\n",
      " [0.55779713]\n",
      " [0.56669575]\n",
      " [0.57633483]\n",
      " [0.58644503]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8308762565987861\n",
      "Predicci√≥n : [[0.59640014]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[[0.52132475]\n",
      "  [0.5309611 ]\n",
      "  [0.53993523]\n",
      "  [0.54902047]\n",
      "  [0.55779713]\n",
      "  [0.56669575]\n",
      "  [0.57633483]\n",
      "  [0.58644503]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05497903749346733\n",
      "Predicci√≥n post entrenamiento : [[0.59816825]]\n",
      "PERDIDAAAA despues: 0.05415300279855728\n",
      "loss en el callback: 0.050028592348098755, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "ejemplar: [[0.5309611 ]\n",
      " [0.53993523]\n",
      " [0.54902047]\n",
      " [0.55779713]\n",
      " [0.56669575]\n",
      " [0.57633483]\n",
      " [0.58644503]\n",
      " [0.59640014]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8156037735215196\n",
      "Predicci√≥n : [[0.60566366]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[[0.5309611 ]\n",
      "  [0.53993523]\n",
      "  [0.54902047]\n",
      "  [0.55779713]\n",
      "  [0.56669575]\n",
      "  [0.57633483]\n",
      "  [0.58644503]\n",
      "  [0.59640014]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04407485947012901\n",
      "Predicci√≥n post entrenamiento : [[0.6062733]]\n",
      "PERDIDAAAA despues: 0.043819256126880646\n",
      "loss en el callback: 0.004135409835726023, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "ejemplar: [[0.53993523]\n",
      " [0.54902047]\n",
      " [0.55779713]\n",
      " [0.56669575]\n",
      " [0.57633483]\n",
      " [0.58644503]\n",
      " [0.59640014]\n",
      " [0.60566366]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8116992058331503\n",
      "Predicci√≥n : [[0.6136961]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[[0.53993523]\n",
      "  [0.54902047]\n",
      "  [0.55779713]\n",
      "  [0.56669575]\n",
      "  [0.57633483]\n",
      "  [0.58644503]\n",
      "  [0.59640014]\n",
      "  [0.60566366]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03920523449778557\n",
      "Predicci√≥n post entrenamiento : [[0.61496377]]\n",
      "PERDIDAAAA despues: 0.03870483487844467\n",
      "loss en el callback: 0.019738459959626198, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "ejemplar: [[0.54902047]\n",
      " [0.55779713]\n",
      " [0.56669575]\n",
      " [0.57633483]\n",
      " [0.58644503]\n",
      " [0.59640014]\n",
      " [0.60566366]\n",
      " [0.6136961 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8191625535336788\n",
      "Predicci√≥n : [[0.62248397]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[[0.54902047]\n",
      "  [0.55779713]\n",
      "  [0.56669575]\n",
      "  [0.57633483]\n",
      "  [0.58644503]\n",
      "  [0.59640014]\n",
      "  [0.60566366]\n",
      "  [0.6136961 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03868246451020241\n",
      "Predicci√≥n post entrenamiento : [[0.62384266]]\n",
      "PERDIDAAAA despues: 0.03814985975623131\n",
      "loss en el callback: 0.029999731108546257, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "ejemplar: [[0.55779713]\n",
      " [0.56669575]\n",
      " [0.57633483]\n",
      " [0.58644503]\n",
      " [0.59640014]\n",
      " [0.60566366]\n",
      " [0.6136961 ]\n",
      " [0.62248397]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8218275636038536\n",
      "Predicci√≥n : [[0.63144237]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[[0.55779713]\n",
      "  [0.56669575]\n",
      "  [0.57633483]\n",
      "  [0.58644503]\n",
      "  [0.59640014]\n",
      "  [0.60566366]\n",
      "  [0.6136961 ]\n",
      "  [0.62248397]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03624653443694115\n",
      "Predicci√≥n post entrenamiento : [[0.633016]]\n",
      "PERDIDAAAA despues: 0.035649821162223816\n",
      "loss en el callback: 0.033754393458366394, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "ejemplar: [[0.56669575]\n",
      " [0.57633483]\n",
      " [0.58644503]\n",
      " [0.59640014]\n",
      " [0.60566366]\n",
      " [0.6136961 ]\n",
      " [0.62248397]\n",
      " [0.63144237]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8196942360436743\n",
      "Predicci√≥n : [[0.64077747]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[[0.56669575]\n",
      "  [0.57633483]\n",
      "  [0.58644503]\n",
      "  [0.59640014]\n",
      "  [0.60566366]\n",
      "  [0.6136961 ]\n",
      "  [0.62248397]\n",
      "  [0.63144237]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03201120346784592\n",
      "Predicci√≥n post entrenamiento : [[0.64143556]]\n",
      "PERDIDAAAA despues: 0.031776148825883865\n",
      "loss en el callback: 0.005780690349638462, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "ejemplar: [[0.57633483]\n",
      " [0.58644503]\n",
      " [0.59640014]\n",
      " [0.60566366]\n",
      " [0.6136961 ]\n",
      " [0.62248397]\n",
      " [0.63144237]\n",
      " [0.64077747]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8178628420548653\n",
      "Predicci√≥n : [[0.64933014]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[[0.57633483]\n",
      "  [0.58644503]\n",
      "  [0.59640014]\n",
      "  [0.60566366]\n",
      "  [0.6136961 ]\n",
      "  [0.62248397]\n",
      "  [0.63144237]\n",
      "  [0.64077747]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.028403280302882195\n",
      "Predicci√≥n post entrenamiento : [[0.6492715]]\n",
      "PERDIDAAAA despues: 0.02842305414378643\n",
      "loss en el callback: 4.0734343201620504e-05, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "ejemplar: [[0.58644503]\n",
      " [0.59640014]\n",
      " [0.60566366]\n",
      " [0.6136961 ]\n",
      " [0.62248397]\n",
      " [0.63144237]\n",
      " [0.64077747]\n",
      " [0.64933014]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8163333816374257\n",
      "Predicci√≥n : [[0.65709174]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[[0.58644503]\n",
      "  [0.59640014]\n",
      "  [0.60566366]\n",
      "  [0.6136961 ]\n",
      "  [0.62248397]\n",
      "  [0.63144237]\n",
      "  [0.64077747]\n",
      "  [0.64933014]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.025357892736792564\n",
      "Predicci√≥n post entrenamiento : [[0.6582561]]\n",
      "PERDIDAAAA despues: 0.024988414719700813\n",
      "loss en el callback: 0.020538510754704475, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "ejemplar: [[0.59640014]\n",
      " [0.60566366]\n",
      " [0.6136961 ]\n",
      " [0.62248397]\n",
      " [0.63144237]\n",
      " [0.64077747]\n",
      " [0.64933014]\n",
      " [0.65709174]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8005556061309519\n",
      "Predicci√≥n : [[0.6658354]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[[0.59640014]\n",
      "  [0.60566366]\n",
      "  [0.6136961 ]\n",
      "  [0.62248397]\n",
      "  [0.63144237]\n",
      "  [0.64077747]\n",
      "  [0.64933014]\n",
      "  [0.65709174]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01814953424036503\n",
      "Predicci√≥n post entrenamiento : [[0.6672212]]\n",
      "PERDIDAAAA despues: 0.01777806133031845\n",
      "loss en el callback: 0.04028132185339928, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "ejemplar: [[0.60566366]\n",
      " [0.6136961 ]\n",
      " [0.62248397]\n",
      " [0.63144237]\n",
      " [0.64077747]\n",
      " [0.64933014]\n",
      " [0.65709174]\n",
      " [0.66583538]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7705295155354442\n",
      "Predicci√≥n : [[0.67454016]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[[0.60566366]\n",
      "  [0.6136961 ]\n",
      "  [0.62248397]\n",
      "  [0.63144237]\n",
      "  [0.64077747]\n",
      "  [0.64933014]\n",
      "  [0.65709174]\n",
      "  [0.66583538]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009213954210281372\n",
      "Predicci√≥n post entrenamiento : [[0.67593706]]\n",
      "PERDIDAAAA despues: 0.008947731927037239\n",
      "loss en el callback: 0.046549003571271896, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "ejemplar: [[0.6136961 ]\n",
      " [0.62248397]\n",
      " [0.63144237]\n",
      " [0.64077747]\n",
      " [0.64933014]\n",
      " [0.65709174]\n",
      " [0.66583538]\n",
      " [0.67454016]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7426586795525351\n",
      "Predicci√≥n : [[0.6831297]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[[0.6136961 ]\n",
      "  [0.62248397]\n",
      "  [0.63144237]\n",
      "  [0.64077747]\n",
      "  [0.64933014]\n",
      "  [0.65709174]\n",
      "  [0.66583538]\n",
      "  [0.67454016]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0035436954349279404\n",
      "Predicci√≥n post entrenamiento : [[0.6843815]]\n",
      "PERDIDAAAA despues: 0.0033962307497859\n",
      "loss en el callback: 0.03985749930143356, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "ejemplar: [[0.62248397]\n",
      " [0.63144237]\n",
      " [0.64077747]\n",
      " [0.64933014]\n",
      " [0.65709174]\n",
      " [0.66583538]\n",
      " [0.67454016]\n",
      " [0.68312973]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.716943098182225\n",
      "Predicci√≥n : [[0.6917562]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[[0.62248397]\n",
      "  [0.63144237]\n",
      "  [0.64077747]\n",
      "  [0.64933014]\n",
      "  [0.65709174]\n",
      "  [0.66583538]\n",
      "  [0.67454016]\n",
      "  [0.68312973]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006343797431327403\n",
      "Predicci√≥n post entrenamiento : [[0.69233716]]\n",
      "PERDIDAAAA despues: 0.0006054517580196261\n",
      "loss en el callback: 0.007396773435175419, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "ejemplar: [[0.63144237]\n",
      " [0.64077747]\n",
      " [0.64933014]\n",
      " [0.65709174]\n",
      " [0.66583538]\n",
      " [0.67454016]\n",
      " [0.68312973]\n",
      " [0.69175619]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7197051306082382\n",
      "Predicci√≥n : [[0.6997038]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[[0.63144237]\n",
      "  [0.64077747]\n",
      "  [0.64933014]\n",
      "  [0.65709174]\n",
      "  [0.66583538]\n",
      "  [0.67454016]\n",
      "  [0.68312973]\n",
      "  [0.69175619]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004000516782980412\n",
      "Predicci√≥n post entrenamiento : [[0.700363]]\n",
      "PERDIDAAAA despues: 0.00037411777884699404\n",
      "loss en el callback: 0.008693435229361057, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "ejemplar: [[0.64077747]\n",
      " [0.64933014]\n",
      " [0.65709174]\n",
      " [0.66583538]\n",
      " [0.67454016]\n",
      " [0.68312973]\n",
      " [0.69175619]\n",
      " [0.69970381]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7509447768305747\n",
      "Predicci√≥n : [[0.70765966]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[[0.64077747]\n",
      "  [0.64933014]\n",
      "  [0.65709174]\n",
      "  [0.66583538]\n",
      "  [0.67454016]\n",
      "  [0.68312973]\n",
      "  [0.69175619]\n",
      "  [0.69970381]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018736026249825954\n",
      "Predicci√≥n post entrenamiento : [[0.7071001]]\n",
      "PERDIDAAAA despues: 0.0019223577110096812\n",
      "loss en el callback: 0.004286107607185841, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "ejemplar: [[0.64933014]\n",
      " [0.65709174]\n",
      " [0.66583538]\n",
      " [0.67454016]\n",
      " [0.68312973]\n",
      " [0.69175619]\n",
      " [0.69970381]\n",
      " [0.70765966]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.740278139029679\n",
      "Predicci√≥n : [[0.71419513]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[[0.64933014]\n",
      "  [0.65709174]\n",
      "  [0.66583538]\n",
      "  [0.67454016]\n",
      "  [0.68312973]\n",
      "  [0.69175619]\n",
      "  [0.69970381]\n",
      "  [0.70765966]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006803225260227919\n",
      "Predicci√≥n post entrenamiento : [[0.7145013]]\n",
      "PERDIDAAAA despues: 0.0006644435925409198\n",
      "loss en el callback: 0.001662275055423379, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "ejemplar: [[0.65709174]\n",
      " [0.66583538]\n",
      " [0.67454016]\n",
      " [0.68312973]\n",
      " [0.69175619]\n",
      " [0.69970381]\n",
      " [0.70765966]\n",
      " [0.71419513]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.687705217205551\n",
      "Predicci√≥n : [[0.72156215]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[[0.65709174]\n",
      "  [0.66583538]\n",
      "  [0.67454016]\n",
      "  [0.68312973]\n",
      "  [0.69175619]\n",
      "  [0.69970381]\n",
      "  [0.70765966]\n",
      "  [0.71419513]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011462916154414415\n",
      "Predicci√≥n post entrenamiento : [[0.7217707]]\n",
      "PERDIDAAAA despues: 0.0011604572646319866\n",
      "loss en el callback: 0.0009695232729427516, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "ejemplar: [[0.66583538]\n",
      " [0.67454016]\n",
      " [0.68312973]\n",
      " [0.69175619]\n",
      " [0.69970381]\n",
      " [0.70765966]\n",
      " [0.71419513]\n",
      " [0.72156215]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6687695580612426\n",
      "Predicci√≥n : [[0.7289825]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[[0.66583538]\n",
      "  [0.67454016]\n",
      "  [0.68312973]\n",
      "  [0.69175619]\n",
      "  [0.69970381]\n",
      "  [0.70765966]\n",
      "  [0.71419513]\n",
      "  [0.72156215]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003625601762905717\n",
      "Predicci√≥n post entrenamiento : [[0.72757703]]\n",
      "PERDIDAAAA despues: 0.0034583210945129395\n",
      "loss en el callback: 0.029672004282474518, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "ejemplar: [[0.67454016]\n",
      " [0.68312973]\n",
      " [0.69175619]\n",
      " [0.69970381]\n",
      " [0.70765966]\n",
      " [0.71419513]\n",
      " [0.72156215]\n",
      " [0.72898251]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6834711615967536\n",
      "Predicci√≥n : [[0.7346509]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[[0.67454016]\n",
      "  [0.68312973]\n",
      "  [0.69175619]\n",
      "  [0.69970381]\n",
      "  [0.70765966]\n",
      "  [0.71419513]\n",
      "  [0.72156215]\n",
      "  [0.72898251]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002619368489831686\n",
      "Predicci√≥n post entrenamiento : [[0.73413116]]\n",
      "PERDIDAAAA despues: 0.002566437004134059\n",
      "loss en el callback: 0.0046982839703559875, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "ejemplar: [[0.68312973]\n",
      " [0.69175619]\n",
      " [0.69970381]\n",
      " [0.70765966]\n",
      " [0.71419513]\n",
      " [0.72156215]\n",
      " [0.72898251]\n",
      " [0.73465091]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6877052172055499\n",
      "Predicci√≥n : [[0.7410113]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[[0.68312973]\n",
      "  [0.69175619]\n",
      "  [0.69970381]\n",
      "  [0.70765966]\n",
      "  [0.71419513]\n",
      "  [0.72156215]\n",
      "  [0.72898251]\n",
      "  [0.73465091]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002841540612280369\n",
      "Predicci√≥n post entrenamiento : [[0.7416664]]\n",
      "PERDIDAAAA despues: 0.00291180657222867\n",
      "loss en el callback: 0.012429730035364628, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "ejemplar: [[0.69175619]\n",
      " [0.69970381]\n",
      " [0.70765966]\n",
      " [0.71419513]\n",
      " [0.72156215]\n",
      " [0.72898251]\n",
      " [0.73465091]\n",
      " [0.74101132]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6814717248876317\n",
      "Predicci√≥n : [[0.7483073]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[[0.69175619]\n",
      "  [0.69970381]\n",
      "  [0.70765966]\n",
      "  [0.71419513]\n",
      "  [0.72156215]\n",
      "  [0.72898251]\n",
      "  [0.73465091]\n",
      "  [0.74101132]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004466995131224394\n",
      "Predicci√≥n post entrenamiento : [[0.7474898]]\n",
      "PERDIDAAAA despues: 0.004358390346169472\n",
      "loss en el callback: 0.011326874606311321, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "ejemplar: [[0.69970381]\n",
      " [0.70765966]\n",
      " [0.71419513]\n",
      " [0.72156215]\n",
      " [0.72898251]\n",
      " [0.73465091]\n",
      " [0.74101132]\n",
      " [0.74830729]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.689261843882625\n",
      "Predicci√≥n : [[0.7537982]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[[0.69970381]\n",
      "  [0.70765966]\n",
      "  [0.71419513]\n",
      "  [0.72156215]\n",
      "  [0.72898251]\n",
      "  [0.73465091]\n",
      "  [0.74101132]\n",
      "  [0.74830729]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004164938349276781\n",
      "Predicci√≥n post entrenamiento : [[0.7529058]]\n",
      "PERDIDAAAA despues: 0.004050550051033497\n",
      "loss en el callback: 0.013788034208118916, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "ejemplar: [[0.70765966]\n",
      " [0.71419513]\n",
      " [0.72156215]\n",
      " [0.72898251]\n",
      " [0.73465091]\n",
      " [0.74101132]\n",
      " [0.74830729]\n",
      " [0.75379819]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7110755741905297\n",
      "Predicci√≥n : [[0.75898266]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[[0.70765966]\n",
      "  [0.71419513]\n",
      "  [0.72156215]\n",
      "  [0.72898251]\n",
      "  [0.73465091]\n",
      "  [0.74101132]\n",
      "  [0.74830729]\n",
      "  [0.75379819]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0022950859274715185\n",
      "Predicci√≥n post entrenamiento : [[0.75851107]]\n",
      "PERDIDAAAA despues: 0.002250123070552945\n",
      "loss en el callback: 0.004303083289414644, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "ejemplar: [[0.71419513]\n",
      " [0.72156215]\n",
      " [0.72898251]\n",
      " [0.73465091]\n",
      " [0.74101132]\n",
      " [0.74830729]\n",
      " [0.75379819]\n",
      " [0.75898266]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7349108623046875\n",
      "Predicci√≥n : [[0.764283]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[[0.71419513]\n",
      "  [0.72156215]\n",
      "  [0.72898251]\n",
      "  [0.73465091]\n",
      "  [0.74101132]\n",
      "  [0.74830729]\n",
      "  [0.75379819]\n",
      "  [0.75898266]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008627235074527562\n",
      "Predicci√≥n post entrenamiento : [[0.76465225]]\n",
      "PERDIDAAAA despues: 0.0008845512638799846\n",
      "loss en el callback: 0.0035014355089515448, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "ejemplar: [[0.72156215]\n",
      " [0.72898251]\n",
      " [0.73465091]\n",
      " [0.74101132]\n",
      " [0.74830729]\n",
      " [0.75379819]\n",
      " [0.75898266]\n",
      " [0.764283  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7607677082250986\n",
      "Predicci√≥n : [[0.7704339]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[[0.72156215]\n",
      "  [0.72898251]\n",
      "  [0.73465091]\n",
      "  [0.74101132]\n",
      "  [0.74830729]\n",
      "  [0.75379819]\n",
      "  [0.75898266]\n",
      "  [0.764283  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 9.34355120989494e-05\n",
      "Predicci√≥n post entrenamiento : [[0.77043927]]\n",
      "PERDIDAAAA despues: 9.353924542665482e-05\n",
      "loss en el callback: 5.787163672721363e-07, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "ejemplar: [[0.72898251]\n",
      " [0.73465091]\n",
      " [0.74101132]\n",
      " [0.74830729]\n",
      " [0.75379819]\n",
      " [0.75898266]\n",
      " [0.764283  ]\n",
      " [0.7704339 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7711170829224028\n",
      "Predicci√≥n : [[0.7759632]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[[0.72898251]\n",
      "  [0.73465091]\n",
      "  [0.74101132]\n",
      "  [0.74830729]\n",
      "  [0.75379819]\n",
      "  [0.75898266]\n",
      "  [0.764283  ]\n",
      "  [0.7704339 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.3484646590077318e-05\n",
      "Predicci√≥n post entrenamiento : [[0.7751457]]\n",
      "PERDIDAAAA despues: 1.6229765606112778e-05\n",
      "loss en el callback: 0.01157159823924303, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "ejemplar: [[0.73465091]\n",
      " [0.74101132]\n",
      " [0.74830729]\n",
      " [0.75379819]\n",
      " [0.75898266]\n",
      " [0.764283  ]\n",
      " [0.7704339 ]\n",
      " [0.77596319]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7659589863965997\n",
      "Predicci√≥n : [[0.7803265]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[[0.73465091]\n",
      "  [0.74101132]\n",
      "  [0.74830729]\n",
      "  [0.75379819]\n",
      "  [0.75898266]\n",
      "  [0.764283  ]\n",
      "  [0.7704339 ]\n",
      "  [0.77596319]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00020642565505113453\n",
      "Predicci√≥n post entrenamiento : [[0.7801028]]\n",
      "PERDIDAAAA despues: 0.00020004776888526976\n",
      "loss en el callback: 0.0010038935579359531, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "ejemplar: [[0.74101132]\n",
      " [0.74830729]\n",
      " [0.75379819]\n",
      " [0.75898266]\n",
      " [0.764283  ]\n",
      " [0.7704339 ]\n",
      " [0.77596319]\n",
      " [0.78032649]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7483323528772654\n",
      "Predicci√≥n : [[0.7853506]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[[0.74101132]\n",
      "  [0.74830729]\n",
      "  [0.75379819]\n",
      "  [0.75898266]\n",
      "  [0.764283  ]\n",
      "  [0.7704339 ]\n",
      "  [0.77596319]\n",
      "  [0.78032649]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013703500153496861\n",
      "Predicci√≥n post entrenamiento : [[0.7858498]]\n",
      "PERDIDAAAA despues: 0.001407557399943471\n",
      "loss en el callback: 0.0072401221841573715, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "ejemplar: [[0.74830729]\n",
      " [0.75379819]\n",
      " [0.75898266]\n",
      " [0.764283  ]\n",
      " [0.7704339 ]\n",
      " [0.77596319]\n",
      " [0.78032649]\n",
      " [0.78535062]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7182371823643998\n",
      "Predicci√≥n : [[0.79095066]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[[0.74830729]\n",
      "  [0.75379819]\n",
      "  [0.75898266]\n",
      "  [0.764283  ]\n",
      "  [0.7704339 ]\n",
      "  [0.77596319]\n",
      "  [0.78032649]\n",
      "  [0.78535062]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005287252366542816\n",
      "Predicci√≥n post entrenamiento : [[0.788959]]\n",
      "PERDIDAAAA despues: 0.005001582205295563\n",
      "loss en el callback: 0.0621039904654026, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "ejemplar: [[0.75379819]\n",
      " [0.75898266]\n",
      " [0.764283  ]\n",
      " [0.7704339 ]\n",
      " [0.77596319]\n",
      " [0.78032649]\n",
      " [0.78535062]\n",
      " [0.79095066]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7089416644962148\n",
      "Predicci√≥n : [[0.79359794]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[[0.75379819]\n",
      "  [0.75898266]\n",
      "  [0.764283  ]\n",
      "  [0.7704339 ]\n",
      "  [0.77596319]\n",
      "  [0.78032649]\n",
      "  [0.78535062]\n",
      "  [0.79095066]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007166688796132803\n",
      "Predicci√≥n post entrenamiento : [[0.7922234]]\n",
      "PERDIDAAAA despues: 0.006935850717127323\n",
      "loss en el callback: 0.03424520418047905, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "ejemplar: [[0.75898266]\n",
      " [0.764283  ]\n",
      " [0.7704339 ]\n",
      " [0.77596319]\n",
      " [0.78032649]\n",
      " [0.78535062]\n",
      " [0.79095066]\n",
      " [0.79359794]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7204457992727099\n",
      "Predicci√≥n : [[0.7968101]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[[0.75898266]\n",
      "  [0.764283  ]\n",
      "  [0.7704339 ]\n",
      "  [0.77596319]\n",
      "  [0.78032649]\n",
      "  [0.78535062]\n",
      "  [0.79095066]\n",
      "  [0.79359794]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005831502843648195\n",
      "Predicci√≥n post entrenamiento : [[0.7963673]]\n",
      "PERDIDAAAA despues: 0.0057640704326331615\n",
      "loss en el callback: 0.004227750934660435, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "ejemplar: [[0.764283  ]\n",
      " [0.7704339 ]\n",
      " [0.77596319]\n",
      " [0.78032649]\n",
      " [0.78535062]\n",
      " [0.79095066]\n",
      " [0.79359794]\n",
      " [0.79681009]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.770615477342717\n",
      "Predicci√≥n : [[0.80094343]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[[0.764283  ]\n",
      "  [0.7704339 ]\n",
      "  [0.77596319]\n",
      "  [0.78032649]\n",
      "  [0.78535062]\n",
      "  [0.79095066]\n",
      "  [0.79359794]\n",
      "  [0.79681009]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009197861072607338\n",
      "Predicci√≥n post entrenamiento : [[0.80093646]]\n",
      "PERDIDAAAA despues: 0.0009193631703965366\n",
      "loss en el callback: 1.116050043492578e-06, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "ejemplar: [[0.7704339 ]\n",
      " [0.77596319]\n",
      " [0.78032649]\n",
      " [0.78535062]\n",
      " [0.79095066]\n",
      " [0.79359794]\n",
      " [0.79681009]\n",
      " [0.80094343]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8594506987062355\n",
      "Predicci√≥n : [[0.8054211]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[[0.7704339 ]\n",
      "  [0.77596319]\n",
      "  [0.78032649]\n",
      "  [0.78535062]\n",
      "  [0.79095066]\n",
      "  [0.79359794]\n",
      "  [0.79681009]\n",
      "  [0.80094343]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002919195918366313\n",
      "Predicci√≥n post entrenamiento : [[0.80524206]]\n",
      "PERDIDAAAA despues: 0.0029385762754827738\n",
      "loss en el callback: 0.00060260109603405, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "ejemplar: [[0.77596319]\n",
      " [0.78032649]\n",
      " [0.78535062]\n",
      " [0.79095066]\n",
      " [0.79359794]\n",
      " [0.79681009]\n",
      " [0.80094343]\n",
      " [0.80542111]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9065410812466371\n",
      "Predicci√≥n : [[0.80933636]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[[0.77596319]\n",
      "  [0.78032649]\n",
      "  [0.78535062]\n",
      "  [0.79095066]\n",
      "  [0.79359794]\n",
      "  [0.79681009]\n",
      "  [0.80094343]\n",
      "  [0.80542111]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00944876205176115\n",
      "Predicci√≥n post entrenamiento : [[0.8100373]]\n",
      "PERDIDAAAA despues: 0.00931298267096281\n",
      "loss en el callback: 0.0118781216442585, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "ejemplar: [[0.78032649]\n",
      " [0.78535062]\n",
      " [0.79095066]\n",
      " [0.79359794]\n",
      " [0.79681009]\n",
      " [0.80094343]\n",
      " [0.80542111]\n",
      " [0.80933636]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9118866249639219\n",
      "Predicci√≥n : [[0.8138248]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[[0.78032649]\n",
      "  [0.78535062]\n",
      "  [0.79095066]\n",
      "  [0.79359794]\n",
      "  [0.79681009]\n",
      "  [0.80094343]\n",
      "  [0.80542111]\n",
      "  [0.80933636]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009616128169000149\n",
      "Predicci√≥n post entrenamiento : [[0.8133277]]\n",
      "PERDIDAAAA despues: 0.009713857434689999\n",
      "loss en el callback: 0.004493238404393196, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "ejemplar: [[0.78535062]\n",
      " [0.79095066]\n",
      " [0.79359794]\n",
      " [0.79681009]\n",
      " [0.80094343]\n",
      " [0.80542111]\n",
      " [0.80933636]\n",
      " [0.81382477]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.904335569053715\n",
      "Predicci√≥n : [[0.81706977]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[[0.78535062]\n",
      "  [0.79095066]\n",
      "  [0.79359794]\n",
      "  [0.79681009]\n",
      "  [0.80094343]\n",
      "  [0.80542111]\n",
      "  [0.80933636]\n",
      "  [0.81382477]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007615318056195974\n",
      "Predicci√≥n post entrenamiento : [[0.8171489]]\n",
      "PERDIDAAAA despues: 0.007601509336382151\n",
      "loss en el callback: 0.00011339666525600478, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "ejemplar: [[0.79095066]\n",
      " [0.79359794]\n",
      " [0.79681009]\n",
      " [0.80094343]\n",
      " [0.80542111]\n",
      " [0.80933636]\n",
      " [0.81382477]\n",
      " [0.81706977]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8838879135160167\n",
      "Predicci√≥n : [[0.8206388]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[[0.79095066]\n",
      "  [0.79359794]\n",
      "  [0.79681009]\n",
      "  [0.80094343]\n",
      "  [0.80542111]\n",
      "  [0.80933636]\n",
      "  [0.81382477]\n",
      "  [0.81706977]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0040004500187933445\n",
      "Predicci√≥n post entrenamiento : [[0.82095444]]\n",
      "PERDIDAAAA despues: 0.003960618283599615\n",
      "loss en el callback: 0.0025517167523503304, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "ejemplar: [[0.79359794]\n",
      " [0.79681009]\n",
      " [0.80094343]\n",
      " [0.80542111]\n",
      " [0.80933636]\n",
      " [0.81382477]\n",
      " [0.81706977]\n",
      " [0.82063878]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9032153489332012\n",
      "Predicci√≥n : [[0.82398736]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[[0.79359794]\n",
      "  [0.79681009]\n",
      "  [0.80094343]\n",
      "  [0.80542111]\n",
      "  [0.80933636]\n",
      "  [0.81382477]\n",
      "  [0.81706977]\n",
      "  [0.82063878]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006277073640376329\n",
      "Predicci√≥n post entrenamiento : [[0.82506317]]\n",
      "PERDIDAAAA despues: 0.006107763387262821\n",
      "loss en el callback: 0.03490510955452919, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "ejemplar: [[0.79681009]\n",
      " [0.80094343]\n",
      " [0.80542111]\n",
      " [0.80933636]\n",
      " [0.81382477]\n",
      " [0.81706977]\n",
      " [0.82063878]\n",
      " [0.82398736]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9623178753052692\n",
      "Predicci√≥n : [[0.82840544]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[[0.79681009]\n",
      "  [0.80094343]\n",
      "  [0.80542111]\n",
      "  [0.80933636]\n",
      "  [0.81382477]\n",
      "  [0.81706977]\n",
      "  [0.82063878]\n",
      "  [0.82398736]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01793254353106022\n",
      "Predicci√≥n post entrenamiento : [[0.82954544]]\n",
      "PERDIDAAAA despues: 0.017628522589802742\n",
      "loss en el callback: 0.03316553309559822, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "ejemplar: [[0.80094343]\n",
      " [0.80542111]\n",
      " [0.80933636]\n",
      " [0.81382477]\n",
      " [0.81706977]\n",
      " [0.82063878]\n",
      " [0.82398736]\n",
      " [0.82840544]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.982058820003038\n",
      "Predicci√≥n : [[0.8330824]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[[0.80094343]\n",
      "  [0.80542111]\n",
      "  [0.80933636]\n",
      "  [0.81382477]\n",
      "  [0.81706977]\n",
      "  [0.82063878]\n",
      "  [0.82398736]\n",
      "  [0.82840544]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02219398133456707\n",
      "Predicci√≥n post entrenamiento : [[0.8338618]]\n",
      "PERDIDAAAA despues: 0.021962350234389305\n",
      "loss en el callback: 0.013752615079283714, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "ejemplar: [[0.80542111]\n",
      " [0.80933636]\n",
      " [0.81382477]\n",
      " [0.81706977]\n",
      " [0.82063878]\n",
      " [0.82398736]\n",
      " [0.82840544]\n",
      " [0.83308238]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9624381830265082\n",
      "Predicci√≥n : [[0.83735734]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[[0.80542111]\n",
      "  [0.80933636]\n",
      "  [0.81382477]\n",
      "  [0.81706977]\n",
      "  [0.82063878]\n",
      "  [0.82398736]\n",
      "  [0.82840544]\n",
      "  [0.83308238]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015645213425159454\n",
      "Predicci√≥n post entrenamiento : [[0.8381205]]\n",
      "PERDIDAAAA despues: 0.01545487716794014\n",
      "loss en el callback: 0.014651789329946041, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "ejemplar: [[0.80933636]\n",
      " [0.81382477]\n",
      " [0.81706977]\n",
      " [0.82063878]\n",
      " [0.82398736]\n",
      " [0.82840544]\n",
      " [0.83308238]\n",
      " [0.83735734]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9302512105217627\n",
      "Predicci√≥n : [[0.84147084]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[[0.80933636]\n",
      "  [0.81382477]\n",
      "  [0.81706977]\n",
      "  [0.82063878]\n",
      "  [0.82398736]\n",
      "  [0.82840544]\n",
      "  [0.83308238]\n",
      "  [0.83735734]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00788194965571165\n",
      "Predicci√≥n post entrenamiento : [[0.84255975]]\n",
      "PERDIDAAAA despues: 0.007689786143600941\n",
      "loss en el callback: 0.042414650321006775, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "ejemplar: [[0.81382477]\n",
      " [0.81706977]\n",
      " [0.82063878]\n",
      " [0.82398736]\n",
      " [0.82840544]\n",
      " [0.83308238]\n",
      " [0.83735734]\n",
      " [0.84147084]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.885497902488802\n",
      "Predicci√≥n : [[0.84591043]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[[0.81382477]\n",
      "  [0.81706977]\n",
      "  [0.82063878]\n",
      "  [0.82398736]\n",
      "  [0.82840544]\n",
      "  [0.83308238]\n",
      "  [0.83735734]\n",
      "  [0.84147084]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015671700239181519\n",
      "Predicci√≥n post entrenamiento : [[0.8457507]]\n",
      "PERDIDAAAA despues: 0.001579842995852232\n",
      "loss en el callback: 0.000598694896325469, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "ejemplar: [[0.81706977]\n",
      " [0.82063878]\n",
      " [0.82398736]\n",
      " [0.82840544]\n",
      " [0.83308238]\n",
      " [0.83735734]\n",
      " [0.84147084]\n",
      " [0.84591043]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597025687419927\n",
      "Predicci√≥n : [[0.8489535]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[[0.81706977]\n",
      "  [0.82063878]\n",
      "  [0.82398736]\n",
      "  [0.82840544]\n",
      "  [0.83308238]\n",
      "  [0.83735734]\n",
      "  [0.84147084]\n",
      "  [0.84591043]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00011554318916751072\n",
      "Predicci√≥n post entrenamiento : [[0.84792465]]\n",
      "PERDIDAAAA despues: 0.0001387198135489598\n",
      "loss en el callback: 0.02051929570734501, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "ejemplar: [[0.82063878]\n",
      " [0.82398736]\n",
      " [0.82840544]\n",
      " [0.83308238]\n",
      " [0.83735734]\n",
      " [0.84147084]\n",
      " [0.84591043]\n",
      " [0.84895349]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8528652092813349\n",
      "Predicci√≥n : [[0.85132176]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[[0.82063878]\n",
      "  [0.82398736]\n",
      "  [0.82840544]\n",
      "  [0.83308238]\n",
      "  [0.83735734]\n",
      "  [0.84147084]\n",
      "  [0.84591043]\n",
      "  [0.84895349]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.382275852141902e-06\n",
      "Predicci√≥n post entrenamiento : [[0.85192543]]\n",
      "PERDIDAAAA despues: 8.831985383039864e-07\n",
      "loss en el callback: 0.011697093956172466, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "ejemplar: [[0.82398736]\n",
      " [0.82840544]\n",
      " [0.83308238]\n",
      " [0.83735734]\n",
      " [0.84147084]\n",
      " [0.84591043]\n",
      " [0.84895349]\n",
      " [0.85132176]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8585854533368672\n",
      "Predicci√≥n : [[0.8554516]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[[0.82398736]\n",
      "  [0.82840544]\n",
      "  [0.83308238]\n",
      "  [0.83735734]\n",
      "  [0.84147084]\n",
      "  [0.84591043]\n",
      "  [0.84895349]\n",
      "  [0.85132176]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 9.821285857469775e-06\n",
      "Predicci√≥n post entrenamiento : [[0.8558111]]\n",
      "PERDIDAAAA despues: 7.697060937061906e-06\n",
      "loss en el callback: 0.003957115579396486, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "ejemplar: [[0.82840544]\n",
      " [0.83308238]\n",
      " [0.83735734]\n",
      " [0.84147084]\n",
      " [0.84591043]\n",
      " [0.84895349]\n",
      " [0.85132176]\n",
      " [0.85545158]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8768633009085897\n",
      "Predicci√≥n : [[0.8595313]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[[0.82840544]\n",
      "  [0.83308238]\n",
      "  [0.83735734]\n",
      "  [0.84147084]\n",
      "  [0.84591043]\n",
      "  [0.84895349]\n",
      "  [0.85132176]\n",
      "  [0.85545158]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000300398824037984\n",
      "Predicci√≥n post entrenamiento : [[0.8592873]]\n",
      "PERDIDAAAA despues: 0.00030891504138708115\n",
      "loss en el callback: 0.001452809665352106, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "ejemplar: [[0.83308238]\n",
      " [0.83735734]\n",
      " [0.84147084]\n",
      " [0.84591043]\n",
      " [0.84895349]\n",
      " [0.85132176]\n",
      " [0.85545158]\n",
      " [0.85953128]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8806463966074481\n",
      "Predicci√≥n : [[0.86290145]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[[0.83308238]\n",
      "  [0.83735734]\n",
      "  [0.84147084]\n",
      "  [0.84591043]\n",
      "  [0.84895349]\n",
      "  [0.85132176]\n",
      "  [0.85545158]\n",
      "  [0.85953128]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00031488353852182627\n",
      "Predicci√≥n post entrenamiento : [[0.8621361]]\n",
      "PERDIDAAAA despues: 0.00034263054840266705\n",
      "loss en el callback: 0.012157585471868515, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "ejemplar: [[0.83735734]\n",
      " [0.84147084]\n",
      " [0.84591043]\n",
      " [0.84895349]\n",
      " [0.85132176]\n",
      " [0.85545158]\n",
      " [0.85953128]\n",
      " [0.86290145]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8699347404334429\n",
      "Predicci√≥n : [[0.86553144]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[[0.83735734]\n",
      "  [0.84147084]\n",
      "  [0.84591043]\n",
      "  [0.84895349]\n",
      "  [0.85132176]\n",
      "  [0.85545158]\n",
      "  [0.85953128]\n",
      "  [0.86290145]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.938899004017003e-05\n",
      "Predicci√≥n post entrenamiento : [[0.86579686]]\n",
      "PERDIDAAAA despues: 1.7121998098446056e-05\n",
      "loss en el callback: 0.0022892586421221495, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "ejemplar: [[0.84147084]\n",
      " [0.84591043]\n",
      " [0.84895349]\n",
      " [0.85132176]\n",
      " [0.85545158]\n",
      " [0.85953128]\n",
      " [0.86290145]\n",
      " [0.86553144]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8465135437340043\n",
      "Predicci√≥n : [[0.86903447]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[[0.84147084]\n",
      "  [0.84591043]\n",
      "  [0.84895349]\n",
      "  [0.85132176]\n",
      "  [0.85545158]\n",
      "  [0.85953128]\n",
      "  [0.86290145]\n",
      "  [0.86553144]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005071909399703145\n",
      "Predicci√≥n post entrenamiento : [[0.8699623]]\n",
      "PERDIDAAAA despues: 0.000549841788597405\n",
      "loss en el callback: 0.036974187940359116, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "ejemplar: [[0.84591043]\n",
      " [0.84895349]\n",
      " [0.85132176]\n",
      " [0.85545158]\n",
      " [0.85953128]\n",
      " [0.86290145]\n",
      " [0.86553144]\n",
      " [0.86903447]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8103828065091326\n",
      "Predicci√≥n : [[0.8730491]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[[0.84591043]\n",
      "  [0.84895349]\n",
      "  [0.85132176]\n",
      "  [0.85545158]\n",
      "  [0.85953128]\n",
      "  [0.86290145]\n",
      "  [0.86553144]\n",
      "  [0.86903447]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003927064593881369\n",
      "Predicci√≥n post entrenamiento : [[0.87227845]]\n",
      "PERDIDAAAA despues: 0.0038310738746076822\n",
      "loss en el callback: 0.014327393844723701, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "ejemplar: [[0.84895349]\n",
      " [0.85132176]\n",
      " [0.85545158]\n",
      " [0.85953128]\n",
      " [0.86290145]\n",
      " [0.86553144]\n",
      " [0.86903447]\n",
      " [0.87304908]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8026111217617493\n",
      "Predicci√≥n : [[0.8750945]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[[0.84895349]\n",
      "  [0.85132176]\n",
      "  [0.85545158]\n",
      "  [0.85953128]\n",
      "  [0.86290145]\n",
      "  [0.86553144]\n",
      "  [0.86903447]\n",
      "  [0.87304908]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005253837443888187\n",
      "Predicci√≥n post entrenamiento : [[0.87421405]]\n",
      "PERDIDAAAA despues: 0.0051269810646772385\n",
      "loss en el callback: 0.019461553543806076, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "ejemplar: [[0.85132176]\n",
      " [0.85545158]\n",
      " [0.85953128]\n",
      " [0.86290145]\n",
      " [0.86553144]\n",
      " [0.86903447]\n",
      " [0.87304908]\n",
      " [0.87509447]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.823198489491854\n",
      "Predicci√≥n : [[0.8771132]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[[0.85132176]\n",
      "  [0.85545158]\n",
      "  [0.85953128]\n",
      "  [0.86290145]\n",
      "  [0.86553144]\n",
      "  [0.86903447]\n",
      "  [0.87304908]\n",
      "  [0.87509447]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029067976865917444\n",
      "Predicci√≥n post entrenamiento : [[0.8766247]]\n",
      "PERDIDAAAA despues: 0.00285435956902802\n",
      "loss en el callback: 0.006722565740346909, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "ejemplar: [[0.85545158]\n",
      " [0.85953128]\n",
      " [0.86290145]\n",
      " [0.86553144]\n",
      " [0.86903447]\n",
      " [0.87304908]\n",
      " [0.87509447]\n",
      " [0.87711322]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8397204264676091\n",
      "Predicci√≥n : [[0.8797965]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[[0.85545158]\n",
      "  [0.85953128]\n",
      "  [0.86290145]\n",
      "  [0.86553144]\n",
      "  [0.86903447]\n",
      "  [0.87304908]\n",
      "  [0.87509447]\n",
      "  [0.87711322]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016060919733718038\n",
      "Predicci√≥n post entrenamiento : [[0.8792384]]\n",
      "PERDIDAAAA despues: 0.001561672193929553\n",
      "loss en el callback: 0.007855026982724667, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "ejemplar: [[0.85953128]\n",
      " [0.86290145]\n",
      " [0.86553144]\n",
      " [0.86903447]\n",
      " [0.87304908]\n",
      " [0.87509447]\n",
      " [0.87711322]\n",
      " [0.8797965 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.852176932689015\n",
      "Predicci√≥n : [[0.88219345]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[[0.85953128]\n",
      "  [0.86290145]\n",
      "  [0.86553144]\n",
      "  [0.86903447]\n",
      "  [0.87304908]\n",
      "  [0.87509447]\n",
      "  [0.87711322]\n",
      "  [0.8797965 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009009927744045854\n",
      "Predicci√≥n post entrenamiento : [[0.8824002]]\n",
      "PERDIDAAAA despues: 0.0009134484571404755\n",
      "loss en el callback: 0.0014707169029861689, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "ejemplar: [[0.86290145]\n",
      " [0.86553144]\n",
      " [0.86903447]\n",
      " [0.87304908]\n",
      " [0.87509447]\n",
      " [0.87711322]\n",
      " [0.8797965 ]\n",
      " [0.88219345]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8615626813481295\n",
      "Predicci√≥n : [[0.8850903]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[[0.86290145]\n",
      "  [0.86553144]\n",
      "  [0.86903447]\n",
      "  [0.87304908]\n",
      "  [0.87509447]\n",
      "  [0.87711322]\n",
      "  [0.8797965 ]\n",
      "  [0.88219345]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005535490345209837\n",
      "Predicci√≥n post entrenamiento : [[0.8851705]]\n",
      "PERDIDAAAA despues: 0.0005573306116275489\n",
      "loss en el callback: 0.00019917366444133222, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "ejemplar: [[0.86553144]\n",
      " [0.86903447]\n",
      " [0.87304908]\n",
      " [0.87509447]\n",
      " [0.87711322]\n",
      " [0.8797965 ]\n",
      " [0.88219345]\n",
      " [0.88509029]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8678776724449532\n",
      "Predicci√≥n : [[0.8877357]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[[0.86553144]\n",
      "  [0.86903447]\n",
      "  [0.87304908]\n",
      "  [0.87509447]\n",
      "  [0.87711322]\n",
      "  [0.8797965 ]\n",
      "  [0.88219345]\n",
      "  [0.88509029]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003943426418118179\n",
      "Predicci√≥n post entrenamiento : [[0.88759744]]\n",
      "PERDIDAAAA despues: 0.00038886969559825957\n",
      "loss en el callback: 0.0005762369837611914, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "ejemplar: [[0.86903447]\n",
      " [0.87304908]\n",
      " [0.87509447]\n",
      " [0.87711322]\n",
      " [0.8797965 ]\n",
      " [0.88219345]\n",
      " [0.88509029]\n",
      " [0.88773572]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8701963127047843\n",
      "Predicci√≥n : [[0.8902119]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[[0.86903447]\n",
      "  [0.87304908]\n",
      "  [0.87509447]\n",
      "  [0.87711322]\n",
      "  [0.8797965 ]\n",
      "  [0.88219345]\n",
      "  [0.88509029]\n",
      "  [0.88773572]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004006217641290277\n",
      "Predicci√≥n post entrenamiento : [[0.8897457]]\n",
      "PERDIDAAAA despues: 0.0003821778518613428\n",
      "loss en el callback: 0.005822412203997374, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "ejemplar: [[0.87304908]\n",
      " [0.87509447]\n",
      " [0.87711322]\n",
      " [0.8797965 ]\n",
      " [0.88219345]\n",
      " [0.88509029]\n",
      " [0.88773572]\n",
      " [0.89021188]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8685186021276227\n",
      "Predicci√≥n : [[0.8921518]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[[0.87304908]\n",
      "  [0.87509447]\n",
      "  [0.87711322]\n",
      "  [0.8797965 ]\n",
      "  [0.88219345]\n",
      "  [0.88509029]\n",
      "  [0.88773572]\n",
      "  [0.89021188]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005585273029282689\n",
      "Predicci√≥n post entrenamiento : [[0.89092326]]\n",
      "PERDIDAAAA despues: 0.0005019692471250892\n",
      "loss en el callback: 0.03502686321735382, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "ejemplar: [[0.87509447]\n",
      " [0.87711322]\n",
      " [0.8797965 ]\n",
      " [0.88219345]\n",
      " [0.88509029]\n",
      " [0.88773572]\n",
      " [0.89021188]\n",
      " [0.89215177]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8529880395838255\n",
      "Predicci√≥n : [[0.8929332]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[[0.87509447]\n",
      "  [0.87711322]\n",
      "  [0.8797965 ]\n",
      "  [0.88219345]\n",
      "  [0.88509029]\n",
      "  [0.88773572]\n",
      "  [0.89021188]\n",
      "  [0.89215177]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015956130810081959\n",
      "Predicci√≥n post entrenamiento : [[0.8922499]]\n",
      "PERDIDAAAA despues: 0.0015414903173223138\n",
      "loss en el callback: 0.012484307400882244, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "ejemplar: [[0.87711322]\n",
      " [0.8797965 ]\n",
      " [0.88219345]\n",
      " [0.88509029]\n",
      " [0.88773572]\n",
      " [0.89021188]\n",
      " [0.89215177]\n",
      " [0.89293319]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8236046250733932\n",
      "Predicci√≥n : [[0.89435625]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[[0.87711322]\n",
      "  [0.8797965 ]\n",
      "  [0.88219345]\n",
      "  [0.88509029]\n",
      "  [0.88773572]\n",
      "  [0.89021188]\n",
      "  [0.89215177]\n",
      "  [0.89293319]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0050057899206876755\n",
      "Predicci√≥n post entrenamiento : [[0.89488566]]\n",
      "PERDIDAAAA despues: 0.00508098304271698\n",
      "loss en el callback: 0.011630340479314327, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "ejemplar: [[0.8797965 ]\n",
      " [0.88219345]\n",
      " [0.88509029]\n",
      " [0.88773572]\n",
      " [0.89021188]\n",
      " [0.89215177]\n",
      " [0.89293319]\n",
      " [0.89435625]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8032508871761479\n",
      "Predicci√≥n : [[0.8970924]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[[0.8797965 ]\n",
      "  [0.88219345]\n",
      "  [0.88509029]\n",
      "  [0.88773572]\n",
      "  [0.89021188]\n",
      "  [0.89215177]\n",
      "  [0.89293319]\n",
      "  [0.89435625]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008806225843727589\n",
      "Predicci√≥n post entrenamiento : [[0.89692163]]\n",
      "PERDIDAAAA despues: 0.00877420511096716\n",
      "loss en el callback: 0.0010287704644724727, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "ejemplar: [[0.88219345]\n",
      " [0.88509029]\n",
      " [0.88773572]\n",
      " [0.89021188]\n",
      " [0.89215177]\n",
      " [0.89293319]\n",
      " [0.89435625]\n",
      " [0.8970924 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7919268258920897\n",
      "Predicci√≥n : [[0.8990301]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[[0.88219345]\n",
      "  [0.88509029]\n",
      "  [0.88773572]\n",
      "  [0.89021188]\n",
      "  [0.89215177]\n",
      "  [0.89293319]\n",
      "  [0.89435625]\n",
      "  [0.8970924 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011471114121377468\n",
      "Predicci√≥n post entrenamiento : [[0.89840794]]\n",
      "PERDIDAAAA despues: 0.011338232085108757\n",
      "loss en el callback: 0.012201618403196335, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "ejemplar: [[0.88509029]\n",
      " [0.88773572]\n",
      " [0.89021188]\n",
      " [0.89215177]\n",
      " [0.89293319]\n",
      " [0.89435625]\n",
      " [0.8970924 ]\n",
      " [0.89903009]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7865023059771536\n",
      "Predicci√≥n : [[0.9004608]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[[0.88509029]\n",
      "  [0.88773572]\n",
      "  [0.89021188]\n",
      "  [0.89215177]\n",
      "  [0.89293319]\n",
      "  [0.89435625]\n",
      "  [0.8970924 ]\n",
      "  [0.89903009]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012986534275114536\n",
      "Predicci√≥n post entrenamiento : [[0.89968705]]\n",
      "PERDIDAAAA despues: 0.012810787186026573\n",
      "loss en el callback: 0.01936916634440422, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "ejemplar: [[0.88773572]\n",
      " [0.89021188]\n",
      " [0.89215177]\n",
      " [0.89293319]\n",
      " [0.89435625]\n",
      " [0.8970924 ]\n",
      " [0.89903009]\n",
      " [0.90046078]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7869773274313391\n",
      "Predicci√≥n : [[0.9015119]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[[0.88773572]\n",
      "  [0.89021188]\n",
      "  [0.89215177]\n",
      "  [0.89293319]\n",
      "  [0.89435625]\n",
      "  [0.8970924 ]\n",
      "  [0.89903009]\n",
      "  [0.90046078]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013118164613842964\n",
      "Predicci√≥n post entrenamiento : [[0.9017082]]\n",
      "PERDIDAAAA despues: 0.013163164258003235\n",
      "loss en el callback: 0.001893682056106627, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "ejemplar: [[0.89021188]\n",
      " [0.89215177]\n",
      " [0.89293319]\n",
      " [0.89435625]\n",
      " [0.8970924 ]\n",
      " [0.89903009]\n",
      " [0.90046078]\n",
      " [0.90151191]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7874362431744556\n",
      "Predicci√≥n : [[0.90332514]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[[0.89021188]\n",
      "  [0.89215177]\n",
      "  [0.89293319]\n",
      "  [0.89435625]\n",
      "  [0.8970924 ]\n",
      "  [0.89903009]\n",
      "  [0.90046078]\n",
      "  [0.90151191]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013430235907435417\n",
      "Predicci√≥n post entrenamiento : [[0.9021714]]\n",
      "PERDIDAAAA despues: 0.013164149597287178\n",
      "loss en el callback: 0.03838980570435524, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "ejemplar: [[0.89215177]\n",
      " [0.89293319]\n",
      " [0.89435625]\n",
      " [0.8970924 ]\n",
      " [0.89903009]\n",
      " [0.90046078]\n",
      " [0.90151191]\n",
      " [0.90332514]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7878790532065031\n",
      "Predicci√≥n : [[0.90358794]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[[0.89215177]\n",
      "  [0.89293319]\n",
      "  [0.89435625]\n",
      "  [0.8970924 ]\n",
      "  [0.89903009]\n",
      "  [0.90046078]\n",
      "  [0.90151191]\n",
      "  [0.90332514]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013388547115027905\n",
      "Predicci√≥n post entrenamiento : [[0.9036875]]\n",
      "PERDIDAAAA despues: 0.01341159176081419\n",
      "loss en el callback: 0.00040750374319031835, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "ejemplar: [[0.89293319]\n",
      " [0.89435625]\n",
      " [0.8970924 ]\n",
      " [0.89903009]\n",
      " [0.90046078]\n",
      " [0.90151191]\n",
      " [0.90332514]\n",
      " [0.90358794]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7954532004373992\n",
      "Predicci√≥n : [[0.90501803]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[[0.89293319]\n",
      "  [0.89435625]\n",
      "  [0.8970924 ]\n",
      "  [0.89903009]\n",
      "  [0.90046078]\n",
      "  [0.90151191]\n",
      "  [0.90332514]\n",
      "  [0.90358794]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012004454620182514\n",
      "Predicci√≥n post entrenamiento : [[0.9041342]]\n",
      "PERDIDAAAA despues: 0.011811564676463604\n",
      "loss en el callback: 0.025013728067278862, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "ejemplar: [[0.89435625]\n",
      " [0.8970924 ]\n",
      " [0.89903009]\n",
      " [0.90046078]\n",
      " [0.90151191]\n",
      " [0.90332514]\n",
      " [0.90358794]\n",
      " [0.90501803]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8101586848671446\n",
      "Predicci√≥n : [[0.9056844]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[[0.89435625]\n",
      "  [0.8970924 ]\n",
      "  [0.89903009]\n",
      "  [0.90046078]\n",
      "  [0.90151191]\n",
      "  [0.90332514]\n",
      "  [0.90358794]\n",
      "  [0.90501803]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00912516750395298\n",
      "Predicci√≥n post entrenamiento : [[0.90603405]]\n",
      "PERDIDAAAA despues: 0.00919208861887455\n",
      "loss en el callback: 0.006294085644185543, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "ejemplar: [[0.8970924 ]\n",
      " [0.89903009]\n",
      " [0.90046078]\n",
      " [0.90151191]\n",
      " [0.90332514]\n",
      " [0.90358794]\n",
      " [0.90501803]\n",
      " [0.90568441]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7668473230866574\n",
      "Predicci√≥n : [[0.9076296]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[[0.8970924 ]\n",
      "  [0.89903009]\n",
      "  [0.90046078]\n",
      "  [0.90151191]\n",
      "  [0.90332514]\n",
      "  [0.90358794]\n",
      "  [0.90501803]\n",
      "  [0.90568441]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019819654524326324\n",
      "Predicci√≥n post entrenamiento : [[0.9070008]]\n",
      "PERDIDAAAA despues: 0.019642993807792664\n",
      "loss en el callback: 0.01534274686127901, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "ejemplar: [[0.89903009]\n",
      " [0.90046078]\n",
      " [0.90151191]\n",
      " [0.90332514]\n",
      " [0.90358794]\n",
      " [0.90501803]\n",
      " [0.90568441]\n",
      " [0.90762961]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6655191150959373\n",
      "Predicci√≥n : [[0.9082499]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[[0.89903009]\n",
      "  [0.90046078]\n",
      "  [0.90151191]\n",
      "  [0.90332514]\n",
      "  [0.90358794]\n",
      "  [0.90501803]\n",
      "  [0.90568441]\n",
      "  [0.90762961]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05891823768615723\n",
      "Predicci√≥n post entrenamiento : [[0.9080047]]\n",
      "PERDIDAAAA despues: 0.05879925936460495\n",
      "loss en el callback: 0.003172151744365692, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "ejemplar: [[0.90046078]\n",
      " [0.90151191]\n",
      " [0.90332514]\n",
      " [0.90358794]\n",
      " [0.90501803]\n",
      " [0.90568441]\n",
      " [0.90762961]\n",
      " [0.90824991]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6360738003224796\n",
      "Predicci√≥n : [[0.9090675]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[[0.90046078]\n",
      "  [0.90151191]\n",
      "  [0.90332514]\n",
      "  [0.90358794]\n",
      "  [0.90501803]\n",
      "  [0.90568441]\n",
      "  [0.90762961]\n",
      "  [0.90824991]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07452555000782013\n",
      "Predicci√≥n post entrenamiento : [[0.9077741]]\n",
      "PERDIDAAAA despues: 0.07382103055715561\n",
      "loss en el callback: 0.06461317837238312, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "ejemplar: [[0.90151191]\n",
      " [0.90332514]\n",
      " [0.90358794]\n",
      " [0.90501803]\n",
      " [0.90568441]\n",
      " [0.90762961]\n",
      " [0.90824991]\n",
      " [0.90906751]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6785113787662842\n",
      "Predicci√≥n : [[0.90875894]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[[0.90151191]\n",
      "  [0.90332514]\n",
      "  [0.90358794]\n",
      "  [0.90501803]\n",
      "  [0.90568441]\n",
      "  [0.90762961]\n",
      "  [0.90824991]\n",
      "  [0.90906751]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.053013939410448074\n",
      "Predicci√≥n post entrenamiento : [[0.9065419]]\n",
      "PERDIDAAAA despues: 0.05199791118502617\n",
      "loss en el callback: 0.13937154412269592, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "ejemplar: [[0.90332514]\n",
      " [0.90358794]\n",
      " [0.90501803]\n",
      " [0.90568441]\n",
      " [0.90762961]\n",
      " [0.90824991]\n",
      " [0.90906751]\n",
      " [0.90875894]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6965967339840231\n",
      "Predicci√≥n : [[0.9075319]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[[0.90332514]\n",
      "  [0.90358794]\n",
      "  [0.90501803]\n",
      "  [0.90568441]\n",
      "  [0.90762961]\n",
      "  [0.90824991]\n",
      "  [0.90906751]\n",
      "  [0.90875894]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.044493649154901505\n",
      "Predicci√≥n post entrenamiento : [[0.9070808]]\n",
      "PERDIDAAAA despues: 0.04430355131626129\n",
      "loss en el callback: 0.009358813986182213, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "ejemplar: [[0.90358794]\n",
      " [0.90501803]\n",
      " [0.90568441]\n",
      " [0.90762961]\n",
      " [0.90824991]\n",
      " [0.90906751]\n",
      " [0.90875894]\n",
      " [0.90753192]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6903298659756966\n",
      "Predicci√≥n : [[0.90783423]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[[0.90358794]\n",
      "  [0.90501803]\n",
      "  [0.90568441]\n",
      "  [0.90762961]\n",
      "  [0.90824991]\n",
      "  [0.90906751]\n",
      "  [0.90875894]\n",
      "  [0.90753192]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04730815440416336\n",
      "Predicci√≥n post entrenamiento : [[0.9069584]]\n",
      "PERDIDAAAA despues: 0.04692792892456055\n",
      "loss en el callback: 0.03424154222011566, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "ejemplar: [[0.90501803]\n",
      " [0.90568441]\n",
      " [0.90762961]\n",
      " [0.90824991]\n",
      " [0.90906751]\n",
      " [0.90875894]\n",
      " [0.90753192]\n",
      " [0.90783423]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6970473058045382\n",
      "Predicci√≥n : [[0.9078498]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[[0.90501803]\n",
      "  [0.90568441]\n",
      "  [0.90762961]\n",
      "  [0.90824991]\n",
      "  [0.90906751]\n",
      "  [0.90875894]\n",
      "  [0.90753192]\n",
      "  [0.90783423]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04443769156932831\n",
      "Predicci√≥n post entrenamiento : [[0.90706474]]\n",
      "PERDIDAAAA despues: 0.04410732537508011\n",
      "loss en el callback: 0.02454361319541931, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "ejemplar: [[0.90568441]\n",
      " [0.90762961]\n",
      " [0.90824991]\n",
      " [0.90906751]\n",
      " [0.90875894]\n",
      " [0.90753192]\n",
      " [0.90783423]\n",
      " [0.90784979]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7167490534705484\n",
      "Predicci√≥n : [[0.90774524]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[[0.90568441]\n",
      "  [0.90762961]\n",
      "  [0.90824991]\n",
      "  [0.90906751]\n",
      "  [0.90875894]\n",
      "  [0.90753192]\n",
      "  [0.90783423]\n",
      "  [0.90784979]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.036479536443948746\n",
      "Predicci√≥n post entrenamiento : [[0.90671927]]\n",
      "PERDIDAAAA despues: 0.03608867526054382\n",
      "loss en el callback: 0.04250696301460266, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "ejemplar: [[0.90762961]\n",
      " [0.90824991]\n",
      " [0.90906751]\n",
      " [0.90875894]\n",
      " [0.90753192]\n",
      " [0.90783423]\n",
      " [0.90784979]\n",
      " [0.90774524]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7490507063998944\n",
      "Predicci√≥n : [[0.9073362]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[[0.90762961]\n",
      "  [0.90824991]\n",
      "  [0.90906751]\n",
      "  [0.90875894]\n",
      "  [0.90753192]\n",
      "  [0.90783423]\n",
      "  [0.90784979]\n",
      "  [0.90774524]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02505429834127426\n",
      "Predicci√≥n post entrenamiento : [[0.9053829]]\n",
      "PERDIDAAAA despues: 0.024439755827188492\n",
      "loss en el callback: 0.11094093322753906, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "ejemplar: [[0.90824991]\n",
      " [0.90906751]\n",
      " [0.90875894]\n",
      " [0.90753192]\n",
      " [0.90783423]\n",
      " [0.90784979]\n",
      " [0.90774524]\n",
      " [0.90733618]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7939522645925762\n",
      "Predicci√≥n : [[0.90553004]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[[0.90824991]\n",
      "  [0.90906751]\n",
      "  [0.90875894]\n",
      "  [0.90753192]\n",
      "  [0.90783423]\n",
      "  [0.90784979]\n",
      "  [0.90774524]\n",
      "  [0.90733618]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012449594214558601\n",
      "Predicci√≥n post entrenamiento : [[0.90508604]]\n",
      "PERDIDAAAA despues: 0.012350711040198803\n",
      "loss en el callback: 0.008383693173527718, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "ejemplar: [[0.90906751]\n",
      " [0.90875894]\n",
      " [0.90753192]\n",
      " [0.90783423]\n",
      " [0.90784979]\n",
      " [0.90774524]\n",
      " [0.90733618]\n",
      " [0.90553004]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8547447263586395\n",
      "Predicci√≥n : [[0.90504223]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[[0.90906751]\n",
      "  [0.90875894]\n",
      "  [0.90753192]\n",
      "  [0.90783423]\n",
      "  [0.90784979]\n",
      "  [0.90774524]\n",
      "  [0.90733618]\n",
      "  [0.90553004]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002529838355258107\n",
      "Predicci√≥n post entrenamiento : [[0.9054994]]\n",
      "PERDIDAAAA despues: 0.0025760361459106207\n",
      "loss en el callback: 0.012843514792621136, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "ejemplar: [[0.90875894]\n",
      " [0.90753192]\n",
      " [0.90783423]\n",
      " [0.90784979]\n",
      " [0.90774524]\n",
      " [0.90733618]\n",
      " [0.90553004]\n",
      " [0.90504223]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9314280916980849\n",
      "Predicci√≥n : [[0.90515995]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[[0.90875894]\n",
      "  [0.90753192]\n",
      "  [0.90783423]\n",
      "  [0.90784979]\n",
      "  [0.90774524]\n",
      "  [0.90733618]\n",
      "  [0.90553004]\n",
      "  [0.90504223]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006900143926031888\n",
      "Predicci√≥n post entrenamiento : [[0.90564144]]\n",
      "PERDIDAAAA despues: 0.0006649506976827979\n",
      "loss en el callback: 0.010787807404994965, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "ejemplar: [[0.90753192]\n",
      " [0.90783423]\n",
      " [0.90784979]\n",
      " [0.90774524]\n",
      " [0.90733618]\n",
      " [0.90553004]\n",
      " [0.90504223]\n",
      " [0.90515995]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9627243989762315\n",
      "Predicci√≥n : [[0.9052743]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[[0.90753192]\n",
      "  [0.90783423]\n",
      "  [0.90784979]\n",
      "  [0.90774524]\n",
      "  [0.90733618]\n",
      "  [0.90553004]\n",
      "  [0.90504223]\n",
      "  [0.90515995]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0033005157019943\n",
      "Predicci√≥n post entrenamiento : [[0.9058246]]\n",
      "PERDIDAAAA despues: 0.003237585537135601\n",
      "loss en el callback: 0.013879268430173397, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "ejemplar: [[0.90783423]\n",
      " [0.90784979]\n",
      " [0.90774524]\n",
      " [0.90733618]\n",
      " [0.90553004]\n",
      " [0.90504223]\n",
      " [0.90515995]\n",
      " [0.90527427]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9486336481930799\n",
      "Predicci√≥n : [[0.9056836]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[[0.90783423]\n",
      "  [0.90784979]\n",
      "  [0.90774524]\n",
      "  [0.90733618]\n",
      "  [0.90553004]\n",
      "  [0.90504223]\n",
      "  [0.90515995]\n",
      "  [0.90527427]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001844710553996265\n",
      "Predicci√≥n post entrenamiento : [[0.90576184]]\n",
      "PERDIDAAAA despues: 0.0018379940884187818\n",
      "loss en el callback: 0.0002625406195875257, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "ejemplar: [[0.90784979]\n",
      " [0.90774524]\n",
      " [0.90733618]\n",
      " [0.90553004]\n",
      " [0.90504223]\n",
      " [0.90515995]\n",
      " [0.90527427]\n",
      " [0.90568358]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9307145892932484\n",
      "Predicci√≥n : [[0.9054451]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[[0.90784979]\n",
      "  [0.90774524]\n",
      "  [0.90733618]\n",
      "  [0.90553004]\n",
      "  [0.90504223]\n",
      "  [0.90515995]\n",
      "  [0.90527427]\n",
      "  [0.90568358]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006385480519384146\n",
      "Predicci√≥n post entrenamiento : [[0.9050956]]\n",
      "PERDIDAAAA despues: 0.0006563346832990646\n",
      "loss en el callback: 0.004221227020025253, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "ejemplar: [[0.90774524]\n",
      " [0.90733618]\n",
      " [0.90553004]\n",
      " [0.90504223]\n",
      " [0.90515995]\n",
      " [0.90527427]\n",
      " [0.90568358]\n",
      " [0.9054451 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.908967222276737\n",
      "Predicci√≥n : [[0.9046654]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[[0.90774524]\n",
      "  [0.90733618]\n",
      "  [0.90553004]\n",
      "  [0.90504223]\n",
      "  [0.90515995]\n",
      "  [0.90527427]\n",
      "  [0.90568358]\n",
      "  [0.9054451 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.8505366824683733e-05\n",
      "Predicci√≥n post entrenamiento : [[0.90469795]]\n",
      "PERDIDAAAA despues: 1.8226430256618187e-05\n",
      "loss en el callback: 4.459707997739315e-05, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "ejemplar: [[0.90733618]\n",
      " [0.90553004]\n",
      " [0.90504223]\n",
      " [0.90515995]\n",
      " [0.90527427]\n",
      " [0.90568358]\n",
      " [0.9054451 ]\n",
      " [0.90466541]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8816379650841193\n",
      "Predicci√≥n : [[0.9041846]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[[0.90733618]\n",
      "  [0.90553004]\n",
      "  [0.90504223]\n",
      "  [0.90515995]\n",
      "  [0.90527427]\n",
      "  [0.90568358]\n",
      "  [0.9054451 ]\n",
      "  [0.90466541]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005083486903458834\n",
      "Predicci√≥n post entrenamiento : [[0.9041358]]\n",
      "PERDIDAAAA despues: 0.0005061524570919573\n",
      "loss en el callback: 0.0001095055413316004, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "ejemplar: [[0.90553004]\n",
      " [0.90504223]\n",
      " [0.90515995]\n",
      " [0.90527427]\n",
      " [0.90568358]\n",
      " [0.9054451 ]\n",
      " [0.90466541]\n",
      " [0.90418458]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8487268177153953\n",
      "Predicci√≥n : [[0.90362865]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[[0.90553004]\n",
      "  [0.90504223]\n",
      "  [0.90515995]\n",
      "  [0.90527427]\n",
      "  [0.90568358]\n",
      "  [0.9054451 ]\n",
      "  [0.90466541]\n",
      "  [0.90418458]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0030142117757350206\n",
      "Predicci√≥n post entrenamiento : [[0.90329844]]\n",
      "PERDIDAAAA despues: 0.0029780627228319645\n",
      "loss en el callback: 0.004502600524574518, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "ejemplar: [[0.90504223]\n",
      " [0.90515995]\n",
      " [0.90527427]\n",
      " [0.90568358]\n",
      " [0.9054451 ]\n",
      " [0.90466541]\n",
      " [0.90418458]\n",
      " [0.90362865]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.875260685634848\n",
      "Predicci√≥n : [[0.9032034]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[[0.90504223]\n",
      "  [0.90515995]\n",
      "  [0.90527427]\n",
      "  [0.90568358]\n",
      "  [0.9054451 ]\n",
      "  [0.90466541]\n",
      "  [0.90418458]\n",
      "  [0.90362865]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000780795409809798\n",
      "Predicci√≥n post entrenamiento : [[0.90179956]]\n",
      "PERDIDAAAA despues: 0.0007043104851618409\n",
      "loss en el callback: 0.059891603887081146, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "ejemplar: [[0.90515995]\n",
      " [0.90527427]\n",
      " [0.90568358]\n",
      " [0.9054451 ]\n",
      " [0.90466541]\n",
      " [0.90418458]\n",
      " [0.90362865]\n",
      " [0.90320343]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9612395688424776\n",
      "Predicci√≥n : [[0.9017957]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[[0.90515995]\n",
      "  [0.90527427]\n",
      "  [0.90568358]\n",
      "  [0.9054451 ]\n",
      "  [0.90466541]\n",
      "  [0.90418458]\n",
      "  [0.90362865]\n",
      "  [0.90320343]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003533576149493456\n",
      "Predicci√≥n post entrenamiento : [[0.9018516]]\n",
      "PERDIDAAAA despues: 0.0035269323270767927\n",
      "loss en el callback: 0.00013061141362413764, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "ejemplar: [[0.90527427]\n",
      " [0.90568358]\n",
      " [0.9054451 ]\n",
      " [0.90466541]\n",
      " [0.90418458]\n",
      " [0.90362865]\n",
      " [0.90320343]\n",
      " [0.90179569]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9925021123407926\n",
      "Predicci√≥n : [[0.9017583]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[[0.90527427]\n",
      "  [0.90568358]\n",
      "  [0.9054451 ]\n",
      "  [0.90466541]\n",
      "  [0.90418458]\n",
      "  [0.90362865]\n",
      "  [0.90320343]\n",
      "  [0.90179569]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008234433829784393\n",
      "Predicci√≥n post entrenamiento : [[0.90233815]]\n",
      "PERDIDAAAA despues: 0.008129537105560303\n",
      "loss en el callback: 0.016929704695940018, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "ejemplar: [[0.90568358]\n",
      " [0.9054451 ]\n",
      " [0.90466541]\n",
      " [0.90418458]\n",
      " [0.90362865]\n",
      " [0.90320343]\n",
      " [0.90179569]\n",
      " [0.90175831]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.969048316129792\n",
      "Predicci√≥n : [[0.90212274]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[[0.90568358]\n",
      "  [0.9054451 ]\n",
      "  [0.90466541]\n",
      "  [0.90418458]\n",
      "  [0.90362865]\n",
      "  [0.90320343]\n",
      "  [0.90179569]\n",
      "  [0.90175831]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004479033872485161\n",
      "Predicci√≥n post entrenamiento : [[0.9029707]]\n",
      "PERDIDAAAA despues: 0.004366255830973387\n",
      "loss en el callback: 0.043594710528850555, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "ejemplar: [[0.9054451 ]\n",
      " [0.90466541]\n",
      " [0.90418458]\n",
      " [0.90362865]\n",
      " [0.90320343]\n",
      " [0.90179569]\n",
      " [0.90175831]\n",
      " [0.90212274]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9715476120161949\n",
      "Predicci√≥n : [[0.9025225]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[[0.9054451 ]\n",
      "  [0.90466541]\n",
      "  [0.90418458]\n",
      "  [0.90362865]\n",
      "  [0.90320343]\n",
      "  [0.90179569]\n",
      "  [0.90175831]\n",
      "  [0.90212274]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004764464218169451\n",
      "Predicci√≥n post entrenamiento : [[0.903178]]\n",
      "PERDIDAAAA despues: 0.004674405790865421\n",
      "loss en el callback: 0.027145344763994217, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "ejemplar: [[0.90466541]\n",
      " [0.90418458]\n",
      " [0.90362865]\n",
      " [0.90320343]\n",
      " [0.90179569]\n",
      " [0.90175831]\n",
      " [0.90212274]\n",
      " [0.9025225 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 1.0\n",
      "Predicci√≥n : [[0.90265405]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[[0.90466541]\n",
      "  [0.90418458]\n",
      "  [0.90362865]\n",
      "  [0.90320343]\n",
      "  [0.90179569]\n",
      "  [0.90175831]\n",
      "  [0.90212274]\n",
      "  [0.9025225 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009476233273744583\n",
      "Predicci√≥n post entrenamiento : [[0.9035803]]\n",
      "PERDIDAAAA despues: 0.00929675716906786\n",
      "loss en el callback: 0.056505024433135986, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "ejemplar: [[0.90418458]\n",
      " [0.90362865]\n",
      " [0.90320343]\n",
      " [0.90179569]\n",
      " [0.90175831]\n",
      " [0.90212274]\n",
      " [0.9025225 ]\n",
      " [0.90265405]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9800636522775721\n",
      "Predicci√≥n : [[0.9031424]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[[0.90418458]\n",
      "  [0.90362865]\n",
      "  [0.90320343]\n",
      "  [0.90179569]\n",
      "  [0.90175831]\n",
      "  [0.90212274]\n",
      "  [0.9025225 ]\n",
      "  [0.90265405]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005916884168982506\n",
      "Predicci√≥n post entrenamiento : [[0.9032897]]\n",
      "PERDIDAAAA despues: 0.005894247442483902\n",
      "loss en el callback: 0.0009570067632012069, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "ejemplar: [[0.90362865]\n",
      " [0.90320343]\n",
      " [0.90179569]\n",
      " [0.90175831]\n",
      " [0.90212274]\n",
      " [0.9025225 ]\n",
      " [0.90265405]\n",
      " [0.90314239]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.911738568848911\n",
      "Predicci√≥n : [[0.9028903]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[[0.90362865]\n",
      "  [0.90320343]\n",
      "  [0.90179569]\n",
      "  [0.90175831]\n",
      "  [0.90212274]\n",
      "  [0.9025225 ]\n",
      "  [0.90265405]\n",
      "  [0.90314239]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.829152309568599e-05\n",
      "Predicci√≥n post entrenamiento : [[0.90289074]]\n",
      "PERDIDAAAA despues: 7.82841452746652e-05\n",
      "loss en el callback: 1.1193268534270828e-08, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "ejemplar: [[0.90320343]\n",
      " [0.90179569]\n",
      " [0.90175831]\n",
      " [0.90212274]\n",
      " [0.9025225 ]\n",
      " [0.90265405]\n",
      " [0.90314239]\n",
      " [0.90289032]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8910857934126422\n",
      "Predicci√≥n : [[0.90258086]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[[0.90320343]\n",
      "  [0.90179569]\n",
      "  [0.90175831]\n",
      "  [0.90212274]\n",
      "  [0.9025225 ]\n",
      "  [0.90265405]\n",
      "  [0.90314239]\n",
      "  [0.90289032]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00013213626516517252\n",
      "Predicci√≥n post entrenamiento : [[0.902113]]\n",
      "PERDIDAAAA despues: 0.00012159951438661665\n",
      "loss en el callback: 0.009837768971920013, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "ejemplar: [[0.90179569]\n",
      " [0.90175831]\n",
      " [0.90212274]\n",
      " [0.9025225 ]\n",
      " [0.90265405]\n",
      " [0.90314239]\n",
      " [0.90289032]\n",
      " [0.90258086]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9181053259687657\n",
      "Predicci√≥n : [[0.9018886]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[[0.90179569]\n",
      "  [0.90175831]\n",
      "  [0.90212274]\n",
      "  [0.9025225 ]\n",
      "  [0.90265405]\n",
      "  [0.90314239]\n",
      "  [0.90289032]\n",
      "  [0.90258086]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00026298119337297976\n",
      "Predicci√≥n post entrenamiento : [[0.9019391]]\n",
      "PERDIDAAAA despues: 0.00026134634390473366\n",
      "loss en el callback: 0.00012736752978526056, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "ejemplar: [[0.90175831]\n",
      " [0.90212274]\n",
      " [0.9025225 ]\n",
      " [0.90265405]\n",
      " [0.90314239]\n",
      " [0.90289032]\n",
      " [0.90258086]\n",
      " [0.90188861]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9450165163483527\n",
      "Predicci√≥n : [[0.90209836]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[[0.90175831]\n",
      "  [0.90212274]\n",
      "  [0.9025225 ]\n",
      "  [0.90265405]\n",
      "  [0.90314239]\n",
      "  [0.90289032]\n",
      "  [0.90258086]\n",
      "  [0.90188861]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018419672269374132\n",
      "Predicci√≥n post entrenamiento : [[0.9021374]]\n",
      "PERDIDAAAA despues: 0.0018386176088824868\n",
      "loss en el callback: 7.524492684751749e-05, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "ejemplar: [[0.90212274]\n",
      " [0.9025225 ]\n",
      " [0.90265405]\n",
      " [0.90314239]\n",
      " [0.90289032]\n",
      " [0.90258086]\n",
      " [0.90188861]\n",
      " [0.90209836]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9718193645514037\n",
      "Predicci√≥n : [[0.90233964]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[[0.90212274]\n",
      "  [0.9025225 ]\n",
      "  [0.90265405]\n",
      "  [0.90314239]\n",
      "  [0.90289032]\n",
      "  [0.90258086]\n",
      "  [0.90188861]\n",
      "  [0.90209836]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004827429074794054\n",
      "Predicci√≥n post entrenamiento : [[0.9027492]]\n",
      "PERDIDAAAA despues: 0.004770686849951744\n",
      "loss en el callback: 0.009666777215898037, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "ejemplar: [[0.9025225 ]\n",
      " [0.90265405]\n",
      " [0.90314239]\n",
      " [0.90289032]\n",
      " [0.90258086]\n",
      " [0.90188861]\n",
      " [0.90209836]\n",
      " [0.90233964]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9829067192737589\n",
      "Predicci√≥n : [[0.9028744]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[[0.9025225 ]\n",
      "  [0.90265405]\n",
      "  [0.90314239]\n",
      "  [0.90289032]\n",
      "  [0.90258086]\n",
      "  [0.90188861]\n",
      "  [0.90209836]\n",
      "  [0.90233964]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006405167281627655\n",
      "Predicci√≥n post entrenamiento : [[0.90323836]]\n",
      "PERDIDAAAA despues: 0.006347044836729765\n",
      "loss en el callback: 0.007259042002260685, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "ejemplar: [[0.90265405]\n",
      " [0.90314239]\n",
      " [0.90289032]\n",
      " [0.90258086]\n",
      " [0.90188861]\n",
      " [0.90209836]\n",
      " [0.90233964]\n",
      " [0.90287441]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9782785805154182\n",
      "Predicci√≥n : [[0.90325886]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[[0.90265405]\n",
      "  [0.90314239]\n",
      "  [0.90289032]\n",
      "  [0.90258086]\n",
      "  [0.90188861]\n",
      "  [0.90209836]\n",
      "  [0.90233964]\n",
      "  [0.90287441]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005627958104014397\n",
      "Predicci√≥n post entrenamiento : [[0.9036132]]\n",
      "PERDIDAAAA despues: 0.005574916955083609\n",
      "loss en el callback: 0.0060989996418356895, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "ejemplar: [[0.05029815]\n",
      " [0.00860651]\n",
      " [0.        ]\n",
      " [0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.049424632939554\n",
      "Predicci√≥n : [[0.22419593]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.05029815]\n",
      "  [0.00860651]\n",
      "  [0.        ]\n",
      "  [0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.030545005574822426\n",
      "Predicci√≥n post entrenamiento : [[0.20207931]]\n",
      "PERDIDAAAA despues: 0.023303451016545296\n",
      "loss en el callback: 0.01602282002568245, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "ejemplar: [[0.00860651]\n",
      " [0.        ]\n",
      " [0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.22419593]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.10789185692558968\n",
      "Predicci√≥n : [[0.19715023]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.00860651]\n",
      "  [0.        ]\n",
      "  [0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.22419593]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007967056706547737\n",
      "Predicci√≥n post entrenamiento : [[0.17065309]]\n",
      "PERDIDAAAA despues: 0.003938972484320402\n",
      "loss en el callback: 0.012064182199537754, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "ejemplar: [[0.        ]\n",
      " [0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.22419593]\n",
      " [0.19715023]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.13719610119365802\n",
      "Predicci√≥n : [[0.17547375]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[[0.        ]\n",
      "  [0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.22419593]\n",
      "  [0.19715023]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014651789097115397\n",
      "Predicci√≥n post entrenamiento : [[0.17111203]]\n",
      "PERDIDAAAA despues: 0.0011502908309921622\n",
      "loss en el callback: 0.0009594939765520394, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "ejemplar: [[0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.22419593]\n",
      " [0.19715023]\n",
      " [0.17547375]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.13733736574375907\n",
      "Predicci√≥n : [[0.18122126]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[[0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.22419593]\n",
      "  [0.19715023]\n",
      "  [0.17547375]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001925795804709196\n",
      "Predicci√≥n post entrenamiento : [[0.17664279]]\n",
      "PERDIDAAAA despues: 0.0015449159545823932\n",
      "loss en el callback: 0.0018902610754594207, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "ejemplar: [[0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.22419593]\n",
      " [0.19715023]\n",
      " [0.17547375]\n",
      " [0.18122126]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.13388569841244483\n",
      "Predicci√≥n : [[0.18637368]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[[0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.22419593]\n",
      "  [0.19715023]\n",
      "  [0.17547375]\n",
      "  [0.18122126]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002754988381639123\n",
      "Predicci√≥n post entrenamiento : [[0.18081048]]\n",
      "PERDIDAAAA despues: 0.0022019355092197657\n",
      "loss en el callback: 0.0035627821926027536, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "ejemplar: [[0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.22419593]\n",
      " [0.19715023]\n",
      " [0.17547375]\n",
      " [0.18122126]\n",
      " [0.18637368]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.12684109919971556\n",
      "Predicci√≥n : [[0.19351494]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[[0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.22419593]\n",
      "  [0.19715023]\n",
      "  [0.17547375]\n",
      "  [0.18122126]\n",
      "  [0.18637368]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004445401486009359\n",
      "Predicci√≥n post entrenamiento : [[0.18427902]]\n",
      "PERDIDAAAA despues: 0.0032991154585033655\n",
      "loss en el callback: 0.011047609150409698, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "ejemplar: [[0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.22419593]\n",
      " [0.19715023]\n",
      " [0.17547375]\n",
      " [0.18122126]\n",
      " [0.18637368]\n",
      " [0.19351494]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14756061137847282\n",
      "Predicci√≥n : [[0.20374188]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[[0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.22419593]\n",
      "  [0.19715023]\n",
      "  [0.17547375]\n",
      "  [0.18122126]\n",
      "  [0.18637368]\n",
      "  [0.19351494]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003156334860250354\n",
      "Predicci√≥n post entrenamiento : [[0.19841598]]\n",
      "PERDIDAAAA despues: 0.002586268587037921\n",
      "loss en el callback: 0.005627877544611692, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "ejemplar: [[0.0202993 ]\n",
      " [0.22419593]\n",
      " [0.19715023]\n",
      " [0.17547375]\n",
      " [0.18122126]\n",
      " [0.18637368]\n",
      " [0.19351494]\n",
      " [0.20374188]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19604423494871648\n",
      "Predicci√≥n : [[0.2246707]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[[0.0202993 ]\n",
      "  [0.22419593]\n",
      "  [0.19715023]\n",
      "  [0.17547375]\n",
      "  [0.18122126]\n",
      "  [0.18637368]\n",
      "  [0.19351494]\n",
      "  [0.20374188]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008194740512408316\n",
      "Predicci√≥n post entrenamiento : [[0.22452278]]\n",
      "PERDIDAAAA despues: 0.0008110277121886611\n",
      "loss en el callback: 8.20097830001032e-06, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "ejemplar: [[0.22419593]\n",
      " [0.19715023]\n",
      " [0.17547375]\n",
      " [0.18122126]\n",
      " [0.18637368]\n",
      " [0.19351494]\n",
      " [0.20374188]\n",
      " [0.22467069]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.21688968214535215\n",
      "Predicci√≥n : [[0.25744307]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[[0.22419593]\n",
      "  [0.19715023]\n",
      "  [0.17547375]\n",
      "  [0.18122126]\n",
      "  [0.18637368]\n",
      "  [0.19351494]\n",
      "  [0.20374188]\n",
      "  [0.22467069]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016445774817839265\n",
      "Predicci√≥n post entrenamiento : [[0.2560565]]\n",
      "PERDIDAAAA despues: 0.0015340388054028153\n",
      "loss en el callback: 0.0007621165132150054, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "ejemplar: [[0.19715023]\n",
      " [0.17547375]\n",
      " [0.18122126]\n",
      " [0.18637368]\n",
      " [0.19351494]\n",
      " [0.20374188]\n",
      " [0.22467069]\n",
      " [0.25744307]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2100969529683796\n",
      "Predicci√≥n : [[0.24993774]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[[0.19715023]\n",
      "  [0.17547375]\n",
      "  [0.18122126]\n",
      "  [0.18637368]\n",
      "  [0.19351494]\n",
      "  [0.20374188]\n",
      "  [0.22467069]\n",
      "  [0.25744307]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015872883377596736\n",
      "Predicci√≥n post entrenamiento : [[0.2476767]]\n",
      "PERDIDAAAA despues: 0.0014122372958809137\n",
      "loss en el callback: 0.0024363750126212835, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "ejemplar: [[0.17547375]\n",
      " [0.18122126]\n",
      " [0.18637368]\n",
      " [0.19351494]\n",
      " [0.20374188]\n",
      " [0.22467069]\n",
      " [0.25744307]\n",
      " [0.24993774]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2026778474621132\n",
      "Predicci√≥n : [[0.24752721]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[[0.17547375]\n",
      "  [0.18122126]\n",
      "  [0.18637368]\n",
      "  [0.19351494]\n",
      "  [0.20374188]\n",
      "  [0.22467069]\n",
      "  [0.25744307]\n",
      "  [0.24993774]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0020114656072109938\n",
      "Predicci√≥n post entrenamiento : [[0.24491566]]\n",
      "PERDIDAAAA despues: 0.001784033258445561\n",
      "loss en el callback: 0.003531418740749359, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "ejemplar: [[0.18122126]\n",
      " [0.18637368]\n",
      " [0.19351494]\n",
      " [0.20374188]\n",
      " [0.22467069]\n",
      " [0.25744307]\n",
      " [0.24993774]\n",
      " [0.24752721]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19463236562655295\n",
      "Predicci√≥n : [[0.25082088]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[[0.18122126]\n",
      "  [0.18637368]\n",
      "  [0.19351494]\n",
      "  [0.20374188]\n",
      "  [0.22467069]\n",
      "  [0.25744307]\n",
      "  [0.24993774]\n",
      "  [0.24752721]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003157148603349924\n",
      "Predicci√≥n post entrenamiento : [[0.24797936]]\n",
      "PERDIDAAAA despues: 0.0028459015302360058\n",
      "loss en el callback: 0.004972032271325588, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "ejemplar: [[0.18637368]\n",
      " [0.19351494]\n",
      " [0.20374188]\n",
      " [0.22467069]\n",
      " [0.25744307]\n",
      " [0.24993774]\n",
      " [0.24752721]\n",
      " [0.25082088]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19407351685692253\n",
      "Predicci√≥n : [[0.25486043]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[[0.18637368]\n",
      "  [0.19351494]\n",
      "  [0.20374188]\n",
      "  [0.22467069]\n",
      "  [0.25744307]\n",
      "  [0.24993774]\n",
      "  [0.24752721]\n",
      "  [0.25082088]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003695049323141575\n",
      "Predicci√≥n post entrenamiento : [[0.25212383]]\n",
      "PERDIDAAAA despues: 0.0033698396291583776\n",
      "loss en el callback: 0.005078903865069151, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "ejemplar: [[0.19351494]\n",
      " [0.20374188]\n",
      " [0.22467069]\n",
      " [0.25744307]\n",
      " [0.24993774]\n",
      " [0.24752721]\n",
      " [0.25082088]\n",
      " [0.25486043]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.20100130115322212\n",
      "Predicci√≥n : [[0.26015136]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[[0.19351494]\n",
      "  [0.20374188]\n",
      "  [0.22467069]\n",
      "  [0.25744307]\n",
      "  [0.24993774]\n",
      "  [0.24752721]\n",
      "  [0.25082088]\n",
      "  [0.25486043]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003498729085549712\n",
      "Predicci√≥n post entrenamiento : [[0.2567315]]\n",
      "PERDIDAAAA despues: 0.0031058562453836203\n",
      "loss en el callback: 0.007977889850735664, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "ejemplar: [[0.20374188]\n",
      " [0.22467069]\n",
      " [0.25744307]\n",
      " [0.24993774]\n",
      " [0.24752721]\n",
      " [0.25082088]\n",
      " [0.25486043]\n",
      " [0.26015136]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19663820581116015\n",
      "Predicci√≥n : [[0.26544476]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[[0.20374188]\n",
      "  [0.22467069]\n",
      "  [0.25744307]\n",
      "  [0.24993774]\n",
      "  [0.24752721]\n",
      "  [0.25082088]\n",
      "  [0.25486043]\n",
      "  [0.26015136]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004734340589493513\n",
      "Predicci√≥n post entrenamiento : [[0.26188427]]\n",
      "PERDIDAAAA despues: 0.0042570484802126884\n",
      "loss en el callback: 0.010389252565801144, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "ejemplar: [[0.22467069]\n",
      " [0.25744307]\n",
      " [0.24993774]\n",
      " [0.24752721]\n",
      " [0.25082088]\n",
      " [0.25486043]\n",
      " [0.26015136]\n",
      " [0.26544476]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1809842308307365\n",
      "Predicci√≥n : [[0.27045104]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[[0.22467069]\n",
      "  [0.25744307]\n",
      "  [0.24993774]\n",
      "  [0.24752721]\n",
      "  [0.25082088]\n",
      "  [0.25486043]\n",
      "  [0.26015136]\n",
      "  [0.26544476]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008004310540854931\n",
      "Predicci√≥n post entrenamiento : [[0.26540062]]\n",
      "PERDIDAAAA despues: 0.007126126904040575\n",
      "loss en el callback: 0.02075098641216755, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "ejemplar: [[0.25744307]\n",
      " [0.24993774]\n",
      " [0.24752721]\n",
      " [0.25082088]\n",
      " [0.25486043]\n",
      " [0.26015136]\n",
      " [0.26544476]\n",
      " [0.27045104]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1653904097109329\n",
      "Predicci√≥n : [[0.2711087]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[[0.25744307]\n",
      "  [0.24993774]\n",
      "  [0.24752721]\n",
      "  [0.25082088]\n",
      "  [0.25486043]\n",
      "  [0.26015136]\n",
      "  [0.26544476]\n",
      "  [0.27045104]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011176352389156818\n",
      "Predicci√≥n post entrenamiento : [[0.26758432]]\n",
      "PERDIDAAAA despues: 0.010443594306707382\n",
      "loss en el callback: 0.01469592284411192, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "ejemplar: [[0.24993774]\n",
      " [0.24752721]\n",
      " [0.25082088]\n",
      " [0.25486043]\n",
      " [0.26015136]\n",
      " [0.26544476]\n",
      " [0.27045104]\n",
      " [0.27110869]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14985674245174896\n",
      "Predicci√≥n : [[0.26711482]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[[0.24993774]\n",
      "  [0.24752721]\n",
      "  [0.25082088]\n",
      "  [0.25486043]\n",
      "  [0.26015136]\n",
      "  [0.26544476]\n",
      "  [0.27045104]\n",
      "  [0.27110869]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013749455101788044\n",
      "Predicci√≥n post entrenamiento : [[0.2634285]]\n",
      "PERDIDAAAA despues: 0.01289854571223259\n",
      "loss en el callback: 0.017300035804510117, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "ejemplar: [[0.24752721]\n",
      " [0.25082088]\n",
      " [0.25486043]\n",
      " [0.26015136]\n",
      " [0.26544476]\n",
      " [0.27045104]\n",
      " [0.27110869]\n",
      " [0.26711482]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.15043111479831345\n",
      "Predicci√≥n : [[0.2649615]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[[0.24752721]\n",
      "  [0.25082088]\n",
      "  [0.25486043]\n",
      "  [0.26015136]\n",
      "  [0.26544476]\n",
      "  [0.27045104]\n",
      "  [0.27110869]\n",
      "  [0.26711482]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013117212802171707\n",
      "Predicci√≥n post entrenamiento : [[0.2624633]]\n",
      "PERDIDAAAA despues: 0.01255121175199747\n",
      "loss en el callback: 0.01051362045109272, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "ejemplar: [[0.25082088]\n",
      " [0.25486043]\n",
      " [0.26015136]\n",
      " [0.26544476]\n",
      " [0.27045104]\n",
      " [0.27110869]\n",
      " [0.26711482]\n",
      " [0.26496151]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.16711352675062616\n",
      "Predicci√≥n : [[0.2651408]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[[0.25082088]\n",
      "  [0.25486043]\n",
      "  [0.26015136]\n",
      "  [0.26544476]\n",
      "  [0.27045104]\n",
      "  [0.27110869]\n",
      "  [0.26711482]\n",
      "  [0.26496151]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009609346278011799\n",
      "Predicci√≥n post entrenamiento : [[0.2617501]]\n",
      "PERDIDAAAA despues: 0.008956081233918667\n",
      "loss en el callback: 0.017586417496204376, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "ejemplar: [[0.25486043]\n",
      " [0.26015136]\n",
      " [0.26544476]\n",
      " [0.27045104]\n",
      " [0.27110869]\n",
      " [0.26711482]\n",
      " [0.26496151]\n",
      " [0.2651408 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2022703535675908\n",
      "Predicci√≥n : [[0.26436043]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[[0.25486043]\n",
      "  [0.26015136]\n",
      "  [0.26544476]\n",
      "  [0.27045104]\n",
      "  [0.27110869]\n",
      "  [0.26711482]\n",
      "  [0.26496151]\n",
      "  [0.2651408 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0038551767356693745\n",
      "Predicci√≥n post entrenamiento : [[0.2639161]]\n",
      "PERDIDAAAA despues: 0.003800197970122099\n",
      "loss en el callback: 0.000499015673995018, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "ejemplar: [[0.26015136]\n",
      " [0.26544476]\n",
      " [0.27045104]\n",
      " [0.27110869]\n",
      " [0.26711482]\n",
      " [0.26496151]\n",
      " [0.2651408 ]\n",
      " [0.26436043]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.25590159524920725\n",
      "Predicci√≥n : [[0.26615775]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[[0.26015136]\n",
      "  [0.26544476]\n",
      "  [0.27045104]\n",
      "  [0.27110869]\n",
      "  [0.26711482]\n",
      "  [0.26496151]\n",
      "  [0.2651408 ]\n",
      "  [0.26436043]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00010518843919271603\n",
      "Predicci√≥n post entrenamiento : [[0.26573452]]\n",
      "PERDIDAAAA despues: 9.668628626968712e-05\n",
      "loss en el callback: 0.00034584643435664475, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "ejemplar: [[0.26544476]\n",
      " [0.27045104]\n",
      " [0.27110869]\n",
      " [0.26711482]\n",
      " [0.26496151]\n",
      " [0.2651408 ]\n",
      " [0.26436043]\n",
      " [0.26615775]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.292688203599549\n",
      "Predicci√≥n : [[0.2671555]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[[0.26544476]\n",
      "  [0.27045104]\n",
      "  [0.27110869]\n",
      "  [0.26711482]\n",
      "  [0.26496151]\n",
      "  [0.2651408 ]\n",
      "  [0.26436043]\n",
      "  [0.26615775]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000651918409857899\n",
      "Predicci√≥n post entrenamiento : [[0.26798183]]\n",
      "PERDIDAAAA despues: 0.0006104044150561094\n",
      "loss en el callback: 0.0017320545157417655, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "ejemplar: [[0.27045104]\n",
      " [0.27110869]\n",
      " [0.26711482]\n",
      " [0.26496151]\n",
      " [0.2651408 ]\n",
      " [0.26436043]\n",
      " [0.26615775]\n",
      " [0.2671555 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31263017861861575\n",
      "Predicci√≥n : [[0.26838353]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[[0.27045104]\n",
      "  [0.27110869]\n",
      "  [0.26711482]\n",
      "  [0.26496151]\n",
      "  [0.2651408 ]\n",
      "  [0.26436043]\n",
      "  [0.26615775]\n",
      "  [0.2671555 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0019577655475586653\n",
      "Predicci√≥n post entrenamiento : [[0.2696518]]\n",
      "PERDIDAAAA despues: 0.001847140840254724\n",
      "loss en el callback: 0.004641443490982056, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "ejemplar: [[0.27110869]\n",
      " [0.26711482]\n",
      " [0.26496151]\n",
      " [0.2651408 ]\n",
      " [0.26436043]\n",
      " [0.26615775]\n",
      " [0.2671555 ]\n",
      " [0.26838353]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3109388849116374\n",
      "Predicci√≥n : [[0.2689244]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[[0.27110869]\n",
      "  [0.26711482]\n",
      "  [0.26496151]\n",
      "  [0.2651408 ]\n",
      "  [0.26436043]\n",
      "  [0.26615775]\n",
      "  [0.2671555 ]\n",
      "  [0.26838353]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017652190290391445\n",
      "Predicci√≥n post entrenamiento : [[0.2699416]]\n",
      "PERDIDAAAA despues: 0.0016807783395051956\n",
      "loss en el callback: 0.003078014124184847, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "ejemplar: [[0.26711482]\n",
      " [0.26496151]\n",
      " [0.2651408 ]\n",
      " [0.26436043]\n",
      " [0.26615775]\n",
      " [0.2671555 ]\n",
      " [0.26838353]\n",
      " [0.26892439]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2876143224786136\n",
      "Predicci√≥n : [[0.26893643]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[[0.26711482]\n",
      "  [0.26496151]\n",
      "  [0.2651408 ]\n",
      "  [0.26436043]\n",
      "  [0.26615775]\n",
      "  [0.2671555 ]\n",
      "  [0.26838353]\n",
      "  [0.26892439]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003488635993562639\n",
      "Predicci√≥n post entrenamiento : [[0.26904142]]\n",
      "PERDIDAAAA despues: 0.0003449524811003357\n",
      "loss en el callback: 3.1193721952149644e-05, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "ejemplar: [[0.26496151]\n",
      " [0.2651408 ]\n",
      " [0.26436043]\n",
      " [0.26615775]\n",
      " [0.2671555 ]\n",
      " [0.26838353]\n",
      " [0.26892439]\n",
      " [0.26893643]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.280161647237227\n",
      "Predicci√≥n : [[0.26883072]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[[0.26496151]\n",
      "  [0.2651408 ]\n",
      "  [0.26436043]\n",
      "  [0.26615775]\n",
      "  [0.2671555 ]\n",
      "  [0.26838353]\n",
      "  [0.26892439]\n",
      "  [0.26893643]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00012839003466069698\n",
      "Predicci√≥n post entrenamiento : [[0.26920676]]\n",
      "PERDIDAAAA despues: 0.00012000954302493483\n",
      "loss en el callback: 0.0004718758864328265, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "ejemplar: [[0.2651408 ]\n",
      " [0.26436043]\n",
      " [0.26615775]\n",
      " [0.2671555 ]\n",
      " [0.26838353]\n",
      " [0.26892439]\n",
      " [0.26893643]\n",
      " [0.26883072]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2885808591874776\n",
      "Predicci√≥n : [[0.26952702]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[[0.2651408 ]\n",
      "  [0.26436043]\n",
      "  [0.26615775]\n",
      "  [0.2671555 ]\n",
      "  [0.26838353]\n",
      "  [0.26892439]\n",
      "  [0.26893643]\n",
      "  [0.26883072]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00036304906825535\n",
      "Predicci√≥n post entrenamiento : [[0.26901156]]\n",
      "PERDIDAAAA despues: 0.0003829578054137528\n",
      "loss en el callback: 0.0007061862270347774, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "ejemplar: [[0.26436043]\n",
      " [0.26615775]\n",
      " [0.2671555 ]\n",
      " [0.26838353]\n",
      " [0.26892439]\n",
      " [0.26893643]\n",
      " [0.26883072]\n",
      " [0.26952702]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2824628234730068\n",
      "Predicci√≥n : [[0.26942024]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[[0.26436043]\n",
      "  [0.26615775]\n",
      "  [0.2671555 ]\n",
      "  [0.26838353]\n",
      "  [0.26892439]\n",
      "  [0.26893643]\n",
      "  [0.26883072]\n",
      "  [0.26952702]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00017010938609018922\n",
      "Predicci√≥n post entrenamiento : [[0.26961085]]\n",
      "PERDIDAAAA despues: 0.00016517347830813378\n",
      "loss en el callback: 0.00013190203753765672, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "ejemplar: [[0.26615775]\n",
      " [0.2671555 ]\n",
      " [0.26838353]\n",
      " [0.26892439]\n",
      " [0.26893643]\n",
      " [0.26883072]\n",
      " [0.26952702]\n",
      " [0.26942024]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.26180754009381474\n",
      "Predicci√≥n : [[0.27033302]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[[0.26615775]\n",
      "  [0.2671555 ]\n",
      "  [0.26838353]\n",
      "  [0.26892439]\n",
      "  [0.26893643]\n",
      "  [0.26883072]\n",
      "  [0.26952702]\n",
      "  [0.26942024]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.268399349413812e-05\n",
      "Predicci√≥n post entrenamiento : [[0.27035943]]\n",
      "PERDIDAAAA despues: 7.313492096727714e-05\n",
      "loss en el callback: 2.60443289334944e-06, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "ejemplar: [[0.2671555 ]\n",
      " [0.26838353]\n",
      " [0.26892439]\n",
      " [0.26893643]\n",
      " [0.26883072]\n",
      " [0.26952702]\n",
      " [0.26942024]\n",
      " [0.27033302]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2801212859371977\n",
      "Predicci√≥n : [[0.27084115]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[[0.2671555 ]\n",
      "  [0.26838353]\n",
      "  [0.26892439]\n",
      "  [0.26893643]\n",
      "  [0.26883072]\n",
      "  [0.26952702]\n",
      "  [0.26942024]\n",
      "  [0.27033302]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.61210937728174e-05\n",
      "Predicci√≥n post entrenamiento : [[0.27124003]]\n",
      "PERDIDAAAA despues: 7.887697574915364e-05\n",
      "loss en el callback: 0.0007230645860545337, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "ejemplar: [[0.26838353]\n",
      " [0.26892439]\n",
      " [0.26893643]\n",
      " [0.26883072]\n",
      " [0.26952702]\n",
      " [0.26942024]\n",
      " [0.27033302]\n",
      " [0.27084115]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3374040610031557\n",
      "Predicci√≥n : [[0.27161488]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[[0.26838353]\n",
      "  [0.26892439]\n",
      "  [0.26893643]\n",
      "  [0.26883072]\n",
      "  [0.26952702]\n",
      "  [0.26942024]\n",
      "  [0.27033302]\n",
      "  [0.27084115]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004328217823058367\n",
      "Predicci√≥n post entrenamiento : [[0.27289248]]\n",
      "PERDIDAAAA despues: 0.0041617462411522865\n",
      "loss en el callback: 0.007573504000902176, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "ejemplar: [[0.26892439]\n",
      " [0.26893643]\n",
      " [0.26883072]\n",
      " [0.26952702]\n",
      " [0.26942024]\n",
      " [0.27033302]\n",
      " [0.27084115]\n",
      " [0.27161488]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3482298154676272\n",
      "Predicci√≥n : [[0.27308887]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[[0.26892439]\n",
      "  [0.26893643]\n",
      "  [0.26883072]\n",
      "  [0.26952702]\n",
      "  [0.26942024]\n",
      "  [0.27033302]\n",
      "  [0.27084115]\n",
      "  [0.27161488]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005646162666380405\n",
      "Predicci√≥n post entrenamiento : [[0.27449098]]\n",
      "PERDIDAAAA despues: 0.005437416955828667\n",
      "loss en el callback: 0.010513147339224815, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "ejemplar: [[0.26893643]\n",
      " [0.26883072]\n",
      " [0.26952702]\n",
      " [0.26942024]\n",
      " [0.27033302]\n",
      " [0.27084115]\n",
      " [0.27161488]\n",
      " [0.27308887]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31259854933061226\n",
      "Predicci√≥n : [[0.27464807]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[[0.26893643]\n",
      "  [0.26883072]\n",
      "  [0.26952702]\n",
      "  [0.26942024]\n",
      "  [0.27033302]\n",
      "  [0.27084115]\n",
      "  [0.27161488]\n",
      "  [0.27308887]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014402393717318773\n",
      "Predicci√≥n post entrenamiento : [[0.27559334]]\n",
      "PERDIDAAAA despues: 0.0013693859800696373\n",
      "loss en el callback: 0.004876826424151659, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "ejemplar: [[0.26883072]\n",
      " [0.26952702]\n",
      " [0.26942024]\n",
      " [0.27033302]\n",
      " [0.27084115]\n",
      " [0.27161488]\n",
      " [0.27308887]\n",
      " [0.27464807]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.34358710169603873\n",
      "Predicci√≥n : [[0.27584603]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[[0.26883072]\n",
      "  [0.26952702]\n",
      "  [0.26942024]\n",
      "  [0.27033302]\n",
      "  [0.27084115]\n",
      "  [0.27161488]\n",
      "  [0.27308887]\n",
      "  [0.27464807]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004588852170854807\n",
      "Predicci√≥n post entrenamiento : [[0.27741453]]\n",
      "PERDIDAAAA despues: 0.004378809127956629\n",
      "loss en el callback: 0.020507950335741043, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "ejemplar: [[0.26952702]\n",
      " [0.26942024]\n",
      " [0.27033302]\n",
      " [0.27084115]\n",
      " [0.27161488]\n",
      " [0.27308887]\n",
      " [0.27464807]\n",
      " [0.27584603]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.4411954725639069\n",
      "Predicci√≥n : [[0.27782726]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[[0.26952702]\n",
      "  [0.26942024]\n",
      "  [0.27033302]\n",
      "  [0.27084115]\n",
      "  [0.27161488]\n",
      "  [0.27308887]\n",
      "  [0.27464807]\n",
      "  [0.27584603]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02668916806578636\n",
      "Predicci√≥n post entrenamiento : [[0.28013712]]\n",
      "PERDIDAAAA despues: 0.025939788669347763\n",
      "loss en el callback: 0.029396651312708855, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "ejemplar: [[0.26942024]\n",
      " [0.27033302]\n",
      " [0.27084115]\n",
      " [0.27161488]\n",
      " [0.27308887]\n",
      " [0.27464807]\n",
      " [0.27584603]\n",
      " [0.27782726]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5210953230441133\n",
      "Predicci√≥n : [[0.28057483]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[[0.26942024]\n",
      "  [0.27033302]\n",
      "  [0.27084115]\n",
      "  [0.27161488]\n",
      "  [0.27308887]\n",
      "  [0.27464807]\n",
      "  [0.27584603]\n",
      "  [0.27782726]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05785011500120163\n",
      "Predicci√≥n post entrenamiento : [[0.28369614]]\n",
      "PERDIDAAAA despues: 0.056358374655246735\n",
      "loss en el callback: 0.04670777916908264, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "ejemplar: [[0.27033302]\n",
      " [0.27084115]\n",
      " [0.27161488]\n",
      " [0.27308887]\n",
      " [0.27464807]\n",
      " [0.27584603]\n",
      " [0.27782726]\n",
      " [0.28057483]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5832866531366584\n",
      "Predicci√≥n : [[0.2843768]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[[0.27033302]\n",
      "  [0.27084115]\n",
      "  [0.27161488]\n",
      "  [0.27308887]\n",
      "  [0.27464807]\n",
      "  [0.27584603]\n",
      "  [0.27782726]\n",
      "  [0.28057483]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08934709429740906\n",
      "Predicci√≥n post entrenamiento : [[0.28812104]]\n",
      "PERDIDAAAA despues: 0.08712273091077805\n",
      "loss en el callback: 0.09373856335878372, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "ejemplar: [[0.27084115]\n",
      " [0.27161488]\n",
      " [0.27308887]\n",
      " [0.27464807]\n",
      " [0.27584603]\n",
      " [0.27782726]\n",
      " [0.28057483]\n",
      " [0.2843768 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6089234523540271\n",
      "Predicci√≥n : [[0.28888702]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[[0.27084115]\n",
      "  [0.27161488]\n",
      "  [0.27308887]\n",
      "  [0.27464807]\n",
      "  [0.27584603]\n",
      "  [0.27782726]\n",
      "  [0.28057483]\n",
      "  [0.2843768 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1024233028292656\n",
      "Predicci√≥n post entrenamiento : [[0.29304227]]\n",
      "PERDIDAAAA despues: 0.09978090971708298\n",
      "loss en el callback: 0.10430195927619934, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "ejemplar: [[0.27161488]\n",
      " [0.27308887]\n",
      " [0.27464807]\n",
      " [0.27584603]\n",
      " [0.27782726]\n",
      " [0.28057483]\n",
      " [0.2843768 ]\n",
      " [0.28888702]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.59800572069622\n",
      "Predicci√≥n : [[0.29405084]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[[0.27161488]\n",
      "  [0.27308887]\n",
      "  [0.27464807]\n",
      "  [0.27584603]\n",
      "  [0.27782726]\n",
      "  [0.28057483]\n",
      "  [0.2843768 ]\n",
      "  [0.28888702]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0923885628581047\n",
      "Predicci√≥n post entrenamiento : [[0.29775354]]\n",
      "PERDIDAAAA despues: 0.0901513621211052\n",
      "loss en el callback: 0.09609635919332504, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "ejemplar: [[0.27308887]\n",
      " [0.27464807]\n",
      " [0.27584603]\n",
      " [0.27782726]\n",
      " [0.28057483]\n",
      " [0.2843768 ]\n",
      " [0.28888702]\n",
      " [0.29405084]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5945301858653699\n",
      "Predicci√≥n : [[0.2990449]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[[0.27308887]\n",
      "  [0.27464807]\n",
      "  [0.27584603]\n",
      "  [0.27782726]\n",
      "  [0.28057483]\n",
      "  [0.2843768 ]\n",
      "  [0.28888702]\n",
      "  [0.29405084]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08731153607368469\n",
      "Predicci√≥n post entrenamiento : [[0.30267918]]\n",
      "PERDIDAAAA despues: 0.0851769968867302\n",
      "loss en el callback: 0.09495750069618225, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "ejemplar: [[0.27464807]\n",
      " [0.27584603]\n",
      " [0.27782726]\n",
      " [0.28057483]\n",
      " [0.2843768 ]\n",
      " [0.28888702]\n",
      " [0.29405084]\n",
      " [0.29904491]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5984968478614763\n",
      "Predicci√≥n : [[0.30420494]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[[0.27464807]\n",
      "  [0.27584603]\n",
      "  [0.27782726]\n",
      "  [0.28057483]\n",
      "  [0.2843768 ]\n",
      "  [0.28888702]\n",
      "  [0.29405084]\n",
      "  [0.29904491]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08660773187875748\n",
      "Predicci√≥n post entrenamiento : [[0.30769795]]\n",
      "PERDIDAAAA despues: 0.08456400036811829\n",
      "loss en el callback: 0.0919908881187439, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "ejemplar: [[0.27584603]\n",
      " [0.27782726]\n",
      " [0.28057483]\n",
      " [0.2843768 ]\n",
      " [0.28888702]\n",
      " [0.29405084]\n",
      " [0.29904491]\n",
      " [0.30420494]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6213543446734934\n",
      "Predicci√≥n : [[0.3095473]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[[0.27584603]\n",
      "  [0.27782726]\n",
      "  [0.28057483]\n",
      "  [0.2843768 ]\n",
      "  [0.28888702]\n",
      "  [0.29405084]\n",
      "  [0.29904491]\n",
      "  [0.30420494]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09722362458705902\n",
      "Predicci√≥n post entrenamiento : [[0.3129919]]\n",
      "PERDIDAAAA despues: 0.09508740156888962\n",
      "loss en el callback: 0.10487803816795349, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "ejemplar: [[0.27782726]\n",
      " [0.28057483]\n",
      " [0.2843768 ]\n",
      " [0.28888702]\n",
      " [0.29405084]\n",
      " [0.29904491]\n",
      " [0.30420494]\n",
      " [0.30954731]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.663102676301421\n",
      "Predicci√≥n : [[0.31536996]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[[0.27782726]\n",
      "  [0.28057483]\n",
      "  [0.2843768 ]\n",
      "  [0.28888702]\n",
      "  [0.29405084]\n",
      "  [0.29904491]\n",
      "  [0.30420494]\n",
      "  [0.30954731]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12091804295778275\n",
      "Predicci√≥n post entrenamiento : [[0.31922334]]\n",
      "PERDIDAAAA despues: 0.11825300008058548\n",
      "loss en el callback: 0.11028540134429932, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "ejemplar: [[0.28057483]\n",
      " [0.2843768 ]\n",
      " [0.28888702]\n",
      " [0.29405084]\n",
      " [0.29904491]\n",
      " [0.30420494]\n",
      " [0.30954731]\n",
      " [0.31536996]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6928724338328028\n",
      "Predicci√≥n : [[0.32209146]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[[0.28057483]\n",
      "  [0.2843768 ]\n",
      "  [0.28888702]\n",
      "  [0.29405084]\n",
      "  [0.29904491]\n",
      "  [0.30420494]\n",
      "  [0.30954731]\n",
      "  [0.31536996]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1374785155057907\n",
      "Predicci√≥n post entrenamiento : [[0.32624406]]\n",
      "PERDIDAAAA despues: 0.1344163417816162\n",
      "loss en el callback: 0.1499348282814026, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "ejemplar: [[0.2843768 ]\n",
      " [0.28888702]\n",
      " [0.29405084]\n",
      " [0.29904491]\n",
      " [0.30420494]\n",
      " [0.30954731]\n",
      " [0.31536996]\n",
      " [0.32209146]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.710663617267639\n",
      "Predicci√≥n : [[0.3295518]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[[0.2843768 ]\n",
      "  [0.28888702]\n",
      "  [0.29405084]\n",
      "  [0.29904491]\n",
      "  [0.30420494]\n",
      "  [0.30954731]\n",
      "  [0.31536996]\n",
      "  [0.32209146]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.145246222615242\n",
      "Predicci√≥n post entrenamiento : [[0.33357894]]\n",
      "PERDIDAAAA despues: 0.14219285547733307\n",
      "loss en el callback: 0.1839904636144638, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "ejemplar: [[0.28888702]\n",
      " [0.29405084]\n",
      " [0.29904491]\n",
      " [0.30420494]\n",
      " [0.30954731]\n",
      " [0.31536996]\n",
      " [0.32209146]\n",
      " [0.32955179]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7216820581308059\n",
      "Predicci√≥n : [[0.33719513]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[[0.28888702]\n",
      "  [0.29405084]\n",
      "  [0.29904491]\n",
      "  [0.30420494]\n",
      "  [0.30954731]\n",
      "  [0.31536996]\n",
      "  [0.32209146]\n",
      "  [0.32955179]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14783020317554474\n",
      "Predicci√≥n post entrenamiento : [[0.3412771]]\n",
      "PERDIDAAAA despues: 0.14470794796943665\n",
      "loss en el callback: 0.14356757700443268, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "ejemplar: [[0.29405084]\n",
      " [0.29904491]\n",
      " [0.30420494]\n",
      " [0.30954731]\n",
      " [0.31536996]\n",
      " [0.32209146]\n",
      " [0.32955179]\n",
      " [0.33719513]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7259277564223031\n",
      "Predicci√≥n : [[0.3451309]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[[0.29405084]\n",
      "  [0.29904491]\n",
      "  [0.30420494]\n",
      "  [0.30954731]\n",
      "  [0.31536996]\n",
      "  [0.32209146]\n",
      "  [0.32955179]\n",
      "  [0.33719513]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14500626921653748\n",
      "Predicci√≥n post entrenamiento : [[0.34898737]]\n",
      "PERDIDAAAA despues: 0.1420840620994568\n",
      "loss en el callback: 0.1302957683801651, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "ejemplar: [[0.29904491]\n",
      " [0.30420494]\n",
      " [0.30954731]\n",
      " [0.31536996]\n",
      " [0.32209146]\n",
      " [0.32955179]\n",
      " [0.33719513]\n",
      " [0.34513089]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7404318224413275\n",
      "Predicci√≥n : [[0.35301244]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[[0.29904491]\n",
      "  [0.30420494]\n",
      "  [0.30954731]\n",
      "  [0.31536996]\n",
      "  [0.32209146]\n",
      "  [0.32955179]\n",
      "  [0.33719513]\n",
      "  [0.34513089]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.15009379386901855\n",
      "Predicci√≥n post entrenamiento : [[0.35707375]]\n",
      "PERDIDAAAA despues: 0.146963432431221\n",
      "loss en el callback: 0.13584470748901367, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "ejemplar: [[0.30420494]\n",
      " [0.30954731]\n",
      " [0.31536996]\n",
      " [0.32209146]\n",
      " [0.32955179]\n",
      " [0.33719513]\n",
      " [0.34513089]\n",
      " [0.35301244]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7651942561878792\n",
      "Predicci√≥n : [[0.3613922]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[[0.30420494]\n",
      "  [0.30954731]\n",
      "  [0.31536996]\n",
      "  [0.32209146]\n",
      "  [0.32955179]\n",
      "  [0.33719513]\n",
      "  [0.34513089]\n",
      "  [0.35301244]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.16305609047412872\n",
      "Predicci√≥n post entrenamiento : [[0.3655319]]\n",
      "PERDIDAAAA despues: 0.1597299873828888\n",
      "loss en el callback: 0.15486301481723785, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "ejemplar: [[0.30954731]\n",
      " [0.31536996]\n",
      " [0.32209146]\n",
      " [0.32955179]\n",
      " [0.33719513]\n",
      " [0.34513089]\n",
      " [0.35301244]\n",
      " [0.3613922 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7447890964420396\n",
      "Predicci√≥n : [[0.37020636]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[[0.30954731]\n",
      "  [0.31536996]\n",
      "  [0.32209146]\n",
      "  [0.32955179]\n",
      "  [0.33719513]\n",
      "  [0.34513089]\n",
      "  [0.35301244]\n",
      "  [0.3613922 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14031225442886353\n",
      "Predicci√≥n post entrenamiento : [[0.37373704]]\n",
      "PERDIDAAAA despues: 0.13767965137958527\n",
      "loss en el callback: 0.09873002022504807, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "ejemplar: [[0.31536996]\n",
      " [0.32209146]\n",
      " [0.32955179]\n",
      " [0.33719513]\n",
      " [0.34513089]\n",
      " [0.35301244]\n",
      " [0.3613922 ]\n",
      " [0.37020636]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6792163432038085\n",
      "Predicci√≥n : [[0.37883148]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[[0.31536996]\n",
      "  [0.32209146]\n",
      "  [0.32955179]\n",
      "  [0.33719513]\n",
      "  [0.34513089]\n",
      "  [0.35301244]\n",
      "  [0.3613922 ]\n",
      "  [0.37020636]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09023106098175049\n",
      "Predicci√≥n post entrenamiento : [[0.38170907]]\n",
      "PERDIDAAAA despues: 0.08851056545972824\n",
      "loss en el callback: 0.06630825996398926, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "ejemplar: [[0.32209146]\n",
      " [0.32955179]\n",
      " [0.33719513]\n",
      " [0.34513089]\n",
      " [0.35301244]\n",
      " [0.3613922 ]\n",
      " [0.37020636]\n",
      " [0.37883148]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6746017659154131\n",
      "Predicci√≥n : [[0.38721666]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[[0.32209146]\n",
      "  [0.32955179]\n",
      "  [0.33719513]\n",
      "  [0.34513089]\n",
      "  [0.35301244]\n",
      "  [0.3613922 ]\n",
      "  [0.37020636]\n",
      "  [0.37883148]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08259021490812302\n",
      "Predicci√≥n post entrenamiento : [[0.39008155]]\n",
      "PERDIDAAAA despues: 0.0809517651796341\n",
      "loss en el callback: 0.07775949686765671, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "ejemplar: [[0.32955179]\n",
      " [0.33719513]\n",
      " [0.34513089]\n",
      " [0.35301244]\n",
      " [0.3613922 ]\n",
      " [0.37020636]\n",
      " [0.37883148]\n",
      " [0.38721666]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7309453645768532\n",
      "Predicci√≥n : [[0.39588094]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[[0.32955179]\n",
      "  [0.33719513]\n",
      "  [0.34513089]\n",
      "  [0.35301244]\n",
      "  [0.3613922 ]\n",
      "  [0.37020636]\n",
      "  [0.37883148]\n",
      "  [0.38721666]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11226815730333328\n",
      "Predicci√≥n post entrenamiento : [[0.3990263]]\n",
      "PERDIDAAAA despues: 0.11017025262117386\n",
      "loss en el callback: 0.090215764939785, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "ejemplar: [[0.33719513]\n",
      " [0.34513089]\n",
      " [0.35301244]\n",
      " [0.3613922 ]\n",
      " [0.37020636]\n",
      " [0.37883148]\n",
      " [0.38721666]\n",
      " [0.39588094]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7467210055914982\n",
      "Predicci√≥n : [[0.4050058]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[[0.33719513]\n",
      "  [0.34513089]\n",
      "  [0.35301244]\n",
      "  [0.3613922 ]\n",
      "  [0.37020636]\n",
      "  [0.37883148]\n",
      "  [0.38721666]\n",
      "  [0.39588094]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11676929146051407\n",
      "Predicci√≥n post entrenamiento : [[0.40835738]]\n",
      "PERDIDAAAA despues: 0.11448995769023895\n",
      "loss en el callback: 0.14152668416500092, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "ejemplar: [[0.34513089]\n",
      " [0.35301244]\n",
      " [0.3613922 ]\n",
      " [0.37020636]\n",
      " [0.37883148]\n",
      " [0.38721666]\n",
      " [0.39588094]\n",
      " [0.40500581]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7219286889593481\n",
      "Predicci√≥n : [[0.41451767]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[[0.34513089]\n",
      "  [0.35301244]\n",
      "  [0.3613922 ]\n",
      "  [0.37020636]\n",
      "  [0.37883148]\n",
      "  [0.38721666]\n",
      "  [0.39588094]\n",
      "  [0.40500581]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0945015475153923\n",
      "Predicci√≥n post entrenamiento : [[0.41714334]]\n",
      "PERDIDAAAA despues: 0.09289412200450897\n",
      "loss en el callback: 0.05867557227611542, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "ejemplar: [[0.35301244]\n",
      " [0.3613922 ]\n",
      " [0.37020636]\n",
      " [0.37883148]\n",
      " [0.38721666]\n",
      " [0.39588094]\n",
      " [0.40500581]\n",
      " [0.41451767]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7199286701160912\n",
      "Predicci√≥n : [[0.4234564]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[[0.35301244]\n",
      "  [0.3613922 ]\n",
      "  [0.37020636]\n",
      "  [0.37883148]\n",
      "  [0.38721666]\n",
      "  [0.39588094]\n",
      "  [0.40500581]\n",
      "  [0.41451767]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08789581060409546\n",
      "Predicci√≥n post entrenamiento : [[0.42623064]]\n",
      "PERDIDAAAA despues: 0.08625853806734085\n",
      "loss en el callback: 0.1036791056394577, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "ejemplar: [[0.3613922 ]\n",
      " [0.37020636]\n",
      " [0.37883148]\n",
      " [0.38721666]\n",
      " [0.39588094]\n",
      " [0.40500581]\n",
      " [0.41451767]\n",
      " [0.4234564 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7407209490617273\n",
      "Predicci√≥n : [[0.43274954]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[[0.3613922 ]\n",
      "  [0.37020636]\n",
      "  [0.37883148]\n",
      "  [0.38721666]\n",
      "  [0.39588094]\n",
      "  [0.40500581]\n",
      "  [0.41451767]\n",
      "  [0.4234564 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09484637528657913\n",
      "Predicci√≥n post entrenamiento : [[0.43542156]]\n",
      "PERDIDAAAA despues: 0.0932077094912529\n",
      "loss en el callback: 0.08304198831319809, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "ejemplar: [[0.37020636]\n",
      " [0.37883148]\n",
      " [0.38721666]\n",
      " [0.39588094]\n",
      " [0.40500581]\n",
      " [0.41451767]\n",
      " [0.4234564 ]\n",
      " [0.43274954]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.736245501831604\n",
      "Predicci√≥n : [[0.44206655]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[[0.37020636]\n",
      "  [0.37883148]\n",
      "  [0.38721666]\n",
      "  [0.39588094]\n",
      "  [0.40500581]\n",
      "  [0.41451767]\n",
      "  [0.4234564 ]\n",
      "  [0.43274954]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08654126524925232\n",
      "Predicci√≥n post entrenamiento : [[0.4446614]]\n",
      "PERDIDAAAA despues: 0.08502128720283508\n",
      "loss en el callback: 0.07133360952138901, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "ejemplar: [[0.37883148]\n",
      " [0.38721666]\n",
      " [0.39588094]\n",
      " [0.40500581]\n",
      " [0.41451767]\n",
      " [0.4234564 ]\n",
      " [0.43274954]\n",
      " [0.44206655]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7065023284257214\n",
      "Predicci√≥n : [[0.45135313]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[[0.37883148]\n",
      "  [0.38721666]\n",
      "  [0.39588094]\n",
      "  [0.40500581]\n",
      "  [0.41451767]\n",
      "  [0.4234564 ]\n",
      "  [0.43274954]\n",
      "  [0.44206655]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06510110944509506\n",
      "Predicci√≥n post entrenamiento : [[0.45358145]]\n",
      "PERDIDAAAA despues: 0.0639689639210701\n",
      "loss en el callback: 0.05344296991825104, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "ejemplar: [[0.38721666]\n",
      " [0.39588094]\n",
      " [0.40500581]\n",
      " [0.41451767]\n",
      " [0.4234564 ]\n",
      " [0.43274954]\n",
      " [0.44206655]\n",
      " [0.45135313]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6979451506854685\n",
      "Predicci√≥n : [[0.46038336]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[[0.38721666]\n",
      "  [0.39588094]\n",
      "  [0.40500581]\n",
      "  [0.41451767]\n",
      "  [0.4234564 ]\n",
      "  [0.43274954]\n",
      "  [0.44206655]\n",
      "  [0.45135313]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05643561854958534\n",
      "Predicci√≥n post entrenamiento : [[0.4623901]]\n",
      "PERDIDAAAA despues: 0.055486198514699936\n",
      "loss en el callback: 0.04650988057255745, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "ejemplar: [[0.39588094]\n",
      " [0.40500581]\n",
      " [0.41451767]\n",
      " [0.4234564 ]\n",
      " [0.43274954]\n",
      " [0.44206655]\n",
      " [0.45135313]\n",
      " [0.46038336]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7105739686108449\n",
      "Predicci√≥n : [[0.46938652]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[[0.39588094]\n",
      "  [0.40500581]\n",
      "  [0.41451767]\n",
      "  [0.4234564 ]\n",
      "  [0.43274954]\n",
      "  [0.44206655]\n",
      "  [0.45135313]\n",
      "  [0.46038336]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.058171387761831284\n",
      "Predicci√≥n post entrenamiento : [[0.4715153]]\n",
      "PERDIDAAAA despues: 0.057149048894643784\n",
      "loss en el callback: 0.051702290773391724, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "ejemplar: [[0.40500581]\n",
      " [0.41451767]\n",
      " [0.4234564 ]\n",
      " [0.43274954]\n",
      " [0.44206655]\n",
      " [0.45135313]\n",
      " [0.46038336]\n",
      " [0.46938652]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7209621522504839\n",
      "Predicci√≥n : [[0.4786666]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[[0.40500581]\n",
      "  [0.41451767]\n",
      "  [0.4234564 ]\n",
      "  [0.43274954]\n",
      "  [0.44206655]\n",
      "  [0.45135313]\n",
      "  [0.46038336]\n",
      "  [0.46938652]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.058707140386104584\n",
      "Predicci√≥n post entrenamiento : [[0.48048192]]\n",
      "PERDIDAAAA despues: 0.057830747216939926\n",
      "loss en el callback: 0.037196408957242966, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "ejemplar: [[0.41451767]\n",
      " [0.4234564 ]\n",
      " [0.43274954]\n",
      " [0.44206655]\n",
      " [0.45135313]\n",
      " [0.46038336]\n",
      " [0.46938652]\n",
      " [0.4786666 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7291097016043858\n",
      "Predicci√≥n : [[0.4876891]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[[0.41451767]\n",
      "  [0.4234564 ]\n",
      "  [0.43274954]\n",
      "  [0.44206655]\n",
      "  [0.45135313]\n",
      "  [0.46038336]\n",
      "  [0.46938652]\n",
      "  [0.4786666 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05828390643000603\n",
      "Predicci√≥n post entrenamiento : [[0.49001464]]\n",
      "PERDIDAAAA despues: 0.0571664497256279\n",
      "loss en el callback: 0.102114737033844, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "ejemplar: [[0.4234564 ]\n",
      " [0.43274954]\n",
      " [0.44206655]\n",
      " [0.45135313]\n",
      " [0.46038336]\n",
      " [0.46938652]\n",
      " [0.4786666 ]\n",
      " [0.48768911]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7674259644168786\n",
      "Predicci√≥n : [[0.49718037]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[[0.4234564 ]\n",
      "  [0.43274954]\n",
      "  [0.44206655]\n",
      "  [0.45135313]\n",
      "  [0.46038336]\n",
      "  [0.46938652]\n",
      "  [0.4786666 ]\n",
      "  [0.48768911]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0730326771736145\n",
      "Predicci√≥n post entrenamiento : [[0.49945486]]\n",
      "PERDIDAAAA despues: 0.07180850952863693\n",
      "loss en el callback: 0.06256170570850372, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "ejemplar: [[0.43274954]\n",
      " [0.44206655]\n",
      " [0.45135313]\n",
      " [0.46038336]\n",
      " [0.46938652]\n",
      " [0.4786666 ]\n",
      " [0.48768911]\n",
      " [0.49718037]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8359109406879621\n",
      "Predicci√≥n : [[0.50671273]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[[0.43274954]\n",
      "  [0.44206655]\n",
      "  [0.45135313]\n",
      "  [0.46038336]\n",
      "  [0.46938652]\n",
      "  [0.4786666 ]\n",
      "  [0.48768911]\n",
      "  [0.49718037]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10837144404649734\n",
      "Predicci√≥n post entrenamiento : [[0.5096785]]\n",
      "PERDIDAAAA despues: 0.10642760246992111\n",
      "loss en el callback: 0.1340157836675644, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "ejemplar: [[0.44206655]\n",
      " [0.45135313]\n",
      " [0.46038336]\n",
      " [0.46938652]\n",
      " [0.4786666 ]\n",
      " [0.48768911]\n",
      " [0.49718037]\n",
      " [0.50671273]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8510103358824123\n",
      "Predicci√≥n : [[0.5169502]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[[0.44206655]\n",
      "  [0.45135313]\n",
      "  [0.46038336]\n",
      "  [0.46938652]\n",
      "  [0.4786666 ]\n",
      "  [0.48768911]\n",
      "  [0.49718037]\n",
      "  [0.50671273]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11159617453813553\n",
      "Predicci√≥n post entrenamiento : [[0.5196508]]\n",
      "PERDIDAAAA despues: 0.10979912430047989\n",
      "loss en el callback: 0.08653523027896881, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "ejemplar: [[0.45135313]\n",
      " [0.46038336]\n",
      " [0.46938652]\n",
      " [0.4786666 ]\n",
      " [0.48768911]\n",
      " [0.49718037]\n",
      " [0.50671273]\n",
      " [0.51695019]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8127241500002294\n",
      "Predicci√≥n : [[0.5269343]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[[0.45135313]\n",
      "  [0.46038336]\n",
      "  [0.46938652]\n",
      "  [0.4786666 ]\n",
      "  [0.48768911]\n",
      "  [0.49718037]\n",
      "  [0.50671273]\n",
      "  [0.51695019]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08167583495378494\n",
      "Predicci√≥n post entrenamiento : [[0.5290652]]\n",
      "PERDIDAAAA despues: 0.08046241849660873\n",
      "loss en el callback: 0.049578405916690826, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "ejemplar: [[0.46038336]\n",
      " [0.46938652]\n",
      " [0.4786666 ]\n",
      " [0.48768911]\n",
      " [0.49718037]\n",
      " [0.50671273]\n",
      " [0.51695019]\n",
      " [0.52693433]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7863940290280375\n",
      "Predicci√≥n : [[0.5363785]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[[0.46038336]\n",
      "  [0.46938652]\n",
      "  [0.4786666 ]\n",
      "  [0.48768911]\n",
      "  [0.49718037]\n",
      "  [0.50671273]\n",
      "  [0.51695019]\n",
      "  [0.52693433]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0625077486038208\n",
      "Predicci√≥n post entrenamiento : [[0.53854114]]\n",
      "PERDIDAAAA despues: 0.06143104285001755\n",
      "loss en el callback: 0.06441615521907806, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "ejemplar: [[0.46938652]\n",
      " [0.4786666 ]\n",
      " [0.48768911]\n",
      " [0.49718037]\n",
      " [0.50671273]\n",
      " [0.51695019]\n",
      " [0.52693433]\n",
      " [0.5363785 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7720199729658365\n",
      "Predicci√≥n : [[0.5459684]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[[0.46938652]\n",
      "  [0.4786666 ]\n",
      "  [0.48768911]\n",
      "  [0.49718037]\n",
      "  [0.50671273]\n",
      "  [0.51695019]\n",
      "  [0.52693433]\n",
      "  [0.5363785 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05109931156039238\n",
      "Predicci√≥n post entrenamiento : [[0.5483037]]\n",
      "PERDIDAAAA despues: 0.05004896596074104\n",
      "loss en el callback: 0.10395325720310211, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "ejemplar: [[0.4786666 ]\n",
      " [0.48768911]\n",
      " [0.49718037]\n",
      " [0.50671273]\n",
      " [0.51695019]\n",
      " [0.52693433]\n",
      " [0.5363785 ]\n",
      " [0.54596841]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8033170564228299\n",
      "Predicci√≥n : [[0.5558812]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[[0.4786666 ]\n",
      "  [0.48768911]\n",
      "  [0.49718037]\n",
      "  [0.50671273]\n",
      "  [0.51695019]\n",
      "  [0.52693433]\n",
      "  [0.5363785 ]\n",
      "  [0.54596841]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06122450903058052\n",
      "Predicci√≥n post entrenamiento : [[0.5582562]]\n",
      "PERDIDAAAA despues: 0.060054827481508255\n",
      "loss en el callback: 0.09641929715871811, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "ejemplar: [[0.48768911]\n",
      " [0.49718037]\n",
      " [0.50671273]\n",
      " [0.51695019]\n",
      " [0.52693433]\n",
      " [0.5363785 ]\n",
      " [0.54596841]\n",
      " [0.5558812 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8802852793990171\n",
      "Predicci√≥n : [[0.5659422]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[[0.48768911]\n",
      "  [0.49718037]\n",
      "  [0.50671273]\n",
      "  [0.51695019]\n",
      "  [0.52693433]\n",
      "  [0.5363785 ]\n",
      "  [0.54596841]\n",
      "  [0.5558812 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0988115444779396\n",
      "Predicci√≥n post entrenamiento : [[0.5688022]]\n",
      "PERDIDAAAA despues: 0.09702171385288239\n",
      "loss en el callback: 0.15399491786956787, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "ejemplar: [[0.49718037]\n",
      " [0.50671273]\n",
      " [0.51695019]\n",
      " [0.52693433]\n",
      " [0.5363785 ]\n",
      " [0.54596841]\n",
      " [0.5558812 ]\n",
      " [0.56594223]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8987051676996881\n",
      "Predicci√≥n : [[0.57668835]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[[0.49718037]\n",
      "  [0.50671273]\n",
      "  [0.51695019]\n",
      "  [0.52693433]\n",
      "  [0.5363785 ]\n",
      "  [0.54596841]\n",
      "  [0.5558812 ]\n",
      "  [0.56594223]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1036948412656784\n",
      "Predicci√≥n post entrenamiento : [[0.5790794]]\n",
      "PERDIDAAAA despues: 0.10216064751148224\n",
      "loss en el callback: 0.07848061621189117, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "ejemplar: [[0.50671273]\n",
      " [0.51695019]\n",
      " [0.52693433]\n",
      " [0.5363785 ]\n",
      " [0.54596841]\n",
      " [0.5558812 ]\n",
      " [0.56594223]\n",
      " [0.57668835]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8585767213248423\n",
      "Predicci√≥n : [[0.5870776]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[[0.50671273]\n",
      "  [0.51695019]\n",
      "  [0.52693433]\n",
      "  [0.5363785 ]\n",
      "  [0.54596841]\n",
      "  [0.5558812 ]\n",
      "  [0.56594223]\n",
      "  [0.57668835]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07371176034212112\n",
      "Predicci√≥n post entrenamiento : [[0.5896703]]\n",
      "PERDIDAAAA despues: 0.07231065630912781\n",
      "loss en el callback: 0.1252259463071823, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "ejemplar: [[0.51695019]\n",
      " [0.52693433]\n",
      " [0.5363785 ]\n",
      " [0.54596841]\n",
      " [0.5558812 ]\n",
      " [0.56594223]\n",
      " [0.57668835]\n",
      " [0.58707762]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8308762565987861\n",
      "Predicci√≥n : [[0.5977932]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[[0.51695019]\n",
      "  [0.52693433]\n",
      "  [0.5363785 ]\n",
      "  [0.54596841]\n",
      "  [0.5558812 ]\n",
      "  [0.56594223]\n",
      "  [0.57668835]\n",
      "  [0.58707762]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05432768911123276\n",
      "Predicci√≥n post entrenamiento : [[0.59866184]]\n",
      "PERDIDAAAA despues: 0.05392352491617203\n",
      "loss en el callback: 0.007935072295367718, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "ejemplar: [[0.52693433]\n",
      " [0.5363785 ]\n",
      " [0.54596841]\n",
      " [0.5558812 ]\n",
      " [0.56594223]\n",
      " [0.57668835]\n",
      " [0.58707762]\n",
      " [0.59779322]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8156037735215196\n",
      "Predicci√≥n : [[0.6067448]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[[0.52693433]\n",
      "  [0.5363785 ]\n",
      "  [0.54596841]\n",
      "  [0.5558812 ]\n",
      "  [0.56594223]\n",
      "  [0.57668835]\n",
      "  [0.58707762]\n",
      "  [0.59779322]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04362206906080246\n",
      "Predicci√≥n post entrenamiento : [[0.6078228]]\n",
      "PERDIDAAAA despues: 0.04317295178771019\n",
      "loss en el callback: 0.014707786962389946, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "ejemplar: [[0.5363785 ]\n",
      " [0.54596841]\n",
      " [0.5558812 ]\n",
      " [0.56594223]\n",
      " [0.57668835]\n",
      " [0.58707762]\n",
      " [0.59779322]\n",
      " [0.60674483]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8116992058331503\n",
      "Predicci√≥n : [[0.6159336]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[[0.5363785 ]\n",
      "  [0.54596841]\n",
      "  [0.5558812 ]\n",
      "  [0.56594223]\n",
      "  [0.57668835]\n",
      "  [0.58707762]\n",
      "  [0.59779322]\n",
      "  [0.60674483]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.038324177265167236\n",
      "Predicci√≥n post entrenamiento : [[0.61731434]]\n",
      "PERDIDAAAA despues: 0.03778547793626785\n",
      "loss en el callback: 0.02917379140853882, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "ejemplar: [[0.54596841]\n",
      " [0.5558812 ]\n",
      " [0.56594223]\n",
      " [0.57668835]\n",
      " [0.58707762]\n",
      " [0.59779322]\n",
      " [0.60674483]\n",
      " [0.6159336 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8191625535336788\n",
      "Predicci√≥n : [[0.6256028]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[[0.54596841]\n",
      "  [0.5558812 ]\n",
      "  [0.56594223]\n",
      "  [0.57668835]\n",
      "  [0.58707762]\n",
      "  [0.59779322]\n",
      "  [0.60674483]\n",
      "  [0.6159336 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03746538236737251\n",
      "Predicci√≥n post entrenamiento : [[0.6267444]]\n",
      "PERDIDAAAA despues: 0.03702474758028984\n",
      "loss en el callback: 0.018072688952088356, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "ejemplar: [[0.5558812 ]\n",
      " [0.56594223]\n",
      " [0.57668835]\n",
      " [0.58707762]\n",
      " [0.59779322]\n",
      " [0.60674483]\n",
      " [0.6159336 ]\n",
      " [0.62560278]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8218275636038536\n",
      "Predicci√≥n : [[0.6351859]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[[0.5558812 ]\n",
      "  [0.56594223]\n",
      "  [0.57668835]\n",
      "  [0.58707762]\n",
      "  [0.59779322]\n",
      "  [0.60674483]\n",
      "  [0.6159336 ]\n",
      "  [0.62560278]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.034835122525691986\n",
      "Predicci√≥n post entrenamiento : [[0.637154]]\n",
      "PERDIDAAAA despues: 0.03410433977842331\n",
      "loss en el callback: 0.08403461426496506, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "ejemplar: [[0.56594223]\n",
      " [0.57668835]\n",
      " [0.58707762]\n",
      " [0.59779322]\n",
      " [0.60674483]\n",
      " [0.6159336 ]\n",
      " [0.62560278]\n",
      " [0.6351859 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8196942360436743\n",
      "Predicci√≥n : [[0.64566517]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[[0.56594223]\n",
      "  [0.57668835]\n",
      "  [0.58707762]\n",
      "  [0.59779322]\n",
      "  [0.60674483]\n",
      "  [0.6159336 ]\n",
      "  [0.62560278]\n",
      "  [0.6351859 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.030286110937595367\n",
      "Predicci√≥n post entrenamiento : [[0.64674693]]\n",
      "PERDIDAAAA despues: 0.02991076372563839\n",
      "loss en el callback: 0.018180495128035545, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "ejemplar: [[0.57668835]\n",
      " [0.58707762]\n",
      " [0.59779322]\n",
      " [0.60674483]\n",
      " [0.6159336 ]\n",
      " [0.62560278]\n",
      " [0.6351859 ]\n",
      " [0.64566517]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8178628420548653\n",
      "Predicci√≥n : [[0.6552728]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[[0.57668835]\n",
      "  [0.58707762]\n",
      "  [0.59779322]\n",
      "  [0.60674483]\n",
      "  [0.6159336 ]\n",
      "  [0.62560278]\n",
      "  [0.6351859 ]\n",
      "  [0.64566517]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02643553540110588\n",
      "Predicci√≥n post entrenamiento : [[0.65682435]]\n",
      "PERDIDAAAA despues: 0.0259334035217762\n",
      "loss en el callback: 0.041234273463487625, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "ejemplar: [[0.58707762]\n",
      " [0.59779322]\n",
      " [0.60674483]\n",
      " [0.6159336 ]\n",
      " [0.62560278]\n",
      " [0.6351859 ]\n",
      " [0.64566517]\n",
      " [0.65527278]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8163333816374257\n",
      "Predicci√≥n : [[0.6651598]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[[0.58707762]\n",
      "  [0.59779322]\n",
      "  [0.60674483]\n",
      "  [0.6159336 ]\n",
      "  [0.62560278]\n",
      "  [0.6351859 ]\n",
      "  [0.64566517]\n",
      "  [0.65527278]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022853435948491096\n",
      "Predicci√≥n post entrenamiento : [[0.666176]]\n",
      "PERDIDAAAA despues: 0.022547224536538124\n",
      "loss en el callback: 0.01494311448186636, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "ejemplar: [[0.59779322]\n",
      " [0.60674483]\n",
      " [0.6159336 ]\n",
      " [0.62560278]\n",
      " [0.6351859 ]\n",
      " [0.64566517]\n",
      " [0.65527278]\n",
      " [0.66515982]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8005556061309519\n",
      "Predicci√≥n : [[0.67437536]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[[0.59779322]\n",
      "  [0.60674483]\n",
      "  [0.6159336 ]\n",
      "  [0.62560278]\n",
      "  [0.6351859 ]\n",
      "  [0.64566517]\n",
      "  [0.65527278]\n",
      "  [0.66515982]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015921451151371002\n",
      "Predicci√≥n post entrenamiento : [[0.6750174]]\n",
      "PERDIDAAAA despues: 0.01575983129441738\n",
      "loss en el callback: 0.006072040181607008, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "ejemplar: [[0.60674483]\n",
      " [0.6159336 ]\n",
      " [0.62560278]\n",
      " [0.6351859 ]\n",
      " [0.64566517]\n",
      " [0.65527278]\n",
      " [0.66515982]\n",
      " [0.67437536]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7705295155354442\n",
      "Predicci√≥n : [[0.6829635]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[[0.60674483]\n",
      "  [0.6159336 ]\n",
      "  [0.62560278]\n",
      "  [0.6351859 ]\n",
      "  [0.64566517]\n",
      "  [0.65527278]\n",
      "  [0.66515982]\n",
      "  [0.67437536]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007667807396501303\n",
      "Predicci√≥n post entrenamiento : [[0.68366283]]\n",
      "PERDIDAAAA despues: 0.007545819506049156\n",
      "loss en el callback: 0.008652780205011368, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "ejemplar: [[0.6159336 ]\n",
      " [0.62560278]\n",
      " [0.6351859 ]\n",
      " [0.64566517]\n",
      " [0.65527278]\n",
      " [0.66515982]\n",
      " [0.67437536]\n",
      " [0.68296349]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7426586795525351\n",
      "Predicci√≥n : [[0.69179815]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[[0.6159336 ]\n",
      "  [0.62560278]\n",
      "  [0.6351859 ]\n",
      "  [0.64566517]\n",
      "  [0.65527278]\n",
      "  [0.66515982]\n",
      "  [0.67437536]\n",
      "  [0.68296349]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0025867929216474295\n",
      "Predicci√≥n post entrenamiento : [[0.6921865]]\n",
      "PERDIDAAAA despues: 0.00254744291305542\n",
      "loss en el callback: 0.0027102443855255842, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "ejemplar: [[0.62560278]\n",
      " [0.6351859 ]\n",
      " [0.64566517]\n",
      " [0.65527278]\n",
      " [0.66515982]\n",
      " [0.67437536]\n",
      " [0.68296349]\n",
      " [0.69179815]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.716943098182225\n",
      "Predicci√≥n : [[0.70045996]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[[0.62560278]\n",
      "  [0.6351859 ]\n",
      "  [0.64566517]\n",
      "  [0.65527278]\n",
      "  [0.66515982]\n",
      "  [0.67437536]\n",
      "  [0.68296349]\n",
      "  [0.69179815]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00027169351233169436\n",
      "Predicci√≥n post entrenamiento : [[0.7007569]]\n",
      "PERDIDAAAA despues: 0.0002619923616293818\n",
      "loss en el callback: 0.0016502869548276067, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "ejemplar: [[0.6351859 ]\n",
      " [0.64566517]\n",
      " [0.65527278]\n",
      " [0.66515982]\n",
      " [0.67437536]\n",
      " [0.68296349]\n",
      " [0.69179815]\n",
      " [0.70045996]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7197051306082382\n",
      "Predicci√≥n : [[0.70902956]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[[0.6351859 ]\n",
      "  [0.64566517]\n",
      "  [0.65527278]\n",
      "  [0.66515982]\n",
      "  [0.67437536]\n",
      "  [0.68296349]\n",
      "  [0.69179815]\n",
      "  [0.70045996]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00011396735499147326\n",
      "Predicci√≥n post entrenamiento : [[0.7091352]]\n",
      "PERDIDAAAA despues: 0.00011172342055942863\n",
      "loss en el callback: 0.00018836533126886934, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "ejemplar: [[0.64566517]\n",
      " [0.65527278]\n",
      " [0.66515982]\n",
      " [0.67437536]\n",
      " [0.68296349]\n",
      " [0.69179815]\n",
      " [0.70045996]\n",
      " [0.70902956]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7509447768305747\n",
      "Predicci√≥n : [[0.71739477]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[[0.64566517]\n",
      "  [0.65527278]\n",
      "  [0.66515982]\n",
      "  [0.67437536]\n",
      "  [0.68296349]\n",
      "  [0.69179815]\n",
      "  [0.70045996]\n",
      "  [0.70902956]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001125604147091508\n",
      "Predicci√≥n post entrenamiento : [[0.7167252]]\n",
      "PERDIDAAAA despues: 0.0011709826067090034\n",
      "loss en el callback: 0.006647768430411816, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "ejemplar: [[0.65527278]\n",
      " [0.66515982]\n",
      " [0.67437536]\n",
      " [0.68296349]\n",
      " [0.69179815]\n",
      " [0.70045996]\n",
      " [0.70902956]\n",
      " [0.71739477]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.740278139029679\n",
      "Predicci√≥n : [[0.72467846]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[[0.65527278]\n",
      "  [0.66515982]\n",
      "  [0.67437536]\n",
      "  [0.68296349]\n",
      "  [0.69179815]\n",
      "  [0.70045996]\n",
      "  [0.70902956]\n",
      "  [0.71739477]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002433496410958469\n",
      "Predicci√≥n post entrenamiento : [[0.72492623]]\n",
      "PERDIDAAAA despues: 0.00023568057804368436\n",
      "loss en el callback: 0.0011426256969571114, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "ejemplar: [[0.66515982]\n",
      " [0.67437536]\n",
      " [0.68296349]\n",
      " [0.69179815]\n",
      " [0.70045996]\n",
      " [0.70902956]\n",
      " [0.71739477]\n",
      " [0.72467846]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.687705217205551\n",
      "Predicci√≥n : [[0.7327316]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[[0.66515982]\n",
      "  [0.67437536]\n",
      "  [0.68296349]\n",
      "  [0.69179815]\n",
      "  [0.70045996]\n",
      "  [0.70902956]\n",
      "  [0.71739477]\n",
      "  [0.72467846]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002027373295277357\n",
      "Predicci√≥n post entrenamiento : [[0.7323975]]\n",
      "PERDIDAAAA despues: 0.0019973996095359325\n",
      "loss en el callback: 0.0019478328758850694, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "ejemplar: [[0.67437536]\n",
      " [0.68296349]\n",
      " [0.69179815]\n",
      " [0.70045996]\n",
      " [0.70902956]\n",
      " [0.71739477]\n",
      " [0.72467846]\n",
      " [0.73273158]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6687695580612426\n",
      "Predicci√≥n : [[0.739915]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[[0.67437536]\n",
      "  [0.68296349]\n",
      "  [0.69179815]\n",
      "  [0.70045996]\n",
      "  [0.70902956]\n",
      "  [0.71739477]\n",
      "  [0.72467846]\n",
      "  [0.73273158]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00506167858839035\n",
      "Predicci√≥n post entrenamiento : [[0.7390845]]\n",
      "PERDIDAAAA despues: 0.004944191314280033\n",
      "loss en el callback: 0.011217736639082432, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "ejemplar: [[0.68296349]\n",
      " [0.69179815]\n",
      " [0.70045996]\n",
      " [0.70902956]\n",
      " [0.71739477]\n",
      " [0.72467846]\n",
      " [0.73273158]\n",
      " [0.73991501]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6834711615967536\n",
      "Predicci√≥n : [[0.74642074]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[[0.68296349]\n",
      "  [0.69179815]\n",
      "  [0.70045996]\n",
      "  [0.70902956]\n",
      "  [0.71739477]\n",
      "  [0.72467846]\n",
      "  [0.73273158]\n",
      "  [0.73991501]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003962651826441288\n",
      "Predicci√≥n post entrenamiento : [[0.74606574]]\n",
      "PERDIDAAAA despues: 0.003918082918971777\n",
      "loss en el callback: 0.002297496423125267, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "ejemplar: [[0.69179815]\n",
      " [0.70045996]\n",
      " [0.70902956]\n",
      " [0.71739477]\n",
      " [0.72467846]\n",
      " [0.73273158]\n",
      " [0.73991501]\n",
      " [0.74642074]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6877052172055499\n",
      "Predicci√≥n : [[0.7533302]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[[0.69179815]\n",
      "  [0.70045996]\n",
      "  [0.70902956]\n",
      "  [0.71739477]\n",
      "  [0.72467846]\n",
      "  [0.73273158]\n",
      "  [0.73991501]\n",
      "  [0.74642074]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004306634422391653\n",
      "Predicci√≥n post entrenamiento : [[0.7529374]]\n",
      "PERDIDAAAA despues: 0.0042552342638373375\n",
      "loss en el callback: 0.002744728699326515, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "ejemplar: [[0.70045996]\n",
      " [0.70902956]\n",
      " [0.71739477]\n",
      " [0.72467846]\n",
      " [0.73273158]\n",
      " [0.73991501]\n",
      " [0.74642074]\n",
      " [0.75333017]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6814717248876317\n",
      "Predicci√≥n : [[0.7600045]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[[0.70045996]\n",
      "  [0.70902956]\n",
      "  [0.71739477]\n",
      "  [0.72467846]\n",
      "  [0.73273158]\n",
      "  [0.73991501]\n",
      "  [0.74642074]\n",
      "  [0.75333017]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00616740295663476\n",
      "Predicci√≥n post entrenamiento : [[0.7594201]]\n",
      "PERDIDAAAA despues: 0.006075951736420393\n",
      "loss en el callback: 0.006485578138381243, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "ejemplar: [[0.70902956]\n",
      " [0.71739477]\n",
      " [0.72467846]\n",
      " [0.73273158]\n",
      " [0.73991501]\n",
      " [0.74642074]\n",
      " [0.75333017]\n",
      " [0.76000452]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.689261843882625\n",
      "Predicci√≥n : [[0.7662616]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[[0.70902956]\n",
      "  [0.71739477]\n",
      "  [0.72467846]\n",
      "  [0.73273158]\n",
      "  [0.73991501]\n",
      "  [0.74642074]\n",
      "  [0.75333017]\n",
      "  [0.76000452]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0059289573691785336\n",
      "Predicci√≥n post entrenamiento : [[0.76552534]]\n",
      "PERDIDAAAA despues: 0.005816119723021984\n",
      "loss en el callback: 0.009793420322239399, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "ejemplar: [[0.71739477]\n",
      " [0.72467846]\n",
      " [0.73273158]\n",
      " [0.73991501]\n",
      " [0.74642074]\n",
      " [0.75333017]\n",
      " [0.76000452]\n",
      " [0.76626158]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7110755741905297\n",
      "Predicci√≥n : [[0.77208775]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[[0.71739477]\n",
      "  [0.72467846]\n",
      "  [0.73273158]\n",
      "  [0.73991501]\n",
      "  [0.74642074]\n",
      "  [0.75333017]\n",
      "  [0.76000452]\n",
      "  [0.76626158]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0037224823608994484\n",
      "Predicci√≥n post entrenamiento : [[0.7713926]]\n",
      "PERDIDAAAA despues: 0.003638138063251972\n",
      "loss en el callback: 0.00876662414520979, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "ejemplar: [[0.72467846]\n",
      " [0.73273158]\n",
      " [0.73991501]\n",
      " [0.74642074]\n",
      " [0.75333017]\n",
      " [0.76000452]\n",
      " [0.76626158]\n",
      " [0.77208775]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7349108623046875\n",
      "Predicci√≥n : [[0.77764845]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[[0.72467846]\n",
      "  [0.73273158]\n",
      "  [0.73991501]\n",
      "  [0.74642074]\n",
      "  [0.75333017]\n",
      "  [0.76000452]\n",
      "  [0.76626158]\n",
      "  [0.77208775]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001826502732001245\n",
      "Predicci√≥n post entrenamiento : [[0.7785792]]\n",
      "PERDIDAAAA despues: 0.0019069230183959007\n",
      "loss en el callback: 0.027189278975129128, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "ejemplar: [[0.73273158]\n",
      " [0.73991501]\n",
      " [0.74642074]\n",
      " [0.75333017]\n",
      " [0.76000452]\n",
      " [0.76626158]\n",
      " [0.77208775]\n",
      " [0.77764845]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7607677082250986\n",
      "Predicci√≥n : [[0.7847481]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[[0.73273158]\n",
      "  [0.73991501]\n",
      "  [0.74642074]\n",
      "  [0.75333017]\n",
      "  [0.76000452]\n",
      "  [0.76626158]\n",
      "  [0.77208775]\n",
      "  [0.77764845]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005750585696659982\n",
      "Predicci√≥n post entrenamiento : [[0.78374916]]\n",
      "PERDIDAAAA despues: 0.0005281477351672947\n",
      "loss en el callback: 0.0159041415899992, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "ejemplar: [[0.73991501]\n",
      " [0.74642074]\n",
      " [0.75333017]\n",
      " [0.76000452]\n",
      " [0.76626158]\n",
      " [0.77208775]\n",
      " [0.77764845]\n",
      " [0.78474808]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7711170829224028\n",
      "Predicci√≥n : [[0.789564]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[[0.73991501]\n",
      "  [0.74642074]\n",
      "  [0.75333017]\n",
      "  [0.76000452]\n",
      "  [0.76626158]\n",
      "  [0.77208775]\n",
      "  [0.77764845]\n",
      "  [0.78474808]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003402889415156096\n",
      "Predicci√≥n post entrenamiento : [[0.78868747]]\n",
      "PERDIDAAAA despues: 0.0003087181248702109\n",
      "loss en el callback: 0.01267571933567524, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "ejemplar: [[0.74642074]\n",
      " [0.75333017]\n",
      " [0.76000452]\n",
      " [0.76626158]\n",
      " [0.77208775]\n",
      " [0.77764845]\n",
      " [0.78474808]\n",
      " [0.78956401]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7659589863965997\n",
      "Predicci√≥n : [[0.79431075]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[[0.74642074]\n",
      "  [0.75333017]\n",
      "  [0.76000452]\n",
      "  [0.76626158]\n",
      "  [0.77208775]\n",
      "  [0.77764845]\n",
      "  [0.78474808]\n",
      "  [0.78956401]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008038236410357058\n",
      "Predicci√≥n post entrenamiento : [[0.79453945]]\n",
      "PERDIDAAAA despues: 0.0008168442291207612\n",
      "loss en el callback: 0.001183588756248355, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "ejemplar: [[0.75333017]\n",
      " [0.76000452]\n",
      " [0.76626158]\n",
      " [0.77208775]\n",
      " [0.77764845]\n",
      " [0.78474808]\n",
      " [0.78956401]\n",
      " [0.79431075]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7483323528772654\n",
      "Predicci√≥n : [[0.8001039]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[[0.75333017]\n",
      "  [0.76000452]\n",
      "  [0.76626158]\n",
      "  [0.77208775]\n",
      "  [0.77764845]\n",
      "  [0.78474808]\n",
      "  [0.78956401]\n",
      "  [0.79431075]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0026802904903888702\n",
      "Predicci√≥n post entrenamiento : [[0.79950005]]\n",
      "PERDIDAAAA despues: 0.002618130063638091\n",
      "loss en el callback: 0.006701607257127762, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "ejemplar: [[0.76000452]\n",
      " [0.76626158]\n",
      " [0.77208775]\n",
      " [0.77764845]\n",
      " [0.78474808]\n",
      " [0.78956401]\n",
      " [0.79431075]\n",
      " [0.8001039 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7182371823643998\n",
      "Predicci√≥n : [[0.8048494]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[[0.76000452]\n",
      "  [0.76626158]\n",
      "  [0.77208775]\n",
      "  [0.77764845]\n",
      "  [0.78474808]\n",
      "  [0.78956401]\n",
      "  [0.79431075]\n",
      "  [0.8001039 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007501677609980106\n",
      "Predicci√≥n post entrenamiento : [[0.803635]]\n",
      "PERDIDAAAA despues: 0.007292790804058313\n",
      "loss en el callback: 0.0258189607411623, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "ejemplar: [[0.76626158]\n",
      " [0.77208775]\n",
      " [0.77764845]\n",
      " [0.78474808]\n",
      " [0.78956401]\n",
      " [0.79431075]\n",
      " [0.8001039 ]\n",
      " [0.80484939]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7089416644962148\n",
      "Predicci√≥n : [[0.80877054]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[[0.76626158]\n",
      "  [0.77208775]\n",
      "  [0.77764845]\n",
      "  [0.78474808]\n",
      "  [0.78956401]\n",
      "  [0.79431075]\n",
      "  [0.8001039 ]\n",
      "  [0.80484939]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009965809062123299\n",
      "Predicci√≥n post entrenamiento : [[0.80925333]]\n",
      "PERDIDAAAA despues: 0.010062436573207378\n",
      "loss en el callback: 0.007801583502441645, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "ejemplar: [[0.77208775]\n",
      " [0.77764845]\n",
      " [0.78474808]\n",
      " [0.78956401]\n",
      " [0.79431075]\n",
      " [0.8001039 ]\n",
      " [0.80484939]\n",
      " [0.80877054]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7204457992727099\n",
      "Predicci√≥n : [[0.8142294]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[[0.77208775]\n",
      "  [0.77764845]\n",
      "  [0.78474808]\n",
      "  [0.78956401]\n",
      "  [0.79431075]\n",
      "  [0.8001039 ]\n",
      "  [0.80484939]\n",
      "  [0.80877054]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008795366622507572\n",
      "Predicci√≥n post entrenamiento : [[0.81370765]]\n",
      "PERDIDAAAA despues: 0.008697770535945892\n",
      "loss en el callback: 0.005821721162647009, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "ejemplar: [[0.77764845]\n",
      " [0.78474808]\n",
      " [0.78956401]\n",
      " [0.79431075]\n",
      " [0.8001039 ]\n",
      " [0.80484939]\n",
      " [0.80877054]\n",
      " [0.81422943]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.770615477342717\n",
      "Predicci√≥n : [[0.81858903]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[[0.77764845]\n",
      "  [0.78474808]\n",
      "  [0.78956401]\n",
      "  [0.79431075]\n",
      "  [0.8001039 ]\n",
      "  [0.80484939]\n",
      "  [0.80877054]\n",
      "  [0.81422943]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0023014636244624853\n",
      "Predicci√≥n post entrenamiento : [[0.8187725]]\n",
      "PERDIDAAAA despues: 0.0023191000800579786\n",
      "loss en el callback: 0.0008184736361727118, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "ejemplar: [[0.78474808]\n",
      " [0.78956401]\n",
      " [0.79431075]\n",
      " [0.8001039 ]\n",
      " [0.80484939]\n",
      " [0.80877054]\n",
      " [0.81422943]\n",
      " [0.81858903]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8594506987062355\n",
      "Predicci√≥n : [[0.8235892]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[[0.78474808]\n",
      "  [0.78956401]\n",
      "  [0.79431075]\n",
      "  [0.8001039 ]\n",
      "  [0.80484939]\n",
      "  [0.80877054]\n",
      "  [0.81422943]\n",
      "  [0.81858903]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012860465794801712\n",
      "Predicci√≥n post entrenamiento : [[0.82385206]]\n",
      "PERDIDAAAA despues: 0.0012672628508880734\n",
      "loss en el callback: 0.0014677057042717934, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "ejemplar: [[0.78956401]\n",
      " [0.79431075]\n",
      " [0.8001039 ]\n",
      " [0.80484939]\n",
      " [0.80877054]\n",
      " [0.81422943]\n",
      " [0.81858903]\n",
      " [0.82358921]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9065410812466371\n",
      "Predicci√≥n : [[0.82812935]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[[0.78956401]\n",
      "  [0.79431075]\n",
      "  [0.8001039 ]\n",
      "  [0.80484939]\n",
      "  [0.80877054]\n",
      "  [0.81422943]\n",
      "  [0.81858903]\n",
      "  [0.82358921]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006148403976112604\n",
      "Predicci√≥n post entrenamiento : [[0.82954454]]\n",
      "PERDIDAAAA despues: 0.005928471218794584\n",
      "loss en el callback: 0.06189214810729027, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "ejemplar: [[0.79431075]\n",
      " [0.8001039 ]\n",
      " [0.80484939]\n",
      " [0.80877054]\n",
      " [0.81422943]\n",
      " [0.81858903]\n",
      " [0.82358921]\n",
      " [0.82812935]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9118866249639219\n",
      "Predicci√≥n : [[0.8338397]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[[0.79431075]\n",
      "  [0.8001039 ]\n",
      "  [0.80484939]\n",
      "  [0.80877054]\n",
      "  [0.81422943]\n",
      "  [0.81858903]\n",
      "  [0.82358921]\n",
      "  [0.82812935]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006091321352869272\n",
      "Predicci√≥n post entrenamiento : [[0.8334674]]\n",
      "PERDIDAAAA despues: 0.006149572320282459\n",
      "loss en el callback: 0.002594699151813984, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "ejemplar: [[0.8001039 ]\n",
      " [0.80484939]\n",
      " [0.80877054]\n",
      " [0.81422943]\n",
      " [0.81858903]\n",
      " [0.82358921]\n",
      " [0.82812935]\n",
      " [0.83383971]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.904335569053715\n",
      "Predicci√≥n : [[0.8377963]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[[0.8001039 ]\n",
      "  [0.80484939]\n",
      "  [0.80877054]\n",
      "  [0.81422943]\n",
      "  [0.81858903]\n",
      "  [0.82358921]\n",
      "  [0.82812935]\n",
      "  [0.83383971]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0044274767860770226\n",
      "Predicci√≥n post entrenamiento : [[0.83878046]]\n",
      "PERDIDAAAA despues: 0.004297470673918724\n",
      "loss en el callback: 0.02684018574655056, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "ejemplar: [[0.80484939]\n",
      " [0.80877054]\n",
      " [0.81422943]\n",
      " [0.81858903]\n",
      " [0.82358921]\n",
      " [0.82812935]\n",
      " [0.83383971]\n",
      " [0.83779627]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8838879135160167\n",
      "Predicci√≥n : [[0.8428473]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[[0.80484939]\n",
      "  [0.80877054]\n",
      "  [0.81422943]\n",
      "  [0.81858903]\n",
      "  [0.82358921]\n",
      "  [0.82812935]\n",
      "  [0.83383971]\n",
      "  [0.83779627]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016843307530507445\n",
      "Predicci√≥n post entrenamiento : [[0.8432731]]\n",
      "PERDIDAAAA despues: 0.0016495606396347284\n",
      "loss en el callback: 0.00456950394436717, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "ejemplar: [[0.80877054]\n",
      " [0.81422943]\n",
      " [0.81858903]\n",
      " [0.82358921]\n",
      " [0.82812935]\n",
      " [0.83383971]\n",
      " [0.83779627]\n",
      " [0.84284729]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9032153489332012\n",
      "Predicci√≥n : [[0.84733945]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[[0.80877054]\n",
      "  [0.81422943]\n",
      "  [0.81858903]\n",
      "  [0.82358921]\n",
      "  [0.82812935]\n",
      "  [0.83383971]\n",
      "  [0.83779627]\n",
      "  [0.84284729]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0031221159733831882\n",
      "Predicci√≥n post entrenamiento : [[0.8468407]]\n",
      "PERDIDAAAA despues: 0.0031781033612787724\n",
      "loss en el callback: 0.004203192424029112, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "ejemplar: [[0.81422943]\n",
      " [0.81858903]\n",
      " [0.82358921]\n",
      " [0.82812935]\n",
      " [0.83383971]\n",
      " [0.83779627]\n",
      " [0.84284729]\n",
      " [0.84733945]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9623178753052692\n",
      "Predicci√≥n : [[0.85114235]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[[0.81422943]\n",
      "  [0.81858903]\n",
      "  [0.82358921]\n",
      "  [0.82812935]\n",
      "  [0.83383971]\n",
      "  [0.83779627]\n",
      "  [0.84284729]\n",
      "  [0.84733945]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012360000051558018\n",
      "Predicci√≥n post entrenamiento : [[0.85154945]]\n",
      "PERDIDAAAA despues: 0.012269646860659122\n",
      "loss en el callback: 0.0033307389821857214, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "ejemplar: [[0.81858903]\n",
      " [0.82358921]\n",
      " [0.82812935]\n",
      " [0.83383971]\n",
      " [0.83779627]\n",
      " [0.84284729]\n",
      " [0.84733945]\n",
      " [0.85114235]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.982058820003038\n",
      "Predicci√≥n : [[0.8556744]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[[0.81858903]\n",
      "  [0.82358921]\n",
      "  [0.82812935]\n",
      "  [0.83383971]\n",
      "  [0.83779627]\n",
      "  [0.84284729]\n",
      "  [0.84733945]\n",
      "  [0.85114235]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015973025932908058\n",
      "Predicci√≥n post entrenamiento : [[0.85680795]]\n",
      "PERDIDAAAA despues: 0.01568778231739998\n",
      "loss en el callback: 0.03063904494047165, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "ejemplar: [[0.82358921]\n",
      " [0.82812935]\n",
      " [0.83383971]\n",
      " [0.83779627]\n",
      " [0.84284729]\n",
      " [0.84733945]\n",
      " [0.85114235]\n",
      " [0.85567439]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9624381830265082\n",
      "Predicci√≥n : [[0.8610334]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[[0.82358921]\n",
      "  [0.82812935]\n",
      "  [0.83383971]\n",
      "  [0.83779627]\n",
      "  [0.84284729]\n",
      "  [0.84733945]\n",
      "  [0.85114235]\n",
      "  [0.85567439]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010282930918037891\n",
      "Predicci√≥n post entrenamiento : [[0.8603501]]\n",
      "PERDIDAAAA despues: 0.010421979241073132\n",
      "loss en el callback: 0.007963035255670547, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "ejemplar: [[0.82812935]\n",
      " [0.83383971]\n",
      " [0.83779627]\n",
      " [0.84284729]\n",
      " [0.84733945]\n",
      " [0.85114235]\n",
      " [0.85567439]\n",
      " [0.86103338]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9302512105217627\n",
      "Predicci√≥n : [[0.8644947]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[[0.82812935]\n",
      "  [0.83383971]\n",
      "  [0.83779627]\n",
      "  [0.84284729]\n",
      "  [0.84733945]\n",
      "  [0.85114235]\n",
      "  [0.85567439]\n",
      "  [0.86103338]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00432391744107008\n",
      "Predicci√≥n post entrenamiento : [[0.864466]]\n",
      "PERDIDAAAA despues: 0.004327688366174698\n",
      "loss en el callback: 1.732384589558933e-05, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "ejemplar: [[0.83383971]\n",
      " [0.83779627]\n",
      " [0.84284729]\n",
      " [0.84733945]\n",
      " [0.85114235]\n",
      " [0.85567439]\n",
      " [0.86103338]\n",
      " [0.86449468]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.885497902488802\n",
      "Predicci√≥n : [[0.86863756]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[[0.83383971]\n",
      "  [0.83779627]\n",
      "  [0.84284729]\n",
      "  [0.84733945]\n",
      "  [0.85114235]\n",
      "  [0.85567439]\n",
      "  [0.86103338]\n",
      "  [0.86449468]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00028427192592062056\n",
      "Predicci√≥n post entrenamiento : [[0.8691202]]\n",
      "PERDIDAAAA despues: 0.0002682305930647999\n",
      "loss en el callback: 0.006338538136333227, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "ejemplar: [[0.83779627]\n",
      " [0.84284729]\n",
      " [0.84733945]\n",
      " [0.85114235]\n",
      " [0.85567439]\n",
      " [0.86103338]\n",
      " [0.86449468]\n",
      " [0.86863756]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597025687419927\n",
      "Predicci√≥n : [[0.8729731]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[[0.83779627]\n",
      "  [0.84284729]\n",
      "  [0.84733945]\n",
      "  [0.85114235]\n",
      "  [0.85567439]\n",
      "  [0.86103338]\n",
      "  [0.86449468]\n",
      "  [0.86863756]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00017610609938856214\n",
      "Predicci√≥n post entrenamiento : [[0.8727446]]\n",
      "PERDIDAAAA despues: 0.00017009461589623243\n",
      "loss en el callback: 0.0011860753875225782, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "ejemplar: [[0.84284729]\n",
      " [0.84733945]\n",
      " [0.85114235]\n",
      " [0.85567439]\n",
      " [0.86103338]\n",
      " [0.86449468]\n",
      " [0.86863756]\n",
      " [0.87297308]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8528652092813349\n",
      "Predicci√≥n : [[0.8767234]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[[0.84284729]\n",
      "  [0.84733945]\n",
      "  [0.85114235]\n",
      "  [0.85567439]\n",
      "  [0.86103338]\n",
      "  [0.86449468]\n",
      "  [0.86863756]\n",
      "  [0.87297308]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005692131817340851\n",
      "Predicci√≥n post entrenamiento : [[0.8749465]]\n",
      "PERDIDAAAA despues: 0.00048758185585029423\n",
      "loss en el callback: 0.05454413220286369, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "ejemplar: [[0.84733945]\n",
      " [0.85114235]\n",
      " [0.85567439]\n",
      " [0.86103338]\n",
      " [0.86449468]\n",
      " [0.86863756]\n",
      " [0.87297308]\n",
      " [0.87672341]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8585854533368672\n",
      "Predicci√≥n : [[0.8787428]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[[0.84733945]\n",
      "  [0.85114235]\n",
      "  [0.85567439]\n",
      "  [0.86103338]\n",
      "  [0.86449468]\n",
      "  [0.86863756]\n",
      "  [0.87297308]\n",
      "  [0.87672341]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004063182568643242\n",
      "Predicci√≥n post entrenamiento : [[0.8780427]]\n",
      "PERDIDAAAA despues: 0.0003785834414884448\n",
      "loss en el callback: 0.010505410842597485, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "ejemplar: [[0.85114235]\n",
      " [0.85567439]\n",
      " [0.86103338]\n",
      " [0.86449468]\n",
      " [0.86863756]\n",
      " [0.87297308]\n",
      " [0.87672341]\n",
      " [0.87874281]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8768633009085897\n",
      "Predicci√≥n : [[0.88176864]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[[0.85114235]\n",
      "  [0.85567439]\n",
      "  [0.86103338]\n",
      "  [0.86449468]\n",
      "  [0.86863756]\n",
      "  [0.87297308]\n",
      "  [0.87672341]\n",
      "  [0.87874281]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.4062390366452746e-05\n",
      "Predicci√≥n post entrenamiento : [[0.8812249]]\n",
      "PERDIDAAAA despues: 1.9023291315534152e-05\n",
      "loss en el callback: 0.006356973201036453, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "ejemplar: [[0.85567439]\n",
      " [0.86103338]\n",
      " [0.86449468]\n",
      " [0.86863756]\n",
      " [0.87297308]\n",
      " [0.87672341]\n",
      " [0.87874281]\n",
      " [0.88176864]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8806463966074481\n",
      "Predicci√≥n : [[0.8850365]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[[0.85567439]\n",
      "  [0.86103338]\n",
      "  [0.86449468]\n",
      "  [0.86863756]\n",
      "  [0.87297308]\n",
      "  [0.87672341]\n",
      "  [0.87874281]\n",
      "  [0.88176864]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.9273158613941632e-05\n",
      "Predicci√≥n post entrenamiento : [[0.8848123]]\n",
      "PERDIDAAAA despues: 1.735462137730792e-05\n",
      "loss en el callback: 0.0012347426963970065, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "ejemplar: [[0.86103338]\n",
      " [0.86449468]\n",
      " [0.86863756]\n",
      " [0.87297308]\n",
      " [0.87672341]\n",
      " [0.87874281]\n",
      " [0.88176864]\n",
      " [0.88503653]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8699347404334429\n",
      "Predicci√≥n : [[0.88847286]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[[0.86103338]\n",
      "  [0.86449468]\n",
      "  [0.86863756]\n",
      "  [0.87297308]\n",
      "  [0.87672341]\n",
      "  [0.87874281]\n",
      "  [0.88176864]\n",
      "  [0.88503653]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003436617844272405\n",
      "Predicci√≥n post entrenamiento : [[0.88892806]]\n",
      "PERDIDAAAA despues: 0.00036074614035896957\n",
      "loss en el callback: 0.006994250230491161, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "ejemplar: [[0.86449468]\n",
      " [0.86863756]\n",
      " [0.87297308]\n",
      " [0.87672341]\n",
      " [0.87874281]\n",
      " [0.88176864]\n",
      " [0.88503653]\n",
      " [0.88847286]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8465135437340043\n",
      "Predicci√≥n : [[0.8921406]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[[0.86449468]\n",
      "  [0.86863756]\n",
      "  [0.87297308]\n",
      "  [0.87672341]\n",
      "  [0.87874281]\n",
      "  [0.88176864]\n",
      "  [0.88503653]\n",
      "  [0.88847286]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002081828424707055\n",
      "Predicci√≥n post entrenamiento : [[0.89149094]]\n",
      "PERDIDAAAA despues: 0.002022963482886553\n",
      "loss en el callback: 0.010456142947077751, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "ejemplar: [[0.86863756]\n",
      " [0.87297308]\n",
      " [0.87672341]\n",
      " [0.87874281]\n",
      " [0.88176864]\n",
      " [0.88503653]\n",
      " [0.88847286]\n",
      " [0.89214063]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8103828065091326\n",
      "Predicci√≥n : [[0.89470917]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[[0.86863756]\n",
      "  [0.87297308]\n",
      "  [0.87672341]\n",
      "  [0.87874281]\n",
      "  [0.88176864]\n",
      "  [0.88503653]\n",
      "  [0.88847286]\n",
      "  [0.89214063]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007110939361155033\n",
      "Predicci√≥n post entrenamiento : [[0.8936254]]\n",
      "PERDIDAAAA despues: 0.006929329596459866\n",
      "loss en el callback: 0.02808263897895813, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "ejemplar: [[0.87297308]\n",
      " [0.87672341]\n",
      " [0.87874281]\n",
      " [0.88176864]\n",
      " [0.88503653]\n",
      " [0.88847286]\n",
      " [0.89214063]\n",
      " [0.89470917]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8026111217617493\n",
      "Predicci√≥n : [[0.8966344]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[[0.87297308]\n",
      "  [0.87672341]\n",
      "  [0.87874281]\n",
      "  [0.88176864]\n",
      "  [0.88503653]\n",
      "  [0.88847286]\n",
      "  [0.89214063]\n",
      "  [0.89470917]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008840378373861313\n",
      "Predicci√≥n post entrenamiento : [[0.8954976]]\n",
      "PERDIDAAAA despues: 0.008627903647720814\n",
      "loss en el callback: 0.030583461746573448, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "ejemplar: [[0.87672341]\n",
      " [0.87874281]\n",
      " [0.88176864]\n",
      " [0.88503653]\n",
      " [0.88847286]\n",
      " [0.89214063]\n",
      " [0.89470917]\n",
      " [0.8966344 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.823198489491854\n",
      "Predicci√≥n : [[0.8981925]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[[0.87672341]\n",
      "  [0.87874281]\n",
      "  [0.88176864]\n",
      "  [0.88503653]\n",
      "  [0.88847286]\n",
      "  [0.89214063]\n",
      "  [0.89470917]\n",
      "  [0.8966344 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005624104291200638\n",
      "Predicci√≥n post entrenamiento : [[0.8978135]]\n",
      "PERDIDAAAA despues: 0.005567398387938738\n",
      "loss en el callback: 0.004245270974934101, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "ejemplar: [[0.87874281]\n",
      " [0.88176864]\n",
      " [0.88503653]\n",
      " [0.88847286]\n",
      " [0.89214063]\n",
      " [0.89470917]\n",
      " [0.8966344 ]\n",
      " [0.89819252]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8397204264676091\n",
      "Predicci√≥n : [[0.9002991]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[[0.87874281]\n",
      "  [0.88176864]\n",
      "  [0.88503653]\n",
      "  [0.88847286]\n",
      "  [0.89214063]\n",
      "  [0.89470917]\n",
      "  [0.8966344 ]\n",
      "  [0.89819252]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0036697720643132925\n",
      "Predicci√≥n post entrenamiento : [[0.8996578]]\n",
      "PERDIDAAAA despues: 0.003592486958950758\n",
      "loss en el callback: 0.011305874213576317, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "ejemplar: [[0.88176864]\n",
      " [0.88503653]\n",
      " [0.88847286]\n",
      " [0.89214063]\n",
      " [0.89470917]\n",
      " [0.8966344 ]\n",
      " [0.89819252]\n",
      " [0.90029907]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.852176932689015\n",
      "Predicci√≥n : [[0.9023795]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[[0.88176864]\n",
      "  [0.88503653]\n",
      "  [0.88847286]\n",
      "  [0.89214063]\n",
      "  [0.89470917]\n",
      "  [0.8966344 ]\n",
      "  [0.89819252]\n",
      "  [0.90029907]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0025203018449246883\n",
      "Predicci√≥n post entrenamiento : [[0.9022398]]\n",
      "PERDIDAAAA despues: 0.0025062933564186096\n",
      "loss en el callback: 0.0006484880577772856, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "ejemplar: [[0.88503653]\n",
      " [0.88847286]\n",
      " [0.89214063]\n",
      " [0.89470917]\n",
      " [0.8966344 ]\n",
      " [0.89819252]\n",
      " [0.90029907]\n",
      " [0.90237951]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8615626813481295\n",
      "Predicci√≥n : [[0.9049116]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[[0.88503653]\n",
      "  [0.88847286]\n",
      "  [0.89214063]\n",
      "  [0.89470917]\n",
      "  [0.8966344 ]\n",
      "  [0.89819252]\n",
      "  [0.90029907]\n",
      "  [0.90237951]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018791278125718236\n",
      "Predicci√≥n post entrenamiento : [[0.9048133]]\n",
      "PERDIDAAAA despues: 0.0018706161063164473\n",
      "loss en el callback: 0.0003156709426548332, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "ejemplar: [[0.88847286]\n",
      " [0.89214063]\n",
      " [0.89470917]\n",
      " [0.8966344 ]\n",
      " [0.89819252]\n",
      " [0.90029907]\n",
      " [0.90237951]\n",
      " [0.90491158]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8678776724449532\n",
      "Predicci√≥n : [[0.9073217]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[[0.88847286]\n",
      "  [0.89214063]\n",
      "  [0.89470917]\n",
      "  [0.8966344 ]\n",
      "  [0.89819252]\n",
      "  [0.90029907]\n",
      "  [0.90237951]\n",
      "  [0.90491158]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001555831404402852\n",
      "Predicci√≥n post entrenamiento : [[0.90790766]]\n",
      "PERDIDAAAA despues: 0.0016024011420086026\n",
      "loss en el callback: 0.012662073597311974, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "ejemplar: [[0.89214063]\n",
      " [0.89470917]\n",
      " [0.8966344 ]\n",
      " [0.89819252]\n",
      " [0.90029907]\n",
      " [0.90237951]\n",
      " [0.90491158]\n",
      " [0.90732169]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8701963127047843\n",
      "Predicci√≥n : [[0.91015196]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[[0.89214063]\n",
      "  [0.89470917]\n",
      "  [0.8966344 ]\n",
      "  [0.89819252]\n",
      "  [0.90029907]\n",
      "  [0.90237951]\n",
      "  [0.90491158]\n",
      "  [0.90732169]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015964512713253498\n",
      "Predicci√≥n post entrenamiento : [[0.91005087]]\n",
      "PERDIDAAAA despues: 0.0015883833402767777\n",
      "loss en el callback: 0.00030322157545015216, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "ejemplar: [[0.89470917]\n",
      " [0.8966344 ]\n",
      " [0.89819252]\n",
      " [0.90029907]\n",
      " [0.90237951]\n",
      " [0.90491158]\n",
      " [0.90732169]\n",
      " [0.91015196]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8685186021276227\n",
      "Predicci√≥n : [[0.91191334]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[[0.89470917]\n",
      "  [0.8966344 ]\n",
      "  [0.89819252]\n",
      "  [0.90029907]\n",
      "  [0.90237951]\n",
      "  [0.90491158]\n",
      "  [0.90732169]\n",
      "  [0.91015196]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018831038614735007\n",
      "Predicci√≥n post entrenamiento : [[0.9116488]]\n",
      "PERDIDAAAA despues: 0.0018602157942950726\n",
      "loss en el callback: 0.001974651589989662, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "ejemplar: [[0.8966344 ]\n",
      " [0.89819252]\n",
      " [0.90029907]\n",
      " [0.90237951]\n",
      " [0.90491158]\n",
      " [0.90732169]\n",
      " [0.91015196]\n",
      " [0.91191334]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8529880395838255\n",
      "Predicci√≥n : [[0.9133925]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[[0.8966344 ]\n",
      "  [0.89819252]\n",
      "  [0.90029907]\n",
      "  [0.90237951]\n",
      "  [0.90491158]\n",
      "  [0.90732169]\n",
      "  [0.91015196]\n",
      "  [0.91191334]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0036486939061433077\n",
      "Predicci√≥n post entrenamiento : [[0.912864]]\n",
      "PERDIDAAAA despues: 0.0035851311404258013\n",
      "loss en el callback: 0.0084900027140975, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "ejemplar: [[0.89819252]\n",
      " [0.90029907]\n",
      " [0.90237951]\n",
      " [0.90491158]\n",
      " [0.90732169]\n",
      " [0.91015196]\n",
      " [0.91191334]\n",
      " [0.91339248]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8236046250733932\n",
      "Predicci√≥n : [[0.91466314]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[[0.89819252]\n",
      "  [0.90029907]\n",
      "  [0.90237951]\n",
      "  [0.90491158]\n",
      "  [0.90732169]\n",
      "  [0.91015196]\n",
      "  [0.91191334]\n",
      "  [0.91339248]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00829164870083332\n",
      "Predicci√≥n post entrenamiento : [[0.9145664]]\n",
      "PERDIDAAAA despues: 0.00827404111623764\n",
      "loss en el callback: 0.00036308428389020264, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "ejemplar: [[0.90029907]\n",
      " [0.90237951]\n",
      " [0.90491158]\n",
      " [0.90732169]\n",
      " [0.91015196]\n",
      " [0.91191334]\n",
      " [0.91339248]\n",
      " [0.91466314]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8032508871761479\n",
      "Predicci√≥n : [[0.9165331]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[[0.90029907]\n",
      "  [0.90237951]\n",
      "  [0.90491158]\n",
      "  [0.90732169]\n",
      "  [0.91015196]\n",
      "  [0.91191334]\n",
      "  [0.91339248]\n",
      "  [0.91466314]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01283285766839981\n",
      "Predicci√≥n post entrenamiento : [[0.9157316]]\n",
      "PERDIDAAAA despues: 0.012651908211410046\n",
      "loss en el callback: 0.018511414527893066, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "ejemplar: [[0.90237951]\n",
      " [0.90491158]\n",
      " [0.90732169]\n",
      " [0.91015196]\n",
      " [0.91191334]\n",
      " [0.91339248]\n",
      " [0.91466314]\n",
      " [0.91653311]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7919268258920897\n",
      "Predicci√≥n : [[0.9177188]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[[0.90237951]\n",
      "  [0.90491158]\n",
      "  [0.90732169]\n",
      "  [0.91015196]\n",
      "  [0.91191334]\n",
      "  [0.91339248]\n",
      "  [0.91466314]\n",
      "  [0.91653311]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01582363434135914\n",
      "Predicci√≥n post entrenamiento : [[0.9154633]]\n",
      "PERDIDAAAA despues: 0.015261273831129074\n",
      "loss en el callback: 0.11827509850263596, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "ejemplar: [[0.90491158]\n",
      " [0.90732169]\n",
      " [0.91015196]\n",
      " [0.91191334]\n",
      " [0.91339248]\n",
      " [0.91466314]\n",
      " [0.91653311]\n",
      " [0.91771883]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7865023059771536\n",
      "Predicci√≥n : [[0.91745675]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[[0.90491158]\n",
      "  [0.90732169]\n",
      "  [0.91015196]\n",
      "  [0.91191334]\n",
      "  [0.91339248]\n",
      "  [0.91466314]\n",
      "  [0.91653311]\n",
      "  [0.91771883]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0171490665525198\n",
      "Predicci√≥n post entrenamiento : [[0.9171708]]\n",
      "PERDIDAAAA despues: 0.017074262723326683\n",
      "loss en el callback: 0.002868445822969079, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "ejemplar: [[0.90732169]\n",
      " [0.91015196]\n",
      " [0.91191334]\n",
      " [0.91339248]\n",
      " [0.91466314]\n",
      " [0.91653311]\n",
      " [0.91771883]\n",
      " [0.91745675]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7869773274313391\n",
      "Predicci√≥n : [[0.91900474]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[[0.90732169]\n",
      "  [0.91015196]\n",
      "  [0.91191334]\n",
      "  [0.91339248]\n",
      "  [0.91466314]\n",
      "  [0.91653311]\n",
      "  [0.91771883]\n",
      "  [0.91745675]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0174312312155962\n",
      "Predicci√≥n post entrenamiento : [[0.91804355]]\n",
      "PERDIDAAAA despues: 0.017178349196910858\n",
      "loss en el callback: 0.027853354811668396, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "ejemplar: [[0.91015196]\n",
      " [0.91191334]\n",
      " [0.91339248]\n",
      " [0.91466314]\n",
      " [0.91653311]\n",
      " [0.91771883]\n",
      " [0.91745675]\n",
      " [0.91900474]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7874362431744556\n",
      "Predicci√≥n : [[0.9196895]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[[0.91015196]\n",
      "  [0.91191334]\n",
      "  [0.91339248]\n",
      "  [0.91466314]\n",
      "  [0.91653311]\n",
      "  [0.91771883]\n",
      "  [0.91745675]\n",
      "  [0.91900474]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017490915954113007\n",
      "Predicci√≥n post entrenamiento : [[0.9192766]]\n",
      "PERDIDAAAA despues: 0.017381876707077026\n",
      "loss en el callback: 0.00567622808739543, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "ejemplar: [[0.91191334]\n",
      " [0.91339248]\n",
      " [0.91466314]\n",
      " [0.91653311]\n",
      " [0.91771883]\n",
      " [0.91745675]\n",
      " [0.91900474]\n",
      " [0.91968948]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7878790532065031\n",
      "Predicci√≥n : [[0.92055154]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[[0.91191334]\n",
      "  [0.91339248]\n",
      "  [0.91466314]\n",
      "  [0.91653311]\n",
      "  [0.91771883]\n",
      "  [0.91745675]\n",
      "  [0.91900474]\n",
      "  [0.91968948]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017601989209651947\n",
      "Predicci√≥n post entrenamiento : [[0.9180476]]\n",
      "PERDIDAAAA despues: 0.016943853348493576\n",
      "loss en el callback: 0.1433328539133072, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "ejemplar: [[0.91339248]\n",
      " [0.91466314]\n",
      " [0.91653311]\n",
      " [0.91771883]\n",
      " [0.91745675]\n",
      " [0.91900474]\n",
      " [0.91968948]\n",
      " [0.92055154]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7954532004373992\n",
      "Predicci√≥n : [[0.91917753]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[[0.91339248]\n",
      "  [0.91466314]\n",
      "  [0.91653311]\n",
      "  [0.91771883]\n",
      "  [0.91745675]\n",
      "  [0.91900474]\n",
      "  [0.91968948]\n",
      "  [0.92055154]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015307712368667126\n",
      "Predicci√≥n post entrenamiento : [[0.91830516]]\n",
      "PERDIDAAAA despues: 0.015092605724930763\n",
      "loss en el callback: 0.024597112089395523, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "ejemplar: [[0.91466314]\n",
      " [0.91653311]\n",
      " [0.91771883]\n",
      " [0.91745675]\n",
      " [0.91900474]\n",
      " [0.91968948]\n",
      " [0.92055154]\n",
      " [0.91917753]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8101586848671446\n",
      "Predicci√≥n : [[0.91931987]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[[0.91466314]\n",
      "  [0.91653311]\n",
      "  [0.91771883]\n",
      "  [0.91745675]\n",
      "  [0.91900474]\n",
      "  [0.91968948]\n",
      "  [0.92055154]\n",
      "  [0.91917753]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011916167102754116\n",
      "Predicci√≥n post entrenamiento : [[0.9175439]]\n",
      "PERDIDAAAA despues: 0.011531584896147251\n",
      "loss en el callback: 0.08552645146846771, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "ejemplar: [[0.91653311]\n",
      " [0.91771883]\n",
      " [0.91745675]\n",
      " [0.91900474]\n",
      " [0.91968948]\n",
      " [0.92055154]\n",
      " [0.91917753]\n",
      " [0.91931987]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7668473230866574\n",
      "Predicci√≥n : [[0.91845024]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[[0.91653311]\n",
      "  [0.91771883]\n",
      "  [0.91745675]\n",
      "  [0.91900474]\n",
      "  [0.91968948]\n",
      "  [0.92055154]\n",
      "  [0.91917753]\n",
      "  [0.91931987]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022983446717262268\n",
      "Predicci√≥n post entrenamiento : [[0.91861564]]\n",
      "PERDIDAAAA despues: 0.0230336245149374\n",
      "loss en el callback: 0.001317811431363225, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "ejemplar: [[0.91771883]\n",
      " [0.91745675]\n",
      " [0.91900474]\n",
      " [0.91968948]\n",
      " [0.92055154]\n",
      " [0.91917753]\n",
      " [0.91931987]\n",
      " [0.91845024]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6655191150959373\n",
      "Predicci√≥n : [[0.91918564]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[[0.91771883]\n",
      "  [0.91745675]\n",
      "  [0.91900474]\n",
      "  [0.91968948]\n",
      "  [0.92055154]\n",
      "  [0.91917753]\n",
      "  [0.91931987]\n",
      "  [0.91845024]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06434670090675354\n",
      "Predicci√≥n post entrenamiento : [[0.91735786]]\n",
      "PERDIDAAAA despues: 0.06342275440692902\n",
      "loss en el callback: 0.09577027708292007, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "ejemplar: [[0.91745675]\n",
      " [0.91900474]\n",
      " [0.91968948]\n",
      " [0.92055154]\n",
      " [0.91917753]\n",
      " [0.91931987]\n",
      " [0.91845024]\n",
      " [0.91918564]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6360738003224796\n",
      "Predicci√≥n : [[0.91770816]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[[0.91745675]\n",
      "  [0.91900474]\n",
      "  [0.91968948]\n",
      "  [0.92055154]\n",
      "  [0.91917753]\n",
      "  [0.91931987]\n",
      "  [0.91845024]\n",
      "  [0.91918564]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07931789755821228\n",
      "Predicci√≥n post entrenamiento : [[0.9169697]]\n",
      "PERDIDAAAA despues: 0.07890249788761139\n",
      "loss en el callback: 0.026101287454366684, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "ejemplar: [[0.91900474]\n",
      " [0.91968948]\n",
      " [0.92055154]\n",
      " [0.91917753]\n",
      " [0.91931987]\n",
      " [0.91845024]\n",
      " [0.91918564]\n",
      " [0.91770816]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6785113787662842\n",
      "Predicci√≥n : [[0.9174509]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[[0.91900474]\n",
      "  [0.91968948]\n",
      "  [0.92055154]\n",
      "  [0.91917753]\n",
      "  [0.91931987]\n",
      "  [0.91845024]\n",
      "  [0.91918564]\n",
      "  [0.91770816]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0570920966565609\n",
      "Predicci√≥n post entrenamiento : [[0.9145938]]\n",
      "PERDIDAAAA despues: 0.055734917521476746\n",
      "loss en el callback: 0.21252228319644928, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "ejemplar: [[0.91968948]\n",
      " [0.92055154]\n",
      " [0.91917753]\n",
      " [0.91931987]\n",
      " [0.91845024]\n",
      " [0.91918564]\n",
      " [0.91770816]\n",
      " [0.9174509 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6965967339840231\n",
      "Predicci√≥n : [[0.91467184]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[[0.91968948]\n",
      "  [0.92055154]\n",
      "  [0.91917753]\n",
      "  [0.91931987]\n",
      "  [0.91845024]\n",
      "  [0.91918564]\n",
      "  [0.91770816]\n",
      "  [0.9174509 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04755674675107002\n",
      "Predicci√≥n post entrenamiento : [[0.9143386]]\n",
      "PERDIDAAAA despues: 0.047411512583494186\n",
      "loss en el callback: 0.005418880842626095, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "ejemplar: [[0.92055154]\n",
      " [0.91917753]\n",
      " [0.91931987]\n",
      " [0.91845024]\n",
      " [0.91918564]\n",
      " [0.91770816]\n",
      " [0.9174509 ]\n",
      " [0.91467184]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6903298659756966\n",
      "Predicci√≥n : [[0.91416246]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[[0.92055154]\n",
      "  [0.91917753]\n",
      "  [0.91931987]\n",
      "  [0.91845024]\n",
      "  [0.91918564]\n",
      "  [0.91770816]\n",
      "  [0.9174509 ]\n",
      "  [0.91467184]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.050101034343242645\n",
      "Predicci√≥n post entrenamiento : [[0.91375715]]\n",
      "PERDIDAAAA despues: 0.04991975799202919\n",
      "loss en el callback: 0.0073443325236439705, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "ejemplar: [[0.91917753]\n",
      " [0.91931987]\n",
      " [0.91845024]\n",
      " [0.91918564]\n",
      " [0.91770816]\n",
      " [0.9174509 ]\n",
      " [0.91467184]\n",
      " [0.91416246]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6970473058045382\n",
      "Predicci√≥n : [[0.9132112]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[[0.91917753]\n",
      "  [0.91931987]\n",
      "  [0.91845024]\n",
      "  [0.91918564]\n",
      "  [0.91770816]\n",
      "  [0.9174509 ]\n",
      "  [0.91467184]\n",
      "  [0.91416246]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04672684520483017\n",
      "Predicci√≥n post entrenamiento : [[0.9117758]]\n",
      "PERDIDAAAA despues: 0.046108342707157135\n",
      "loss en el callback: 0.07120455801486969, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "ejemplar: [[0.91931987]\n",
      " [0.91845024]\n",
      " [0.91918564]\n",
      " [0.91770816]\n",
      " [0.9174509 ]\n",
      " [0.91467184]\n",
      " [0.91416246]\n",
      " [0.91321123]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7167490534705484\n",
      "Predicci√≥n : [[0.91142344]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[[0.91931987]\n",
      "  [0.91845024]\n",
      "  [0.91918564]\n",
      "  [0.91770816]\n",
      "  [0.9174509 ]\n",
      "  [0.91467184]\n",
      "  [0.91416246]\n",
      "  [0.91321123]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03789811208844185\n",
      "Predicci√≥n post entrenamiento : [[0.90987915]]\n",
      "PERDIDAAAA despues: 0.037299226969480515\n",
      "loss en el callback: 0.08034255355596542, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "ejemplar: [[0.91845024]\n",
      " [0.91918564]\n",
      " [0.91770816]\n",
      " [0.9174509 ]\n",
      " [0.91467184]\n",
      " [0.91416246]\n",
      " [0.91321123]\n",
      " [0.91142344]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7490507063998944\n",
      "Predicci√≥n : [[0.9092867]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[[0.91845024]\n",
      "  [0.91918564]\n",
      "  [0.91770816]\n",
      "  [0.9174509 ]\n",
      "  [0.91467184]\n",
      "  [0.91416246]\n",
      "  [0.91321123]\n",
      "  [0.91142344]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02567557618021965\n",
      "Predicci√≥n post entrenamiento : [[0.9074289]]\n",
      "PERDIDAAAA despues: 0.025083668529987335\n",
      "loss en el callback: 0.10391833633184433, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "ejemplar: [[0.91918564]\n",
      " [0.91770816]\n",
      " [0.9174509 ]\n",
      " [0.91467184]\n",
      " [0.91416246]\n",
      " [0.91321123]\n",
      " [0.91142344]\n",
      " [0.90928668]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7939522645925762\n",
      "Predicci√≥n : [[0.90681815]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[[0.91918564]\n",
      "  [0.91770816]\n",
      "  [0.9174509 ]\n",
      "  [0.91467184]\n",
      "  [0.91416246]\n",
      "  [0.91321123]\n",
      "  [0.91142344]\n",
      "  [0.90928668]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01273870375007391\n",
      "Predicci√≥n post entrenamiento : [[0.9058649]]\n",
      "PERDIDAAAA despues: 0.012524431571364403\n",
      "loss en el callback: 0.030941935256123543, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "ejemplar: [[0.91770816]\n",
      " [0.9174509 ]\n",
      " [0.91467184]\n",
      " [0.91416246]\n",
      " [0.91321123]\n",
      " [0.91142344]\n",
      " [0.90928668]\n",
      " [0.90681815]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8547447263586395\n",
      "Predicci√≥n : [[0.9047394]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[[0.91770816]\n",
      "  [0.9174509 ]\n",
      "  [0.91467184]\n",
      "  [0.91416246]\n",
      "  [0.91321123]\n",
      "  [0.91142344]\n",
      "  [0.90928668]\n",
      "  [0.90681815]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0024994646664708853\n",
      "Predicci√≥n post entrenamiento : [[0.904452]]\n",
      "PERDIDAAAA despues: 0.0024708150885999203\n",
      "loss en el callback: 0.00317377015016973, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "ejemplar: [[0.9174509 ]\n",
      " [0.91467184]\n",
      " [0.91416246]\n",
      " [0.91321123]\n",
      " [0.91142344]\n",
      " [0.90928668]\n",
      " [0.90681815]\n",
      " [0.90473938]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9314280916980849\n",
      "Predicci√≥n : [[0.9033401]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[[0.9174509 ]\n",
      "  [0.91467184]\n",
      "  [0.91416246]\n",
      "  [0.91321123]\n",
      "  [0.91142344]\n",
      "  [0.90928668]\n",
      "  [0.90681815]\n",
      "  [0.90473938]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007889342377893627\n",
      "Predicci√≥n post entrenamiento : [[0.9033237]]\n",
      "PERDIDAAAA despues: 0.0007898553158156574\n",
      "loss en el callback: 1.0318315617041662e-05, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "ejemplar: [[0.91467184]\n",
      " [0.91416246]\n",
      " [0.91321123]\n",
      " [0.91142344]\n",
      " [0.90928668]\n",
      " [0.90681815]\n",
      " [0.90473938]\n",
      " [0.9033401 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9627243989762315\n",
      "Predicci√≥n : [[0.9018578]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[[0.91467184]\n",
      "  [0.91416246]\n",
      "  [0.91321123]\n",
      "  [0.91142344]\n",
      "  [0.90928668]\n",
      "  [0.90681815]\n",
      "  [0.90473938]\n",
      "  [0.9033401 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003704742295667529\n",
      "Predicci√≥n post entrenamiento : [[0.9024182]]\n",
      "PERDIDAAAA despues: 0.0036368367727845907\n",
      "loss en el callback: 0.015942832455039024, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "ejemplar: [[0.91416246]\n",
      " [0.91321123]\n",
      " [0.91142344]\n",
      " [0.90928668]\n",
      " [0.90681815]\n",
      " [0.90473938]\n",
      " [0.9033401 ]\n",
      " [0.90185779]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9486336481930799\n",
      "Predicci√≥n : [[0.90125245]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[[0.91416246]\n",
      "  [0.91321123]\n",
      "  [0.91142344]\n",
      "  [0.90928668]\n",
      "  [0.90681815]\n",
      "  [0.90473938]\n",
      "  [0.9033401 ]\n",
      "  [0.90185779]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0022449803072959185\n",
      "Predicci√≥n post entrenamiento : [[0.90117776]]\n",
      "PERDIDAAAA despues: 0.002252063015475869\n",
      "loss en el callback: 0.0002196282584918663, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "ejemplar: [[0.91321123]\n",
      " [0.91142344]\n",
      " [0.90928668]\n",
      " [0.90681815]\n",
      " [0.90473938]\n",
      " [0.9033401 ]\n",
      " [0.90185779]\n",
      " [0.90125245]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9307145892932484\n",
      "Predicci√≥n : [[0.89970106]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[[0.91321123]\n",
      "  [0.91142344]\n",
      "  [0.90928668]\n",
      "  [0.90681815]\n",
      "  [0.90473938]\n",
      "  [0.9033401 ]\n",
      "  [0.90185779]\n",
      "  [0.90125245]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009618402109481394\n",
      "Predicci√≥n post entrenamiento : [[0.8997944]]\n",
      "PERDIDAAAA despues: 0.0009560592588968575\n",
      "loss en el callback: 0.00034746446181088686, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "ejemplar: [[0.91142344]\n",
      " [0.90928668]\n",
      " [0.90681815]\n",
      " [0.90473938]\n",
      " [0.9033401 ]\n",
      " [0.90185779]\n",
      " [0.90125245]\n",
      " [0.89970106]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.908967222276737\n",
      "Predicci√≥n : [[0.8980925]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[[0.91142344]\n",
      "  [0.90928668]\n",
      "  [0.90681815]\n",
      "  [0.90473938]\n",
      "  [0.9033401 ]\n",
      "  [0.90185779]\n",
      "  [0.90125245]\n",
      "  [0.89970106]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00011825885303551331\n",
      "Predicci√≥n post entrenamiento : [[0.89794976]]\n",
      "PERDIDAAAA despues: 0.00012138402234995738\n",
      "loss en el callback: 0.0008348050760105252, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "ejemplar: [[0.90928668]\n",
      " [0.90681815]\n",
      " [0.90473938]\n",
      " [0.9033401 ]\n",
      " [0.90185779]\n",
      " [0.90125245]\n",
      " [0.89970106]\n",
      " [0.89809251]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8816379650841193\n",
      "Predicci√≥n : [[0.8962475]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[[0.90928668]\n",
      "  [0.90681815]\n",
      "  [0.90473938]\n",
      "  [0.9033401 ]\n",
      "  [0.90185779]\n",
      "  [0.90125245]\n",
      "  [0.89970106]\n",
      "  [0.89809251]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00021343794651329517\n",
      "Predicci√≥n post entrenamiento : [[0.8957969]]\n",
      "PERDIDAAAA despues: 0.00020047457655891776\n",
      "loss en el callback: 0.00800508912652731, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "ejemplar: [[0.90681815]\n",
      " [0.90473938]\n",
      " [0.9033401 ]\n",
      " [0.90185779]\n",
      " [0.90125245]\n",
      " [0.89970106]\n",
      " [0.89809251]\n",
      " [0.89624751]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8487268177153953\n",
      "Predicci√≥n : [[0.89421475]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[[0.90681815]\n",
      "  [0.90473938]\n",
      "  [0.9033401 ]\n",
      "  [0.90185779]\n",
      "  [0.90125245]\n",
      "  [0.89970106]\n",
      "  [0.89809251]\n",
      "  [0.89624751]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002069152658805251\n",
      "Predicci√≥n post entrenamiento : [[0.89412826]]\n",
      "PERDIDAAAA despues: 0.002061292063444853\n",
      "loss en el callback: 0.0003397394029889256, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "ejemplar: [[0.90473938]\n",
      " [0.9033401 ]\n",
      " [0.90185779]\n",
      " [0.90125245]\n",
      " [0.89970106]\n",
      " [0.89809251]\n",
      " [0.89624751]\n",
      " [0.89421475]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.875260685634848\n",
      "Predicci√≥n : [[0.89278823]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[[0.90473938]\n",
      "  [0.9033401 ]\n",
      "  [0.90185779]\n",
      "  [0.90125245]\n",
      "  [0.89970106]\n",
      "  [0.89809251]\n",
      "  [0.89624751]\n",
      "  [0.89421475]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000307213980704546\n",
      "Predicci√≥n post entrenamiento : [[0.8919052]]\n",
      "PERDIDAAAA despues: 0.0002770386345218867\n",
      "loss en el callback: 0.027035977691411972, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "ejemplar: [[0.9033401 ]\n",
      " [0.90185779]\n",
      " [0.90125245]\n",
      " [0.89970106]\n",
      " [0.89809251]\n",
      " [0.89624751]\n",
      " [0.89421475]\n",
      " [0.89278823]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9612395688424776\n",
      "Predicci√≥n : [[0.89073163]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[[0.9033401 ]\n",
      "  [0.90185779]\n",
      "  [0.90125245]\n",
      "  [0.89970106]\n",
      "  [0.89809251]\n",
      "  [0.89624751]\n",
      "  [0.89421475]\n",
      "  [0.89278823]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004971370100975037\n",
      "Predicci√≥n post entrenamiento : [[0.8912001]]\n",
      "PERDIDAAAA despues: 0.004905524663627148\n",
      "loss en el callback: 0.009021857753396034, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "ejemplar: [[0.90185779]\n",
      " [0.90125245]\n",
      " [0.89970106]\n",
      " [0.89809251]\n",
      " [0.89624751]\n",
      " [0.89421475]\n",
      " [0.89278823]\n",
      " [0.89073163]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9925021123407926\n",
      "Predicci√≥n : [[0.89001]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[[0.90185779]\n",
      "  [0.90125245]\n",
      "  [0.89970106]\n",
      "  [0.89809251]\n",
      "  [0.89624751]\n",
      "  [0.89421475]\n",
      "  [0.89278823]\n",
      "  [0.89073163]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010504629462957382\n",
      "Predicci√≥n post entrenamiento : [[0.89097446]]\n",
      "PERDIDAAAA despues: 0.010307859629392624\n",
      "loss en el callback: 0.04894673451781273, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "ejemplar: [[0.90125245]\n",
      " [0.89970106]\n",
      " [0.89809251]\n",
      " [0.89624751]\n",
      " [0.89421475]\n",
      " [0.89278823]\n",
      " [0.89073163]\n",
      " [0.89001   ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.969048316129792\n",
      "Predicci√≥n : [[0.88977784]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[[0.90125245]\n",
      "  [0.89970106]\n",
      "  [0.89809251]\n",
      "  [0.89624751]\n",
      "  [0.89421475]\n",
      "  [0.89278823]\n",
      "  [0.89073163]\n",
      "  [0.89001   ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006283809430897236\n",
      "Predicci√≥n post entrenamiento : [[0.8899185]]\n",
      "PERDIDAAAA despues: 0.0062615275382995605\n",
      "loss en el callback: 0.0008825598633848131, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "ejemplar: [[0.89970106]\n",
      " [0.89809251]\n",
      " [0.89624751]\n",
      " [0.89421475]\n",
      " [0.89278823]\n",
      " [0.89073163]\n",
      " [0.89001   ]\n",
      " [0.88977784]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9715476120161949\n",
      "Predicci√≥n : [[0.8884665]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[[0.89970106]\n",
      "  [0.89809251]\n",
      "  [0.89624751]\n",
      "  [0.89421475]\n",
      "  [0.89278823]\n",
      "  [0.89073163]\n",
      "  [0.89001   ]\n",
      "  [0.88977784]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006902473513036966\n",
      "Predicci√≥n post entrenamiento : [[0.88881814]]\n",
      "PERDIDAAAA despues: 0.006844163406640291\n",
      "loss en el callback: 0.00606877077370882, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "ejemplar: [[0.89809251]\n",
      " [0.89624751]\n",
      " [0.89421475]\n",
      " [0.89278823]\n",
      " [0.89073163]\n",
      " [0.89001   ]\n",
      " [0.88977784]\n",
      " [0.88846648]]\n",
      "ejemplar: (8, 1)\n",
      "y: 1.0\n",
      "Predicci√≥n : [[0.88735753]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[[0.89809251]\n",
      "  [0.89624751]\n",
      "  [0.89421475]\n",
      "  [0.89278823]\n",
      "  [0.89073163]\n",
      "  [0.89001   ]\n",
      "  [0.88977784]\n",
      "  [0.88846648]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012688325718045235\n",
      "Predicci√≥n post entrenamiento : [[0.88786614]]\n",
      "PERDIDAAAA despues: 0.01257400307804346\n",
      "loss en el callback: 0.011598607525229454, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "ejemplar: [[0.89624751]\n",
      " [0.89421475]\n",
      " [0.89278823]\n",
      " [0.89073163]\n",
      " [0.89001   ]\n",
      " [0.88977784]\n",
      " [0.88846648]\n",
      " [0.88735753]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9800636522775721\n",
      "Predicci√≥n : [[0.88643503]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[[0.89624751]\n",
      "  [0.89421475]\n",
      "  [0.89278823]\n",
      "  [0.89073163]\n",
      "  [0.89001   ]\n",
      "  [0.88977784]\n",
      "  [0.88846648]\n",
      "  [0.88735753]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008766323328018188\n",
      "Predicci√≥n post entrenamiento : [[0.8864645]]\n",
      "PERDIDAAAA despues: 0.008760809898376465\n",
      "loss en el callback: 3.8420239434344694e-05, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "ejemplar: [[0.89421475]\n",
      " [0.89278823]\n",
      " [0.89073163]\n",
      " [0.89001   ]\n",
      " [0.88977784]\n",
      " [0.88846648]\n",
      " [0.88735753]\n",
      " [0.88643503]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.911738568848911\n",
      "Predicci√≥n : [[0.8851603]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[[0.89421475]\n",
      "  [0.89278823]\n",
      "  [0.89073163]\n",
      "  [0.89001   ]\n",
      "  [0.88977784]\n",
      "  [0.88846648]\n",
      "  [0.88735753]\n",
      "  [0.88643503]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007064032251946628\n",
      "Predicci√≥n post entrenamiento : [[0.8852916]]\n",
      "PERDIDAAAA despues: 0.000699443684425205\n",
      "loss en el callback: 0.000757573579903692, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "ejemplar: [[0.89278823]\n",
      " [0.89073163]\n",
      " [0.89001   ]\n",
      " [0.88977784]\n",
      " [0.88846648]\n",
      " [0.88735753]\n",
      " [0.88643503]\n",
      " [0.88516033]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8910857934126422\n",
      "Predicci√≥n : [[0.8842056]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[[0.89278823]\n",
      "  [0.89073163]\n",
      "  [0.89001   ]\n",
      "  [0.88977784]\n",
      "  [0.88846648]\n",
      "  [0.88735753]\n",
      "  [0.88643503]\n",
      "  [0.88516033]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.733747846330516e-05\n",
      "Predicci√≥n post entrenamiento : [[0.8845072]]\n",
      "PERDIDAAAA despues: 4.3278298107907176e-05\n",
      "loss en el callback: 0.00642930855974555, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "ejemplar: [[0.89073163]\n",
      " [0.89001   ]\n",
      " [0.88977784]\n",
      " [0.88846648]\n",
      " [0.88735753]\n",
      " [0.88643503]\n",
      " [0.88516033]\n",
      " [0.88420558]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9181053259687657\n",
      "Predicci√≥n : [[0.88350976]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[[0.89073163]\n",
      "  [0.89001   ]\n",
      "  [0.88977784]\n",
      "  [0.88846648]\n",
      "  [0.88735753]\n",
      "  [0.88643503]\n",
      "  [0.88516033]\n",
      "  [0.88420558]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011968520702794194\n",
      "Predicci√≥n post entrenamiento : [[0.8839433]]\n",
      "PERDIDAAAA despues: 0.0011670412495732307\n",
      "loss en el callback: 0.012899844907224178, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "ejemplar: [[0.89001   ]\n",
      " [0.88977784]\n",
      " [0.88846648]\n",
      " [0.88735753]\n",
      " [0.88643503]\n",
      " [0.88516033]\n",
      " [0.88420558]\n",
      " [0.88350976]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9450165163483527\n",
      "Predicci√≥n : [[0.88323253]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[[0.89001   ]\n",
      "  [0.88977784]\n",
      "  [0.88846648]\n",
      "  [0.88735753]\n",
      "  [0.88643503]\n",
      "  [0.88516033]\n",
      "  [0.88420558]\n",
      "  [0.88350976]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00381725886836648\n",
      "Predicci√≥n post entrenamiento : [[0.8828992]]\n",
      "PERDIDAAAA despues: 0.0038585562724620104\n",
      "loss en el callback: 0.004639295395463705, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "ejemplar: [[0.88977784]\n",
      " [0.88846648]\n",
      " [0.88735753]\n",
      " [0.88643503]\n",
      " [0.88516033]\n",
      " [0.88420558]\n",
      " [0.88350976]\n",
      " [0.88323253]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9718193645514037\n",
      "Predicci√≥n : [[0.8821375]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[[0.88977784]\n",
      "  [0.88846648]\n",
      "  [0.88735753]\n",
      "  [0.88643503]\n",
      "  [0.88516033]\n",
      "  [0.88420558]\n",
      "  [0.88350976]\n",
      "  [0.88323253]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00804283656179905\n",
      "Predicci√≥n post entrenamiento : [[0.88221765]]\n",
      "PERDIDAAAA despues: 0.008028463460505009\n",
      "loss en el callback: 0.00027039230917580426, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "ejemplar: [[0.88846648]\n",
      " [0.88735753]\n",
      " [0.88643503]\n",
      " [0.88516033]\n",
      " [0.88420558]\n",
      " [0.88350976]\n",
      " [0.88323253]\n",
      " [0.88213748]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9829067192737589\n",
      "Predicci√≥n : [[0.88126]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[[0.88846648]\n",
      "  [0.88735753]\n",
      "  [0.88643503]\n",
      "  [0.88516033]\n",
      "  [0.88420558]\n",
      "  [0.88350976]\n",
      "  [0.88323253]\n",
      "  [0.88213748]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010332056321203709\n",
      "Predicci√≥n post entrenamiento : [[0.88192004]]\n",
      "PERDIDAAAA despues: 0.010198305360972881\n",
      "loss en el callback: 0.026420168578624725, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "ejemplar: [[0.88735753]\n",
      " [0.88643503]\n",
      " [0.88516033]\n",
      " [0.88420558]\n",
      " [0.88350976]\n",
      " [0.88323253]\n",
      " [0.88213748]\n",
      " [0.88125998]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9782785805154182\n",
      "Predicci√≥n : [[0.88105375]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[[0.88735753]\n",
      "  [0.88643503]\n",
      "  [0.88516033]\n",
      "  [0.88420558]\n",
      "  [0.88350976]\n",
      "  [0.88323253]\n",
      "  [0.88213748]\n",
      "  [0.88125998]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009452668018639088\n",
      "Predicci√≥n post entrenamiento : [[0.8813617]]\n",
      "PERDIDAAAA despues: 0.009392877109348774\n",
      "loss en el callback: 0.005205105524510145, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "ejemplar: [[0.05029815]\n",
      " [0.00860651]\n",
      " [0.        ]\n",
      " [0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.049424632939554\n",
      "Predicci√≥n : [[0.21383911]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.05029815]\n",
      "  [0.00860651]\n",
      "  [0.        ]\n",
      "  [0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.027032122015953064\n",
      "Predicci√≥n post entrenamiento : [[0.17672211]]\n",
      "PERDIDAAAA despues: 0.016204647719860077\n",
      "loss en el callback: 0.02765289507806301, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "ejemplar: [[0.00860651]\n",
      " [0.        ]\n",
      " [0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.21383911]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.10789185692558968\n",
      "Predicci√≥n : [[0.17176487]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.00860651]\n",
      "  [0.        ]\n",
      "  [0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.21383911]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004079760983586311\n",
      "Predicci√≥n post entrenamiento : [[0.1592674]]\n",
      "PERDIDAAAA despues: 0.0026394459418952465\n",
      "loss en el callback: 0.003363576252013445, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "ejemplar: [[0.        ]\n",
      " [0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.21383911]\n",
      " [0.17176487]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.13719610119365802\n",
      "Predicci√≥n : [[0.16388296]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[[0.        ]\n",
      "  [0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.21383911]\n",
      "  [0.17176487]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007121886010281742\n",
      "Predicci√≥n post entrenamiento : [[0.15519229]]\n",
      "PERDIDAAAA despues: 0.00032386291422881186\n",
      "loss en el callback: 0.0028159087523818016, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "ejemplar: [[0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.21383911]\n",
      " [0.17176487]\n",
      " [0.16388296]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.13733736574375907\n",
      "Predicci√≥n : [[0.16481078]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[[0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.21383911]\n",
      "  [0.17176487]\n",
      "  [0.16388296]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007547879940830171\n",
      "Predicci√≥n post entrenamiento : [[0.1652525]]\n",
      "PERDIDAAAA despues: 0.0007792547694407403\n",
      "loss en el callback: 2.3583826987305656e-05, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "ejemplar: [[0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.21383911]\n",
      " [0.17176487]\n",
      " [0.16388296]\n",
      " [0.16481078]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.13388569841244483\n",
      "Predicci√≥n : [[0.17412835]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[[0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.21383911]\n",
      "  [0.17176487]\n",
      "  [0.16388296]\n",
      "  [0.16481078]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016194714698940516\n",
      "Predicci√≥n post entrenamiento : [[0.17442766]]\n",
      "PERDIDAAAA despues: 0.0016436506994068623\n",
      "loss en el callback: 1.8791717593558133e-05, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "ejemplar: [[0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.21383911]\n",
      " [0.17176487]\n",
      " [0.16388296]\n",
      " [0.16481078]\n",
      " [0.17412835]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.12684109919971556\n",
      "Predicci√≥n : [[0.18585452]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[[0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.21383911]\n",
      "  [0.17176487]\n",
      "  [0.16388296]\n",
      "  [0.16481078]\n",
      "  [0.17412835]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003482584375888109\n",
      "Predicci√≥n post entrenamiento : [[0.18207793]]\n",
      "PERDIDAAAA despues: 0.0030511075165122747\n",
      "loss en el callback: 0.0028724216390401125, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "ejemplar: [[0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.21383911]\n",
      " [0.17176487]\n",
      " [0.16388296]\n",
      " [0.16481078]\n",
      " [0.17412835]\n",
      " [0.18585452]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14756061137847282\n",
      "Predicci√≥n : [[0.19984247]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[[0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.21383911]\n",
      "  [0.17176487]\n",
      "  [0.16388296]\n",
      "  [0.16481078]\n",
      "  [0.17412835]\n",
      "  [0.18585452]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002733392408117652\n",
      "Predicci√≥n post entrenamiento : [[0.19776437]]\n",
      "PERDIDAAAA despues: 0.002520417096093297\n",
      "loss en el callback: 0.0012705570552498102, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "ejemplar: [[0.0202993 ]\n",
      " [0.21383911]\n",
      " [0.17176487]\n",
      " [0.16388296]\n",
      " [0.16481078]\n",
      " [0.17412835]\n",
      " [0.18585452]\n",
      " [0.19984247]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19604423494871648\n",
      "Predicci√≥n : [[0.2219122]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[[0.0202993 ]\n",
      "  [0.21383911]\n",
      "  [0.17176487]\n",
      "  [0.16388296]\n",
      "  [0.16481078]\n",
      "  [0.17412835]\n",
      "  [0.18585452]\n",
      "  [0.19984247]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006691518356092274\n",
      "Predicci√≥n post entrenamiento : [[0.22009708]]\n",
      "PERDIDAAAA despues: 0.0005785392713733017\n",
      "loss en el callback: 0.000938425597269088, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "ejemplar: [[0.21383911]\n",
      " [0.17176487]\n",
      " [0.16388296]\n",
      " [0.16481078]\n",
      " [0.17412835]\n",
      " [0.18585452]\n",
      " [0.19984247]\n",
      " [0.22191221]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.21688968214535215\n",
      "Predicci√≥n : [[0.25048986]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[[0.21383911]\n",
      "  [0.17176487]\n",
      "  [0.16388296]\n",
      "  [0.16481078]\n",
      "  [0.17412835]\n",
      "  [0.18585452]\n",
      "  [0.19984247]\n",
      "  [0.22191221]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001128972158767283\n",
      "Predicci√≥n post entrenamiento : [[0.24739383]]\n",
      "PERDIDAAAA despues: 0.0009305033017881215\n",
      "loss en el callback: 0.003048752201721072, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "ejemplar: [[0.17176487]\n",
      " [0.16388296]\n",
      " [0.16481078]\n",
      " [0.17412835]\n",
      " [0.18585452]\n",
      " [0.19984247]\n",
      " [0.22191221]\n",
      " [0.25048986]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2100969529683796\n",
      "Predicci√≥n : [[0.24075125]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[[0.17176487]\n",
      "  [0.16388296]\n",
      "  [0.16481078]\n",
      "  [0.17412835]\n",
      "  [0.18585452]\n",
      "  [0.19984247]\n",
      "  [0.22191221]\n",
      "  [0.25048986]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009396858513355255\n",
      "Predicci√≥n post entrenamiento : [[0.24025504]]\n",
      "PERDIDAAAA despues: 0.0009095102432183921\n",
      "loss en el callback: 0.00013076438335701823, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "ejemplar: [[0.16388296]\n",
      " [0.16481078]\n",
      " [0.17412835]\n",
      " [0.18585452]\n",
      " [0.19984247]\n",
      " [0.22191221]\n",
      " [0.25048986]\n",
      " [0.24075125]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2026778474621132\n",
      "Predicci√≥n : [[0.24306616]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[[0.16388296]\n",
      "  [0.16481078]\n",
      "  [0.17412835]\n",
      "  [0.18585452]\n",
      "  [0.19984247]\n",
      "  [0.22191221]\n",
      "  [0.25048986]\n",
      "  [0.24075125]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016312160296365619\n",
      "Predicci√≥n post entrenamiento : [[0.24035235]]\n",
      "PERDIDAAAA despues: 0.001419368083588779\n",
      "loss en el callback: 0.00351092591881752, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "ejemplar: [[0.16481078]\n",
      " [0.17412835]\n",
      " [0.18585452]\n",
      " [0.19984247]\n",
      " [0.22191221]\n",
      " [0.25048986]\n",
      " [0.24075125]\n",
      " [0.24306616]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19463236562655295\n",
      "Predicci√≥n : [[0.24680324]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[[0.16481078]\n",
      "  [0.17412835]\n",
      "  [0.18585452]\n",
      "  [0.19984247]\n",
      "  [0.22191221]\n",
      "  [0.25048986]\n",
      "  [0.24075125]\n",
      "  [0.24306616]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0027218000032007694\n",
      "Predicci√≥n post entrenamiento : [[0.24570048]]\n",
      "PERDIDAAAA despues: 0.002607952104881406\n",
      "loss en el callback: 0.000937328499276191, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "ejemplar: [[0.17412835]\n",
      " [0.18585452]\n",
      " [0.19984247]\n",
      " [0.22191221]\n",
      " [0.25048986]\n",
      " [0.24075125]\n",
      " [0.24306616]\n",
      " [0.24680324]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19407351685692253\n",
      "Predicci√≥n : [[0.25443903]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[[0.17412835]\n",
      "  [0.18585452]\n",
      "  [0.19984247]\n",
      "  [0.22191221]\n",
      "  [0.25048986]\n",
      "  [0.24075125]\n",
      "  [0.24306616]\n",
      "  [0.24680324]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003643995150923729\n",
      "Predicci√≥n post entrenamiento : [[0.25240365]]\n",
      "PERDIDAAAA despues: 0.003402404487133026\n",
      "loss en el callback: 0.0031917081214487553, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "ejemplar: [[0.18585452]\n",
      " [0.19984247]\n",
      " [0.22191221]\n",
      " [0.25048986]\n",
      " [0.24075125]\n",
      " [0.24306616]\n",
      " [0.24680324]\n",
      " [0.25443903]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.20100130115322212\n",
      "Predicci√≥n : [[0.26177174]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[[0.18585452]\n",
      "  [0.19984247]\n",
      "  [0.22191221]\n",
      "  [0.25048986]\n",
      "  [0.24075125]\n",
      "  [0.24306616]\n",
      "  [0.24680324]\n",
      "  [0.25443903]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003693046048283577\n",
      "Predicci√≥n post entrenamiento : [[0.2596088]]\n",
      "PERDIDAAAA despues: 0.0034348394256085157\n",
      "loss en el callback: 0.0041531892493367195, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "ejemplar: [[0.19984247]\n",
      " [0.22191221]\n",
      " [0.25048986]\n",
      " [0.24075125]\n",
      " [0.24306616]\n",
      " [0.24680324]\n",
      " [0.25443903]\n",
      " [0.26177174]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19663820581116015\n",
      "Predicci√≥n : [[0.26893952]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[[0.19984247]\n",
      "  [0.22191221]\n",
      "  [0.25048986]\n",
      "  [0.24075125]\n",
      "  [0.24306616]\n",
      "  [0.24680324]\n",
      "  [0.25443903]\n",
      "  [0.26177174]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005227480083703995\n",
      "Predicci√≥n post entrenamiento : [[0.2662933]]\n",
      "PERDIDAAAA despues: 0.00485182972624898\n",
      "loss en el callback: 0.006700648460537195, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "ejemplar: [[0.22191221]\n",
      " [0.25048986]\n",
      " [0.24075125]\n",
      " [0.24306616]\n",
      " [0.24680324]\n",
      " [0.25443903]\n",
      " [0.26177174]\n",
      " [0.26893952]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1809842308307365\n",
      "Predicci√≥n : [[0.27482554]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[[0.22191221]\n",
      "  [0.25048986]\n",
      "  [0.24075125]\n",
      "  [0.24306616]\n",
      "  [0.24680324]\n",
      "  [0.25443903]\n",
      "  [0.26177174]\n",
      "  [0.26893952]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008806192316114902\n",
      "Predicci√≥n post entrenamiento : [[0.2727034]]\n",
      "PERDIDAAAA despues: 0.008412407711148262\n",
      "loss en el callback: 0.005234746262431145, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "ejemplar: [[0.25048986]\n",
      " [0.24075125]\n",
      " [0.24306616]\n",
      " [0.24680324]\n",
      " [0.25443903]\n",
      " [0.26177174]\n",
      " [0.26893952]\n",
      " [0.27482554]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1653904097109329\n",
      "Predicci√≥n : [[0.27824518]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[[0.25048986]\n",
      "  [0.24075125]\n",
      "  [0.24306616]\n",
      "  [0.24680324]\n",
      "  [0.25443903]\n",
      "  [0.26177174]\n",
      "  [0.26893952]\n",
      "  [0.27482554]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01273619756102562\n",
      "Predicci√≥n post entrenamiento : [[0.27651533]]\n",
      "PERDIDAAAA despues: 0.012348747812211514\n",
      "loss en el callback: 0.004815549124032259, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "ejemplar: [[0.24075125]\n",
      " [0.24306616]\n",
      " [0.24680324]\n",
      " [0.25443903]\n",
      " [0.26177174]\n",
      " [0.26893952]\n",
      " [0.27482554]\n",
      " [0.27824518]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14985674245174896\n",
      "Predicci√≥n : [[0.27697277]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[[0.24075125]\n",
      "  [0.24306616]\n",
      "  [0.24680324]\n",
      "  [0.25443903]\n",
      "  [0.26177174]\n",
      "  [0.26893952]\n",
      "  [0.27482554]\n",
      "  [0.27824518]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016158483922481537\n",
      "Predicci√≥n post entrenamiento : [[0.27373755]]\n",
      "PERDIDAAAA despues: 0.01534645352512598\n",
      "loss en el callback: 0.013873405754566193, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "ejemplar: [[0.24306616]\n",
      " [0.24680324]\n",
      " [0.25443903]\n",
      " [0.26177174]\n",
      " [0.26893952]\n",
      " [0.27482554]\n",
      " [0.27824518]\n",
      " [0.27697277]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.15043111479831345\n",
      "Predicci√≥n : [[0.2771346]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[[0.24306616]\n",
      "  [0.24680324]\n",
      "  [0.25443903]\n",
      "  [0.26177174]\n",
      "  [0.26893952]\n",
      "  [0.27482554]\n",
      "  [0.27824518]\n",
      "  [0.27697277]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01605377346277237\n",
      "Predicci√≥n post entrenamiento : [[0.27342787]]\n",
      "PERDIDAAAA despues: 0.01512820366770029\n",
      "loss en el callback: 0.01957716792821884, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "ejemplar: [[0.24680324]\n",
      " [0.25443903]\n",
      " [0.26177174]\n",
      " [0.26893952]\n",
      " [0.27482554]\n",
      " [0.27824518]\n",
      " [0.27697277]\n",
      " [0.2771346 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.16711352675062616\n",
      "Predicci√≥n : [[0.27744687]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[[0.24680324]\n",
      "  [0.25443903]\n",
      "  [0.26177174]\n",
      "  [0.26893952]\n",
      "  [0.27482554]\n",
      "  [0.27824518]\n",
      "  [0.27697277]\n",
      "  [0.2771346 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012173445895314217\n",
      "Predicci√≥n post entrenamiento : [[0.2746667]]\n",
      "PERDIDAAAA despues: 0.011567683890461922\n",
      "loss en el callback: 0.0135086914524436, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "ejemplar: [[0.25443903]\n",
      " [0.26177174]\n",
      " [0.26893952]\n",
      " [0.27482554]\n",
      " [0.27824518]\n",
      " [0.27697277]\n",
      " [0.2771346 ]\n",
      " [0.27744687]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2022703535675908\n",
      "Predicci√≥n : [[0.27897716]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[[0.25443903]\n",
      "  [0.26177174]\n",
      "  [0.26893952]\n",
      "  [0.27482554]\n",
      "  [0.27824518]\n",
      "  [0.27697277]\n",
      "  [0.2771346 ]\n",
      "  [0.27744687]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005883932579308748\n",
      "Predicci√≥n post entrenamiento : [[0.27824762]]\n",
      "PERDIDAAAA despues: 0.005772545002400875\n",
      "loss en el callback: 0.001258733682334423, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "ejemplar: [[0.26177174]\n",
      " [0.26893952]\n",
      " [0.27482554]\n",
      " [0.27824518]\n",
      " [0.27697277]\n",
      " [0.2771346 ]\n",
      " [0.27744687]\n",
      " [0.27897716]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.25590159524920725\n",
      "Predicci√≥n : [[0.2818623]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[[0.26177174]\n",
      "  [0.26893952]\n",
      "  [0.27482554]\n",
      "  [0.27824518]\n",
      "  [0.27697277]\n",
      "  [0.2771346 ]\n",
      "  [0.27744687]\n",
      "  [0.27897716]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006739571108482778\n",
      "Predicci√≥n post entrenamiento : [[0.2817886]]\n",
      "PERDIDAAAA despues: 0.0006701358943246305\n",
      "loss en el callback: 1.4440942322835326e-05, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "ejemplar: [[0.26893952]\n",
      " [0.27482554]\n",
      " [0.27824518]\n",
      " [0.27697277]\n",
      " [0.2771346 ]\n",
      " [0.27744687]\n",
      " [0.27897716]\n",
      " [0.28186229]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.292688203599549\n",
      "Predicci√≥n : [[0.2845424]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[[0.26893952]\n",
      "  [0.27482554]\n",
      "  [0.27824518]\n",
      "  [0.27697277]\n",
      "  [0.2771346 ]\n",
      "  [0.27744687]\n",
      "  [0.27897716]\n",
      "  [0.28186229]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.635372119490057e-05\n",
      "Predicci√≥n post entrenamiento : [[0.28463218]]\n",
      "PERDIDAAAA despues: 6.489937368314713e-05\n",
      "loss en el callback: 1.6904665244510397e-05, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "ejemplar: [[0.27482554]\n",
      " [0.27824518]\n",
      " [0.27697277]\n",
      " [0.2771346 ]\n",
      " [0.27744687]\n",
      " [0.27897716]\n",
      " [0.28186229]\n",
      " [0.28454241]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31263017861861575\n",
      "Predicci√≥n : [[0.28634548]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[[0.27482554]\n",
      "  [0.27824518]\n",
      "  [0.27697277]\n",
      "  [0.2771346 ]\n",
      "  [0.27744687]\n",
      "  [0.27897716]\n",
      "  [0.28186229]\n",
      "  [0.28454241]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006908851792104542\n",
      "Predicci√≥n post entrenamiento : [[0.28672028]]\n",
      "PERDIDAAAA despues: 0.0006713229813612998\n",
      "loss en el callback: 0.0003380474227014929, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "ejemplar: [[0.27824518]\n",
      " [0.27697277]\n",
      " [0.2771346 ]\n",
      " [0.27744687]\n",
      " [0.27897716]\n",
      " [0.28186229]\n",
      " [0.28454241]\n",
      " [0.28634548]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3109388849116374\n",
      "Predicci√≥n : [[0.2874942]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[[0.27824518]\n",
      "  [0.27697277]\n",
      "  [0.2771346 ]\n",
      "  [0.27744687]\n",
      "  [0.27897716]\n",
      "  [0.28186229]\n",
      "  [0.28454241]\n",
      "  [0.28634548]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005496531375683844\n",
      "Predicci√≥n post entrenamiento : [[0.28762564]]\n",
      "PERDIDAAAA despues: 0.0005435078055597842\n",
      "loss en el callback: 4.351781899458729e-05, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "ejemplar: [[0.27697277]\n",
      " [0.2771346 ]\n",
      " [0.27744687]\n",
      " [0.27897716]\n",
      " [0.28186229]\n",
      " [0.28454241]\n",
      " [0.28634548]\n",
      " [0.28749421]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2876143224786136\n",
      "Predicci√≥n : [[0.28789482]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[[0.27697277]\n",
      "  [0.2771346 ]\n",
      "  [0.27744687]\n",
      "  [0.27897716]\n",
      "  [0.28186229]\n",
      "  [0.28454241]\n",
      "  [0.28634548]\n",
      "  [0.28749421]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.867994611387985e-08\n",
      "Predicci√≥n post entrenamiento : [[0.2887822]]\n",
      "PERDIDAAAA despues: 1.3639750022775843e-06\n",
      "loss en el callback: 0.0030745414551347494, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "ejemplar: [[0.2771346 ]\n",
      " [0.27744687]\n",
      " [0.27897716]\n",
      " [0.28186229]\n",
      " [0.28454241]\n",
      " [0.28634548]\n",
      " [0.28749421]\n",
      " [0.28789482]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.280161647237227\n",
      "Predicci√≥n : [[0.289584]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[[0.2771346 ]\n",
      "  [0.27744687]\n",
      "  [0.27897716]\n",
      "  [0.28186229]\n",
      "  [0.28454241]\n",
      "  [0.28634548]\n",
      "  [0.28749421]\n",
      "  [0.28789482]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.878090011421591e-05\n",
      "Predicci√≥n post entrenamiento : [[0.28947723]]\n",
      "PERDIDAAAA despues: 8.678003359818831e-05\n",
      "loss en el callback: 3.411677971598692e-05, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "ejemplar: [[0.27744687]\n",
      " [0.27897716]\n",
      " [0.28186229]\n",
      " [0.28454241]\n",
      " [0.28634548]\n",
      " [0.28749421]\n",
      " [0.28789482]\n",
      " [0.28958401]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2885808591874776\n",
      "Predicci√≥n : [[0.29057813]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[[0.27744687]\n",
      "  [0.27897716]\n",
      "  [0.28186229]\n",
      "  [0.28454241]\n",
      "  [0.28634548]\n",
      "  [0.28749421]\n",
      "  [0.28789482]\n",
      "  [0.28958401]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.989056494901888e-06\n",
      "Predicci√≥n post entrenamiento : [[0.29002893]]\n",
      "PERDIDAAAA despues: 2.096892330882838e-06\n",
      "loss en el callback: 0.000824707793071866, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "ejemplar: [[0.27897716]\n",
      " [0.28186229]\n",
      " [0.28454241]\n",
      " [0.28634548]\n",
      " [0.28749421]\n",
      " [0.28789482]\n",
      " [0.28958401]\n",
      " [0.29057813]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2824628234730068\n",
      "Predicci√≥n : [[0.29143676]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[[0.27897716]\n",
      "  [0.28186229]\n",
      "  [0.28454241]\n",
      "  [0.28634548]\n",
      "  [0.28749421]\n",
      "  [0.28789482]\n",
      "  [0.28958401]\n",
      "  [0.29057813]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.053135388763621e-05\n",
      "Predicci√≥n post entrenamiento : [[0.2908688]]\n",
      "PERDIDAAAA despues: 7.066005491651595e-05\n",
      "loss en el callback: 0.0009310970199294388, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "ejemplar: [[0.28186229]\n",
      " [0.28454241]\n",
      " [0.28634548]\n",
      " [0.28749421]\n",
      " [0.28789482]\n",
      " [0.28958401]\n",
      " [0.29057813]\n",
      " [0.29143676]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.26180754009381474\n",
      "Predicci√≥n : [[0.2923279]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[[0.28186229]\n",
      "  [0.28454241]\n",
      "  [0.28634548]\n",
      "  [0.28749421]\n",
      "  [0.28789482]\n",
      "  [0.28958401]\n",
      "  [0.29057813]\n",
      "  [0.29143676]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009314935887232423\n",
      "Predicci√≥n post entrenamiento : [[0.29182148]]\n",
      "PERDIDAAAA despues: 0.0009008371271193027\n",
      "loss en el callback: 0.0009342916891910136, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "ejemplar: [[0.28454241]\n",
      " [0.28634548]\n",
      " [0.28749421]\n",
      " [0.28789482]\n",
      " [0.28958401]\n",
      " [0.29057813]\n",
      " [0.29143676]\n",
      " [0.29232791]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2801212859371977\n",
      "Predicci√≥n : [[0.2929962]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[[0.28454241]\n",
      "  [0.28634548]\n",
      "  [0.28749421]\n",
      "  [0.28789482]\n",
      "  [0.28958401]\n",
      "  [0.29057813]\n",
      "  [0.29143676]\n",
      "  [0.29232791]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00016576307825744152\n",
      "Predicci√≥n post entrenamiento : [[0.2923747]]\n",
      "PERDIDAAAA despues: 0.0001501459046266973\n",
      "loss en el callback: 0.001366445212624967, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "ejemplar: [[0.28634548]\n",
      " [0.28749421]\n",
      " [0.28789482]\n",
      " [0.28958401]\n",
      " [0.29057813]\n",
      " [0.29143676]\n",
      " [0.29232791]\n",
      " [0.2929962 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3374040610031557\n",
      "Predicci√≥n : [[0.2932439]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[[0.28634548]\n",
      "  [0.28749421]\n",
      "  [0.28789482]\n",
      "  [0.28958401]\n",
      "  [0.29057813]\n",
      "  [0.29143676]\n",
      "  [0.29232791]\n",
      "  [0.2929962 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001950119505636394\n",
      "Predicci√≥n post entrenamiento : [[0.29386416]]\n",
      "PERDIDAAAA despues: 0.0018957238644361496\n",
      "loss en el callback: 0.0015987074002623558, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "ejemplar: [[0.28749421]\n",
      " [0.28789482]\n",
      " [0.28958401]\n",
      " [0.29057813]\n",
      " [0.29143676]\n",
      " [0.29232791]\n",
      " [0.2929962 ]\n",
      " [0.29324391]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3482298154676272\n",
      "Predicci√≥n : [[0.29456788]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[[0.28749421]\n",
      "  [0.28789482]\n",
      "  [0.28958401]\n",
      "  [0.29057813]\n",
      "  [0.29143676]\n",
      "  [0.29232791]\n",
      "  [0.2929962 ]\n",
      "  [0.29324391]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002879603998735547\n",
      "Predicci√≥n post entrenamiento : [[0.29577562]]\n",
      "PERDIDAAAA despues: 0.002751443535089493\n",
      "loss en el callback: 0.007426139898598194, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "ejemplar: [[0.28789482]\n",
      " [0.28958401]\n",
      " [0.29057813]\n",
      " [0.29143676]\n",
      " [0.29232791]\n",
      " [0.2929962 ]\n",
      " [0.29324391]\n",
      " [0.29456788]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31259854933061226\n",
      "Predicci√≥n : [[0.29643258]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[[0.28789482]\n",
      "  [0.28958401]\n",
      "  [0.29057813]\n",
      "  [0.29143676]\n",
      "  [0.29232791]\n",
      "  [0.2929962 ]\n",
      "  [0.29324391]\n",
      "  [0.29456788]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002613386313896626\n",
      "Predicci√≥n post entrenamiento : [[0.29712665]]\n",
      "PERDIDAAAA despues: 0.00023937986406963319\n",
      "loss en el callback: 0.003069432219490409, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "ejemplar: [[0.28958401]\n",
      " [0.29057813]\n",
      " [0.29143676]\n",
      " [0.29232791]\n",
      " [0.2929962 ]\n",
      " [0.29324391]\n",
      " [0.29456788]\n",
      " [0.29643258]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.34358710169603873\n",
      "Predicci√≥n : [[0.29790455]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[[0.28958401]\n",
      "  [0.29057813]\n",
      "  [0.29143676]\n",
      "  [0.29232791]\n",
      "  [0.2929962 ]\n",
      "  [0.29324391]\n",
      "  [0.29456788]\n",
      "  [0.29643258]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0020868952851742506\n",
      "Predicci√≥n post entrenamiento : [[0.29847524]]\n",
      "PERDIDAAAA despues: 0.0020350804552435875\n",
      "loss en el callback: 0.0016208809101954103, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "ejemplar: [[0.29057813]\n",
      " [0.29143676]\n",
      " [0.29232791]\n",
      " [0.2929962 ]\n",
      " [0.29324391]\n",
      " [0.29456788]\n",
      " [0.29643258]\n",
      " [0.29790455]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.4411954725639069\n",
      "Predicci√≥n : [[0.299096]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[[0.29057813]\n",
      "  [0.29143676]\n",
      "  [0.29232791]\n",
      "  [0.2929962 ]\n",
      "  [0.29324391]\n",
      "  [0.29456788]\n",
      "  [0.29643258]\n",
      "  [0.29790455]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.020192259922623634\n",
      "Predicci√≥n post entrenamiento : [[0.3013142]]\n",
      "PERDIDAAAA despues: 0.019566765055060387\n",
      "loss en el callback: 0.03542693331837654, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "ejemplar: [[0.29143676]\n",
      " [0.29232791]\n",
      " [0.2929962 ]\n",
      " [0.29324391]\n",
      " [0.29456788]\n",
      " [0.29643258]\n",
      " [0.29790455]\n",
      " [0.29909599]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5210953230441133\n",
      "Predicci√≥n : [[0.30192515]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[[0.29143676]\n",
      "  [0.29232791]\n",
      "  [0.2929962 ]\n",
      "  [0.29324391]\n",
      "  [0.29456788]\n",
      "  [0.29643258]\n",
      "  [0.29790455]\n",
      "  [0.29909599]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04803556948900223\n",
      "Predicci√≥n post entrenamiento : [[0.30450848]]\n",
      "PERDIDAAAA despues: 0.046909868717193604\n",
      "loss en el callback: 0.028074519708752632, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "ejemplar: [[0.29232791]\n",
      " [0.2929962 ]\n",
      " [0.29324391]\n",
      " [0.29456788]\n",
      " [0.29643258]\n",
      " [0.29790455]\n",
      " [0.29909599]\n",
      " [0.30192515]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5832866531366584\n",
      "Predicci√≥n : [[0.30516034]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[[0.29232791]\n",
      "  [0.2929962 ]\n",
      "  [0.29324391]\n",
      "  [0.29456788]\n",
      "  [0.29643258]\n",
      "  [0.29790455]\n",
      "  [0.29909599]\n",
      "  [0.30192515]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07735423743724823\n",
      "Predicci√≥n post entrenamiento : [[0.3088516]]\n",
      "PERDIDAAAA despues: 0.07531459629535675\n",
      "loss en el callback: 0.10707678645849228, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "ejemplar: [[0.2929962 ]\n",
      " [0.29324391]\n",
      " [0.29456788]\n",
      " [0.29643258]\n",
      " [0.29790455]\n",
      " [0.29909599]\n",
      " [0.30192515]\n",
      " [0.30516034]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6089234523540271\n",
      "Predicci√≥n : [[0.30957597]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[[0.2929962 ]\n",
      "  [0.29324391]\n",
      "  [0.29456788]\n",
      "  [0.29643258]\n",
      "  [0.29790455]\n",
      "  [0.29909599]\n",
      "  [0.30192515]\n",
      "  [0.30516034]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08960890024900436\n",
      "Predicci√≥n post entrenamiento : [[0.31267557]]\n",
      "PERDIDAAAA despues: 0.08776280283927917\n",
      "loss en el callback: 0.0362539105117321, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "ejemplar: [[0.29324391]\n",
      " [0.29456788]\n",
      " [0.29643258]\n",
      " [0.29790455]\n",
      " [0.29909599]\n",
      " [0.30192515]\n",
      " [0.30516034]\n",
      " [0.30957597]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.59800572069622\n",
      "Predicci√≥n : [[0.31358355]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[[0.29324391]\n",
      "  [0.29456788]\n",
      "  [0.29643258]\n",
      "  [0.29790455]\n",
      "  [0.29909599]\n",
      "  [0.30192515]\n",
      "  [0.30516034]\n",
      "  [0.30957597]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08089596778154373\n",
      "Predicci√≥n post entrenamiento : [[0.3169727]]\n",
      "PERDIDAAAA despues: 0.07897955179214478\n",
      "loss en el callback: 0.05007762461900711, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "ejemplar: [[0.29456788]\n",
      " [0.29643258]\n",
      " [0.29790455]\n",
      " [0.29909599]\n",
      " [0.30192515]\n",
      " [0.30516034]\n",
      " [0.30957597]\n",
      " [0.31358355]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5945301858653699\n",
      "Predicci√≥n : [[0.31824923]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[[0.29456788]\n",
      "  [0.29643258]\n",
      "  [0.29790455]\n",
      "  [0.29909599]\n",
      "  [0.30192515]\n",
      "  [0.30516034]\n",
      "  [0.30957597]\n",
      "  [0.31358355]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07633116096258163\n",
      "Predicci√≥n post entrenamiento : [[0.3217506]]\n",
      "PERDIDAAAA despues: 0.07440868765115738\n",
      "loss en el callback: 0.08028911054134369, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "ejemplar: [[0.29643258]\n",
      " [0.29790455]\n",
      " [0.29909599]\n",
      " [0.30192515]\n",
      " [0.30516034]\n",
      " [0.30957597]\n",
      " [0.31358355]\n",
      " [0.31824923]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5984968478614763\n",
      "Predicci√≥n : [[0.32325977]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[[0.29643258]\n",
      "  [0.29790455]\n",
      "  [0.29909599]\n",
      "  [0.30192515]\n",
      "  [0.30516034]\n",
      "  [0.30957597]\n",
      "  [0.31358355]\n",
      "  [0.31824923]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07575545459985733\n",
      "Predicci√≥n post entrenamiento : [[0.32659763]]\n",
      "PERDIDAAAA despues: 0.07392919063568115\n",
      "loss en el callback: 0.060155946761369705, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "ejemplar: [[0.29790455]\n",
      " [0.29909599]\n",
      " [0.30192515]\n",
      " [0.30516034]\n",
      " [0.30957597]\n",
      " [0.31358355]\n",
      " [0.31824923]\n",
      " [0.32325977]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6213543446734934\n",
      "Predicci√≥n : [[0.32831055]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[[0.29790455]\n",
      "  [0.29909599]\n",
      "  [0.30192515]\n",
      "  [0.30516034]\n",
      "  [0.30957597]\n",
      "  [0.31358355]\n",
      "  [0.31824923]\n",
      "  [0.32325977]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08587466180324554\n",
      "Predicci√≥n post entrenamiento : [[0.33188844]]\n",
      "PERDIDAAAA despues: 0.08379051089286804\n",
      "loss en el callback: 0.10857012867927551, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "ejemplar: [[0.29909599]\n",
      " [0.30192515]\n",
      " [0.30516034]\n",
      " [0.30957597]\n",
      " [0.31358355]\n",
      " [0.31824923]\n",
      " [0.32325977]\n",
      " [0.32831055]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.663102676301421\n",
      "Predicci√≥n : [[0.3339949]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[[0.29909599]\n",
      "  [0.30192515]\n",
      "  [0.30516034]\n",
      "  [0.30957597]\n",
      "  [0.31358355]\n",
      "  [0.31824923]\n",
      "  [0.32325977]\n",
      "  [0.32831055]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10831193625926971\n",
      "Predicci√≥n post entrenamiento : [[0.33788818]]\n",
      "PERDIDAAAA despues: 0.1057644709944725\n",
      "loss en el callback: 0.12739282846450806, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "ejemplar: [[0.30192515]\n",
      " [0.30516034]\n",
      " [0.30957597]\n",
      " [0.31358355]\n",
      " [0.31824923]\n",
      " [0.32325977]\n",
      " [0.32831055]\n",
      " [0.3339949 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6928724338328028\n",
      "Predicci√≥n : [[0.3405795]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[[0.30192515]\n",
      "  [0.30516034]\n",
      "  [0.30957597]\n",
      "  [0.31358355]\n",
      "  [0.31824923]\n",
      "  [0.32325977]\n",
      "  [0.32831055]\n",
      "  [0.3339949 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12411028146743774\n",
      "Predicci√≥n post entrenamiento : [[0.34467813]]\n",
      "PERDIDAAAA despues: 0.12123925238847733\n",
      "loss en el callback: 0.13704729080200195, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "ejemplar: [[0.30516034]\n",
      " [0.30957597]\n",
      " [0.31358355]\n",
      " [0.31824923]\n",
      " [0.32325977]\n",
      " [0.32831055]\n",
      " [0.3339949 ]\n",
      " [0.34057951]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.710663617267639\n",
      "Predicci√≥n : [[0.34771135]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[[0.30516034]\n",
      "  [0.30957597]\n",
      "  [0.31358355]\n",
      "  [0.31824923]\n",
      "  [0.32325977]\n",
      "  [0.32831055]\n",
      "  [0.3339949 ]\n",
      "  [0.34057951]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13173434138298035\n",
      "Predicci√≥n post entrenamiento : [[0.35137108]]\n",
      "PERDIDAAAA despues: 0.12909112870693207\n",
      "loss en el callback: 0.07245240360498428, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "ejemplar: [[0.30957597]\n",
      " [0.31358355]\n",
      " [0.31824923]\n",
      " [0.32325977]\n",
      " [0.32831055]\n",
      " [0.3339949 ]\n",
      " [0.34057951]\n",
      " [0.34771135]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7216820581308059\n",
      "Predicci√≥n : [[0.35475576]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[[0.30957597]\n",
      "  [0.31358355]\n",
      "  [0.31824923]\n",
      "  [0.32325977]\n",
      "  [0.32831055]\n",
      "  [0.3339949 ]\n",
      "  [0.34057951]\n",
      "  [0.34771135]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13463491201400757\n",
      "Predicci√≥n post entrenamiento : [[0.35851386]]\n",
      "PERDIDAAAA despues: 0.1318911463022232\n",
      "loss en el callback: 0.13652783632278442, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "ejemplar: [[0.31358355]\n",
      " [0.31824923]\n",
      " [0.32325977]\n",
      " [0.32831055]\n",
      " [0.3339949 ]\n",
      " [0.34057951]\n",
      " [0.34771135]\n",
      " [0.35475576]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7259277564223031\n",
      "Predicci√≥n : [[0.3620749]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[[0.31358355]\n",
      "  [0.31824923]\n",
      "  [0.32325977]\n",
      "  [0.32831055]\n",
      "  [0.3339949 ]\n",
      "  [0.34057951]\n",
      "  [0.34771135]\n",
      "  [0.35475576]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1323889046907425\n",
      "Predicci√≥n post entrenamiento : [[0.36606878]]\n",
      "PERDIDAAAA despues: 0.12949849665164948\n",
      "loss en el callback: 0.18011876940727234, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "ejemplar: [[0.31824923]\n",
      " [0.32325977]\n",
      " [0.32831055]\n",
      " [0.3339949 ]\n",
      " [0.34057951]\n",
      " [0.34771135]\n",
      " [0.35475576]\n",
      " [0.36207491]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7404318224413275\n",
      "Predicci√≥n : [[0.36998713]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[[0.31824923]\n",
      "  [0.32325977]\n",
      "  [0.32831055]\n",
      "  [0.3339949 ]\n",
      "  [0.34057951]\n",
      "  [0.34771135]\n",
      "  [0.35475576]\n",
      "  [0.36207491]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1372292935848236\n",
      "Predicci√≥n post entrenamiento : [[0.37389022]]\n",
      "PERDIDAAAA despues: 0.13435275852680206\n",
      "loss en el callback: 0.2194850891828537, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "ejemplar: [[0.32325977]\n",
      " [0.32831055]\n",
      " [0.3339949 ]\n",
      " [0.34057951]\n",
      " [0.34771135]\n",
      " [0.35475576]\n",
      " [0.36207491]\n",
      " [0.36998713]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7651942561878792\n",
      "Predicci√≥n : [[0.37811875]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[[0.32325977]\n",
      "  [0.32831055]\n",
      "  [0.3339949 ]\n",
      "  [0.34057951]\n",
      "  [0.34771135]\n",
      "  [0.35475576]\n",
      "  [0.36207491]\n",
      "  [0.36998713]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14982743561267853\n",
      "Predicci√≥n post entrenamiento : [[0.38229954]]\n",
      "PERDIDAAAA despues: 0.1466083526611328\n",
      "loss en el callback: 0.14452753961086273, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "ejemplar: [[0.32831055]\n",
      " [0.3339949 ]\n",
      " [0.34057951]\n",
      " [0.34771135]\n",
      " [0.35475576]\n",
      " [0.36207491]\n",
      " [0.36998713]\n",
      " [0.37811875]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7447890964420396\n",
      "Predicci√≥n : [[0.38685805]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[[0.32831055]\n",
      "  [0.3339949 ]\n",
      "  [0.34057951]\n",
      "  [0.34771135]\n",
      "  [0.35475576]\n",
      "  [0.36207491]\n",
      "  [0.36998713]\n",
      "  [0.37811875]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12811465561389923\n",
      "Predicci√≥n post entrenamiento : [[0.3907782]]\n",
      "PERDIDAAAA despues: 0.12532372772693634\n",
      "loss en el callback: 0.15924237668514252, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "ejemplar: [[0.3339949 ]\n",
      " [0.34057951]\n",
      " [0.34771135]\n",
      " [0.35475576]\n",
      " [0.36207491]\n",
      " [0.36998713]\n",
      " [0.37811875]\n",
      " [0.38685805]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6792163432038085\n",
      "Predicci√≥n : [[0.39576146]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[[0.3339949 ]\n",
      "  [0.34057951]\n",
      "  [0.34771135]\n",
      "  [0.35475576]\n",
      "  [0.36207491]\n",
      "  [0.36998713]\n",
      "  [0.37811875]\n",
      "  [0.38685805]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08034665882587433\n",
      "Predicci√≥n post entrenamiento : [[0.39878017]]\n",
      "PERDIDAAAA despues: 0.07864443957805634\n",
      "loss en el callback: 0.10988623648881912, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "ejemplar: [[0.34057951]\n",
      " [0.34771135]\n",
      " [0.35475576]\n",
      " [0.36207491]\n",
      " [0.36998713]\n",
      " [0.37811875]\n",
      " [0.38685805]\n",
      " [0.39576146]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6746017659154131\n",
      "Predicci√≥n : [[0.40414724]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[[0.34057951]\n",
      "  [0.34771135]\n",
      "  [0.35475576]\n",
      "  [0.36207491]\n",
      "  [0.36998713]\n",
      "  [0.37811875]\n",
      "  [0.38685805]\n",
      "  [0.39576146]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07314566522836685\n",
      "Predicci√≥n post entrenamiento : [[0.4071752]]\n",
      "PERDIDAAAA despues: 0.0715169757604599\n",
      "loss en el callback: 0.11278340965509415, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "ejemplar: [[0.34771135]\n",
      " [0.35475576]\n",
      " [0.36207491]\n",
      " [0.36998713]\n",
      " [0.37811875]\n",
      " [0.38685805]\n",
      " [0.39576146]\n",
      " [0.40414724]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7309453645768532\n",
      "Predicci√≥n : [[0.4128044]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[[0.34771135]\n",
      "  [0.35475576]\n",
      "  [0.36207491]\n",
      "  [0.36998713]\n",
      "  [0.37811875]\n",
      "  [0.38685805]\n",
      "  [0.39576146]\n",
      "  [0.40414724]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10121366381645203\n",
      "Predicci√≥n post entrenamiento : [[0.4158739]]\n",
      "PERDIDAAAA despues: 0.09927003085613251\n",
      "loss en el callback: 0.09141495823860168, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "ejemplar: [[0.35475576]\n",
      " [0.36207491]\n",
      " [0.36998713]\n",
      " [0.37811875]\n",
      " [0.38685805]\n",
      " [0.39576146]\n",
      " [0.40414724]\n",
      " [0.41280439]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7467210055914982\n",
      "Predicci√≥n : [[0.42170352]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[[0.35475576]\n",
      "  [0.36207491]\n",
      "  [0.36998713]\n",
      "  [0.37811875]\n",
      "  [0.38685805]\n",
      "  [0.39576146]\n",
      "  [0.40414724]\n",
      "  [0.41280439]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10563638061285019\n",
      "Predicci√≥n post entrenamiento : [[0.42504394]]\n",
      "PERDIDAAAA despues: 0.1034761518239975\n",
      "loss en el callback: 0.16247935593128204, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "ejemplar: [[0.36207491]\n",
      " [0.36998713]\n",
      " [0.37811875]\n",
      " [0.38685805]\n",
      " [0.39576146]\n",
      " [0.40414724]\n",
      " [0.41280439]\n",
      " [0.42170352]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7219286889593481\n",
      "Predicci√≥n : [[0.43115556]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[[0.36207491]\n",
      "  [0.36998713]\n",
      "  [0.37811875]\n",
      "  [0.38685805]\n",
      "  [0.39576146]\n",
      "  [0.40414724]\n",
      "  [0.41280439]\n",
      "  [0.42170352]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08454902470111847\n",
      "Predicci√≥n post entrenamiento : [[0.43393195]]\n",
      "PERDIDAAAA despues: 0.08294213563203812\n",
      "loss en el callback: 0.08986619859933853, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "ejemplar: [[0.36998713]\n",
      " [0.37811875]\n",
      " [0.38685805]\n",
      " [0.39576146]\n",
      " [0.40414724]\n",
      " [0.41280439]\n",
      " [0.42170352]\n",
      " [0.43115556]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7199286701160912\n",
      "Predicci√≥n : [[0.44032493]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[[0.36998713]\n",
      "  [0.37811875]\n",
      "  [0.38685805]\n",
      "  [0.39576146]\n",
      "  [0.40414724]\n",
      "  [0.41280439]\n",
      "  [0.42170352]\n",
      "  [0.43115556]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07817825675010681\n",
      "Predicci√≥n post entrenamiento : [[0.4427481]]\n",
      "PERDIDAAAA despues: 0.07682907581329346\n",
      "loss en el callback: 0.04870876297354698, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "ejemplar: [[0.37811875]\n",
      " [0.38685805]\n",
      " [0.39576146]\n",
      " [0.40414724]\n",
      " [0.41280439]\n",
      " [0.42170352]\n",
      " [0.43115556]\n",
      " [0.44032493]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7407209490617273\n",
      "Predicci√≥n : [[0.44933507]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[[0.37811875]\n",
      "  [0.38685805]\n",
      "  [0.39576146]\n",
      "  [0.40414724]\n",
      "  [0.41280439]\n",
      "  [0.42170352]\n",
      "  [0.43115556]\n",
      "  [0.44032493]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0849057212471962\n",
      "Predicci√≥n post entrenamiento : [[0.45216823]]\n",
      "PERDIDAAAA despues: 0.08326265960931778\n",
      "loss en el callback: 0.11924340575933456, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "ejemplar: [[0.38685805]\n",
      " [0.39576146]\n",
      " [0.40414724]\n",
      " [0.41280439]\n",
      " [0.42170352]\n",
      " [0.43115556]\n",
      " [0.44032493]\n",
      " [0.44933507]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.736245501831604\n",
      "Predicci√≥n : [[0.45893782]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[[0.38685805]\n",
      "  [0.39576146]\n",
      "  [0.40414724]\n",
      "  [0.41280439]\n",
      "  [0.42170352]\n",
      "  [0.43115556]\n",
      "  [0.44032493]\n",
      "  [0.44933507]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07689955085515976\n",
      "Predicci√≥n post entrenamiento : [[0.46163625]]\n",
      "PERDIDAAAA despues: 0.07541024684906006\n",
      "loss en el callback: 0.11111856997013092, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "ejemplar: [[0.39576146]\n",
      " [0.40414724]\n",
      " [0.41280439]\n",
      " [0.42170352]\n",
      " [0.43115556]\n",
      " [0.44032493]\n",
      " [0.44933507]\n",
      " [0.45893782]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7065023284257214\n",
      "Predicci√≥n : [[0.46847278]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[[0.39576146]\n",
      "  [0.40414724]\n",
      "  [0.41280439]\n",
      "  [0.42170352]\n",
      "  [0.43115556]\n",
      "  [0.44032493]\n",
      "  [0.44933507]\n",
      "  [0.45893782]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0566580630838871\n",
      "Predicci√≥n post entrenamiento : [[0.4708006]]\n",
      "PERDIDAAAA despues: 0.05555529519915581\n",
      "loss en el callback: 0.06088370829820633, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "ejemplar: [[0.40414724]\n",
      " [0.41280439]\n",
      " [0.42170352]\n",
      " [0.43115556]\n",
      " [0.44032493]\n",
      " [0.44933507]\n",
      " [0.45893782]\n",
      " [0.46847278]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6979451506854685\n",
      "Predicci√≥n : [[0.47768232]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[[0.40414724]\n",
      "  [0.41280439]\n",
      "  [0.42170352]\n",
      "  [0.43115556]\n",
      "  [0.44032493]\n",
      "  [0.44933507]\n",
      "  [0.45893782]\n",
      "  [0.46847278]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04851572588086128\n",
      "Predicci√≥n post entrenamiento : [[0.4791721]]\n",
      "PERDIDAAAA despues: 0.04786165431141853\n",
      "loss en el callback: 0.018167702481150627, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "ejemplar: [[0.41280439]\n",
      " [0.42170352]\n",
      " [0.43115556]\n",
      " [0.44032493]\n",
      " [0.44933507]\n",
      " [0.45893782]\n",
      " [0.46847278]\n",
      " [0.47768232]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7105739686108449\n",
      "Predicci√≥n : [[0.48624718]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[[0.41280439]\n",
      "  [0.42170352]\n",
      "  [0.43115556]\n",
      "  [0.44032493]\n",
      "  [0.44933507]\n",
      "  [0.45893782]\n",
      "  [0.46847278]\n",
      "  [0.47768232]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.050322506576776505\n",
      "Predicci√≥n post entrenamiento : [[0.4887167]]\n",
      "PERDIDAAAA despues: 0.049220651388168335\n",
      "loss en el callback: 0.09503122419118881, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "ejemplar: [[0.42170352]\n",
      " [0.43115556]\n",
      " [0.44032493]\n",
      " [0.44933507]\n",
      " [0.45893782]\n",
      " [0.46847278]\n",
      " [0.47768232]\n",
      " [0.48624718]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7209621522504839\n",
      "Predicci√≥n : [[0.49595195]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[[0.42170352]\n",
      "  [0.43115556]\n",
      "  [0.44032493]\n",
      "  [0.44933507]\n",
      "  [0.45893782]\n",
      "  [0.46847278]\n",
      "  [0.47768232]\n",
      "  [0.48624718]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.050629597157239914\n",
      "Predicci√≥n post entrenamiento : [[0.49830294]]\n",
      "PERDIDAAAA despues: 0.04957713186740875\n",
      "loss en el callback: 0.1008896678686142, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "ejemplar: [[0.43115556]\n",
      " [0.44032493]\n",
      " [0.44933507]\n",
      " [0.45893782]\n",
      " [0.46847278]\n",
      " [0.47768232]\n",
      " [0.48624718]\n",
      " [0.49595195]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7291097016043858\n",
      "Predicci√≥n : [[0.50565875]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[[0.43115556]\n",
      "  [0.44032493]\n",
      "  [0.44933507]\n",
      "  [0.45893782]\n",
      "  [0.46847278]\n",
      "  [0.47768232]\n",
      "  [0.48624718]\n",
      "  [0.49595195]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.049930330365896225\n",
      "Predicci√≥n post entrenamiento : [[0.5076361]]\n",
      "PERDIDAAAA despues: 0.04905056953430176\n",
      "loss en el callback: 0.04328341782093048, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "ejemplar: [[0.44032493]\n",
      " [0.44933507]\n",
      " [0.45893782]\n",
      " [0.46847278]\n",
      " [0.47768232]\n",
      " [0.48624718]\n",
      " [0.49595195]\n",
      " [0.50565875]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7674259644168786\n",
      "Predicci√≥n : [[0.514984]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[[0.44032493]\n",
      "  [0.44933507]\n",
      "  [0.45893782]\n",
      "  [0.46847278]\n",
      "  [0.47768232]\n",
      "  [0.48624718]\n",
      "  [0.49595195]\n",
      "  [0.50565875]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06372693181037903\n",
      "Predicci√≥n post entrenamiento : [[0.5172295]]\n",
      "PERDIDAAAA despues: 0.06259826570749283\n",
      "loss en el callback: 0.06630326807498932, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "ejemplar: [[0.44933507]\n",
      " [0.45893782]\n",
      " [0.46847278]\n",
      " [0.47768232]\n",
      " [0.48624718]\n",
      " [0.49595195]\n",
      " [0.50565875]\n",
      " [0.51498401]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8359109406879621\n",
      "Predicci√≥n : [[0.5246401]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[[0.44933507]\n",
      "  [0.45893782]\n",
      "  [0.46847278]\n",
      "  [0.47768232]\n",
      "  [0.48624718]\n",
      "  [0.49595195]\n",
      "  [0.50565875]\n",
      "  [0.51498401]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09688953310251236\n",
      "Predicci√≥n post entrenamiento : [[0.52742684]]\n",
      "PERDIDAAAA despues: 0.09516242891550064\n",
      "loss en el callback: 0.1457865983247757, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "ejemplar: [[0.45893782]\n",
      " [0.46847278]\n",
      " [0.47768232]\n",
      " [0.48624718]\n",
      " [0.49595195]\n",
      " [0.50565875]\n",
      " [0.51498401]\n",
      " [0.52464008]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8510103358824123\n",
      "Predicci√≥n : [[0.53495306]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[[0.45893782]\n",
      "  [0.46847278]\n",
      "  [0.47768232]\n",
      "  [0.48624718]\n",
      "  [0.49595195]\n",
      "  [0.50565875]\n",
      "  [0.51498401]\n",
      "  [0.52464008]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09989219158887863\n",
      "Predicci√≥n post entrenamiento : [[0.53827614]]\n",
      "PERDIDAAAA despues: 0.09780266880989075\n",
      "loss en el callback: 0.20490695536136627, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "ejemplar: [[0.46847278]\n",
      " [0.47768232]\n",
      " [0.48624718]\n",
      " [0.49595195]\n",
      " [0.50565875]\n",
      " [0.51498401]\n",
      " [0.52464008]\n",
      " [0.53495306]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8127241500002294\n",
      "Predicci√≥n : [[0.54578424]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[[0.46847278]\n",
      "  [0.47768232]\n",
      "  [0.48624718]\n",
      "  [0.49595195]\n",
      "  [0.50565875]\n",
      "  [0.51498401]\n",
      "  [0.52464008]\n",
      "  [0.53495306]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07125692814588547\n",
      "Predicci√≥n post entrenamiento : [[0.5481048]]\n",
      "PERDIDAAAA despues: 0.07002340257167816\n",
      "loss en el callback: 0.08005782961845398, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "ejemplar: [[0.47768232]\n",
      " [0.48624718]\n",
      " [0.49595195]\n",
      " [0.50565875]\n",
      " [0.51498401]\n",
      " [0.52464008]\n",
      " [0.53495306]\n",
      " [0.54578424]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7863940290280375\n",
      "Predicci√≥n : [[0.55562174]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[[0.47768232]\n",
      "  [0.48624718]\n",
      "  [0.49595195]\n",
      "  [0.50565875]\n",
      "  [0.51498401]\n",
      "  [0.52464008]\n",
      "  [0.53495306]\n",
      "  [0.54578424]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0532558336853981\n",
      "Predicci√≥n post entrenamiento : [[0.55740386]]\n",
      "PERDIDAAAA despues: 0.05243648216128349\n",
      "loss en el callback: 0.03905860334634781, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "ejemplar: [[0.48624718]\n",
      " [0.49595195]\n",
      " [0.50565875]\n",
      " [0.51498401]\n",
      " [0.52464008]\n",
      " [0.53495306]\n",
      " [0.54578424]\n",
      " [0.55562174]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7720199729658365\n",
      "Predicci√≥n : [[0.565035]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[[0.48624718]\n",
      "  [0.49595195]\n",
      "  [0.50565875]\n",
      "  [0.51498401]\n",
      "  [0.52464008]\n",
      "  [0.53495306]\n",
      "  [0.54578424]\n",
      "  [0.55562174]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.042842790484428406\n",
      "Predicci√≥n post entrenamiento : [[0.5669218]]\n",
      "PERDIDAAAA despues: 0.04206527769565582\n",
      "loss en el callback: 0.04763854295015335, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "ejemplar: [[0.49595195]\n",
      " [0.50565875]\n",
      " [0.51498401]\n",
      " [0.52464008]\n",
      " [0.53495306]\n",
      " [0.54578424]\n",
      " [0.55562174]\n",
      " [0.56503499]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8033170564228299\n",
      "Predicci√≥n : [[0.5748722]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[[0.49595195]\n",
      "  [0.50565875]\n",
      "  [0.51498401]\n",
      "  [0.52464008]\n",
      "  [0.53495306]\n",
      "  [0.54578424]\n",
      "  [0.55562174]\n",
      "  [0.56503499]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.052187059074640274\n",
      "Predicci√≥n post entrenamiento : [[0.5771851]]\n",
      "PERDIDAAAA despues: 0.05113567039370537\n",
      "loss en el callback: 0.10290434211492538, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "ejemplar: [[0.50565875]\n",
      " [0.51498401]\n",
      " [0.52464008]\n",
      " [0.53495306]\n",
      " [0.54578424]\n",
      " [0.55562174]\n",
      " [0.56503499]\n",
      " [0.5748722 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8802852793990171\n",
      "Predicci√≥n : [[0.5852082]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[[0.50565875]\n",
      "  [0.51498401]\n",
      "  [0.52464008]\n",
      "  [0.53495306]\n",
      "  [0.54578424]\n",
      "  [0.55562174]\n",
      "  [0.56503499]\n",
      "  [0.5748722 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08707048743963242\n",
      "Predicci√≥n post entrenamiento : [[0.58766454]]\n",
      "PERDIDAAAA despues: 0.08562688529491425\n",
      "loss en el callback: 0.08258314430713654, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "ejemplar: [[0.51498401]\n",
      " [0.52464008]\n",
      " [0.53495306]\n",
      " [0.54578424]\n",
      " [0.55562174]\n",
      " [0.56503499]\n",
      " [0.5748722 ]\n",
      " [0.58520818]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8987051676996881\n",
      "Predicci√≥n : [[0.59577346]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[[0.51498401]\n",
      "  [0.52464008]\n",
      "  [0.53495306]\n",
      "  [0.54578424]\n",
      "  [0.55562174]\n",
      "  [0.56503499]\n",
      "  [0.5748722 ]\n",
      "  [0.58520818]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09176763147115707\n",
      "Predicci√≥n post entrenamiento : [[0.59843314]]\n",
      "PERDIDAAAA despues: 0.09016330540180206\n",
      "loss en el callback: 0.10424605011940002, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "ejemplar: [[0.52464008]\n",
      " [0.53495306]\n",
      " [0.54578424]\n",
      " [0.55562174]\n",
      " [0.56503499]\n",
      " [0.5748722 ]\n",
      " [0.58520818]\n",
      " [0.59577346]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8585767213248423\n",
      "Predicci√≥n : [[0.6067464]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[[0.52464008]\n",
      "  [0.53495306]\n",
      "  [0.54578424]\n",
      "  [0.55562174]\n",
      "  [0.56503499]\n",
      "  [0.5748722 ]\n",
      "  [0.58520818]\n",
      "  [0.59577346]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06341852247714996\n",
      "Predicci√≥n post entrenamiento : [[0.60922873]]\n",
      "PERDIDAAAA despues: 0.062174417078495026\n",
      "loss en el callback: 0.11538587510585785, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "ejemplar: [[0.53495306]\n",
      " [0.54578424]\n",
      " [0.55562174]\n",
      " [0.56503499]\n",
      " [0.5748722 ]\n",
      " [0.58520818]\n",
      " [0.59577346]\n",
      " [0.60674638]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8308762565987861\n",
      "Predicci√≥n : [[0.61769176]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[[0.53495306]\n",
      "  [0.54578424]\n",
      "  [0.55562174]\n",
      "  [0.56503499]\n",
      "  [0.5748722 ]\n",
      "  [0.58520818]\n",
      "  [0.59577346]\n",
      "  [0.60674638]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04544762149453163\n",
      "Predicci√≥n post entrenamiento : [[0.6197291]]\n",
      "PERDIDAAAA despues: 0.04458311200141907\n",
      "loss en el callback: 0.06683170050382614, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "ejemplar: [[0.54578424]\n",
      " [0.55562174]\n",
      " [0.56503499]\n",
      " [0.5748722 ]\n",
      " [0.58520818]\n",
      " [0.59577346]\n",
      " [0.60674638]\n",
      " [0.61769176]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8156037735215196\n",
      "Predicci√≥n : [[0.6281912]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[[0.54578424]\n",
      "  [0.55562174]\n",
      "  [0.56503499]\n",
      "  [0.5748722 ]\n",
      "  [0.58520818]\n",
      "  [0.59577346]\n",
      "  [0.60674638]\n",
      "  [0.61769176]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.035123489797115326\n",
      "Predicci√≥n post entrenamiento : [[0.6298193]]\n",
      "PERDIDAAAA despues: 0.03451588749885559\n",
      "loss en el callback: 0.039997611194849014, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "ejemplar: [[0.55562174]\n",
      " [0.56503499]\n",
      " [0.5748722 ]\n",
      " [0.58520818]\n",
      " [0.59577346]\n",
      " [0.60674638]\n",
      " [0.61769176]\n",
      " [0.62819117]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8116992058331503\n",
      "Predicci√≥n : [[0.6381488]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[[0.55562174]\n",
      "  [0.56503499]\n",
      "  [0.5748722 ]\n",
      "  [0.58520818]\n",
      "  [0.59577346]\n",
      "  [0.60674638]\n",
      "  [0.61769176]\n",
      "  [0.62819117]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.030119750648736954\n",
      "Predicci√≥n post entrenamiento : [[0.6399091]]\n",
      "PERDIDAAAA despues: 0.029511846601963043\n",
      "loss en el callback: 0.05570539832115173, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "ejemplar: [[0.56503499]\n",
      " [0.5748722 ]\n",
      " [0.58520818]\n",
      " [0.59577346]\n",
      " [0.60674638]\n",
      " [0.61769176]\n",
      " [0.62819117]\n",
      " [0.63814878]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8191625535336788\n",
      "Predicci√≥n : [[0.64837044]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[[0.56503499]\n",
      "  [0.5748722 ]\n",
      "  [0.58520818]\n",
      "  [0.59577346]\n",
      "  [0.60674638]\n",
      "  [0.61769176]\n",
      "  [0.62819117]\n",
      "  [0.63814878]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.029169943183660507\n",
      "Predicci√≥n post entrenamiento : [[0.6495816]]\n",
      "PERDIDAAAA despues: 0.028757693246006966\n",
      "loss en el callback: 0.021349994465708733, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "ejemplar: [[0.5748722 ]\n",
      " [0.58520818]\n",
      " [0.59577346]\n",
      " [0.60674638]\n",
      " [0.61769176]\n",
      " [0.62819117]\n",
      " [0.63814878]\n",
      " [0.64837044]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8218275636038536\n",
      "Predicci√≥n : [[0.6583195]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[[0.5748722 ]\n",
      "  [0.58520818]\n",
      "  [0.59577346]\n",
      "  [0.60674638]\n",
      "  [0.61769176]\n",
      "  [0.62819117]\n",
      "  [0.63814878]\n",
      "  [0.64837044]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.026734905317425728\n",
      "Predicci√≥n post entrenamiento : [[0.6597854]]\n",
      "PERDIDAAAA despues: 0.026257675141096115\n",
      "loss en el callback: 0.03160478547215462, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "ejemplar: [[0.58520818]\n",
      " [0.59577346]\n",
      " [0.60674638]\n",
      " [0.61769176]\n",
      " [0.62819117]\n",
      " [0.63814878]\n",
      " [0.64837044]\n",
      " [0.65831947]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8196942360436743\n",
      "Predicci√≥n : [[0.668723]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[[0.58520818]\n",
      "  [0.59577346]\n",
      "  [0.60674638]\n",
      "  [0.61769176]\n",
      "  [0.62819117]\n",
      "  [0.63814878]\n",
      "  [0.64837044]\n",
      "  [0.65831947]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022792313247919083\n",
      "Predicci√≥n post entrenamiento : [[0.66952145]]\n",
      "PERDIDAAAA despues: 0.02255186066031456\n",
      "loss en el callback: 0.00849294662475586, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "ejemplar: [[0.59577346]\n",
      " [0.60674638]\n",
      " [0.61769176]\n",
      " [0.62819117]\n",
      " [0.63814878]\n",
      " [0.64837044]\n",
      " [0.65831947]\n",
      " [0.66872299]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8178628420548653\n",
      "Predicci√≥n : [[0.67853516]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[[0.59577346]\n",
      "  [0.60674638]\n",
      "  [0.61769176]\n",
      "  [0.62819117]\n",
      "  [0.63814878]\n",
      "  [0.64837044]\n",
      "  [0.65831947]\n",
      "  [0.66872299]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0194122102111578\n",
      "Predicci√≥n post entrenamiento : [[0.6798359]]\n",
      "PERDIDAAAA despues: 0.019051440060138702\n",
      "loss en el callback: 0.026332523673772812, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "ejemplar: [[0.60674638]\n",
      " [0.61769176]\n",
      " [0.62819117]\n",
      " [0.63814878]\n",
      " [0.64837044]\n",
      " [0.65831947]\n",
      " [0.66872299]\n",
      " [0.67853516]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8163333816374257\n",
      "Predicci√≥n : [[0.6888532]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[[0.60674638]\n",
      "  [0.61769176]\n",
      "  [0.62819117]\n",
      "  [0.63814878]\n",
      "  [0.64837044]\n",
      "  [0.65831947]\n",
      "  [0.66872299]\n",
      "  [0.67853516]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01625118777155876\n",
      "Predicci√≥n post entrenamiento : [[0.6893882]]\n",
      "PERDIDAAAA despues: 0.016115067526698112\n",
      "loss en el callback: 0.0038545290008187294, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "ejemplar: [[0.61769176]\n",
      " [0.62819117]\n",
      " [0.63814878]\n",
      " [0.64837044]\n",
      " [0.65831947]\n",
      " [0.66872299]\n",
      " [0.67853516]\n",
      " [0.6888532 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8005556061309519\n",
      "Predicci√≥n : [[0.69827175]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[[0.61769176]\n",
      "  [0.62819117]\n",
      "  [0.63814878]\n",
      "  [0.64837044]\n",
      "  [0.65831947]\n",
      "  [0.66872299]\n",
      "  [0.67853516]\n",
      "  [0.6888532 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010461983270943165\n",
      "Predicci√≥n post entrenamiento : [[0.6995177]]\n",
      "PERDIDAAAA despues: 0.010208649560809135\n",
      "loss en el callback: 0.028611881658434868, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "ejemplar: [[0.62819117]\n",
      " [0.63814878]\n",
      " [0.64837044]\n",
      " [0.65831947]\n",
      " [0.66872299]\n",
      " [0.67853516]\n",
      " [0.6888532 ]\n",
      " [0.69827175]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7705295155354442\n",
      "Predicci√≥n : [[0.70823556]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[[0.62819117]\n",
      "  [0.63814878]\n",
      "  [0.64837044]\n",
      "  [0.65831947]\n",
      "  [0.66872299]\n",
      "  [0.67853516]\n",
      "  [0.6888532 ]\n",
      "  [0.69827175]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0038805357180535793\n",
      "Predicci√≥n post entrenamiento : [[0.70882124]]\n",
      "PERDIDAAAA despues: 0.003807910718023777\n",
      "loss en el callback: 0.005803217180073261, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "ejemplar: [[0.63814878]\n",
      " [0.64837044]\n",
      " [0.65831947]\n",
      " [0.66872299]\n",
      " [0.67853516]\n",
      " [0.6888532 ]\n",
      " [0.69827175]\n",
      " [0.70823556]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7426586795525351\n",
      "Predicci√≥n : [[0.71745545]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[[0.63814878]\n",
      "  [0.64837044]\n",
      "  [0.65831947]\n",
      "  [0.66872299]\n",
      "  [0.67853516]\n",
      "  [0.6888532 ]\n",
      "  [0.69827175]\n",
      "  [0.70823556]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006352026830427349\n",
      "Predicci√≥n post entrenamiento : [[0.7177344]]\n",
      "PERDIDAAAA despues: 0.0006212196312844753\n",
      "loss en el callback: 0.0013766279444098473, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "ejemplar: [[0.64837044]\n",
      " [0.65831947]\n",
      " [0.66872299]\n",
      " [0.67853516]\n",
      " [0.6888532 ]\n",
      " [0.69827175]\n",
      " [0.70823556]\n",
      " [0.71745545]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.716943098182225\n",
      "Predicci√≥n : [[0.726407]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[[0.64837044]\n",
      "  [0.65831947]\n",
      "  [0.66872299]\n",
      "  [0.67853516]\n",
      "  [0.6888532 ]\n",
      "  [0.69827175]\n",
      "  [0.70823556]\n",
      "  [0.71745545]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.956552483141422e-05\n",
      "Predicci√≥n post entrenamiento : [[0.72564065]]\n",
      "PERDIDAAAA despues: 7.564771658508107e-05\n",
      "loss en el callback: 0.00801315438002348, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "ejemplar: [[0.65831947]\n",
      " [0.66872299]\n",
      " [0.67853516]\n",
      " [0.6888532 ]\n",
      " [0.69827175]\n",
      " [0.70823556]\n",
      " [0.71745545]\n",
      " [0.72640699]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7197051306082382\n",
      "Predicci√≥n : [[0.7342584]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[[0.65831947]\n",
      "  [0.66872299]\n",
      "  [0.67853516]\n",
      "  [0.6888532 ]\n",
      "  [0.69827175]\n",
      "  [0.70823556]\n",
      "  [0.71745545]\n",
      "  [0.72640699]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00021179878967814147\n",
      "Predicci√≥n post entrenamiento : [[0.73450994]]\n",
      "PERDIDAAAA despues: 0.0002191832900280133\n",
      "loss en el callback: 0.0012392540229484439, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "ejemplar: [[0.66872299]\n",
      " [0.67853516]\n",
      " [0.6888532 ]\n",
      " [0.69827175]\n",
      " [0.70823556]\n",
      " [0.71745545]\n",
      " [0.72640699]\n",
      " [0.73425841]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7509447768305747\n",
      "Predicci√≥n : [[0.7431107]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[[0.66872299]\n",
      "  [0.67853516]\n",
      "  [0.6888532 ]\n",
      "  [0.69827175]\n",
      "  [0.70823556]\n",
      "  [0.71745545]\n",
      "  [0.72640699]\n",
      "  [0.73425841]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.137276068329811e-05\n",
      "Predicci√≥n post entrenamiento : [[0.7429751]]\n",
      "PERDIDAAAA despues: 6.351575575536117e-05\n",
      "loss en el callback: 0.0002856020291801542, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "ejemplar: [[0.67853516]\n",
      " [0.6888532 ]\n",
      " [0.69827175]\n",
      " [0.70823556]\n",
      " [0.71745545]\n",
      " [0.72640699]\n",
      " [0.73425841]\n",
      " [0.74311072]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.740278139029679\n",
      "Predicci√≥n : [[0.75138605]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[[0.67853516]\n",
      "  [0.6888532 ]\n",
      "  [0.69827175]\n",
      "  [0.70823556]\n",
      "  [0.71745545]\n",
      "  [0.72640699]\n",
      "  [0.73425841]\n",
      "  [0.74311072]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001233859220519662\n",
      "Predicci√≥n post entrenamiento : [[0.75023127]]\n",
      "PERDIDAAAA despues: 9.906502236844972e-05\n",
      "loss en el callback: 0.017945123836398125, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "ejemplar: [[0.6888532 ]\n",
      " [0.69827175]\n",
      " [0.70823556]\n",
      " [0.71745545]\n",
      " [0.72640699]\n",
      " [0.73425841]\n",
      " [0.74311072]\n",
      " [0.75138605]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.687705217205551\n",
      "Predicci√≥n : [[0.75854385]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[[0.6888532 ]\n",
      "  [0.69827175]\n",
      "  [0.70823556]\n",
      "  [0.71745545]\n",
      "  [0.72640699]\n",
      "  [0.73425841]\n",
      "  [0.74311072]\n",
      "  [0.75138605]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005018111318349838\n",
      "Predicci√≥n post entrenamiento : [[0.75810885]]\n",
      "PERDIDAAAA despues: 0.004956671968102455\n",
      "loss en el callback: 0.0030494730453938246, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "ejemplar: [[0.69827175]\n",
      " [0.70823556]\n",
      " [0.71745545]\n",
      " [0.72640699]\n",
      " [0.73425841]\n",
      " [0.74311072]\n",
      " [0.75138605]\n",
      " [0.75854385]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6687695580612426\n",
      "Predicci√≥n : [[0.7661187]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[[0.69827175]\n",
      "  [0.70823556]\n",
      "  [0.71745545]\n",
      "  [0.72640699]\n",
      "  [0.73425841]\n",
      "  [0.74311072]\n",
      "  [0.75138605]\n",
      "  [0.75854385]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0094768600538373\n",
      "Predicci√≥n post entrenamiento : [[0.76515764]]\n",
      "PERDIDAAAA despues: 0.009290666319429874\n",
      "loss en el callback: 0.016047976911067963, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "ejemplar: [[0.70823556]\n",
      " [0.71745545]\n",
      " [0.72640699]\n",
      " [0.73425841]\n",
      " [0.74311072]\n",
      " [0.75138605]\n",
      " [0.75854385]\n",
      " [0.76611871]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6834711615967536\n",
      "Predicci√≥n : [[0.7730211]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[[0.70823556]\n",
      "  [0.71745545]\n",
      "  [0.72640699]\n",
      "  [0.73425841]\n",
      "  [0.74311072]\n",
      "  [0.75138605]\n",
      "  [0.75854385]\n",
      "  [0.76611871]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008019194938242435\n",
      "Predicci√≥n post entrenamiento : [[0.77232885]]\n",
      "PERDIDAAAA despues: 0.007895692251622677\n",
      "loss en el callback: 0.008688055910170078, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "ejemplar: [[0.71745545]\n",
      " [0.72640699]\n",
      " [0.73425841]\n",
      " [0.74311072]\n",
      " [0.75138605]\n",
      " [0.75854385]\n",
      " [0.76611871]\n",
      " [0.7730211 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6877052172055499\n",
      "Predicci√≥n : [[0.77981776]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[[0.71745545]\n",
      "  [0.72640699]\n",
      "  [0.73425841]\n",
      "  [0.74311072]\n",
      "  [0.75138605]\n",
      "  [0.75854385]\n",
      "  [0.76611871]\n",
      "  [0.7730211 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00848472025245428\n",
      "Predicci√≥n post entrenamiento : [[0.7786152]]\n",
      "PERDIDAAAA despues: 0.008264620788395405\n",
      "loss en el callback: 0.023014523088932037, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "ejemplar: [[0.72640699]\n",
      " [0.73425841]\n",
      " [0.74311072]\n",
      " [0.75138605]\n",
      " [0.75854385]\n",
      " [0.76611871]\n",
      " [0.7730211 ]\n",
      " [0.77981776]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6814717248876317\n",
      "Predicci√≥n : [[0.7858331]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[[0.72640699]\n",
      "  [0.73425841]\n",
      "  [0.74311072]\n",
      "  [0.75138605]\n",
      "  [0.75854385]\n",
      "  [0.76611871]\n",
      "  [0.7730211 ]\n",
      "  [0.77981776]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010891305282711983\n",
      "Predicci√≥n post entrenamiento : [[0.78582084]]\n",
      "PERDIDAAAA despues: 0.010888742282986641\n",
      "loss en el callback: 3.6689673379441956e-06, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "ejemplar: [[0.73425841]\n",
      " [0.74311072]\n",
      " [0.75138605]\n",
      " [0.75854385]\n",
      " [0.76611871]\n",
      " [0.7730211 ]\n",
      " [0.77981776]\n",
      " [0.78583312]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.689261843882625\n",
      "Predicci√≥n : [[0.7927558]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[[0.73425841]\n",
      "  [0.74311072]\n",
      "  [0.75138605]\n",
      "  [0.75854385]\n",
      "  [0.76611871]\n",
      "  [0.7730211 ]\n",
      "  [0.77981776]\n",
      "  [0.78583312]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01071099378168583\n",
      "Predicci√≥n post entrenamiento : [[0.7932088]]\n",
      "PERDIDAAAA despues: 0.010804963298141956\n",
      "loss en el callback: 0.005366338882595301, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "ejemplar: [[0.74311072]\n",
      " [0.75138605]\n",
      " [0.75854385]\n",
      " [0.76611871]\n",
      " [0.7730211 ]\n",
      " [0.77981776]\n",
      " [0.78583312]\n",
      " [0.79275578]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7110755741905297\n",
      "Predicci√≥n : [[0.80008453]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[[0.74311072]\n",
      "  [0.75138605]\n",
      "  [0.75854385]\n",
      "  [0.76611871]\n",
      "  [0.7730211 ]\n",
      "  [0.77981776]\n",
      "  [0.78583312]\n",
      "  [0.79275578]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007922588847577572\n",
      "Predicci√≥n post entrenamiento : [[0.79909956]]\n",
      "PERDIDAAAA despues: 0.007748217787593603\n",
      "loss en el callback: 0.016696808859705925, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "ejemplar: [[0.75138605]\n",
      " [0.75854385]\n",
      " [0.76611871]\n",
      " [0.7730211 ]\n",
      " [0.77981776]\n",
      " [0.78583312]\n",
      " [0.79275578]\n",
      " [0.80008453]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7349108623046875\n",
      "Predicci√≥n : [[0.80557764]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[[0.75138605]\n",
      "  [0.75854385]\n",
      "  [0.76611871]\n",
      "  [0.7730211 ]\n",
      "  [0.77981776]\n",
      "  [0.78583312]\n",
      "  [0.79275578]\n",
      "  [0.80008453]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004993795417249203\n",
      "Predicci√≥n post entrenamiento : [[0.8045418]]\n",
      "PERDIDAAAA despues: 0.004848473239690065\n",
      "loss en el callback: 0.01745886355638504, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "ejemplar: [[0.75854385]\n",
      " [0.76611871]\n",
      " [0.7730211 ]\n",
      " [0.77981776]\n",
      " [0.78583312]\n",
      " [0.79275578]\n",
      " [0.80008453]\n",
      " [0.80557764]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7607677082250986\n",
      "Predicci√≥n : [[0.8106925]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[[0.75854385]\n",
      "  [0.76611871]\n",
      "  [0.7730211 ]\n",
      "  [0.77981776]\n",
      "  [0.78583312]\n",
      "  [0.79275578]\n",
      "  [0.80008453]\n",
      "  [0.80557764]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002492484636604786\n",
      "Predicci√≥n post entrenamiento : [[0.80970496]]\n",
      "PERDIDAAAA despues: 0.0023948554880917072\n",
      "loss en el callback: 0.015642499551177025, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "ejemplar: [[0.76611871]\n",
      " [0.7730211 ]\n",
      " [0.77981776]\n",
      " [0.78583312]\n",
      " [0.79275578]\n",
      " [0.80008453]\n",
      " [0.80557764]\n",
      " [0.81069249]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7711170829224028\n",
      "Predicci√≥n : [[0.8157646]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[[0.76611871]\n",
      "  [0.7730211 ]\n",
      "  [0.77981776]\n",
      "  [0.78583312]\n",
      "  [0.79275578]\n",
      "  [0.80008453]\n",
      "  [0.80557764]\n",
      "  [0.81069249]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0019934005104005337\n",
      "Predicci√≥n post entrenamiento : [[0.8161564]]\n",
      "PERDIDAAAA despues: 0.0020285381469875574\n",
      "loss en el callback: 0.0035149569157510996, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "ejemplar: [[0.7730211 ]\n",
      " [0.77981776]\n",
      " [0.78583312]\n",
      " [0.79275578]\n",
      " [0.80008453]\n",
      " [0.80557764]\n",
      " [0.81069249]\n",
      " [0.81576461]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7659589863965997\n",
      "Predicci√≥n : [[0.8219576]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[[0.7730211 ]\n",
      "  [0.77981776]\n",
      "  [0.78583312]\n",
      "  [0.79275578]\n",
      "  [0.80008453]\n",
      "  [0.80557764]\n",
      "  [0.81069249]\n",
      "  [0.81576461]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0031358457636088133\n",
      "Predicci√≥n post entrenamiento : [[0.8213878]]\n",
      "PERDIDAAAA despues: 0.003072358900681138\n",
      "loss en el callback: 0.005987969227135181, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "ejemplar: [[0.77981776]\n",
      " [0.78583312]\n",
      " [0.79275578]\n",
      " [0.80008453]\n",
      " [0.80557764]\n",
      " [0.81069249]\n",
      " [0.81576461]\n",
      " [0.82195759]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7483323528772654\n",
      "Predicci√≥n : [[0.82704675]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[[0.77981776]\n",
      "  [0.78583312]\n",
      "  [0.79275578]\n",
      "  [0.80008453]\n",
      "  [0.80557764]\n",
      "  [0.81069249]\n",
      "  [0.81576461]\n",
      "  [0.82195759]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00619595218449831\n",
      "Predicci√≥n post entrenamiento : [[0.8268747]]\n",
      "PERDIDAAAA despues: 0.006168891675770283\n",
      "loss en el callback: 0.000611005409155041, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "ejemplar: [[0.78583312]\n",
      " [0.79275578]\n",
      " [0.80008453]\n",
      " [0.80557764]\n",
      " [0.81069249]\n",
      " [0.81576461]\n",
      " [0.82195759]\n",
      " [0.82704675]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7182371823643998\n",
      "Predicci√≥n : [[0.8323668]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[[0.78583312]\n",
      "  [0.79275578]\n",
      "  [0.80008453]\n",
      "  [0.80557764]\n",
      "  [0.81069249]\n",
      "  [0.81576461]\n",
      "  [0.82195759]\n",
      "  [0.82704675]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01302557997405529\n",
      "Predicci√≥n post entrenamiento : [[0.8319298]]\n",
      "PERDIDAAAA despues: 0.012926016934216022\n",
      "loss en el callback: 0.00398655841127038, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "ejemplar: [[0.79275578]\n",
      " [0.80008453]\n",
      " [0.80557764]\n",
      " [0.81069249]\n",
      " [0.81576461]\n",
      " [0.82195759]\n",
      " [0.82704675]\n",
      " [0.83236682]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7089416644962148\n",
      "Predicci√≥n : [[0.8374197]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[[0.79275578]\n",
      "  [0.80008453]\n",
      "  [0.80557764]\n",
      "  [0.81069249]\n",
      "  [0.81576461]\n",
      "  [0.82195759]\n",
      "  [0.82704675]\n",
      "  [0.83236682]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016506608575582504\n",
      "Predicci√≥n post entrenamiento : [[0.83562833]]\n",
      "PERDIDAAAA despues: 0.016049517318606377\n",
      "loss en el callback: 0.054017599672079086, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "ejemplar: [[0.80008453]\n",
      " [0.80557764]\n",
      " [0.81069249]\n",
      " [0.81576461]\n",
      " [0.82195759]\n",
      " [0.82704675]\n",
      " [0.83236682]\n",
      " [0.83741969]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7204457992727099\n",
      "Predicci√≥n : [[0.84081763]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[[0.80008453]\n",
      "  [0.80557764]\n",
      "  [0.81069249]\n",
      "  [0.81576461]\n",
      "  [0.82195759]\n",
      "  [0.82704675]\n",
      "  [0.83236682]\n",
      "  [0.83741969]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014489375054836273\n",
      "Predicci√≥n post entrenamiento : [[0.8408128]]\n",
      "PERDIDAAAA despues: 0.014488212764263153\n",
      "loss en el callback: 7.145541758291074e-07, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "ejemplar: [[0.80557764]\n",
      " [0.81069249]\n",
      " [0.81576461]\n",
      " [0.82195759]\n",
      " [0.82704675]\n",
      " [0.83236682]\n",
      " [0.83741969]\n",
      " [0.84081763]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.770615477342717\n",
      "Predicci√≥n : [[0.84550714]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[[0.80557764]\n",
      "  [0.81069249]\n",
      "  [0.81576461]\n",
      "  [0.82195759]\n",
      "  [0.82704675]\n",
      "  [0.83236682]\n",
      "  [0.83741969]\n",
      "  [0.84081763]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005608764477074146\n",
      "Predicci√≥n post entrenamiento : [[0.84343034]]\n",
      "PERDIDAAAA despues: 0.005302006844431162\n",
      "loss en el callback: 0.06633040308952332, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "ejemplar: [[0.81069249]\n",
      " [0.81576461]\n",
      " [0.82195759]\n",
      " [0.82704675]\n",
      " [0.83236682]\n",
      " [0.83741969]\n",
      " [0.84081763]\n",
      " [0.84550714]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8594506987062355\n",
      "Predicci√≥n : [[0.8480522]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[[0.81069249]\n",
      "  [0.81576461]\n",
      "  [0.82195759]\n",
      "  [0.82704675]\n",
      "  [0.83236682]\n",
      "  [0.83741969]\n",
      "  [0.84081763]\n",
      "  [0.84550714]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00012992566917091608\n",
      "Predicci√≥n post entrenamiento : [[0.84907126]]\n",
      "PERDIDAAAA despues: 0.0001077326451195404\n",
      "loss en el callback: 0.03257490321993828, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "ejemplar: [[0.81576461]\n",
      " [0.82195759]\n",
      " [0.82704675]\n",
      " [0.83236682]\n",
      " [0.83741969]\n",
      " [0.84081763]\n",
      " [0.84550714]\n",
      " [0.8480522 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9065410812466371\n",
      "Predicci√≥n : [[0.8536866]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[[0.81576461]\n",
      "  [0.82195759]\n",
      "  [0.82704675]\n",
      "  [0.83236682]\n",
      "  [0.83741969]\n",
      "  [0.84081763]\n",
      "  [0.84550714]\n",
      "  [0.8480522 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002793602179735899\n",
      "Predicci√≥n post entrenamiento : [[0.85371614]]\n",
      "PERDIDAAAA despues: 0.0027904778253287077\n",
      "loss en el callback: 1.6127632989082485e-05, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "ejemplar: [[0.82195759]\n",
      " [0.82704675]\n",
      " [0.83236682]\n",
      " [0.83741969]\n",
      " [0.84081763]\n",
      " [0.84550714]\n",
      " [0.8480522 ]\n",
      " [0.85368657]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9118866249639219\n",
      "Predicci√≥n : [[0.85829514]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[[0.82195759]\n",
      "  [0.82704675]\n",
      "  [0.83236682]\n",
      "  [0.83741969]\n",
      "  [0.84081763]\n",
      "  [0.84550714]\n",
      "  [0.8480522 ]\n",
      "  [0.85368657]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0028720477130264044\n",
      "Predicci√≥n post entrenamiento : [[0.85928255]]\n",
      "PERDIDAAAA despues: 0.002767189173027873\n",
      "loss en el callback: 0.02579609490931034, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "ejemplar: [[0.82704675]\n",
      " [0.83236682]\n",
      " [0.83741969]\n",
      " [0.84081763]\n",
      " [0.84550714]\n",
      " [0.8480522 ]\n",
      " [0.85368657]\n",
      " [0.85829514]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.904335569053715\n",
      "Predicci√≥n : [[0.863464]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[[0.82704675]\n",
      "  [0.83236682]\n",
      "  [0.83741969]\n",
      "  [0.84081763]\n",
      "  [0.84550714]\n",
      "  [0.8480522 ]\n",
      "  [0.85368657]\n",
      "  [0.85829514]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016704844310879707\n",
      "Predicci√≥n post entrenamiento : [[0.86349577]]\n",
      "PERDIDAAAA despues: 0.0016678886022418737\n",
      "loss en el callback: 1.9581057131290436e-05, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "ejemplar: [[0.83236682]\n",
      " [0.83741969]\n",
      " [0.84081763]\n",
      " [0.84550714]\n",
      " [0.8480522 ]\n",
      " [0.85368657]\n",
      " [0.85829514]\n",
      " [0.863464  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8838879135160167\n",
      "Predicci√≥n : [[0.86752033]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[[0.83236682]\n",
      "  [0.83741969]\n",
      "  [0.84081763]\n",
      "  [0.84550714]\n",
      "  [0.8480522 ]\n",
      "  [0.85368657]\n",
      "  [0.85829514]\n",
      "  [0.863464  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00026789685944095254\n",
      "Predicci√≥n post entrenamiento : [[0.86707956]]\n",
      "PERDIDAAAA despues: 0.000282519991742447\n",
      "loss en el callback: 0.003601223463192582, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "ejemplar: [[0.83741969]\n",
      " [0.84081763]\n",
      " [0.84550714]\n",
      " [0.8480522 ]\n",
      " [0.85368657]\n",
      " [0.85829514]\n",
      " [0.863464  ]\n",
      " [0.86752033]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9032153489332012\n",
      "Predicci√≥n : [[0.8708524]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[[0.83741969]\n",
      "  [0.84081763]\n",
      "  [0.84550714]\n",
      "  [0.8480522 ]\n",
      "  [0.85368657]\n",
      "  [0.85829514]\n",
      "  [0.863464  ]\n",
      "  [0.86752033]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010473597794771194\n",
      "Predicci√≥n post entrenamiento : [[0.87060237]]\n",
      "PERDIDAAAA despues: 0.0010636064689606428\n",
      "loss en el callback: 0.0012081994209438562, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "ejemplar: [[0.84081763]\n",
      " [0.84550714]\n",
      " [0.8480522 ]\n",
      " [0.85368657]\n",
      " [0.85829514]\n",
      " [0.863464  ]\n",
      " [0.86752033]\n",
      " [0.87085241]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9623178753052692\n",
      "Predicci√≥n : [[0.8741656]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[[0.84081763]\n",
      "  [0.84550714]\n",
      "  [0.8480522 ]\n",
      "  [0.85368657]\n",
      "  [0.85829514]\n",
      "  [0.863464  ]\n",
      "  [0.86752033]\n",
      "  [0.87085241]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007770826108753681\n",
      "Predicci√≥n post entrenamiento : [[0.8739326]]\n",
      "PERDIDAAAA despues: 0.007811958435922861\n",
      "loss en el callback: 0.0010136696510016918, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "ejemplar: [[0.84550714]\n",
      " [0.8480522 ]\n",
      " [0.85368657]\n",
      " [0.85829514]\n",
      " [0.863464  ]\n",
      " [0.86752033]\n",
      " [0.87085241]\n",
      " [0.87416559]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.982058820003038\n",
      "Predicci√≥n : [[0.87773204]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[[0.84550714]\n",
      "  [0.8480522 ]\n",
      "  [0.85368657]\n",
      "  [0.85829514]\n",
      "  [0.863464  ]\n",
      "  [0.86752033]\n",
      "  [0.87085241]\n",
      "  [0.87416559]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010884078219532967\n",
      "Predicci√≥n post entrenamiento : [[0.878974]]\n",
      "PERDIDAAAA despues: 0.010626476258039474\n",
      "loss en el callback: 0.04505724459886551, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "ejemplar: [[0.8480522 ]\n",
      " [0.85368657]\n",
      " [0.85829514]\n",
      " [0.863464  ]\n",
      " [0.86752033]\n",
      " [0.87085241]\n",
      " [0.87416559]\n",
      " [0.87773204]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9624381830265082\n",
      "Predicci√≥n : [[0.88266367]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[[0.8480522 ]\n",
      "  [0.85368657]\n",
      "  [0.85829514]\n",
      "  [0.863464  ]\n",
      "  [0.86752033]\n",
      "  [0.87085241]\n",
      "  [0.87416559]\n",
      "  [0.87773204]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006363970693200827\n",
      "Predicci√≥n post entrenamiento : [[0.8808177]]\n",
      "PERDIDAAAA despues: 0.006661898456513882\n",
      "loss en el callback: 0.04837449640035629, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "ejemplar: [[0.85368657]\n",
      " [0.85829514]\n",
      " [0.863464  ]\n",
      " [0.86752033]\n",
      " [0.87085241]\n",
      " [0.87416559]\n",
      " [0.87773204]\n",
      " [0.88266367]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9302512105217627\n",
      "Predicci√≥n : [[0.88497967]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[[0.85368657]\n",
      "  [0.85829514]\n",
      "  [0.863464  ]\n",
      "  [0.86752033]\n",
      "  [0.87085241]\n",
      "  [0.87416559]\n",
      "  [0.87773204]\n",
      "  [0.88266367]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002049510134384036\n",
      "Predicci√≥n post entrenamiento : [[0.8858399]]\n",
      "PERDIDAAAA despues: 0.0019723637960851192\n",
      "loss en el callback: 0.023160334676504135, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "ejemplar: [[0.85829514]\n",
      " [0.863464  ]\n",
      " [0.86752033]\n",
      " [0.87085241]\n",
      " [0.87416559]\n",
      " [0.87773204]\n",
      " [0.88266367]\n",
      " [0.88497967]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.885497902488802\n",
      "Predicci√≥n : [[0.88962287]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[[0.85829514]\n",
      "  [0.863464  ]\n",
      "  [0.86752033]\n",
      "  [0.87085241]\n",
      "  [0.87416559]\n",
      "  [0.87773204]\n",
      "  [0.88266367]\n",
      "  [0.88497967]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.7015125195030123e-05\n",
      "Predicci√≥n post entrenamiento : [[0.89007014]]\n",
      "PERDIDAAAA despues: 2.090512862196192e-05\n",
      "loss en el callback: 0.005368216894567013, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "ejemplar: [[0.863464  ]\n",
      " [0.86752033]\n",
      " [0.87085241]\n",
      " [0.87416559]\n",
      " [0.87773204]\n",
      " [0.88266367]\n",
      " [0.88497967]\n",
      " [0.88962287]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597025687419927\n",
      "Predicci√≥n : [[0.89368635]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[[0.863464  ]\n",
      "  [0.86752033]\n",
      "  [0.87085241]\n",
      "  [0.87416559]\n",
      "  [0.87773204]\n",
      "  [0.88266367]\n",
      "  [0.88497967]\n",
      "  [0.88962287]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011548964539542794\n",
      "Predicci√≥n post entrenamiento : [[0.8925817]]\n",
      "PERDIDAAAA despues: 0.0010810361709445715\n",
      "loss en el callback: 0.022903401404619217, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "ejemplar: [[0.86752033]\n",
      " [0.87085241]\n",
      " [0.87416559]\n",
      " [0.87773204]\n",
      " [0.88266367]\n",
      " [0.88497967]\n",
      " [0.88962287]\n",
      " [0.89368635]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8528652092813349\n",
      "Predicci√≥n : [[0.8958302]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[[0.86752033]\n",
      "  [0.87085241]\n",
      "  [0.87416559]\n",
      "  [0.87773204]\n",
      "  [0.88266367]\n",
      "  [0.88497967]\n",
      "  [0.88962287]\n",
      "  [0.89368635]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018459907732903957\n",
      "Predicci√≥n post entrenamiento : [[0.89569074]]\n",
      "PERDIDAAAA despues: 0.001834025140851736\n",
      "loss en el callback: 0.0004913823795504868, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "ejemplar: [[0.87085241]\n",
      " [0.87416559]\n",
      " [0.87773204]\n",
      " [0.88266367]\n",
      " [0.88497967]\n",
      " [0.88962287]\n",
      " [0.89368635]\n",
      " [0.89583021]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8585854533368672\n",
      "Predicci√≥n : [[0.89883465]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[[0.87085241]\n",
      "  [0.87416559]\n",
      "  [0.87773204]\n",
      "  [0.88266367]\n",
      "  [0.88497967]\n",
      "  [0.88962287]\n",
      "  [0.89368635]\n",
      "  [0.89583021]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016199955716729164\n",
      "Predicci√≥n post entrenamiento : [[0.898713]]\n",
      "PERDIDAAAA despues: 0.0016102174995467067\n",
      "loss en el callback: 0.00038005775422789156, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "ejemplar: [[0.87416559]\n",
      " [0.87773204]\n",
      " [0.88266367]\n",
      " [0.88497967]\n",
      " [0.88962287]\n",
      " [0.89368635]\n",
      " [0.89583021]\n",
      " [0.89883465]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8768633009085897\n",
      "Predicci√≥n : [[0.9019386]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[[0.87416559]\n",
      "  [0.87773204]\n",
      "  [0.88266367]\n",
      "  [0.88497967]\n",
      "  [0.88962287]\n",
      "  [0.89368635]\n",
      "  [0.89583021]\n",
      "  [0.89883465]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006287714932113886\n",
      "Predicci√≥n post entrenamiento : [[0.9023071]]\n",
      "PERDIDAAAA despues: 0.00064738659420982\n",
      "loss en el callback: 0.004134643357247114, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "ejemplar: [[0.87773204]\n",
      " [0.88266367]\n",
      " [0.88497967]\n",
      " [0.88962287]\n",
      " [0.89368635]\n",
      " [0.89583021]\n",
      " [0.89883465]\n",
      " [0.90193862]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8806463966074481\n",
      "Predicci√≥n : [[0.9056179]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[[0.87773204]\n",
      "  [0.88266367]\n",
      "  [0.88497967]\n",
      "  [0.88962287]\n",
      "  [0.89368635]\n",
      "  [0.89583021]\n",
      "  [0.89883465]\n",
      "  [0.90193862]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006235750624909997\n",
      "Predicci√≥n post entrenamiento : [[0.90536207]]\n",
      "PERDIDAAAA despues: 0.0006108639645390213\n",
      "loss en el callback: 0.0015332591719925404, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "ejemplar: [[0.88266367]\n",
      " [0.88497967]\n",
      " [0.88962287]\n",
      " [0.89368635]\n",
      " [0.89583021]\n",
      " [0.89883465]\n",
      " [0.90193862]\n",
      " [0.90561789]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8699347404334429\n",
      "Predicci√≥n : [[0.9086763]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[[0.88266367]\n",
      "  [0.88497967]\n",
      "  [0.88962287]\n",
      "  [0.89368635]\n",
      "  [0.89583021]\n",
      "  [0.89883465]\n",
      "  [0.90193862]\n",
      "  [0.90561789]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015009107301011682\n",
      "Predicci√≥n post entrenamiento : [[0.9089851]]\n",
      "PERDIDAAAA despues: 0.001524929073639214\n",
      "loss en el callback: 0.003135478589683771, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "ejemplar: [[0.88497967]\n",
      " [0.88962287]\n",
      " [0.89368635]\n",
      " [0.89583021]\n",
      " [0.89883465]\n",
      " [0.90193862]\n",
      " [0.90561789]\n",
      " [0.90867633]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8465135437340043\n",
      "Predicci√≥n : [[0.91188943]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[[0.88497967]\n",
      "  [0.88962287]\n",
      "  [0.89368635]\n",
      "  [0.89583021]\n",
      "  [0.89883465]\n",
      "  [0.90193862]\n",
      "  [0.90561789]\n",
      "  [0.90867633]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0042740036733448505\n",
      "Predicci√≥n post entrenamiento : [[0.91242874]]\n",
      "PERDIDAAAA despues: 0.0043448093347251415\n",
      "loss en el callback: 0.010753142647445202, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "ejemplar: [[0.88962287]\n",
      " [0.89368635]\n",
      " [0.89583021]\n",
      " [0.89883465]\n",
      " [0.90193862]\n",
      " [0.90561789]\n",
      " [0.90867633]\n",
      " [0.91188943]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8103828065091326\n",
      "Predicci√≥n : [[0.9156075]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[[0.88962287]\n",
      "  [0.89368635]\n",
      "  [0.89583021]\n",
      "  [0.89883465]\n",
      "  [0.90193862]\n",
      "  [0.90561789]\n",
      "  [0.90867633]\n",
      "  [0.91188943]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011072243563830853\n",
      "Predicci√≥n post entrenamiento : [[0.9137424]]\n",
      "PERDIDAAAA despues: 0.010683215223252773\n",
      "loss en el callback: 0.07523312419652939, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "ejemplar: [[0.89368635]\n",
      " [0.89583021]\n",
      " [0.89883465]\n",
      " [0.90193862]\n",
      " [0.90561789]\n",
      " [0.90867633]\n",
      " [0.91188943]\n",
      " [0.91560751]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8026111217617493\n",
      "Predicci√≥n : [[0.9165513]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[[0.89368635]\n",
      "  [0.89583021]\n",
      "  [0.89883465]\n",
      "  [0.90193862]\n",
      "  [0.90561789]\n",
      "  [0.90867633]\n",
      "  [0.91188943]\n",
      "  [0.91560751]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012982364743947983\n",
      "Predicci√≥n post entrenamiento : [[0.9158549]]\n",
      "PERDIDAAAA despues: 0.012824148871004581\n",
      "loss en el callback: 0.01250633504241705, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "ejemplar: [[0.89583021]\n",
      " [0.89883465]\n",
      " [0.90193862]\n",
      " [0.90561789]\n",
      " [0.90867633]\n",
      " [0.91188943]\n",
      " [0.91560751]\n",
      " [0.91655129]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.823198489491854\n",
      "Predicci√≥n : [[0.9183984]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[[0.89583021]\n",
      "  [0.89883465]\n",
      "  [0.90193862]\n",
      "  [0.90561789]\n",
      "  [0.90867633]\n",
      "  [0.91188943]\n",
      "  [0.91560751]\n",
      "  [0.91655129]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009063017554581165\n",
      "Predicci√≥n post entrenamiento : [[0.9184543]]\n",
      "PERDIDAAAA despues: 0.009073666296899319\n",
      "loss en el callback: 9.730971942190081e-05, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "ejemplar: [[0.89883465]\n",
      " [0.90193862]\n",
      " [0.90561789]\n",
      " [0.90867633]\n",
      " [0.91188943]\n",
      " [0.91560751]\n",
      " [0.91655129]\n",
      " [0.91839838]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8397204264676091\n",
      "Predicci√≥n : [[0.9212371]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[[0.89883465]\n",
      "  [0.90193862]\n",
      "  [0.90561789]\n",
      "  [0.90867633]\n",
      "  [0.91188943]\n",
      "  [0.91560751]\n",
      "  [0.91655129]\n",
      "  [0.91839838]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006644969806075096\n",
      "Predicci√≥n post entrenamiento : [[0.9214883]]\n",
      "PERDIDAAAA despues: 0.006685982458293438\n",
      "loss en el callback: 0.0022617755457758904, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "ejemplar: [[0.90193862]\n",
      " [0.90561789]\n",
      " [0.90867633]\n",
      " [0.91188943]\n",
      " [0.91560751]\n",
      " [0.91655129]\n",
      " [0.91839838]\n",
      " [0.92123711]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.852176932689015\n",
      "Predicci√≥n : [[0.9242743]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[[0.90193862]\n",
      "  [0.90561789]\n",
      "  [0.90867633]\n",
      "  [0.91188943]\n",
      "  [0.91560751]\n",
      "  [0.91655129]\n",
      "  [0.91839838]\n",
      "  [0.92123711]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005198038183152676\n",
      "Predicci√≥n post entrenamiento : [[0.9230551]]\n",
      "PERDIDAAAA despues: 0.00502372020855546\n",
      "loss en el callback: 0.03277161344885826, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "ejemplar: [[0.90561789]\n",
      " [0.90867633]\n",
      " [0.91188943]\n",
      " [0.91560751]\n",
      " [0.91655129]\n",
      " [0.91839838]\n",
      " [0.92123711]\n",
      " [0.92427433]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8615626813481295\n",
      "Predicci√≥n : [[0.92578745]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[[0.90561789]\n",
      "  [0.90867633]\n",
      "  [0.91188943]\n",
      "  [0.91560751]\n",
      "  [0.91655129]\n",
      "  [0.91839838]\n",
      "  [0.92123711]\n",
      "  [0.92427433]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004124822095036507\n",
      "Predicci√≥n post entrenamiento : [[0.9243465]]\n",
      "PERDIDAAAA despues: 0.0039418102242052555\n",
      "loss en el callback: 0.04248582944273949, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "ejemplar: [[0.90867633]\n",
      " [0.91188943]\n",
      " [0.91560751]\n",
      " [0.91655129]\n",
      " [0.91839838]\n",
      " [0.92123711]\n",
      " [0.92427433]\n",
      " [0.92578745]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8678776724449532\n",
      "Predicci√≥n : [[0.9268202]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[[0.90867633]\n",
      "  [0.91188943]\n",
      "  [0.91560751]\n",
      "  [0.91655129]\n",
      "  [0.91839838]\n",
      "  [0.92123711]\n",
      "  [0.92427433]\n",
      "  [0.92578745]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0034742250572890043\n",
      "Predicci√≥n post entrenamiento : [[0.92578596]]\n",
      "PERDIDAAAA despues: 0.0033533708192408085\n",
      "loss en el callback: 0.02427276223897934, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "ejemplar: [[0.91188943]\n",
      " [0.91560751]\n",
      " [0.91655129]\n",
      " [0.91839838]\n",
      " [0.92123711]\n",
      " [0.92427433]\n",
      " [0.92578745]\n",
      " [0.92682022]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8701963127047843\n",
      "Predicci√≥n : [[0.92811185]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[[0.91188943]\n",
      "  [0.91560751]\n",
      "  [0.91655129]\n",
      "  [0.91839838]\n",
      "  [0.92123711]\n",
      "  [0.92427433]\n",
      "  [0.92578745]\n",
      "  [0.92682022]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0033542062155902386\n",
      "Predicci√≥n post entrenamiento : [[0.9284424]]\n",
      "PERDIDAAAA despues: 0.0033926053438335657\n",
      "loss en el callback: 0.003918732050806284, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "ejemplar: [[0.91560751]\n",
      " [0.91655129]\n",
      " [0.91839838]\n",
      " [0.92123711]\n",
      " [0.92427433]\n",
      " [0.92578745]\n",
      " [0.92682022]\n",
      " [0.92811185]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8685186021276227\n",
      "Predicci√≥n : [[0.9305226]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[[0.91560751]\n",
      "  [0.91655129]\n",
      "  [0.91839838]\n",
      "  [0.92123711]\n",
      "  [0.92427433]\n",
      "  [0.92578745]\n",
      "  [0.92682022]\n",
      "  [0.92811185]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003844499820843339\n",
      "Predicci√≥n post entrenamiento : [[0.9308791]]\n",
      "PERDIDAAAA despues: 0.003888835199177265\n",
      "loss en el callback: 0.004917379468679428, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "ejemplar: [[0.91655129]\n",
      " [0.91839838]\n",
      " [0.92123711]\n",
      " [0.92427433]\n",
      " [0.92578745]\n",
      " [0.92682022]\n",
      " [0.92811185]\n",
      " [0.93052262]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8529880395838255\n",
      "Predicci√≥n : [[0.93251055]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[[0.91655129]\n",
      "  [0.91839838]\n",
      "  [0.92123711]\n",
      "  [0.92427433]\n",
      "  [0.92578745]\n",
      "  [0.92682022]\n",
      "  [0.92811185]\n",
      "  [0.93052262]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006323826499283314\n",
      "Predicci√≥n post entrenamiento : [[0.931531]]\n",
      "PERDIDAAAA despues: 0.006168994586914778\n",
      "loss en el callback: 0.02462317980825901, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "ejemplar: [[0.91839838]\n",
      " [0.92123711]\n",
      " [0.92427433]\n",
      " [0.92578745]\n",
      " [0.92682022]\n",
      " [0.92811185]\n",
      " [0.93052262]\n",
      " [0.93251055]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8236046250733932\n",
      "Predicci√≥n : [[0.9334419]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[[0.91839838]\n",
      "  [0.92123711]\n",
      "  [0.92427433]\n",
      "  [0.92578745]\n",
      "  [0.92682022]\n",
      "  [0.92811185]\n",
      "  [0.93052262]\n",
      "  [0.93251055]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01206421758979559\n",
      "Predicci√≥n post entrenamiento : [[0.9322428]]\n",
      "PERDIDAAAA despues: 0.01180225145071745\n",
      "loss en el callback: 0.037086568772792816, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "ejemplar: [[0.92123711]\n",
      " [0.92427433]\n",
      " [0.92578745]\n",
      " [0.92682022]\n",
      " [0.92811185]\n",
      " [0.93052262]\n",
      " [0.93251055]\n",
      " [0.93344188]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8032508871761479\n",
      "Predicci√≥n : [[0.9341939]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[[0.92123711]\n",
      "  [0.92427433]\n",
      "  [0.92578745]\n",
      "  [0.92682022]\n",
      "  [0.92811185]\n",
      "  [0.93052262]\n",
      "  [0.93251055]\n",
      "  [0.93344188]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017146069556474686\n",
      "Predicci√≥n post entrenamiento : [[0.9321729]]\n",
      "PERDIDAAAA despues: 0.016620878130197525\n",
      "loss en el callback: 0.09280969947576523, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "ejemplar: [[0.92427433]\n",
      " [0.92578745]\n",
      " [0.92682022]\n",
      " [0.92811185]\n",
      " [0.93052262]\n",
      " [0.93251055]\n",
      " [0.93344188]\n",
      " [0.93419391]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7919268258920897\n",
      "Predicci√≥n : [[0.933855]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[[0.92427433]\n",
      "  [0.92578745]\n",
      "  [0.92682022]\n",
      "  [0.92811185]\n",
      "  [0.93052262]\n",
      "  [0.93251055]\n",
      "  [0.93344188]\n",
      "  [0.93419391]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02014361321926117\n",
      "Predicci√≥n post entrenamiento : [[0.9337102]]\n",
      "PERDIDAAAA despues: 0.02010253630578518\n",
      "loss en el callback: 0.0009165676310658455, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "ejemplar: [[0.92578745]\n",
      " [0.92682022]\n",
      " [0.92811185]\n",
      " [0.93052262]\n",
      " [0.93251055]\n",
      " [0.93344188]\n",
      " [0.93419391]\n",
      " [0.933855  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7865023059771536\n",
      "Predicci√≥n : [[0.93499625]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[[0.92578745]\n",
      "  [0.92682022]\n",
      "  [0.92811185]\n",
      "  [0.93052262]\n",
      "  [0.93251055]\n",
      "  [0.93344188]\n",
      "  [0.93419391]\n",
      "  [0.933855  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02205045148730278\n",
      "Predicci√≥n post entrenamiento : [[0.9338355]]\n",
      "PERDIDAAAA despues: 0.021707072854042053\n",
      "loss en el callback: 0.03804761916399002, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "ejemplar: [[0.92682022]\n",
      " [0.92811185]\n",
      " [0.93052262]\n",
      " [0.93251055]\n",
      " [0.93344188]\n",
      " [0.93419391]\n",
      " [0.933855  ]\n",
      " [0.93499625]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7869773274313391\n",
      "Predicci√≥n : [[0.935084]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[[0.92682022]\n",
      "  [0.92811185]\n",
      "  [0.93052262]\n",
      "  [0.93251055]\n",
      "  [0.93344188]\n",
      "  [0.93419391]\n",
      "  [0.933855  ]\n",
      "  [0.93499625]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02193557471036911\n",
      "Predicci√≥n post entrenamiento : [[0.93382084]]\n",
      "PERDIDAAAA despues: 0.021563012152910233\n",
      "loss en el callback: 0.0469961054623127, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "ejemplar: [[0.92811185]\n",
      " [0.93052262]\n",
      " [0.93251055]\n",
      " [0.93344188]\n",
      " [0.93419391]\n",
      " [0.933855  ]\n",
      " [0.93499625]\n",
      " [0.93508399]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7874362431744556\n",
      "Predicci√≥n : [[0.9351353]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[[0.92811185]\n",
      "  [0.93052262]\n",
      "  [0.93251055]\n",
      "  [0.93344188]\n",
      "  [0.93419391]\n",
      "  [0.933855  ]\n",
      "  [0.93499625]\n",
      "  [0.93508399]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.021815011277794838\n",
      "Predicci√≥n post entrenamiento : [[0.93339413]]\n",
      "PERDIDAAAA despues: 0.021303704008460045\n",
      "loss en el callback: 0.08091726154088974, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "ejemplar: [[0.93052262]\n",
      " [0.93251055]\n",
      " [0.93344188]\n",
      " [0.93419391]\n",
      " [0.933855  ]\n",
      " [0.93499625]\n",
      " [0.93508399]\n",
      " [0.9351353 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7878790532065031\n",
      "Predicci√≥n : [[0.93466896]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[[0.93052262]\n",
      "  [0.93251055]\n",
      "  [0.93344188]\n",
      "  [0.93419391]\n",
      "  [0.933855  ]\n",
      "  [0.93499625]\n",
      "  [0.93508399]\n",
      "  [0.9351353 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02154727652668953\n",
      "Predicci√≥n post entrenamiento : [[0.9341417]]\n",
      "PERDIDAAAA despues: 0.021392760798335075\n",
      "loss en el callback: 0.009642097167670727, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "ejemplar: [[0.93251055]\n",
      " [0.93344188]\n",
      " [0.93419391]\n",
      " [0.933855  ]\n",
      " [0.93499625]\n",
      " [0.93508399]\n",
      " [0.9351353 ]\n",
      " [0.93466896]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7954532004373992\n",
      "Predicci√≥n : [[0.9350003]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[[0.93251055]\n",
      "  [0.93344188]\n",
      "  [0.93419391]\n",
      "  [0.933855  ]\n",
      "  [0.93499625]\n",
      "  [0.93508399]\n",
      "  [0.9351353 ]\n",
      "  [0.93466896]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019473396241664886\n",
      "Predicci√≥n post entrenamiento : [[0.9338495]]\n",
      "PERDIDAAAA despues: 0.019153542816638947\n",
      "loss en el callback: 0.04074378311634064, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "ejemplar: [[0.93344188]\n",
      " [0.93419391]\n",
      " [0.933855  ]\n",
      " [0.93499625]\n",
      " [0.93508399]\n",
      " [0.9351353 ]\n",
      " [0.93466896]\n",
      " [0.9350003 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8101586848671446\n",
      "Predicci√≥n : [[0.9343167]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[[0.93344188]\n",
      "  [0.93419391]\n",
      "  [0.933855  ]\n",
      "  [0.93499625]\n",
      "  [0.93508399]\n",
      "  [0.9351353 ]\n",
      "  [0.93466896]\n",
      "  [0.9350003 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01541521493345499\n",
      "Predicci√≥n post entrenamiento : [[0.9338869]]\n",
      "PERDIDAAAA despues: 0.01530867163091898\n",
      "loss en el callback: 0.007357926107943058, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "ejemplar: [[0.93419391]\n",
      " [0.933855  ]\n",
      " [0.93499625]\n",
      " [0.93508399]\n",
      " [0.9351353 ]\n",
      " [0.93466896]\n",
      " [0.9350003 ]\n",
      " [0.93431669]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7668473230866574\n",
      "Predicci√≥n : [[0.9341844]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[[0.93419391]\n",
      "  [0.933855  ]\n",
      "  [0.93499625]\n",
      "  [0.93508399]\n",
      "  [0.9351353 ]\n",
      "  [0.93466896]\n",
      "  [0.9350003 ]\n",
      "  [0.93431669]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02800169214606285\n",
      "Predicci√≥n post entrenamiento : [[0.93395376]]\n",
      "PERDIDAAAA despues: 0.027924565598368645\n",
      "loss en el callback: 0.002427401253953576, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "ejemplar: [[0.933855  ]\n",
      " [0.93499625]\n",
      " [0.93508399]\n",
      " [0.9351353 ]\n",
      " [0.93466896]\n",
      " [0.9350003 ]\n",
      " [0.93431669]\n",
      " [0.93418437]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6655191150959373\n",
      "Predicci√≥n : [[0.9340892]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[[0.933855  ]\n",
      "  [0.93499625]\n",
      "  [0.93508399]\n",
      "  [0.9351353 ]\n",
      "  [0.93466896]\n",
      "  [0.9350003 ]\n",
      "  [0.93431669]\n",
      "  [0.93418437]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07212988287210464\n",
      "Predicci√≥n post entrenamiento : [[0.9320376]]\n",
      "PERDIDAAAA despues: 0.0710320994257927\n",
      "loss en el callback: 0.1225186288356781, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "ejemplar: [[0.93499625]\n",
      " [0.93508399]\n",
      " [0.9351353 ]\n",
      " [0.93466896]\n",
      " [0.9350003 ]\n",
      " [0.93431669]\n",
      " [0.93418437]\n",
      " [0.93408918]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6360738003224796\n",
      "Predicci√≥n : [[0.932286]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[[0.93499625]\n",
      "  [0.93508399]\n",
      "  [0.9351353 ]\n",
      "  [0.93466896]\n",
      "  [0.9350003 ]\n",
      "  [0.93431669]\n",
      "  [0.93418437]\n",
      "  [0.93408918]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0877416655421257\n",
      "Predicci√≥n post entrenamiento : [[0.9305549]]\n",
      "PERDIDAAAA despues: 0.08671911805868149\n",
      "loss en el callback: 0.10052873939275742, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "ejemplar: [[0.93508399]\n",
      " [0.9351353 ]\n",
      " [0.93466896]\n",
      " [0.9350003 ]\n",
      " [0.93431669]\n",
      " [0.93418437]\n",
      " [0.93408918]\n",
      " [0.93228602]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6785113787662842\n",
      "Predicci√≥n : [[0.9304806]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[[0.93508399]\n",
      "  [0.9351353 ]\n",
      "  [0.93466896]\n",
      "  [0.9350003 ]\n",
      "  [0.93431669]\n",
      "  [0.93418437]\n",
      "  [0.93408918]\n",
      "  [0.93228602]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06348848342895508\n",
      "Predicci√≥n post entrenamiento : [[0.92779326]]\n",
      "PERDIDAAAA despues: 0.062141455709934235\n",
      "loss en el callback: 0.19474004209041595, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "ejemplar: [[0.9351353 ]\n",
      " [0.93466896]\n",
      " [0.9350003 ]\n",
      " [0.93431669]\n",
      " [0.93418437]\n",
      " [0.93408918]\n",
      " [0.93228602]\n",
      " [0.9304806 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6965967339840231\n",
      "Predicci√≥n : [[0.92762333]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[[0.9351353 ]\n",
      "  [0.93466896]\n",
      "  [0.9350003 ]\n",
      "  [0.93431669]\n",
      "  [0.93418437]\n",
      "  [0.93408918]\n",
      "  [0.93228602]\n",
      "  [0.9304806 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05337328463792801\n",
      "Predicci√≥n post entrenamiento : [[0.9276221]]\n",
      "PERDIDAAAA despues: 0.05337270721793175\n",
      "loss en el callback: 1.2174906771633687e-07, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "ejemplar: [[0.93466896]\n",
      " [0.9350003 ]\n",
      " [0.93431669]\n",
      " [0.93418437]\n",
      " [0.93408918]\n",
      " [0.93228602]\n",
      " [0.9304806 ]\n",
      " [0.92762333]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6903298659756966\n",
      "Predicci√≥n : [[0.9273104]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[[0.93466896]\n",
      "  [0.9350003 ]\n",
      "  [0.93431669]\n",
      "  [0.93418437]\n",
      "  [0.93408918]\n",
      "  [0.93228602]\n",
      "  [0.9304806 ]\n",
      "  [0.92762333]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05615978315472603\n",
      "Predicci√≥n post entrenamiento : [[0.9267052]]\n",
      "PERDIDAAAA despues: 0.05587329715490341\n",
      "loss en el callback: 0.01708538644015789, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "ejemplar: [[0.9350003 ]\n",
      " [0.93431669]\n",
      " [0.93418437]\n",
      " [0.93408918]\n",
      " [0.93228602]\n",
      " [0.9304806 ]\n",
      " [0.92762333]\n",
      " [0.92731041]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6970473058045382\n",
      "Predicci√≥n : [[0.9263391]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[[0.9350003 ]\n",
      "  [0.93431669]\n",
      "  [0.93418437]\n",
      "  [0.93408918]\n",
      "  [0.93228602]\n",
      "  [0.9304806 ]\n",
      "  [0.92762333]\n",
      "  [0.92731041]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.052574727684259415\n",
      "Predicci√≥n post entrenamiento : [[0.9248148]]\n",
      "PERDIDAAAA despues: 0.05187804624438286\n",
      "loss en el callback: 0.082989901304245, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "ejemplar: [[0.93431669]\n",
      " [0.93418437]\n",
      " [0.93408918]\n",
      " [0.93228602]\n",
      " [0.9304806 ]\n",
      " [0.92762333]\n",
      " [0.92731041]\n",
      " [0.92633909]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7167490534705484\n",
      "Predicci√≥n : [[0.924119]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[[0.93431669]\n",
      "  [0.93418437]\n",
      "  [0.93408918]\n",
      "  [0.93228602]\n",
      "  [0.9304806 ]\n",
      "  [0.92762333]\n",
      "  [0.92731041]\n",
      "  [0.92633909]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.043002285063266754\n",
      "Predicci√≥n post entrenamiento : [[0.9236767]]\n",
      "PERDIDAAAA despues: 0.042819056659936905\n",
      "loss en el callback: 0.009581591933965683, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "ejemplar: [[0.93418437]\n",
      " [0.93408918]\n",
      " [0.93228602]\n",
      " [0.9304806 ]\n",
      " [0.92762333]\n",
      " [0.92731041]\n",
      " [0.92633909]\n",
      " [0.924119  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7490507063998944\n",
      "Predicci√≥n : [[0.9228618]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[[0.93418437]\n",
      "  [0.93408918]\n",
      "  [0.93228602]\n",
      "  [0.9304806 ]\n",
      "  [0.92762333]\n",
      "  [0.92731041]\n",
      "  [0.92633909]\n",
      "  [0.924119  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.030210312455892563\n",
      "Predicci√≥n post entrenamiento : [[0.9224902]]\n",
      "PERDIDAAAA despues: 0.030081260949373245\n",
      "loss en el callback: 0.00606093555688858, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "ejemplar: [[0.93408918]\n",
      " [0.93228602]\n",
      " [0.9304806 ]\n",
      " [0.92762333]\n",
      " [0.92731041]\n",
      " [0.92633909]\n",
      " [0.924119  ]\n",
      " [0.92286181]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7939522645925762\n",
      "Predicci√≥n : [[0.9213571]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[[0.93408918]\n",
      "  [0.93228602]\n",
      "  [0.9304806 ]\n",
      "  [0.92762333]\n",
      "  [0.92731041]\n",
      "  [0.92633909]\n",
      "  [0.924119  ]\n",
      "  [0.92286181]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01623198576271534\n",
      "Predicci√≥n post entrenamiento : [[0.91992664]]\n",
      "PERDIDAAAA despues: 0.015869539231061935\n",
      "loss en el callback: 0.06625579297542572, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "ejemplar: [[0.93228602]\n",
      " [0.9304806 ]\n",
      " [0.92762333]\n",
      " [0.92731041]\n",
      " [0.92633909]\n",
      " [0.924119  ]\n",
      " [0.92286181]\n",
      " [0.9213571 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8547447263586395\n",
      "Predicci√≥n : [[0.91840935]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[[0.93228602]\n",
      "  [0.9304806 ]\n",
      "  [0.92762333]\n",
      "  [0.92731041]\n",
      "  [0.92633909]\n",
      "  [0.924119  ]\n",
      "  [0.92286181]\n",
      "  [0.9213571 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004053183365613222\n",
      "Predicci√≥n post entrenamiento : [[0.9176256]]\n",
      "PERDIDAAAA despues: 0.003954004496335983\n",
      "loss en el callback: 0.020089473575353622, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "ejemplar: [[0.9304806 ]\n",
      " [0.92762333]\n",
      " [0.92731041]\n",
      " [0.92633909]\n",
      " [0.924119  ]\n",
      " [0.92286181]\n",
      " [0.9213571 ]\n",
      " [0.91840935]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9314280916980849\n",
      "Predicci√≥n : [[0.91615665]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[[0.9304806 ]\n",
      "  [0.92762333]\n",
      "  [0.92731041]\n",
      "  [0.92633909]\n",
      "  [0.924119  ]\n",
      "  [0.92286181]\n",
      "  [0.9213571 ]\n",
      "  [0.91840935]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00023321642947848886\n",
      "Predicci√≥n post entrenamiento : [[0.9152033]]\n",
      "PERDIDAAAA despues: 0.0002632441755849868\n",
      "loss en el callback: 0.027271151542663574, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "ejemplar: [[0.92762333]\n",
      " [0.92731041]\n",
      " [0.92633909]\n",
      " [0.924119  ]\n",
      " [0.92286181]\n",
      " [0.9213571 ]\n",
      " [0.91840935]\n",
      " [0.91615665]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9627243989762315\n",
      "Predicci√≥n : [[0.9137844]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[[0.92762333]\n",
      "  [0.92731041]\n",
      "  [0.92633909]\n",
      "  [0.924119  ]\n",
      "  [0.92286181]\n",
      "  [0.9213571 ]\n",
      "  [0.91840935]\n",
      "  [0.91615665]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00239512394182384\n",
      "Predicci√≥n post entrenamiento : [[0.9148506]]\n",
      "PERDIDAAAA despues: 0.0022919003386050463\n",
      "loss en el callback: 0.06280767172574997, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "ejemplar: [[0.92731041]\n",
      " [0.92633909]\n",
      " [0.924119  ]\n",
      " [0.92286181]\n",
      " [0.9213571 ]\n",
      " [0.91840935]\n",
      " [0.91615665]\n",
      " [0.91378438]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9486336481930799\n",
      "Predicci√≥n : [[0.9137699]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[[0.92731041]\n",
      "  [0.92633909]\n",
      "  [0.924119  ]\n",
      "  [0.92286181]\n",
      "  [0.9213571 ]\n",
      "  [0.91840935]\n",
      "  [0.91615665]\n",
      "  [0.91378438]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001215482479892671\n",
      "Predicci√≥n post entrenamiento : [[0.91405416]]\n",
      "PERDIDAAAA despues: 0.0011957428650930524\n",
      "loss en el callback: 0.0035709766671061516, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "ejemplar: [[0.92633909]\n",
      " [0.924119  ]\n",
      " [0.92286181]\n",
      " [0.9213571 ]\n",
      " [0.91840935]\n",
      " [0.91615665]\n",
      " [0.91378438]\n",
      " [0.9137699 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9307145892932484\n",
      "Predicci√≥n : [[0.9126106]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[[0.92633909]\n",
      "  [0.924119  ]\n",
      "  [0.92286181]\n",
      "  [0.9213571 ]\n",
      "  [0.91840935]\n",
      "  [0.91615665]\n",
      "  [0.91378438]\n",
      "  [0.9137699 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00032775543513707817\n",
      "Predicci√≥n post entrenamiento : [[0.9122747]]\n",
      "PERDIDAAAA despues: 0.0003400295099709183\n",
      "loss en el callback: 0.004217161796987057, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "ejemplar: [[0.924119  ]\n",
      " [0.92286181]\n",
      " [0.9213571 ]\n",
      " [0.91840935]\n",
      " [0.91615665]\n",
      " [0.91378438]\n",
      " [0.9137699 ]\n",
      " [0.91261059]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.908967222276737\n",
      "Predicci√≥n : [[0.9106011]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[[0.924119  ]\n",
      "  [0.92286181]\n",
      "  [0.9213571 ]\n",
      "  [0.91840935]\n",
      "  [0.91615665]\n",
      "  [0.91378438]\n",
      "  [0.9137699 ]\n",
      "  [0.91261059]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.669572040758794e-06\n",
      "Predicci√≥n post entrenamiento : [[0.9098077]]\n",
      "PERDIDAAAA despues: 7.064152214297792e-07\n",
      "loss en el callback: 0.021377263590693474, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "ejemplar: [[0.92286181]\n",
      " [0.9213571 ]\n",
      " [0.91840935]\n",
      " [0.91615665]\n",
      " [0.91378438]\n",
      " [0.9137699 ]\n",
      " [0.91261059]\n",
      " [0.91060108]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8816379650841193\n",
      "Predicci√≥n : [[0.9082376]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[[0.92286181]\n",
      "  [0.9213571 ]\n",
      "  [0.91840935]\n",
      "  [0.91615665]\n",
      "  [0.91378438]\n",
      "  [0.9137699 ]\n",
      "  [0.91261059]\n",
      "  [0.91060108]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007075379835441709\n",
      "Predicci√≥n post entrenamiento : [[0.9084693]]\n",
      "PERDIDAAAA despues: 0.0007199202082119882\n",
      "loss en el callback: 0.0027142364997416735, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "ejemplar: [[0.9213571 ]\n",
      " [0.91840935]\n",
      " [0.91615665]\n",
      " [0.91378438]\n",
      " [0.9137699 ]\n",
      " [0.91261059]\n",
      " [0.91060108]\n",
      " [0.90823758]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8487268177153953\n",
      "Predicci√≥n : [[0.90674967]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[[0.9213571 ]\n",
      "  [0.91840935]\n",
      "  [0.91615665]\n",
      "  [0.91378438]\n",
      "  [0.9137699 ]\n",
      "  [0.91261059]\n",
      "  [0.91060108]\n",
      "  [0.90823758]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0033666519448161125\n",
      "Predicci√≥n post entrenamiento : [[0.9071334]]\n",
      "PERDIDAAAA despues: 0.0034113298170268536\n",
      "loss en el callback: 0.008567793294787407, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "ejemplar: [[0.91840935]\n",
      " [0.91615665]\n",
      " [0.91378438]\n",
      " [0.9137699 ]\n",
      " [0.91261059]\n",
      " [0.91060108]\n",
      " [0.90823758]\n",
      " [0.90674967]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.875260685634848\n",
      "Predicci√≥n : [[0.9053272]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[[0.91840935]\n",
      "  [0.91615665]\n",
      "  [0.91378438]\n",
      "  [0.9137699 ]\n",
      "  [0.91261059]\n",
      "  [0.91060108]\n",
      "  [0.90823758]\n",
      "  [0.90674967]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009039938449859619\n",
      "Predicci√≥n post entrenamiento : [[0.904827]]\n",
      "PERDIDAAAA despues: 0.0008741653873585165\n",
      "loss en el callback: 0.009450245648622513, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "ejemplar: [[0.91615665]\n",
      " [0.91378438]\n",
      " [0.9137699 ]\n",
      " [0.91261059]\n",
      " [0.91060108]\n",
      " [0.90823758]\n",
      " [0.90674967]\n",
      " [0.9053272 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9612395688424776\n",
      "Predicci√≥n : [[0.9033507]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[[0.91615665]\n",
      "  [0.91378438]\n",
      "  [0.9137699 ]\n",
      "  [0.91261059]\n",
      "  [0.91060108]\n",
      "  [0.90823758]\n",
      "  [0.90674967]\n",
      "  [0.9053272 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0033511207439005375\n",
      "Predicci√≥n post entrenamiento : [[0.90412533]]\n",
      "PERDIDAAAA despues: 0.0032620367128401995\n",
      "loss en el callback: 0.03531284257769585, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "ejemplar: [[0.91378438]\n",
      " [0.9137699 ]\n",
      " [0.91261059]\n",
      " [0.91060108]\n",
      " [0.90823758]\n",
      " [0.90674967]\n",
      " [0.9053272 ]\n",
      " [0.90335071]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9925021123407926\n",
      "Predicci√≥n : [[0.9028308]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[[0.91378438]\n",
      "  [0.9137699 ]\n",
      "  [0.91261059]\n",
      "  [0.91060108]\n",
      "  [0.90823758]\n",
      "  [0.90674967]\n",
      "  [0.9053272 ]\n",
      "  [0.90335071]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00804094411432743\n",
      "Predicci√≥n post entrenamiento : [[0.9034366]]\n",
      "PERDIDAAAA despues: 0.007932662032544613\n",
      "loss en el callback: 0.018281126394867897, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "ejemplar: [[0.9137699 ]\n",
      " [0.91261059]\n",
      " [0.91060108]\n",
      " [0.90823758]\n",
      " [0.90674967]\n",
      " [0.9053272 ]\n",
      " [0.90335071]\n",
      " [0.90283078]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.969048316129792\n",
      "Predicci√≥n : [[0.9023806]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[[0.9137699 ]\n",
      "  [0.91261059]\n",
      "  [0.91060108]\n",
      "  [0.90823758]\n",
      "  [0.90674967]\n",
      "  [0.9053272 ]\n",
      "  [0.90335071]\n",
      "  [0.90283078]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004444587044417858\n",
      "Predicci√≥n post entrenamiento : [[0.9032254]]\n",
      "PERDIDAAAA despues: 0.004332654178142548\n",
      "loss en el callback: 0.0448404997587204, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "ejemplar: [[0.91261059]\n",
      " [0.91060108]\n",
      " [0.90823758]\n",
      " [0.90674967]\n",
      " [0.9053272 ]\n",
      " [0.90335071]\n",
      " [0.90283078]\n",
      " [0.90238059]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9715476120161949\n",
      "Predicci√≥n : [[0.9017668]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[[0.91261059]\n",
      "  [0.91060108]\n",
      "  [0.90823758]\n",
      "  [0.90674967]\n",
      "  [0.9053272 ]\n",
      "  [0.90335071]\n",
      "  [0.90283078]\n",
      "  [0.90238059]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004869363736361265\n",
      "Predicci√≥n post entrenamiento : [[0.9014789]]\n",
      "PERDIDAAAA despues: 0.00490962527692318\n",
      "loss en el callback: 0.0031248475424945354, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "ejemplar: [[0.91060108]\n",
      " [0.90823758]\n",
      " [0.90674967]\n",
      " [0.9053272 ]\n",
      " [0.90335071]\n",
      " [0.90283078]\n",
      " [0.90238059]\n",
      " [0.90176678]]\n",
      "ejemplar: (8, 1)\n",
      "y: 1.0\n",
      "Predicci√≥n : [[0.8999067]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[[0.91060108]\n",
      "  [0.90823758]\n",
      "  [0.90674967]\n",
      "  [0.9053272 ]\n",
      "  [0.90335071]\n",
      "  [0.90283078]\n",
      "  [0.90238059]\n",
      "  [0.90176678]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010018670000135899\n",
      "Predicci√≥n post entrenamiento : [[0.9007327]]\n",
      "PERDIDAAAA despues: 0.009853997267782688\n",
      "loss en el callback: 0.03449463099241257, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "ejemplar: [[0.90823758]\n",
      " [0.90674967]\n",
      " [0.9053272 ]\n",
      " [0.90335071]\n",
      " [0.90283078]\n",
      " [0.90238059]\n",
      " [0.90176678]\n",
      " [0.89990669]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9800636522775721\n",
      "Predicci√≥n : [[0.8993022]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[[0.90823758]\n",
      "  [0.90674967]\n",
      "  [0.9053272 ]\n",
      "  [0.90335071]\n",
      "  [0.90283078]\n",
      "  [0.90238059]\n",
      "  [0.90176678]\n",
      "  [0.89990669]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006522418465465307\n",
      "Predicci√≥n post entrenamiento : [[0.8994122]]\n",
      "PERDIDAAAA despues: 0.00650465814396739\n",
      "loss en el callback: 0.0005645952187478542, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "ejemplar: [[0.90674967]\n",
      " [0.9053272 ]\n",
      " [0.90335071]\n",
      " [0.90283078]\n",
      " [0.90238059]\n",
      " [0.90176678]\n",
      " [0.89990669]\n",
      " [0.89930218]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.911738568848911\n",
      "Predicci√≥n : [[0.89827275]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[[0.90674967]\n",
      "  [0.9053272 ]\n",
      "  [0.90335071]\n",
      "  [0.90283078]\n",
      "  [0.90238059]\n",
      "  [0.90176678]\n",
      "  [0.89990669]\n",
      "  [0.89930218]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00018132835975848138\n",
      "Predicci√≥n post entrenamiento : [[0.89900327]]\n",
      "PERDIDAAAA despues: 0.00016218805103562772\n",
      "loss en el callback: 0.036329738795757294, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "ejemplar: [[0.9053272 ]\n",
      " [0.90335071]\n",
      " [0.90283078]\n",
      " [0.90238059]\n",
      " [0.90176678]\n",
      " [0.89990669]\n",
      " [0.89930218]\n",
      " [0.89827275]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8910857934126422\n",
      "Predicci√≥n : [[0.8979631]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[[0.9053272 ]\n",
      "  [0.90335071]\n",
      "  [0.90283078]\n",
      "  [0.90238059]\n",
      "  [0.90176678]\n",
      "  [0.89990669]\n",
      "  [0.89930218]\n",
      "  [0.89827275]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.729729698738083e-05\n",
      "Predicci√≥n post entrenamiento : [[0.8978428]]\n",
      "PERDIDAAAA despues: 4.565733252093196e-05\n",
      "loss en el callback: 0.0006680344231426716, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "ejemplar: [[0.90335071]\n",
      " [0.90283078]\n",
      " [0.90238059]\n",
      " [0.90176678]\n",
      " [0.89990669]\n",
      " [0.89930218]\n",
      " [0.89827275]\n",
      " [0.89796311]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9181053259687657\n",
      "Predicci√≥n : [[0.8969122]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[[0.90335071]\n",
      "  [0.90283078]\n",
      "  [0.90238059]\n",
      "  [0.90176678]\n",
      "  [0.89990669]\n",
      "  [0.89930218]\n",
      "  [0.89827275]\n",
      "  [0.89796311]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004491469298955053\n",
      "Predicci√≥n post entrenamiento : [[0.89696354]]\n",
      "PERDIDAAAA despues: 0.00044697432895191014\n",
      "loss en el callback: 0.0001380536996293813, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "ejemplar: [[0.90283078]\n",
      " [0.90238059]\n",
      " [0.90176678]\n",
      " [0.89990669]\n",
      " [0.89930218]\n",
      " [0.89827275]\n",
      " [0.89796311]\n",
      " [0.89691222]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9450165163483527\n",
      "Predicci√≥n : [[0.8963248]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[[0.90283078]\n",
      "  [0.90238059]\n",
      "  [0.90176678]\n",
      "  [0.89990669]\n",
      "  [0.89930218]\n",
      "  [0.89827275]\n",
      "  [0.89796311]\n",
      "  [0.89691222]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0023708806838840246\n",
      "Predicci√≥n post entrenamiento : [[0.89690083]]\n",
      "PERDIDAAAA despues: 0.002315117744728923\n",
      "loss en el callback: 0.02291659079492092, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "ejemplar: [[0.90238059]\n",
      " [0.90176678]\n",
      " [0.89990669]\n",
      " [0.89930218]\n",
      " [0.89827275]\n",
      " [0.89796311]\n",
      " [0.89691222]\n",
      " [0.89632481]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9718193645514037\n",
      "Predicci√≥n : [[0.89617836]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[[0.90238059]\n",
      "  [0.90176678]\n",
      "  [0.89990669]\n",
      "  [0.89930218]\n",
      "  [0.89827275]\n",
      "  [0.89796311]\n",
      "  [0.89691222]\n",
      "  [0.89632481]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005721557419747114\n",
      "Predicci√≥n post entrenamiento : [[0.8953622]]\n",
      "PERDIDAAAA despues: 0.005845694802701473\n",
      "loss en el callback: 0.02294251322746277, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "ejemplar: [[0.90176678]\n",
      " [0.89990669]\n",
      " [0.89930218]\n",
      " [0.89827275]\n",
      " [0.89796311]\n",
      " [0.89691222]\n",
      " [0.89632481]\n",
      " [0.89617836]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9829067192737589\n",
      "Predicci√≥n : [[0.89453036]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[[0.90176678]\n",
      "  [0.89990669]\n",
      "  [0.89930218]\n",
      "  [0.89827275]\n",
      "  [0.89796311]\n",
      "  [0.89691222]\n",
      "  [0.89632481]\n",
      "  [0.89617836]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007810377981513739\n",
      "Predicci√≥n post entrenamiento : [[0.8948889]]\n",
      "PERDIDAAAA despues: 0.007747136987745762\n",
      "loss en el callback: 0.006292297970503569, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "ejemplar: [[0.89990669]\n",
      " [0.89930218]\n",
      " [0.89827275]\n",
      " [0.89796311]\n",
      " [0.89691222]\n",
      " [0.89632481]\n",
      " [0.89617836]\n",
      " [0.89453036]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9782785805154182\n",
      "Predicci√≥n : [[0.89398485]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[[0.89990669]\n",
      "  [0.89930218]\n",
      "  [0.89827275]\n",
      "  [0.89796311]\n",
      "  [0.89691222]\n",
      "  [0.89632481]\n",
      "  [0.89617836]\n",
      "  [0.89453036]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0071054319851100445\n",
      "Predicci√≥n post entrenamiento : [[0.89403677]]\n",
      "PERDIDAAAA despues: 0.007096682209521532\n",
      "loss en el callback: 0.00012293082545511425, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "ejemplar: [[0.05029815]\n",
      " [0.00860651]\n",
      " [0.        ]\n",
      " [0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.049424632939554\n",
      "Predicci√≥n : [[0.21178502]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.05029815]\n",
      "  [0.00860651]\n",
      "  [0.        ]\n",
      "  [0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.026360895484685898\n",
      "Predicci√≥n post entrenamiento : [[0.17483373]]\n",
      "PERDIDAAAA despues: 0.015727441757917404\n",
      "loss en el callback: 0.027590520679950714, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "ejemplar: [[0.00860651]\n",
      " [0.        ]\n",
      " [0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.21178502]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.10789185692558968\n",
      "Predicci√≥n : [[0.16984357]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.00860651]\n",
      "  [0.        ]\n",
      "  [0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.21178502]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003838014556095004\n",
      "Predicci√≥n post entrenamiento : [[0.15956777]]\n",
      "PERDIDAAAA despues: 0.002670400310307741\n",
      "loss en el callback: 0.002497090259566903, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "ejemplar: [[0.        ]\n",
      " [0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.21178502]\n",
      " [0.16984357]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.13719610119365802\n",
      "Predicci√≥n : [[0.16417909]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[[0.        ]\n",
      "  [0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.21178502]\n",
      "  [0.16984357]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007280819118022919\n",
      "Predicci√≥n post entrenamiento : [[0.15544307]]\n",
      "PERDIDAAAA despues: 0.00033295221510343254\n",
      "loss en el callback: 0.0028269849717617035, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "ejemplar: [[0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.21178502]\n",
      " [0.16984357]\n",
      " [0.16417909]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.13733736574375907\n",
      "Predicci√≥n : [[0.16506065]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[[0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.21178502]\n",
      "  [0.16984357]\n",
      "  [0.16417909]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000768580415751785\n",
      "Predicci√≥n post entrenamiento : [[0.1623517]]\n",
      "PERDIDAAAA despues: 0.0006257165223360062\n",
      "loss en el callback: 0.0006088157533667982, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "ejemplar: [[0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.21178502]\n",
      " [0.16984357]\n",
      " [0.16417909]\n",
      " [0.16506065]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.13388569841244483\n",
      "Predicci√≥n : [[0.17118725]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[[0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.21178502]\n",
      "  [0.16984357]\n",
      "  [0.16417909]\n",
      "  [0.16506065]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013914060546085238\n",
      "Predicci√≥n post entrenamiento : [[0.16401112]]\n",
      "PERDIDAAAA despues: 0.0009075411944650114\n",
      "loss en el callback: 0.005097334738820791, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "ejemplar: [[0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.21178502]\n",
      " [0.16984357]\n",
      " [0.16417909]\n",
      " [0.16506065]\n",
      " [0.17118725]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.12684109919971556\n",
      "Predicci√≥n : [[0.17533666]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[[0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.21178502]\n",
      "  [0.16984357]\n",
      "  [0.16417909]\n",
      "  [0.16506065]\n",
      "  [0.17118725]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0023518195375800133\n",
      "Predicci√≥n post entrenamiento : [[0.1729326]]\n",
      "PERDIDAAAA despues: 0.0021244261879473925\n",
      "loss en el callback: 0.0011586174368858337, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "ejemplar: [[0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.21178502]\n",
      " [0.16984357]\n",
      " [0.16417909]\n",
      " [0.16506065]\n",
      " [0.17118725]\n",
      " [0.17533666]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14756061137847282\n",
      "Predicci√≥n : [[0.1905331]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[[0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.21178502]\n",
      "  [0.16984357]\n",
      "  [0.16417909]\n",
      "  [0.16506065]\n",
      "  [0.17118725]\n",
      "  [0.17533666]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018466348992660642\n",
      "Predicci√≥n post entrenamiento : [[0.18824823]]\n",
      "PERDIDAAAA despues: 0.001655482454225421\n",
      "loss en el callback: 0.0013380983145907521, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "ejemplar: [[0.0202993 ]\n",
      " [0.21178502]\n",
      " [0.16984357]\n",
      " [0.16417909]\n",
      " [0.16506065]\n",
      " [0.17118725]\n",
      " [0.17533666]\n",
      " [0.1905331 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19604423494871648\n",
      "Predicci√≥n : [[0.21209992]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[[0.0202993 ]\n",
      "  [0.21178502]\n",
      "  [0.16984357]\n",
      "  [0.16417909]\n",
      "  [0.16506065]\n",
      "  [0.17118725]\n",
      "  [0.17533666]\n",
      "  [0.1905331 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00025778511189855635\n",
      "Predicci√≥n post entrenamiento : [[0.21168594]]\n",
      "PERDIDAAAA despues: 0.00024466292234137654\n",
      "loss en el callback: 6.203832163009793e-05, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "ejemplar: [[0.21178502]\n",
      " [0.16984357]\n",
      " [0.16417909]\n",
      " [0.16506065]\n",
      " [0.17118725]\n",
      " [0.17533666]\n",
      " [0.1905331 ]\n",
      " [0.21209992]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.21688968214535215\n",
      "Predicci√≥n : [[0.24160159]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[[0.21178502]\n",
      "  [0.16984357]\n",
      "  [0.16417909]\n",
      "  [0.16506065]\n",
      "  [0.17118725]\n",
      "  [0.17533666]\n",
      "  [0.1905331 ]\n",
      "  [0.21209992]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006106783403083682\n",
      "Predicci√≥n post entrenamiento : [[0.2393007]]\n",
      "PERDIDAAAA despues: 0.0005022537661716342\n",
      "loss en el callback: 0.0017272628610953689, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "ejemplar: [[0.16984357]\n",
      " [0.16417909]\n",
      " [0.16506065]\n",
      " [0.17118725]\n",
      " [0.17533666]\n",
      " [0.1905331 ]\n",
      " [0.21209992]\n",
      " [0.24160159]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2100969529683796\n",
      "Predicci√≥n : [[0.23231716]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[[0.16984357]\n",
      "  [0.16417909]\n",
      "  [0.16506065]\n",
      "  [0.17118725]\n",
      "  [0.17533666]\n",
      "  [0.1905331 ]\n",
      "  [0.21209992]\n",
      "  [0.24160159]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004937376943416893\n",
      "Predicci√≥n post entrenamiento : [[0.23151837]]\n",
      "PERDIDAAAA despues: 0.0004588771262206137\n",
      "loss en el callback: 0.0003021151351276785, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "ejemplar: [[0.16417909]\n",
      " [0.16506065]\n",
      " [0.17118725]\n",
      " [0.17533666]\n",
      " [0.1905331 ]\n",
      " [0.21209992]\n",
      " [0.24160159]\n",
      " [0.23231716]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2026778474621132\n",
      "Predicci√≥n : [[0.23375493]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[[0.16417909]\n",
      "  [0.16506065]\n",
      "  [0.17118725]\n",
      "  [0.17533666]\n",
      "  [0.1905331 ]\n",
      "  [0.21209992]\n",
      "  [0.24160159]\n",
      "  [0.23231716]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009657853515818715\n",
      "Predicci√≥n post entrenamiento : [[0.23211059]]\n",
      "PERDIDAAAA despues: 0.0008662863983772695\n",
      "loss en el callback: 0.0013634999049827456, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "ejemplar: [[0.16506065]\n",
      " [0.17118725]\n",
      " [0.17533666]\n",
      " [0.1905331 ]\n",
      " [0.21209992]\n",
      " [0.24160159]\n",
      " [0.23231716]\n",
      " [0.23375493]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19463236562655295\n",
      "Predicci√≥n : [[0.23724397]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[[0.16506065]\n",
      "  [0.17118725]\n",
      "  [0.17533666]\n",
      "  [0.1905331 ]\n",
      "  [0.21209992]\n",
      "  [0.24160159]\n",
      "  [0.23231716]\n",
      "  [0.23375493]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018157484009861946\n",
      "Predicci√≥n post entrenamiento : [[0.23594332]]\n",
      "PERDIDAAAA despues: 0.0017065947176888585\n",
      "loss en el callback: 0.0010978588834404945, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "ejemplar: [[0.17118725]\n",
      " [0.17533666]\n",
      " [0.1905331 ]\n",
      " [0.21209992]\n",
      " [0.24160159]\n",
      " [0.23231716]\n",
      " [0.23375493]\n",
      " [0.23724397]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19407351685692253\n",
      "Predicci√≥n : [[0.24303144]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[[0.17118725]\n",
      "  [0.17533666]\n",
      "  [0.1905331 ]\n",
      "  [0.21209992]\n",
      "  [0.24160159]\n",
      "  [0.23231716]\n",
      "  [0.23375493]\n",
      "  [0.23724397]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0023968787863850594\n",
      "Predicci√≥n post entrenamiento : [[0.24213237]]\n",
      "PERDIDAAAA despues: 0.0023096532095223665\n",
      "loss en el callback: 0.0007427391246892512, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "ejemplar: [[0.17533666]\n",
      " [0.1905331 ]\n",
      " [0.21209992]\n",
      " [0.24160159]\n",
      " [0.23231716]\n",
      " [0.23375493]\n",
      " [0.23724397]\n",
      " [0.24303144]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.20100130115322212\n",
      "Predicci√≥n : [[0.2502244]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[[0.17533666]\n",
      "  [0.1905331 ]\n",
      "  [0.21209992]\n",
      "  [0.24160159]\n",
      "  [0.23231716]\n",
      "  [0.23375493]\n",
      "  [0.23724397]\n",
      "  [0.24303144]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002422914607450366\n",
      "Predicci√≥n post entrenamiento : [[0.2497799]]\n",
      "PERDIDAAAA despues: 0.002379351295530796\n",
      "loss en el callback: 0.00022588780848309398, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "ejemplar: [[0.1905331 ]\n",
      " [0.21209992]\n",
      " [0.24160159]\n",
      " [0.23231716]\n",
      " [0.23375493]\n",
      " [0.23724397]\n",
      " [0.24303144]\n",
      " [0.25022441]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19663820581116015\n",
      "Predicci√≥n : [[0.25931987]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[[0.1905331 ]\n",
      "  [0.21209992]\n",
      "  [0.24160159]\n",
      "  [0.23231716]\n",
      "  [0.23375493]\n",
      "  [0.23724397]\n",
      "  [0.24303144]\n",
      "  [0.25022441]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0039289905689656734\n",
      "Predicci√≥n post entrenamiento : [[0.2567394]]\n",
      "PERDIDAAAA despues: 0.003612153697758913\n",
      "loss en el callback: 0.005794404540210962, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "ejemplar: [[0.21209992]\n",
      " [0.24160159]\n",
      " [0.23231716]\n",
      " [0.23375493]\n",
      " [0.23724397]\n",
      " [0.24303144]\n",
      " [0.25022441]\n",
      " [0.25931987]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1809842308307365\n",
      "Predicci√≥n : [[0.26522097]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[[0.21209992]\n",
      "  [0.24160159]\n",
      "  [0.23231716]\n",
      "  [0.23375493]\n",
      "  [0.23724397]\n",
      "  [0.24303144]\n",
      "  [0.25022441]\n",
      "  [0.25931987]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007095828652381897\n",
      "Predicci√≥n post entrenamiento : [[0.2627063]]\n",
      "PERDIDAAAA despues: 0.006678498350083828\n",
      "loss en el callback: 0.0073306444101035595, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "ejemplar: [[0.24160159]\n",
      " [0.23231716]\n",
      " [0.23375493]\n",
      " [0.23724397]\n",
      " [0.24303144]\n",
      " [0.25022441]\n",
      " [0.25931987]\n",
      " [0.26522097]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1653904097109329\n",
      "Predicci√≥n : [[0.26828015]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[[0.24160159]\n",
      "  [0.23231716]\n",
      "  [0.23375493]\n",
      "  [0.23724397]\n",
      "  [0.24303144]\n",
      "  [0.25022441]\n",
      "  [0.25931987]\n",
      "  [0.26522097]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010586297139525414\n",
      "Predicci√≥n post entrenamiento : [[0.2631921]]\n",
      "PERDIDAAAA despues: 0.009565167129039764\n",
      "loss en el callback: 0.023452697321772575, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "ejemplar: [[0.23231716]\n",
      " [0.23375493]\n",
      " [0.23724397]\n",
      " [0.24303144]\n",
      " [0.25022441]\n",
      " [0.25931987]\n",
      " [0.26522097]\n",
      " [0.26828015]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14985674245174896\n",
      "Predicci√≥n : [[0.26345143]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[[0.23231716]\n",
      "  [0.23375493]\n",
      "  [0.23724397]\n",
      "  [0.24303144]\n",
      "  [0.25022441]\n",
      "  [0.25931987]\n",
      "  [0.26522097]\n",
      "  [0.26828015]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01290375180542469\n",
      "Predicci√≥n post entrenamiento : [[0.26086745]]\n",
      "PERDIDAAAA despues: 0.012323375791311264\n",
      "loss en el callback: 0.010069552809000015, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "ejemplar: [[0.23375493]\n",
      " [0.23724397]\n",
      " [0.24303144]\n",
      " [0.25022441]\n",
      " [0.25931987]\n",
      " [0.26522097]\n",
      " [0.26828015]\n",
      " [0.26345143]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.15043111479831345\n",
      "Predicci√≥n : [[0.2638934]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[[0.23375493]\n",
      "  [0.23724397]\n",
      "  [0.24303144]\n",
      "  [0.25022441]\n",
      "  [0.25931987]\n",
      "  [0.26522097]\n",
      "  [0.26828015]\n",
      "  [0.26345143]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012873689644038677\n",
      "Predicci√≥n post entrenamiento : [[0.26158184]]\n",
      "PERDIDAAAA despues: 0.01235448382794857\n",
      "loss en el callback: 0.009571000002324581, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "ejemplar: [[0.23724397]\n",
      " [0.24303144]\n",
      " [0.25022441]\n",
      " [0.25931987]\n",
      " [0.26522097]\n",
      " [0.26828015]\n",
      " [0.26345143]\n",
      " [0.2638934 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.16711352675062616\n",
      "Predicci√≥n : [[0.2653356]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[[0.23724397]\n",
      "  [0.24303144]\n",
      "  [0.25022441]\n",
      "  [0.25931987]\n",
      "  [0.26522097]\n",
      "  [0.26828015]\n",
      "  [0.26345143]\n",
      "  [0.2638934 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009647573344409466\n",
      "Predicci√≥n post entrenamiento : [[0.26230034]]\n",
      "PERDIDAAAA despues: 0.009060529991984367\n",
      "loss en el callback: 0.014506896957755089, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "ejemplar: [[0.24303144]\n",
      " [0.25022441]\n",
      " [0.25931987]\n",
      " [0.26522097]\n",
      " [0.26828015]\n",
      " [0.26345143]\n",
      " [0.2638934 ]\n",
      " [0.26533559]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2022703535675908\n",
      "Predicci√≥n : [[0.26632115]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[[0.24303144]\n",
      "  [0.25022441]\n",
      "  [0.25931987]\n",
      "  [0.26522097]\n",
      "  [0.26828015]\n",
      "  [0.26345143]\n",
      "  [0.2638934 ]\n",
      "  [0.26533559]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004102504346519709\n",
      "Predicci√≥n post entrenamiento : [[0.26464954]]\n",
      "PERDIDAAAA despues: 0.0038911623414605856\n",
      "loss en el callback: 0.004845514893531799, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "ejemplar: [[0.25022441]\n",
      " [0.25931987]\n",
      " [0.26522097]\n",
      " [0.26828015]\n",
      " [0.26345143]\n",
      " [0.2638934 ]\n",
      " [0.26533559]\n",
      " [0.26632115]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.25590159524920725\n",
      "Predicci√≥n : [[0.26831552]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[[0.25022441]\n",
      "  [0.25931987]\n",
      "  [0.26522097]\n",
      "  [0.26828015]\n",
      "  [0.26345143]\n",
      "  [0.2638934 ]\n",
      "  [0.26533559]\n",
      "  [0.26632115]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00015410537889692932\n",
      "Predicci√≥n post entrenamiento : [[0.2685054]]\n",
      "PERDIDAAAA despues: 0.00015885551692917943\n",
      "loss en el callback: 8.322554640471935e-05, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "ejemplar: [[0.25931987]\n",
      " [0.26522097]\n",
      " [0.26828015]\n",
      " [0.26345143]\n",
      " [0.2638934 ]\n",
      " [0.26533559]\n",
      " [0.26632115]\n",
      " [0.26831552]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.292688203599549\n",
      "Predicci√≥n : [[0.27130532]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[[0.25931987]\n",
      "  [0.26522097]\n",
      "  [0.26828015]\n",
      "  [0.26345143]\n",
      "  [0.2638934 ]\n",
      "  [0.26533559]\n",
      "  [0.26632115]\n",
      "  [0.26831552]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00045722705544903874\n",
      "Predicci√≥n post entrenamiento : [[0.27174854]]\n",
      "PERDIDAAAA despues: 0.00043846885091625154\n",
      "loss en el callback: 0.0004362899053376168, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "ejemplar: [[0.26522097]\n",
      " [0.26828015]\n",
      " [0.26345143]\n",
      " [0.2638934 ]\n",
      " [0.26533559]\n",
      " [0.26632115]\n",
      " [0.26831552]\n",
      " [0.27130532]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31263017861861575\n",
      "Predicci√≥n : [[0.27301365]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[[0.26522097]\n",
      "  [0.26828015]\n",
      "  [0.26345143]\n",
      "  [0.2638934 ]\n",
      "  [0.26533559]\n",
      "  [0.26632115]\n",
      "  [0.26831552]\n",
      "  [0.27130532]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001569469110108912\n",
      "Predicci√≥n post entrenamiento : [[0.2730854]]\n",
      "PERDIDAAAA despues: 0.001563790487125516\n",
      "loss en el callback: 9.341077202407178e-06, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "ejemplar: [[0.26828015]\n",
      " [0.26345143]\n",
      " [0.2638934 ]\n",
      " [0.26533559]\n",
      " [0.26632115]\n",
      " [0.26831552]\n",
      " [0.27130532]\n",
      " [0.27301365]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3109388849116374\n",
      "Predicci√≥n : [[0.2732865]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[[0.26828015]\n",
      "  [0.26345143]\n",
      "  [0.2638934 ]\n",
      "  [0.26533559]\n",
      "  [0.26632115]\n",
      "  [0.26831552]\n",
      "  [0.27130532]\n",
      "  [0.27301365]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014177034609019756\n",
      "Predicci√≥n post entrenamiento : [[0.27424836]]\n",
      "PERDIDAAAA despues: 0.001346195233054459\n",
      "loss en el callback: 0.002868681913241744, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "ejemplar: [[0.26345143]\n",
      " [0.2638934 ]\n",
      " [0.26533559]\n",
      " [0.26632115]\n",
      " [0.26831552]\n",
      " [0.27130532]\n",
      " [0.27301365]\n",
      " [0.27328649]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2876143224786136\n",
      "Predicci√≥n : [[0.27390108]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[[0.26345143]\n",
      "  [0.2638934 ]\n",
      "  [0.26533559]\n",
      "  [0.26632115]\n",
      "  [0.26831552]\n",
      "  [0.27130532]\n",
      "  [0.27301365]\n",
      "  [0.27328649]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00018805297440849245\n",
      "Predicci√≥n post entrenamiento : [[0.27366003]]\n",
      "PERDIDAAAA despues: 0.00019472198619041592\n",
      "loss en el callback: 0.00014117785030975938, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "ejemplar: [[0.2638934 ]\n",
      " [0.26533559]\n",
      " [0.26632115]\n",
      " [0.26831552]\n",
      " [0.27130532]\n",
      " [0.27301365]\n",
      " [0.27328649]\n",
      " [0.27390108]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.280161647237227\n",
      "Predicci√≥n : [[0.27454785]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[[0.2638934 ]\n",
      "  [0.26533559]\n",
      "  [0.26632115]\n",
      "  [0.26831552]\n",
      "  [0.27130532]\n",
      "  [0.27301365]\n",
      "  [0.27328649]\n",
      "  [0.27390108]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.151479540974833e-05\n",
      "Predicci√≥n post entrenamiento : [[0.27555126]]\n",
      "PERDIDAAAA despues: 2.1255691535770893e-05\n",
      "loss en el callback: 0.0047391257248818874, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "ejemplar: [[0.26533559]\n",
      " [0.26632115]\n",
      " [0.26831552]\n",
      " [0.27130532]\n",
      " [0.27301365]\n",
      " [0.27328649]\n",
      " [0.27390108]\n",
      " [0.27454785]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2885808591874776\n",
      "Predicci√≥n : [[0.27665958]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[[0.26533559]\n",
      "  [0.26632115]\n",
      "  [0.26831552]\n",
      "  [0.27130532]\n",
      "  [0.27301365]\n",
      "  [0.27328649]\n",
      "  [0.27390108]\n",
      "  [0.27454785]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00014211707457434386\n",
      "Predicci√≥n post entrenamiento : [[0.2761951]]\n",
      "PERDIDAAAA despues: 0.00015340694517362863\n",
      "loss en el callback: 0.000612727424595505, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "ejemplar: [[0.26632115]\n",
      " [0.26831552]\n",
      " [0.27130532]\n",
      " [0.27301365]\n",
      " [0.27328649]\n",
      " [0.27390108]\n",
      " [0.27454785]\n",
      " [0.27665958]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2824628234730068\n",
      "Predicci√≥n : [[0.27731675]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[[0.26632115]\n",
      "  [0.26831552]\n",
      "  [0.27130532]\n",
      "  [0.27301365]\n",
      "  [0.27328649]\n",
      "  [0.27390108]\n",
      "  [0.27454785]\n",
      "  [0.27665958]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.648220288392622e-05\n",
      "Predicci√≥n post entrenamiento : [[0.2778596]]\n",
      "PERDIDAAAA despues: 2.1189789549680427e-05\n",
      "loss en el callback: 0.001111139776185155, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "ejemplar: [[0.26831552]\n",
      " [0.27130532]\n",
      " [0.27301365]\n",
      " [0.27328649]\n",
      " [0.27390108]\n",
      " [0.27454785]\n",
      " [0.27665958]\n",
      " [0.27731675]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.26180754009381474\n",
      "Predicci√≥n : [[0.27908796]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[[0.26831552]\n",
      "  [0.27130532]\n",
      "  [0.27301365]\n",
      "  [0.27328649]\n",
      "  [0.27390108]\n",
      "  [0.27454785]\n",
      "  [0.27665958]\n",
      "  [0.27731675]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002986132458318025\n",
      "Predicci√≥n post entrenamiento : [[0.27884933]]\n",
      "PERDIDAAAA despues: 0.00029042302048765123\n",
      "loss en el callback: 0.00020241439051460475, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "ejemplar: [[0.27130532]\n",
      " [0.27301365]\n",
      " [0.27328649]\n",
      " [0.27390108]\n",
      " [0.27454785]\n",
      " [0.27665958]\n",
      " [0.27731675]\n",
      " [0.27908796]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2801212859371977\n",
      "Predicci√≥n : [[0.2799515]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[[0.27130532]\n",
      "  [0.27301365]\n",
      "  [0.27328649]\n",
      "  [0.27390108]\n",
      "  [0.27454785]\n",
      "  [0.27665958]\n",
      "  [0.27731675]\n",
      "  [0.27908796]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.8826548259530682e-08\n",
      "Predicci√≥n post entrenamiento : [[0.27986088]]\n",
      "PERDIDAAAA despues: 6.781476713513257e-08\n",
      "loss en el callback: 3.135271617793478e-05, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "ejemplar: [[0.27301365]\n",
      " [0.27328649]\n",
      " [0.27390108]\n",
      " [0.27454785]\n",
      " [0.27665958]\n",
      " [0.27731675]\n",
      " [0.27908796]\n",
      " [0.27995151]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3374040610031557\n",
      "Predicci√≥n : [[0.2805737]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[[0.27301365]\n",
      "  [0.27328649]\n",
      "  [0.27390108]\n",
      "  [0.27454785]\n",
      "  [0.27665958]\n",
      "  [0.27731675]\n",
      "  [0.27908796]\n",
      "  [0.27995151]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0032296916469931602\n",
      "Predicci√≥n post entrenamiento : [[0.28136608]]\n",
      "PERDIDAAAA despues: 0.003140256507322192\n",
      "loss en el callback: 0.0022974165622144938, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "ejemplar: [[0.27328649]\n",
      " [0.27390108]\n",
      " [0.27454785]\n",
      " [0.27665958]\n",
      " [0.27731675]\n",
      " [0.27908796]\n",
      " [0.27995151]\n",
      " [0.2805737 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3482298154676272\n",
      "Predicci√≥n : [[0.28192416]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[[0.27328649]\n",
      "  [0.27390108]\n",
      "  [0.27454785]\n",
      "  [0.27665958]\n",
      "  [0.27731675]\n",
      "  [0.27908796]\n",
      "  [0.27995151]\n",
      "  [0.2805737 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004396441392600536\n",
      "Predicci√≥n post entrenamiento : [[0.28285223]]\n",
      "PERDIDAAAA despues: 0.004274229519069195\n",
      "loss en el callback: 0.003954052925109863, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "ejemplar: [[0.27390108]\n",
      " [0.27454785]\n",
      " [0.27665958]\n",
      " [0.27731675]\n",
      " [0.27908796]\n",
      " [0.27995151]\n",
      " [0.2805737 ]\n",
      " [0.28192416]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31259854933061226\n",
      "Predicci√≥n : [[0.28357172]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[[0.27390108]\n",
      "  [0.27454785]\n",
      "  [0.27665958]\n",
      "  [0.27731675]\n",
      "  [0.27908796]\n",
      "  [0.27995151]\n",
      "  [0.2805737 ]\n",
      "  [0.28192416]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008425572304986417\n",
      "Predicci√≥n post entrenamiento : [[0.283709]]\n",
      "PERDIDAAAA despues: 0.0008346070535480976\n",
      "loss en el callback: 8.865907147992402e-05, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "ejemplar: [[0.27454785]\n",
      " [0.27665958]\n",
      " [0.27731675]\n",
      " [0.27908796]\n",
      " [0.27995151]\n",
      " [0.2805737 ]\n",
      " [0.28192416]\n",
      " [0.28357172]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.34358710169603873\n",
      "Predicci√≥n : [[0.2845419]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[[0.27454785]\n",
      "  [0.27665958]\n",
      "  [0.27731675]\n",
      "  [0.27908796]\n",
      "  [0.27995151]\n",
      "  [0.2805737 ]\n",
      "  [0.28192416]\n",
      "  [0.28357172]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0034863350447267294\n",
      "Predicci√≥n post entrenamiento : [[0.28564182]]\n",
      "PERDIDAAAA despues: 0.0033576556015759706\n",
      "loss en el callback: 0.007124582305550575, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "ejemplar: [[0.27665958]\n",
      " [0.27731675]\n",
      " [0.27908796]\n",
      " [0.27995151]\n",
      " [0.2805737 ]\n",
      " [0.28192416]\n",
      " [0.28357172]\n",
      " [0.2845419 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.4411954725639069\n",
      "Predicci√≥n : [[0.28660005]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[[0.27665958]\n",
      "  [0.27731675]\n",
      "  [0.27908796]\n",
      "  [0.27995151]\n",
      "  [0.2805737 ]\n",
      "  [0.28192416]\n",
      "  [0.28357172]\n",
      "  [0.2845419 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.023899739608168602\n",
      "Predicci√≥n post entrenamiento : [[0.2886345]]\n",
      "PERDIDAAAA despues: 0.023274842649698257\n",
      "loss en el callback: 0.01991412788629532, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "ejemplar: [[0.27731675]\n",
      " [0.27908796]\n",
      " [0.27995151]\n",
      " [0.2805737 ]\n",
      " [0.28192416]\n",
      " [0.28357172]\n",
      " [0.2845419 ]\n",
      " [0.28660005]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5210953230441133\n",
      "Predicci√≥n : [[0.28939784]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[[0.27731675]\n",
      "  [0.27908796]\n",
      "  [0.27995151]\n",
      "  [0.2805737 ]\n",
      "  [0.28192416]\n",
      "  [0.28357172]\n",
      "  [0.2845419 ]\n",
      "  [0.28660005]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05368373170495033\n",
      "Predicci√≥n post entrenamiento : [[0.29205266]]\n",
      "PERDIDAAAA despues: 0.05246054753661156\n",
      "loss en el callback: 0.03505557030439377, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "ejemplar: [[0.27908796]\n",
      " [0.27995151]\n",
      " [0.2805737 ]\n",
      " [0.28192416]\n",
      " [0.28357172]\n",
      " [0.2845419 ]\n",
      " [0.28660005]\n",
      " [0.28939784]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5832866531366584\n",
      "Predicci√≥n : [[0.29294446]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[[0.27908796]\n",
      "  [0.27995151]\n",
      "  [0.2805737 ]\n",
      "  [0.28192416]\n",
      "  [0.28357172]\n",
      "  [0.2845419 ]\n",
      "  [0.28660005]\n",
      "  [0.28939784]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08429858088493347\n",
      "Predicci√≥n post entrenamiento : [[0.29671675]]\n",
      "PERDIDAAAA despues: 0.082122303545475\n",
      "loss en el callback: 0.11043514311313629, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "ejemplar: [[0.27995151]\n",
      " [0.2805737 ]\n",
      " [0.28192416]\n",
      " [0.28357172]\n",
      " [0.2845419 ]\n",
      " [0.28660005]\n",
      " [0.28939784]\n",
      " [0.29294446]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6089234523540271\n",
      "Predicci√≥n : [[0.29752433]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[[0.27995151]\n",
      "  [0.2805737 ]\n",
      "  [0.28192416]\n",
      "  [0.28357172]\n",
      "  [0.2845419 ]\n",
      "  [0.28660005]\n",
      "  [0.28939784]\n",
      "  [0.29294446]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09696940332651138\n",
      "Predicci√≥n post entrenamiento : [[0.30150905]]\n",
      "PERDIDAAAA despues: 0.09450360387563705\n",
      "loss en el callback: 0.13239642977714539, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "ejemplar: [[0.2805737 ]\n",
      " [0.28192416]\n",
      " [0.28357172]\n",
      " [0.2845419 ]\n",
      " [0.28660005]\n",
      " [0.28939784]\n",
      " [0.29294446]\n",
      " [0.29752433]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.59800572069622\n",
      "Predicci√≥n : [[0.30247882]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[[0.2805737 ]\n",
      "  [0.28192416]\n",
      "  [0.28357172]\n",
      "  [0.2845419 ]\n",
      "  [0.28660005]\n",
      "  [0.28939784]\n",
      "  [0.29294446]\n",
      "  [0.29752433]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08733614534139633\n",
      "Predicci√≥n post entrenamiento : [[0.30597073]]\n",
      "PERDIDAAAA despues: 0.08528443425893784\n",
      "loss en el callback: 0.15875065326690674, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "ejemplar: [[0.28192416]\n",
      " [0.28357172]\n",
      " [0.2845419 ]\n",
      " [0.28660005]\n",
      " [0.28939784]\n",
      " [0.29294446]\n",
      " [0.29752433]\n",
      " [0.30247882]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5945301858653699\n",
      "Predicci√≥n : [[0.30724812]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[[0.28192416]\n",
      "  [0.28357172]\n",
      "  [0.2845419 ]\n",
      "  [0.28660005]\n",
      "  [0.28939784]\n",
      "  [0.29294446]\n",
      "  [0.29752433]\n",
      "  [0.30247882]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08253097534179688\n",
      "Predicci√≥n post entrenamiento : [[0.31054926]]\n",
      "PERDIDAAAA despues: 0.08064515143632889\n",
      "loss en el callback: 0.06643912196159363, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "ejemplar: [[0.28357172]\n",
      " [0.2845419 ]\n",
      " [0.28660005]\n",
      " [0.28939784]\n",
      " [0.29294446]\n",
      " [0.29752433]\n",
      " [0.30247882]\n",
      " [0.30724812]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5984968478614763\n",
      "Predicci√≥n : [[0.3120803]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[[0.28357172]\n",
      "  [0.2845419 ]\n",
      "  [0.28660005]\n",
      "  [0.28939784]\n",
      "  [0.29294446]\n",
      "  [0.29752433]\n",
      "  [0.30247882]\n",
      "  [0.30724812]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08203444629907608\n",
      "Predicci√≥n post entrenamiento : [[0.31544405]]\n",
      "PERDIDAAAA despues: 0.08011888712644577\n",
      "loss en el callback: 0.08758938312530518, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "ejemplar: [[0.2845419 ]\n",
      " [0.28660005]\n",
      " [0.28939784]\n",
      " [0.29294446]\n",
      " [0.29752433]\n",
      " [0.30247882]\n",
      " [0.30724812]\n",
      " [0.31208029]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6213543446734934\n",
      "Predicci√≥n : [[0.3172683]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[[0.2845419 ]\n",
      "  [0.28660005]\n",
      "  [0.28939784]\n",
      "  [0.29294446]\n",
      "  [0.29752433]\n",
      "  [0.30247882]\n",
      "  [0.30724812]\n",
      "  [0.31208029]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09246831387281418\n",
      "Predicci√≥n post entrenamiento : [[0.32066667]]\n",
      "PERDIDAAAA despues: 0.09041307866573334\n",
      "loss en el callback: 0.07995983958244324, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "ejemplar: [[0.28660005]\n",
      " [0.28939784]\n",
      " [0.29294446]\n",
      " [0.29752433]\n",
      " [0.30247882]\n",
      " [0.30724812]\n",
      " [0.31208029]\n",
      " [0.31726831]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.663102676301421\n",
      "Predicci√≥n : [[0.3230583]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[[0.28660005]\n",
      "  [0.28939784]\n",
      "  [0.29294446]\n",
      "  [0.29752433]\n",
      "  [0.30247882]\n",
      "  [0.30724812]\n",
      "  [0.31208029]\n",
      "  [0.31726831]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11563017964363098\n",
      "Predicci√≥n post entrenamiento : [[0.32692733]]\n",
      "PERDIDAAAA despues: 0.1130138710141182\n",
      "loss en el callback: 0.13018283247947693, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "ejemplar: [[0.28939784]\n",
      " [0.29294446]\n",
      " [0.29752433]\n",
      " [0.30247882]\n",
      " [0.30724812]\n",
      " [0.31208029]\n",
      " [0.31726831]\n",
      " [0.32305831]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6928724338328028\n",
      "Predicci√≥n : [[0.32977593]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[[0.28939784]\n",
      "  [0.29294446]\n",
      "  [0.29752433]\n",
      "  [0.30247882]\n",
      "  [0.30724812]\n",
      "  [0.31208029]\n",
      "  [0.31726831]\n",
      "  [0.32305831]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13183905184268951\n",
      "Predicci√≥n post entrenamiento : [[0.33417562]]\n",
      "PERDIDAAAA despues: 0.12866339087486267\n",
      "loss en el callback: 0.1559184193611145, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "ejemplar: [[0.29294446]\n",
      " [0.29752433]\n",
      " [0.30247882]\n",
      " [0.30724812]\n",
      " [0.31208029]\n",
      " [0.31726831]\n",
      " [0.32305831]\n",
      " [0.32977593]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.710663617267639\n",
      "Predicci√≥n : [[0.3374276]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[[0.29294446]\n",
      "  [0.29752433]\n",
      "  [0.30247882]\n",
      "  [0.30724812]\n",
      "  [0.31208029]\n",
      "  [0.31726831]\n",
      "  [0.32305831]\n",
      "  [0.32977593]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13930512964725494\n",
      "Predicci√≥n post entrenamiento : [[0.34158573]]\n",
      "PERDIDAAAA despues: 0.13621848821640015\n",
      "loss en el callback: 0.13276779651641846, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "ejemplar: [[0.29752433]\n",
      " [0.30247882]\n",
      " [0.30724812]\n",
      " [0.31208029]\n",
      " [0.31726831]\n",
      " [0.32305831]\n",
      " [0.32977593]\n",
      " [0.33742759]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7216820581308059\n",
      "Predicci√≥n : [[0.34517583]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[[0.29752433]\n",
      "  [0.30247882]\n",
      "  [0.30724812]\n",
      "  [0.31208029]\n",
      "  [0.31726831]\n",
      "  [0.32305831]\n",
      "  [0.32977593]\n",
      "  [0.33742759]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14175695180892944\n",
      "Predicci√≥n post entrenamiento : [[0.3491474]]\n",
      "PERDIDAAAA despues: 0.1387820690870285\n",
      "loss en el callback: 0.12470000237226486, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "ejemplar: [[0.30247882]\n",
      " [0.30724812]\n",
      " [0.31208029]\n",
      " [0.31726831]\n",
      " [0.32305831]\n",
      " [0.32977593]\n",
      " [0.33742759]\n",
      " [0.34517583]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7259277564223031\n",
      "Predicci√≥n : [[0.35293323]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[[0.30247882]\n",
      "  [0.30724812]\n",
      "  [0.31208029]\n",
      "  [0.31726831]\n",
      "  [0.32305831]\n",
      "  [0.32977593]\n",
      "  [0.33742759]\n",
      "  [0.34517583]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13912492990493774\n",
      "Predicci√≥n post entrenamiento : [[0.35693324]]\n",
      "PERDIDAAAA despues: 0.13615696132183075\n",
      "loss en el callback: 0.2019243687391281, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "ejemplar: [[0.30724812]\n",
      " [0.31208029]\n",
      " [0.31726831]\n",
      " [0.32305831]\n",
      " [0.32977593]\n",
      " [0.33742759]\n",
      " [0.34517583]\n",
      " [0.35293323]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7404318224413275\n",
      "Predicci√≥n : [[0.36091274]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[[0.30724812]\n",
      "  [0.31208029]\n",
      "  [0.31726831]\n",
      "  [0.32305831]\n",
      "  [0.32977593]\n",
      "  [0.33742759]\n",
      "  [0.34517583]\n",
      "  [0.35293323]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1440347582101822\n",
      "Predicci√≥n post entrenamiento : [[0.36496657]]\n",
      "PERDIDAAAA despues: 0.14097417891025543\n",
      "loss en el callback: 0.10958094894886017, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "ejemplar: [[0.31208029]\n",
      " [0.31726831]\n",
      " [0.32305831]\n",
      " [0.32977593]\n",
      " [0.33742759]\n",
      " [0.34517583]\n",
      " [0.35293323]\n",
      " [0.36091274]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7651942561878792\n",
      "Predicci√≥n : [[0.3692771]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[[0.31208029]\n",
      "  [0.31726831]\n",
      "  [0.32305831]\n",
      "  [0.32977593]\n",
      "  [0.33742759]\n",
      "  [0.34517583]\n",
      "  [0.35293323]\n",
      "  [0.36091274]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1567503809928894\n",
      "Predicci√≥n post entrenamiento : [[0.37324572]]\n",
      "PERDIDAAAA despues: 0.15362364053726196\n",
      "loss en el callback: 0.1456405222415924, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "ejemplar: [[0.31726831]\n",
      " [0.32305831]\n",
      " [0.32977593]\n",
      " [0.33742759]\n",
      " [0.34517583]\n",
      " [0.35293323]\n",
      " [0.36091274]\n",
      " [0.36927709]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7447890964420396\n",
      "Predicci√≥n : [[0.37798592]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[[0.31726831]\n",
      "  [0.32305831]\n",
      "  [0.32977593]\n",
      "  [0.33742759]\n",
      "  [0.34517583]\n",
      "  [0.35293323]\n",
      "  [0.36091274]\n",
      "  [0.36927709]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13454458117485046\n",
      "Predicci√≥n post entrenamiento : [[0.38181904]]\n",
      "PERDIDAAAA despues: 0.1317472755908966\n",
      "loss en el callback: 0.14690081775188446, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "ejemplar: [[0.32305831]\n",
      " [0.32977593]\n",
      " [0.33742759]\n",
      " [0.34517583]\n",
      " [0.35293323]\n",
      " [0.36091274]\n",
      " [0.36927709]\n",
      " [0.37798592]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6792163432038085\n",
      "Predicci√≥n : [[0.38702458]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[[0.32305831]\n",
      "  [0.32977593]\n",
      "  [0.33742759]\n",
      "  [0.34517583]\n",
      "  [0.35293323]\n",
      "  [0.36091274]\n",
      "  [0.36927709]\n",
      "  [0.37798592]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08537601679563522\n",
      "Predicci√≥n post entrenamiento : [[0.39006898]]\n",
      "PERDIDAAAA despues: 0.08360619097948074\n",
      "loss en el callback: 0.11972978711128235, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "ejemplar: [[0.32977593]\n",
      " [0.33742759]\n",
      " [0.34517583]\n",
      " [0.35293323]\n",
      " [0.36091274]\n",
      " [0.36927709]\n",
      " [0.37798592]\n",
      " [0.38702458]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6746017659154131\n",
      "Predicci√≥n : [[0.39570984]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[[0.32977593]\n",
      "  [0.33742759]\n",
      "  [0.34517583]\n",
      "  [0.35293323]\n",
      "  [0.36091274]\n",
      "  [0.36927709]\n",
      "  [0.37798592]\n",
      "  [0.38702458]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07778072357177734\n",
      "Predicci√≥n post entrenamiento : [[0.39839157]]\n",
      "PERDIDAAAA despues: 0.07629208266735077\n",
      "loss en el callback: 0.06763136386871338, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "ejemplar: [[0.33742759]\n",
      " [0.34517583]\n",
      " [0.35293323]\n",
      " [0.36091274]\n",
      " [0.36927709]\n",
      " [0.37798592]\n",
      " [0.38702458]\n",
      " [0.39570984]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7309453645768532\n",
      "Predicci√≥n : [[0.40434232]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[[0.33742759]\n",
      "  [0.34517583]\n",
      "  [0.35293323]\n",
      "  [0.36091274]\n",
      "  [0.36927709]\n",
      "  [0.37798592]\n",
      "  [0.38702458]\n",
      "  [0.39570984]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10666953772306442\n",
      "Predicci√≥n post entrenamiento : [[0.40748128]]\n",
      "PERDIDAAAA despues: 0.10462900251150131\n",
      "loss en el callback: 0.09614906460046768, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "ejemplar: [[0.34517583]\n",
      " [0.35293323]\n",
      " [0.36091274]\n",
      " [0.36927709]\n",
      " [0.37798592]\n",
      " [0.38702458]\n",
      " [0.39570984]\n",
      " [0.40434232]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7467210055914982\n",
      "Predicci√≥n : [[0.4135844]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[[0.34517583]\n",
      "  [0.35293323]\n",
      "  [0.36091274]\n",
      "  [0.36927709]\n",
      "  [0.37798592]\n",
      "  [0.38702458]\n",
      "  [0.39570984]\n",
      "  [0.40434232]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11098000407218933\n",
      "Predicci√≥n post entrenamiento : [[0.41708395]]\n",
      "PERDIDAAAA despues: 0.10866060107946396\n",
      "loss en el callback: 0.14746934175491333, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "ejemplar: [[0.35293323]\n",
      " [0.36091274]\n",
      " [0.36927709]\n",
      " [0.37798592]\n",
      " [0.38702458]\n",
      " [0.39570984]\n",
      " [0.40434232]\n",
      " [0.41358441]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7219286889593481\n",
      "Predicci√≥n : [[0.4233602]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[[0.35293323]\n",
      "  [0.36091274]\n",
      "  [0.36927709]\n",
      "  [0.37798592]\n",
      "  [0.38702458]\n",
      "  [0.39570984]\n",
      "  [0.40434232]\n",
      "  [0.41358441]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08914315700531006\n",
      "Predicci√≥n post entrenamiento : [[0.4263004]]\n",
      "PERDIDAAAA despues: 0.08739610016345978\n",
      "loss en el callback: 0.09501296281814575, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "ejemplar: [[0.36091274]\n",
      " [0.36927709]\n",
      " [0.37798592]\n",
      " [0.38702458]\n",
      " [0.39570984]\n",
      " [0.40434232]\n",
      " [0.41358441]\n",
      " [0.4233602 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7199286701160912\n",
      "Predicci√≥n : [[0.4327949]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[[0.36091274]\n",
      "  [0.36927709]\n",
      "  [0.37798592]\n",
      "  [0.38702458]\n",
      "  [0.39570984]\n",
      "  [0.40434232]\n",
      "  [0.41358441]\n",
      "  [0.4233602 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08244580775499344\n",
      "Predicci√≥n post entrenamiento : [[0.43572617]]\n",
      "PERDIDAAAA despues: 0.0807710736989975\n",
      "loss en el callback: 0.11558447778224945, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "ejemplar: [[0.36927709]\n",
      " [0.37798592]\n",
      " [0.38702458]\n",
      " [0.39570984]\n",
      " [0.40434232]\n",
      " [0.41358441]\n",
      " [0.4233602 ]\n",
      " [0.4327949 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7407209490617273\n",
      "Predicci√≥n : [[0.44243807]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[[0.36927709]\n",
      "  [0.37798592]\n",
      "  [0.38702458]\n",
      "  [0.39570984]\n",
      "  [0.40434232]\n",
      "  [0.41358441]\n",
      "  [0.4233602 ]\n",
      "  [0.4327949 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08897266536951065\n",
      "Predicci√≥n post entrenamiento : [[0.44529274]]\n",
      "PERDIDAAAA despues: 0.08727781474590302\n",
      "loss en el callback: 0.07558082044124603, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "ejemplar: [[0.37798592]\n",
      " [0.38702458]\n",
      " [0.39570984]\n",
      " [0.40434232]\n",
      " [0.41358441]\n",
      " [0.4233602 ]\n",
      " [0.4327949 ]\n",
      " [0.44243807]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.736245501831604\n",
      "Predicci√≥n : [[0.45217663]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[[0.37798592]\n",
      "  [0.38702458]\n",
      "  [0.39570984]\n",
      "  [0.40434232]\n",
      "  [0.41358441]\n",
      "  [0.4233602 ]\n",
      "  [0.4327949 ]\n",
      "  [0.44243807]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08069512993097305\n",
      "Predicci√≥n post entrenamiento : [[0.45426974]]\n",
      "PERDIDAAAA despues: 0.07951033860445023\n",
      "loss en el callback: 0.036246418952941895, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "ejemplar: [[0.38702458]\n",
      " [0.39570984]\n",
      " [0.40434232]\n",
      " [0.41358441]\n",
      " [0.4233602 ]\n",
      " [0.4327949 ]\n",
      " [0.44243807]\n",
      " [0.45217663]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7065023284257214\n",
      "Predicci√≥n : [[0.461279]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[[0.38702458]\n",
      "  [0.39570984]\n",
      "  [0.40434232]\n",
      "  [0.41358441]\n",
      "  [0.4233602 ]\n",
      "  [0.4327949 ]\n",
      "  [0.44243807]\n",
      "  [0.45217663]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06013447418808937\n",
      "Predicci√≥n post entrenamiento : [[0.4634804]]\n",
      "PERDIDAAAA despues: 0.05905964598059654\n",
      "loss en el callback: 0.06518500298261642, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "ejemplar: [[0.39570984]\n",
      " [0.40434232]\n",
      " [0.41358441]\n",
      " [0.4233602 ]\n",
      " [0.4327949 ]\n",
      " [0.44243807]\n",
      " [0.45217663]\n",
      " [0.461279  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6979451506854685\n",
      "Predicci√≥n : [[0.4705624]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[[0.39570984]\n",
      "  [0.40434232]\n",
      "  [0.41358441]\n",
      "  [0.4233602 ]\n",
      "  [0.4327949 ]\n",
      "  [0.44243807]\n",
      "  [0.45217663]\n",
      "  [0.461279  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05170292779803276\n",
      "Predicci√≥n post entrenamiento : [[0.47287112]]\n",
      "PERDIDAAAA despues: 0.05065833032131195\n",
      "loss en el callback: 0.07534579187631607, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "ejemplar: [[0.40434232]\n",
      " [0.41358441]\n",
      " [0.4233602 ]\n",
      " [0.4327949 ]\n",
      " [0.44243807]\n",
      " [0.45217663]\n",
      " [0.461279  ]\n",
      " [0.4705624 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7105739686108449\n",
      "Predicci√≥n : [[0.4801356]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[[0.40434232]\n",
      "  [0.41358441]\n",
      "  [0.4233602 ]\n",
      "  [0.4327949 ]\n",
      "  [0.44243807]\n",
      "  [0.45217663]\n",
      "  [0.461279  ]\n",
      "  [0.4705624 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05310184881091118\n",
      "Predicci√≥n post entrenamiento : [[0.48230982]]\n",
      "PERDIDAAAA despues: 0.05210452526807785\n",
      "loss en el callback: 0.0736156478524208, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "ejemplar: [[0.41358441]\n",
      " [0.4233602 ]\n",
      " [0.4327949 ]\n",
      " [0.44243807]\n",
      " [0.45217663]\n",
      " [0.461279  ]\n",
      " [0.4705624 ]\n",
      " [0.48013559]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7209621522504839\n",
      "Predicci√≥n : [[0.4898016]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[[0.41358441]\n",
      "  [0.4233602 ]\n",
      "  [0.4327949 ]\n",
      "  [0.44243807]\n",
      "  [0.45217663]\n",
      "  [0.461279  ]\n",
      "  [0.4705624 ]\n",
      "  [0.48013559]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05343521386384964\n",
      "Predicci√≥n post entrenamiento : [[0.49211523]]\n",
      "PERDIDAAAA despues: 0.05237092077732086\n",
      "loss en el callback: 0.07956206053495407, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "ejemplar: [[0.4233602 ]\n",
      " [0.4327949 ]\n",
      " [0.44243807]\n",
      " [0.45217663]\n",
      " [0.461279  ]\n",
      " [0.4705624 ]\n",
      " [0.48013559]\n",
      " [0.48980159]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7291097016043858\n",
      "Predicci√≥n : [[0.4997088]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[[0.4233602 ]\n",
      "  [0.4327949 ]\n",
      "  [0.44243807]\n",
      "  [0.45217663]\n",
      "  [0.461279  ]\n",
      "  [0.4705624 ]\n",
      "  [0.48013559]\n",
      "  [0.48980159]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05262477323412895\n",
      "Predicci√≥n post entrenamiento : [[0.5007776]]\n",
      "PERDIDAAAA despues: 0.05213554948568344\n",
      "loss en el callback: 0.009033058770000935, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "ejemplar: [[0.4327949 ]\n",
      " [0.44243807]\n",
      " [0.45217663]\n",
      " [0.461279  ]\n",
      " [0.4705624 ]\n",
      " [0.48013559]\n",
      " [0.48980159]\n",
      " [0.4997088 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7674259644168786\n",
      "Predicci√≥n : [[0.50834095]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[[0.4327949 ]\n",
      "  [0.44243807]\n",
      "  [0.45217663]\n",
      "  [0.461279  ]\n",
      "  [0.4705624 ]\n",
      "  [0.48013559]\n",
      "  [0.48980159]\n",
      "  [0.4997088 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06712503731250763\n",
      "Predicci√≥n post entrenamiento : [[0.51018155]]\n",
      "PERDIDAAAA despues: 0.06617468595504761\n",
      "loss en el callback: 0.030566390603780746, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "ejemplar: [[0.44243807]\n",
      " [0.45217663]\n",
      " [0.461279  ]\n",
      " [0.4705624 ]\n",
      " [0.48013559]\n",
      " [0.48980159]\n",
      " [0.4997088 ]\n",
      " [0.50834095]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8359109406879621\n",
      "Predicci√≥n : [[0.5177924]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[[0.44243807]\n",
      "  [0.45217663]\n",
      "  [0.461279  ]\n",
      "  [0.4705624 ]\n",
      "  [0.48013559]\n",
      "  [0.48980159]\n",
      "  [0.4997088 ]\n",
      "  [0.50834095]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10119938850402832\n",
      "Predicci√≥n post entrenamiento : [[0.5205714]]\n",
      "PERDIDAAAA despues: 0.09943900257349014\n",
      "loss en el callback: 0.10000442713499069, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "ejemplar: [[0.45217663]\n",
      " [0.461279  ]\n",
      " [0.4705624 ]\n",
      " [0.48013559]\n",
      " [0.48980159]\n",
      " [0.4997088 ]\n",
      " [0.50834095]\n",
      " [0.5177924 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8510103358824123\n",
      "Predicci√≥n : [[0.5281763]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[[0.45217663]\n",
      "  [0.461279  ]\n",
      "  [0.4705624 ]\n",
      "  [0.48013559]\n",
      "  [0.48980159]\n",
      "  [0.4997088 ]\n",
      "  [0.50834095]\n",
      "  [0.5177924 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10422179847955704\n",
      "Predicci√≥n post entrenamiento : [[0.5308063]]\n",
      "PERDIDAAAA despues: 0.10253061354160309\n",
      "loss en el callback: 0.07809606939554214, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "ejemplar: [[0.461279  ]\n",
      " [0.4705624 ]\n",
      " [0.48013559]\n",
      " [0.48980159]\n",
      " [0.4997088 ]\n",
      " [0.50834095]\n",
      " [0.5177924 ]\n",
      " [0.52817631]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8127241500002294\n",
      "Predicci√≥n : [[0.53837496]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[[0.461279  ]\n",
      "  [0.4705624 ]\n",
      "  [0.48013559]\n",
      "  [0.48980159]\n",
      "  [0.4997088 ]\n",
      "  [0.50834095]\n",
      "  [0.5177924 ]\n",
      "  [0.52817631]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.075267493724823\n",
      "Predicci√≥n post entrenamiento : [[0.54045063]]\n",
      "PERDIDAAAA despues: 0.07413288205862045\n",
      "loss en el callback: 0.056798435747623444, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "ejemplar: [[0.4705624 ]\n",
      " [0.48013559]\n",
      " [0.48980159]\n",
      " [0.4997088 ]\n",
      " [0.50834095]\n",
      " [0.5177924 ]\n",
      " [0.52817631]\n",
      " [0.53837496]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7863940290280375\n",
      "Predicci√≥n : [[0.54814786]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[[0.4705624 ]\n",
      "  [0.48013559]\n",
      "  [0.48980159]\n",
      "  [0.4997088 ]\n",
      "  [0.50834095]\n",
      "  [0.5177924 ]\n",
      "  [0.52817631]\n",
      "  [0.53837496]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05676122382283211\n",
      "Predicci√≥n post entrenamiento : [[0.5502119]]\n",
      "PERDIDAAAA despues: 0.05578198283910751\n",
      "loss en el callback: 0.05103309825062752, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "ejemplar: [[0.48013559]\n",
      " [0.48980159]\n",
      " [0.4997088 ]\n",
      " [0.50834095]\n",
      " [0.5177924 ]\n",
      " [0.52817631]\n",
      " [0.53837496]\n",
      " [0.54814786]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7720199729658365\n",
      "Predicci√≥n : [[0.5580162]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[[0.48013559]\n",
      "  [0.48980159]\n",
      "  [0.4997088 ]\n",
      "  [0.50834095]\n",
      "  [0.5177924 ]\n",
      "  [0.52817631]\n",
      "  [0.53837496]\n",
      "  [0.54814786]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04579762741923332\n",
      "Predicci√≥n post entrenamiento : [[0.5600185]]\n",
      "PERDIDAAAA despues: 0.0449446365237236\n",
      "loss en el callback: 0.05996307358145714, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "ejemplar: [[0.48980159]\n",
      " [0.4997088 ]\n",
      " [0.50834095]\n",
      " [0.5177924 ]\n",
      " [0.52817631]\n",
      " [0.53837496]\n",
      " [0.54814786]\n",
      " [0.55801618]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8033170564228299\n",
      "Predicci√≥n : [[0.5678743]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[[0.48980159]\n",
      "  [0.4997088 ]\n",
      "  [0.50834095]\n",
      "  [0.5177924 ]\n",
      "  [0.52817631]\n",
      "  [0.53837496]\n",
      "  [0.54814786]\n",
      "  [0.55801618]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05543329194188118\n",
      "Predicci√≥n post entrenamiento : [[0.56964535]]\n",
      "PERDIDAAAA despues: 0.054602473974227905\n",
      "loss en el callback: 0.037099242210388184, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "ejemplar: [[0.4997088 ]\n",
      " [0.50834095]\n",
      " [0.5177924 ]\n",
      " [0.52817631]\n",
      " [0.53837496]\n",
      " [0.54814786]\n",
      " [0.55801618]\n",
      " [0.56787431]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8802852793990171\n",
      "Predicci√≥n : [[0.57754046]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[[0.4997088 ]\n",
      "  [0.50834095]\n",
      "  [0.5177924 ]\n",
      "  [0.52817631]\n",
      "  [0.53837496]\n",
      "  [0.54814786]\n",
      "  [0.55801618]\n",
      "  [0.56787431]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09165441989898682\n",
      "Predicci√≥n post entrenamiento : [[0.5803181]]\n",
      "PERDIDAAAA despues: 0.08998030424118042\n",
      "loss en el callback: 0.12283532321453094, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "ejemplar: [[0.50834095]\n",
      " [0.5177924 ]\n",
      " [0.52817631]\n",
      " [0.53837496]\n",
      " [0.54814786]\n",
      " [0.55801618]\n",
      " [0.56787431]\n",
      " [0.57754046]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8987051676996881\n",
      "Predicci√≥n : [[0.5882012]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[[0.50834095]\n",
      "  [0.5177924 ]\n",
      "  [0.52817631]\n",
      "  [0.53837496]\n",
      "  [0.54814786]\n",
      "  [0.55801618]\n",
      "  [0.56787431]\n",
      "  [0.57754046]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09641271084547043\n",
      "Predicci√≥n post entrenamiento : [[0.5907249]]\n",
      "PERDIDAAAA despues: 0.09485186636447906\n",
      "loss en el callback: 0.08161734789609909, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "ejemplar: [[0.5177924 ]\n",
      " [0.52817631]\n",
      " [0.53837496]\n",
      " [0.54814786]\n",
      " [0.55801618]\n",
      " [0.56787431]\n",
      " [0.57754046]\n",
      " [0.58820122]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8585767213248423\n",
      "Predicci√≥n : [[0.59894466]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[[0.5177924 ]\n",
      "  [0.52817631]\n",
      "  [0.53837496]\n",
      "  [0.54814786]\n",
      "  [0.55801618]\n",
      "  [0.56787431]\n",
      "  [0.57754046]\n",
      "  [0.58820122]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06740880012512207\n",
      "Predicci√≥n post entrenamiento : [[0.6006801]]\n",
      "PERDIDAAAA despues: 0.0665106549859047\n",
      "loss en el callback: 0.0362473726272583, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "ejemplar: [[0.52817631]\n",
      " [0.53837496]\n",
      " [0.54814786]\n",
      " [0.55801618]\n",
      " [0.56787431]\n",
      " [0.57754046]\n",
      " [0.58820122]\n",
      " [0.59894466]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8308762565987861\n",
      "Predicci√≥n : [[0.6090714]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[[0.52817631]\n",
      "  [0.53837496]\n",
      "  [0.54814786]\n",
      "  [0.55801618]\n",
      "  [0.56787431]\n",
      "  [0.57754046]\n",
      "  [0.58820122]\n",
      "  [0.59894466]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04919739440083504\n",
      "Predicci√≥n post entrenamiento : [[0.6101832]]\n",
      "PERDIDAAAA despues: 0.04870542138814926\n",
      "loss en el callback: 0.014230458065867424, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "ejemplar: [[0.53837496]\n",
      " [0.54814786]\n",
      " [0.55801618]\n",
      " [0.56787431]\n",
      " [0.57754046]\n",
      " [0.58820122]\n",
      " [0.59894466]\n",
      " [0.60907137]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8156037735215196\n",
      "Predicci√≥n : [[0.618519]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[[0.53837496]\n",
      "  [0.54814786]\n",
      "  [0.55801618]\n",
      "  [0.56787431]\n",
      "  [0.57754046]\n",
      "  [0.58820122]\n",
      "  [0.59894466]\n",
      "  [0.60907137]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03884241357445717\n",
      "Predicci√≥n post entrenamiento : [[0.6200688]]\n",
      "PERDIDAAAA despues: 0.03823393955826759\n",
      "loss en el callback: 0.0333348885178566, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "ejemplar: [[0.54814786]\n",
      " [0.55801618]\n",
      " [0.56787431]\n",
      " [0.57754046]\n",
      " [0.58820122]\n",
      " [0.59894466]\n",
      " [0.60907137]\n",
      " [0.61851901]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8116992058331503\n",
      "Predicci√≥n : [[0.628392]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[[0.54814786]\n",
      "  [0.55801618]\n",
      "  [0.56787431]\n",
      "  [0.57754046]\n",
      "  [0.58820122]\n",
      "  [0.59894466]\n",
      "  [0.60907137]\n",
      "  [0.61851901]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0336015410721302\n",
      "Predicci√≥n post entrenamiento : [[0.63034266]]\n",
      "PERDIDAAAA despues: 0.0328901968896389\n",
      "loss en el callback: 0.059512071311473846, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "ejemplar: [[0.55801618]\n",
      " [0.56787431]\n",
      " [0.57754046]\n",
      " [0.58820122]\n",
      " [0.59894466]\n",
      " [0.60907137]\n",
      " [0.61851901]\n",
      " [0.62839198]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8191625535336788\n",
      "Predicci√≥n : [[0.63876724]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[[0.55801618]\n",
      "  [0.56787431]\n",
      "  [0.57754046]\n",
      "  [0.58820122]\n",
      "  [0.59894466]\n",
      "  [0.60907137]\n",
      "  [0.61851901]\n",
      "  [0.62839198]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03254246711730957\n",
      "Predicci√≥n post entrenamiento : [[0.64058626]]\n",
      "PERDIDAAAA despues: 0.03188949078321457\n",
      "loss en el callback: 0.05936263129115105, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "ejemplar: [[0.56787431]\n",
      " [0.57754046]\n",
      " [0.58820122]\n",
      " [0.59894466]\n",
      " [0.60907137]\n",
      " [0.61851901]\n",
      " [0.62839198]\n",
      " [0.63876724]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8218275636038536\n",
      "Predicci√≥n : [[0.64909935]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[[0.56787431]\n",
      "  [0.57754046]\n",
      "  [0.58820122]\n",
      "  [0.59894466]\n",
      "  [0.60907137]\n",
      "  [0.61851901]\n",
      "  [0.62839198]\n",
      "  [0.63876724]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.029835045337677002\n",
      "Predicci√≥n post entrenamiento : [[0.64954937]]\n",
      "PERDIDAAAA despues: 0.029679786413908005\n",
      "loss en el callback: 0.0024121839087456465, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "ejemplar: [[0.57754046]\n",
      " [0.58820122]\n",
      " [0.59894466]\n",
      " [0.60907137]\n",
      " [0.61851901]\n",
      " [0.62839198]\n",
      " [0.63876724]\n",
      " [0.64909935]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8196942360436743\n",
      "Predicci√≥n : [[0.6581594]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[[0.57754046]\n",
      "  [0.58820122]\n",
      "  [0.59894466]\n",
      "  [0.60907137]\n",
      "  [0.61851901]\n",
      "  [0.62839198]\n",
      "  [0.63876724]\n",
      "  [0.64909935]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.026093507185578346\n",
      "Predicci√≥n post entrenamiento : [[0.65962034]]\n",
      "PERDIDAAAA despues: 0.02562364563345909\n",
      "loss en el callback: 0.03653910011053085, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "ejemplar: [[0.58820122]\n",
      " [0.59894466]\n",
      " [0.60907137]\n",
      " [0.61851901]\n",
      " [0.62839198]\n",
      " [0.63876724]\n",
      " [0.64909935]\n",
      " [0.65815938]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8178628420548653\n",
      "Predicci√≥n : [[0.6683854]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[[0.58820122]\n",
      "  [0.59894466]\n",
      "  [0.60907137]\n",
      "  [0.61851901]\n",
      "  [0.62839198]\n",
      "  [0.63876724]\n",
      "  [0.64909935]\n",
      "  [0.65815938]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02234351821243763\n",
      "Predicci√≥n post entrenamiento : [[0.67004603]]\n",
      "PERDIDAAAA despues: 0.021849816665053368\n",
      "loss en el callback: 0.055500391870737076, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "ejemplar: [[0.59894466]\n",
      " [0.60907137]\n",
      " [0.61851901]\n",
      " [0.62839198]\n",
      " [0.63876724]\n",
      " [0.64909935]\n",
      " [0.65815938]\n",
      " [0.66838539]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8163333816374257\n",
      "Predicci√≥n : [[0.6786977]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[[0.59894466]\n",
      "  [0.60907137]\n",
      "  [0.61851901]\n",
      "  [0.62839198]\n",
      "  [0.63876724]\n",
      "  [0.64909935]\n",
      "  [0.65815938]\n",
      "  [0.66838539]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01894357241690159\n",
      "Predicci√≥n post entrenamiento : [[0.67951876]]\n",
      "PERDIDAAAA despues: 0.018718233332037926\n",
      "loss en el callback: 0.010339400731027126, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "ejemplar: [[0.60907137]\n",
      " [0.61851901]\n",
      " [0.62839198]\n",
      " [0.63876724]\n",
      " [0.64909935]\n",
      " [0.65815938]\n",
      " [0.66838539]\n",
      " [0.67869771]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8005556061309519\n",
      "Predicci√≥n : [[0.6880011]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[[0.60907137]\n",
      "  [0.61851901]\n",
      "  [0.62839198]\n",
      "  [0.63876724]\n",
      "  [0.64909935]\n",
      "  [0.65815938]\n",
      "  [0.66838539]\n",
      "  [0.67869771]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01266851369291544\n",
      "Predicci√≥n post entrenamiento : [[0.68799067]]\n",
      "PERDIDAAAA despues: 0.012670861557126045\n",
      "loss en el callback: 1.3762542039330583e-06, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "ejemplar: [[0.61851901]\n",
      " [0.62839198]\n",
      " [0.63876724]\n",
      " [0.64909935]\n",
      " [0.65815938]\n",
      " [0.66838539]\n",
      " [0.67869771]\n",
      " [0.6880011 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7705295155354442\n",
      "Predicci√≥n : [[0.696439]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[[0.61851901]\n",
      "  [0.62839198]\n",
      "  [0.63876724]\n",
      "  [0.64909935]\n",
      "  [0.65815938]\n",
      "  [0.66838539]\n",
      "  [0.67869771]\n",
      "  [0.6880011 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005489399190992117\n",
      "Predicci√≥n post entrenamiento : [[0.69713056]]\n",
      "PERDIDAAAA despues: 0.005387405399233103\n",
      "loss en el callback: 0.008255833759903908, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "ejemplar: [[0.62839198]\n",
      " [0.63876724]\n",
      " [0.64909935]\n",
      " [0.65815938]\n",
      " [0.66838539]\n",
      " [0.67869771]\n",
      " [0.6880011 ]\n",
      " [0.69643903]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7426586795525351\n",
      "Predicci√≥n : [[0.7057183]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[[0.62839198]\n",
      "  [0.63876724]\n",
      "  [0.64909935]\n",
      "  [0.65815938]\n",
      "  [0.66838539]\n",
      "  [0.67869771]\n",
      "  [0.6880011 ]\n",
      "  [0.69643903]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001364592812024057\n",
      "Predicci√≥n post entrenamiento : [[0.70565015]]\n",
      "PERDIDAAAA despues: 0.0013696308014914393\n",
      "loss en el callback: 6.559411849593744e-05, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "ejemplar: [[0.63876724]\n",
      " [0.64909935]\n",
      " [0.65815938]\n",
      " [0.66838539]\n",
      " [0.67869771]\n",
      " [0.6880011 ]\n",
      " [0.69643903]\n",
      " [0.70571828]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.716943098182225\n",
      "Predicci√≥n : [[0.7142536]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[[0.63876724]\n",
      "  [0.64909935]\n",
      "  [0.65815938]\n",
      "  [0.66838539]\n",
      "  [0.67869771]\n",
      "  [0.6880011 ]\n",
      "  [0.69643903]\n",
      "  [0.70571828]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.2333068601437844e-06\n",
      "Predicci√≥n post entrenamiento : [[0.71446127]]\n",
      "PERDIDAAAA despues: 6.15942144577275e-06\n",
      "loss en el callback: 0.0008027424919418991, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "ejemplar: [[0.64909935]\n",
      " [0.65815938]\n",
      " [0.66838539]\n",
      " [0.67869771]\n",
      " [0.6880011 ]\n",
      " [0.69643903]\n",
      " [0.70571828]\n",
      " [0.7142536 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7197051306082382\n",
      "Predicci√≥n : [[0.7229093]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[[0.64909935]\n",
      "  [0.65815938]\n",
      "  [0.66838539]\n",
      "  [0.67869771]\n",
      "  [0.6880011 ]\n",
      "  [0.69643903]\n",
      "  [0.70571828]\n",
      "  [0.7142536 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.0266685421811417e-05\n",
      "Predicci√≥n post entrenamiento : [[0.72228396]]\n",
      "PERDIDAAAA despues: 6.650490831816569e-06\n",
      "loss en el callback: 0.005427931901067495, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "ejemplar: [[0.65815938]\n",
      " [0.66838539]\n",
      " [0.67869771]\n",
      " [0.6880011 ]\n",
      " [0.69643903]\n",
      " [0.70571828]\n",
      " [0.7142536 ]\n",
      " [0.72290927]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7509447768305747\n",
      "Predicci√≥n : [[0.73052746]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[[0.65815938]\n",
      "  [0.66838539]\n",
      "  [0.67869771]\n",
      "  [0.6880011 ]\n",
      "  [0.69643903]\n",
      "  [0.70571828]\n",
      "  [0.7142536 ]\n",
      "  [0.72290927]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00041686746408231556\n",
      "Predicci√≥n post entrenamiento : [[0.7304606]]\n",
      "PERDIDAAAA despues: 0.00041960281669162214\n",
      "loss en el callback: 7.185401045717299e-05, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "ejemplar: [[0.66838539]\n",
      " [0.67869771]\n",
      " [0.6880011 ]\n",
      " [0.69643903]\n",
      " [0.70571828]\n",
      " [0.7142536 ]\n",
      " [0.72290927]\n",
      " [0.73052746]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.740278139029679\n",
      "Predicci√≥n : [[0.7387899]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[[0.66838539]\n",
      "  [0.67869771]\n",
      "  [0.6880011 ]\n",
      "  [0.69643903]\n",
      "  [0.70571828]\n",
      "  [0.7142536 ]\n",
      "  [0.72290927]\n",
      "  [0.73052746]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.2147653453430394e-06\n",
      "Predicci√≥n post entrenamiento : [[0.73834413]]\n",
      "PERDIDAAAA despues: 3.7403247006295715e-06\n",
      "loss en el callback: 0.003297557821497321, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "ejemplar: [[0.67869771]\n",
      " [0.6880011 ]\n",
      " [0.69643903]\n",
      " [0.70571828]\n",
      " [0.7142536 ]\n",
      " [0.72290927]\n",
      " [0.73052746]\n",
      " [0.73878992]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.687705217205551\n",
      "Predicci√≥n : [[0.7463956]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[[0.67869771]\n",
      "  [0.6880011 ]\n",
      "  [0.69643903]\n",
      "  [0.70571828]\n",
      "  [0.7142536 ]\n",
      "  [0.72290927]\n",
      "  [0.73052746]\n",
      "  [0.73878992]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003444559406489134\n",
      "Predicci√≥n post entrenamiento : [[0.7465202]]\n",
      "PERDIDAAAA despues: 0.0034592044539749622\n",
      "loss en el callback: 0.0003115417202934623, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "ejemplar: [[0.6880011 ]\n",
      " [0.69643903]\n",
      " [0.70571828]\n",
      " [0.7142536 ]\n",
      " [0.72290927]\n",
      " [0.73052746]\n",
      " [0.73878992]\n",
      " [0.74639559]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6687695580612426\n",
      "Predicci√≥n : [[0.7541843]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[[0.6880011 ]\n",
      "  [0.69643903]\n",
      "  [0.70571828]\n",
      "  [0.7142536 ]\n",
      "  [0.72290927]\n",
      "  [0.73052746]\n",
      "  [0.73878992]\n",
      "  [0.74639559]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007295682560652494\n",
      "Predicci√≥n post entrenamiento : [[0.7546451]]\n",
      "PERDIDAAAA despues: 0.007374613545835018\n",
      "loss en el callback: 0.005250243470072746, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "ejemplar: [[0.69643903]\n",
      " [0.70571828]\n",
      " [0.7142536 ]\n",
      " [0.72290927]\n",
      " [0.73052746]\n",
      " [0.73878992]\n",
      " [0.74639559]\n",
      " [0.75418431]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6834711615967536\n",
      "Predicci√≥n : [[0.76211405]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[[0.69643903]\n",
      "  [0.70571828]\n",
      "  [0.7142536 ]\n",
      "  [0.72290927]\n",
      "  [0.73052746]\n",
      "  [0.73878992]\n",
      "  [0.74639559]\n",
      "  [0.75418431]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006184706464409828\n",
      "Predicci√≥n post entrenamiento : [[0.76138824]]\n",
      "PERDIDAAAA despues: 0.006071074400097132\n",
      "loss en el callback: 0.009811926633119583, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "ejemplar: [[0.70571828]\n",
      " [0.7142536 ]\n",
      " [0.72290927]\n",
      " [0.73052746]\n",
      " [0.73878992]\n",
      " [0.74639559]\n",
      " [0.75418431]\n",
      " [0.76211405]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6877052172055499\n",
      "Predicci√≥n : [[0.768845]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[[0.70571828]\n",
      "  [0.7142536 ]\n",
      "  [0.72290927]\n",
      "  [0.73052746]\n",
      "  [0.73878992]\n",
      "  [0.74639559]\n",
      "  [0.75418431]\n",
      "  [0.76211405]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006583667825907469\n",
      "Predicci√≥n post entrenamiento : [[0.76923424]]\n",
      "PERDIDAAAA despues: 0.0066469814628362656\n",
      "loss en el callback: 0.003690179670229554, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "ejemplar: [[0.7142536 ]\n",
      " [0.72290927]\n",
      " [0.73052746]\n",
      " [0.73878992]\n",
      " [0.74639559]\n",
      " [0.75418431]\n",
      " [0.76211405]\n",
      " [0.76884502]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6814717248876317\n",
      "Predicci√≥n : [[0.77640754]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[[0.7142536 ]\n",
      "  [0.72290927]\n",
      "  [0.73052746]\n",
      "  [0.73878992]\n",
      "  [0.74639559]\n",
      "  [0.75418431]\n",
      "  [0.76211405]\n",
      "  [0.76884502]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009012812748551369\n",
      "Predicci√≥n post entrenamiento : [[0.776691]]\n",
      "PERDIDAAAA despues: 0.009066717699170113\n",
      "loss en el callback: 0.0022062098141759634, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "ejemplar: [[0.72290927]\n",
      " [0.73052746]\n",
      " [0.73878992]\n",
      " [0.74639559]\n",
      " [0.75418431]\n",
      " [0.76211405]\n",
      " [0.76884502]\n",
      " [0.77640754]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.689261843882625\n",
      "Predicci√≥n : [[0.78371954]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[[0.72290927]\n",
      "  [0.73052746]\n",
      "  [0.73878992]\n",
      "  [0.74639559]\n",
      "  [0.75418431]\n",
      "  [0.76211405]\n",
      "  [0.76884502]\n",
      "  [0.77640754]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008922254666686058\n",
      "Predicci√≥n post entrenamiento : [[0.7818697]]\n",
      "PERDIDAAAA despues: 0.008576215244829655\n",
      "loss en el callback: 0.04744251072406769, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "ejemplar: [[0.73052746]\n",
      " [0.73878992]\n",
      " [0.74639559]\n",
      " [0.75418431]\n",
      " [0.76211405]\n",
      " [0.76884502]\n",
      " [0.77640754]\n",
      " [0.78371954]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7110755741905297\n",
      "Predicci√≥n : [[0.78866786]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[[0.73052746]\n",
      "  [0.73878992]\n",
      "  [0.74639559]\n",
      "  [0.75418431]\n",
      "  [0.76211405]\n",
      "  [0.76884502]\n",
      "  [0.77640754]\n",
      "  [0.78371954]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006020557601004839\n",
      "Predicci√≥n post entrenamiento : [[0.787981]]\n",
      "PERDIDAAAA despues: 0.005914435721933842\n",
      "loss en el callback: 0.008228247053921223, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "ejemplar: [[0.73878992]\n",
      " [0.74639559]\n",
      " [0.75418431]\n",
      " [0.76211405]\n",
      " [0.76884502]\n",
      " [0.77640754]\n",
      " [0.78371954]\n",
      " [0.78866786]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7349108623046875\n",
      "Predicci√≥n : [[0.7947813]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[[0.73878992]\n",
      "  [0.74639559]\n",
      "  [0.75418431]\n",
      "  [0.76211405]\n",
      "  [0.76884502]\n",
      "  [0.77640754]\n",
      "  [0.78371954]\n",
      "  [0.78866786]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0035844745580106974\n",
      "Predicci√≥n post entrenamiento : [[0.7954522]]\n",
      "PERDIDAAAA despues: 0.003665252821519971\n",
      "loss en el callback: 0.012217319570481777, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "ejemplar: [[0.74639559]\n",
      " [0.75418431]\n",
      " [0.76211405]\n",
      " [0.76884502]\n",
      " [0.77640754]\n",
      " [0.78371954]\n",
      " [0.78866786]\n",
      " [0.79478133]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7607677082250986\n",
      "Predicci√≥n : [[0.802031]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[[0.74639559]\n",
      "  [0.75418431]\n",
      "  [0.76211405]\n",
      "  [0.76884502]\n",
      "  [0.77640754]\n",
      "  [0.78371954]\n",
      "  [0.78866786]\n",
      "  [0.79478133]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017026584828272462\n",
      "Predicci√≥n post entrenamiento : [[0.8010764]]\n",
      "PERDIDAAAA despues: 0.0016247924650087953\n",
      "loss en el callback: 0.01387647446244955, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "ejemplar: [[0.75418431]\n",
      " [0.76211405]\n",
      " [0.76884502]\n",
      " [0.77640754]\n",
      " [0.78371954]\n",
      " [0.78866786]\n",
      " [0.79478133]\n",
      " [0.80203098]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7711170829224028\n",
      "Predicci√≥n : [[0.8075448]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[[0.75418431]\n",
      "  [0.76211405]\n",
      "  [0.76884502]\n",
      "  [0.77640754]\n",
      "  [0.78371954]\n",
      "  [0.78866786]\n",
      "  [0.79478133]\n",
      "  [0.80203098]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013269799528643489\n",
      "Predicci√≥n post entrenamiento : [[0.806332]]\n",
      "PERDIDAAAA despues: 0.0012400893028825521\n",
      "loss en el callback: 0.021814342588186264, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "ejemplar: [[0.76211405]\n",
      " [0.76884502]\n",
      " [0.77640754]\n",
      " [0.78371954]\n",
      " [0.78866786]\n",
      " [0.79478133]\n",
      " [0.80203098]\n",
      " [0.80754483]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7659589863965997\n",
      "Predicci√≥n : [[0.81257993]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[[0.76211405]\n",
      "  [0.76884502]\n",
      "  [0.77640754]\n",
      "  [0.78371954]\n",
      "  [0.78866786]\n",
      "  [0.79478133]\n",
      "  [0.80203098]\n",
      "  [0.80754483]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002173514338210225\n",
      "Predicci√≥n post entrenamiento : [[0.81155443]]\n",
      "PERDIDAAAA despues: 0.002078946679830551\n",
      "loss en el callback: 0.01720532774925232, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "ejemplar: [[0.76884502]\n",
      " [0.77640754]\n",
      " [0.78371954]\n",
      " [0.78866786]\n",
      " [0.79478133]\n",
      " [0.80203098]\n",
      " [0.80754483]\n",
      " [0.81257993]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7483323528772654\n",
      "Predicci√≥n : [[0.81746554]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[[0.76884502]\n",
      "  [0.77640754]\n",
      "  [0.78371954]\n",
      "  [0.78866786]\n",
      "  [0.79478133]\n",
      "  [0.80203098]\n",
      "  [0.80754483]\n",
      "  [0.81257993]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0047793942503631115\n",
      "Predicci√≥n post entrenamiento : [[0.81560403]]\n",
      "PERDIDAAAA despues: 0.004525474738329649\n",
      "loss en el callback: 0.0517658069729805, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "ejemplar: [[0.77640754]\n",
      " [0.78371954]\n",
      " [0.78866786]\n",
      " [0.79478133]\n",
      " [0.80203098]\n",
      " [0.80754483]\n",
      " [0.81257993]\n",
      " [0.81746554]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7182371823643998\n",
      "Predicci√≥n : [[0.8214269]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[[0.77640754]\n",
      "  [0.78371954]\n",
      "  [0.78866786]\n",
      "  [0.79478133]\n",
      "  [0.80203098]\n",
      "  [0.80754483]\n",
      "  [0.81257993]\n",
      "  [0.81746554]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010648127645254135\n",
      "Predicci√≥n post entrenamiento : [[0.8198594]]\n",
      "PERDIDAAAA despues: 0.01032707653939724\n",
      "loss en el callback: 0.039936721324920654, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "ejemplar: [[0.78371954]\n",
      " [0.78866786]\n",
      " [0.79478133]\n",
      " [0.80203098]\n",
      " [0.80754483]\n",
      " [0.81257993]\n",
      " [0.81746554]\n",
      " [0.82142693]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7089416644962148\n",
      "Predicci√≥n : [[0.8252919]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[[0.78371954]\n",
      "  [0.78866786]\n",
      "  [0.79478133]\n",
      "  [0.80203098]\n",
      "  [0.80754483]\n",
      "  [0.81257993]\n",
      "  [0.81746554]\n",
      "  [0.82142693]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013537377119064331\n",
      "Predicci√≥n post entrenamiento : [[0.8250358]]\n",
      "PERDIDAAAA despues: 0.01347785722464323\n",
      "loss en el callback: 0.0015430024359375238, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "ejemplar: [[0.78866786]\n",
      " [0.79478133]\n",
      " [0.80203098]\n",
      " [0.80754483]\n",
      " [0.81257993]\n",
      " [0.81746554]\n",
      " [0.82142693]\n",
      " [0.82529187]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7204457992727099\n",
      "Predicci√≥n : [[0.83004177]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[[0.78866786]\n",
      "  [0.79478133]\n",
      "  [0.80203098]\n",
      "  [0.80754483]\n",
      "  [0.81257993]\n",
      "  [0.81746554]\n",
      "  [0.82142693]\n",
      "  [0.82529187]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012011272832751274\n",
      "Predicci√≥n post entrenamiento : [[0.82814586]]\n",
      "PERDIDAAAA despues: 0.011599300429224968\n",
      "loss en el callback: 0.05584109574556351, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "ejemplar: [[0.79478133]\n",
      " [0.80203098]\n",
      " [0.80754483]\n",
      " [0.81257993]\n",
      " [0.81746554]\n",
      " [0.82142693]\n",
      " [0.82529187]\n",
      " [0.83004177]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.770615477342717\n",
      "Predicci√≥n : [[0.83328974]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[[0.79478133]\n",
      "  [0.80203098]\n",
      "  [0.80754483]\n",
      "  [0.81257993]\n",
      "  [0.81746554]\n",
      "  [0.82142693]\n",
      "  [0.82529187]\n",
      "  [0.83004177]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00392806576564908\n",
      "Predicci√≥n post entrenamiento : [[0.8320308]]\n",
      "PERDIDAAAA despues: 0.003771840827539563\n",
      "loss en el callback: 0.028109535574913025, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "ejemplar: [[0.80203098]\n",
      " [0.80754483]\n",
      " [0.81257993]\n",
      " [0.81746554]\n",
      " [0.82142693]\n",
      " [0.82529187]\n",
      " [0.83004177]\n",
      " [0.83328974]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8594506987062355\n",
      "Predicci√≥n : [[0.83694]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[[0.80203098]\n",
      "  [0.80754483]\n",
      "  [0.81257993]\n",
      "  [0.81746554]\n",
      "  [0.82142693]\n",
      "  [0.82529187]\n",
      "  [0.83004177]\n",
      "  [0.83328974]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005067319725640118\n",
      "Predicci√≥n post entrenamiento : [[0.8367387]]\n",
      "PERDIDAAAA despues: 0.0005158346029929817\n",
      "loss en el callback: 0.0007697987020947039, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "ejemplar: [[0.80754483]\n",
      " [0.81257993]\n",
      " [0.81746554]\n",
      " [0.82142693]\n",
      " [0.82529187]\n",
      " [0.83004177]\n",
      " [0.83328974]\n",
      " [0.83693999]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9065410812466371\n",
      "Predicci√≥n : [[0.84099233]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[[0.80754483]\n",
      "  [0.81257993]\n",
      "  [0.81746554]\n",
      "  [0.82142693]\n",
      "  [0.82529187]\n",
      "  [0.83004177]\n",
      "  [0.83328974]\n",
      "  [0.83693999]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004296642262488604\n",
      "Predicci√≥n post entrenamiento : [[0.84157044]]\n",
      "PERDIDAAAA despues: 0.004221188370138407\n",
      "loss en el callback: 0.00817058328539133, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "ejemplar: [[0.81257993]\n",
      " [0.81746554]\n",
      " [0.82142693]\n",
      " [0.82529187]\n",
      " [0.83004177]\n",
      " [0.83328974]\n",
      " [0.83693999]\n",
      " [0.84099233]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9118866249639219\n",
      "Predicci√≥n : [[0.84552926]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[[0.81257993]\n",
      "  [0.81746554]\n",
      "  [0.82142693]\n",
      "  [0.82529187]\n",
      "  [0.83004177]\n",
      "  [0.83328974]\n",
      "  [0.83693999]\n",
      "  [0.84099233]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004403301049023867\n",
      "Predicci√≥n post entrenamiento : [[0.84629023]]\n",
      "PERDIDAAAA despues: 0.004302887711673975\n",
      "loss en el callback: 0.014273835346102715, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "ejemplar: [[0.81746554]\n",
      " [0.82142693]\n",
      " [0.82529187]\n",
      " [0.83004177]\n",
      " [0.83328974]\n",
      " [0.83693999]\n",
      " [0.84099233]\n",
      " [0.84552926]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.904335569053715\n",
      "Predicci√≥n : [[0.850025]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[[0.81746554]\n",
      "  [0.82142693]\n",
      "  [0.82529187]\n",
      "  [0.83004177]\n",
      "  [0.83328974]\n",
      "  [0.83693999]\n",
      "  [0.84099233]\n",
      "  [0.84552926]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002949636895209551\n",
      "Predicci√≥n post entrenamiento : [[0.85117686]]\n",
      "PERDIDAAAA despues: 0.0028258473612368107\n",
      "loss en el callback: 0.040792617946863174, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "ejemplar: [[0.82142693]\n",
      " [0.82529187]\n",
      " [0.83004177]\n",
      " [0.83328974]\n",
      " [0.83693999]\n",
      " [0.84099233]\n",
      " [0.84552926]\n",
      " [0.850025  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8838879135160167\n",
      "Predicci√≥n : [[0.8546901]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[[0.82142693]\n",
      "  [0.82529187]\n",
      "  [0.83004177]\n",
      "  [0.83328974]\n",
      "  [0.83693999]\n",
      "  [0.84099233]\n",
      "  [0.84552926]\n",
      "  [0.850025  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008525122539140284\n",
      "Predicci√≥n post entrenamiento : [[0.8551296]]\n",
      "PERDIDAAAA despues: 0.0008270390680991113\n",
      "loss en el callback: 0.004781504161655903, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "ejemplar: [[0.82529187]\n",
      " [0.83004177]\n",
      " [0.83328974]\n",
      " [0.83693999]\n",
      " [0.84099233]\n",
      " [0.84552926]\n",
      " [0.850025  ]\n",
      " [0.85469007]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9032153489332012\n",
      "Predicci√≥n : [[0.8586608]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[[0.82529187]\n",
      "  [0.83004177]\n",
      "  [0.83328974]\n",
      "  [0.83693999]\n",
      "  [0.84099233]\n",
      "  [0.84552926]\n",
      "  [0.850025  ]\n",
      "  [0.85469007]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001985106384381652\n",
      "Predicci√≥n post entrenamiento : [[0.85977846]]\n",
      "PERDIDAAAA despues: 0.0018867629114538431\n",
      "loss en el callback: 0.034691937267780304, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "ejemplar: [[0.83004177]\n",
      " [0.83328974]\n",
      " [0.83693999]\n",
      " [0.84099233]\n",
      " [0.84552926]\n",
      " [0.850025  ]\n",
      " [0.85469007]\n",
      " [0.85866082]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9623178753052692\n",
      "Predicci√≥n : [[0.86336917]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[[0.83004177]\n",
      "  [0.83328974]\n",
      "  [0.83693999]\n",
      "  [0.84099233]\n",
      "  [0.84552926]\n",
      "  [0.850025  ]\n",
      "  [0.85469007]\n",
      "  [0.85866082]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009790848940610886\n",
      "Predicci√≥n post entrenamiento : [[0.86395156]]\n",
      "PERDIDAAAA despues: 0.009675933048129082\n",
      "loss en el callback: 0.007893172092735767, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "ejemplar: [[0.83328974]\n",
      " [0.83693999]\n",
      " [0.84099233]\n",
      " [0.84552926]\n",
      " [0.850025  ]\n",
      " [0.85469007]\n",
      " [0.85866082]\n",
      " [0.86336917]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.982058820003038\n",
      "Predicci√≥n : [[0.8673692]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[[0.83328974]\n",
      "  [0.83693999]\n",
      "  [0.84099233]\n",
      "  [0.84552926]\n",
      "  [0.850025  ]\n",
      "  [0.85469007]\n",
      "  [0.85866082]\n",
      "  [0.86336917]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013153715059161186\n",
      "Predicci√≥n post entrenamiento : [[0.8676751]]\n",
      "PERDIDAAAA despues: 0.013083630241453648\n",
      "loss en el callback: 0.0017409938154742122, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "ejemplar: [[0.83693999]\n",
      " [0.84099233]\n",
      " [0.84552926]\n",
      " [0.850025  ]\n",
      " [0.85469007]\n",
      " [0.85866082]\n",
      " [0.86336917]\n",
      " [0.86736917]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9624381830265082\n",
      "Predicci√≥n : [[0.8713442]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[[0.83693999]\n",
      "  [0.84099233]\n",
      "  [0.84552926]\n",
      "  [0.850025  ]\n",
      "  [0.85469007]\n",
      "  [0.85866082]\n",
      "  [0.86336917]\n",
      "  [0.86736917]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008298109285533428\n",
      "Predicci√≥n post entrenamiento : [[0.87152916]]\n",
      "PERDIDAAAA despues: 0.008264446631073952\n",
      "loss en el callback: 0.0007198082748800516, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "ejemplar: [[0.84099233]\n",
      " [0.84552926]\n",
      " [0.850025  ]\n",
      " [0.85469007]\n",
      " [0.85866082]\n",
      " [0.86336917]\n",
      " [0.86736917]\n",
      " [0.87134421]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9302512105217627\n",
      "Predicci√≥n : [[0.8753777]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[[0.84099233]\n",
      "  [0.84552926]\n",
      "  [0.850025  ]\n",
      "  [0.85469007]\n",
      "  [0.85866082]\n",
      "  [0.86336917]\n",
      "  [0.86736917]\n",
      "  [0.87134421]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0030110974330455065\n",
      "Predicci√≥n post entrenamiento : [[0.87578654]]\n",
      "PERDIDAAAA despues: 0.0029663967434316874\n",
      "loss en el callback: 0.00419733626767993, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "ejemplar: [[0.84552926]\n",
      " [0.850025  ]\n",
      " [0.85469007]\n",
      " [0.85866082]\n",
      " [0.86336917]\n",
      " [0.86736917]\n",
      " [0.87134421]\n",
      " [0.87537771]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.885497902488802\n",
      "Predicci√≥n : [[0.87972057]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[[0.84552926]\n",
      "  [0.850025  ]\n",
      "  [0.85469007]\n",
      "  [0.85866082]\n",
      "  [0.86336917]\n",
      "  [0.86736917]\n",
      "  [0.87134421]\n",
      "  [0.87537771]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.337787711643614e-05\n",
      "Predicci√≥n post entrenamiento : [[0.8799843]]\n",
      "PERDIDAAAA despues: 3.0399878596654162e-05\n",
      "loss en el callback: 0.0016877767629921436, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "ejemplar: [[0.850025  ]\n",
      " [0.85469007]\n",
      " [0.85866082]\n",
      " [0.86336917]\n",
      " [0.86736917]\n",
      " [0.87134421]\n",
      " [0.87537771]\n",
      " [0.87972057]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597025687419927\n",
      "Predicci√≥n : [[0.8838665]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[[0.850025  ]\n",
      "  [0.85469007]\n",
      "  [0.85866082]\n",
      "  [0.86336917]\n",
      "  [0.86736917]\n",
      "  [0.87134421]\n",
      "  [0.87537771]\n",
      "  [0.87972057]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005838941433466971\n",
      "Predicci√≥n post entrenamiento : [[0.88367975]]\n",
      "PERDIDAAAA despues: 0.0005749042029492557\n",
      "loss en el callback: 0.0007819450693204999, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "ejemplar: [[0.85469007]\n",
      " [0.85866082]\n",
      " [0.86336917]\n",
      " [0.86736917]\n",
      " [0.87134421]\n",
      " [0.87537771]\n",
      " [0.87972057]\n",
      " [0.88386649]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8528652092813349\n",
      "Predicci√≥n : [[0.8875031]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[[0.85469007]\n",
      "  [0.85866082]\n",
      "  [0.86336917]\n",
      "  [0.86736917]\n",
      "  [0.87134421]\n",
      "  [0.87537771]\n",
      "  [0.87972057]\n",
      "  [0.88386649]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011997818946838379\n",
      "Predicci√≥n post entrenamiento : [[0.8877678]]\n",
      "PERDIDAAAA despues: 0.0012181896017864347\n",
      "loss en el callback: 0.002003611298277974, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "ejemplar: [[0.85866082]\n",
      " [0.86336917]\n",
      " [0.86736917]\n",
      " [0.87134421]\n",
      " [0.87537771]\n",
      " [0.87972057]\n",
      " [0.88386649]\n",
      " [0.88750309]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8585854533368672\n",
      "Predicci√≥n : [[0.891465]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[[0.85866082]\n",
      "  [0.86336917]\n",
      "  [0.86736917]\n",
      "  [0.87134421]\n",
      "  [0.87537771]\n",
      "  [0.87972057]\n",
      "  [0.88386649]\n",
      "  [0.88750309]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010810635285452008\n",
      "Predicci√≥n post entrenamiento : [[0.89141846]]\n",
      "PERDIDAAAA despues: 0.0010780045995488763\n",
      "loss en el callback: 5.9881167544517666e-05, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "ejemplar: [[0.86336917]\n",
      " [0.86736917]\n",
      " [0.87134421]\n",
      " [0.87537771]\n",
      " [0.87972057]\n",
      " [0.88386649]\n",
      " [0.88750309]\n",
      " [0.89146501]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8768633009085897\n",
      "Predicci√≥n : [[0.8951636]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[[0.86336917]\n",
      "  [0.86736917]\n",
      "  [0.87134421]\n",
      "  [0.87537771]\n",
      "  [0.87972057]\n",
      "  [0.88386649]\n",
      "  [0.88750309]\n",
      "  [0.89146501]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00033490080386400223\n",
      "Predicci√≥n post entrenamiento : [[0.8957053]]\n",
      "PERDIDAAAA despues: 0.00035502028185874224\n",
      "loss en el callback: 0.009976748377084732, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "ejemplar: [[0.86736917]\n",
      " [0.87134421]\n",
      " [0.87537771]\n",
      " [0.87972057]\n",
      " [0.88386649]\n",
      " [0.88750309]\n",
      " [0.89146501]\n",
      " [0.8951636 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8806463966074481\n",
      "Predicci√≥n : [[0.89928263]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[[0.86736917]\n",
      "  [0.87134421]\n",
      "  [0.87537771]\n",
      "  [0.87972057]\n",
      "  [0.88386649]\n",
      "  [0.88750309]\n",
      "  [0.89146501]\n",
      "  [0.8951636 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003473089309409261\n",
      "Predicci√≥n post entrenamiento : [[0.899248]]\n",
      "PERDIDAAAA despues: 0.0003460193984210491\n",
      "loss en el callback: 3.094852581853047e-05, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "ejemplar: [[0.87134421]\n",
      " [0.87537771]\n",
      " [0.87972057]\n",
      " [0.88386649]\n",
      " [0.88750309]\n",
      " [0.89146501]\n",
      " [0.8951636 ]\n",
      " [0.89928263]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8699347404334429\n",
      "Predicci√≥n : [[0.902831]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[[0.87134421]\n",
      "  [0.87537771]\n",
      "  [0.87972057]\n",
      "  [0.88386649]\n",
      "  [0.88750309]\n",
      "  [0.89146501]\n",
      "  [0.8951636 ]\n",
      "  [0.89928263]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001082165283150971\n",
      "Predicci√≥n post entrenamiento : [[0.90364736]]\n",
      "PERDIDAAAA despues: 0.0011365411337465048\n",
      "loss en el callback: 0.029632365331053734, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "ejemplar: [[0.87537771]\n",
      " [0.87972057]\n",
      " [0.88386649]\n",
      " [0.88750309]\n",
      " [0.89146501]\n",
      " [0.8951636 ]\n",
      " [0.89928263]\n",
      " [0.90283102]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8465135437340043\n",
      "Predicci√≥n : [[0.9072375]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[[0.87537771]\n",
      "  [0.87972057]\n",
      "  [0.88386649]\n",
      "  [0.88750309]\n",
      "  [0.89146501]\n",
      "  [0.8951636 ]\n",
      "  [0.89928263]\n",
      "  [0.90283102]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0036873994395136833\n",
      "Predicci√≥n post entrenamiento : [[0.907538]]\n",
      "PERDIDAAAA despues: 0.003723980626091361\n",
      "loss en el callback: 0.002749302191659808, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "ejemplar: [[0.87972057]\n",
      " [0.88386649]\n",
      " [0.88750309]\n",
      " [0.89146501]\n",
      " [0.8951636 ]\n",
      " [0.89928263]\n",
      " [0.90283102]\n",
      " [0.90723753]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8103828065091326\n",
      "Predicci√≥n : [[0.9111134]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[[0.87972057]\n",
      "  [0.88386649]\n",
      "  [0.88750309]\n",
      "  [0.89146501]\n",
      "  [0.8951636 ]\n",
      "  [0.89928263]\n",
      "  [0.90283102]\n",
      "  [0.90723753]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010146653279662132\n",
      "Predicci√≥n post entrenamiento : [[0.90918016]]\n",
      "PERDIDAAAA despues: 0.009760922752320766\n",
      "loss en el callback: 0.07347342371940613, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "ejemplar: [[0.88386649]\n",
      " [0.88750309]\n",
      " [0.89146501]\n",
      " [0.8951636 ]\n",
      " [0.89928263]\n",
      " [0.90283102]\n",
      " [0.90723753]\n",
      " [0.91111338]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8026111217617493\n",
      "Predicci√≥n : [[0.91264176]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[[0.88386649]\n",
      "  [0.88750309]\n",
      "  [0.89146501]\n",
      "  [0.8951636 ]\n",
      "  [0.89928263]\n",
      "  [0.90283102]\n",
      "  [0.90723753]\n",
      "  [0.91111338]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012106744572520256\n",
      "Predicci√≥n post entrenamiento : [[0.912702]]\n",
      "PERDIDAAAA despues: 0.01212000846862793\n",
      "loss en el callback: 0.00011825885303551331, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "ejemplar: [[0.88750309]\n",
      " [0.89146501]\n",
      " [0.8951636 ]\n",
      " [0.89928263]\n",
      " [0.90283102]\n",
      " [0.90723753]\n",
      " [0.91111338]\n",
      " [0.91264176]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.823198489491854\n",
      "Predicci√≥n : [[0.9160801]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[[0.88750309]\n",
      "  [0.89146501]\n",
      "  [0.8951636 ]\n",
      "  [0.89928263]\n",
      "  [0.90283102]\n",
      "  [0.90723753]\n",
      "  [0.91111338]\n",
      "  [0.91264176]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008626995608210564\n",
      "Predicci√≥n post entrenamiento : [[0.914614]]\n",
      "PERDIDAAAA despues: 0.008356798440217972\n",
      "loss en el callback: 0.044489726424217224, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "ejemplar: [[0.89146501]\n",
      " [0.8951636 ]\n",
      " [0.89928263]\n",
      " [0.90283102]\n",
      " [0.90723753]\n",
      " [0.91111338]\n",
      " [0.91264176]\n",
      " [0.91608012]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8397204264676091\n",
      "Predicci√≥n : [[0.9180254]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[[0.89146501]\n",
      "  [0.8951636 ]\n",
      "  [0.89928263]\n",
      "  [0.90283102]\n",
      "  [0.90723753]\n",
      "  [0.91111338]\n",
      "  [0.91264176]\n",
      "  [0.91608012]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006131664849817753\n",
      "Predicci√≥n post entrenamiento : [[0.9182095]]\n",
      "PERDIDAAAA despues: 0.006160533521324396\n",
      "loss en el callback: 0.0012816386297345161, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "ejemplar: [[0.8951636 ]\n",
      " [0.89928263]\n",
      " [0.90283102]\n",
      " [0.90723753]\n",
      " [0.91111338]\n",
      " [0.91264176]\n",
      " [0.91608012]\n",
      " [0.91802537]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.852176932689015\n",
      "Predicci√≥n : [[0.9215362]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[[0.8951636 ]\n",
      "  [0.89928263]\n",
      "  [0.90283102]\n",
      "  [0.90723753]\n",
      "  [0.91111338]\n",
      "  [0.91264176]\n",
      "  [0.91608012]\n",
      "  [0.91802537]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004810712765902281\n",
      "Predicci√≥n post entrenamiento : [[0.92166626]]\n",
      "PERDIDAAAA despues: 0.004828771110624075\n",
      "loss en el callback: 0.000583136803470552, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "ejemplar: [[0.89928263]\n",
      " [0.90283102]\n",
      " [0.90723753]\n",
      " [0.91111338]\n",
      " [0.91264176]\n",
      " [0.91608012]\n",
      " [0.91802537]\n",
      " [0.92153621]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8615626813481295\n",
      "Predicci√≥n : [[0.9249397]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[[0.89928263]\n",
      "  [0.90283102]\n",
      "  [0.90723753]\n",
      "  [0.91111338]\n",
      "  [0.91264176]\n",
      "  [0.91608012]\n",
      "  [0.91802537]\n",
      "  [0.92153621]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00401664711534977\n",
      "Predicci√≥n post entrenamiento : [[0.9243313]]\n",
      "PERDIDAAAA despues: 0.003939901944249868\n",
      "loss en el callback: 0.010134156793355942, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "ejemplar: [[0.90283102]\n",
      " [0.90723753]\n",
      " [0.91111338]\n",
      " [0.91264176]\n",
      " [0.91608012]\n",
      " [0.91802537]\n",
      " [0.92153621]\n",
      " [0.92493969]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8678776724449532\n",
      "Predicci√≥n : [[0.9273905]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[[0.90283102]\n",
      "  [0.90723753]\n",
      "  [0.91111338]\n",
      "  [0.91264176]\n",
      "  [0.91608012]\n",
      "  [0.91802537]\n",
      "  [0.92153621]\n",
      "  [0.92493969]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0035417797043919563\n",
      "Predicci√≥n post entrenamiento : [[0.9271085]]\n",
      "PERDIDAAAA despues: 0.003508295165374875\n",
      "loss en el callback: 0.0023350927513092756, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "ejemplar: [[0.90723753]\n",
      " [0.91111338]\n",
      " [0.91264176]\n",
      " [0.91608012]\n",
      " [0.91802537]\n",
      " [0.92153621]\n",
      " [0.92493969]\n",
      " [0.92739052]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8701963127047843\n",
      "Predicci√≥n : [[0.9300628]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[[0.90723753]\n",
      "  [0.91111338]\n",
      "  [0.91264176]\n",
      "  [0.91608012]\n",
      "  [0.91802537]\n",
      "  [0.92153621]\n",
      "  [0.92493969]\n",
      "  [0.92739052]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0035839893389493227\n",
      "Predicci√≥n post entrenamiento : [[0.92988884]]\n",
      "PERDIDAAAA despues: 0.0035631947685033083\n",
      "loss en el callback: 0.0008992081275209785, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "ejemplar: [[0.91111338]\n",
      " [0.91264176]\n",
      " [0.91608012]\n",
      " [0.91802537]\n",
      " [0.92153621]\n",
      " [0.92493969]\n",
      " [0.92739052]\n",
      " [0.93006277]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8685186021276227\n",
      "Predicci√≥n : [[0.93245405]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[[0.91111338]\n",
      "  [0.91264176]\n",
      "  [0.91608012]\n",
      "  [0.91802537]\n",
      "  [0.92153621]\n",
      "  [0.92493969]\n",
      "  [0.92739052]\n",
      "  [0.93006277]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004087742883712053\n",
      "Predicci√≥n post entrenamiento : [[0.9319083]]\n",
      "PERDIDAAAA despues: 0.004018256440758705\n",
      "loss en el callback: 0.008587214164435863, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "ejemplar: [[0.91264176]\n",
      " [0.91608012]\n",
      " [0.91802537]\n",
      " [0.92153621]\n",
      " [0.92493969]\n",
      " [0.92739052]\n",
      " [0.93006277]\n",
      " [0.93245405]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8529880395838255\n",
      "Predicci√≥n : [[0.93417454]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[[0.91264176]\n",
      "  [0.91608012]\n",
      "  [0.91802537]\n",
      "  [0.92153621]\n",
      "  [0.92493969]\n",
      "  [0.92739052]\n",
      "  [0.93006277]\n",
      "  [0.93245405]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006591243669390678\n",
      "Predicci√≥n post entrenamiento : [[0.9345773]]\n",
      "PERDIDAAAA despues: 0.006656801328063011\n",
      "loss en el callback: 0.0072196065448224545, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "ejemplar: [[0.91608012]\n",
      " [0.91802537]\n",
      " [0.92153621]\n",
      " [0.92493969]\n",
      " [0.92739052]\n",
      " [0.93006277]\n",
      " [0.93245405]\n",
      " [0.93417454]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8236046250733932\n",
      "Predicci√≥n : [[0.9371812]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[[0.91608012]\n",
      "  [0.91802537]\n",
      "  [0.92153621]\n",
      "  [0.92493969]\n",
      "  [0.92739052]\n",
      "  [0.93006277]\n",
      "  [0.93245405]\n",
      "  [0.93417454]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012899628840386868\n",
      "Predicci√≥n post entrenamiento : [[0.9363337]]\n",
      "PERDIDAAAA despues: 0.012707843445241451\n",
      "loss en el callback: 0.020174451172351837, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "ejemplar: [[0.91802537]\n",
      " [0.92153621]\n",
      " [0.92493969]\n",
      " [0.92739052]\n",
      " [0.93006277]\n",
      " [0.93245405]\n",
      " [0.93417454]\n",
      " [0.93718117]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8032508871761479\n",
      "Predicci√≥n : [[0.9387572]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[[0.91802537]\n",
      "  [0.92153621]\n",
      "  [0.92493969]\n",
      "  [0.92739052]\n",
      "  [0.93006277]\n",
      "  [0.93245405]\n",
      "  [0.93417454]\n",
      "  [0.93718117]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018361950293183327\n",
      "Predicci√≥n post entrenamiento : [[0.9372718]]\n",
      "PERDIDAAAA despues: 0.017961591482162476\n",
      "loss en el callback: 0.05701231211423874, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "ejemplar: [[0.92153621]\n",
      " [0.92493969]\n",
      " [0.92739052]\n",
      " [0.93006277]\n",
      " [0.93245405]\n",
      " [0.93417454]\n",
      " [0.93718117]\n",
      " [0.93875718]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7919268258920897\n",
      "Predicci√≥n : [[0.93990296]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[[0.92153621]\n",
      "  [0.92493969]\n",
      "  [0.92739052]\n",
      "  [0.93006277]\n",
      "  [0.93245405]\n",
      "  [0.93417454]\n",
      "  [0.93718117]\n",
      "  [0.93875718]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02189694344997406\n",
      "Predicci√≥n post entrenamiento : [[0.9387342]]\n",
      "PERDIDAAAA despues: 0.021552404388785362\n",
      "loss en el callback: 0.0387437529861927, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "ejemplar: [[0.92493969]\n",
      " [0.92739052]\n",
      " [0.93006277]\n",
      " [0.93245405]\n",
      " [0.93417454]\n",
      " [0.93718117]\n",
      " [0.93875718]\n",
      " [0.93990296]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7865023059771536\n",
      "Predicci√≥n : [[0.9411162]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[[0.92493969]\n",
      "  [0.92739052]\n",
      "  [0.93006277]\n",
      "  [0.93245405]\n",
      "  [0.93417454]\n",
      "  [0.93718117]\n",
      "  [0.93875718]\n",
      "  [0.93990296]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02390546165406704\n",
      "Predicci√≥n post entrenamiento : [[0.9415917]]\n",
      "PERDIDAAAA despues: 0.024052714928984642\n",
      "loss en el callback: 0.010770097374916077, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "ejemplar: [[0.92739052]\n",
      " [0.93006277]\n",
      " [0.93245405]\n",
      " [0.93417454]\n",
      " [0.93718117]\n",
      " [0.93875718]\n",
      " [0.93990296]\n",
      " [0.94111621]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7869773274313391\n",
      "Predicci√≥n : [[0.9436843]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[[0.92739052]\n",
      "  [0.93006277]\n",
      "  [0.93245405]\n",
      "  [0.93417454]\n",
      "  [0.93718117]\n",
      "  [0.93875718]\n",
      "  [0.93990296]\n",
      "  [0.94111621]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02455706149339676\n",
      "Predicci√≥n post entrenamiento : [[0.9431025]]\n",
      "PERDIDAAAA despues: 0.024375054985284805\n",
      "loss en el callback: 0.011792437173426151, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "ejemplar: [[0.93006277]\n",
      " [0.93245405]\n",
      " [0.93417454]\n",
      " [0.93718117]\n",
      " [0.93875718]\n",
      " [0.93990296]\n",
      " [0.94111621]\n",
      " [0.94368428]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7874362431744556\n",
      "Predicci√≥n : [[0.9451143]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[[0.93006277]\n",
      "  [0.93245405]\n",
      "  [0.93417454]\n",
      "  [0.93718117]\n",
      "  [0.93875718]\n",
      "  [0.93990296]\n",
      "  [0.94111621]\n",
      "  [0.94368428]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.024862373247742653\n",
      "Predicci√≥n post entrenamiento : [[0.9444134]]\n",
      "PERDIDAAAA despues: 0.02464183419942856\n",
      "loss en el callback: 0.015663020312786102, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "ejemplar: [[0.93245405]\n",
      " [0.93417454]\n",
      " [0.93718117]\n",
      " [0.93875718]\n",
      " [0.93990296]\n",
      " [0.94111621]\n",
      " [0.94368428]\n",
      " [0.94511431]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7878790532065031\n",
      "Predicci√≥n : [[0.94624585]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[[0.93245405]\n",
      "  [0.93417454]\n",
      "  [0.93718117]\n",
      "  [0.93875718]\n",
      "  [0.93990296]\n",
      "  [0.94111621]\n",
      "  [0.94368428]\n",
      "  [0.94511431]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.025080043822526932\n",
      "Predicci√≥n post entrenamiento : [[0.9452713]]\n",
      "PERDIDAAAA despues: 0.024772323668003082\n",
      "loss en el callback: 0.030567245557904243, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "ejemplar: [[0.93417454]\n",
      " [0.93718117]\n",
      " [0.93875718]\n",
      " [0.93990296]\n",
      " [0.94111621]\n",
      " [0.94368428]\n",
      " [0.94511431]\n",
      " [0.94624585]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7954532004373992\n",
      "Predicci√≥n : [[0.9469603]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[[0.93417454]\n",
      "  [0.93718117]\n",
      "  [0.93875718]\n",
      "  [0.93990296]\n",
      "  [0.94111621]\n",
      "  [0.94368428]\n",
      "  [0.94511431]\n",
      "  [0.94624585]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022954395040869713\n",
      "Predicci√≥n post entrenamiento : [[0.946011]]\n",
      "PERDIDAAAA despues: 0.0226676557213068\n",
      "loss en el callback: 0.030238082632422447, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "ejemplar: [[0.93718117]\n",
      " [0.93875718]\n",
      " [0.93990296]\n",
      " [0.94111621]\n",
      " [0.94368428]\n",
      " [0.94511431]\n",
      " [0.94624585]\n",
      " [0.94696027]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8101586848671446\n",
      "Predicci√≥n : [[0.9477087]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[[0.93718117]\n",
      "  [0.93875718]\n",
      "  [0.93990296]\n",
      "  [0.94111621]\n",
      "  [0.94368428]\n",
      "  [0.94511431]\n",
      "  [0.94624585]\n",
      "  [0.94696027]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018920017406344414\n",
      "Predicci√≥n post entrenamiento : [[0.94623965]]\n",
      "PERDIDAAAA despues: 0.018518032506108284\n",
      "loss en el callback: 0.059338439255952835, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "ejemplar: [[0.93875718]\n",
      " [0.93990296]\n",
      " [0.94111621]\n",
      " [0.94368428]\n",
      " [0.94511431]\n",
      " [0.94624585]\n",
      " [0.94696027]\n",
      " [0.94770873]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7668473230866574\n",
      "Predicci√≥n : [[0.9475489]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[[0.93875718]\n",
      "  [0.93990296]\n",
      "  [0.94111621]\n",
      "  [0.94368428]\n",
      "  [0.94511431]\n",
      "  [0.94624585]\n",
      "  [0.94696027]\n",
      "  [0.94770873]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0326530747115612\n",
      "Predicci√≥n post entrenamiento : [[0.94631046]]\n",
      "PERDIDAAAA despues: 0.03220702335238457\n",
      "loss en el callback: 0.04951915144920349, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "ejemplar: [[0.93990296]\n",
      " [0.94111621]\n",
      " [0.94368428]\n",
      " [0.94511431]\n",
      " [0.94624585]\n",
      " [0.94696027]\n",
      " [0.94770873]\n",
      " [0.94754893]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6655191150959373\n",
      "Predicci√≥n : [[0.9475655]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[[0.93990296]\n",
      "  [0.94111621]\n",
      "  [0.94368428]\n",
      "  [0.94511431]\n",
      "  [0.94624585]\n",
      "  [0.94696027]\n",
      "  [0.94770873]\n",
      "  [0.94754893]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07955016195774078\n",
      "Predicci√≥n post entrenamiento : [[0.9458283]]\n",
      "PERDIDAAAA despues: 0.07857324928045273\n",
      "loss en el callback: 0.09811917692422867, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "ejemplar: [[0.94111621]\n",
      " [0.94368428]\n",
      " [0.94511431]\n",
      " [0.94624585]\n",
      " [0.94696027]\n",
      " [0.94770873]\n",
      " [0.94754893]\n",
      " [0.9475655 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6360738003224796\n",
      "Predicci√≥n : [[0.9471144]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[[0.94111621]\n",
      "  [0.94368428]\n",
      "  [0.94511431]\n",
      "  [0.94624585]\n",
      "  [0.94696027]\n",
      "  [0.94770873]\n",
      "  [0.94754893]\n",
      "  [0.9475655 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09674624353647232\n",
      "Predicci√≥n post entrenamiento : [[0.9459608]]\n",
      "PERDIDAAAA despues: 0.09602994471788406\n",
      "loss en el callback: 0.05012035742402077, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "ejemplar: [[0.94368428]\n",
      " [0.94511431]\n",
      " [0.94624585]\n",
      " [0.94696027]\n",
      " [0.94770873]\n",
      " [0.94754893]\n",
      " [0.9475655 ]\n",
      " [0.94711441]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6785113787662842\n",
      "Predicci√≥n : [[0.9472165]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[[0.94368428]\n",
      "  [0.94511431]\n",
      "  [0.94624585]\n",
      "  [0.94696027]\n",
      "  [0.94770873]\n",
      "  [0.94754893]\n",
      "  [0.9475655 ]\n",
      "  [0.94711441]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07220244407653809\n",
      "Predicci√≥n post entrenamiento : [[0.94656205]]\n",
      "PERDIDAAAA despues: 0.07185116410255432\n",
      "loss en el callback: 0.019936146214604378, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "ejemplar: [[0.94511431]\n",
      " [0.94624585]\n",
      " [0.94696027]\n",
      " [0.94770873]\n",
      " [0.94754893]\n",
      " [0.9475655 ]\n",
      " [0.94711441]\n",
      " [0.94721651]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6965967339840231\n",
      "Predicci√≥n : [[0.94733864]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[[0.94511431]\n",
      "  [0.94624585]\n",
      "  [0.94696027]\n",
      "  [0.94770873]\n",
      "  [0.94754893]\n",
      "  [0.9475655 ]\n",
      "  [0.94711441]\n",
      "  [0.94721651]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06287150084972382\n",
      "Predicci√≥n post entrenamiento : [[0.94588125]]\n",
      "PERDIDAAAA despues: 0.062142763286828995\n",
      "loss en el callback: 0.0728110522031784, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "ejemplar: [[0.94624585]\n",
      " [0.94696027]\n",
      " [0.94770873]\n",
      " [0.94754893]\n",
      " [0.9475655 ]\n",
      " [0.94711441]\n",
      " [0.94721651]\n",
      " [0.94733864]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6903298659756966\n",
      "Predicci√≥n : [[0.9463998]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[[0.94624585]\n",
      "  [0.94696027]\n",
      "  [0.94770873]\n",
      "  [0.94754893]\n",
      "  [0.9475655 ]\n",
      "  [0.94711441]\n",
      "  [0.94721651]\n",
      "  [0.94733864]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06557182222604752\n",
      "Predicci√≥n post entrenamiento : [[0.94606924]]\n",
      "PERDIDAAAA despues: 0.06540263444185257\n",
      "loss en el callback: 0.006026552990078926, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "ejemplar: [[0.94696027]\n",
      " [0.94770873]\n",
      " [0.94754893]\n",
      " [0.9475655 ]\n",
      " [0.94711441]\n",
      " [0.94721651]\n",
      " [0.94733864]\n",
      " [0.94639981]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6970473058045382\n",
      "Predicci√≥n : [[0.946347]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[[0.94696027]\n",
      "  [0.94770873]\n",
      "  [0.94754893]\n",
      "  [0.9475655 ]\n",
      "  [0.94711441]\n",
      "  [0.94721651]\n",
      "  [0.94733864]\n",
      "  [0.94639981]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.062150344252586365\n",
      "Predicci√≥n post entrenamiento : [[0.94448125]]\n",
      "PERDIDAAAA despues: 0.06122356653213501\n",
      "loss en el callback: 0.105254627764225, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "ejemplar: [[0.94770873]\n",
      " [0.94754893]\n",
      " [0.9475655 ]\n",
      " [0.94711441]\n",
      " [0.94721651]\n",
      " [0.94733864]\n",
      " [0.94639981]\n",
      " [0.946347  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7167490534705484\n",
      "Predicci√≥n : [[0.9445798]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[[0.94770873]\n",
      "  [0.94754893]\n",
      "  [0.9475655 ]\n",
      "  [0.94711441]\n",
      "  [0.94721651]\n",
      "  [0.94733864]\n",
      "  [0.94639981]\n",
      "  [0.946347  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.051906831562519073\n",
      "Predicci√≥n post entrenamiento : [[0.9438055]]\n",
      "PERDIDAAAA despues: 0.05155462771654129\n",
      "loss en el callback: 0.022983500733971596, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "ejemplar: [[0.94754893]\n",
      " [0.9475655 ]\n",
      " [0.94711441]\n",
      " [0.94721651]\n",
      " [0.94733864]\n",
      " [0.94639981]\n",
      " [0.946347  ]\n",
      " [0.94457978]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7490507063998944\n",
      "Predicci√≥n : [[0.9436647]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[[0.94754893]\n",
      "  [0.9475655 ]\n",
      "  [0.94711441]\n",
      "  [0.94721651]\n",
      "  [0.94733864]\n",
      "  [0.94639981]\n",
      "  [0.946347  ]\n",
      "  [0.94457978]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.037874627858400345\n",
      "Predicci√≥n post entrenamiento : [[0.943256]]\n",
      "PERDIDAAAA despues: 0.037715714424848557\n",
      "loss en el callback: 0.006982809863984585, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "ejemplar: [[0.9475655 ]\n",
      " [0.94711441]\n",
      " [0.94721651]\n",
      " [0.94733864]\n",
      " [0.94639981]\n",
      " [0.946347  ]\n",
      " [0.94457978]\n",
      " [0.94366473]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7939522645925762\n",
      "Predicci√≥n : [[0.94308233]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[[0.9475655 ]\n",
      "  [0.94711441]\n",
      "  [0.94721651]\n",
      "  [0.94733864]\n",
      "  [0.94639981]\n",
      "  [0.946347  ]\n",
      "  [0.94457978]\n",
      "  [0.94366473]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022239770740270615\n",
      "Predicci√≥n post entrenamiento : [[0.94199324]]\n",
      "PERDIDAAAA despues: 0.02191612310707569\n",
      "loss en el callback: 0.04063316807150841, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "ejemplar: [[0.94711441]\n",
      " [0.94721651]\n",
      " [0.94733864]\n",
      " [0.94639981]\n",
      " [0.946347  ]\n",
      " [0.94457978]\n",
      " [0.94366473]\n",
      " [0.94308233]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8547447263586395\n",
      "Predicci√≥n : [[0.94170827]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[[0.94711441]\n",
      "  [0.94721651]\n",
      "  [0.94733864]\n",
      "  [0.94639981]\n",
      "  [0.946347  ]\n",
      "  [0.94457978]\n",
      "  [0.94366473]\n",
      "  [0.94308233]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007562656421214342\n",
      "Predicci√≥n post entrenamiento : [[0.9418592]]\n",
      "PERDIDAAAA despues: 0.00758892809972167\n",
      "loss en el callback: 0.000912591174710542, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "ejemplar: [[0.94721651]\n",
      " [0.94733864]\n",
      " [0.94639981]\n",
      " [0.946347  ]\n",
      " [0.94457978]\n",
      " [0.94366473]\n",
      " [0.94308233]\n",
      " [0.94170827]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9314280916980849\n",
      "Predicci√≥n : [[0.9415572]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[[0.94721651]\n",
      "  [0.94733864]\n",
      "  [0.94639981]\n",
      "  [0.946347  ]\n",
      "  [0.94457978]\n",
      "  [0.94366473]\n",
      "  [0.94308233]\n",
      "  [0.94170827]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00010259975533699617\n",
      "Predicci√≥n post entrenamiento : [[0.94221914]]\n",
      "PERDIDAAAA despues: 0.00011644704500213265\n",
      "loss en el callback: 0.025674639269709587, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "ejemplar: [[0.94733864]\n",
      " [0.94639981]\n",
      " [0.946347  ]\n",
      " [0.94457978]\n",
      " [0.94366473]\n",
      " [0.94308233]\n",
      " [0.94170827]\n",
      " [0.94155723]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9627243989762315\n",
      "Predicci√≥n : [[0.94171613]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[[0.94733864]\n",
      "  [0.94639981]\n",
      "  [0.946347  ]\n",
      "  [0.94457978]\n",
      "  [0.94366473]\n",
      "  [0.94308233]\n",
      "  [0.94170827]\n",
      "  [0.94155723]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004413466958794743\n",
      "Predicci√≥n post entrenamiento : [[0.94186395]]\n",
      "PERDIDAAAA despues: 0.0004351576790213585\n",
      "loss en el callback: 0.0008696527220308781, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "ejemplar: [[0.94639981]\n",
      " [0.946347  ]\n",
      " [0.94457978]\n",
      " [0.94366473]\n",
      " [0.94308233]\n",
      " [0.94170827]\n",
      " [0.94155723]\n",
      " [0.94171613]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9486336481930799\n",
      "Predicci√≥n : [[0.9411186]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[[0.94639981]\n",
      "  [0.946347  ]\n",
      "  [0.94457978]\n",
      "  [0.94366473]\n",
      "  [0.94308233]\n",
      "  [0.94170827]\n",
      "  [0.94155723]\n",
      "  [0.94171613]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.647632133332081e-05\n",
      "Predicci√≥n post entrenamiento : [[0.9418071]]\n",
      "PERDIDAAAA despues: 4.660218837670982e-05\n",
      "loss en el callback: 0.024088576436042786, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "ejemplar: [[0.946347  ]\n",
      " [0.94457978]\n",
      " [0.94366473]\n",
      " [0.94308233]\n",
      " [0.94170827]\n",
      " [0.94155723]\n",
      " [0.94171613]\n",
      " [0.9411186 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9307145892932484\n",
      "Predicci√≥n : [[0.94109935]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[[0.946347  ]\n",
      "  [0.94457978]\n",
      "  [0.94366473]\n",
      "  [0.94308233]\n",
      "  [0.94170827]\n",
      "  [0.94155723]\n",
      "  [0.94171613]\n",
      "  [0.9411186 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00010784279584186152\n",
      "Predicci√≥n post entrenamiento : [[0.9416947]]\n",
      "PERDIDAAAA despues: 0.00012056192645104602\n",
      "loss en el callback: 0.01874125376343727, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "ejemplar: [[0.94457978]\n",
      " [0.94366473]\n",
      " [0.94308233]\n",
      " [0.94170827]\n",
      " [0.94155723]\n",
      " [0.94171613]\n",
      " [0.9411186 ]\n",
      " [0.94109935]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.908967222276737\n",
      "Predicci√≥n : [[0.9407909]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[[0.94457978]\n",
      "  [0.94366473]\n",
      "  [0.94308233]\n",
      "  [0.94170827]\n",
      "  [0.94155723]\n",
      "  [0.94171613]\n",
      "  [0.9411186 ]\n",
      "  [0.94109935]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010127475252375007\n",
      "Predicci√≥n post entrenamiento : [[0.941121]]\n",
      "PERDIDAAAA despues: 0.0010338658466935158\n",
      "loss en el callback: 0.005357915069907904, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "ejemplar: [[0.94366473]\n",
      " [0.94308233]\n",
      " [0.94170827]\n",
      " [0.94155723]\n",
      " [0.94171613]\n",
      " [0.9411186 ]\n",
      " [0.94109935]\n",
      " [0.94079089]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8816379650841193\n",
      "Predicci√≥n : [[0.94051516]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[[0.94366473]\n",
      "  [0.94308233]\n",
      "  [0.94170827]\n",
      "  [0.94155723]\n",
      "  [0.94171613]\n",
      "  [0.9411186 ]\n",
      "  [0.94109935]\n",
      "  [0.94079089]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003466521156951785\n",
      "Predicci√≥n post entrenamiento : [[0.94079596]]\n",
      "PERDIDAAAA despues: 0.0034996650647372007\n",
      "loss en el callback: 0.004403665196150541, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "ejemplar: [[0.94308233]\n",
      " [0.94170827]\n",
      " [0.94155723]\n",
      " [0.94171613]\n",
      " [0.9411186 ]\n",
      " [0.94109935]\n",
      " [0.94079089]\n",
      " [0.94051516]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8487268177153953\n",
      "Predicci√≥n : [[0.9403048]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[[0.94308233]\n",
      "  [0.94170827]\n",
      "  [0.94155723]\n",
      "  [0.94171613]\n",
      "  [0.9411186 ]\n",
      "  [0.94109935]\n",
      "  [0.94079089]\n",
      "  [0.94051516]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008386530913412571\n",
      "Predicci√≥n post entrenamiento : [[0.9403257]]\n",
      "PERDIDAAAA despues: 0.008390353061258793\n",
      "loss en el callback: 1.979740227397997e-05, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "ejemplar: [[0.94170827]\n",
      " [0.94155723]\n",
      " [0.94171613]\n",
      " [0.9411186 ]\n",
      " [0.94109935]\n",
      " [0.94079089]\n",
      " [0.94051516]\n",
      " [0.94030482]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.875260685634848\n",
      "Predicci√≥n : [[0.93988425]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[[0.94170827]\n",
      "  [0.94155723]\n",
      "  [0.94171613]\n",
      "  [0.9411186 ]\n",
      "  [0.94109935]\n",
      "  [0.94079089]\n",
      "  [0.94051516]\n",
      "  [0.94030482]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004176201298832893\n",
      "Predicci√≥n post entrenamiento : [[0.9389358]]\n",
      "PERDIDAAAA despues: 0.004054518882185221\n",
      "loss en el callback: 0.029710497707128525, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "ejemplar: [[0.94155723]\n",
      " [0.94171613]\n",
      " [0.9411186 ]\n",
      " [0.94109935]\n",
      " [0.94079089]\n",
      " [0.94051516]\n",
      " [0.94030482]\n",
      " [0.93988425]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9612395688424776\n",
      "Predicci√≥n : [[0.93878984]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[[0.94155723]\n",
      "  [0.94171613]\n",
      "  [0.9411186 ]\n",
      "  [0.94109935]\n",
      "  [0.94079089]\n",
      "  [0.94051516]\n",
      "  [0.94030482]\n",
      "  [0.93988425]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005039904499426484\n",
      "Predicci√≥n post entrenamiento : [[0.93943936]]\n",
      "PERDIDAAAA despues: 0.0004752496024593711\n",
      "loss en el callback: 0.021404428407549858, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "ejemplar: [[0.94171613]\n",
      " [0.9411186 ]\n",
      " [0.94109935]\n",
      " [0.94079089]\n",
      " [0.94051516]\n",
      " [0.94030482]\n",
      " [0.93988425]\n",
      " [0.93878984]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9925021123407926\n",
      "Predicci√≥n : [[0.9392709]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[[0.94171613]\n",
      "  [0.9411186 ]\n",
      "  [0.94109935]\n",
      "  [0.94079089]\n",
      "  [0.94051516]\n",
      "  [0.94030482]\n",
      "  [0.93988425]\n",
      "  [0.93878984]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002833558479323983\n",
      "Predicci√≥n post entrenamiento : [[0.94012755]]\n",
      "PERDIDAAAA despues: 0.0027430925983935595\n",
      "loss en el callback: 0.04465099796652794, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "ejemplar: [[0.9411186 ]\n",
      " [0.94109935]\n",
      " [0.94079089]\n",
      " [0.94051516]\n",
      " [0.94030482]\n",
      " [0.93988425]\n",
      " [0.93878984]\n",
      " [0.93927091]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.969048316129792\n",
      "Predicci√≥n : [[0.93983805]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[[0.9411186 ]\n",
      "  [0.94109935]\n",
      "  [0.94079089]\n",
      "  [0.94051516]\n",
      "  [0.94030482]\n",
      "  [0.93988425]\n",
      "  [0.93878984]\n",
      "  [0.93927091]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008532398496754467\n",
      "Predicci√≥n post entrenamiento : [[0.9401463]]\n",
      "PERDIDAAAA despues: 0.0008353252778761089\n",
      "loss en el callback: 0.004443887621164322, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "ejemplar: [[0.94109935]\n",
      " [0.94079089]\n",
      " [0.94051516]\n",
      " [0.94030482]\n",
      " [0.93988425]\n",
      " [0.93878984]\n",
      " [0.93927091]\n",
      " [0.93983805]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9715476120161949\n",
      "Predicci√≥n : [[0.9399412]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[[0.94109935]\n",
      "  [0.94079089]\n",
      "  [0.94051516]\n",
      "  [0.94030482]\n",
      "  [0.93988425]\n",
      "  [0.93878984]\n",
      "  [0.93927091]\n",
      "  [0.93983805]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000998963019810617\n",
      "Predicci√≥n post entrenamiento : [[0.939869]]\n",
      "PERDIDAAAA despues: 0.0010035347659140825\n",
      "loss en el callback: 0.00020363822113722563, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "ejemplar: [[0.94079089]\n",
      " [0.94051516]\n",
      " [0.94030482]\n",
      " [0.93988425]\n",
      " [0.93878984]\n",
      " [0.93927091]\n",
      " [0.93983805]\n",
      " [0.93994123]]\n",
      "ejemplar: (8, 1)\n",
      "y: 1.0\n",
      "Predicci√≥n : [[0.9396005]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[[0.94079089]\n",
      "  [0.94051516]\n",
      "  [0.94030482]\n",
      "  [0.93988425]\n",
      "  [0.93878984]\n",
      "  [0.93927091]\n",
      "  [0.93983805]\n",
      "  [0.93994123]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003648096229881048\n",
      "Predicci√≥n post entrenamiento : [[0.94042015]]\n",
      "PERDIDAAAA despues: 0.003549758344888687\n",
      "loss en el callback: 0.04238948971033096, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "ejemplar: [[0.94051516]\n",
      " [0.94030482]\n",
      " [0.93988425]\n",
      " [0.93878984]\n",
      " [0.93927091]\n",
      " [0.93983805]\n",
      " [0.93994123]\n",
      " [0.93960053]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9800636522775721\n",
      "Predicci√≥n : [[0.9401735]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[[0.94051516]\n",
      "  [0.94030482]\n",
      "  [0.93988425]\n",
      "  [0.93878984]\n",
      "  [0.93927091]\n",
      "  [0.93983805]\n",
      "  [0.93994123]\n",
      "  [0.93960053]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015912256203591824\n",
      "Predicci√≥n post entrenamiento : [[0.94027483]]\n",
      "PERDIDAAAA despues: 0.0015831519849598408\n",
      "loss en el callback: 0.00045929665793664753, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "ejemplar: [[0.94030482]\n",
      " [0.93988425]\n",
      " [0.93878984]\n",
      " [0.93927091]\n",
      " [0.93983805]\n",
      " [0.93994123]\n",
      " [0.93960053]\n",
      " [0.94017351]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.911738568848911\n",
      "Predicci√≥n : [[0.94005895]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[[0.94030482]\n",
      "  [0.93988425]\n",
      "  [0.93878984]\n",
      "  [0.93927091]\n",
      "  [0.93983805]\n",
      "  [0.93994123]\n",
      "  [0.93960053]\n",
      "  [0.94017351]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008020434761419892\n",
      "Predicci√≥n post entrenamiento : [[0.93949884]]\n",
      "PERDIDAAAA despues: 0.0007706324104219675\n",
      "loss en el callback: 0.012276474386453629, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "ejemplar: [[0.93988425]\n",
      " [0.93878984]\n",
      " [0.93927091]\n",
      " [0.93983805]\n",
      " [0.93994123]\n",
      " [0.93960053]\n",
      " [0.94017351]\n",
      " [0.94005895]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8910857934126422\n",
      "Predicci√≥n : [[0.9393143]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[[0.93988425]\n",
      "  [0.93878984]\n",
      "  [0.93927091]\n",
      "  [0.93983805]\n",
      "  [0.93994123]\n",
      "  [0.93960053]\n",
      "  [0.94017351]\n",
      "  [0.94005895]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0023259883746504784\n",
      "Predicci√≥n post entrenamiento : [[0.9395115]]\n",
      "PERDIDAAAA despues: 0.002345046028494835\n",
      "loss en el callback: 0.002118188887834549, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "ejemplar: [[0.93878984]\n",
      " [0.93927091]\n",
      " [0.93983805]\n",
      " [0.93994123]\n",
      " [0.93960053]\n",
      " [0.94017351]\n",
      " [0.94005895]\n",
      " [0.93931431]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9181053259687657\n",
      "Predicci√≥n : [[0.93943304]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[[0.93878984]\n",
      "  [0.93927091]\n",
      "  [0.93983805]\n",
      "  [0.93994123]\n",
      "  [0.93960053]\n",
      "  [0.94017351]\n",
      "  [0.94005895]\n",
      "  [0.93931431]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00045487223542295396\n",
      "Predicci√≥n post entrenamiento : [[0.93967783]]\n",
      "PERDIDAAAA despues: 0.00046537406160496175\n",
      "loss en el callback: 0.0027206619270145893, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "ejemplar: [[0.93927091]\n",
      " [0.93983805]\n",
      " [0.93994123]\n",
      " [0.93960053]\n",
      " [0.94017351]\n",
      " [0.94005895]\n",
      " [0.93931431]\n",
      " [0.93943304]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9450165163483527\n",
      "Predicci√≥n : [[0.9399176]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[[0.93927091]\n",
      "  [0.93983805]\n",
      "  [0.93994123]\n",
      "  [0.93960053]\n",
      "  [0.94017351]\n",
      "  [0.94005895]\n",
      "  [0.93931431]\n",
      "  [0.93943304]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.5998569981311448e-05\n",
      "Predicci√≥n post entrenamiento : [[0.93989986]]\n",
      "PERDIDAAAA despues: 2.6180019631283358e-05\n",
      "loss en el callback: 1.5721385352662764e-05, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "ejemplar: [[0.93983805]\n",
      " [0.93994123]\n",
      " [0.93960053]\n",
      " [0.94017351]\n",
      " [0.94005895]\n",
      " [0.93931431]\n",
      " [0.93943304]\n",
      " [0.93991762]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9718193645514037\n",
      "Predicci√≥n : [[0.9400391]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[[0.93983805]\n",
      "  [0.93994123]\n",
      "  [0.93960053]\n",
      "  [0.94017351]\n",
      "  [0.94005895]\n",
      "  [0.93931431]\n",
      "  [0.93943304]\n",
      "  [0.93991762]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010099838254973292\n",
      "Predicci√≥n post entrenamiento : [[0.9396279]]\n",
      "PERDIDAAAA despues: 0.0010362898465245962\n",
      "loss en el callback: 0.006872071884572506, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "ejemplar: [[0.93994123]\n",
      " [0.93960053]\n",
      " [0.94017351]\n",
      " [0.94005895]\n",
      " [0.93931431]\n",
      " [0.93943304]\n",
      " [0.93991762]\n",
      " [0.9400391 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9829067192737589\n",
      "Predicci√≥n : [[0.93962085]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[[0.93994123]\n",
      "  [0.93960053]\n",
      "  [0.94017351]\n",
      "  [0.94005895]\n",
      "  [0.93931431]\n",
      "  [0.93943304]\n",
      "  [0.93991762]\n",
      "  [0.9400391 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018736645579338074\n",
      "Predicci√≥n post entrenamiento : [[0.940454]]\n",
      "PERDIDAAAA despues: 0.0018022311851382256\n",
      "loss en el callback: 0.040571462363004684, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "ejemplar: [[0.93960053]\n",
      " [0.94017351]\n",
      " [0.94005895]\n",
      " [0.93931431]\n",
      " [0.93943304]\n",
      " [0.93991762]\n",
      " [0.9400391 ]\n",
      " [0.93962085]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9782785805154182\n",
      "Predicci√≥n : [[0.9404125]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[[0.93960053]\n",
      "  [0.94017351]\n",
      "  [0.94005895]\n",
      "  [0.93931431]\n",
      "  [0.93943304]\n",
      "  [0.93991762]\n",
      "  [0.9400391 ]\n",
      "  [0.93962085]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014338381588459015\n",
      "Predicci√≥n post entrenamiento : [[0.9407658]]\n",
      "PERDIDAAAA despues: 0.0014072086196392775\n",
      "loss en el callback: 0.006480538751929998, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "ejemplar: [[0.05029815]\n",
      " [0.00860651]\n",
      " [0.        ]\n",
      " [0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.049424632939554\n",
      "Predicci√≥n : [[0.21521252]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.05029815]\n",
      "  [0.00860651]\n",
      "  [0.        ]\n",
      "  [0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.027485623955726624\n",
      "Predicci√≥n post entrenamiento : [[0.16926016]]\n",
      "PERDIDAAAA despues: 0.014360553584992886\n",
      "loss en el callback: 0.03627406060695648, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "ejemplar: [[0.00860651]\n",
      " [0.        ]\n",
      " [0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.21521252]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.10789185692558968\n",
      "Predicci√≥n : [[0.16424862]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.00860651]\n",
      "  [0.        ]\n",
      "  [0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.21521252]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003176084253937006\n",
      "Predicci√≥n post entrenamiento : [[0.15793957]]\n",
      "PERDIDAAAA despues: 0.002504773437976837\n",
      "loss en el callback: 0.0010978520149365067, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "ejemplar: [[0.        ]\n",
      " [0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.21521252]\n",
      " [0.16424862]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.13719610119365802\n",
      "Predicci√≥n : [[0.16259988]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[[0.        ]\n",
      "  [0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.21521252]\n",
      "  [0.16424862]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006453521782532334\n",
      "Predicci√≥n post entrenamiento : [[0.15813865]]\n",
      "PERDIDAAAA despues: 0.0004385905631352216\n",
      "loss en el callback: 0.0008464787970297039, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "ejemplar: [[0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.21521252]\n",
      " [0.16424862]\n",
      " [0.16259988]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.13733736574375907\n",
      "Predicci√≥n : [[0.16784754]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[[0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.21521252]\n",
      "  [0.16424862]\n",
      "  [0.16259988]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009308705921284854\n",
      "Predicci√≥n post entrenamiento : [[0.16841005]]\n",
      "PERDIDAAAA despues: 0.0009655111934989691\n",
      "loss en el callback: 4.1431179852224886e-05, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "ejemplar: [[0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.21521252]\n",
      " [0.16424862]\n",
      " [0.16259988]\n",
      " [0.16784754]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.13388569841244483\n",
      "Predicci√≥n : [[0.17732634]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[[0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.21521252]\n",
      "  [0.16424862]\n",
      "  [0.16259988]\n",
      "  [0.16784754]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001887089223600924\n",
      "Predicci√≥n post entrenamiento : [[0.17271905]]\n",
      "PERDIDAAAA despues: 0.001508029061369598\n",
      "loss en el callback: 0.0025410873349756002, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "ejemplar: [[0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.21521252]\n",
      " [0.16424862]\n",
      " [0.16259988]\n",
      " [0.16784754]\n",
      " [0.17732634]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.12684109919971556\n",
      "Predicci√≥n : [[0.18418762]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[[0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.21521252]\n",
      "  [0.16424862]\n",
      "  [0.16259988]\n",
      "  [0.16784754]\n",
      "  [0.17732634]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003288623644039035\n",
      "Predicci√≥n post entrenamiento : [[0.1794525]]\n",
      "PERDIDAAAA despues: 0.0027679589111357927\n",
      "loss en el callback: 0.004009508527815342, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "ejemplar: [[0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.21521252]\n",
      " [0.16424862]\n",
      " [0.16259988]\n",
      " [0.16784754]\n",
      " [0.17732634]\n",
      " [0.18418762]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14756061137847282\n",
      "Predicci√≥n : [[0.19733313]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[[0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.21521252]\n",
      "  [0.16424862]\n",
      "  [0.16259988]\n",
      "  [0.16784754]\n",
      "  [0.17732634]\n",
      "  [0.18418762]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0024773033801466227\n",
      "Predicci√≥n post entrenamiento : [[0.1921319]]\n",
      "PERDIDAAAA despues: 0.0019866004586219788\n",
      "loss en el callback: 0.005264213774353266, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "ejemplar: [[0.0202993 ]\n",
      " [0.21521252]\n",
      " [0.16424862]\n",
      " [0.16259988]\n",
      " [0.16784754]\n",
      " [0.17732634]\n",
      " [0.18418762]\n",
      " [0.19733313]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19604423494871648\n",
      "Predicci√≥n : [[0.21644063]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[[0.0202993 ]\n",
      "  [0.21521252]\n",
      "  [0.16424862]\n",
      "  [0.16259988]\n",
      "  [0.16784754]\n",
      "  [0.17732634]\n",
      "  [0.18418762]\n",
      "  [0.19733313]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004160130047239363\n",
      "Predicci√≥n post entrenamiento : [[0.21644688]]\n",
      "PERDIDAAAA despues: 0.00041626772144809365\n",
      "loss en el callback: 1.5025108268673648e-08, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "ejemplar: [[0.21521252]\n",
      " [0.16424862]\n",
      " [0.16259988]\n",
      " [0.16784754]\n",
      " [0.17732634]\n",
      " [0.18418762]\n",
      " [0.19733313]\n",
      " [0.21644063]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.21688968214535215\n",
      "Predicci√≥n : [[0.24706997]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[[0.21521252]\n",
      "  [0.16424862]\n",
      "  [0.16259988]\n",
      "  [0.16784754]\n",
      "  [0.17732634]\n",
      "  [0.18418762]\n",
      "  [0.19733313]\n",
      "  [0.21644063]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009108499507419765\n",
      "Predicci√≥n post entrenamiento : [[0.24629149]]\n",
      "PERDIDAAAA despues: 0.0008644663612358272\n",
      "loss en el callback: 0.00026005529798567295, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "ejemplar: [[0.16424862]\n",
      " [0.16259988]\n",
      " [0.16784754]\n",
      " [0.17732634]\n",
      " [0.18418762]\n",
      " [0.19733313]\n",
      " [0.21644063]\n",
      " [0.24706997]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2100969529683796\n",
      "Predicci√≥n : [[0.2390134]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[[0.16424862]\n",
      "  [0.16259988]\n",
      "  [0.16784754]\n",
      "  [0.17732634]\n",
      "  [0.18418762]\n",
      "  [0.19733313]\n",
      "  [0.21644063]\n",
      "  [0.24706997]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008361609652638435\n",
      "Predicci√≥n post entrenamiento : [[0.23934586]]\n",
      "PERDIDAAAA despues: 0.0008554986561648548\n",
      "loss en el callback: 6.452034722315148e-05, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "ejemplar: [[0.16259988]\n",
      " [0.16784754]\n",
      " [0.17732634]\n",
      " [0.18418762]\n",
      " [0.19733313]\n",
      " [0.21644063]\n",
      " [0.24706997]\n",
      " [0.2390134 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2026778474621132\n",
      "Predicci√≥n : [[0.24354985]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[[0.16259988]\n",
      "  [0.16784754]\n",
      "  [0.17732634]\n",
      "  [0.18418762]\n",
      "  [0.19733313]\n",
      "  [0.21644063]\n",
      "  [0.24706997]\n",
      "  [0.2390134 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016705209854990244\n",
      "Predicci√≥n post entrenamiento : [[0.243464]]\n",
      "PERDIDAAAA despues: 0.0016635097563266754\n",
      "loss en el callback: 5.659287580783712e-06, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "ejemplar: [[0.16784754]\n",
      " [0.17732634]\n",
      " [0.18418762]\n",
      " [0.19733313]\n",
      " [0.21644063]\n",
      " [0.24706997]\n",
      " [0.2390134 ]\n",
      " [0.24354985]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19463236562655295\n",
      "Predicci√≥n : [[0.25013265]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[[0.16784754]\n",
      "  [0.17732634]\n",
      "  [0.18418762]\n",
      "  [0.19733313]\n",
      "  [0.21644063]\n",
      "  [0.24706997]\n",
      "  [0.2390134 ]\n",
      "  [0.24354985]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0030802814289927483\n",
      "Predicci√≥n post entrenamiento : [[0.24941495]]\n",
      "PERDIDAAAA despues: 0.00300113158300519\n",
      "loss en el callback: 0.0003909441002178937, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "ejemplar: [[0.17732634]\n",
      " [0.18418762]\n",
      " [0.19733313]\n",
      " [0.21644063]\n",
      " [0.24706997]\n",
      " [0.2390134 ]\n",
      " [0.24354985]\n",
      " [0.25013265]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19407351685692253\n",
      "Predicci√≥n : [[0.25740722]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[[0.17732634]\n",
      "  [0.18418762]\n",
      "  [0.19733313]\n",
      "  [0.21644063]\n",
      "  [0.24706997]\n",
      "  [0.2390134 ]\n",
      "  [0.24354985]\n",
      "  [0.25013265]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004011158365756273\n",
      "Predicci√≥n post entrenamiento : [[0.2549432]]\n",
      "PERDIDAAAA despues: 0.003705117851495743\n",
      "loss en el callback: 0.0044614695943892, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "ejemplar: [[0.18418762]\n",
      " [0.19733313]\n",
      " [0.21644063]\n",
      " [0.24706997]\n",
      " [0.2390134 ]\n",
      " [0.24354985]\n",
      " [0.25013265]\n",
      " [0.25740722]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.20100130115322212\n",
      "Predicci√≥n : [[0.26340908]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[[0.18418762]\n",
      "  [0.19733313]\n",
      "  [0.21644063]\n",
      "  [0.24706997]\n",
      "  [0.2390134 ]\n",
      "  [0.24354985]\n",
      "  [0.25013265]\n",
      "  [0.25740722]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003894730703905225\n",
      "Predicci√≥n post entrenamiento : [[0.26186034]]\n",
      "PERDIDAAAA despues: 0.0037038226146250963\n",
      "loss en el callback: 0.0021287400741130114, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "ejemplar: [[0.19733313]\n",
      " [0.21644063]\n",
      " [0.24706997]\n",
      " [0.2390134 ]\n",
      " [0.24354985]\n",
      " [0.25013265]\n",
      " [0.25740722]\n",
      " [0.26340908]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19663820581116015\n",
      "Predicci√≥n : [[0.271327]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[[0.19733313]\n",
      "  [0.21644063]\n",
      "  [0.24706997]\n",
      "  [0.2390134 ]\n",
      "  [0.24354985]\n",
      "  [0.25013265]\n",
      "  [0.25740722]\n",
      "  [0.26340908]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0055784136056900024\n",
      "Predicci√≥n post entrenamiento : [[0.26990664]]\n",
      "PERDIDAAAA despues: 0.005368262529373169\n",
      "loss en el callback: 0.002440815092995763, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "ejemplar: [[0.21644063]\n",
      " [0.24706997]\n",
      " [0.2390134 ]\n",
      " [0.24354985]\n",
      " [0.25013265]\n",
      " [0.25740722]\n",
      " [0.26340908]\n",
      " [0.27132699]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1809842308307365\n",
      "Predicci√≥n : [[0.2788866]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[[0.21644063]\n",
      "  [0.24706997]\n",
      "  [0.2390134 ]\n",
      "  [0.24354985]\n",
      "  [0.25013265]\n",
      "  [0.25740722]\n",
      "  [0.26340908]\n",
      "  [0.27132699]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009584872052073479\n",
      "Predicci√≥n post entrenamiento : [[0.27615732]]\n",
      "PERDIDAAAA despues: 0.009057917632162571\n",
      "loss en el callback: 0.007767463568598032, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "ejemplar: [[0.24706997]\n",
      " [0.2390134 ]\n",
      " [0.24354985]\n",
      " [0.25013265]\n",
      " [0.25740722]\n",
      " [0.26340908]\n",
      " [0.27132699]\n",
      " [0.27888659]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1653904097109329\n",
      "Predicci√≥n : [[0.28297287]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[[0.24706997]\n",
      "  [0.2390134 ]\n",
      "  [0.24354985]\n",
      "  [0.25013265]\n",
      "  [0.25740722]\n",
      "  [0.26340908]\n",
      "  [0.27132699]\n",
      "  [0.27888659]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013825633563101292\n",
      "Predicci√≥n post entrenamiento : [[0.2792892]]\n",
      "PERDIDAAAA despues: 0.012972929514944553\n",
      "loss en el callback: 0.016123728826642036, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "ejemplar: [[0.2390134 ]\n",
      " [0.24354985]\n",
      " [0.25013265]\n",
      " [0.25740722]\n",
      " [0.26340908]\n",
      " [0.27132699]\n",
      " [0.27888659]\n",
      " [0.28297287]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14985674245174896\n",
      "Predicci√≥n : [[0.2807599]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[[0.2390134 ]\n",
      "  [0.24354985]\n",
      "  [0.25013265]\n",
      "  [0.25740722]\n",
      "  [0.26340908]\n",
      "  [0.27132699]\n",
      "  [0.27888659]\n",
      "  [0.28297287]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017135635018348694\n",
      "Predicci√≥n post entrenamiento : [[0.2761633]]\n",
      "PERDIDAAAA despues: 0.015953347086906433\n",
      "loss en el callback: 0.02568380907177925, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "ejemplar: [[0.24354985]\n",
      " [0.25013265]\n",
      " [0.25740722]\n",
      " [0.26340908]\n",
      " [0.27132699]\n",
      " [0.27888659]\n",
      " [0.28297287]\n",
      " [0.2807599 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.15043111479831345\n",
      "Predicci√≥n : [[0.28046829]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[[0.24354985]\n",
      "  [0.25013265]\n",
      "  [0.25740722]\n",
      "  [0.26340908]\n",
      "  [0.27132699]\n",
      "  [0.27888659]\n",
      "  [0.28297287]\n",
      "  [0.2807599 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01690966635942459\n",
      "Predicci√≥n post entrenamiento : [[0.27814505]]\n",
      "PERDIDAAAA despues: 0.01631084829568863\n",
      "loss en el callback: 0.010591859929263592, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "ejemplar: [[0.25013265]\n",
      " [0.25740722]\n",
      " [0.26340908]\n",
      " [0.27132699]\n",
      " [0.27888659]\n",
      " [0.28297287]\n",
      " [0.2807599 ]\n",
      " [0.28046829]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.16711352675062616\n",
      "Predicci√≥n : [[0.2827537]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[[0.25013265]\n",
      "  [0.25740722]\n",
      "  [0.26340908]\n",
      "  [0.27132699]\n",
      "  [0.27888659]\n",
      "  [0.28297287]\n",
      "  [0.2807599 ]\n",
      "  [0.28046829]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013372651301324368\n",
      "Predicci√≥n post entrenamiento : [[0.2792017]]\n",
      "PERDIDAAAA despues: 0.012563755735754967\n",
      "loss en el callback: 0.01926306076347828, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "ejemplar: [[0.25740722]\n",
      " [0.26340908]\n",
      " [0.27132699]\n",
      " [0.27888659]\n",
      " [0.28297287]\n",
      " [0.2807599 ]\n",
      " [0.28046829]\n",
      " [0.28275371]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2022703535675908\n",
      "Predicci√≥n : [[0.28355858]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[[0.25740722]\n",
      "  [0.26340908]\n",
      "  [0.27132699]\n",
      "  [0.27888659]\n",
      "  [0.28297287]\n",
      "  [0.2807599 ]\n",
      "  [0.28046829]\n",
      "  [0.28275371]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006607774645090103\n",
      "Predicci√≥n post entrenamiento : [[0.282034]]\n",
      "PERDIDAAAA despues: 0.006362239830195904\n",
      "loss en el callback: 0.00433308957144618, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "ejemplar: [[0.26340908]\n",
      " [0.27132699]\n",
      " [0.27888659]\n",
      " [0.28297287]\n",
      " [0.2807599 ]\n",
      " [0.28046829]\n",
      " [0.28275371]\n",
      " [0.28355858]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.25590159524920725\n",
      "Predicci√≥n : [[0.28580007]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[[0.26340908]\n",
      "  [0.27132699]\n",
      "  [0.27888659]\n",
      "  [0.28297287]\n",
      "  [0.2807599 ]\n",
      "  [0.28046829]\n",
      "  [0.28275371]\n",
      "  [0.28355858]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008939182152971625\n",
      "Predicci√≥n post entrenamiento : [[0.28587916]]\n",
      "PERDIDAAAA despues: 0.0008986541070044041\n",
      "loss en el callback: 1.6324031093972735e-05, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "ejemplar: [[0.27132699]\n",
      " [0.27888659]\n",
      " [0.28297287]\n",
      " [0.2807599 ]\n",
      " [0.28046829]\n",
      " [0.28275371]\n",
      " [0.28355858]\n",
      " [0.28580007]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.292688203599549\n",
      "Predicci√≥n : [[0.28913411]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[[0.27132699]\n",
      "  [0.27888659]\n",
      "  [0.28297287]\n",
      "  [0.2807599 ]\n",
      "  [0.28046829]\n",
      "  [0.28275371]\n",
      "  [0.28355858]\n",
      "  [0.28580007]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.2631456229428295e-05\n",
      "Predicci√≥n post entrenamiento : [[0.28833792]]\n",
      "PERDIDAAAA despues: 1.8924891264759935e-05\n",
      "loss en el callback: 0.0011507294839248061, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "ejemplar: [[0.27888659]\n",
      " [0.28297287]\n",
      " [0.2807599 ]\n",
      " [0.28046829]\n",
      " [0.28275371]\n",
      " [0.28355858]\n",
      " [0.28580007]\n",
      " [0.28913411]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31263017861861575\n",
      "Predicci√≥n : [[0.2904537]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[[0.27888659]\n",
      "  [0.28297287]\n",
      "  [0.2807599 ]\n",
      "  [0.28046829]\n",
      "  [0.28275371]\n",
      "  [0.28355858]\n",
      "  [0.28580007]\n",
      "  [0.28913411]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004917960031889379\n",
      "Predicci√≥n post entrenamiento : [[0.29072684]]\n",
      "PERDIDAAAA despues: 0.0004797561268787831\n",
      "loss en el callback: 0.00016962153313215822, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "ejemplar: [[0.28297287]\n",
      " [0.2807599 ]\n",
      " [0.28046829]\n",
      " [0.28275371]\n",
      " [0.28355858]\n",
      " [0.28580007]\n",
      " [0.28913411]\n",
      " [0.2904537 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3109388849116374\n",
      "Predicci√≥n : [[0.29155996]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[[0.28297287]\n",
      "  [0.2807599 ]\n",
      "  [0.28046829]\n",
      "  [0.28275371]\n",
      "  [0.28355858]\n",
      "  [0.28580007]\n",
      "  [0.28913411]\n",
      "  [0.2904537 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003755429352167994\n",
      "Predicci√≥n post entrenamiento : [[0.29116002]]\n",
      "PERDIDAAAA despues: 0.00039120399742387235\n",
      "loss en el callback: 0.0003626811958383769, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "ejemplar: [[0.2807599 ]\n",
      " [0.28046829]\n",
      " [0.28275371]\n",
      " [0.28355858]\n",
      " [0.28580007]\n",
      " [0.28913411]\n",
      " [0.2904537 ]\n",
      " [0.29155996]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2876143224786136\n",
      "Predicci√≥n : [[0.29133084]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[[0.2807599 ]\n",
      "  [0.28046829]\n",
      "  [0.28275371]\n",
      "  [0.28355858]\n",
      "  [0.28580007]\n",
      "  [0.28913411]\n",
      "  [0.2904537 ]\n",
      "  [0.29155996]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.3812583347316831e-05\n",
      "Predicci√≥n post entrenamiento : [[0.29167256]]\n",
      "PERDIDAAAA despues: 1.6469326510559767e-05\n",
      "loss en el callback: 0.0003546733350958675, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "ejemplar: [[0.28046829]\n",
      " [0.28275371]\n",
      " [0.28355858]\n",
      " [0.28580007]\n",
      " [0.28913411]\n",
      " [0.2904537 ]\n",
      " [0.29155996]\n",
      " [0.29133084]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.280161647237227\n",
      "Predicci√≥n : [[0.29258847]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[[0.28046829]\n",
      "  [0.28275371]\n",
      "  [0.28355858]\n",
      "  [0.28580007]\n",
      "  [0.28913411]\n",
      "  [0.2904537 ]\n",
      "  [0.29155996]\n",
      "  [0.29133084]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00015442594303749502\n",
      "Predicci√≥n post entrenamiento : [[0.29137182]]\n",
      "PERDIDAAAA despues: 0.00012566798250190914\n",
      "loss en el callback: 0.003287140280008316, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "ejemplar: [[0.28275371]\n",
      " [0.28355858]\n",
      " [0.28580007]\n",
      " [0.28913411]\n",
      " [0.2904537 ]\n",
      " [0.29155996]\n",
      " [0.29133084]\n",
      " [0.29258847]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2885808591874776\n",
      "Predicci√≥n : [[0.2927019]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[[0.28275371]\n",
      "  [0.28355858]\n",
      "  [0.28580007]\n",
      "  [0.28913411]\n",
      "  [0.2904537 ]\n",
      "  [0.29155996]\n",
      "  [0.29133084]\n",
      "  [0.29258847]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.698293272056617e-05\n",
      "Predicci√≥n post entrenamiento : [[0.29203296]]\n",
      "PERDIDAAAA despues: 1.1916941730305552e-05\n",
      "loss en el callback: 0.0011866234708577394, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "ejemplar: [[0.28355858]\n",
      " [0.28580007]\n",
      " [0.28913411]\n",
      " [0.2904537 ]\n",
      " [0.29155996]\n",
      " [0.29133084]\n",
      " [0.29258847]\n",
      " [0.2927019 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2824628234730068\n",
      "Predicci√≥n : [[0.29321137]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[[0.28355858]\n",
      "  [0.28580007]\n",
      "  [0.28913411]\n",
      "  [0.2904537 ]\n",
      "  [0.29155996]\n",
      "  [0.29133084]\n",
      "  [0.29258847]\n",
      "  [0.2927019 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00011553101649042219\n",
      "Predicci√≥n post entrenamiento : [[0.2918905]]\n",
      "PERDIDAAAA despues: 8.888090087566525e-05\n",
      "loss en el callback: 0.004142389167100191, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "ejemplar: [[0.28580007]\n",
      " [0.28913411]\n",
      " [0.2904537 ]\n",
      " [0.29155996]\n",
      " [0.29133084]\n",
      " [0.29258847]\n",
      " [0.2927019 ]\n",
      " [0.29321137]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.26180754009381474\n",
      "Predicci√≥n : [[0.29321185]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[[0.28580007]\n",
      "  [0.28913411]\n",
      "  [0.2904537 ]\n",
      "  [0.29155996]\n",
      "  [0.29133084]\n",
      "  [0.29258847]\n",
      "  [0.2927019 ]\n",
      "  [0.29321137]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009862311417236924\n",
      "Predicci√≥n post entrenamiento : [[0.29288822]]\n",
      "PERDIDAAAA despues: 0.0009660094510763884\n",
      "loss en el callback: 0.00041070941369980574, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "ejemplar: [[0.28913411]\n",
      " [0.2904537 ]\n",
      " [0.29155996]\n",
      " [0.29133084]\n",
      " [0.29258847]\n",
      " [0.2927019 ]\n",
      " [0.29321137]\n",
      " [0.29321185]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2801212859371977\n",
      "Predicci√≥n : [[0.2939975]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[[0.28913411]\n",
      "  [0.2904537 ]\n",
      "  [0.29155996]\n",
      "  [0.29133084]\n",
      "  [0.29258847]\n",
      "  [0.2927019 ]\n",
      "  [0.29321137]\n",
      "  [0.29321185]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00019254891958553344\n",
      "Predicci√≥n post entrenamiento : [[0.29449633]]\n",
      "PERDIDAAAA despues: 0.00020664151816163212\n",
      "loss en el callback: 0.0012097787111997604, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "ejemplar: [[0.2904537 ]\n",
      " [0.29155996]\n",
      " [0.29133084]\n",
      " [0.29258847]\n",
      " [0.2927019 ]\n",
      " [0.29321137]\n",
      " [0.29321185]\n",
      " [0.2939975 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3374040610031557\n",
      "Predicci√≥n : [[0.2950679]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[[0.2904537 ]\n",
      "  [0.29155996]\n",
      "  [0.29133084]\n",
      "  [0.29258847]\n",
      "  [0.2927019 ]\n",
      "  [0.29321137]\n",
      "  [0.29321185]\n",
      "  [0.2939975 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017923509003594518\n",
      "Predicci√≥n post entrenamiento : [[0.29637262]]\n",
      "PERDIDAAAA despues: 0.0016835798742249608\n",
      "loss en el callback: 0.00983787514269352, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "ejemplar: [[0.29155996]\n",
      " [0.29133084]\n",
      " [0.29258847]\n",
      " [0.2927019 ]\n",
      " [0.29321137]\n",
      " [0.29321185]\n",
      " [0.2939975 ]\n",
      " [0.29506791]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3482298154676272\n",
      "Predicci√≥n : [[0.2967848]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[[0.29155996]\n",
      "  [0.29133084]\n",
      "  [0.29258847]\n",
      "  [0.2927019 ]\n",
      "  [0.29321137]\n",
      "  [0.29321185]\n",
      "  [0.2939975 ]\n",
      "  [0.29506791]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0026465917471796274\n",
      "Predicci√≥n post entrenamiento : [[0.29812983]]\n",
      "PERDIDAAAA despues: 0.0025100097991526127\n",
      "loss en el callback: 0.009113891050219536, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "ejemplar: [[0.29133084]\n",
      " [0.29258847]\n",
      " [0.2927019 ]\n",
      " [0.29321137]\n",
      " [0.29321185]\n",
      " [0.2939975 ]\n",
      " [0.29506791]\n",
      " [0.29678479]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31259854933061226\n",
      "Predicci√≥n : [[0.29841316]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[[0.29133084]\n",
      "  [0.29258847]\n",
      "  [0.2927019 ]\n",
      "  [0.29321137]\n",
      "  [0.29321185]\n",
      "  [0.2939975 ]\n",
      "  [0.29506791]\n",
      "  [0.29678479]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00020122554269619286\n",
      "Predicci√≥n post entrenamiento : [[0.29792526]]\n",
      "PERDIDAAAA despues: 0.00021530551020987332\n",
      "loss en el callback: 0.0008933231001719832, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "ejemplar: [[0.29258847]\n",
      " [0.2927019 ]\n",
      " [0.29321137]\n",
      " [0.29321185]\n",
      " [0.2939975 ]\n",
      " [0.29506791]\n",
      " [0.29678479]\n",
      " [0.29841316]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.34358710169603873\n",
      "Predicci√≥n : [[0.2983933]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[[0.29258847]\n",
      "  [0.2927019 ]\n",
      "  [0.29321137]\n",
      "  [0.29321185]\n",
      "  [0.2939975 ]\n",
      "  [0.29506791]\n",
      "  [0.29678479]\n",
      "  [0.29841316]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002042478881776333\n",
      "Predicci√≥n post entrenamiento : [[0.29908028]]\n",
      "PERDIDAAAA despues: 0.0019808567594736814\n",
      "loss en el callback: 0.002541592111811042, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "ejemplar: [[0.2927019 ]\n",
      " [0.29321137]\n",
      " [0.29321185]\n",
      " [0.2939975 ]\n",
      " [0.29506791]\n",
      " [0.29678479]\n",
      " [0.29841316]\n",
      " [0.29839331]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.4411954725639069\n",
      "Predicci√≥n : [[0.29942334]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[[0.2927019 ]\n",
      "  [0.29321137]\n",
      "  [0.29321185]\n",
      "  [0.2939975 ]\n",
      "  [0.29506791]\n",
      "  [0.29678479]\n",
      "  [0.29841316]\n",
      "  [0.29839331]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02009933441877365\n",
      "Predicci√≥n post entrenamiento : [[0.3001736]]\n",
      "PERDIDAAAA despues: 0.019887162372469902\n",
      "loss en el callback: 0.001952141523361206, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "ejemplar: [[0.29321137]\n",
      " [0.29321185]\n",
      " [0.2939975 ]\n",
      " [0.29506791]\n",
      " [0.29678479]\n",
      " [0.29841316]\n",
      " [0.29839331]\n",
      " [0.29942334]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5210953230441133\n",
      "Predicci√≥n : [[0.30065683]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[[0.29321137]\n",
      "  [0.29321185]\n",
      "  [0.2939975 ]\n",
      "  [0.29506791]\n",
      "  [0.29678479]\n",
      "  [0.29841316]\n",
      "  [0.29839331]\n",
      "  [0.29942334]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04859313741326332\n",
      "Predicci√≥n post entrenamiento : [[0.30351257]]\n",
      "PERDIDAAAA despues: 0.04734225943684578\n",
      "loss en el callback: 0.03957818076014519, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "ejemplar: [[0.29321185]\n",
      " [0.2939975 ]\n",
      " [0.29506791]\n",
      " [0.29678479]\n",
      " [0.29841316]\n",
      " [0.29839331]\n",
      " [0.29942334]\n",
      " [0.30065683]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5832866531366584\n",
      "Predicci√≥n : [[0.30407602]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[[0.29321185]\n",
      "  [0.2939975 ]\n",
      "  [0.29506791]\n",
      "  [0.29678479]\n",
      "  [0.29841316]\n",
      "  [0.29839331]\n",
      "  [0.29942334]\n",
      "  [0.30065683]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07795857638120651\n",
      "Predicci√≥n post entrenamiento : [[0.30760124]]\n",
      "PERDIDAAAA despues: 0.07600244134664536\n",
      "loss en el callback: 0.057082682847976685, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "ejemplar: [[0.2939975 ]\n",
      " [0.29506791]\n",
      " [0.29678479]\n",
      " [0.29841316]\n",
      " [0.29839331]\n",
      " [0.29942334]\n",
      " [0.30065683]\n",
      " [0.30407602]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6089234523540271\n",
      "Predicci√≥n : [[0.30839843]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[[0.2939975 ]\n",
      "  [0.29506791]\n",
      "  [0.29678479]\n",
      "  [0.29841316]\n",
      "  [0.29839331]\n",
      "  [0.29942334]\n",
      "  [0.30065683]\n",
      "  [0.30407602]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09031528234481812\n",
      "Predicci√≥n post entrenamiento : [[0.3125042]]\n",
      "PERDIDAAAA despues: 0.08786436170339584\n",
      "loss en el callback: 0.10258276015520096, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "ejemplar: [[0.29506791]\n",
      " [0.29678479]\n",
      " [0.29841316]\n",
      " [0.29839331]\n",
      " [0.29942334]\n",
      " [0.30065683]\n",
      " [0.30407602]\n",
      " [0.30839843]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.59800572069622\n",
      "Predicci√≥n : [[0.31341758]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[[0.29506791]\n",
      "  [0.29678479]\n",
      "  [0.29841316]\n",
      "  [0.29839331]\n",
      "  [0.29942334]\n",
      "  [0.30065683]\n",
      "  [0.30407602]\n",
      "  [0.30839843]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08099040389060974\n",
      "Predicci√≥n post entrenamiento : [[0.31705722]]\n",
      "PERDIDAAAA despues: 0.07893205434083939\n",
      "loss en el callback: 0.07807173579931259, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "ejemplar: [[0.29678479]\n",
      " [0.29841316]\n",
      " [0.29839331]\n",
      " [0.29942334]\n",
      " [0.30065683]\n",
      " [0.30407602]\n",
      " [0.30839843]\n",
      " [0.31341758]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5945301858653699\n",
      "Predicci√≥n : [[0.31808823]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[[0.29678479]\n",
      "  [0.29841316]\n",
      "  [0.29839331]\n",
      "  [0.29942334]\n",
      "  [0.30065683]\n",
      "  [0.30407602]\n",
      "  [0.30839843]\n",
      "  [0.31341758]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0764201432466507\n",
      "Predicci√≥n post entrenamiento : [[0.32136554]]\n",
      "PERDIDAAAA despues: 0.07461891323328018\n",
      "loss en el callback: 0.07225015014410019, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "ejemplar: [[0.29841316]\n",
      " [0.29839331]\n",
      " [0.29942334]\n",
      " [0.30065683]\n",
      " [0.30407602]\n",
      " [0.30839843]\n",
      " [0.31341758]\n",
      " [0.31808823]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5984968478614763\n",
      "Predicci√≥n : [[0.3224457]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[[0.29841316]\n",
      "  [0.29839331]\n",
      "  [0.29942334]\n",
      "  [0.30065683]\n",
      "  [0.30407602]\n",
      "  [0.30839843]\n",
      "  [0.31341758]\n",
      "  [0.31808823]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07620424777269363\n",
      "Predicci√≥n post entrenamiento : [[0.32581025]]\n",
      "PERDIDAAAA despues: 0.07435797899961472\n",
      "loss en el callback: 0.10824370384216309, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "ejemplar: [[0.29839331]\n",
      " [0.29942334]\n",
      " [0.30065683]\n",
      " [0.30407602]\n",
      " [0.30839843]\n",
      " [0.31341758]\n",
      " [0.31808823]\n",
      " [0.32244569]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6213543446734934\n",
      "Predicci√≥n : [[0.3270476]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[[0.29839331]\n",
      "  [0.29942334]\n",
      "  [0.30065683]\n",
      "  [0.30407602]\n",
      "  [0.30839843]\n",
      "  [0.31341758]\n",
      "  [0.31808823]\n",
      "  [0.32244569]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08661646395921707\n",
      "Predicci√≥n post entrenamiento : [[0.33062536]]\n",
      "PERDIDAAAA despues: 0.08452334254980087\n",
      "loss en el callback: 0.08441676944494247, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "ejemplar: [[0.29942334]\n",
      " [0.30065683]\n",
      " [0.30407602]\n",
      " [0.30839843]\n",
      " [0.31341758]\n",
      " [0.31808823]\n",
      " [0.32244569]\n",
      " [0.32704759]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.663102676301421\n",
      "Predicci√≥n : [[0.33252302]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[[0.29942334]\n",
      "  [0.30065683]\n",
      "  [0.30407602]\n",
      "  [0.30839843]\n",
      "  [0.31341758]\n",
      "  [0.31808823]\n",
      "  [0.32244569]\n",
      "  [0.32704759]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10928291827440262\n",
      "Predicci√≥n post entrenamiento : [[0.3361708]]\n",
      "PERDIDAAAA despues: 0.10688446462154388\n",
      "loss en el callback: 0.08335967361927032, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "ejemplar: [[0.30065683]\n",
      " [0.30407602]\n",
      " [0.30839843]\n",
      " [0.31341758]\n",
      " [0.31808823]\n",
      " [0.32244569]\n",
      " [0.32704759]\n",
      " [0.33252302]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6928724338328028\n",
      "Predicci√≥n : [[0.33865187]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[[0.30065683]\n",
      "  [0.30407602]\n",
      "  [0.30839843]\n",
      "  [0.31341758]\n",
      "  [0.31808823]\n",
      "  [0.32244569]\n",
      "  [0.32704759]\n",
      "  [0.33252302]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12547218799591064\n",
      "Predicci√≥n post entrenamiento : [[0.34260628]]\n",
      "PERDIDAAAA despues: 0.12268636375665665\n",
      "loss en el callback: 0.14974862337112427, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "ejemplar: [[0.30407602]\n",
      " [0.30839843]\n",
      " [0.31341758]\n",
      " [0.31808823]\n",
      " [0.32244569]\n",
      " [0.32704759]\n",
      " [0.33252302]\n",
      " [0.33865187]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.710663617267639\n",
      "Predicci√≥n : [[0.34577188]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[[0.30407602]\n",
      "  [0.30839843]\n",
      "  [0.31341758]\n",
      "  [0.31808823]\n",
      "  [0.32244569]\n",
      "  [0.32704759]\n",
      "  [0.33252302]\n",
      "  [0.33865187]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13314597308635712\n",
      "Predicci√≥n post entrenamiento : [[0.34968936]]\n",
      "PERDIDAAAA despues: 0.13030241429805756\n",
      "loss en el callback: 0.10009630024433136, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "ejemplar: [[0.30839843]\n",
      " [0.31341758]\n",
      " [0.31808823]\n",
      " [0.32244569]\n",
      " [0.32704759]\n",
      " [0.33252302]\n",
      " [0.33865187]\n",
      " [0.34577188]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7216820581308059\n",
      "Predicci√≥n : [[0.35316446]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[[0.30839843]\n",
      "  [0.31341758]\n",
      "  [0.31808823]\n",
      "  [0.32244569]\n",
      "  [0.32704759]\n",
      "  [0.33252302]\n",
      "  [0.33865187]\n",
      "  [0.34577188]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13580523431301117\n",
      "Predicci√≥n post entrenamiento : [[0.3572439]]\n",
      "PERDIDAAAA despues: 0.1328151822090149\n",
      "loss en el callback: 0.1259128451347351, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "ejemplar: [[0.31341758]\n",
      " [0.31808823]\n",
      " [0.32244569]\n",
      " [0.32704759]\n",
      " [0.33252302]\n",
      " [0.33865187]\n",
      " [0.34577188]\n",
      " [0.35316446]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7259277564223031\n",
      "Predicci√≥n : [[0.3609031]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[[0.31341758]\n",
      "  [0.31808823]\n",
      "  [0.32244569]\n",
      "  [0.32704759]\n",
      "  [0.33252302]\n",
      "  [0.33865187]\n",
      "  [0.34577188]\n",
      "  [0.35316446]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13324299454689026\n",
      "Predicci√≥n post entrenamiento : [[0.36490035]]\n",
      "PERDIDAAAA despues: 0.1303407996892929\n",
      "loss en el callback: 0.1389288604259491, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "ejemplar: [[0.31808823]\n",
      " [0.32244569]\n",
      " [0.32704759]\n",
      " [0.33252302]\n",
      " [0.33865187]\n",
      " [0.34577188]\n",
      " [0.35316446]\n",
      " [0.36090311]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7404318224413275\n",
      "Predicci√≥n : [[0.36865574]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[[0.31808823]\n",
      "  [0.32244569]\n",
      "  [0.32704759]\n",
      "  [0.33252302]\n",
      "  [0.33865187]\n",
      "  [0.34577188]\n",
      "  [0.35316446]\n",
      "  [0.36090311]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13821746408939362\n",
      "Predicci√≥n post entrenamiento : [[0.37265447]]\n",
      "PERDIDAAAA despues: 0.1352601945400238\n",
      "loss en el callback: 0.17880745232105255, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "ejemplar: [[0.32244569]\n",
      " [0.32704759]\n",
      " [0.33252302]\n",
      " [0.33865187]\n",
      " [0.34577188]\n",
      " [0.35316446]\n",
      " [0.36090311]\n",
      " [0.36865574]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7651942561878792\n",
      "Predicci√≥n : [[0.3766697]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[[0.32244569]\n",
      "  [0.32704759]\n",
      "  [0.33252302]\n",
      "  [0.33865187]\n",
      "  [0.34577188]\n",
      "  [0.35316446]\n",
      "  [0.36090311]\n",
      "  [0.36865574]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1509513109922409\n",
      "Predicci√≥n post entrenamiento : [[0.38064685]]\n",
      "PERDIDAAAA despues: 0.14787669479846954\n",
      "loss en el callback: 0.13154366612434387, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "ejemplar: [[0.32704759]\n",
      " [0.33252302]\n",
      " [0.33865187]\n",
      " [0.34577188]\n",
      " [0.35316446]\n",
      " [0.36090311]\n",
      " [0.36865574]\n",
      " [0.3766697 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7447890964420396\n",
      "Predicci√≥n : [[0.38510698]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[[0.32704759]\n",
      "  [0.33252302]\n",
      "  [0.33865187]\n",
      "  [0.34577188]\n",
      "  [0.35316446]\n",
      "  [0.36090311]\n",
      "  [0.36865574]\n",
      "  [0.3766697 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12937124073505402\n",
      "Predicci√≥n post entrenamiento : [[0.38848236]]\n",
      "PERDIDAAAA despues: 0.12695451080799103\n",
      "loss en el callback: 0.08497659862041473, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "ejemplar: [[0.33252302]\n",
      " [0.33865187]\n",
      " [0.34577188]\n",
      " [0.35316446]\n",
      " [0.36090311]\n",
      " [0.36865574]\n",
      " [0.3766697 ]\n",
      " [0.38510698]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6792163432038085\n",
      "Predicci√≥n : [[0.3934585]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[[0.33252302]\n",
      "  [0.33865187]\n",
      "  [0.34577188]\n",
      "  [0.35316446]\n",
      "  [0.36090311]\n",
      "  [0.36865574]\n",
      "  [0.3766697 ]\n",
      "  [0.38510698]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0816575437784195\n",
      "Predicci√≥n post entrenamiento : [[0.39659333]]\n",
      "PERDIDAAAA despues: 0.07987575978040695\n",
      "loss en el callback: 0.12261153012514114, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "ejemplar: [[0.33865187]\n",
      " [0.34577188]\n",
      " [0.35316446]\n",
      " [0.36090311]\n",
      " [0.36865574]\n",
      " [0.3766697 ]\n",
      " [0.38510698]\n",
      " [0.39345849]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6746017659154131\n",
      "Predicci√≥n : [[0.4019984]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[[0.33865187]\n",
      "  [0.34577188]\n",
      "  [0.35316446]\n",
      "  [0.36090311]\n",
      "  [0.36865574]\n",
      "  [0.3766697 ]\n",
      "  [0.38510698]\n",
      "  [0.39345849]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07431261241436005\n",
      "Predicci√≥n post entrenamiento : [[0.40428662]]\n",
      "PERDIDAAAA despues: 0.07307028770446777\n",
      "loss en el callback: 0.03820834681391716, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "ejemplar: [[0.34577188]\n",
      " [0.35316446]\n",
      " [0.36090311]\n",
      " [0.36865574]\n",
      " [0.3766697 ]\n",
      " [0.38510698]\n",
      " [0.39345849]\n",
      " [0.4019984 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7309453645768532\n",
      "Predicci√≥n : [[0.41006073]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[[0.34577188]\n",
      "  [0.35316446]\n",
      "  [0.36090311]\n",
      "  [0.36865574]\n",
      "  [0.3766697 ]\n",
      "  [0.38510698]\n",
      "  [0.39345849]\n",
      "  [0.4019984 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10296693444252014\n",
      "Predicci√≥n post entrenamiento : [[0.4133765]]\n",
      "PERDIDAAAA despues: 0.10084996372461319\n",
      "loss en el callback: 0.2118915617465973, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "ejemplar: [[0.35316446]\n",
      " [0.36090311]\n",
      " [0.36865574]\n",
      " [0.3766697 ]\n",
      " [0.38510698]\n",
      " [0.39345849]\n",
      " [0.4019984 ]\n",
      " [0.41006073]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7467210055914982\n",
      "Predicci√≥n : [[0.419355]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[[0.35316446]\n",
      "  [0.36090311]\n",
      "  [0.36865574]\n",
      "  [0.3766697 ]\n",
      "  [0.38510698]\n",
      "  [0.39345849]\n",
      "  [0.4019984 ]\n",
      "  [0.41006073]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10716851055622101\n",
      "Predicci√≥n post entrenamiento : [[0.4223047]]\n",
      "PERDIDAAAA despues: 0.10524596273899078\n",
      "loss en el callback: 0.07652051746845245, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "ejemplar: [[0.36090311]\n",
      " [0.36865574]\n",
      " [0.3766697 ]\n",
      " [0.38510698]\n",
      " [0.39345849]\n",
      " [0.4019984 ]\n",
      " [0.41006073]\n",
      " [0.41935501]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7219286889593481\n",
      "Predicci√≥n : [[0.42847034]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[[0.36090311]\n",
      "  [0.36865574]\n",
      "  [0.3766697 ]\n",
      "  [0.38510698]\n",
      "  [0.39345849]\n",
      "  [0.4019984 ]\n",
      "  [0.41006073]\n",
      "  [0.41935501]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08611781895160675\n",
      "Predicci√≥n post entrenamiento : [[0.43122795]]\n",
      "PERDIDAAAA despues: 0.08450693637132645\n",
      "loss en el callback: 0.09206579625606537, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "ejemplar: [[0.36865574]\n",
      " [0.3766697 ]\n",
      " [0.38510698]\n",
      " [0.39345849]\n",
      " [0.4019984 ]\n",
      " [0.41006073]\n",
      " [0.41935501]\n",
      " [0.42847034]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7199286701160912\n",
      "Predicci√≥n : [[0.43754107]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[[0.36865574]\n",
      "  [0.3766697 ]\n",
      "  [0.38510698]\n",
      "  [0.39345849]\n",
      "  [0.4019984 ]\n",
      "  [0.41006073]\n",
      "  [0.41935501]\n",
      "  [0.42847034]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07974276691675186\n",
      "Predicci√≥n post entrenamiento : [[0.44055605]]\n",
      "PERDIDAAAA despues: 0.07804907113313675\n",
      "loss en el callback: 0.1258251965045929, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "ejemplar: [[0.3766697 ]\n",
      " [0.38510698]\n",
      " [0.39345849]\n",
      " [0.4019984 ]\n",
      " [0.41006073]\n",
      " [0.41935501]\n",
      " [0.42847034]\n",
      " [0.43754107]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7407209490617273\n",
      "Predicci√≥n : [[0.44705486]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[[0.3766697 ]\n",
      "  [0.38510698]\n",
      "  [0.39345849]\n",
      "  [0.4019984 ]\n",
      "  [0.41006073]\n",
      "  [0.41935501]\n",
      "  [0.42847034]\n",
      "  [0.43754107]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.086239755153656\n",
      "Predicci√≥n post entrenamiento : [[0.44989505]]\n",
      "PERDIDAAAA despues: 0.08457969129085541\n",
      "loss en el callback: 0.10392627120018005, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "ejemplar: [[0.38510698]\n",
      " [0.39345849]\n",
      " [0.4019984 ]\n",
      " [0.41006073]\n",
      " [0.41935501]\n",
      " [0.42847034]\n",
      " [0.43754107]\n",
      " [0.44705486]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.736245501831604\n",
      "Predicci√≥n : [[0.45656124]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[[0.38510698]\n",
      "  [0.39345849]\n",
      "  [0.4019984 ]\n",
      "  [0.41006073]\n",
      "  [0.41935501]\n",
      "  [0.42847034]\n",
      "  [0.43754107]\n",
      "  [0.44705486]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07822329550981522\n",
      "Predicci√≥n post entrenamiento : [[0.45852557]]\n",
      "PERDIDAAAA despues: 0.07712836563587189\n",
      "loss en el callback: 0.03142101690173149, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "ejemplar: [[0.39345849]\n",
      " [0.4019984 ]\n",
      " [0.41006073]\n",
      " [0.41935501]\n",
      " [0.42847034]\n",
      " [0.43754107]\n",
      " [0.44705486]\n",
      " [0.45656124]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7065023284257214\n",
      "Predicci√≥n : [[0.4652934]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[[0.39345849]\n",
      "  [0.4019984 ]\n",
      "  [0.41006073]\n",
      "  [0.41935501]\n",
      "  [0.42847034]\n",
      "  [0.43754107]\n",
      "  [0.44705486]\n",
      "  [0.45656124]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05818174034357071\n",
      "Predicci√≥n post entrenamiento : [[0.46659672]]\n",
      "PERDIDAAAA despues: 0.0575546957552433\n",
      "loss en el callback: 0.012602545320987701, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "ejemplar: [[0.4019984 ]\n",
      " [0.41006073]\n",
      " [0.41935501]\n",
      " [0.42847034]\n",
      " [0.43754107]\n",
      " [0.44705486]\n",
      " [0.45656124]\n",
      " [0.46529341]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6979451506854685\n",
      "Predicci√≥n : [[0.4735171]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[[0.4019984 ]\n",
      "  [0.41006073]\n",
      "  [0.41935501]\n",
      "  [0.42847034]\n",
      "  [0.43754107]\n",
      "  [0.44705486]\n",
      "  [0.45656124]\n",
      "  [0.46529341]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.050367966294288635\n",
      "Predicci√≥n post entrenamiento : [[0.47568658]]\n",
      "PERDIDAAAA despues: 0.04939888417720795\n",
      "loss en el callback: 0.052675433456897736, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "ejemplar: [[0.41006073]\n",
      " [0.41935501]\n",
      " [0.42847034]\n",
      " [0.43754107]\n",
      " [0.44705486]\n",
      " [0.45656124]\n",
      " [0.46529341]\n",
      " [0.47351709]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7105739686108449\n",
      "Predicci√≥n : [[0.48274276]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[[0.41006073]\n",
      "  [0.41935501]\n",
      "  [0.42847034]\n",
      "  [0.43754107]\n",
      "  [0.44705486]\n",
      "  [0.45656124]\n",
      "  [0.46529341]\n",
      "  [0.47351709]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05190706253051758\n",
      "Predicci√≥n post entrenamiento : [[0.48499185]]\n",
      "PERDIDAAAA despues: 0.05088729411363602\n",
      "loss en el callback: 0.07700393348932266, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "ejemplar: [[0.41935501]\n",
      " [0.42847034]\n",
      " [0.43754107]\n",
      " [0.44705486]\n",
      " [0.45656124]\n",
      " [0.46529341]\n",
      " [0.47351709]\n",
      " [0.48274276]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7209621522504839\n",
      "Predicci√≥n : [[0.49232796]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[[0.41935501]\n",
      "  [0.42847034]\n",
      "  [0.43754107]\n",
      "  [0.44705486]\n",
      "  [0.45656124]\n",
      "  [0.46529341]\n",
      "  [0.47351709]\n",
      "  [0.48274276]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05227360129356384\n",
      "Predicci√≥n post entrenamiento : [[0.49385893]]\n",
      "PERDIDAAAA despues: 0.05157587677240372\n",
      "loss en el callback: 0.02214728109538555, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "ejemplar: [[0.42847034]\n",
      " [0.43754107]\n",
      " [0.44705486]\n",
      " [0.45656124]\n",
      " [0.46529341]\n",
      " [0.47351709]\n",
      " [0.48274276]\n",
      " [0.49232796]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7291097016043858\n",
      "Predicci√≥n : [[0.50118846]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[[0.42847034]\n",
      "  [0.43754107]\n",
      "  [0.44705486]\n",
      "  [0.45656124]\n",
      "  [0.46529341]\n",
      "  [0.47351709]\n",
      "  [0.48274276]\n",
      "  [0.49232796]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.051948096603155136\n",
      "Predicci√≥n post entrenamiento : [[0.50339323]]\n",
      "PERDIDAAAA despues: 0.05094792693853378\n",
      "loss en el callback: 0.06603770703077316, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "ejemplar: [[0.43754107]\n",
      " [0.44705486]\n",
      " [0.45656124]\n",
      " [0.46529341]\n",
      " [0.47351709]\n",
      " [0.48274276]\n",
      " [0.49232796]\n",
      " [0.50118846]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7674259644168786\n",
      "Predicci√≥n : [[0.51075345]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[[0.43754107]\n",
      "  [0.44705486]\n",
      "  [0.45656124]\n",
      "  [0.46529341]\n",
      "  [0.47351709]\n",
      "  [0.48274276]\n",
      "  [0.49232796]\n",
      "  [0.50118846]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06588077545166016\n",
      "Predicci√≥n post entrenamiento : [[0.51243865]]\n",
      "PERDIDAAAA despues: 0.06501851975917816\n",
      "loss en el callback: 0.02890709973871708, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "ejemplar: [[0.44705486]\n",
      " [0.45656124]\n",
      " [0.46529341]\n",
      " [0.47351709]\n",
      " [0.48274276]\n",
      " [0.49232796]\n",
      " [0.50118846]\n",
      " [0.51075345]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8359109406879621\n",
      "Predicci√≥n : [[0.51983833]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[[0.44705486]\n",
      "  [0.45656124]\n",
      "  [0.46529341]\n",
      "  [0.47351709]\n",
      "  [0.48274276]\n",
      "  [0.49232796]\n",
      "  [0.50118846]\n",
      "  [0.51075345]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09990187734365463\n",
      "Predicci√≥n post entrenamiento : [[0.5222037]]\n",
      "PERDIDAAAA despues: 0.09841223061084747\n",
      "loss en el callback: 0.06002330780029297, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "ejemplar: [[0.45656124]\n",
      " [0.46529341]\n",
      " [0.47351709]\n",
      " [0.48274276]\n",
      " [0.49232796]\n",
      " [0.50118846]\n",
      " [0.51075345]\n",
      " [0.51983833]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8510103358824123\n",
      "Predicci√≥n : [[0.52952933]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[[0.45656124]\n",
      "  [0.46529341]\n",
      "  [0.47351709]\n",
      "  [0.48274276]\n",
      "  [0.49232796]\n",
      "  [0.50118846]\n",
      "  [0.51075345]\n",
      "  [0.51983833]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10335002839565277\n",
      "Predicci√≥n post entrenamiento : [[0.53231543]]\n",
      "PERDIDAAAA despues: 0.10156643390655518\n",
      "loss en el callback: 0.09599718451499939, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "ejemplar: [[0.46529341]\n",
      " [0.47351709]\n",
      " [0.48274276]\n",
      " [0.49232796]\n",
      " [0.50118846]\n",
      " [0.51075345]\n",
      " [0.51983833]\n",
      " [0.52952933]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8127241500002294\n",
      "Predicci√≥n : [[0.5395606]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[[0.46529341]\n",
      "  [0.47351709]\n",
      "  [0.48274276]\n",
      "  [0.49232796]\n",
      "  [0.50118846]\n",
      "  [0.51075345]\n",
      "  [0.51983833]\n",
      "  [0.52952933]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07461833208799362\n",
      "Predicci√≥n post entrenamiento : [[0.5420171]]\n",
      "PERDIDAAAA despues: 0.07328231632709503\n",
      "loss en el callback: 0.08033724874258041, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "ejemplar: [[0.47351709]\n",
      " [0.48274276]\n",
      " [0.49232796]\n",
      " [0.50118846]\n",
      " [0.51075345]\n",
      " [0.51983833]\n",
      " [0.52952933]\n",
      " [0.53956062]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7863940290280375\n",
      "Predicci√≥n : [[0.5493869]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[[0.47351709]\n",
      "  [0.48274276]\n",
      "  [0.49232796]\n",
      "  [0.50118846]\n",
      "  [0.51075345]\n",
      "  [0.51983833]\n",
      "  [0.52952933]\n",
      "  [0.53956062]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05617235600948334\n",
      "Predicci√≥n post entrenamiento : [[0.55123204]]\n",
      "PERDIDAAAA despues: 0.05530114844441414\n",
      "loss en el callback: 0.0415157675743103, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "ejemplar: [[0.48274276]\n",
      " [0.49232796]\n",
      " [0.50118846]\n",
      " [0.51075345]\n",
      " [0.51983833]\n",
      " [0.52952933]\n",
      " [0.53956062]\n",
      " [0.54938692]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7720199729658365\n",
      "Predicci√≥n : [[0.5588968]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[[0.48274276]\n",
      "  [0.49232796]\n",
      "  [0.50118846]\n",
      "  [0.51075345]\n",
      "  [0.51983833]\n",
      "  [0.52952933]\n",
      "  [0.53956062]\n",
      "  [0.54938692]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.045421499758958817\n",
      "Predicci√≥n post entrenamiento : [[0.56042945]]\n",
      "PERDIDAAAA despues: 0.04477054998278618\n",
      "loss en el callback: 0.026440750807523727, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "ejemplar: [[0.49232796]\n",
      " [0.50118846]\n",
      " [0.51075345]\n",
      " [0.51983833]\n",
      " [0.52952933]\n",
      " [0.53956062]\n",
      " [0.54938692]\n",
      " [0.55889678]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8033170564228299\n",
      "Predicci√≥n : [[0.56817496]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[[0.49232796]\n",
      "  [0.50118846]\n",
      "  [0.51075345]\n",
      "  [0.51983833]\n",
      "  [0.52952933]\n",
      "  [0.53956062]\n",
      "  [0.54938692]\n",
      "  [0.55889678]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05529181286692619\n",
      "Predicci√≥n post entrenamiento : [[0.5705074]]\n",
      "PERDIDAAAA despues: 0.05420034006237984\n",
      "loss en el callback: 0.09865318983793259, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "ejemplar: [[0.50118846]\n",
      " [0.51075345]\n",
      " [0.51983833]\n",
      " [0.52952933]\n",
      " [0.53956062]\n",
      " [0.54938692]\n",
      " [0.55889678]\n",
      " [0.56817496]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8802852793990171\n",
      "Predicci√≥n : [[0.5782561]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[[0.50118846]\n",
      "  [0.51075345]\n",
      "  [0.51983833]\n",
      "  [0.52952933]\n",
      "  [0.53956062]\n",
      "  [0.54938692]\n",
      "  [0.55889678]\n",
      "  [0.56817496]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0912216305732727\n",
      "Predicci√≥n post entrenamiento : [[0.58064586]]\n",
      "PERDIDAAAA despues: 0.08978377282619476\n",
      "loss en el callback: 0.07656794786453247, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "ejemplar: [[0.51075345]\n",
      " [0.51983833]\n",
      " [0.52952933]\n",
      " [0.53956062]\n",
      " [0.54938692]\n",
      " [0.55889678]\n",
      " [0.56817496]\n",
      " [0.57825607]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8987051676996881\n",
      "Predicci√≥n : [[0.5885995]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[[0.51075345]\n",
      "  [0.51983833]\n",
      "  [0.52952933]\n",
      "  [0.53956062]\n",
      "  [0.54938692]\n",
      "  [0.55889678]\n",
      "  [0.56817496]\n",
      "  [0.57825607]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09616553038358688\n",
      "Predicci√≥n post entrenamiento : [[0.59154123]]\n",
      "PERDIDAAAA despues: 0.0943496972322464\n",
      "loss en el callback: 0.15256181359291077, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "ejemplar: [[0.51983833]\n",
      " [0.52952933]\n",
      " [0.53956062]\n",
      " [0.54938692]\n",
      " [0.55889678]\n",
      " [0.56817496]\n",
      " [0.57825607]\n",
      " [0.5885995 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8585767213248423\n",
      "Predicci√≥n : [[0.59954756]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[[0.51983833]\n",
      "  [0.52952933]\n",
      "  [0.53956062]\n",
      "  [0.54938692]\n",
      "  [0.55889678]\n",
      "  [0.56817496]\n",
      "  [0.57825607]\n",
      "  [0.5885995 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06709609925746918\n",
      "Predicci√≥n post entrenamiento : [[0.60104686]]\n",
      "PERDIDAAAA despues: 0.06632162630558014\n",
      "loss en el callback: 0.025377999991178513, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "ejemplar: [[0.52952933]\n",
      " [0.53956062]\n",
      " [0.54938692]\n",
      " [0.55889678]\n",
      " [0.56817496]\n",
      " [0.57825607]\n",
      " [0.5885995 ]\n",
      " [0.59954756]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8308762565987861\n",
      "Predicci√≥n : [[0.60925174]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[[0.52952933]\n",
      "  [0.53956062]\n",
      "  [0.54938692]\n",
      "  [0.55889678]\n",
      "  [0.56817496]\n",
      "  [0.57825607]\n",
      "  [0.5885995 ]\n",
      "  [0.59954756]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04911741614341736\n",
      "Predicci√≥n post entrenamiento : [[0.6111313]]\n",
      "PERDIDAAAA despues: 0.048287831246852875\n",
      "loss en el callback: 0.054816897958517075, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "ejemplar: [[0.53956062]\n",
      " [0.54938692]\n",
      " [0.55889678]\n",
      " [0.56817496]\n",
      " [0.57825607]\n",
      " [0.5885995 ]\n",
      " [0.59954756]\n",
      " [0.60925174]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8156037735215196\n",
      "Predicci√≥n : [[0.6194093]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[[0.53956062]\n",
      "  [0.54938692]\n",
      "  [0.55889678]\n",
      "  [0.56817496]\n",
      "  [0.57825607]\n",
      "  [0.5885995 ]\n",
      "  [0.59954756]\n",
      "  [0.60925174]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.038492269814014435\n",
      "Predicci√≥n post entrenamiento : [[0.6212882]]\n",
      "PERDIDAAAA despues: 0.03775855898857117\n",
      "loss en el callback: 0.0528048574924469, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "ejemplar: [[0.54938692]\n",
      " [0.55889678]\n",
      " [0.56817496]\n",
      " [0.57825607]\n",
      " [0.5885995 ]\n",
      " [0.59954756]\n",
      " [0.60925174]\n",
      " [0.61940932]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8116992058331503\n",
      "Predicci√≥n : [[0.6295641]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[[0.54938692]\n",
      "  [0.55889678]\n",
      "  [0.56817496]\n",
      "  [0.57825607]\n",
      "  [0.5885995 ]\n",
      "  [0.59954756]\n",
      "  [0.60925174]\n",
      "  [0.61940932]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03317319601774216\n",
      "Predicci√≥n post entrenamiento : [[0.63055205]]\n",
      "PERDIDAAAA despues: 0.03281429409980774\n",
      "loss en el callback: 0.012667533941566944, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "ejemplar: [[0.55889678]\n",
      " [0.56817496]\n",
      " [0.57825607]\n",
      " [0.5885995 ]\n",
      " [0.59954756]\n",
      " [0.60925174]\n",
      " [0.61940932]\n",
      " [0.62956411]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8191625535336788\n",
      "Predicci√≥n : [[0.638889]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[[0.55889678]\n",
      "  [0.56817496]\n",
      "  [0.57825607]\n",
      "  [0.5885995 ]\n",
      "  [0.59954756]\n",
      "  [0.60925174]\n",
      "  [0.61940932]\n",
      "  [0.62956411]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.032498545944690704\n",
      "Predicci√≥n post entrenamiento : [[0.6407118]]\n",
      "PERDIDAAAA despues: 0.03184467554092407\n",
      "loss en el callback: 0.061381205916404724, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "ejemplar: [[0.56817496]\n",
      " [0.57825607]\n",
      " [0.5885995 ]\n",
      " [0.59954756]\n",
      " [0.60925174]\n",
      " [0.61940932]\n",
      " [0.62956411]\n",
      " [0.63888901]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8218275636038536\n",
      "Predicci√≥n : [[0.64921176]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[[0.56817496]\n",
      "  [0.57825607]\n",
      "  [0.5885995 ]\n",
      "  [0.59954756]\n",
      "  [0.60925174]\n",
      "  [0.61940932]\n",
      "  [0.62956411]\n",
      "  [0.63888901]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02979622408747673\n",
      "Predicci√≥n post entrenamiento : [[0.6504372]]\n",
      "PERDIDAAAA despues: 0.02937467396259308\n",
      "loss en el callback: 0.021392012014985085, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "ejemplar: [[0.57825607]\n",
      " [0.5885995 ]\n",
      " [0.59954756]\n",
      " [0.60925174]\n",
      " [0.61940932]\n",
      " [0.62956411]\n",
      " [0.63888901]\n",
      " [0.64921176]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8196942360436743\n",
      "Predicci√≥n : [[0.6591857]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[[0.57825607]\n",
      "  [0.5885995 ]\n",
      "  [0.59954756]\n",
      "  [0.60925174]\n",
      "  [0.61940932]\n",
      "  [0.62956411]\n",
      "  [0.63888901]\n",
      "  [0.64921176]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.025762982666492462\n",
      "Predicci√≥n post entrenamiento : [[0.6588961]]\n",
      "PERDIDAAAA despues: 0.02585603855550289\n",
      "loss en el callback: 0.0008421333623118699, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "ejemplar: [[0.5885995 ]\n",
      " [0.59954756]\n",
      " [0.60925174]\n",
      " [0.61940932]\n",
      " [0.62956411]\n",
      " [0.63888901]\n",
      " [0.64921176]\n",
      " [0.65918571]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8178628420548653\n",
      "Predicci√≥n : [[0.6676903]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[[0.5885995 ]\n",
      "  [0.59954756]\n",
      "  [0.60925174]\n",
      "  [0.61940932]\n",
      "  [0.62956411]\n",
      "  [0.63888901]\n",
      "  [0.64921176]\n",
      "  [0.65918571]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022551806643605232\n",
      "Predicci√≥n post entrenamiento : [[0.66951245]]\n",
      "PERDIDAAAA despues: 0.02200784720480442\n",
      "loss en el callback: 0.06835849583148956, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "ejemplar: [[0.59954756]\n",
      " [0.60925174]\n",
      " [0.61940932]\n",
      " [0.62956411]\n",
      " [0.63888901]\n",
      " [0.64921176]\n",
      " [0.65918571]\n",
      " [0.66769028]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8163333816374257\n",
      "Predicci√≥n : [[0.67826897]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[[0.59954756]\n",
      "  [0.60925174]\n",
      "  [0.61940932]\n",
      "  [0.62956411]\n",
      "  [0.63888901]\n",
      "  [0.64921176]\n",
      "  [0.65918571]\n",
      "  [0.66769028]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019061774015426636\n",
      "Predicci√≥n post entrenamiento : [[0.6795879]]\n",
      "PERDIDAAAA despues: 0.018699318170547485\n",
      "loss en el callback: 0.025888290256261826, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "ejemplar: [[0.60925174]\n",
      " [0.61940932]\n",
      " [0.62956411]\n",
      " [0.63888901]\n",
      " [0.64921176]\n",
      " [0.65918571]\n",
      " [0.66769028]\n",
      " [0.67826897]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8005556061309519\n",
      "Predicci√≥n : [[0.68810827]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[[0.60925174]\n",
      "  [0.61940932]\n",
      "  [0.62956411]\n",
      "  [0.63888901]\n",
      "  [0.64921176]\n",
      "  [0.65918571]\n",
      "  [0.66769028]\n",
      "  [0.67826897]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012644399888813496\n",
      "Predicci√≥n post entrenamiento : [[0.68864703]]\n",
      "PERDIDAAAA despues: 0.012523524463176727\n",
      "loss en el callback: 0.004029546398669481, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "ejemplar: [[0.61940932]\n",
      " [0.62956411]\n",
      " [0.63888901]\n",
      " [0.64921176]\n",
      " [0.65918571]\n",
      " [0.66769028]\n",
      " [0.67826897]\n",
      " [0.68810827]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7705295155354442\n",
      "Predicci√≥n : [[0.6972296]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[[0.61940932]\n",
      "  [0.62956411]\n",
      "  [0.63888901]\n",
      "  [0.64921176]\n",
      "  [0.65918571]\n",
      "  [0.66769028]\n",
      "  [0.67826897]\n",
      "  [0.68810827]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005372873041778803\n",
      "Predicci√≥n post entrenamiento : [[0.69869846]]\n",
      "PERDIDAAAA despues: 0.005159699358046055\n",
      "loss en el callback: 0.05341372266411781, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "ejemplar: [[0.62956411]\n",
      " [0.63888901]\n",
      " [0.64921176]\n",
      " [0.65918571]\n",
      " [0.66769028]\n",
      " [0.67826897]\n",
      " [0.68810827]\n",
      " [0.69722962]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7426586795525351\n",
      "Predicci√≥n : [[0.70721525]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[[0.62956411]\n",
      "  [0.63888901]\n",
      "  [0.64921176]\n",
      "  [0.65918571]\n",
      "  [0.66769028]\n",
      "  [0.67826897]\n",
      "  [0.68810827]\n",
      "  [0.69722962]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012562363408505917\n",
      "Predicci√≥n post entrenamiento : [[0.7075141]]\n",
      "PERDIDAAAA despues: 0.001235140603967011\n",
      "loss en el callback: 0.0014189583016559482, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "ejemplar: [[0.63888901]\n",
      " [0.64921176]\n",
      " [0.65918571]\n",
      " [0.66769028]\n",
      " [0.67826897]\n",
      " [0.68810827]\n",
      " [0.69722962]\n",
      " [0.70721525]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.716943098182225\n",
      "Predicci√≥n : [[0.7159416]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[[0.63888901]\n",
      "  [0.64921176]\n",
      "  [0.65918571]\n",
      "  [0.66769028]\n",
      "  [0.67826897]\n",
      "  [0.68810827]\n",
      "  [0.69722962]\n",
      "  [0.70721525]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.0029566510638688e-06\n",
      "Predicci√≥n post entrenamiento : [[0.71686554]]\n",
      "PERDIDAAAA despues: 6.013326725451407e-09\n",
      "loss en el callback: 0.023212559521198273, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "ejemplar: [[0.64921176]\n",
      " [0.65918571]\n",
      " [0.66769028]\n",
      " [0.67826897]\n",
      " [0.68810827]\n",
      " [0.69722962]\n",
      " [0.70721525]\n",
      " [0.71594161]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7197051306082382\n",
      "Predicci√≥n : [[0.725416]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[[0.64921176]\n",
      "  [0.65918571]\n",
      "  [0.66769028]\n",
      "  [0.67826897]\n",
      "  [0.68810827]\n",
      "  [0.69722962]\n",
      "  [0.70721525]\n",
      "  [0.71594161]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.261437814217061e-05\n",
      "Predicci√≥n post entrenamiento : [[0.7244273]]\n",
      "PERDIDAAAA despues: 2.2298965632217005e-05\n",
      "loss en el callback: 0.013857242651283741, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "ejemplar: [[0.65918571]\n",
      " [0.66769028]\n",
      " [0.67826897]\n",
      " [0.68810827]\n",
      " [0.69722962]\n",
      " [0.70721525]\n",
      " [0.71594161]\n",
      " [0.725416  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7509447768305747\n",
      "Predicci√≥n : [[0.732814]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[[0.65918571]\n",
      "  [0.66769028]\n",
      "  [0.67826897]\n",
      "  [0.68810827]\n",
      "  [0.69722962]\n",
      "  [0.70721525]\n",
      "  [0.71594161]\n",
      "  [0.725416  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003287251456640661\n",
      "Predicci√≥n post entrenamiento : [[0.73292744]]\n",
      "PERDIDAAAA despues: 0.000324624968925491\n",
      "loss en el callback: 0.000220893241930753, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "ejemplar: [[0.66769028]\n",
      " [0.67826897]\n",
      " [0.68810827]\n",
      " [0.69722962]\n",
      " [0.70721525]\n",
      " [0.71594161]\n",
      " [0.725416  ]\n",
      " [0.73281401]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.740278139029679\n",
      "Predicci√≥n : [[0.74120444]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[[0.66769028]\n",
      "  [0.67826897]\n",
      "  [0.68810827]\n",
      "  [0.69722962]\n",
      "  [0.70721525]\n",
      "  [0.71594161]\n",
      "  [0.725416  ]\n",
      "  [0.73281401]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.580609573982656e-07\n",
      "Predicci√≥n post entrenamiento : [[0.7415251]]\n",
      "PERDIDAAAA despues: 1.5549810541415354e-06\n",
      "loss en el callback: 0.00197029416449368, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "ejemplar: [[0.67826897]\n",
      " [0.68810827]\n",
      " [0.69722962]\n",
      " [0.70721525]\n",
      " [0.71594161]\n",
      " [0.725416  ]\n",
      " [0.73281401]\n",
      " [0.74120444]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.687705217205551\n",
      "Predicci√≥n : [[0.7500631]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[[0.67826897]\n",
      "  [0.68810827]\n",
      "  [0.69722962]\n",
      "  [0.70721525]\n",
      "  [0.71594161]\n",
      "  [0.725416  ]\n",
      "  [0.73281401]\n",
      "  [0.74120444]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0038885080721229315\n",
      "Predicci√≥n post entrenamiento : [[0.7498615]]\n",
      "PERDIDAAAA despues: 0.003863400546833873\n",
      "loss en el callback: 0.0007490079151466489, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "ejemplar: [[0.68810827]\n",
      " [0.69722962]\n",
      " [0.70721525]\n",
      " [0.71594161]\n",
      " [0.725416  ]\n",
      " [0.73281401]\n",
      " [0.74120444]\n",
      " [0.75006312]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6687695580612426\n",
      "Predicci√≥n : [[0.7580651]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[[0.68810827]\n",
      "  [0.69722962]\n",
      "  [0.70721525]\n",
      "  [0.71594161]\n",
      "  [0.725416  ]\n",
      "  [0.73281401]\n",
      "  [0.74120444]\n",
      "  [0.75006312]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00797369796782732\n",
      "Predicci√≥n post entrenamiento : [[0.7570852]]\n",
      "PERDIDAAAA despues: 0.007799656596034765\n",
      "loss en el callback: 0.015561213716864586, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "ejemplar: [[0.69722962]\n",
      " [0.70721525]\n",
      " [0.71594161]\n",
      " [0.725416  ]\n",
      " [0.73281401]\n",
      " [0.74120444]\n",
      " [0.75006312]\n",
      " [0.7580651 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6834711615967536\n",
      "Predicci√≥n : [[0.7650729]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[[0.69722962]\n",
      "  [0.70721525]\n",
      "  [0.71594161]\n",
      "  [0.725416  ]\n",
      "  [0.73281401]\n",
      "  [0.74120444]\n",
      "  [0.75006312]\n",
      "  [0.7580651 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006658843718469143\n",
      "Predicci√≥n post entrenamiento : [[0.7653572]]\n",
      "PERDIDAAAA despues: 0.006705325562506914\n",
      "loss en el callback: 0.0018549340311437845, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "ejemplar: [[0.70721525]\n",
      " [0.71594161]\n",
      " [0.725416  ]\n",
      " [0.73281401]\n",
      " [0.74120444]\n",
      " [0.75006312]\n",
      " [0.7580651 ]\n",
      " [0.76507288]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6877052172055499\n",
      "Predicci√≥n : [[0.7732651]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[[0.70721525]\n",
      "  [0.71594161]\n",
      "  [0.725416  ]\n",
      "  [0.73281401]\n",
      "  [0.74120444]\n",
      "  [0.75006312]\n",
      "  [0.7580651 ]\n",
      "  [0.76507288]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0073204971849918365\n",
      "Predicci√≥n post entrenamiento : [[0.7732796]]\n",
      "PERDIDAAAA despues: 0.007322975900024176\n",
      "loss en el callback: 4.804430773219792e-06, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "ejemplar: [[0.71594161]\n",
      " [0.725416  ]\n",
      " [0.73281401]\n",
      " [0.74120444]\n",
      " [0.75006312]\n",
      " [0.7580651 ]\n",
      " [0.76507288]\n",
      " [0.77326512]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6814717248876317\n",
      "Predicci√≥n : [[0.7808077]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[[0.71594161]\n",
      "  [0.725416  ]\n",
      "  [0.73281401]\n",
      "  [0.74120444]\n",
      "  [0.75006312]\n",
      "  [0.7580651 ]\n",
      "  [0.76507288]\n",
      "  [0.77326512]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009867634624242783\n",
      "Predicci√≥n post entrenamiento : [[0.779128]]\n",
      "PERDIDAAAA despues: 0.00953675527125597\n",
      "loss en el callback: 0.04072008281946182, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "ejemplar: [[0.725416  ]\n",
      " [0.73281401]\n",
      " [0.74120444]\n",
      " [0.75006312]\n",
      " [0.7580651 ]\n",
      " [0.76507288]\n",
      " [0.77326512]\n",
      " [0.78080767]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.689261843882625\n",
      "Predicci√≥n : [[0.78654444]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[[0.725416  ]\n",
      "  [0.73281401]\n",
      "  [0.74120444]\n",
      "  [0.75006312]\n",
      "  [0.7580651 ]\n",
      "  [0.76507288]\n",
      "  [0.77326512]\n",
      "  [0.78080767]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0094639016315341\n",
      "Predicci√≥n post entrenamiento : [[0.7863641]]\n",
      "PERDIDAAAA despues: 0.0094288419932127\n",
      "loss en el callback: 0.0006778279785066843, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "ejemplar: [[0.73281401]\n",
      " [0.74120444]\n",
      " [0.75006312]\n",
      " [0.7580651 ]\n",
      " [0.76507288]\n",
      " [0.77326512]\n",
      " [0.78080767]\n",
      " [0.78654444]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7110755741905297\n",
      "Predicci√≥n : [[0.7934043]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[[0.73281401]\n",
      "  [0.74120444]\n",
      "  [0.75006312]\n",
      "  [0.7580651 ]\n",
      "  [0.76507288]\n",
      "  [0.77326512]\n",
      "  [0.78080767]\n",
      "  [0.78654444]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0067780110985040665\n",
      "Predicci√≥n post entrenamiento : [[0.7920401]]\n",
      "PERDIDAAAA despues: 0.006555251311510801\n",
      "loss en el callback: 0.027378369122743607, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "ejemplar: [[0.74120444]\n",
      " [0.75006312]\n",
      " [0.7580651 ]\n",
      " [0.76507288]\n",
      " [0.77326512]\n",
      " [0.78080767]\n",
      " [0.78654444]\n",
      " [0.79340428]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7349108623046875\n",
      "Predicci√≥n : [[0.79920596]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[[0.74120444]\n",
      "  [0.75006312]\n",
      "  [0.7580651 ]\n",
      "  [0.76507288]\n",
      "  [0.77326512]\n",
      "  [0.78080767]\n",
      "  [0.78654444]\n",
      "  [0.79340428]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0041338615119457245\n",
      "Predicci√≥n post entrenamiento : [[0.7985324]]\n",
      "PERDIDAAAA despues: 0.004047705326229334\n",
      "loss en el callback: 0.0084738964214921, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "ejemplar: [[0.75006312]\n",
      " [0.7580651 ]\n",
      " [0.76507288]\n",
      " [0.77326512]\n",
      " [0.78080767]\n",
      " [0.78654444]\n",
      " [0.79340428]\n",
      " [0.79920596]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7607677082250986\n",
      "Predicci√≥n : [[0.8055085]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[[0.75006312]\n",
      "  [0.7580651 ]\n",
      "  [0.76507288]\n",
      "  [0.77326512]\n",
      "  [0.78080767]\n",
      "  [0.78654444]\n",
      "  [0.79340428]\n",
      "  [0.79920596]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0020017388742417097\n",
      "Predicci√≥n post entrenamiento : [[0.8049429]]\n",
      "PERDIDAAAA despues: 0.0019514489686116576\n",
      "loss en el callback: 0.005318173207342625, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "ejemplar: [[0.7580651 ]\n",
      " [0.76507288]\n",
      " [0.77326512]\n",
      " [0.78080767]\n",
      " [0.78654444]\n",
      " [0.79340428]\n",
      " [0.79920596]\n",
      " [0.80550849]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7711170829224028\n",
      "Predicci√≥n : [[0.81151205]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[[0.7580651 ]\n",
      "  [0.76507288]\n",
      "  [0.77326512]\n",
      "  [0.78080767]\n",
      "  [0.78654444]\n",
      "  [0.79340428]\n",
      "  [0.79920596]\n",
      "  [0.80550849]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016317529371008277\n",
      "Predicci√≥n post entrenamiento : [[0.80998427]]\n",
      "PERDIDAAAA despues: 0.0015106573700904846\n",
      "loss en el callback: 0.03582032024860382, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "ejemplar: [[0.76507288]\n",
      " [0.77326512]\n",
      " [0.78080767]\n",
      " [0.78654444]\n",
      " [0.79340428]\n",
      " [0.79920596]\n",
      " [0.80550849]\n",
      " [0.81151205]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7659589863965997\n",
      "Predicci√≥n : [[0.8162839]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[[0.76507288]\n",
      "  [0.77326512]\n",
      "  [0.78080767]\n",
      "  [0.78654444]\n",
      "  [0.79340428]\n",
      "  [0.79920596]\n",
      "  [0.80550849]\n",
      "  [0.81151205]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002532597165554762\n",
      "Predicci√≥n post entrenamiento : [[0.81490064]]\n",
      "PERDIDAAAA despues: 0.0023952871561050415\n",
      "loss en el callback: 0.028599200770258904, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "ejemplar: [[0.77326512]\n",
      " [0.78080767]\n",
      " [0.78654444]\n",
      " [0.79340428]\n",
      " [0.79920596]\n",
      " [0.80550849]\n",
      " [0.81151205]\n",
      " [0.81628388]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7483323528772654\n",
      "Predicci√≥n : [[0.82113075]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[[0.77326512]\n",
      "  [0.78080767]\n",
      "  [0.78654444]\n",
      "  [0.79340428]\n",
      "  [0.79920596]\n",
      "  [0.80550849]\n",
      "  [0.81151205]\n",
      "  [0.81628388]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005299602635204792\n",
      "Predicci√≥n post entrenamiento : [[0.81933475]]\n",
      "PERDIDAAAA despues: 0.0050413357093930244\n",
      "loss en el callback: 0.04900374636054039, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "ejemplar: [[0.78080767]\n",
      " [0.78654444]\n",
      " [0.79340428]\n",
      " [0.79920596]\n",
      " [0.80550849]\n",
      " [0.81151205]\n",
      " [0.81628388]\n",
      " [0.82113075]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7182371823643998\n",
      "Predicci√≥n : [[0.8250879]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[[0.78080767]\n",
      "  [0.78654444]\n",
      "  [0.79340428]\n",
      "  [0.79920596]\n",
      "  [0.80550849]\n",
      "  [0.81151205]\n",
      "  [0.81628388]\n",
      "  [0.82113075]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011417081579566002\n",
      "Predicci√≥n post entrenamiento : [[0.8245647]]\n",
      "PERDIDAAAA despues: 0.011305544525384903\n",
      "loss en el callback: 0.0055997781455516815, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "ejemplar: [[0.78654444]\n",
      " [0.79340428]\n",
      " [0.79920596]\n",
      " [0.80550849]\n",
      " [0.81151205]\n",
      " [0.81628388]\n",
      " [0.82113075]\n",
      " [0.8250879 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7089416644962148\n",
      "Predicci√≥n : [[0.82990795]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[[0.78654444]\n",
      "  [0.79340428]\n",
      "  [0.79920596]\n",
      "  [0.80550849]\n",
      "  [0.81151205]\n",
      "  [0.81628388]\n",
      "  [0.82113075]\n",
      "  [0.8250879 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014632849022746086\n",
      "Predicci√≥n post entrenamiento : [[0.8294445]]\n",
      "PERDIDAAAA despues: 0.014520945958793163\n",
      "loss en el callback: 0.004796923138201237, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "ejemplar: [[0.79340428]\n",
      " [0.79920596]\n",
      " [0.80550849]\n",
      " [0.81151205]\n",
      " [0.81628388]\n",
      " [0.82113075]\n",
      " [0.8250879 ]\n",
      " [0.82990795]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7204457992727099\n",
      "Predicci√≥n : [[0.83479214]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[[0.79340428]\n",
      "  [0.79920596]\n",
      "  [0.80550849]\n",
      "  [0.81151205]\n",
      "  [0.81628388]\n",
      "  [0.82113075]\n",
      "  [0.8250879 ]\n",
      "  [0.82990795]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013075082562863827\n",
      "Predicci√≥n post entrenamiento : [[0.8335015]]\n",
      "PERDIDAAAA despues: 0.012781593017280102\n",
      "loss en el callback: 0.030549926683306694, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "ejemplar: [[0.79920596]\n",
      " [0.80550849]\n",
      " [0.81151205]\n",
      " [0.81628388]\n",
      " [0.82113075]\n",
      " [0.8250879 ]\n",
      " [0.82990795]\n",
      " [0.83479214]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.770615477342717\n",
      "Predicci√≥n : [[0.8384801]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[[0.79920596]\n",
      "  [0.80550849]\n",
      "  [0.81151205]\n",
      "  [0.81628388]\n",
      "  [0.82113075]\n",
      "  [0.8250879 ]\n",
      "  [0.82990795]\n",
      "  [0.83479214]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0046056117862463\n",
      "Predicci√≥n post entrenamiento : [[0.8379542]]\n",
      "PERDIDAAAA despues: 0.004534509032964706\n",
      "loss en el callback: 0.0064088124781847, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "ejemplar: [[0.80550849]\n",
      " [0.81151205]\n",
      " [0.81628388]\n",
      " [0.82113075]\n",
      " [0.8250879 ]\n",
      " [0.82990795]\n",
      " [0.83479214]\n",
      " [0.83848011]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8594506987062355\n",
      "Predicci√≥n : [[0.84277093]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[[0.80550849]\n",
      "  [0.81151205]\n",
      "  [0.81628388]\n",
      "  [0.82113075]\n",
      "  [0.8250879 ]\n",
      "  [0.82990795]\n",
      "  [0.83479214]\n",
      "  [0.83848011]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002782145165838301\n",
      "Predicci√≥n post entrenamiento : [[0.8425298]]\n",
      "PERDIDAAAA despues: 0.00028631766326725483\n",
      "loss en el callback: 0.0011013355106115341, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "ejemplar: [[0.81151205]\n",
      " [0.81628388]\n",
      " [0.82113075]\n",
      " [0.8250879 ]\n",
      " [0.82990795]\n",
      " [0.83479214]\n",
      " [0.83848011]\n",
      " [0.84277093]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9065410812466371\n",
      "Predicci√≥n : [[0.8469741]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[[0.81151205]\n",
      "  [0.81628388]\n",
      "  [0.82113075]\n",
      "  [0.8250879 ]\n",
      "  [0.82990795]\n",
      "  [0.83479214]\n",
      "  [0.83848011]\n",
      "  [0.84277093]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0035482316743582487\n",
      "Predicci√≥n post entrenamiento : [[0.84828657]]\n",
      "PERDIDAAAA despues: 0.00339359138160944\n",
      "loss en el callback: 0.055011410266160965, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "ejemplar: [[0.81628388]\n",
      " [0.82113075]\n",
      " [0.8250879 ]\n",
      " [0.82990795]\n",
      " [0.83479214]\n",
      " [0.83848011]\n",
      " [0.84277093]\n",
      " [0.84697407]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9118866249639219\n",
      "Predicci√≥n : [[0.8523623]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[[0.81628388]\n",
      "  [0.82113075]\n",
      "  [0.8250879 ]\n",
      "  [0.82990795]\n",
      "  [0.83479214]\n",
      "  [0.83848011]\n",
      "  [0.84277093]\n",
      "  [0.84697407]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0035431492142379284\n",
      "Predicci√≥n post entrenamiento : [[0.85293853]]\n",
      "PERDIDAAAA despues: 0.003474878380075097\n",
      "loss en el callback: 0.007481082808226347, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "ejemplar: [[0.82113075]\n",
      " [0.8250879 ]\n",
      " [0.82990795]\n",
      " [0.83479214]\n",
      " [0.83848011]\n",
      " [0.84277093]\n",
      " [0.84697407]\n",
      " [0.85236228]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.904335569053715\n",
      "Predicci√≥n : [[0.8569372]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[[0.82113075]\n",
      "  [0.8250879 ]\n",
      "  [0.82990795]\n",
      "  [0.83479214]\n",
      "  [0.83848011]\n",
      "  [0.84277093]\n",
      "  [0.84697407]\n",
      "  [0.85236228]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0022466015070676804\n",
      "Predicci√≥n post entrenamiento : [[0.85789126]]\n",
      "PERDIDAAAA despues: 0.0021570727694779634\n",
      "loss en el callback: 0.023770568892359734, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "ejemplar: [[0.8250879 ]\n",
      " [0.82990795]\n",
      " [0.83479214]\n",
      " [0.83848011]\n",
      " [0.84277093]\n",
      " [0.84697407]\n",
      " [0.85236228]\n",
      " [0.85693723]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8838879135160167\n",
      "Predicci√≥n : [[0.86178094]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[[0.8250879 ]\n",
      "  [0.82990795]\n",
      "  [0.83479214]\n",
      "  [0.83848011]\n",
      "  [0.84277093]\n",
      "  [0.84697407]\n",
      "  [0.85236228]\n",
      "  [0.85693723]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004887170507572591\n",
      "Predicci√≥n post entrenamiento : [[0.8626275]]\n",
      "PERDIDAAAA despues: 0.00045200379099696875\n",
      "loss en el callback: 0.020040420815348625, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "ejemplar: [[0.82990795]\n",
      " [0.83479214]\n",
      " [0.83848011]\n",
      " [0.84277093]\n",
      " [0.84697407]\n",
      " [0.85236228]\n",
      " [0.85693723]\n",
      " [0.86178094]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9032153489332012\n",
      "Predicci√≥n : [[0.86665726]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[[0.82990795]\n",
      "  [0.83479214]\n",
      "  [0.83848011]\n",
      "  [0.84277093]\n",
      "  [0.84697407]\n",
      "  [0.85236228]\n",
      "  [0.85693723]\n",
      "  [0.86178094]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001336494111455977\n",
      "Predicci√≥n post entrenamiento : [[0.8651921]]\n",
      "PERDIDAAAA despues: 0.0014457663055509329\n",
      "loss en el callback: 0.03217654302716255, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "ejemplar: [[0.83479214]\n",
      " [0.83848011]\n",
      " [0.84277093]\n",
      " [0.84697407]\n",
      " [0.85236228]\n",
      " [0.85693723]\n",
      " [0.86178094]\n",
      " [0.86665726]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9623178753052692\n",
      "Predicci√≥n : [[0.86913747]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[[0.83479214]\n",
      "  [0.83848011]\n",
      "  [0.84277093]\n",
      "  [0.84697407]\n",
      "  [0.85236228]\n",
      "  [0.85693723]\n",
      "  [0.86178094]\n",
      "  [0.86665726]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00868258997797966\n",
      "Predicci√≥n post entrenamiento : [[0.86992455]]\n",
      "PERDIDAAAA despues: 0.008536528795957565\n",
      "loss en el callback: 0.014213156886398792, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "ejemplar: [[0.83848011]\n",
      " [0.84277093]\n",
      " [0.84697407]\n",
      " [0.85236228]\n",
      " [0.85693723]\n",
      " [0.86178094]\n",
      " [0.86665726]\n",
      " [0.86913747]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.982058820003038\n",
      "Predicci√≥n : [[0.87375754]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[[0.83848011]\n",
      "  [0.84277093]\n",
      "  [0.84697407]\n",
      "  [0.85236228]\n",
      "  [0.85693723]\n",
      "  [0.86178094]\n",
      "  [0.86665726]\n",
      "  [0.86913747]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011729167774319649\n",
      "Predicci√≥n post entrenamiento : [[0.87490606]]\n",
      "PERDIDAAAA despues: 0.011481714434921741\n",
      "loss en el callback: 0.029941203072667122, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "ejemplar: [[0.84277093]\n",
      " [0.84697407]\n",
      " [0.85236228]\n",
      " [0.85693723]\n",
      " [0.86178094]\n",
      " [0.86665726]\n",
      " [0.86913747]\n",
      " [0.87375754]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9624381830265082\n",
      "Predicci√≥n : [[0.87895775]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[[0.84277093]\n",
      "  [0.84697407]\n",
      "  [0.85236228]\n",
      "  [0.85693723]\n",
      "  [0.86178094]\n",
      "  [0.86665726]\n",
      "  [0.86913747]\n",
      "  [0.87375754]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006968980189412832\n",
      "Predicci√≥n post entrenamiento : [[0.8799227]]\n",
      "PERDIDAAAA despues: 0.006808804348111153\n",
      "loss en el callback: 0.026261016726493835, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "ejemplar: [[0.84697407]\n",
      " [0.85236228]\n",
      " [0.85693723]\n",
      " [0.86178094]\n",
      " [0.86665726]\n",
      " [0.86913747]\n",
      " [0.87375754]\n",
      " [0.87895775]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9302512105217627\n",
      "Predicci√≥n : [[0.8840443]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[[0.84697407]\n",
      "  [0.85236228]\n",
      "  [0.85693723]\n",
      "  [0.86178094]\n",
      "  [0.86665726]\n",
      "  [0.86913747]\n",
      "  [0.87375754]\n",
      "  [0.87895775]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002135076792910695\n",
      "Predicci√≥n post entrenamiento : [[0.884158]]\n",
      "PERDIDAAAA despues: 0.002124579856172204\n",
      "loss en el callback: 0.00026986136799678206, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "ejemplar: [[0.85236228]\n",
      " [0.85693723]\n",
      " [0.86178094]\n",
      " [0.86665726]\n",
      " [0.86913747]\n",
      " [0.87375754]\n",
      " [0.87895775]\n",
      " [0.88404429]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.885497902488802\n",
      "Predicci√≥n : [[0.88837814]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[[0.85236228]\n",
      "  [0.85693723]\n",
      "  [0.86178094]\n",
      "  [0.86665726]\n",
      "  [0.86913747]\n",
      "  [0.87375754]\n",
      "  [0.87895775]\n",
      "  [0.88404429]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.295642146549653e-06\n",
      "Predicci√≥n post entrenamiento : [[0.8880402]]\n",
      "PERDIDAAAA despues: 6.463072168116923e-06\n",
      "loss en el callback: 0.0022539698984473944, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "ejemplar: [[0.85693723]\n",
      " [0.86178094]\n",
      " [0.86665726]\n",
      " [0.86913747]\n",
      " [0.87375754]\n",
      " [0.87895775]\n",
      " [0.88404429]\n",
      " [0.88837814]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597025687419927\n",
      "Predicci√≥n : [[0.89201957]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[[0.85693723]\n",
      "  [0.86178094]\n",
      "  [0.86665726]\n",
      "  [0.86913747]\n",
      "  [0.87375754]\n",
      "  [0.87895775]\n",
      "  [0.88404429]\n",
      "  [0.88837814]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010443873470649123\n",
      "Predicci√≥n post entrenamiento : [[0.89201945]]\n",
      "PERDIDAAAA despues: 0.0010443796636536717\n",
      "loss en el callback: 5.130118552187923e-10, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "ejemplar: [[0.86178094]\n",
      " [0.86665726]\n",
      " [0.86913747]\n",
      " [0.87375754]\n",
      " [0.87895775]\n",
      " [0.88404429]\n",
      " [0.88837814]\n",
      " [0.89201957]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8528652092813349\n",
      "Predicci√≥n : [[0.895957]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[[0.86178094]\n",
      "  [0.86665726]\n",
      "  [0.86913747]\n",
      "  [0.87375754]\n",
      "  [0.87895775]\n",
      "  [0.88404429]\n",
      "  [0.88837814]\n",
      "  [0.89201957]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018569009844213724\n",
      "Predicci√≥n post entrenamiento : [[0.8947023]]\n",
      "PERDIDAAAA despues: 0.001750342664308846\n",
      "loss en el callback: 0.03044433891773224, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "ejemplar: [[0.86665726]\n",
      " [0.86913747]\n",
      " [0.87375754]\n",
      " [0.87895775]\n",
      " [0.88404429]\n",
      " [0.88837814]\n",
      " [0.89201957]\n",
      " [0.89595699]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8585854533368672\n",
      "Predicci√≥n : [[0.898509]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[[0.86665726]\n",
      "  [0.86913747]\n",
      "  [0.87375754]\n",
      "  [0.87895775]\n",
      "  [0.88404429]\n",
      "  [0.88837814]\n",
      "  [0.89201957]\n",
      "  [0.89595699]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015938897849991918\n",
      "Predicci√≥n post entrenamiento : [[0.8961771]]\n",
      "PERDIDAAAA despues: 0.001413131132721901\n",
      "loss en el callback: 0.08710918575525284, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "ejemplar: [[0.86913747]\n",
      " [0.87375754]\n",
      " [0.87895775]\n",
      " [0.88404429]\n",
      " [0.88837814]\n",
      " [0.89201957]\n",
      " [0.89595699]\n",
      " [0.89850903]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8768633009085897\n",
      "Predicci√≥n : [[0.89981407]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[[0.86913747]\n",
      "  [0.87375754]\n",
      "  [0.87895775]\n",
      "  [0.88404429]\n",
      "  [0.88837814]\n",
      "  [0.89201957]\n",
      "  [0.89595699]\n",
      "  [0.89850903]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005267377709969878\n",
      "Predicci√≥n post entrenamiento : [[0.90004194]]\n",
      "PERDIDAAAA despues: 0.0005372492014430463\n",
      "loss en el callback: 0.0014548413455486298, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "ejemplar: [[0.87375754]\n",
      " [0.87895775]\n",
      " [0.88404429]\n",
      " [0.88837814]\n",
      " [0.89201957]\n",
      " [0.89595699]\n",
      " [0.89850903]\n",
      " [0.89981407]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8806463966074481\n",
      "Predicci√≥n : [[0.90415704]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[[0.87375754]\n",
      "  [0.87895775]\n",
      "  [0.88404429]\n",
      "  [0.88837814]\n",
      "  [0.89201957]\n",
      "  [0.89595699]\n",
      "  [0.89850903]\n",
      "  [0.89981407]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005527499597519636\n",
      "Predicci√≥n post entrenamiento : [[0.90360177]]\n",
      "PERDIDAAAA despues: 0.0005269484827294946\n",
      "loss en el callback: 0.007008145097643137, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "ejemplar: [[0.87895775]\n",
      " [0.88404429]\n",
      " [0.88837814]\n",
      " [0.89201957]\n",
      " [0.89595699]\n",
      " [0.89850903]\n",
      " [0.89981407]\n",
      " [0.90415704]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8699347404334429\n",
      "Predicci√≥n : [[0.9075894]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[[0.87895775]\n",
      "  [0.88404429]\n",
      "  [0.88837814]\n",
      "  [0.89201957]\n",
      "  [0.89595699]\n",
      "  [0.89850903]\n",
      "  [0.89981407]\n",
      "  [0.90415704]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014178717974573374\n",
      "Predicci√≥n post entrenamiento : [[0.90786445]]\n",
      "PERDIDAAAA despues: 0.0014386632246896625\n",
      "loss en el callback: 0.002286328002810478, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "ejemplar: [[0.88404429]\n",
      " [0.88837814]\n",
      " [0.89201957]\n",
      " [0.89595699]\n",
      " [0.89850903]\n",
      " [0.89981407]\n",
      " [0.90415704]\n",
      " [0.90758938]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8465135437340043\n",
      "Predicci√≥n : [[0.91148275]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[[0.88404429]\n",
      "  [0.88837814]\n",
      "  [0.89201957]\n",
      "  [0.89595699]\n",
      "  [0.89850903]\n",
      "  [0.89981407]\n",
      "  [0.90415704]\n",
      "  [0.90758938]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004220994655042887\n",
      "Predicci√≥n post entrenamiento : [[0.9116785]]\n",
      "PERDIDAAAA despues: 0.004246467258781195\n",
      "loss en el callback: 0.0011932379566133022, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "ejemplar: [[0.88837814]\n",
      " [0.89201957]\n",
      " [0.89595699]\n",
      " [0.89850903]\n",
      " [0.89981407]\n",
      " [0.90415704]\n",
      " [0.90758938]\n",
      " [0.91148275]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8103828065091326\n",
      "Predicci√≥n : [[0.91486925]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[[0.88837814]\n",
      "  [0.89201957]\n",
      "  [0.89595699]\n",
      "  [0.89850903]\n",
      "  [0.89981407]\n",
      "  [0.90415704]\n",
      "  [0.90758938]\n",
      "  [0.91148275]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01091742143034935\n",
      "Predicci√≥n post entrenamiento : [[0.9155848]]\n",
      "PERDIDAAAA despues: 0.0110674649477005\n",
      "loss en el callback: 0.023490050807595253, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "ejemplar: [[0.89201957]\n",
      " [0.89595699]\n",
      " [0.89850903]\n",
      " [0.89981407]\n",
      " [0.90415704]\n",
      " [0.90758938]\n",
      " [0.91148275]\n",
      " [0.91486925]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8026111217617493\n",
      "Predicci√≥n : [[0.91849196]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[[0.89201957]\n",
      "  [0.89595699]\n",
      "  [0.89850903]\n",
      "  [0.89981407]\n",
      "  [0.90415704]\n",
      "  [0.90758938]\n",
      "  [0.91148275]\n",
      "  [0.91486925]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013428370468318462\n",
      "Predicci√≥n post entrenamiento : [[0.9170651]]\n",
      "PERDIDAAAA despues: 0.013099711388349533\n",
      "loss en el callback: 0.04674810916185379, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "ejemplar: [[0.89595699]\n",
      " [0.89850903]\n",
      " [0.89981407]\n",
      " [0.90415704]\n",
      " [0.90758938]\n",
      " [0.91148275]\n",
      " [0.91486925]\n",
      " [0.91849196]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.823198489491854\n",
      "Predicci√≥n : [[0.9198522]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[[0.89595699]\n",
      "  [0.89850903]\n",
      "  [0.89981407]\n",
      "  [0.90415704]\n",
      "  [0.90758938]\n",
      "  [0.91148275]\n",
      "  [0.91486925]\n",
      "  [0.91849196]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009341937489807606\n",
      "Predicci√≥n post entrenamiento : [[0.9193088]]\n",
      "PERDIDAAAA despues: 0.00923718698322773\n",
      "loss en el callback: 0.00836965162307024, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "ejemplar: [[0.89850903]\n",
      " [0.89981407]\n",
      " [0.90415704]\n",
      " [0.90758938]\n",
      " [0.91148275]\n",
      " [0.91486925]\n",
      " [0.91849196]\n",
      " [0.9198522 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8397204264676091\n",
      "Predicci√≥n : [[0.921877]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[[0.89850903]\n",
      "  [0.89981407]\n",
      "  [0.90415704]\n",
      "  [0.90758938]\n",
      "  [0.91148275]\n",
      "  [0.91486925]\n",
      "  [0.91849196]\n",
      "  [0.9198522 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00674970680847764\n",
      "Predicci√≥n post entrenamiento : [[0.9203853]]\n",
      "PERDIDAAAA despues: 0.006506821606308222\n",
      "loss en el callback: 0.04876331984996796, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "ejemplar: [[0.89981407]\n",
      " [0.90415704]\n",
      " [0.90758938]\n",
      " [0.91148275]\n",
      " [0.91486925]\n",
      " [0.91849196]\n",
      " [0.9198522 ]\n",
      " [0.92187703]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.852176932689015\n",
      "Predicci√≥n : [[0.92310804]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[[0.89981407]\n",
      "  [0.90415704]\n",
      "  [0.90758938]\n",
      "  [0.91148275]\n",
      "  [0.91486925]\n",
      "  [0.91849196]\n",
      "  [0.9198522 ]\n",
      "  [0.92187703]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005031226202845573\n",
      "Predicci√≥n post entrenamiento : [[0.92238265]]\n",
      "PERDIDAAAA despues: 0.0049288468435406685\n",
      "loss en el callback: 0.012818600982427597, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "ejemplar: [[0.90415704]\n",
      " [0.90758938]\n",
      " [0.91148275]\n",
      " [0.91486925]\n",
      " [0.91849196]\n",
      " [0.9198522 ]\n",
      " [0.92187703]\n",
      " [0.92310804]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8615626813481295\n",
      "Predicci√≥n : [[0.9256244]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[[0.90415704]\n",
      "  [0.90758938]\n",
      "  [0.91148275]\n",
      "  [0.91486925]\n",
      "  [0.91849196]\n",
      "  [0.9198522 ]\n",
      "  [0.92187703]\n",
      "  [0.92310804]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004103901796042919\n",
      "Predicci√≥n post entrenamiento : [[0.9238226]]\n",
      "PERDIDAAAA despues: 0.003876296803355217\n",
      "loss en el callback: 0.06445055454969406, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "ejemplar: [[0.90758938]\n",
      " [0.91148275]\n",
      " [0.91486925]\n",
      " [0.91849196]\n",
      " [0.9198522 ]\n",
      " [0.92187703]\n",
      " [0.92310804]\n",
      " [0.92562437]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8678776724449532\n",
      "Predicci√≥n : [[0.9267199]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[[0.90758938]\n",
      "  [0.91148275]\n",
      "  [0.91486925]\n",
      "  [0.91849196]\n",
      "  [0.9198522 ]\n",
      "  [0.92187703]\n",
      "  [0.92310804]\n",
      "  [0.92562437]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0034624093677848577\n",
      "Predicci√≥n post entrenamiento : [[0.92614037]]\n",
      "PERDIDAAAA despues: 0.003394542960450053\n",
      "loss en el callback: 0.008567308075726032, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "ejemplar: [[0.91148275]\n",
      " [0.91486925]\n",
      " [0.91849196]\n",
      " [0.9198522 ]\n",
      " [0.92187703]\n",
      " [0.92310804]\n",
      " [0.92562437]\n",
      " [0.9267199 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8701963127047843\n",
      "Predicci√≥n : [[0.92885333]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[[0.91148275]\n",
      "  [0.91486925]\n",
      "  [0.91849196]\n",
      "  [0.9198522 ]\n",
      "  [0.92187703]\n",
      "  [0.92310804]\n",
      "  [0.92562437]\n",
      "  [0.9267199 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003440642496570945\n",
      "Predicci√≥n post entrenamiento : [[0.92881346]]\n",
      "PERDIDAAAA despues: 0.003435966093093157\n",
      "loss en el callback: 5.063858407083899e-05, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "ejemplar: [[0.91486925]\n",
      " [0.91849196]\n",
      " [0.9198522 ]\n",
      " [0.92187703]\n",
      " [0.92310804]\n",
      " [0.92562437]\n",
      " [0.9267199 ]\n",
      " [0.92885333]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8685186021276227\n",
      "Predicci√≥n : [[0.93113023]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[[0.91486925]\n",
      "  [0.91849196]\n",
      "  [0.9198522 ]\n",
      "  [0.92187703]\n",
      "  [0.92310804]\n",
      "  [0.92562437]\n",
      "  [0.9267199 ]\n",
      "  [0.92885333]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003920217510312796\n",
      "Predicci√≥n post entrenamiento : [[0.9314062]]\n",
      "PERDIDAAAA despues: 0.003954851534217596\n",
      "loss en el callback: 0.002351978328078985, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "ejemplar: [[0.91849196]\n",
      " [0.9198522 ]\n",
      " [0.92187703]\n",
      " [0.92310804]\n",
      " [0.92562437]\n",
      " [0.9267199 ]\n",
      " [0.92885333]\n",
      " [0.93113023]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8529880395838255\n",
      "Predicci√≥n : [[0.93338305]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[[0.91849196]\n",
      "  [0.9198522 ]\n",
      "  [0.92187703]\n",
      "  [0.92310804]\n",
      "  [0.92562437]\n",
      "  [0.9267199 ]\n",
      "  [0.92885333]\n",
      "  [0.93113023]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006463353522121906\n",
      "Predicci√≥n post entrenamiento : [[0.93322223]]\n",
      "PERDIDAAAA despues: 0.006437521893531084\n",
      "loss en el callback: 0.0008454715716652572, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "ejemplar: [[0.9198522 ]\n",
      " [0.92187703]\n",
      " [0.92310804]\n",
      " [0.92562437]\n",
      " [0.9267199 ]\n",
      " [0.92885333]\n",
      " [0.93113023]\n",
      " [0.93338305]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8236046250733932\n",
      "Predicci√≥n : [[0.93472695]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[[0.9198522 ]\n",
      "  [0.92187703]\n",
      "  [0.92310804]\n",
      "  [0.92562437]\n",
      "  [0.9267199 ]\n",
      "  [0.92885333]\n",
      "  [0.93113023]\n",
      "  [0.93338305]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012348167598247528\n",
      "Predicci√≥n post entrenamiento : [[0.9347862]]\n",
      "PERDIDAAAA despues: 0.01236133836209774\n",
      "loss en el callback: 0.00013675553782377392, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "ejemplar: [[0.92187703]\n",
      " [0.92310804]\n",
      " [0.92562437]\n",
      " [0.9267199 ]\n",
      " [0.92885333]\n",
      " [0.93113023]\n",
      " [0.93338305]\n",
      " [0.93472695]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8032508871761479\n",
      "Predicci√≥n : [[0.9364156]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[[0.92187703]\n",
      "  [0.92310804]\n",
      "  [0.92562437]\n",
      "  [0.9267199 ]\n",
      "  [0.92885333]\n",
      "  [0.93113023]\n",
      "  [0.93338305]\n",
      "  [0.93472695]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017732838168740273\n",
      "Predicci√≥n post entrenamiento : [[0.9350259]]\n",
      "PERDIDAAAA despues: 0.017364639788866043\n",
      "loss en el callback: 0.05040108039975166, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "ejemplar: [[0.92310804]\n",
      " [0.92562437]\n",
      " [0.9267199 ]\n",
      " [0.92885333]\n",
      " [0.93113023]\n",
      " [0.93338305]\n",
      " [0.93472695]\n",
      " [0.93641561]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7919268258920897\n",
      "Predicci√≥n : [[0.9366075]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[[0.92310804]\n",
      "  [0.92562437]\n",
      "  [0.9267199 ]\n",
      "  [0.92885333]\n",
      "  [0.93113023]\n",
      "  [0.93338305]\n",
      "  [0.93472695]\n",
      "  [0.93641561]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.020932499319314957\n",
      "Predicci√≥n post entrenamiento : [[0.93581766]]\n",
      "PERDIDAAAA despues: 0.02070457860827446\n",
      "loss en el callback: 0.019743166863918304, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "ejemplar: [[0.92562437]\n",
      " [0.9267199 ]\n",
      " [0.92885333]\n",
      " [0.93113023]\n",
      " [0.93338305]\n",
      " [0.93472695]\n",
      " [0.93641561]\n",
      " [0.93660748]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7865023059771536\n",
      "Predicci√≥n : [[0.93756866]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[[0.92562437]\n",
      "  [0.9267199 ]\n",
      "  [0.92885333]\n",
      "  [0.93113023]\n",
      "  [0.93338305]\n",
      "  [0.93472695]\n",
      "  [0.93641561]\n",
      "  [0.93660748]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02282104641199112\n",
      "Predicci√≥n post entrenamiento : [[0.9367239]]\n",
      "PERDIDAAAA despues: 0.022566525265574455\n",
      "loss en el callback: 0.0215146541595459, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "ejemplar: [[0.9267199 ]\n",
      " [0.92885333]\n",
      " [0.93113023]\n",
      " [0.93338305]\n",
      " [0.93472695]\n",
      " [0.93641561]\n",
      " [0.93660748]\n",
      " [0.93756866]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7869773274313391\n",
      "Predicci√≥n : [[0.93827176]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[[0.9267199 ]\n",
      "  [0.92885333]\n",
      "  [0.93113023]\n",
      "  [0.93338305]\n",
      "  [0.93472695]\n",
      "  [0.93641561]\n",
      "  [0.93660748]\n",
      "  [0.93756866]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02288999781012535\n",
      "Predicci√≥n post entrenamiento : [[0.9374649]]\n",
      "PERDIDAAAA despues: 0.022646499797701836\n",
      "loss en el callback: 0.0207733865827322, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "ejemplar: [[0.92885333]\n",
      " [0.93113023]\n",
      " [0.93338305]\n",
      " [0.93472695]\n",
      " [0.93641561]\n",
      " [0.93660748]\n",
      " [0.93756866]\n",
      " [0.93827176]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7874362431744556\n",
      "Predicci√≥n : [[0.93916863]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[[0.92885333]\n",
      "  [0.93113023]\n",
      "  [0.93338305]\n",
      "  [0.93472695]\n",
      "  [0.93641561]\n",
      "  [0.93660748]\n",
      "  [0.93756866]\n",
      "  [0.93827176]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.023022716864943504\n",
      "Predicci√≥n post entrenamiento : [[0.93724483]]\n",
      "PERDIDAAAA despues: 0.022442612797021866\n",
      "loss en el callback: 0.08760922402143478, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "ejemplar: [[0.93113023]\n",
      " [0.93338305]\n",
      " [0.93472695]\n",
      " [0.93641561]\n",
      " [0.93660748]\n",
      " [0.93756866]\n",
      " [0.93827176]\n",
      " [0.93916863]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7878790532065031\n",
      "Predicci√≥n : [[0.9387857]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[[0.93113023]\n",
      "  [0.93338305]\n",
      "  [0.93472695]\n",
      "  [0.93641561]\n",
      "  [0.93660748]\n",
      "  [0.93756866]\n",
      "  [0.93827176]\n",
      "  [0.93916863]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022772809490561485\n",
      "Predicci√≥n post entrenamiento : [[0.93784404]]\n",
      "PERDIDAAAA despues: 0.022489497438073158\n",
      "loss en el callback: 0.025136390700936317, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "ejemplar: [[0.93338305]\n",
      " [0.93472695]\n",
      " [0.93641561]\n",
      " [0.93660748]\n",
      " [0.93756866]\n",
      " [0.93827176]\n",
      " [0.93916863]\n",
      " [0.93878567]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7954532004373992\n",
      "Predicci√≥n : [[0.9391127]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[[0.93338305]\n",
      "  [0.93472695]\n",
      "  [0.93641561]\n",
      "  [0.93660748]\n",
      "  [0.93756866]\n",
      "  [0.93827176]\n",
      "  [0.93916863]\n",
      "  [0.93878567]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.020638061687350273\n",
      "Predicci√≥n post entrenamiento : [[0.93823916]]\n",
      "PERDIDAAAA despues: 0.020387832075357437\n",
      "loss en el callback: 0.022800125181674957, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "ejemplar: [[0.93472695]\n",
      " [0.93641561]\n",
      " [0.93660748]\n",
      " [0.93756866]\n",
      " [0.93827176]\n",
      " [0.93916863]\n",
      " [0.93878567]\n",
      " [0.93911272]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8101586848671446\n",
      "Predicci√≥n : [[0.9391641]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[[0.93472695]\n",
      "  [0.93641561]\n",
      "  [0.93660748]\n",
      "  [0.93756866]\n",
      "  [0.93827176]\n",
      "  [0.93916863]\n",
      "  [0.93878567]\n",
      "  [0.93911272]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01664240099489689\n",
      "Predicci√≥n post entrenamiento : [[0.9379278]]\n",
      "PERDIDAAAA despues: 0.016324946656823158\n",
      "loss en el callback: 0.04364166408777237, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "ejemplar: [[0.93641561]\n",
      " [0.93660748]\n",
      " [0.93756866]\n",
      " [0.93827176]\n",
      " [0.93916863]\n",
      " [0.93878567]\n",
      " [0.93911272]\n",
      " [0.9391641 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7668473230866574\n",
      "Predicci√≥n : [[0.93869245]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[[0.93641561]\n",
      "  [0.93660748]\n",
      "  [0.93756866]\n",
      "  [0.93827176]\n",
      "  [0.93916863]\n",
      "  [0.93878567]\n",
      "  [0.93911272]\n",
      "  [0.9391641 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.029530750587582588\n",
      "Predicci√≥n post entrenamiento : [[0.93797815]]\n",
      "PERDIDAAAA despues: 0.029285762459039688\n",
      "loss en el callback: 0.018847839906811714, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "ejemplar: [[0.93660748]\n",
      " [0.93756866]\n",
      " [0.93827176]\n",
      " [0.93916863]\n",
      " [0.93878567]\n",
      " [0.93911272]\n",
      " [0.9391641 ]\n",
      " [0.93869245]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6655191150959373\n",
      "Predicci√≥n : [[0.93843025]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[[0.93660748]\n",
      "  [0.93756866]\n",
      "  [0.93827176]\n",
      "  [0.93916863]\n",
      "  [0.93878567]\n",
      "  [0.93911272]\n",
      "  [0.9391641 ]\n",
      "  [0.93869245]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07448048889636993\n",
      "Predicci√≥n post entrenamiento : [[0.9372305]]\n",
      "PERDIDAAAA despues: 0.07382708787918091\n",
      "loss en el callback: 0.051915984600782394, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "ejemplar: [[0.93756866]\n",
      " [0.93827176]\n",
      " [0.93916863]\n",
      " [0.93878567]\n",
      " [0.93911272]\n",
      " [0.9391641 ]\n",
      " [0.93869245]\n",
      " [0.93843025]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6360738003224796\n",
      "Predicci√≥n : [[0.93773705]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[[0.93756866]\n",
      "  [0.93827176]\n",
      "  [0.93916863]\n",
      "  [0.93878567]\n",
      "  [0.93911272]\n",
      "  [0.9391641 ]\n",
      "  [0.93869245]\n",
      "  [0.93843025]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09100069850683212\n",
      "Predicci√≥n post entrenamiento : [[0.93669987]]\n",
      "PERDIDAAAA despues: 0.09037601202726364\n",
      "loss en el callback: 0.04063665494322777, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "ejemplar: [[0.93827176]\n",
      " [0.93916863]\n",
      " [0.93878567]\n",
      " [0.93911272]\n",
      " [0.9391641 ]\n",
      " [0.93869245]\n",
      " [0.93843025]\n",
      " [0.93773705]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6785113787662842\n",
      "Predicci√≥n : [[0.93701446]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[[0.93827176]\n",
      "  [0.93916863]\n",
      "  [0.93878567]\n",
      "  [0.93911272]\n",
      "  [0.9391641 ]\n",
      "  [0.93869245]\n",
      "  [0.93843025]\n",
      "  [0.93773705]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06682384014129639\n",
      "Predicci√≥n post entrenamiento : [[0.9362173]]\n",
      "PERDIDAAAA despues: 0.06641234457492828\n",
      "loss en el callback: 0.025525618344545364, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "ejemplar: [[0.93916863]\n",
      " [0.93878567]\n",
      " [0.93911272]\n",
      " [0.9391641 ]\n",
      " [0.93869245]\n",
      " [0.93843025]\n",
      " [0.93773705]\n",
      " [0.93701446]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6965967339840231\n",
      "Predicci√≥n : [[0.93635637]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[[0.93916863]\n",
      "  [0.93878567]\n",
      "  [0.93911272]\n",
      "  [0.9391641 ]\n",
      "  [0.93869245]\n",
      "  [0.93843025]\n",
      "  [0.93773705]\n",
      "  [0.93701446]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05748467892408371\n",
      "Predicci√≥n post entrenamiento : [[0.9351699]]\n",
      "PERDIDAAAA despues: 0.056917138397693634\n",
      "loss en el callback: 0.047895122319459915, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "ejemplar: [[0.93878567]\n",
      " [0.93911272]\n",
      " [0.9391641 ]\n",
      " [0.93869245]\n",
      " [0.93843025]\n",
      " [0.93773705]\n",
      " [0.93701446]\n",
      " [0.93635637]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6903298659756966\n",
      "Predicci√≥n : [[0.9350252]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[[0.93878567]\n",
      "  [0.93911272]\n",
      "  [0.9391641 ]\n",
      "  [0.93869245]\n",
      "  [0.93843025]\n",
      "  [0.93773705]\n",
      "  [0.93701446]\n",
      "  [0.93635637]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05987582355737686\n",
      "Predicci√≥n post entrenamiento : [[0.9335913]]\n",
      "PERDIDAAAA despues: 0.059176135808229446\n",
      "loss en el callback: 0.07301503419876099, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "ejemplar: [[0.93911272]\n",
      " [0.9391641 ]\n",
      " [0.93869245]\n",
      " [0.93843025]\n",
      " [0.93773705]\n",
      " [0.93701446]\n",
      " [0.93635637]\n",
      " [0.93502522]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6970473058045382\n",
      "Predicci√≥n : [[0.9334706]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[[0.93911272]\n",
      "  [0.9391641 ]\n",
      "  [0.93869245]\n",
      "  [0.93843025]\n",
      "  [0.93773705]\n",
      "  [0.93701446]\n",
      "  [0.93635637]\n",
      "  [0.93502522]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.055895984172821045\n",
      "Predicci√≥n post entrenamiento : [[0.93251866]]\n",
      "PERDIDAAAA despues: 0.05544676631689072\n",
      "loss en el callback: 0.036757294088602066, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "ejemplar: [[0.9391641 ]\n",
      " [0.93869245]\n",
      " [0.93843025]\n",
      " [0.93773705]\n",
      " [0.93701446]\n",
      " [0.93635637]\n",
      " [0.93502522]\n",
      " [0.93347061]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7167490534705484\n",
      "Predicci√≥n : [[0.9321886]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[[0.9391641 ]\n",
      "  [0.93869245]\n",
      "  [0.93843025]\n",
      "  [0.93773705]\n",
      "  [0.93701446]\n",
      "  [0.93635637]\n",
      "  [0.93502522]\n",
      "  [0.93347061]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04641417786478996\n",
      "Predicci√≥n post entrenamiento : [[0.93102527]]\n",
      "PERDIDAAAA despues: 0.045914288610219955\n",
      "loss en el callback: 0.05345475301146507, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "ejemplar: [[0.93869245]\n",
      " [0.93843025]\n",
      " [0.93773705]\n",
      " [0.93701446]\n",
      " [0.93635637]\n",
      " [0.93502522]\n",
      " [0.93347061]\n",
      " [0.93218857]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7490507063998944\n",
      "Predicci√≥n : [[0.93050635]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[[0.93869245]\n",
      "  [0.93843025]\n",
      "  [0.93773705]\n",
      "  [0.93701446]\n",
      "  [0.93635637]\n",
      "  [0.93502522]\n",
      "  [0.93347061]\n",
      "  [0.93218857]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03292616084218025\n",
      "Predicci√≥n post entrenamiento : [[0.9305932]]\n",
      "PERDIDAAAA despues: 0.03295768424868584\n",
      "loss en el callback: 0.00043600110802799463, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "ejemplar: [[0.93843025]\n",
      " [0.93773705]\n",
      " [0.93701446]\n",
      " [0.93635637]\n",
      " [0.93502522]\n",
      " [0.93347061]\n",
      " [0.93218857]\n",
      " [0.93050635]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7939522645925762\n",
      "Predicci√≥n : [[0.92998105]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[[0.93843025]\n",
      "  [0.93773705]\n",
      "  [0.93701446]\n",
      "  [0.93635637]\n",
      "  [0.93502522]\n",
      "  [0.93347061]\n",
      "  [0.93218857]\n",
      "  [0.93050635]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0185038261115551\n",
      "Predicci√≥n post entrenamiento : [[0.9298868]]\n",
      "PERDIDAAAA despues: 0.01847819611430168\n",
      "loss en el callback: 0.00044009790872223675, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "ejemplar: [[0.93773705]\n",
      " [0.93701446]\n",
      " [0.93635637]\n",
      " [0.93502522]\n",
      " [0.93347061]\n",
      " [0.93218857]\n",
      " [0.93050635]\n",
      " [0.92998105]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8547447263586395\n",
      "Predicci√≥n : [[0.9290849]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[[0.93773705]\n",
      "  [0.93701446]\n",
      "  [0.93635637]\n",
      "  [0.93502522]\n",
      "  [0.93347061]\n",
      "  [0.93218857]\n",
      "  [0.93050635]\n",
      "  [0.92998105]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005526460241526365\n",
      "Predicci√≥n post entrenamiento : [[0.92847884]]\n",
      "PERDIDAAAA despues: 0.005436717998236418\n",
      "loss en el callback: 0.013353437185287476, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "ejemplar: [[0.93701446]\n",
      " [0.93635637]\n",
      " [0.93502522]\n",
      " [0.93347061]\n",
      " [0.93218857]\n",
      " [0.93050635]\n",
      " [0.92998105]\n",
      " [0.9290849 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9314280916980849\n",
      "Predicci√≥n : [[0.92757237]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[[0.93701446]\n",
      "  [0.93635637]\n",
      "  [0.93502522]\n",
      "  [0.93347061]\n",
      "  [0.93218857]\n",
      "  [0.93050635]\n",
      "  [0.92998105]\n",
      "  [0.9290849 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.4866463061480317e-05\n",
      "Predicci√≥n post entrenamiento : [[0.9280113]]\n",
      "PERDIDAAAA despues: 1.167436312243808e-05\n",
      "loss en el callback: 0.008420987986028194, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "ejemplar: [[0.93635637]\n",
      " [0.93502522]\n",
      " [0.93347061]\n",
      " [0.93218857]\n",
      " [0.93050635]\n",
      " [0.92998105]\n",
      " [0.9290849 ]\n",
      " [0.92757237]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9627243989762315\n",
      "Predicci√≥n : [[0.92698574]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[[0.93635637]\n",
      "  [0.93502522]\n",
      "  [0.93347061]\n",
      "  [0.93218857]\n",
      "  [0.93050635]\n",
      "  [0.92998105]\n",
      "  [0.9290849 ]\n",
      "  [0.92757237]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001277250936254859\n",
      "Predicci√≥n post entrenamiento : [[0.92663306]]\n",
      "PERDIDAAAA despues: 0.0013025839580222964\n",
      "loss en el callback: 0.004253966733813286, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "ejemplar: [[0.93502522]\n",
      " [0.93347061]\n",
      " [0.93218857]\n",
      " [0.93050635]\n",
      " [0.92998105]\n",
      " [0.9290849 ]\n",
      " [0.92757237]\n",
      " [0.92698574]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9486336481930799\n",
      "Predicci√≥n : [[0.9254547]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[[0.93502522]\n",
      "  [0.93347061]\n",
      "  [0.93218857]\n",
      "  [0.93050635]\n",
      "  [0.92998105]\n",
      "  [0.9290849 ]\n",
      "  [0.92757237]\n",
      "  [0.92698574]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005372657906264067\n",
      "Predicci√≥n post entrenamiento : [[0.9253618]]\n",
      "PERDIDAAAA despues: 0.000541579385753721\n",
      "loss en el callback: 0.00033852539490908384, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "ejemplar: [[0.93347061]\n",
      " [0.93218857]\n",
      " [0.93050635]\n",
      " [0.92998105]\n",
      " [0.9290849 ]\n",
      " [0.92757237]\n",
      " [0.92698574]\n",
      " [0.92545468]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9307145892932484\n",
      "Predicci√≥n : [[0.9242123]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[[0.93347061]\n",
      "  [0.93218857]\n",
      "  [0.93050635]\n",
      "  [0.92998105]\n",
      "  [0.9290849 ]\n",
      "  [0.92757237]\n",
      "  [0.92698574]\n",
      "  [0.92545468]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.228029865771532e-05\n",
      "Predicci√≥n post entrenamiento : [[0.924144]]\n",
      "PERDIDAAAA despues: 4.317249113228172e-05\n",
      "loss en el callback: 0.00018074772378895432, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "ejemplar: [[0.93218857]\n",
      " [0.93050635]\n",
      " [0.92998105]\n",
      " [0.9290849 ]\n",
      " [0.92757237]\n",
      " [0.92698574]\n",
      " [0.92545468]\n",
      " [0.92421228]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.908967222276737\n",
      "Predicci√≥n : [[0.92310005]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[[0.93218857]\n",
      "  [0.93050635]\n",
      "  [0.92998105]\n",
      "  [0.9290849 ]\n",
      "  [0.92757237]\n",
      "  [0.92698574]\n",
      "  [0.92545468]\n",
      "  [0.92421228]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00019973765301983804\n",
      "Predicci√≥n post entrenamiento : [[0.92254245]]\n",
      "PERDIDAAAA despues: 0.00018428757903166115\n",
      "loss en el callback: 0.010354000143706799, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "ejemplar: [[0.93050635]\n",
      " [0.92998105]\n",
      " [0.9290849 ]\n",
      " [0.92757237]\n",
      " [0.92698574]\n",
      " [0.92545468]\n",
      " [0.92421228]\n",
      " [0.92310005]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8816379650841193\n",
      "Predicci√≥n : [[0.9215427]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[[0.93050635]\n",
      "  [0.92998105]\n",
      "  [0.9290849 ]\n",
      "  [0.92757237]\n",
      "  [0.92698574]\n",
      "  [0.92545468]\n",
      "  [0.92421228]\n",
      "  [0.92310005]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001592386164702475\n",
      "Predicci√≥n post entrenamiento : [[0.92099386]]\n",
      "PERDIDAAAA despues: 0.001548884785734117\n",
      "loss en el callback: 0.011288933455944061, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "ejemplar: [[0.92998105]\n",
      " [0.9290849 ]\n",
      " [0.92757237]\n",
      " [0.92698574]\n",
      " [0.92545468]\n",
      " [0.92421228]\n",
      " [0.92310005]\n",
      " [0.9215427 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8487268177153953\n",
      "Predicci√≥n : [[0.9201563]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[[0.92998105]\n",
      "  [0.9290849 ]\n",
      "  [0.92757237]\n",
      "  [0.92698574]\n",
      "  [0.92545468]\n",
      "  [0.92421228]\n",
      "  [0.92310005]\n",
      "  [0.9215427 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005102172028273344\n",
      "Predicci√≥n post entrenamiento : [[0.91928285]]\n",
      "PERDIDAAAA despues: 0.004978155251592398\n",
      "loss en el callback: 0.0293379295617342, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "ejemplar: [[0.9290849 ]\n",
      " [0.92757237]\n",
      " [0.92698574]\n",
      " [0.92545468]\n",
      " [0.92421228]\n",
      " [0.92310005]\n",
      " [0.9215427 ]\n",
      " [0.9201563 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.875260685634848\n",
      "Predicci√≥n : [[0.9182838]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[[0.9290849 ]\n",
      "  [0.92757237]\n",
      "  [0.92698574]\n",
      "  [0.92545468]\n",
      "  [0.92421228]\n",
      "  [0.92310005]\n",
      "  [0.9215427 ]\n",
      "  [0.9201563 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001850987900979817\n",
      "Predicci√≥n post entrenamiento : [[0.9187014]]\n",
      "PERDIDAAAA despues: 0.0018870943458750844\n",
      "loss en el callback: 0.009167851880192757, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "ejemplar: [[0.92757237]\n",
      " [0.92698574]\n",
      " [0.92545468]\n",
      " [0.92421228]\n",
      " [0.92310005]\n",
      " [0.9215427 ]\n",
      " [0.9201563 ]\n",
      " [0.91828382]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9612395688424776\n",
      "Predicci√≥n : [[0.9176116]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[[0.92757237]\n",
      "  [0.92698574]\n",
      "  [0.92545468]\n",
      "  [0.92421228]\n",
      "  [0.92310005]\n",
      "  [0.9215427 ]\n",
      "  [0.9201563 ]\n",
      "  [0.91828382]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0019034004071727395\n",
      "Predicci√≥n post entrenamiento : [[0.9178549]]\n",
      "PERDIDAAAA despues: 0.0018822296988219023\n",
      "loss en el callback: 0.002402509795501828, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "ejemplar: [[0.92698574]\n",
      " [0.92545468]\n",
      " [0.92421228]\n",
      " [0.92310005]\n",
      " [0.9215427 ]\n",
      " [0.9201563 ]\n",
      " [0.91828382]\n",
      " [0.9176116 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9925021123407926\n",
      "Predicci√≥n : [[0.91683364]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[[0.92698574]\n",
      "  [0.92545468]\n",
      "  [0.92421228]\n",
      "  [0.92310005]\n",
      "  [0.9215427 ]\n",
      "  [0.9201563 ]\n",
      "  [0.91828382]\n",
      "  [0.9176116 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005725714843720198\n",
      "Predicci√≥n post entrenamiento : [[0.9172186]]\n",
      "PERDIDAAAA despues: 0.005667600315064192\n",
      "loss en el callback: 0.0065809884108603, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "ejemplar: [[0.92545468]\n",
      " [0.92421228]\n",
      " [0.92310005]\n",
      " [0.9215427 ]\n",
      " [0.9201563 ]\n",
      " [0.91828382]\n",
      " [0.9176116 ]\n",
      " [0.91683364]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.969048316129792\n",
      "Predicci√≥n : [[0.9160039]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[[0.92545468]\n",
      "  [0.92421228]\n",
      "  [0.92310005]\n",
      "  [0.9215427 ]\n",
      "  [0.9201563 ]\n",
      "  [0.91828382]\n",
      "  [0.9176116 ]\n",
      "  [0.91683364]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0028137124609202147\n",
      "Predicci√≥n post entrenamiento : [[0.91640174]]\n",
      "PERDIDAAAA despues: 0.0027716620825231075\n",
      "loss en el callback: 0.006737695075571537, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "ejemplar: [[0.92421228]\n",
      " [0.92310005]\n",
      " [0.9215427 ]\n",
      " [0.9201563 ]\n",
      " [0.91828382]\n",
      " [0.9176116 ]\n",
      " [0.91683364]\n",
      " [0.91600388]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9715476120161949\n",
      "Predicci√≥n : [[0.9152478]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[[0.92421228]\n",
      "  [0.92310005]\n",
      "  [0.9215427 ]\n",
      "  [0.9201563 ]\n",
      "  [0.91828382]\n",
      "  [0.9176116 ]\n",
      "  [0.91683364]\n",
      "  [0.91600388]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0031696681398898363\n",
      "Predicci√≥n post entrenamiento : [[0.9158396]]\n",
      "PERDIDAAAA despues: 0.003103380324319005\n",
      "loss en el callback: 0.018604224547743797, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "ejemplar: [[0.92310005]\n",
      " [0.9215427 ]\n",
      " [0.9201563 ]\n",
      " [0.91828382]\n",
      " [0.9176116 ]\n",
      " [0.91683364]\n",
      " [0.91600388]\n",
      " [0.9152478 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 1.0\n",
      "Predicci√≥n : [[0.91468364]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[[0.92310005]\n",
      "  [0.9215427 ]\n",
      "  [0.9201563 ]\n",
      "  [0.91828382]\n",
      "  [0.9176116 ]\n",
      "  [0.91683364]\n",
      "  [0.91600388]\n",
      "  [0.9152478 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007278881501406431\n",
      "Predicci√≥n post entrenamiento : [[0.9155425]]\n",
      "PERDIDAAAA despues: 0.00713307224214077\n",
      "loss en el callback: 0.03941953927278519, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "ejemplar: [[0.9215427 ]\n",
      " [0.9201563 ]\n",
      " [0.91828382]\n",
      " [0.9176116 ]\n",
      " [0.91683364]\n",
      " [0.91600388]\n",
      " [0.9152478 ]\n",
      " [0.91468364]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9800636522775721\n",
      "Predicci√≥n : [[0.914364]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[[0.9215427 ]\n",
      "  [0.9201563 ]\n",
      "  [0.91828382]\n",
      "  [0.9176116 ]\n",
      "  [0.91683364]\n",
      "  [0.91600388]\n",
      "  [0.9152478 ]\n",
      "  [0.91468364]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004316450096666813\n",
      "Predicci√≥n post entrenamiento : [[0.91471267]]\n",
      "PERDIDAAAA despues: 0.004270754288882017\n",
      "loss en el callback: 0.005729756783694029, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "ejemplar: [[0.9201563 ]\n",
      " [0.91828382]\n",
      " [0.9176116 ]\n",
      " [0.91683364]\n",
      " [0.91600388]\n",
      " [0.9152478 ]\n",
      " [0.91468364]\n",
      " [0.91436398]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.911738568848911\n",
      "Predicci√≥n : [[0.9136629]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[[0.9201563 ]\n",
      "  [0.91828382]\n",
      "  [0.9176116 ]\n",
      "  [0.91683364]\n",
      "  [0.91600388]\n",
      "  [0.9152478 ]\n",
      "  [0.91468364]\n",
      "  [0.91436398]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.7030688417871716e-06\n",
      "Predicci√≥n post entrenamiento : [[0.91416985]]\n",
      "PERDIDAAAA despues: 5.9110907386639155e-06\n",
      "loss en el callback: 0.016683580353856087, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "ejemplar: [[0.91828382]\n",
      " [0.9176116 ]\n",
      " [0.91683364]\n",
      " [0.91600388]\n",
      " [0.9152478 ]\n",
      " [0.91468364]\n",
      " [0.91436398]\n",
      " [0.91366291]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8910857934126422\n",
      "Predicci√≥n : [[0.9132415]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[[0.91828382]\n",
      "  [0.9176116 ]\n",
      "  [0.91683364]\n",
      "  [0.91600388]\n",
      "  [0.9152478 ]\n",
      "  [0.91468364]\n",
      "  [0.91436398]\n",
      "  [0.91366291]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004908751579932868\n",
      "Predicci√≥n post entrenamiento : [[0.91332746]]\n",
      "PERDIDAAAA despues: 0.000494691077619791\n",
      "loss en el callback: 0.00038286333438009024, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "ejemplar: [[0.9176116 ]\n",
      " [0.91683364]\n",
      " [0.91600388]\n",
      " [0.9152478 ]\n",
      " [0.91468364]\n",
      " [0.91436398]\n",
      " [0.91366291]\n",
      " [0.91324151]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9181053259687657\n",
      "Predicci√≥n : [[0.91269857]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[[0.9176116 ]\n",
      "  [0.91683364]\n",
      "  [0.91600388]\n",
      "  [0.9152478 ]\n",
      "  [0.91468364]\n",
      "  [0.91436398]\n",
      "  [0.91366291]\n",
      "  [0.91324151]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.9232807719381526e-05\n",
      "Predicci√≥n post entrenamiento : [[0.9126045]]\n",
      "PERDIDAAAA despues: 3.025872865691781e-05\n",
      "loss en el callback: 0.0003784674918279052, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "ejemplar: [[0.91683364]\n",
      " [0.91600388]\n",
      " [0.9152478 ]\n",
      " [0.91468364]\n",
      " [0.91436398]\n",
      " [0.91366291]\n",
      " [0.91324151]\n",
      " [0.91269857]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9450165163483527\n",
      "Predicci√≥n : [[0.9119797]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[[0.91683364]\n",
      "  [0.91600388]\n",
      "  [0.9152478 ]\n",
      "  [0.91468364]\n",
      "  [0.91436398]\n",
      "  [0.91366291]\n",
      "  [0.91324151]\n",
      "  [0.91269857]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010914320591837168\n",
      "Predicci√≥n post entrenamiento : [[0.91215605]]\n",
      "PERDIDAAAA despues: 0.0010798097355291247\n",
      "loss en el callback: 0.0015782370464876294, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "ejemplar: [[0.91600388]\n",
      " [0.9152478 ]\n",
      " [0.91468364]\n",
      " [0.91436398]\n",
      " [0.91366291]\n",
      " [0.91324151]\n",
      " [0.91269857]\n",
      " [0.91197968]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9718193645514037\n",
      "Predicci√≥n : [[0.9115728]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[[0.91600388]\n",
      "  [0.9152478 ]\n",
      "  [0.91468364]\n",
      "  [0.91436398]\n",
      "  [0.91366291]\n",
      "  [0.91324151]\n",
      "  [0.91269857]\n",
      "  [0.91197968]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0036296439357101917\n",
      "Predicci√≥n post entrenamiento : [[0.91093415]]\n",
      "PERDIDAAAA despues: 0.003707006573677063\n",
      "loss en el callback: 0.015748610720038414, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "ejemplar: [[0.9152478 ]\n",
      " [0.91468364]\n",
      " [0.91436398]\n",
      " [0.91366291]\n",
      " [0.91324151]\n",
      " [0.91269857]\n",
      " [0.91197968]\n",
      " [0.91157281]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9829067192737589\n",
      "Predicci√≥n : [[0.9104189]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[[0.9152478 ]\n",
      "  [0.91468364]\n",
      "  [0.91436398]\n",
      "  [0.91366291]\n",
      "  [0.91324151]\n",
      "  [0.91269857]\n",
      "  [0.91197968]\n",
      "  [0.91157281]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005254476796835661\n",
      "Predicci√≥n post entrenamiento : [[0.9109351]]\n",
      "PERDIDAAAA despues: 0.005179910454899073\n",
      "loss en el callback: 0.012773238122463226, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "ejemplar: [[0.91468364]\n",
      " [0.91436398]\n",
      " [0.91366291]\n",
      " [0.91324151]\n",
      " [0.91269857]\n",
      " [0.91197968]\n",
      " [0.91157281]\n",
      " [0.91041893]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9782785805154182\n",
      "Predicci√≥n : [[0.9104744]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[[0.91468364]\n",
      "  [0.91436398]\n",
      "  [0.91366291]\n",
      "  [0.91324151]\n",
      "  [0.91269857]\n",
      "  [0.91197968]\n",
      "  [0.91157281]\n",
      "  [0.91041893]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004597403574734926\n",
      "Predicci√≥n post entrenamiento : [[0.91031736]]\n",
      "PERDIDAAAA despues: 0.004618726670742035\n",
      "loss en el callback: 0.00101475918199867, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "ejemplar: [[0.05029815]\n",
      " [0.00860651]\n",
      " [0.        ]\n",
      " [0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.049424632939554\n",
      "Predicci√≥n : [[0.20540677]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.05029815]\n",
      "  [0.00860651]\n",
      "  [0.        ]\n",
      "  [0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02433042787015438\n",
      "Predicci√≥n post entrenamiento : [[0.17609353]]\n",
      "PERDIDAAAA despues: 0.016045009717345238\n",
      "loss en el callback: 0.019822122529149055, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "ejemplar: [[0.00860651]\n",
      " [0.        ]\n",
      " [0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.20540677]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.10789185692558968\n",
      "Predicci√≥n : [[0.17099643]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.00860651]\n",
      "  [0.        ]\n",
      "  [0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.20540677]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003982186783105135\n",
      "Predicci√≥n post entrenamiento : [[0.16578001]]\n",
      "PERDIDAAAA despues: 0.0033510378561913967\n",
      "loss en el callback: 0.0008711263071745634, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "ejemplar: [[0.        ]\n",
      " [0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.20540677]\n",
      " [0.17099643]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.13719610119365802\n",
      "Predicci√≥n : [[0.17041035]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[[0.        ]\n",
      "  [0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.20540677]\n",
      "  [0.17099643]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011031868634745479\n",
      "Predicci√≥n post entrenamiento : [[0.1655699]]\n",
      "PERDIDAAAA despues: 0.0008050729520618916\n",
      "loss en el callback: 0.0010937952902168036, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "ejemplar: [[0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.20540677]\n",
      " [0.17099643]\n",
      " [0.17041035]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.13733736574375907\n",
      "Predicci√≥n : [[0.17530307]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[[0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.20540677]\n",
      "  [0.17099643]\n",
      "  [0.17041035]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014413943281397223\n",
      "Predicci√≥n post entrenamiento : [[0.17126247]]\n",
      "PERDIDAAAA despues: 0.001150912488810718\n",
      "loss en el callback: 0.0013897223398089409, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "ejemplar: [[0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.20540677]\n",
      " [0.17099643]\n",
      " [0.17041035]\n",
      " [0.17530307]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.13388569841244483\n",
      "Predicci√≥n : [[0.18024597]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[[0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.20540677]\n",
      "  [0.17099643]\n",
      "  [0.17041035]\n",
      "  [0.17530307]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0021492745727300644\n",
      "Predicci√≥n post entrenamiento : [[0.17569123]]\n",
      "PERDIDAAAA despues: 0.0017477028304710984\n",
      "loss en el callback: 0.002511174650862813, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "ejemplar: [[0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.20540677]\n",
      " [0.17099643]\n",
      " [0.17041035]\n",
      " [0.17530307]\n",
      " [0.18024597]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.12684109919971556\n",
      "Predicci√≥n : [[0.18735364]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[[0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.20540677]\n",
      "  [0.17099643]\n",
      "  [0.17041035]\n",
      "  [0.17530307]\n",
      "  [0.18024597]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0036617678124457598\n",
      "Predicci√≥n post entrenamiento : [[0.18429431]]\n",
      "PERDIDAAAA despues: 0.0033008719328790903\n",
      "loss en el callback: 0.0018605770310387015, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "ejemplar: [[0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.20540677]\n",
      " [0.17099643]\n",
      " [0.17041035]\n",
      " [0.17530307]\n",
      " [0.18024597]\n",
      " [0.18735364]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14756061137847282\n",
      "Predicci√≥n : [[0.20256688]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[[0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.20540677]\n",
      "  [0.17099643]\n",
      "  [0.17041035]\n",
      "  [0.17530307]\n",
      "  [0.18024597]\n",
      "  [0.18735364]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003025689162313938\n",
      "Predicci√≥n post entrenamiento : [[0.19946603]]\n",
      "PERDIDAAAA despues: 0.002694173017516732\n",
      "loss en el callback: 0.0022265538573265076, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "ejemplar: [[0.0202993 ]\n",
      " [0.20540677]\n",
      " [0.17099643]\n",
      " [0.17041035]\n",
      " [0.17530307]\n",
      " [0.18024597]\n",
      " [0.18735364]\n",
      " [0.20256688]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19604423494871648\n",
      "Predicci√≥n : [[0.22441024]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[[0.0202993 ]\n",
      "  [0.20540677]\n",
      "  [0.17099643]\n",
      "  [0.17041035]\n",
      "  [0.17530307]\n",
      "  [0.18024597]\n",
      "  [0.18735364]\n",
      "  [0.20256688]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008046299335546792\n",
      "Predicci√≥n post entrenamiento : [[0.22144349]]\n",
      "PERDIDAAAA despues: 0.0006451220251619816\n",
      "loss en el callback: 0.0022907161619514227, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "ejemplar: [[0.20540677]\n",
      " [0.17099643]\n",
      " [0.17041035]\n",
      " [0.17530307]\n",
      " [0.18024597]\n",
      " [0.18735364]\n",
      " [0.20256688]\n",
      " [0.22441024]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.21688968214535215\n",
      "Predicci√≥n : [[0.25292698]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[[0.20540677]\n",
      "  [0.17099643]\n",
      "  [0.17041035]\n",
      "  [0.17530307]\n",
      "  [0.18024597]\n",
      "  [0.18735364]\n",
      "  [0.20256688]\n",
      "  [0.22441024]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012986867222934961\n",
      "Predicci√≥n post entrenamiento : [[0.2503085]]\n",
      "PERDIDAAAA despues: 0.0011168185155838728\n",
      "loss en el callback: 0.002202691975980997, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "ejemplar: [[0.17099643]\n",
      " [0.17041035]\n",
      " [0.17530307]\n",
      " [0.18024597]\n",
      " [0.18735364]\n",
      " [0.20256688]\n",
      " [0.22441024]\n",
      " [0.25292698]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2100969529683796\n",
      "Predicci√≥n : [[0.24602687]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[[0.17099643]\n",
      "  [0.17041035]\n",
      "  [0.17530307]\n",
      "  [0.18024597]\n",
      "  [0.18735364]\n",
      "  [0.20256688]\n",
      "  [0.22441024]\n",
      "  [0.25292698]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012909590732306242\n",
      "Predicci√≥n post entrenamiento : [[0.2447534]]\n",
      "PERDIDAAAA despues: 0.0012010695645585656\n",
      "loss en el callback: 0.0007986684795469046, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "ejemplar: [[0.17041035]\n",
      " [0.17530307]\n",
      " [0.18024597]\n",
      " [0.18735364]\n",
      " [0.20256688]\n",
      " [0.22441024]\n",
      " [0.25292698]\n",
      " [0.24602687]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2026778474621132\n",
      "Predicci√≥n : [[0.24880028]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[[0.17041035]\n",
      "  [0.17530307]\n",
      "  [0.18024597]\n",
      "  [0.18735364]\n",
      "  [0.20256688]\n",
      "  [0.22441024]\n",
      "  [0.25292698]\n",
      "  [0.24602687]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002127278596162796\n",
      "Predicci√≥n post entrenamiento : [[0.24548261]]\n",
      "PERDIDAAAA despues: 0.0018322477117180824\n",
      "loss en el callback: 0.0050362711772322655, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "ejemplar: [[0.17530307]\n",
      " [0.18024597]\n",
      " [0.18735364]\n",
      " [0.20256688]\n",
      " [0.22441024]\n",
      " [0.25292698]\n",
      " [0.24602687]\n",
      " [0.24880028]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19463236562655295\n",
      "Predicci√≥n : [[0.25173196]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[[0.17530307]\n",
      "  [0.18024597]\n",
      "  [0.18735364]\n",
      "  [0.20256688]\n",
      "  [0.22441024]\n",
      "  [0.25292698]\n",
      "  [0.24602687]\n",
      "  [0.24880028]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0032603638246655464\n",
      "Predicci√≥n post entrenamiento : [[0.24974519]]\n",
      "PERDIDAAAA despues: 0.003037423361092806\n",
      "loss en el callback: 0.0025546394754201174, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "ejemplar: [[0.18024597]\n",
      " [0.18735364]\n",
      " [0.20256688]\n",
      " [0.22441024]\n",
      " [0.25292698]\n",
      " [0.24602687]\n",
      " [0.24880028]\n",
      " [0.25173196]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19407351685692253\n",
      "Predicci√≥n : [[0.25732136]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[[0.18024597]\n",
      "  [0.18735364]\n",
      "  [0.20256688]\n",
      "  [0.22441024]\n",
      "  [0.25292698]\n",
      "  [0.24602687]\n",
      "  [0.24880028]\n",
      "  [0.25173196]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004000289831310511\n",
      "Predicci√≥n post entrenamiento : [[0.2563707]]\n",
      "PERDIDAAAA despues: 0.003880938747897744\n",
      "loss en el callback: 0.0008786667603999376, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "ejemplar: [[0.18735364]\n",
      " [0.20256688]\n",
      " [0.22441024]\n",
      " [0.25292698]\n",
      " [0.24602687]\n",
      " [0.24880028]\n",
      " [0.25173196]\n",
      " [0.25732136]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.20100130115322212\n",
      "Predicci√≥n : [[0.26537585]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[[0.18735364]\n",
      "  [0.20256688]\n",
      "  [0.22441024]\n",
      "  [0.25292698]\n",
      "  [0.24602687]\n",
      "  [0.24880028]\n",
      "  [0.25173196]\n",
      "  [0.25732136]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004144082777202129\n",
      "Predicci√≥n post entrenamiento : [[0.26318488]]\n",
      "PERDIDAAAA despues: 0.003866796847432852\n",
      "loss en el callback: 0.0041244374588131905, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "ejemplar: [[0.20256688]\n",
      " [0.22441024]\n",
      " [0.25292698]\n",
      " [0.24602687]\n",
      " [0.24880028]\n",
      " [0.25173196]\n",
      " [0.25732136]\n",
      " [0.26537585]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19663820581116015\n",
      "Predicci√≥n : [[0.27316073]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[[0.20256688]\n",
      "  [0.22441024]\n",
      "  [0.25292698]\n",
      "  [0.24602687]\n",
      "  [0.24880028]\n",
      "  [0.25173196]\n",
      "  [0.25732136]\n",
      "  [0.26537585]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005855695344507694\n",
      "Predicci√≥n post entrenamiento : [[0.26933658]]\n",
      "PERDIDAAAA despues: 0.005285053048282862\n",
      "loss en el callback: 0.011386490426957607, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "ejemplar: [[0.22441024]\n",
      " [0.25292698]\n",
      " [0.24602687]\n",
      " [0.24880028]\n",
      " [0.25173196]\n",
      " [0.25732136]\n",
      " [0.26537585]\n",
      " [0.27316073]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1809842308307365\n",
      "Predicci√≥n : [[0.27830487]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[[0.22441024]\n",
      "  [0.25292698]\n",
      "  [0.24602687]\n",
      "  [0.24880028]\n",
      "  [0.25173196]\n",
      "  [0.25732136]\n",
      "  [0.26537585]\n",
      "  [0.27316073]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009471308439970016\n",
      "Predicci√≥n post entrenamiento : [[0.27459136]]\n",
      "PERDIDAAAA despues: 0.008762294426560402\n",
      "loss en el callback: 0.013615966774523258, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "ejemplar: [[0.25292698]\n",
      " [0.24602687]\n",
      " [0.24880028]\n",
      " [0.25173196]\n",
      " [0.25732136]\n",
      " [0.26537585]\n",
      " [0.27316073]\n",
      " [0.27830487]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1653904097109329\n",
      "Predicci√≥n : [[0.28059945]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[[0.25292698]\n",
      "  [0.24602687]\n",
      "  [0.24880028]\n",
      "  [0.25173196]\n",
      "  [0.25732136]\n",
      "  [0.26537585]\n",
      "  [0.27316073]\n",
      "  [0.27830487]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013273119926452637\n",
      "Predicci√≥n post entrenamiento : [[0.2767076]]\n",
      "PERDIDAAAA despues: 0.012391513213515282\n",
      "loss en el callback: 0.016501428559422493, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "ejemplar: [[0.24602687]\n",
      " [0.24880028]\n",
      " [0.25173196]\n",
      " [0.25732136]\n",
      " [0.26537585]\n",
      " [0.27316073]\n",
      " [0.27830487]\n",
      " [0.28059945]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14985674245174896\n",
      "Predicci√≥n : [[0.27757248]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[[0.24602687]\n",
      "  [0.24880028]\n",
      "  [0.25173196]\n",
      "  [0.25732136]\n",
      "  [0.26537585]\n",
      "  [0.27316073]\n",
      "  [0.27830487]\n",
      "  [0.28059945]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01631131023168564\n",
      "Predicci√≥n post entrenamiento : [[0.27269125]]\n",
      "PERDIDAAAA despues: 0.01508831512182951\n",
      "loss en el callback: 0.02704201452434063, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "ejemplar: [[0.24880028]\n",
      " [0.25173196]\n",
      " [0.25732136]\n",
      " [0.26537585]\n",
      " [0.27316073]\n",
      " [0.27830487]\n",
      " [0.28059945]\n",
      " [0.27757248]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.15043111479831345\n",
      "Predicci√≥n : [[0.27590573]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[[0.24880028]\n",
      "  [0.25173196]\n",
      "  [0.25732136]\n",
      "  [0.26537585]\n",
      "  [0.27316073]\n",
      "  [0.27830487]\n",
      "  [0.28059945]\n",
      "  [0.27757248]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015743879601359367\n",
      "Predicci√≥n post entrenamiento : [[0.2719939]]\n",
      "PERDIDAAAA despues: 0.014777513220906258\n",
      "loss en el callback: 0.019926708191633224, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "ejemplar: [[0.25173196]\n",
      " [0.25732136]\n",
      " [0.26537585]\n",
      " [0.27316073]\n",
      " [0.27830487]\n",
      " [0.28059945]\n",
      " [0.27757248]\n",
      " [0.27590573]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.16711352675062616\n",
      "Predicci√≥n : [[0.27562028]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[[0.25173196]\n",
      "  [0.25732136]\n",
      "  [0.26537585]\n",
      "  [0.27316073]\n",
      "  [0.27830487]\n",
      "  [0.28059945]\n",
      "  [0.27757248]\n",
      "  [0.27590573]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011773715727031231\n",
      "Predicci√≥n post entrenamiento : [[0.27392513]]\n",
      "PERDIDAAAA despues: 0.01140871737152338\n",
      "loss en el callback: 0.005702664144337177, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "ejemplar: [[0.25732136]\n",
      " [0.26537585]\n",
      " [0.27316073]\n",
      " [0.27830487]\n",
      " [0.28059945]\n",
      " [0.27757248]\n",
      " [0.27590573]\n",
      " [0.27562028]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2022703535675908\n",
      "Predicci√≥n : [[0.27787295]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[[0.25732136]\n",
      "  [0.26537585]\n",
      "  [0.27316073]\n",
      "  [0.27830487]\n",
      "  [0.28059945]\n",
      "  [0.27757248]\n",
      "  [0.27590573]\n",
      "  [0.27562028]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005715751554816961\n",
      "Predicci√≥n post entrenamiento : [[0.2766405]]\n",
      "PERDIDAAAA despues: 0.00553091848269105\n",
      "loss en el callback: 0.0032755795400589705, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "ejemplar: [[0.26537585]\n",
      " [0.27316073]\n",
      " [0.27830487]\n",
      " [0.28059945]\n",
      " [0.27757248]\n",
      " [0.27590573]\n",
      " [0.27562028]\n",
      " [0.27787295]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.25590159524920725\n",
      "Predicci√≥n : [[0.28018868]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[[0.26537585]\n",
      "  [0.27316073]\n",
      "  [0.27830487]\n",
      "  [0.28059945]\n",
      "  [0.27757248]\n",
      "  [0.27590573]\n",
      "  [0.27562028]\n",
      "  [0.27787295]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005898620001971722\n",
      "Predicci√≥n post entrenamiento : [[0.27986848]]\n",
      "PERDIDAAAA despues: 0.0005744113004766405\n",
      "loss en el callback: 0.0002045502042165026, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "ejemplar: [[0.27316073]\n",
      " [0.27830487]\n",
      " [0.28059945]\n",
      " [0.27757248]\n",
      " [0.27590573]\n",
      " [0.27562028]\n",
      " [0.27787295]\n",
      " [0.28018868]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.292688203599549\n",
      "Predicci√≥n : [[0.28223816]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[[0.27316073]\n",
      "  [0.27830487]\n",
      "  [0.28059945]\n",
      "  [0.27757248]\n",
      "  [0.27590573]\n",
      "  [0.27562028]\n",
      "  [0.27787295]\n",
      "  [0.28018868]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001092032398446463\n",
      "Predicci√≥n post entrenamiento : [[0.28238803]]\n",
      "PERDIDAAAA despues: 0.0001060932845575735\n",
      "loss en el callback: 4.846323645324446e-05, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "ejemplar: [[0.27830487]\n",
      " [0.28059945]\n",
      " [0.27757248]\n",
      " [0.27590573]\n",
      " [0.27562028]\n",
      " [0.27787295]\n",
      " [0.28018868]\n",
      " [0.28223816]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31263017861861575\n",
      "Predicci√≥n : [[0.28337225]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[[0.27830487]\n",
      "  [0.28059945]\n",
      "  [0.27757248]\n",
      "  [0.27590573]\n",
      "  [0.27562028]\n",
      "  [0.27787295]\n",
      "  [0.28018868]\n",
      "  [0.28223816]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008560260757803917\n",
      "Predicci√≥n post entrenamiento : [[0.28527826]]\n",
      "PERDIDAAAA despues: 0.000748127291444689\n",
      "loss en el callback: 0.01886434108018875, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "ejemplar: [[0.28059945]\n",
      " [0.27757248]\n",
      " [0.27590573]\n",
      " [0.27562028]\n",
      " [0.27787295]\n",
      " [0.28018868]\n",
      " [0.28223816]\n",
      " [0.28337225]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3109388849116374\n",
      "Predicci√≥n : [[0.2852636]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[[0.28059945]\n",
      "  [0.27757248]\n",
      "  [0.27590573]\n",
      "  [0.27562028]\n",
      "  [0.27787295]\n",
      "  [0.28018868]\n",
      "  [0.28223816]\n",
      "  [0.28337225]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000659220851957798\n",
      "Predicci√≥n post entrenamiento : [[0.2853754]]\n",
      "PERDIDAAAA despues: 0.0006534929270856082\n",
      "loss en el callback: 2.7641171982395463e-05, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "ejemplar: [[0.27757248]\n",
      " [0.27590573]\n",
      " [0.27562028]\n",
      " [0.27787295]\n",
      " [0.28018868]\n",
      " [0.28223816]\n",
      " [0.28337225]\n",
      " [0.2852636 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2876143224786136\n",
      "Predicci√≥n : [[0.28491402]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[[0.27757248]\n",
      "  [0.27590573]\n",
      "  [0.27562028]\n",
      "  [0.27787295]\n",
      "  [0.28018868]\n",
      "  [0.28223816]\n",
      "  [0.28337225]\n",
      "  [0.2852636 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.291615020221798e-06\n",
      "Predicci√≥n post entrenamiento : [[0.28455645]]\n",
      "PERDIDAAAA despues: 9.350552318210248e-06\n",
      "loss en el callback: 0.00029724903288297355, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "ejemplar: [[0.27590573]\n",
      " [0.27562028]\n",
      " [0.27787295]\n",
      " [0.28018868]\n",
      " [0.28223816]\n",
      " [0.28337225]\n",
      " [0.2852636 ]\n",
      " [0.28491402]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.280161647237227\n",
      "Predicci√≥n : [[0.2848872]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[[0.27590573]\n",
      "  [0.27562028]\n",
      "  [0.27787295]\n",
      "  [0.28018868]\n",
      "  [0.28223816]\n",
      "  [0.28337225]\n",
      "  [0.2852636 ]\n",
      "  [0.28491402]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.2330781575874425e-05\n",
      "Predicci√≥n post entrenamiento : [[0.2838337]]\n",
      "PERDIDAAAA despues: 1.3484049304679502e-05\n",
      "loss en el callback: 0.0025797130074352026, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "ejemplar: [[0.27562028]\n",
      " [0.27787295]\n",
      " [0.28018868]\n",
      " [0.28223816]\n",
      " [0.28337225]\n",
      " [0.2852636 ]\n",
      " [0.28491402]\n",
      " [0.28488719]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2885808591874776\n",
      "Predicci√≥n : [[0.28478214]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[[0.27562028]\n",
      "  [0.27787295]\n",
      "  [0.28018868]\n",
      "  [0.28223816]\n",
      "  [0.28337225]\n",
      "  [0.2852636 ]\n",
      "  [0.28491402]\n",
      "  [0.28488719]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.4430298506340478e-05\n",
      "Predicci√≥n post entrenamiento : [[0.28463176]]\n",
      "PERDIDAAAA despues: 1.5595436707371846e-05\n",
      "loss en el callback: 6.829033372923732e-05, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "ejemplar: [[0.27787295]\n",
      " [0.28018868]\n",
      " [0.28223816]\n",
      " [0.28337225]\n",
      " [0.2852636 ]\n",
      " [0.28491402]\n",
      " [0.28488719]\n",
      " [0.28478214]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2824628234730068\n",
      "Predicci√≥n : [[0.28595358]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[[0.27787295]\n",
      "  [0.28018868]\n",
      "  [0.28223816]\n",
      "  [0.28337225]\n",
      "  [0.2852636 ]\n",
      "  [0.28491402]\n",
      "  [0.28488719]\n",
      "  [0.28478214]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.2185308150947094e-05\n",
      "Predicci√≥n post entrenamiento : [[0.2859216]]\n",
      "PERDIDAAAA despues: 1.1963076758547686e-05\n",
      "loss en el callback: 3.553999704308808e-06, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "ejemplar: [[0.28018868]\n",
      " [0.28223816]\n",
      " [0.28337225]\n",
      " [0.2852636 ]\n",
      " [0.28491402]\n",
      " [0.28488719]\n",
      " [0.28478214]\n",
      " [0.28595358]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.26180754009381474\n",
      "Predicci√≥n : [[0.2870407]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[[0.28018868]\n",
      "  [0.28223816]\n",
      "  [0.28337225]\n",
      "  [0.2852636 ]\n",
      "  [0.28491402]\n",
      "  [0.28488719]\n",
      "  [0.28478214]\n",
      "  [0.28595358]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006367133464664221\n",
      "Predicci√≥n post entrenamiento : [[0.28708854]]\n",
      "PERDIDAAAA despues: 0.0006391295464709401\n",
      "loss en el callback: 1.0200140422966797e-05, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "ejemplar: [[0.28223816]\n",
      " [0.28337225]\n",
      " [0.2852636 ]\n",
      " [0.28491402]\n",
      " [0.28488719]\n",
      " [0.28478214]\n",
      " [0.28595358]\n",
      " [0.28704071]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2801212859371977\n",
      "Predicci√≥n : [[0.28792635]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[[0.28223816]\n",
      "  [0.28337225]\n",
      "  [0.2852636 ]\n",
      "  [0.28491402]\n",
      "  [0.28488719]\n",
      "  [0.28478214]\n",
      "  [0.28595358]\n",
      "  [0.28704071]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.091879549785517e-05\n",
      "Predicci√≥n post entrenamiento : [[0.28769073]]\n",
      "PERDIDAAAA despues: 5.729630356654525e-05\n",
      "loss en el callback: 0.00020125851733610034, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "ejemplar: [[0.28337225]\n",
      " [0.2852636 ]\n",
      " [0.28491402]\n",
      " [0.28488719]\n",
      " [0.28478214]\n",
      " [0.28595358]\n",
      " [0.28704071]\n",
      " [0.28792635]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3374040610031557\n",
      "Predicci√≥n : [[0.2882479]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[[0.28337225]\n",
      "  [0.2852636 ]\n",
      "  [0.28491402]\n",
      "  [0.28488719]\n",
      "  [0.28478214]\n",
      "  [0.28595358]\n",
      "  [0.28704071]\n",
      "  [0.28792635]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0024163280613720417\n",
      "Predicci√≥n post entrenamiento : [[0.28880045]]\n",
      "PERDIDAAAA despues: 0.0023623122833669186\n",
      "loss en el callback: 0.0011973902583122253, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "ejemplar: [[0.2852636 ]\n",
      " [0.28491402]\n",
      " [0.28488719]\n",
      " [0.28478214]\n",
      " [0.28595358]\n",
      " [0.28704071]\n",
      " [0.28792635]\n",
      " [0.28824791]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3482298154676272\n",
      "Predicci√≥n : [[0.28924385]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[[0.2852636 ]\n",
      "  [0.28491402]\n",
      "  [0.28488719]\n",
      "  [0.28478214]\n",
      "  [0.28595358]\n",
      "  [0.28704071]\n",
      "  [0.28792635]\n",
      "  [0.28824791]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003479345701634884\n",
      "Predicci√≥n post entrenamiento : [[0.29058993]]\n",
      "PERDIDAAAA despues: 0.003322357777506113\n",
      "loss en el callback: 0.010931426659226418, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "ejemplar: [[0.28491402]\n",
      " [0.28488719]\n",
      " [0.28478214]\n",
      " [0.28595358]\n",
      " [0.28704071]\n",
      " [0.28792635]\n",
      " [0.28824791]\n",
      " [0.28924385]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31259854933061226\n",
      "Predicci√≥n : [[0.29072514]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[[0.28491402]\n",
      "  [0.28488719]\n",
      "  [0.28478214]\n",
      "  [0.28595358]\n",
      "  [0.28704071]\n",
      "  [0.28792635]\n",
      "  [0.28824791]\n",
      "  [0.28924385]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004784462507814169\n",
      "Predicci√≥n post entrenamiento : [[0.28989252]]\n",
      "PERDIDAAAA despues: 0.0005155638791620731\n",
      "loss en el callback: 0.002223208313807845, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "ejemplar: [[0.28488719]\n",
      " [0.28478214]\n",
      " [0.28595358]\n",
      " [0.28704071]\n",
      " [0.28792635]\n",
      " [0.28824791]\n",
      " [0.28924385]\n",
      " [0.29072514]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.34358710169603873\n",
      "Predicci√≥n : [[0.29021916]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[[0.28488719]\n",
      "  [0.28478214]\n",
      "  [0.28595358]\n",
      "  [0.28704071]\n",
      "  [0.28792635]\n",
      "  [0.28824791]\n",
      "  [0.28924385]\n",
      "  [0.29072514]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002848137402907014\n",
      "Predicci√≥n post entrenamiento : [[0.29144663]]\n",
      "PERDIDAAAA despues: 0.0027186290826648474\n",
      "loss en el callback: 0.009871856309473515, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "ejemplar: [[0.28478214]\n",
      " [0.28595358]\n",
      " [0.28704071]\n",
      " [0.28792635]\n",
      " [0.28824791]\n",
      " [0.28924385]\n",
      " [0.29072514]\n",
      " [0.29021916]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.4411954725639069\n",
      "Predicci√≥n : [[0.29192823]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[[0.28478214]\n",
      "  [0.28595358]\n",
      "  [0.28704071]\n",
      "  [0.28792635]\n",
      "  [0.28824791]\n",
      "  [0.28924385]\n",
      "  [0.29072514]\n",
      "  [0.29021916]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022280704230070114\n",
      "Predicci√≥n post entrenamiento : [[0.29408187]]\n",
      "PERDIDAAAA despues: 0.02164240926504135\n",
      "loss en el callback: 0.024096284061670303, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "ejemplar: [[0.28595358]\n",
      " [0.28704071]\n",
      " [0.28792635]\n",
      " [0.28824791]\n",
      " [0.28924385]\n",
      " [0.29072514]\n",
      " [0.29021916]\n",
      " [0.29192823]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5210953230441133\n",
      "Predicci√≥n : [[0.29476726]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[[0.28595358]\n",
      "  [0.28704071]\n",
      "  [0.28792635]\n",
      "  [0.28824791]\n",
      "  [0.28924385]\n",
      "  [0.29072514]\n",
      "  [0.29021916]\n",
      "  [0.29192823]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.051224399358034134\n",
      "Predicci√≥n post entrenamiento : [[0.29768398]]\n",
      "PERDIDAAAA despues: 0.04991263151168823\n",
      "loss en el callback: 0.04125194624066353, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "ejemplar: [[0.28704071]\n",
      " [0.28792635]\n",
      " [0.28824791]\n",
      " [0.28924385]\n",
      " [0.29072514]\n",
      " [0.29021916]\n",
      " [0.29192823]\n",
      " [0.29476726]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5832866531366584\n",
      "Predicci√≥n : [[0.2983115]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[[0.28704071]\n",
      "  [0.28792635]\n",
      "  [0.28824791]\n",
      "  [0.28924385]\n",
      "  [0.29072514]\n",
      "  [0.29021916]\n",
      "  [0.29192823]\n",
      "  [0.29476726]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08121082931756973\n",
      "Predicci√≥n post entrenamiento : [[0.30173188]]\n",
      "PERDIDAAAA despues: 0.07927308231592178\n",
      "loss en el callback: 0.05322326719760895, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "ejemplar: [[0.28792635]\n",
      " [0.28824791]\n",
      " [0.28924385]\n",
      " [0.29072514]\n",
      " [0.29021916]\n",
      " [0.29192823]\n",
      " [0.29476726]\n",
      " [0.2983115 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6089234523540271\n",
      "Predicci√≥n : [[0.30233848]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[[0.28792635]\n",
      "  [0.28824791]\n",
      "  [0.28924385]\n",
      "  [0.29072514]\n",
      "  [0.29021916]\n",
      "  [0.29192823]\n",
      "  [0.29476726]\n",
      "  [0.2983115 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09399433434009552\n",
      "Predicci√≥n post entrenamiento : [[0.30629107]]\n",
      "PERDIDAAAA despues: 0.09158634394407272\n",
      "loss en el callback: 0.10694634169340134, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "ejemplar: [[0.28824791]\n",
      " [0.28924385]\n",
      " [0.29072514]\n",
      " [0.29021916]\n",
      " [0.29192823]\n",
      " [0.29476726]\n",
      " [0.2983115 ]\n",
      " [0.30233848]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.59800572069622\n",
      "Predicci√≥n : [[0.30696908]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[[0.28824791]\n",
      "  [0.28924385]\n",
      "  [0.29072514]\n",
      "  [0.29021916]\n",
      "  [0.29192823]\n",
      "  [0.29476726]\n",
      "  [0.2983115 ]\n",
      "  [0.30233848]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08470232039690018\n",
      "Predicci√≥n post entrenamiento : [[0.31039265]]\n",
      "PERDIDAAAA despues: 0.0827212780714035\n",
      "loss en el callback: 0.06012992933392525, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "ejemplar: [[0.28924385]\n",
      " [0.29072514]\n",
      " [0.29021916]\n",
      " [0.29192823]\n",
      " [0.29476726]\n",
      " [0.2983115 ]\n",
      " [0.30233848]\n",
      " [0.30696908]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5945301858653699\n",
      "Predicci√≥n : [[0.31135428]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[[0.28924385]\n",
      "  [0.29072514]\n",
      "  [0.29021916]\n",
      "  [0.29192823]\n",
      "  [0.29476726]\n",
      "  [0.2983115 ]\n",
      "  [0.30233848]\n",
      "  [0.30696908]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0801885798573494\n",
      "Predicci√≥n post entrenamiento : [[0.31480667]]\n",
      "PERDIDAAAA despues: 0.07824523746967316\n",
      "loss en el callback: 0.07684245705604553, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "ejemplar: [[0.29072514]\n",
      " [0.29021916]\n",
      " [0.29192823]\n",
      " [0.29476726]\n",
      " [0.2983115 ]\n",
      " [0.30233848]\n",
      " [0.30696908]\n",
      " [0.31135428]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5984968478614763\n",
      "Predicci√≥n : [[0.3160093]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[[0.29072514]\n",
      "  [0.29021916]\n",
      "  [0.29192823]\n",
      "  [0.29476726]\n",
      "  [0.2983115 ]\n",
      "  [0.30233848]\n",
      "  [0.30696908]\n",
      "  [0.31135428]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07979921251535416\n",
      "Predicci√≥n post entrenamiento : [[0.31956512]]\n",
      "PERDIDAAAA despues: 0.07780291140079498\n",
      "loss en el callback: 0.09656304866075516, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "ejemplar: [[0.29021916]\n",
      " [0.29192823]\n",
      " [0.29476726]\n",
      " [0.2983115 ]\n",
      " [0.30233848]\n",
      " [0.30696908]\n",
      " [0.31135428]\n",
      " [0.31600931]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6213543446734934\n",
      "Predicci√≥n : [[0.32100654]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[[0.29021916]\n",
      "  [0.29192823]\n",
      "  [0.29476726]\n",
      "  [0.2983115 ]\n",
      "  [0.30233848]\n",
      "  [0.30696908]\n",
      "  [0.31135428]\n",
      "  [0.31600931]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09020880609750748\n",
      "Predicci√≥n post entrenamiento : [[0.32432672]]\n",
      "PERDIDAAAA despues: 0.08822540938854218\n",
      "loss en el callback: 0.05964408814907074, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "ejemplar: [[0.29192823]\n",
      " [0.29476726]\n",
      " [0.2983115 ]\n",
      " [0.30233848]\n",
      " [0.30696908]\n",
      " [0.31135428]\n",
      " [0.31600931]\n",
      " [0.32100654]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.663102676301421\n",
      "Predicci√≥n : [[0.32659933]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[[0.29192823]\n",
      "  [0.29476726]\n",
      "  [0.2983115 ]\n",
      "  [0.30233848]\n",
      "  [0.30696908]\n",
      "  [0.31135428]\n",
      "  [0.31600931]\n",
      "  [0.32100654]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1132345125079155\n",
      "Predicci√≥n post entrenamiento : [[0.33052]]\n",
      "PERDIDAAAA despues: 0.11061123758554459\n",
      "loss en el callback: 0.11622508615255356, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "ejemplar: [[0.29476726]\n",
      " [0.2983115 ]\n",
      " [0.30233848]\n",
      " [0.30696908]\n",
      " [0.31135428]\n",
      " [0.31600931]\n",
      " [0.32100654]\n",
      " [0.32659933]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6928724338328028\n",
      "Predicci√≥n : [[0.33328196]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[[0.29476726]\n",
      "  [0.2983115 ]\n",
      "  [0.30233848]\n",
      "  [0.30696908]\n",
      "  [0.31135428]\n",
      "  [0.31600931]\n",
      "  [0.32100654]\n",
      "  [0.32659933]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12930528819561005\n",
      "Predicci√≥n post entrenamiento : [[0.33737075]]\n",
      "PERDIDAAAA despues: 0.12638142704963684\n",
      "loss en el callback: 0.18879258632659912, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "ejemplar: [[0.2983115 ]\n",
      " [0.30233848]\n",
      " [0.30696908]\n",
      " [0.31135428]\n",
      " [0.31600931]\n",
      " [0.32100654]\n",
      " [0.32659933]\n",
      " [0.33328196]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.710663617267639\n",
      "Predicci√≥n : [[0.3404765]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[[0.2983115 ]\n",
      "  [0.30233848]\n",
      "  [0.30696908]\n",
      "  [0.31135428]\n",
      "  [0.31600931]\n",
      "  [0.32100654]\n",
      "  [0.32659933]\n",
      "  [0.33328196]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13703849911689758\n",
      "Predicci√≥n post entrenamiento : [[0.34456658]]\n",
      "PERDIDAAAA despues: 0.13402703404426575\n",
      "loss en el callback: 0.1141250878572464, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "ejemplar: [[0.30233848]\n",
      " [0.30696908]\n",
      " [0.31135428]\n",
      " [0.31600931]\n",
      " [0.32100654]\n",
      " [0.32659933]\n",
      " [0.33328196]\n",
      " [0.34047651]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7216820581308059\n",
      "Predicci√≥n : [[0.3479508]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[[0.30233848]\n",
      "  [0.30696908]\n",
      "  [0.31135428]\n",
      "  [0.31600931]\n",
      "  [0.32100654]\n",
      "  [0.32659933]\n",
      "  [0.33328196]\n",
      "  [0.34047651]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1396750807762146\n",
      "Predicci√≥n post entrenamiento : [[0.35182697]]\n",
      "PERDIDAAAA despues: 0.13679279386997223\n",
      "loss en el callback: 0.15032054483890533, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "ejemplar: [[0.30696908]\n",
      " [0.31135428]\n",
      " [0.31600931]\n",
      " [0.32100654]\n",
      " [0.32659933]\n",
      " [0.33328196]\n",
      " [0.34047651]\n",
      " [0.34795079]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7259277564223031\n",
      "Predicci√≥n : [[0.3554719]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[[0.30696908]\n",
      "  [0.31135428]\n",
      "  [0.31600931]\n",
      "  [0.32100654]\n",
      "  [0.32659933]\n",
      "  [0.33328196]\n",
      "  [0.34047651]\n",
      "  [0.34795079]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.137237548828125\n",
      "Predicci√≥n post entrenamiento : [[0.35938036]]\n",
      "PERDIDAAAA despues: 0.1343570053577423\n",
      "loss en el callback: 0.1781047135591507, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "ejemplar: [[0.31135428]\n",
      " [0.31600931]\n",
      " [0.32100654]\n",
      " [0.32659933]\n",
      " [0.33328196]\n",
      " [0.34047651]\n",
      " [0.34795079]\n",
      " [0.35547191]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7404318224413275\n",
      "Predicci√≥n : [[0.3632392]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[[0.31135428]\n",
      "  [0.31600931]\n",
      "  [0.32100654]\n",
      "  [0.32659933]\n",
      "  [0.33328196]\n",
      "  [0.34047651]\n",
      "  [0.34795079]\n",
      "  [0.35547191]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14227429032325745\n",
      "Predicci√≥n post entrenamiento : [[0.36724165]]\n",
      "PERDIDAAAA despues: 0.13927091658115387\n",
      "loss en el callback: 0.12217068672180176, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "ejemplar: [[0.31600931]\n",
      " [0.32100654]\n",
      " [0.32659933]\n",
      " [0.33328196]\n",
      " [0.34047651]\n",
      " [0.34795079]\n",
      " [0.35547191]\n",
      " [0.3632392 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7651942561878792\n",
      "Predicci√≥n : [[0.37147185]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[[0.31600931]\n",
      "  [0.32100654]\n",
      "  [0.32659933]\n",
      "  [0.33328196]\n",
      "  [0.34047651]\n",
      "  [0.34795079]\n",
      "  [0.35547191]\n",
      "  [0.3632392 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.15501731634140015\n",
      "Predicci√≥n post entrenamiento : [[0.37548998]]\n",
      "PERDIDAAAA despues: 0.15186940133571625\n",
      "loss en el callback: 0.16211684048175812, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "ejemplar: [[0.32100654]\n",
      " [0.32659933]\n",
      " [0.33328196]\n",
      " [0.34047651]\n",
      " [0.34795079]\n",
      " [0.35547191]\n",
      " [0.3632392 ]\n",
      " [0.37147185]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7447890964420396\n",
      "Predicci√≥n : [[0.38014585]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[[0.32100654]\n",
      "  [0.32659933]\n",
      "  [0.33328196]\n",
      "  [0.34047651]\n",
      "  [0.34795079]\n",
      "  [0.35547191]\n",
      "  [0.3632392 ]\n",
      "  [0.37147185]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13296471536159515\n",
      "Predicci√≥n post entrenamiento : [[0.3836362]]\n",
      "PERDIDAAAA despues: 0.1304314285516739\n",
      "loss en el callback: 0.08662723749876022, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "ejemplar: [[0.32659933]\n",
      " [0.33328196]\n",
      " [0.34047651]\n",
      " [0.34795079]\n",
      " [0.35547191]\n",
      " [0.3632392 ]\n",
      " [0.37147185]\n",
      " [0.38014585]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6792163432038085\n",
      "Predicci√≥n : [[0.38875583]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[[0.32659933]\n",
      "  [0.33328196]\n",
      "  [0.34047651]\n",
      "  [0.34795079]\n",
      "  [0.35547191]\n",
      "  [0.3632392 ]\n",
      "  [0.37147185]\n",
      "  [0.38014585]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0843672975897789\n",
      "Predicci√≥n post entrenamiento : [[0.39170972]]\n",
      "PERDIDAAAA despues: 0.08266004920005798\n",
      "loss en el callback: 0.08748918026685715, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "ejemplar: [[0.33328196]\n",
      " [0.34047651]\n",
      " [0.34795079]\n",
      " [0.35547191]\n",
      " [0.3632392 ]\n",
      " [0.37147185]\n",
      " [0.38014585]\n",
      " [0.38875583]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6746017659154131\n",
      "Predicci√≥n : [[0.39726397]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[[0.33328196]\n",
      "  [0.34047651]\n",
      "  [0.34795079]\n",
      "  [0.35547191]\n",
      "  [0.3632392 ]\n",
      "  [0.37147185]\n",
      "  [0.38014585]\n",
      "  [0.38875583]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07691626250743866\n",
      "Predicci√≥n post entrenamiento : [[0.40020037]]\n",
      "PERDIDAAAA despues: 0.07529614120721817\n",
      "loss en el callback: 0.10083802044391632, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "ejemplar: [[0.34047651]\n",
      " [0.34795079]\n",
      " [0.35547191]\n",
      " [0.3632392 ]\n",
      " [0.37147185]\n",
      " [0.38014585]\n",
      " [0.38875583]\n",
      " [0.39726397]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7309453645768532\n",
      "Predicci√≥n : [[0.40602082]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[[0.34047651]\n",
      "  [0.34795079]\n",
      "  [0.35547191]\n",
      "  [0.3632392 ]\n",
      "  [0.37147185]\n",
      "  [0.38014585]\n",
      "  [0.38875583]\n",
      "  [0.39726397]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10557594895362854\n",
      "Predicci√≥n post entrenamiento : [[0.40912843]]\n",
      "PERDIDAAAA despues: 0.10356613248586655\n",
      "loss en el callback: 0.08015761524438858, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "ejemplar: [[0.34795079]\n",
      " [0.35547191]\n",
      " [0.3632392 ]\n",
      " [0.37147185]\n",
      " [0.38014585]\n",
      " [0.38875583]\n",
      " [0.39726397]\n",
      " [0.40602082]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7467210055914982\n",
      "Predicci√≥n : [[0.41515654]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[[0.34795079]\n",
      "  [0.35547191]\n",
      "  [0.3632392 ]\n",
      "  [0.37147185]\n",
      "  [0.38014585]\n",
      "  [0.38875583]\n",
      "  [0.39726397]\n",
      "  [0.40602082]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10993500798940659\n",
      "Predicci√≥n post entrenamiento : [[0.4183557]]\n",
      "PERDIDAAAA despues: 0.10782378911972046\n",
      "loss en el callback: 0.11688961088657379, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "ejemplar: [[0.35547191]\n",
      " [0.3632392 ]\n",
      " [0.37147185]\n",
      " [0.38014585]\n",
      " [0.38875583]\n",
      " [0.39726397]\n",
      " [0.40602082]\n",
      " [0.41515654]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7219286889593481\n",
      "Predicci√≥n : [[0.42457867]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[[0.35547191]\n",
      "  [0.3632392 ]\n",
      "  [0.37147185]\n",
      "  [0.38014585]\n",
      "  [0.38875583]\n",
      "  [0.39726397]\n",
      "  [0.40602082]\n",
      "  [0.41515654]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08841705322265625\n",
      "Predicci√≥n post entrenamiento : [[0.4274977]]\n",
      "PERDIDAAAA despues: 0.08668961375951767\n",
      "loss en el callback: 0.0886286199092865, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "ejemplar: [[0.3632392 ]\n",
      " [0.37147185]\n",
      " [0.38014585]\n",
      " [0.38875583]\n",
      " [0.39726397]\n",
      " [0.40602082]\n",
      " [0.41515654]\n",
      " [0.42457867]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7199286701160912\n",
      "Predicci√≥n : [[0.43395787]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[[0.3632392 ]\n",
      "  [0.37147185]\n",
      "  [0.38014585]\n",
      "  [0.38875583]\n",
      "  [0.39726397]\n",
      "  [0.40602082]\n",
      "  [0.41515654]\n",
      "  [0.42457867]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08177930116653442\n",
      "Predicci√≥n post entrenamiento : [[0.43679047]]\n",
      "PERDIDAAAA despues: 0.0801672488451004\n",
      "loss en el callback: 0.08546855300664902, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "ejemplar: [[0.37147185]\n",
      " [0.38014585]\n",
      " [0.38875583]\n",
      " [0.39726397]\n",
      " [0.40602082]\n",
      " [0.41515654]\n",
      " [0.42457867]\n",
      " [0.43395787]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7407209490617273\n",
      "Predicci√≥n : [[0.44348362]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[[0.37147185]\n",
      "  [0.38014585]\n",
      "  [0.38875583]\n",
      "  [0.39726397]\n",
      "  [0.40602082]\n",
      "  [0.41515654]\n",
      "  [0.42457867]\n",
      "  [0.43395787]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08835001289844513\n",
      "Predicci√≥n post entrenamiento : [[0.44625413]]\n",
      "PERDIDAAAA despues: 0.08671069145202637\n",
      "loss en el callback: 0.07117746025323868, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "ejemplar: [[0.38014585]\n",
      " [0.38875583]\n",
      " [0.39726397]\n",
      " [0.40602082]\n",
      " [0.41515654]\n",
      " [0.42457867]\n",
      " [0.43395787]\n",
      " [0.44348362]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.736245501831604\n",
      "Predicci√≥n : [[0.45311663]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[[0.38014585]\n",
      "  [0.38875583]\n",
      "  [0.39726397]\n",
      "  [0.40602082]\n",
      "  [0.41515654]\n",
      "  [0.42457867]\n",
      "  [0.43395787]\n",
      "  [0.44348362]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08016196638345718\n",
      "Predicci√≥n post entrenamiento : [[0.4559456]]\n",
      "PERDIDAAAA despues: 0.07856803387403488\n",
      "loss en el callback: 0.1063125729560852, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "ejemplar: [[0.38875583]\n",
      " [0.39726397]\n",
      " [0.40602082]\n",
      " [0.41515654]\n",
      " [0.42457867]\n",
      " [0.43395787]\n",
      " [0.44348362]\n",
      " [0.45311663]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7065023284257214\n",
      "Predicci√≥n : [[0.46290764]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[[0.38875583]\n",
      "  [0.39726397]\n",
      "  [0.40602082]\n",
      "  [0.41515654]\n",
      "  [0.42457867]\n",
      "  [0.43395787]\n",
      "  [0.44348362]\n",
      "  [0.45311663]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.059338364750146866\n",
      "Predicci√≥n post entrenamiento : [[0.4654928]]\n",
      "PERDIDAAAA despues: 0.05808557942509651\n",
      "loss en el callback: 0.09261895716190338, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "ejemplar: [[0.39726397]\n",
      " [0.40602082]\n",
      " [0.41515654]\n",
      " [0.42457867]\n",
      " [0.43395787]\n",
      " [0.44348362]\n",
      " [0.45311663]\n",
      " [0.46290764]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6979451506854685\n",
      "Predicci√≥n : [[0.47260338]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[[0.39726397]\n",
      "  [0.40602082]\n",
      "  [0.41515654]\n",
      "  [0.42457867]\n",
      "  [0.43395787]\n",
      "  [0.44348362]\n",
      "  [0.45311663]\n",
      "  [0.46290764]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05077892541885376\n",
      "Predicci√≥n post entrenamiento : [[0.4744607]]\n",
      "PERDIDAAAA despues: 0.04994531720876694\n",
      "loss en el callback: 0.034670691937208176, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "ejemplar: [[0.40602082]\n",
      " [0.41515654]\n",
      " [0.42457867]\n",
      " [0.43395787]\n",
      " [0.44348362]\n",
      " [0.45311663]\n",
      " [0.46290764]\n",
      " [0.47260338]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7105739686108449\n",
      "Predicci√≥n : [[0.48178473]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[[0.40602082]\n",
      "  [0.41515654]\n",
      "  [0.42457867]\n",
      "  [0.43395787]\n",
      "  [0.44348362]\n",
      "  [0.45311663]\n",
      "  [0.46290764]\n",
      "  [0.47260338]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.052344515919685364\n",
      "Predicci√≥n post entrenamiento : [[0.4840301]]\n",
      "PERDIDAAAA despues: 0.051322124898433685\n",
      "loss en el callback: 0.07774987071752548, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "ejemplar: [[0.41515654]\n",
      " [0.42457867]\n",
      " [0.43395787]\n",
      " [0.44348362]\n",
      " [0.45311663]\n",
      " [0.46290764]\n",
      " [0.47260338]\n",
      " [0.48178473]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7209621522504839\n",
      "Predicci√≥n : [[0.49154705]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[[0.41515654]\n",
      "  [0.42457867]\n",
      "  [0.43395787]\n",
      "  [0.44348362]\n",
      "  [0.45311663]\n",
      "  [0.46290764]\n",
      "  [0.47260338]\n",
      "  [0.48178473]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05263129621744156\n",
      "Predicci√≥n post entrenamiento : [[0.49395353]]\n",
      "PERDIDAAAA despues: 0.05153292417526245\n",
      "loss en el callback: 0.076786570250988, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "ejemplar: [[0.42457867]\n",
      " [0.43395787]\n",
      " [0.44348362]\n",
      " [0.45311663]\n",
      " [0.46290764]\n",
      " [0.47260338]\n",
      " [0.48178473]\n",
      " [0.49154705]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7291097016043858\n",
      "Predicci√≥n : [[0.50159734]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[[0.42457867]\n",
      "  [0.43395787]\n",
      "  [0.44348362]\n",
      "  [0.45311663]\n",
      "  [0.46290764]\n",
      "  [0.47260338]\n",
      "  [0.48178473]\n",
      "  [0.49154705]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.051761873066425323\n",
      "Predicci√≥n post entrenamiento : [[0.5038773]]\n",
      "PERDIDAAAA despues: 0.05072964355349541\n",
      "loss en el callback: 0.07757270336151123, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "ejemplar: [[0.43395787]\n",
      " [0.44348362]\n",
      " [0.45311663]\n",
      " [0.46290764]\n",
      " [0.47260338]\n",
      " [0.48178473]\n",
      " [0.49154705]\n",
      " [0.50159734]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7674259644168786\n",
      "Predicci√≥n : [[0.51159316]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[[0.43395787]\n",
      "  [0.44348362]\n",
      "  [0.45311663]\n",
      "  [0.46290764]\n",
      "  [0.47260338]\n",
      "  [0.48178473]\n",
      "  [0.49154705]\n",
      "  [0.50159734]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06545041501522064\n",
      "Predicci√≥n post entrenamiento : [[0.51362705]]\n",
      "PERDIDAAAA despues: 0.064413882791996\n",
      "loss en el callback: 0.05077795684337616, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "ejemplar: [[0.44348362]\n",
      " [0.45311663]\n",
      " [0.46290764]\n",
      " [0.47260338]\n",
      " [0.48178473]\n",
      " [0.49154705]\n",
      " [0.50159734]\n",
      " [0.51159316]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8359109406879621\n",
      "Predicci√≥n : [[0.52143836]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[[0.44348362]\n",
      "  [0.45311663]\n",
      "  [0.46290764]\n",
      "  [0.47260338]\n",
      "  [0.48178473]\n",
      "  [0.49154705]\n",
      "  [0.50159734]\n",
      "  [0.51159316]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09889298677444458\n",
      "Predicci√≥n post entrenamiento : [[0.52455604]]\n",
      "PERDIDAAAA despues: 0.09694185853004456\n",
      "loss en el callback: 0.1391417533159256, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "ejemplar: [[0.45311663]\n",
      " [0.46290764]\n",
      " [0.47260338]\n",
      " [0.48178473]\n",
      " [0.49154705]\n",
      " [0.50159734]\n",
      " [0.51159316]\n",
      " [0.52143836]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8510103358824123\n",
      "Predicci√≥n : [[0.5324429]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[[0.45311663]\n",
      "  [0.46290764]\n",
      "  [0.47260338]\n",
      "  [0.48178473]\n",
      "  [0.49154705]\n",
      "  [0.50159734]\n",
      "  [0.51159316]\n",
      "  [0.52143836]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10148518532514572\n",
      "Predicci√≥n post entrenamiento : [[0.5354383]]\n",
      "PERDIDAAAA despues: 0.09958570450544357\n",
      "loss en el callback: 0.14351746439933777, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "ejemplar: [[0.46290764]\n",
      " [0.47260338]\n",
      " [0.48178473]\n",
      " [0.49154705]\n",
      " [0.50159734]\n",
      " [0.51159316]\n",
      " [0.52143836]\n",
      " [0.53244293]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8127241500002294\n",
      "Predicci√≥n : [[0.54339147]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[[0.46290764]\n",
      "  [0.47260338]\n",
      "  [0.48178473]\n",
      "  [0.49154705]\n",
      "  [0.50159734]\n",
      "  [0.51159316]\n",
      "  [0.52143836]\n",
      "  [0.53244293]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07254010438919067\n",
      "Predicci√≥n post entrenamiento : [[0.54593724]]\n",
      "PERDIDAAAA despues: 0.07117526978254318\n",
      "loss en el callback: 0.09095744043588638, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "ejemplar: [[0.47260338]\n",
      " [0.48178473]\n",
      " [0.49154705]\n",
      " [0.50159734]\n",
      " [0.51159316]\n",
      " [0.52143836]\n",
      " [0.53244293]\n",
      " [0.54339147]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7863940290280375\n",
      "Predicci√≥n : [[0.5539376]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[[0.47260338]\n",
      "  [0.48178473]\n",
      "  [0.49154705]\n",
      "  [0.50159734]\n",
      "  [0.51159316]\n",
      "  [0.52143836]\n",
      "  [0.53244293]\n",
      "  [0.54339147]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0540359728038311\n",
      "Predicci√≥n post entrenamiento : [[0.55605316]]\n",
      "PERDIDAAAA despues: 0.053056903183460236\n",
      "loss en el callback: 0.06250983476638794, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "ejemplar: [[0.48178473]\n",
      " [0.49154705]\n",
      " [0.50159734]\n",
      " [0.51159316]\n",
      " [0.52143836]\n",
      " [0.53244293]\n",
      " [0.54339147]\n",
      " [0.55393761]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7720199729658365\n",
      "Predicci√≥n : [[0.56415355]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[[0.48178473]\n",
      "  [0.49154705]\n",
      "  [0.50159734]\n",
      "  [0.51159316]\n",
      "  [0.52143836]\n",
      "  [0.53244293]\n",
      "  [0.54339147]\n",
      "  [0.55393761]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04320845380425453\n",
      "Predicci√≥n post entrenamiento : [[0.5664209]]\n",
      "PERDIDAAAA despues: 0.042270977050065994\n",
      "loss en el callback: 0.08558058738708496, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "ejemplar: [[0.49154705]\n",
      " [0.50159734]\n",
      " [0.51159316]\n",
      " [0.52143836]\n",
      " [0.53244293]\n",
      " [0.54339147]\n",
      " [0.55393761]\n",
      " [0.56415355]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8033170564228299\n",
      "Predicci√≥n : [[0.5747962]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[[0.49154705]\n",
      "  [0.50159734]\n",
      "  [0.51159316]\n",
      "  [0.52143836]\n",
      "  [0.53244293]\n",
      "  [0.54339147]\n",
      "  [0.55393761]\n",
      "  [0.56415355]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.052221789956092834\n",
      "Predicci√≥n post entrenamiento : [[0.57685554]]\n",
      "PERDIDAAAA despues: 0.051284823566675186\n",
      "loss en el callback: 0.05761253833770752, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "ejemplar: [[0.50159734]\n",
      " [0.51159316]\n",
      " [0.52143836]\n",
      " [0.53244293]\n",
      " [0.54339147]\n",
      " [0.55393761]\n",
      " [0.56415355]\n",
      " [0.5747962 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8802852793990171\n",
      "Predicci√≥n : [[0.5854044]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[[0.50159734]\n",
      "  [0.51159316]\n",
      "  [0.52143836]\n",
      "  [0.53244293]\n",
      "  [0.54339147]\n",
      "  [0.55393761]\n",
      "  [0.56415355]\n",
      "  [0.5747962 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08695472776889801\n",
      "Predicci√≥n post entrenamiento : [[0.58824307]]\n",
      "PERDIDAAAA despues: 0.0852886438369751\n",
      "loss en el callback: 0.12295831739902496, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "ejemplar: [[0.51159316]\n",
      " [0.52143836]\n",
      " [0.53244293]\n",
      " [0.54339147]\n",
      " [0.55393761]\n",
      " [0.56415355]\n",
      " [0.5747962 ]\n",
      " [0.5854044 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8987051676996881\n",
      "Predicci√≥n : [[0.59692365]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[[0.51159316]\n",
      "  [0.52143836]\n",
      "  [0.53244293]\n",
      "  [0.54339147]\n",
      "  [0.55393761]\n",
      "  [0.56415355]\n",
      "  [0.5747962 ]\n",
      "  [0.5854044 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09107209742069244\n",
      "Predicci√≥n post entrenamiento : [[0.6000184]]\n",
      "PERDIDAAAA despues: 0.08921380341053009\n",
      "loss en el callback: 0.1927611231803894, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "ejemplar: [[0.52143836]\n",
      " [0.53244293]\n",
      " [0.54339147]\n",
      " [0.55393761]\n",
      " [0.56415355]\n",
      " [0.5747962 ]\n",
      " [0.5854044 ]\n",
      " [0.59692365]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8585767213248423\n",
      "Predicci√≥n : [[0.6088746]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[[0.52143836]\n",
      "  [0.53244293]\n",
      "  [0.54339147]\n",
      "  [0.55393761]\n",
      "  [0.56415355]\n",
      "  [0.5747962 ]\n",
      "  [0.5854044 ]\n",
      "  [0.59692365]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06235113739967346\n",
      "Predicci√≥n post entrenamiento : [[0.61093855]]\n",
      "PERDIDAAAA despues: 0.06132465973496437\n",
      "loss en el callback: 0.056549154222011566, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "ejemplar: [[0.53244293]\n",
      " [0.54339147]\n",
      " [0.55393761]\n",
      " [0.56415355]\n",
      " [0.5747962 ]\n",
      " [0.5854044 ]\n",
      " [0.59692365]\n",
      " [0.60887462]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8308762565987861\n",
      "Predicci√≥n : [[0.62004805]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[[0.53244293]\n",
      "  [0.54339147]\n",
      "  [0.55393761]\n",
      "  [0.56415355]\n",
      "  [0.5747962 ]\n",
      "  [0.5854044 ]\n",
      "  [0.59692365]\n",
      "  [0.60887462]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.044448524713516235\n",
      "Predicci√≥n post entrenamiento : [[0.62206054]]\n",
      "PERDIDAAAA despues: 0.04360399395227432\n",
      "loss en el callback: 0.05961000174283981, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "ejemplar: [[0.54339147]\n",
      " [0.55393761]\n",
      " [0.56415355]\n",
      " [0.5747962 ]\n",
      " [0.5854044 ]\n",
      " [0.59692365]\n",
      " [0.60887462]\n",
      " [0.62004805]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8156037735215196\n",
      "Predicci√≥n : [[0.6311527]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[[0.54339147]\n",
      "  [0.55393761]\n",
      "  [0.56415355]\n",
      "  [0.5747962 ]\n",
      "  [0.5854044 ]\n",
      "  [0.59692365]\n",
      "  [0.60887462]\n",
      "  [0.62004805]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03402220830321312\n",
      "Predicci√≥n post entrenamiento : [[0.6330913]]\n",
      "PERDIDAAAA despues: 0.033310819417238235\n",
      "loss en el callback: 0.06731994450092316, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "ejemplar: [[0.55393761]\n",
      " [0.56415355]\n",
      " [0.5747962 ]\n",
      " [0.5854044 ]\n",
      " [0.59692365]\n",
      " [0.60887462]\n",
      " [0.62004805]\n",
      " [0.63115269]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8116992058331503\n",
      "Predicci√≥n : [[0.64219135]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[[0.55393761]\n",
      "  [0.56415355]\n",
      "  [0.5747962 ]\n",
      "  [0.5854044 ]\n",
      "  [0.59692365]\n",
      "  [0.60887462]\n",
      "  [0.62004805]\n",
      "  [0.63115269]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.028732914477586746\n",
      "Predicci√≥n post entrenamiento : [[0.6435088]]\n",
      "PERDIDAAAA despues: 0.028288017958402634\n",
      "loss en el callback: 0.024630850180983543, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "ejemplar: [[0.56415355]\n",
      " [0.5747962 ]\n",
      " [0.5854044 ]\n",
      " [0.59692365]\n",
      " [0.60887462]\n",
      " [0.62004805]\n",
      " [0.63115269]\n",
      " [0.64219135]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8191625535336788\n",
      "Predicci√≥n : [[0.6527428]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[[0.56415355]\n",
      "  [0.5747962 ]\n",
      "  [0.5854044 ]\n",
      "  [0.59692365]\n",
      "  [0.60887462]\n",
      "  [0.62004805]\n",
      "  [0.63115269]\n",
      "  [0.64219135]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.027695531025528908\n",
      "Predicci√≥n post entrenamiento : [[0.6535262]]\n",
      "PERDIDAAAA despues: 0.02743540331721306\n",
      "loss en el callback: 0.007161764893680811, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "ejemplar: [[0.5747962 ]\n",
      " [0.5854044 ]\n",
      " [0.59692365]\n",
      " [0.60887462]\n",
      " [0.62004805]\n",
      " [0.63115269]\n",
      " [0.64219135]\n",
      " [0.6527428 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8218275636038536\n",
      "Predicci√≥n : [[0.6630123]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[[0.5747962 ]\n",
      "  [0.5854044 ]\n",
      "  [0.59692365]\n",
      "  [0.60887462]\n",
      "  [0.62004805]\n",
      "  [0.63115269]\n",
      "  [0.64219135]\n",
      "  [0.6527428 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.025222288444638252\n",
      "Predicci√≥n post entrenamiento : [[0.66404235]]\n",
      "PERDIDAAAA despues: 0.024896180257201195\n",
      "loss en el callback: 0.013735326938331127, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "ejemplar: [[0.5854044 ]\n",
      " [0.59692365]\n",
      " [0.60887462]\n",
      " [0.62004805]\n",
      " [0.63115269]\n",
      " [0.64219135]\n",
      " [0.6527428 ]\n",
      " [0.66301233]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8196942360436743\n",
      "Predicci√≥n : [[0.67369366]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[[0.5854044 ]\n",
      "  [0.59692365]\n",
      "  [0.60887462]\n",
      "  [0.62004805]\n",
      "  [0.63115269]\n",
      "  [0.64219135]\n",
      "  [0.6527428 ]\n",
      "  [0.66301233]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0213161651045084\n",
      "Predicci√≥n post entrenamiento : [[0.6743102]]\n",
      "PERDIDAAAA despues: 0.021136511117219925\n",
      "loss en el callback: 0.005006279330700636, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "ejemplar: [[0.59692365]\n",
      " [0.60887462]\n",
      " [0.62004805]\n",
      " [0.63115269]\n",
      " [0.64219135]\n",
      " [0.6527428 ]\n",
      " [0.66301233]\n",
      " [0.67369366]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8178628420548653\n",
      "Predicci√≥n : [[0.68413943]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[[0.59692365]\n",
      "  [0.60887462]\n",
      "  [0.62004805]\n",
      "  [0.63115269]\n",
      "  [0.64219135]\n",
      "  [0.6527428 ]\n",
      "  [0.66301233]\n",
      "  [0.67369366]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017881957814097404\n",
      "Predicci√≥n post entrenamiento : [[0.6852685]]\n",
      "PERDIDAAAA despues: 0.017581261694431305\n",
      "loss en el callback: 0.021937359124422073, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "ejemplar: [[0.60887462]\n",
      " [0.62004805]\n",
      " [0.63115269]\n",
      " [0.64219135]\n",
      " [0.6527428 ]\n",
      " [0.66301233]\n",
      " [0.67369366]\n",
      " [0.68413943]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8163333816374257\n",
      "Predicci√≥n : [[0.69501686]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[[0.60887462]\n",
      "  [0.62004805]\n",
      "  [0.63115269]\n",
      "  [0.64219135]\n",
      "  [0.6527428 ]\n",
      "  [0.66301233]\n",
      "  [0.67369366]\n",
      "  [0.68413943]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014717691577970982\n",
      "Predicci√≥n post entrenamiento : [[0.69581765]]\n",
      "PERDIDAAAA despues: 0.014524035155773163\n",
      "loss en el callback: 0.009904437698423862, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "ejemplar: [[0.62004805]\n",
      " [0.63115269]\n",
      " [0.64219135]\n",
      " [0.6527428 ]\n",
      " [0.66301233]\n",
      " [0.67369366]\n",
      " [0.68413943]\n",
      " [0.69501686]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8005556061309519\n",
      "Predicci√≥n : [[0.70531905]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[[0.62004805]\n",
      "  [0.63115269]\n",
      "  [0.64219135]\n",
      "  [0.6527428 ]\n",
      "  [0.66301233]\n",
      "  [0.67369366]\n",
      "  [0.68413943]\n",
      "  [0.69501686]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009069998748600483\n",
      "Predicci√≥n post entrenamiento : [[0.7049089]]\n",
      "PERDIDAAAA despues: 0.00914828758686781\n",
      "loss en el callback: 0.002052841242402792, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "ejemplar: [[0.63115269]\n",
      " [0.64219135]\n",
      " [0.6527428 ]\n",
      " [0.66301233]\n",
      " [0.67369366]\n",
      " [0.68413943]\n",
      " [0.69501686]\n",
      " [0.70531905]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7705295155354442\n",
      "Predicci√≥n : [[0.71431863]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[[0.63115269]\n",
      "  [0.64219135]\n",
      "  [0.6527428 ]\n",
      "  [0.66301233]\n",
      "  [0.67369366]\n",
      "  [0.68413943]\n",
      "  [0.69501686]\n",
      "  [0.70531905]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003159662475809455\n",
      "Predicci√≥n post entrenamiento : [[0.7150594]]\n",
      "PERDIDAAAA despues: 0.003076933091506362\n",
      "loss en el callback: 0.008912798017263412, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "ejemplar: [[0.64219135]\n",
      " [0.6527428 ]\n",
      " [0.66301233]\n",
      " [0.67369366]\n",
      " [0.68413943]\n",
      " [0.69501686]\n",
      " [0.70531905]\n",
      " [0.71431863]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7426586795525351\n",
      "Predicci√≥n : [[0.72436315]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[[0.64219135]\n",
      "  [0.6527428 ]\n",
      "  [0.66301233]\n",
      "  [0.67369366]\n",
      "  [0.68413943]\n",
      "  [0.69501686]\n",
      "  [0.70531905]\n",
      "  [0.71431863]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00033472629729658365\n",
      "Predicci√≥n post entrenamiento : [[0.7228315]]\n",
      "PERDIDAAAA despues: 0.00039311734144575894\n",
      "loss en el callback: 0.027668120339512825, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "ejemplar: [[0.6527428 ]\n",
      " [0.66301233]\n",
      " [0.67369366]\n",
      " [0.68413943]\n",
      " [0.69501686]\n",
      " [0.70531905]\n",
      " [0.71431863]\n",
      " [0.72436315]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.716943098182225\n",
      "Predicci√≥n : [[0.7319988]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[[0.6527428 ]\n",
      "  [0.66301233]\n",
      "  [0.67369366]\n",
      "  [0.68413943]\n",
      "  [0.69501686]\n",
      "  [0.70531905]\n",
      "  [0.71431863]\n",
      "  [0.72436315]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002266745868837461\n",
      "Predicci√≥n post entrenamiento : [[0.7319825]]\n",
      "PERDIDAAAA despues: 0.00022618487128056586\n",
      "loss en el callback: 4.20560581915197e-06, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "ejemplar: [[0.66301233]\n",
      " [0.67369366]\n",
      " [0.68413943]\n",
      " [0.69501686]\n",
      " [0.70531905]\n",
      " [0.71431863]\n",
      " [0.72436315]\n",
      " [0.7319988 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7197051306082382\n",
      "Predicci√≥n : [[0.7411009]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[[0.66301233]\n",
      "  [0.67369366]\n",
      "  [0.68413943]\n",
      "  [0.69501686]\n",
      "  [0.70531905]\n",
      "  [0.71431863]\n",
      "  [0.72436315]\n",
      "  [0.7319988 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00045778037747368217\n",
      "Predicci√≥n post entrenamiento : [[0.74095]]\n",
      "PERDIDAAAA despues: 0.0004513450840022415\n",
      "loss en el callback: 0.0003761195403058082, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "ejemplar: [[0.67369366]\n",
      " [0.68413943]\n",
      " [0.69501686]\n",
      " [0.70531905]\n",
      " [0.71431863]\n",
      " [0.72436315]\n",
      " [0.7319988 ]\n",
      " [0.74110091]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7509447768305747\n",
      "Predicci√≥n : [[0.7500467]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[[0.67369366]\n",
      "  [0.68413943]\n",
      "  [0.69501686]\n",
      "  [0.70531905]\n",
      "  [0.71431863]\n",
      "  [0.72436315]\n",
      "  [0.7319988 ]\n",
      "  [0.74110091]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.066245413829165e-07\n",
      "Predicci√≥n post entrenamiento : [[0.7498585]]\n",
      "PERDIDAAAA despues: 1.180036065306922e-06\n",
      "loss en el callback: 0.0005907844752073288, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "ejemplar: [[0.68413943]\n",
      " [0.69501686]\n",
      " [0.70531905]\n",
      " [0.71431863]\n",
      " [0.72436315]\n",
      " [0.7319988 ]\n",
      " [0.74110091]\n",
      " [0.75004667]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.740278139029679\n",
      "Predicci√≥n : [[0.7587601]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[[0.68413943]\n",
      "  [0.69501686]\n",
      "  [0.70531905]\n",
      "  [0.71431863]\n",
      "  [0.72436315]\n",
      "  [0.7319988 ]\n",
      "  [0.74110091]\n",
      "  [0.75004667]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000341583217959851\n",
      "Predicci√≥n post entrenamiento : [[0.75846165]]\n",
      "PERDIDAAAA despues: 0.00033064073068089783\n",
      "loss en el callback: 0.0014414906036108732, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "ejemplar: [[0.69501686]\n",
      " [0.70531905]\n",
      " [0.71431863]\n",
      " [0.72436315]\n",
      " [0.7319988 ]\n",
      " [0.74110091]\n",
      " [0.75004667]\n",
      " [0.75876009]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.687705217205551\n",
      "Predicci√≥n : [[0.7671541]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[[0.69501686]\n",
      "  [0.70531905]\n",
      "  [0.71431863]\n",
      "  [0.72436315]\n",
      "  [0.7319988 ]\n",
      "  [0.74110091]\n",
      "  [0.75004667]\n",
      "  [0.75876009]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00631212443113327\n",
      "Predicci√≥n post entrenamiento : [[0.766618]]\n",
      "PERDIDAAAA despues: 0.006227229256182909\n",
      "loss en el callback: 0.004523534327745438, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "ejemplar: [[0.70531905]\n",
      " [0.71431863]\n",
      " [0.72436315]\n",
      " [0.7319988 ]\n",
      " [0.74110091]\n",
      " [0.75004667]\n",
      " [0.75876009]\n",
      " [0.7671541 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6687695580612426\n",
      "Predicci√≥n : [[0.7748979]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[[0.70531905]\n",
      "  [0.71431863]\n",
      "  [0.72436315]\n",
      "  [0.7319988 ]\n",
      "  [0.74110091]\n",
      "  [0.75004667]\n",
      "  [0.75876009]\n",
      "  [0.7671541 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011263223364949226\n",
      "Predicci√≥n post entrenamiento : [[0.77277994]]\n",
      "PERDIDAAAA despues: 0.010818163864314556\n",
      "loss en el callback: 0.055510055273771286, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "ejemplar: [[0.71431863]\n",
      " [0.72436315]\n",
      " [0.7319988 ]\n",
      " [0.74110091]\n",
      " [0.75004667]\n",
      " [0.75876009]\n",
      " [0.7671541 ]\n",
      " [0.77489787]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6834711615967536\n",
      "Predicci√≥n : [[0.780708]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[[0.71431863]\n",
      "  [0.72436315]\n",
      "  [0.7319988 ]\n",
      "  [0.74110091]\n",
      "  [0.75004667]\n",
      "  [0.75876009]\n",
      "  [0.7671541 ]\n",
      "  [0.77489787]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009455009363591671\n",
      "Predicci√≥n post entrenamiento : [[0.77963555]]\n",
      "PERDIDAAAA despues: 0.009247592650353909\n",
      "loss en el callback: 0.01745346188545227, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "ejemplar: [[0.72436315]\n",
      " [0.7319988 ]\n",
      " [0.74110091]\n",
      " [0.75004667]\n",
      " [0.75876009]\n",
      " [0.7671541 ]\n",
      " [0.77489787]\n",
      " [0.78070801]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6877052172055499\n",
      "Predicci√≥n : [[0.78749585]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[[0.72436315]\n",
      "  [0.7319988 ]\n",
      "  [0.74110091]\n",
      "  [0.75004667]\n",
      "  [0.75876009]\n",
      "  [0.7671541 ]\n",
      "  [0.77489787]\n",
      "  [0.78070801]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009958170354366302\n",
      "Predicci√≥n post entrenamiento : [[0.7870397]]\n",
      "PERDIDAAAA despues: 0.009867338463664055\n",
      "loss en el callback: 0.0039738258346915245, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "ejemplar: [[0.7319988 ]\n",
      " [0.74110091]\n",
      " [0.75004667]\n",
      " [0.75876009]\n",
      " [0.7671541 ]\n",
      " [0.77489787]\n",
      " [0.78070801]\n",
      " [0.78749585]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6814717248876317\n",
      "Predicci√≥n : [[0.7944704]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[[0.7319988 ]\n",
      "  [0.74110091]\n",
      "  [0.75004667]\n",
      "  [0.75876009]\n",
      "  [0.7671541 ]\n",
      "  [0.77489787]\n",
      "  [0.78070801]\n",
      "  [0.78749585]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012768711894750595\n",
      "Predicci√≥n post entrenamiento : [[0.7931643]]\n",
      "PERDIDAAAA despues: 0.012475238181650639\n",
      "loss en el callback: 0.029112981632351875, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "ejemplar: [[0.74110091]\n",
      " [0.75004667]\n",
      " [0.75876009]\n",
      " [0.7671541 ]\n",
      " [0.77489787]\n",
      " [0.78070801]\n",
      " [0.78749585]\n",
      " [0.79447043]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.689261843882625\n",
      "Predicci√≥n : [[0.8007428]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[[0.74110091]\n",
      "  [0.75004667]\n",
      "  [0.75876009]\n",
      "  [0.7671541 ]\n",
      "  [0.77489787]\n",
      "  [0.78070801]\n",
      "  [0.78749585]\n",
      "  [0.79447043]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012428002431988716\n",
      "Predicci√≥n post entrenamiento : [[0.799611]]\n",
      "PERDIDAAAA despues: 0.012176928110420704\n",
      "loss en el callback: 0.02194366231560707, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "ejemplar: [[0.75004667]\n",
      " [0.75876009]\n",
      " [0.7671541 ]\n",
      " [0.77489787]\n",
      " [0.78070801]\n",
      " [0.78749585]\n",
      " [0.79447043]\n",
      " [0.80074281]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7110755741905297\n",
      "Predicci√≥n : [[0.8068723]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[[0.75004667]\n",
      "  [0.75876009]\n",
      "  [0.7671541 ]\n",
      "  [0.77489787]\n",
      "  [0.78070801]\n",
      "  [0.78749585]\n",
      "  [0.79447043]\n",
      "  [0.80074281]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009177008643746376\n",
      "Predicci√≥n post entrenamiento : [[0.8057568]]\n",
      "PERDIDAAAA despues: 0.008964530192315578\n",
      "loss en el callback: 0.02109365537762642, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "ejemplar: [[0.75876009]\n",
      " [0.7671541 ]\n",
      " [0.77489787]\n",
      " [0.78070801]\n",
      " [0.78749585]\n",
      " [0.79447043]\n",
      " [0.80074281]\n",
      " [0.80687231]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7349108623046875\n",
      "Predicci√≥n : [[0.81263435]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[[0.75876009]\n",
      "  [0.7671541 ]\n",
      "  [0.77489787]\n",
      "  [0.78070801]\n",
      "  [0.78749585]\n",
      "  [0.79447043]\n",
      "  [0.80074281]\n",
      "  [0.80687231]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00604094285517931\n",
      "Predicci√≥n post entrenamiento : [[0.8111426]]\n",
      "PERDIDAAAA despues: 0.005811283830553293\n",
      "loss en el callback: 0.03237072005867958, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "ejemplar: [[0.7671541 ]\n",
      " [0.77489787]\n",
      " [0.78070801]\n",
      " [0.78749585]\n",
      " [0.79447043]\n",
      " [0.80074281]\n",
      " [0.80687231]\n",
      " [0.81263435]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7607677082250986\n",
      "Predicci√≥n : [[0.81758773]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[[0.7671541 ]\n",
      "  [0.77489787]\n",
      "  [0.78070801]\n",
      "  [0.78749585]\n",
      "  [0.79447043]\n",
      "  [0.80074281]\n",
      "  [0.80687231]\n",
      "  [0.81263435]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0032285163179039955\n",
      "Predicci√≥n post entrenamiento : [[0.8178641]]\n",
      "PERDIDAAAA despues: 0.0032600013073533773\n",
      "loss en el callback: 0.0016103993402794003, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "ejemplar: [[0.77489787]\n",
      " [0.78070801]\n",
      " [0.78749585]\n",
      " [0.79447043]\n",
      " [0.80074281]\n",
      " [0.80687231]\n",
      " [0.81263435]\n",
      " [0.81758773]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7711170829224028\n",
      "Predicci√≥n : [[0.8238578]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[[0.77489787]\n",
      "  [0.78070801]\n",
      "  [0.78749585]\n",
      "  [0.79447043]\n",
      "  [0.80074281]\n",
      "  [0.80687231]\n",
      "  [0.81263435]\n",
      "  [0.81758773]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0027815806679427624\n",
      "Predicci√≥n post entrenamiento : [[0.824131]]\n",
      "PERDIDAAAA despues: 0.002810475882142782\n",
      "loss en el callback: 0.0018523114267736673, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "ejemplar: [[0.78070801]\n",
      " [0.78749585]\n",
      " [0.79447043]\n",
      " [0.80074281]\n",
      " [0.80687231]\n",
      " [0.81263435]\n",
      " [0.81758773]\n",
      " [0.82385778]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7659589863965997\n",
      "Predicci√≥n : [[0.82975876]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[[0.78070801]\n",
      "  [0.78749585]\n",
      "  [0.79447043]\n",
      "  [0.80074281]\n",
      "  [0.80687231]\n",
      "  [0.81263435]\n",
      "  [0.81758773]\n",
      "  [0.82385778]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00407041423022747\n",
      "Predicci√≥n post entrenamiento : [[0.8298625]]\n",
      "PERDIDAAAA despues: 0.004083658568561077\n",
      "loss en el callback: 0.00021587788069155067, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "ejemplar: [[0.78749585]\n",
      " [0.79447043]\n",
      " [0.80074281]\n",
      " [0.80687231]\n",
      " [0.81263435]\n",
      " [0.81758773]\n",
      " [0.82385778]\n",
      " [0.82975876]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7483323528772654\n",
      "Predicci√≥n : [[0.8356075]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[[0.78749585]\n",
      "  [0.79447043]\n",
      "  [0.80074281]\n",
      "  [0.80687231]\n",
      "  [0.81263435]\n",
      "  [0.81758773]\n",
      "  [0.82385778]\n",
      "  [0.82975876]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007616951130330563\n",
      "Predicci√≥n post entrenamiento : [[0.83352536]]\n",
      "PERDIDAAAA despues: 0.007257843390107155\n",
      "loss en el callback: 0.06094990670681, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "ejemplar: [[0.79447043]\n",
      " [0.80074281]\n",
      " [0.80687231]\n",
      " [0.81263435]\n",
      " [0.81758773]\n",
      " [0.82385778]\n",
      " [0.82975876]\n",
      " [0.83560753]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7182371823643998\n",
      "Predicci√≥n : [[0.8390927]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[[0.79447043]\n",
      "  [0.80074281]\n",
      "  [0.80687231]\n",
      "  [0.81263435]\n",
      "  [0.81758773]\n",
      "  [0.82385778]\n",
      "  [0.82975876]\n",
      "  [0.83560753]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014606053940951824\n",
      "Predicci√≥n post entrenamiento : [[0.8384791]]\n",
      "PERDIDAAAA despues: 0.01445812452584505\n",
      "loss en el callback: 0.0072661940939724445, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "ejemplar: [[0.80074281]\n",
      " [0.80687231]\n",
      " [0.81263435]\n",
      " [0.81758773]\n",
      " [0.82385778]\n",
      " [0.82975876]\n",
      " [0.83560753]\n",
      " [0.83909267]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7089416644962148\n",
      "Predicci√≥n : [[0.8437575]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[[0.80074281]\n",
      "  [0.80687231]\n",
      "  [0.81263435]\n",
      "  [0.81758773]\n",
      "  [0.82385778]\n",
      "  [0.82975876]\n",
      "  [0.83560753]\n",
      "  [0.83909267]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018175318837165833\n",
      "Predicci√≥n post entrenamiento : [[0.84245497]]\n",
      "PERDIDAAAA despues: 0.017825810238718987\n",
      "loss en el callback: 0.032396141439676285, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "ejemplar: [[0.80687231]\n",
      " [0.81263435]\n",
      " [0.81758773]\n",
      " [0.82385778]\n",
      " [0.82975876]\n",
      " [0.83560753]\n",
      " [0.83909267]\n",
      " [0.84375751]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7204457992727099\n",
      "Predicci√≥n : [[0.847573]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[[0.80687231]\n",
      "  [0.81263435]\n",
      "  [0.81758773]\n",
      "  [0.82385778]\n",
      "  [0.82975876]\n",
      "  [0.83560753]\n",
      "  [0.83909267]\n",
      "  [0.84375751]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016161317005753517\n",
      "Predicci√≥n post entrenamiento : [[0.846247]]\n",
      "PERDIDAAAA despues: 0.015825944021344185\n",
      "loss en el callback: 0.030509039759635925, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "ejemplar: [[0.81263435]\n",
      " [0.81758773]\n",
      " [0.82385778]\n",
      " [0.82975876]\n",
      " [0.83560753]\n",
      " [0.83909267]\n",
      " [0.84375751]\n",
      " [0.84757298]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.770615477342717\n",
      "Predicci√≥n : [[0.8511839]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[[0.81263435]\n",
      "  [0.81758773]\n",
      "  [0.82385778]\n",
      "  [0.82975876]\n",
      "  [0.83560753]\n",
      "  [0.83909267]\n",
      "  [0.84375751]\n",
      "  [0.84757298]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006491272244602442\n",
      "Predicci√≥n post entrenamiento : [[0.8502982]]\n",
      "PERDIDAAAA despues: 0.006349343340843916\n",
      "loss en el callback: 0.013826807960867882, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "ejemplar: [[0.81758773]\n",
      " [0.82385778]\n",
      " [0.82975876]\n",
      " [0.83560753]\n",
      " [0.83909267]\n",
      " [0.84375751]\n",
      " [0.84757298]\n",
      " [0.85118389]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8594506987062355\n",
      "Predicci√≥n : [[0.85509086]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[[0.81758773]\n",
      "  [0.82385778]\n",
      "  [0.82975876]\n",
      "  [0.83560753]\n",
      "  [0.83909267]\n",
      "  [0.84375751]\n",
      "  [0.84757298]\n",
      "  [0.85118389]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.9008217350346968e-05\n",
      "Predicci√≥n post entrenamiento : [[0.8546679]]\n",
      "PERDIDAAAA despues: 2.2875135982758366e-05\n",
      "loss en el callback: 0.0030079581774771214, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "ejemplar: [[0.82385778]\n",
      " [0.82975876]\n",
      " [0.83560753]\n",
      " [0.83909267]\n",
      " [0.84375751]\n",
      " [0.84757298]\n",
      " [0.85118389]\n",
      " [0.85509086]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9065410812466371\n",
      "Predicci√≥n : [[0.85947996]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[[0.82385778]\n",
      "  [0.82975876]\n",
      "  [0.83560753]\n",
      "  [0.83909267]\n",
      "  [0.84375751]\n",
      "  [0.84757298]\n",
      "  [0.85118389]\n",
      "  [0.85509086]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0022147514391690493\n",
      "Predicci√≥n post entrenamiento : [[0.86067456]]\n",
      "PERDIDAAAA despues: 0.0021037403494119644\n",
      "loss en el callback: 0.0354585126042366, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "ejemplar: [[0.82975876]\n",
      " [0.83560753]\n",
      " [0.83909267]\n",
      " [0.84375751]\n",
      " [0.84757298]\n",
      " [0.85118389]\n",
      " [0.85509086]\n",
      " [0.85947996]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9118866249639219\n",
      "Predicci√≥n : [[0.8650741]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[[0.82975876]\n",
      "  [0.83560753]\n",
      "  [0.83909267]\n",
      "  [0.84375751]\n",
      "  [0.84757298]\n",
      "  [0.85118389]\n",
      "  [0.85509086]\n",
      "  [0.85947996]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00219141342677176\n",
      "Predicci√≥n post entrenamiento : [[0.8663898]]\n",
      "PERDIDAAAA despues: 0.0020699608139693737\n",
      "loss en el callback: 0.05587003007531166, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "ejemplar: [[0.83560753]\n",
      " [0.83909267]\n",
      " [0.84375751]\n",
      " [0.84757298]\n",
      " [0.85118389]\n",
      " [0.85509086]\n",
      " [0.85947996]\n",
      " [0.8650741 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.904335569053715\n",
      "Predicci√≥n : [[0.8703918]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[[0.83560753]\n",
      "  [0.83909267]\n",
      "  [0.84375751]\n",
      "  [0.84757298]\n",
      "  [0.85118389]\n",
      "  [0.85509086]\n",
      "  [0.85947996]\n",
      "  [0.8650741 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011521796695888042\n",
      "Predicci√≥n post entrenamiento : [[0.86975133]]\n",
      "PERDIDAAAA despues: 0.0011960685951635242\n",
      "loss en el callback: 0.007317774463444948, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "ejemplar: [[0.83909267]\n",
      " [0.84375751]\n",
      " [0.84757298]\n",
      " [0.85118389]\n",
      " [0.85509086]\n",
      " [0.85947996]\n",
      " [0.8650741 ]\n",
      " [0.87039179]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8838879135160167\n",
      "Predicci√≥n : [[0.8733091]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[[0.83909267]\n",
      "  [0.84375751]\n",
      "  [0.84757298]\n",
      "  [0.85118389]\n",
      "  [0.85509086]\n",
      "  [0.85947996]\n",
      "  [0.8650741 ]\n",
      "  [0.87039179]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00011191124212928116\n",
      "Predicci√≥n post entrenamiento : [[0.87220234]]\n",
      "PERDIDAAAA despues: 0.00013655208749696612\n",
      "loss en el callback: 0.02013772539794445, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "ejemplar: [[0.84375751]\n",
      " [0.84757298]\n",
      " [0.85118389]\n",
      " [0.85509086]\n",
      " [0.85947996]\n",
      " [0.8650741 ]\n",
      " [0.87039179]\n",
      " [0.87330908]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9032153489332012\n",
      "Predicci√≥n : [[0.8759532]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[[0.84375751]\n",
      "  [0.84757298]\n",
      "  [0.85118389]\n",
      "  [0.85509086]\n",
      "  [0.85947996]\n",
      "  [0.8650741 ]\n",
      "  [0.87039179]\n",
      "  [0.87330908]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007432248676195741\n",
      "Predicci√≥n post entrenamiento : [[0.8767106]]\n",
      "PERDIDAAAA despues: 0.0007025020313449204\n",
      "loss en el callback: 0.014873714186251163, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "ejemplar: [[0.84757298]\n",
      " [0.85118389]\n",
      " [0.85509086]\n",
      " [0.85947996]\n",
      " [0.8650741 ]\n",
      " [0.87039179]\n",
      " [0.87330908]\n",
      " [0.8759532 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9623178753052692\n",
      "Predicci√≥n : [[0.8803417]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[[0.84757298]\n",
      "  [0.85118389]\n",
      "  [0.85509086]\n",
      "  [0.85947996]\n",
      "  [0.8650741 ]\n",
      "  [0.87039179]\n",
      "  [0.87330908]\n",
      "  [0.8759532 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006720093544572592\n",
      "Predicci√≥n post entrenamiento : [[0.8808061]]\n",
      "PERDIDAAAA despues: 0.006644172593951225\n",
      "loss en el callback: 0.004381416365504265, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "ejemplar: [[0.85118389]\n",
      " [0.85509086]\n",
      " [0.85947996]\n",
      " [0.8650741 ]\n",
      " [0.87039179]\n",
      " [0.87330908]\n",
      " [0.8759532 ]\n",
      " [0.88034171]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.982058820003038\n",
      "Predicci√≥n : [[0.8845464]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[[0.85118389]\n",
      "  [0.85509086]\n",
      "  [0.85947996]\n",
      "  [0.8650741 ]\n",
      "  [0.87039179]\n",
      "  [0.87330908]\n",
      "  [0.8759532 ]\n",
      "  [0.88034171]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00950867310166359\n",
      "Predicci√≥n post entrenamiento : [[0.88615036]]\n",
      "PERDIDAAAA despues: 0.009198433719575405\n",
      "loss en el callback: 0.08058744668960571, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "ejemplar: [[0.85509086]\n",
      " [0.85947996]\n",
      " [0.8650741 ]\n",
      " [0.87039179]\n",
      " [0.87330908]\n",
      " [0.8759532 ]\n",
      " [0.88034171]\n",
      " [0.8845464 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9624381830265082\n",
      "Predicci√≥n : [[0.89006877]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[[0.85509086]\n",
      "  [0.85947996]\n",
      "  [0.8650741 ]\n",
      "  [0.87039179]\n",
      "  [0.87330908]\n",
      "  [0.8759532 ]\n",
      "  [0.88034171]\n",
      "  [0.8845464 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005237329751253128\n",
      "Predicci√≥n post entrenamiento : [[0.88977563]]\n",
      "PERDIDAAAA despues: 0.00527984369546175\n",
      "loss en el callback: 0.001578739145770669, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "ejemplar: [[0.85947996]\n",
      " [0.8650741 ]\n",
      " [0.87039179]\n",
      " [0.87330908]\n",
      " [0.8759532 ]\n",
      " [0.88034171]\n",
      " [0.8845464 ]\n",
      " [0.89006877]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9302512105217627\n",
      "Predicci√≥n : [[0.89380056]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[[0.85947996]\n",
      "  [0.8650741 ]\n",
      "  [0.87039179]\n",
      "  [0.87330908]\n",
      "  [0.8759532 ]\n",
      "  [0.88034171]\n",
      "  [0.8845464 ]\n",
      "  [0.89006877]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001328648068010807\n",
      "Predicci√≥n post entrenamiento : [[0.8945408]]\n",
      "PERDIDAAAA despues: 0.00127523229457438\n",
      "loss en el callback: 0.015566166490316391, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "ejemplar: [[0.8650741 ]\n",
      " [0.87039179]\n",
      " [0.87330908]\n",
      " [0.8759532 ]\n",
      " [0.88034171]\n",
      " [0.8845464 ]\n",
      " [0.89006877]\n",
      " [0.89380056]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.885497902488802\n",
      "Predicci√≥n : [[0.8985339]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[[0.8650741 ]\n",
      "  [0.87039179]\n",
      "  [0.87330908]\n",
      "  [0.8759532 ]\n",
      "  [0.88034171]\n",
      "  [0.8845464 ]\n",
      "  [0.89006877]\n",
      "  [0.89380056]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00016993607277981937\n",
      "Predicci√≥n post entrenamiento : [[0.8994797]]\n",
      "PERDIDAAAA despues: 0.00019548959971871227\n",
      "loss en el callback: 0.033417146652936935, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "ejemplar: [[0.87039179]\n",
      " [0.87330908]\n",
      " [0.8759532 ]\n",
      " [0.88034171]\n",
      " [0.8845464 ]\n",
      " [0.89006877]\n",
      " [0.89380056]\n",
      " [0.89853388]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597025687419927\n",
      "Predicci√≥n : [[0.9030767]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[[0.87039179]\n",
      "  [0.87330908]\n",
      "  [0.8759532 ]\n",
      "  [0.88034171]\n",
      "  [0.8845464 ]\n",
      "  [0.89006877]\n",
      "  [0.89380056]\n",
      "  [0.89853388]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001881314441561699\n",
      "Predicci√≥n post entrenamiento : [[0.9034257]]\n",
      "PERDIDAAAA despues: 0.0019117100164294243\n",
      "loss en el callback: 0.00314092799089849, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "ejemplar: [[0.87330908]\n",
      " [0.8759532 ]\n",
      " [0.88034171]\n",
      " [0.8845464 ]\n",
      " [0.89006877]\n",
      " [0.89380056]\n",
      " [0.89853388]\n",
      " [0.90307671]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8528652092813349\n",
      "Predicci√≥n : [[0.90666354]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[[0.87330908]\n",
      "  [0.8759532 ]\n",
      "  [0.88034171]\n",
      "  [0.8845464 ]\n",
      "  [0.89006877]\n",
      "  [0.89380056]\n",
      "  [0.89853388]\n",
      "  [0.90307671]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0028942590579390526\n",
      "Predicci√≥n post entrenamiento : [[0.90555316]]\n",
      "PERDIDAAAA despues: 0.002776019275188446\n",
      "loss en el callback: 0.02445147931575775, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "ejemplar: [[0.8759532 ]\n",
      " [0.88034171]\n",
      " [0.8845464 ]\n",
      " [0.89006877]\n",
      " [0.89380056]\n",
      " [0.89853388]\n",
      " [0.90307671]\n",
      " [0.90666354]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8585854533368672\n",
      "Predicci√≥n : [[0.90910894]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[[0.8759532 ]\n",
      "  [0.88034171]\n",
      "  [0.8845464 ]\n",
      "  [0.89006877]\n",
      "  [0.89380056]\n",
      "  [0.89853388]\n",
      "  [0.90307671]\n",
      "  [0.90666354]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0025526199024170637\n",
      "Predicci√≥n post entrenamiento : [[0.9087108]]\n",
      "PERDIDAAAA despues: 0.0025125457905232906\n",
      "loss en el callback: 0.004039533901959658, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "ejemplar: [[0.88034171]\n",
      " [0.8845464 ]\n",
      " [0.89006877]\n",
      " [0.89380056]\n",
      " [0.89853388]\n",
      " [0.90307671]\n",
      " [0.90666354]\n",
      " [0.90910894]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8768633009085897\n",
      "Predicci√≥n : [[0.9127173]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[[0.88034171]\n",
      "  [0.8845464 ]\n",
      "  [0.89006877]\n",
      "  [0.89380056]\n",
      "  [0.89853388]\n",
      "  [0.90307671]\n",
      "  [0.90666354]\n",
      "  [0.90910894]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012855080422013998\n",
      "Predicci√≥n post entrenamiento : [[0.911787]]\n",
      "PERDIDAAAA despues: 0.0012196629540994763\n",
      "loss en el callback: 0.020202822983264923, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "ejemplar: [[0.8845464 ]\n",
      " [0.89006877]\n",
      " [0.89380056]\n",
      " [0.89853388]\n",
      " [0.90307671]\n",
      " [0.90666354]\n",
      " [0.90910894]\n",
      " [0.91271728]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8806463966074481\n",
      "Predicci√≥n : [[0.9157745]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[[0.8845464 ]\n",
      "  [0.89006877]\n",
      "  [0.89380056]\n",
      "  [0.89853388]\n",
      "  [0.90307671]\n",
      "  [0.90666354]\n",
      "  [0.90910894]\n",
      "  [0.91271728]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012339845998212695\n",
      "Predicci√≥n post entrenamiento : [[0.9159976]]\n",
      "PERDIDAAAA despues: 0.00124970858450979\n",
      "loss en el callback: 0.0013069889973849058, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "ejemplar: [[0.89006877]\n",
      " [0.89380056]\n",
      " [0.89853388]\n",
      " [0.90307671]\n",
      " [0.90666354]\n",
      " [0.90910894]\n",
      " [0.91271728]\n",
      " [0.91577452]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8699347404334429\n",
      "Predicci√≥n : [[0.9199807]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[[0.89006877]\n",
      "  [0.89380056]\n",
      "  [0.89853388]\n",
      "  [0.90307671]\n",
      "  [0.90666354]\n",
      "  [0.90910894]\n",
      "  [0.91271728]\n",
      "  [0.91577452]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0025045988149940968\n",
      "Predicci√≥n post entrenamiento : [[0.91992354]]\n",
      "PERDIDAAAA despues: 0.0024988807272166014\n",
      "loss en el callback: 9.254919859813526e-05, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "ejemplar: [[0.89380056]\n",
      " [0.89853388]\n",
      " [0.90307671]\n",
      " [0.90666354]\n",
      " [0.90910894]\n",
      " [0.91271728]\n",
      " [0.91577452]\n",
      " [0.9199807 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8465135437340043\n",
      "Predicci√≥n : [[0.92347693]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[[0.89380056]\n",
      "  [0.89853388]\n",
      "  [0.90307671]\n",
      "  [0.90666354]\n",
      "  [0.90910894]\n",
      "  [0.91271728]\n",
      "  [0.91577452]\n",
      "  [0.9199807 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005923359654843807\n",
      "Predicci√≥n post entrenamiento : [[0.9227082]]\n",
      "PERDIDAAAA despues: 0.005805623717606068\n",
      "loss en el callback: 0.01442517526447773, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "ejemplar: [[0.89853388]\n",
      " [0.90307671]\n",
      " [0.90666354]\n",
      " [0.90910894]\n",
      " [0.91271728]\n",
      " [0.91577452]\n",
      " [0.9199807 ]\n",
      " [0.92347693]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8103828065091326\n",
      "Predicci√≥n : [[0.92626876]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[[0.89853388]\n",
      "  [0.90307671]\n",
      "  [0.90666354]\n",
      "  [0.90910894]\n",
      "  [0.91271728]\n",
      "  [0.91577452]\n",
      "  [0.9199807 ]\n",
      "  [0.92347693]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013429558835923672\n",
      "Predicci√≥n post entrenamiento : [[0.9260819]]\n",
      "PERDIDAAAA despues: 0.013386284932494164\n",
      "loss en el callback: 0.0010104915127158165, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "ejemplar: [[0.90307671]\n",
      " [0.90666354]\n",
      " [0.90910894]\n",
      " [0.91271728]\n",
      " [0.91577452]\n",
      " [0.9199807 ]\n",
      " [0.92347693]\n",
      " [0.92626876]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8026111217617493\n",
      "Predicci√≥n : [[0.92933345]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[[0.90307671]\n",
      "  [0.90666354]\n",
      "  [0.90910894]\n",
      "  [0.91271728]\n",
      "  [0.91577452]\n",
      "  [0.9199807 ]\n",
      "  [0.92347693]\n",
      "  [0.92626876]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016058551147580147\n",
      "Predicci√≥n post entrenamiento : [[0.9275094]]\n",
      "PERDIDAAAA despues: 0.015599588863551617\n",
      "loss en el callback: 0.06805059313774109, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "ejemplar: [[0.90666354]\n",
      " [0.90910894]\n",
      " [0.91271728]\n",
      " [0.91577452]\n",
      " [0.9199807 ]\n",
      " [0.92347693]\n",
      " [0.92626876]\n",
      " [0.92933345]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.823198489491854\n",
      "Predicci√≥n : [[0.93044716]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[[0.90666354]\n",
      "  [0.90910894]\n",
      "  [0.91271728]\n",
      "  [0.91577452]\n",
      "  [0.9199807 ]\n",
      "  [0.92347693]\n",
      "  [0.92626876]\n",
      "  [0.92933345]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011502276174724102\n",
      "Predicci√≥n post entrenamiento : [[0.92948157]]\n",
      "PERDIDAAAA despues: 0.011296090669929981\n",
      "loss en el callback: 0.020631777122616768, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "ejemplar: [[0.90910894]\n",
      " [0.91271728]\n",
      " [0.91577452]\n",
      " [0.9199807 ]\n",
      " [0.92347693]\n",
      " [0.92626876]\n",
      " [0.92933345]\n",
      " [0.93044716]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8397204264676091\n",
      "Predicci√≥n : [[0.93232644]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[[0.90910894]\n",
      "  [0.91271728]\n",
      "  [0.91577452]\n",
      "  [0.9199807 ]\n",
      "  [0.92347693]\n",
      "  [0.92626876]\n",
      "  [0.92933345]\n",
      "  [0.93044716]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008575872518122196\n",
      "Predicci√≥n post entrenamiento : [[0.9317876]]\n",
      "PERDIDAAAA despues: 0.00847636628895998\n",
      "loss en el callback: 0.007557484321296215, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "ejemplar: [[0.91271728]\n",
      " [0.91577452]\n",
      " [0.9199807 ]\n",
      " [0.92347693]\n",
      " [0.92626876]\n",
      " [0.92933345]\n",
      " [0.93044716]\n",
      " [0.93232644]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.852176932689015\n",
      "Predicci√≥n : [[0.93483764]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[[0.91271728]\n",
      "  [0.91577452]\n",
      "  [0.9199807 ]\n",
      "  [0.92347693]\n",
      "  [0.92626876]\n",
      "  [0.92933345]\n",
      "  [0.93044716]\n",
      "  [0.93232644]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006832797080278397\n",
      "Predicci√≥n post entrenamiento : [[0.9336195]]\n",
      "PERDIDAAAA despues: 0.006632896140217781\n",
      "loss en el callback: 0.033436261117458344, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "ejemplar: [[0.91577452]\n",
      " [0.9199807 ]\n",
      " [0.92347693]\n",
      " [0.92626876]\n",
      " [0.92933345]\n",
      " [0.93044716]\n",
      " [0.93232644]\n",
      " [0.93483764]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8615626813481295\n",
      "Predicci√≥n : [[0.93652415]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[[0.91577452]\n",
      "  [0.9199807 ]\n",
      "  [0.92347693]\n",
      "  [0.92626876]\n",
      "  [0.92933345]\n",
      "  [0.93044716]\n",
      "  [0.93232644]\n",
      "  [0.93483764]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005619224160909653\n",
      "Predicci√≥n post entrenamiento : [[0.93649286]]\n",
      "PERDIDAAAA despues: 0.005614533554762602\n",
      "loss en el callback: 2.796299486362841e-05, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "ejemplar: [[0.9199807 ]\n",
      " [0.92347693]\n",
      " [0.92626876]\n",
      " [0.92933345]\n",
      " [0.93044716]\n",
      " [0.93232644]\n",
      " [0.93483764]\n",
      " [0.93652415]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8678776724449532\n",
      "Predicci√≥n : [[0.93934804]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[[0.9199807 ]\n",
      "  [0.92347693]\n",
      "  [0.92626876]\n",
      "  [0.92933345]\n",
      "  [0.93044716]\n",
      "  [0.93232644]\n",
      "  [0.93483764]\n",
      "  [0.93652415]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0051080151461064816\n",
      "Predicci√≥n post entrenamiento : [[0.93886995]]\n",
      "PERDIDAAAA despues: 0.005039905197918415\n",
      "loss en el callback: 0.0059072598814964294, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "ejemplar: [[0.92347693]\n",
      " [0.92626876]\n",
      " [0.92933345]\n",
      " [0.93044716]\n",
      " [0.93232644]\n",
      " [0.93483764]\n",
      " [0.93652415]\n",
      " [0.93934804]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8701963127047843\n",
      "Predicci√≥n : [[0.94128746]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[[0.92347693]\n",
      "  [0.92626876]\n",
      "  [0.92933345]\n",
      "  [0.93044716]\n",
      "  [0.93232644]\n",
      "  [0.93483764]\n",
      "  [0.93652415]\n",
      "  [0.93934804]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005053946748375893\n",
      "Predicci√≥n post entrenamiento : [[0.9412933]]\n",
      "PERDIDAAAA despues: 0.00505477748811245\n",
      "loss en el callback: 1.0272174222336616e-06, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "ejemplar: [[0.92626876]\n",
      " [0.92933345]\n",
      " [0.93044716]\n",
      " [0.93232644]\n",
      " [0.93483764]\n",
      " [0.93652415]\n",
      " [0.93934804]\n",
      " [0.94128746]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8685186021276227\n",
      "Predicci√≥n : [[0.943391]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[[0.92626876]\n",
      "  [0.92933345]\n",
      "  [0.93044716]\n",
      "  [0.93232644]\n",
      "  [0.93483764]\n",
      "  [0.93652415]\n",
      "  [0.93934804]\n",
      "  [0.94128746]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005605881568044424\n",
      "Predicci√≥n post entrenamiento : [[0.94249994]]\n",
      "PERDIDAAAA despues: 0.0054732393473386765\n",
      "loss en el callback: 0.019633354619145393, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "ejemplar: [[0.92933345]\n",
      " [0.93044716]\n",
      " [0.93232644]\n",
      " [0.93483764]\n",
      " [0.93652415]\n",
      " [0.93934804]\n",
      " [0.94128746]\n",
      " [0.94339103]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8529880395838255\n",
      "Predicci√≥n : [[0.9444259]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[[0.92933345]\n",
      "  [0.93044716]\n",
      "  [0.93232644]\n",
      "  [0.93483764]\n",
      "  [0.93652415]\n",
      "  [0.93934804]\n",
      "  [0.94128746]\n",
      "  [0.94339103]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00836087390780449\n",
      "Predicci√≥n post entrenamiento : [[0.9431688]]\n",
      "PERDIDAAAA despues: 0.008132568560540676\n",
      "loss en el callback: 0.039525244385004044, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "ejemplar: [[0.93044716]\n",
      " [0.93232644]\n",
      " [0.93483764]\n",
      " [0.93652415]\n",
      " [0.93934804]\n",
      " [0.94128746]\n",
      " [0.94339103]\n",
      " [0.94442588]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8236046250733932\n",
      "Predicci√≥n : [[0.94481134]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[[0.93044716]\n",
      "  [0.93232644]\n",
      "  [0.93483764]\n",
      "  [0.93652415]\n",
      "  [0.93934804]\n",
      "  [0.94128746]\n",
      "  [0.94339103]\n",
      "  [0.94442588]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01469106413424015\n",
      "Predicci√≥n post entrenamiento : [[0.94390154]]\n",
      "PERDIDAAAA despues: 0.014471342787146568\n",
      "loss en el callback: 0.022537291049957275, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "ejemplar: [[0.93232644]\n",
      " [0.93483764]\n",
      " [0.93652415]\n",
      " [0.93934804]\n",
      " [0.94128746]\n",
      " [0.94339103]\n",
      " [0.94442588]\n",
      " [0.94481134]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8032508871761479\n",
      "Predicci√≥n : [[0.9457835]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[[0.93232644]\n",
      "  [0.93483764]\n",
      "  [0.93652415]\n",
      "  [0.93934804]\n",
      "  [0.94128746]\n",
      "  [0.94339103]\n",
      "  [0.94442588]\n",
      "  [0.94481134]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.020315539091825485\n",
      "Predicci√≥n post entrenamiento : [[0.9447542]]\n",
      "PERDIDAAAA despues: 0.020023176446557045\n",
      "loss en el callback: 0.030157746747136116, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "ejemplar: [[0.93483764]\n",
      " [0.93652415]\n",
      " [0.93934804]\n",
      " [0.94128746]\n",
      " [0.94339103]\n",
      " [0.94442588]\n",
      " [0.94481134]\n",
      " [0.9457835 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7919268258920897\n",
      "Predicci√≥n : [[0.94665974]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[[0.93483764]\n",
      "  [0.93652415]\n",
      "  [0.93934804]\n",
      "  [0.94128746]\n",
      "  [0.94339103]\n",
      "  [0.94442588]\n",
      "  [0.94481134]\n",
      "  [0.9457835 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.023942284286022186\n",
      "Predicci√≥n post entrenamiento : [[0.94490576]]\n",
      "PERDIDAAAA despues: 0.023402560502290726\n",
      "loss en el callback: 0.07762329280376434, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "ejemplar: [[0.93652415]\n",
      " [0.93934804]\n",
      " [0.94128746]\n",
      " [0.94339103]\n",
      " [0.94442588]\n",
      " [0.94481134]\n",
      " [0.9457835 ]\n",
      " [0.94665974]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7865023059771536\n",
      "Predicci√≥n : [[0.9466143]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[[0.93652415]\n",
      "  [0.93934804]\n",
      "  [0.94128746]\n",
      "  [0.94339103]\n",
      "  [0.94442588]\n",
      "  [0.94481134]\n",
      "  [0.9457835 ]\n",
      "  [0.94665974]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.025635860860347748\n",
      "Predicci√≥n post entrenamiento : [[0.9460378]]\n",
      "PERDIDAAAA despues: 0.02545158378779888\n",
      "loss en el callback: 0.011551166884601116, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "ejemplar: [[0.93934804]\n",
      " [0.94128746]\n",
      " [0.94339103]\n",
      " [0.94442588]\n",
      " [0.94481134]\n",
      " [0.9457835 ]\n",
      " [0.94665974]\n",
      " [0.94661433]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7869773274313391\n",
      "Predicci√≥n : [[0.94771796]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[[0.93934804]\n",
      "  [0.94128746]\n",
      "  [0.94339103]\n",
      "  [0.94442588]\n",
      "  [0.94481134]\n",
      "  [0.9457835 ]\n",
      "  [0.94665974]\n",
      "  [0.94661433]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.025837544351816177\n",
      "Predicci√≥n post entrenamiento : [[0.94665575]]\n",
      "PERDIDAAAA despues: 0.0254971906542778\n",
      "loss en el callback: 0.03366741165518761, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "ejemplar: [[0.94128746]\n",
      " [0.94339103]\n",
      " [0.94442588]\n",
      " [0.94481134]\n",
      " [0.9457835 ]\n",
      " [0.94665974]\n",
      " [0.94661433]\n",
      " [0.94771796]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7874362431744556\n",
      "Predicci√≥n : [[0.94792354]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[[0.94128746]\n",
      "  [0.94339103]\n",
      "  [0.94442588]\n",
      "  [0.94481134]\n",
      "  [0.9457835 ]\n",
      "  [0.94665974]\n",
      "  [0.94661433]\n",
      "  [0.94771796]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.025756170973181725\n",
      "Predicci√≥n post entrenamiento : [[0.946505]]\n",
      "PERDIDAAAA despues: 0.02530287206172943\n",
      "loss en el callback: 0.05468158796429634, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "ejemplar: [[0.94339103]\n",
      " [0.94442588]\n",
      " [0.94481134]\n",
      " [0.9457835 ]\n",
      " [0.94665974]\n",
      " [0.94661433]\n",
      " [0.94771796]\n",
      " [0.94792354]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7878790532065031\n",
      "Predicci√≥n : [[0.9475228]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[[0.94339103]\n",
      "  [0.94442588]\n",
      "  [0.94481134]\n",
      "  [0.9457835 ]\n",
      "  [0.94665974]\n",
      "  [0.94661433]\n",
      "  [0.94771796]\n",
      "  [0.94792354]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.025486133992671967\n",
      "Predicci√≥n post entrenamiento : [[0.94692135]]\n",
      "PERDIDAAAA despues: 0.025294452905654907\n",
      "loss en el callback: 0.011308029294013977, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "ejemplar: [[0.94442588]\n",
      " [0.94481134]\n",
      " [0.9457835 ]\n",
      " [0.94665974]\n",
      " [0.94661433]\n",
      " [0.94771796]\n",
      " [0.94792354]\n",
      " [0.94752282]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7954532004373992\n",
      "Predicci√≥n : [[0.9475738]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[[0.94442588]\n",
      "  [0.94481134]\n",
      "  [0.9457835 ]\n",
      "  [0.94665974]\n",
      "  [0.94661433]\n",
      "  [0.94771796]\n",
      "  [0.94792354]\n",
      "  [0.94752282]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.023140674456954002\n",
      "Predicci√≥n post entrenamiento : [[0.94754696]]\n",
      "PERDIDAAAA despues: 0.02313251420855522\n",
      "loss en el callback: 2.9419376005535014e-05, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "ejemplar: [[0.94481134]\n",
      " [0.9457835 ]\n",
      " [0.94665974]\n",
      " [0.94661433]\n",
      " [0.94771796]\n",
      " [0.94792354]\n",
      " [0.94752282]\n",
      " [0.94757378]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8101586848671446\n",
      "Predicci√≥n : [[0.9480731]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[[0.94481134]\n",
      "  [0.9457835 ]\n",
      "  [0.94665974]\n",
      "  [0.94661433]\n",
      "  [0.94771796]\n",
      "  [0.94792354]\n",
      "  [0.94752282]\n",
      "  [0.94757378]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019020387902855873\n",
      "Predicci√≥n post entrenamiento : [[0.94727707]]\n",
      "PERDIDAAAA despues: 0.018801454454660416\n",
      "loss en el callback: 0.019520334899425507, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "ejemplar: [[0.9457835 ]\n",
      " [0.94665974]\n",
      " [0.94661433]\n",
      " [0.94771796]\n",
      " [0.94792354]\n",
      " [0.94752282]\n",
      " [0.94757378]\n",
      " [0.94807309]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7668473230866574\n",
      "Predicci√≥n : [[0.9478322]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[[0.9457835 ]\n",
      "  [0.94665974]\n",
      "  [0.94661433]\n",
      "  [0.94771796]\n",
      "  [0.94792354]\n",
      "  [0.94752282]\n",
      "  [0.94757378]\n",
      "  [0.94807309]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0327555388212204\n",
      "Predicci√≥n post entrenamiento : [[0.9467641]]\n",
      "PERDIDAAAA despues: 0.032370053231716156\n",
      "loss en el callback: 0.03554074093699455, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "ejemplar: [[0.94665974]\n",
      " [0.94661433]\n",
      " [0.94771796]\n",
      " [0.94792354]\n",
      " [0.94752282]\n",
      " [0.94757378]\n",
      " [0.94807309]\n",
      " [0.94783223]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6655191150959373\n",
      "Predicci√≥n : [[0.94716084]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[[0.94665974]\n",
      "  [0.94661433]\n",
      "  [0.94771796]\n",
      "  [0.94792354]\n",
      "  [0.94752282]\n",
      "  [0.94757378]\n",
      "  [0.94807309]\n",
      "  [0.94783223]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07932206243276596\n",
      "Predicci√≥n post entrenamiento : [[0.9455982]]\n",
      "PERDIDAAAA despues: 0.07844428718090057\n",
      "loss en el callback: 0.07873496413230896, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "ejemplar: [[0.94661433]\n",
      " [0.94771796]\n",
      " [0.94792354]\n",
      " [0.94752282]\n",
      " [0.94757378]\n",
      " [0.94807309]\n",
      " [0.94783223]\n",
      " [0.94716084]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6360738003224796\n",
      "Predicci√≥n : [[0.94582164]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[[0.94661433]\n",
      "  [0.94771796]\n",
      "  [0.94792354]\n",
      "  [0.94752282]\n",
      "  [0.94757378]\n",
      "  [0.94807309]\n",
      "  [0.94783223]\n",
      "  [0.94716084]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09594371169805527\n",
      "Predicci√≥n post entrenamiento : [[0.94322765]]\n",
      "PERDIDAAAA despues: 0.09434346854686737\n",
      "loss en el callback: 0.19150733947753906, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "ejemplar: [[0.94771796]\n",
      " [0.94792354]\n",
      " [0.94752282]\n",
      " [0.94757378]\n",
      " [0.94807309]\n",
      " [0.94783223]\n",
      " [0.94716084]\n",
      " [0.94582164]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6785113787662842\n",
      "Predicci√≥n : [[0.9434972]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[[0.94771796]\n",
      "  [0.94792354]\n",
      "  [0.94752282]\n",
      "  [0.94757378]\n",
      "  [0.94807309]\n",
      "  [0.94783223]\n",
      "  [0.94716084]\n",
      "  [0.94582164]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07021747529506683\n",
      "Predicci√≥n post entrenamiento : [[0.9412399]]\n",
      "PERDIDAAAA despues: 0.06902626901865005\n",
      "loss en el callback: 0.14743316173553467, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "ejemplar: [[0.94792354]\n",
      " [0.94752282]\n",
      " [0.94757378]\n",
      " [0.94807309]\n",
      " [0.94783223]\n",
      " [0.94716084]\n",
      " [0.94582164]\n",
      " [0.94349718]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6965967339840231\n",
      "Predicci√≥n : [[0.9411862]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[[0.94792354]\n",
      "  [0.94752282]\n",
      "  [0.94757378]\n",
      "  [0.94807309]\n",
      "  [0.94783223]\n",
      "  [0.94716084]\n",
      "  [0.94582164]\n",
      "  [0.94349718]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05982399731874466\n",
      "Predicci√≥n post entrenamiento : [[0.94084805]]\n",
      "PERDIDAAAA despues: 0.059658702462911606\n",
      "loss en el callback: 0.006147254258394241, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "ejemplar: [[0.94752282]\n",
      " [0.94757378]\n",
      " [0.94807309]\n",
      " [0.94783223]\n",
      " [0.94716084]\n",
      " [0.94582164]\n",
      " [0.94349718]\n",
      " [0.94118619]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6903298659756966\n",
      "Predicci√≥n : [[0.9406385]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[[0.94752282]\n",
      "  [0.94757378]\n",
      "  [0.94807309]\n",
      "  [0.94783223]\n",
      "  [0.94716084]\n",
      "  [0.94582164]\n",
      "  [0.94349718]\n",
      "  [0.94118619]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06265441328287125\n",
      "Predicci√≥n post entrenamiento : [[0.9395172]]\n",
      "PERDIDAAAA despues: 0.06209433451294899\n",
      "loss en el callback: 0.04382851719856262, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "ejemplar: [[0.94757378]\n",
      " [0.94807309]\n",
      " [0.94783223]\n",
      " [0.94716084]\n",
      " [0.94582164]\n",
      " [0.94349718]\n",
      " [0.94118619]\n",
      " [0.94063848]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6970473058045382\n",
      "Predicci√≥n : [[0.93926036]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[[0.94757378]\n",
      "  [0.94807309]\n",
      "  [0.94783223]\n",
      "  [0.94716084]\n",
      "  [0.94582164]\n",
      "  [0.94349718]\n",
      "  [0.94118619]\n",
      "  [0.94063848]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.058667171746492386\n",
      "Predicci√≥n post entrenamiento : [[0.9379665]]\n",
      "PERDIDAAAA despues: 0.058042075484991074\n",
      "loss en el callback: 0.05420352891087532, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "ejemplar: [[0.94807309]\n",
      " [0.94783223]\n",
      " [0.94716084]\n",
      " [0.94582164]\n",
      " [0.94349718]\n",
      " [0.94118619]\n",
      " [0.94063848]\n",
      " [0.93926036]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7167490534705484\n",
      "Predicci√≥n : [[0.9374748]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[[0.94807309]\n",
      "  [0.94783223]\n",
      "  [0.94716084]\n",
      "  [0.94582164]\n",
      "  [0.94349718]\n",
      "  [0.94118619]\n",
      "  [0.94063848]\n",
      "  [0.93926036]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04871984198689461\n",
      "Predicci√≥n post entrenamiento : [[0.9347532]]\n",
      "PERDIDAAAA despues: 0.047525789588689804\n",
      "loss en el callback: 0.185870960354805, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "ejemplar: [[0.94783223]\n",
      " [0.94716084]\n",
      " [0.94582164]\n",
      " [0.94349718]\n",
      " [0.94118619]\n",
      " [0.94063848]\n",
      " [0.93926036]\n",
      " [0.93747479]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7490507063998944\n",
      "Predicci√≥n : [[0.93381965]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[[0.94783223]\n",
      "  [0.94716084]\n",
      "  [0.94582164]\n",
      "  [0.94349718]\n",
      "  [0.94118619]\n",
      "  [0.94063848]\n",
      "  [0.93926036]\n",
      "  [0.93747479]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03413957357406616\n",
      "Predicci√≥n post entrenamiento : [[0.93342966]]\n",
      "PERDIDAAAA despues: 0.0339956097304821\n",
      "loss en el callback: 0.006752821616828442, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "ejemplar: [[0.94716084]\n",
      " [0.94582164]\n",
      " [0.94349718]\n",
      " [0.94118619]\n",
      " [0.94063848]\n",
      " [0.93926036]\n",
      " [0.93747479]\n",
      " [0.93381965]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7939522645925762\n",
      "Predicci√≥n : [[0.9321698]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[[0.94716084]\n",
      "  [0.94582164]\n",
      "  [0.94349718]\n",
      "  [0.94118619]\n",
      "  [0.94063848]\n",
      "  [0.93926036]\n",
      "  [0.93747479]\n",
      "  [0.93381965]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01910408027470112\n",
      "Predicci√≥n post entrenamiento : [[0.931532]]\n",
      "PERDIDAAAA despues: 0.01892818510532379\n",
      "loss en el callback: 0.014847890473902225, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "ejemplar: [[0.94582164]\n",
      " [0.94349718]\n",
      " [0.94118619]\n",
      " [0.94063848]\n",
      " [0.93926036]\n",
      " [0.93747479]\n",
      " [0.93381965]\n",
      " [0.9321698 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8547447263586395\n",
      "Predicci√≥n : [[0.92999965]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[[0.94582164]\n",
      "  [0.94349718]\n",
      "  [0.94118619]\n",
      "  [0.94063848]\n",
      "  [0.93926036]\n",
      "  [0.93747479]\n",
      "  [0.93381965]\n",
      "  [0.9321698 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005663302727043629\n",
      "Predicci√≥n post entrenamiento : [[0.9289029]]\n",
      "PERDIDAAAA despues: 0.00549943745136261\n",
      "loss en el callback: 0.036124058067798615, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "ejemplar: [[0.94349718]\n",
      " [0.94118619]\n",
      " [0.94063848]\n",
      " [0.93926036]\n",
      " [0.93747479]\n",
      " [0.93381965]\n",
      " [0.9321698 ]\n",
      " [0.92999965]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9314280916980849\n",
      "Predicci√≥n : [[0.92723835]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[[0.94349718]\n",
      "  [0.94118619]\n",
      "  [0.94063848]\n",
      "  [0.93926036]\n",
      "  [0.93747479]\n",
      "  [0.93381965]\n",
      "  [0.9321698 ]\n",
      "  [0.92999965]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.755383527779486e-05\n",
      "Predicci√≥n post entrenamiento : [[0.9272086]]\n",
      "PERDIDAAAA despues: 1.780394813977182e-05\n",
      "loss en el callback: 3.0603972845710814e-05, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "ejemplar: [[0.94118619]\n",
      " [0.94063848]\n",
      " [0.93926036]\n",
      " [0.93747479]\n",
      " [0.93381965]\n",
      " [0.9321698 ]\n",
      " [0.92999965]\n",
      " [0.92723835]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9627243989762315\n",
      "Predicci√≥n : [[0.9256628]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[[0.94118619]\n",
      "  [0.94063848]\n",
      "  [0.93926036]\n",
      "  [0.93747479]\n",
      "  [0.93381965]\n",
      "  [0.9321698 ]\n",
      "  [0.92999965]\n",
      "  [0.92723835]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013735601678490639\n",
      "Predicci√≥n post entrenamiento : [[0.92570513]]\n",
      "PERDIDAAAA despues: 0.0013704251032322645\n",
      "loss en el callback: 6.455937545979396e-05, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "ejemplar: [[0.94063848]\n",
      " [0.93926036]\n",
      " [0.93747479]\n",
      " [0.93381965]\n",
      " [0.9321698 ]\n",
      " [0.92999965]\n",
      " [0.92723835]\n",
      " [0.92566282]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9486336481930799\n",
      "Predicci√≥n : [[0.92427087]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[[0.94063848]\n",
      "  [0.93926036]\n",
      "  [0.93747479]\n",
      "  [0.93381965]\n",
      "  [0.9321698 ]\n",
      "  [0.92999965]\n",
      "  [0.92723835]\n",
      "  [0.92566282]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005935461376793683\n",
      "Predicci√≥n post entrenamiento : [[0.92411035]]\n",
      "PERDIDAAAA despues: 0.0006013931124471128\n",
      "loss en el callback: 0.0010814908891916275, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "ejemplar: [[0.93926036]\n",
      " [0.93747479]\n",
      " [0.93381965]\n",
      " [0.9321698 ]\n",
      " [0.92999965]\n",
      " [0.92723835]\n",
      " [0.92566282]\n",
      " [0.92427087]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9307145892932484\n",
      "Predicci√≥n : [[0.92227244]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[[0.93926036]\n",
      "  [0.93747479]\n",
      "  [0.93381965]\n",
      "  [0.9321698 ]\n",
      "  [0.92999965]\n",
      "  [0.92723835]\n",
      "  [0.92566282]\n",
      "  [0.92427087]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.127012213459238e-05\n",
      "Predicci√≥n post entrenamiento : [[0.9227894]]\n",
      "PERDIDAAAA despues: 6.280899106059223e-05\n",
      "loss en el callback: 0.013467147015035152, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "ejemplar: [[0.93747479]\n",
      " [0.93381965]\n",
      " [0.9321698 ]\n",
      " [0.92999965]\n",
      " [0.92723835]\n",
      " [0.92566282]\n",
      " [0.92427087]\n",
      " [0.92227244]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.908967222276737\n",
      "Predicci√≥n : [[0.9207302]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[[0.93747479]\n",
      "  [0.93381965]\n",
      "  [0.9321698 ]\n",
      "  [0.92999965]\n",
      "  [0.92723835]\n",
      "  [0.92566282]\n",
      "  [0.92427087]\n",
      "  [0.92227244]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00013836761354468763\n",
      "Predicci√≥n post entrenamiento : [[0.9204513]]\n",
      "PERDIDAAAA despues: 0.00013188424054533243\n",
      "loss en el callback: 0.0028529586270451546, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "ejemplar: [[0.93381965]\n",
      " [0.9321698 ]\n",
      " [0.92999965]\n",
      " [0.92723835]\n",
      " [0.92566282]\n",
      " [0.92427087]\n",
      " [0.92227244]\n",
      " [0.92073017]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8816379650841193\n",
      "Predicci√≥n : [[0.9182759]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[[0.93381965]\n",
      "  [0.9321698 ]\n",
      "  [0.92999965]\n",
      "  [0.92723835]\n",
      "  [0.92566282]\n",
      "  [0.92427087]\n",
      "  [0.92227244]\n",
      "  [0.92073017]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013423358323052526\n",
      "Predicci√≥n post entrenamiento : [[0.9178307]]\n",
      "PERDIDAAAA despues: 0.0013099126517772675\n",
      "loss en el callback: 0.008391750045120716, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "ejemplar: [[0.9321698 ]\n",
      " [0.92999965]\n",
      " [0.92723835]\n",
      " [0.92566282]\n",
      " [0.92427087]\n",
      " [0.92227244]\n",
      " [0.92073017]\n",
      " [0.91827589]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8487268177153953\n",
      "Predicci√≥n : [[0.91608673]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[[0.9321698 ]\n",
      "  [0.92999965]\n",
      "  [0.92723835]\n",
      "  [0.92566282]\n",
      "  [0.92427087]\n",
      "  [0.92227244]\n",
      "  [0.92073017]\n",
      "  [0.91827589]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004537359345704317\n",
      "Predicci√≥n post entrenamiento : [[0.9158316]]\n",
      "PERDIDAAAA despues: 0.0045030564069747925\n",
      "loss en el callback: 0.002749220933765173, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "ejemplar: [[0.92999965]\n",
      " [0.92723835]\n",
      " [0.92566282]\n",
      " [0.92427087]\n",
      " [0.92227244]\n",
      " [0.92073017]\n",
      " [0.91827589]\n",
      " [0.91608673]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.875260685634848\n",
      "Predicci√≥n : [[0.91400415]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[[0.92999965]\n",
      "  [0.92723835]\n",
      "  [0.92566282]\n",
      "  [0.92427087]\n",
      "  [0.92227244]\n",
      "  [0.92073017]\n",
      "  [0.91827589]\n",
      "  [0.91608673]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015010538045316935\n",
      "Predicci√≥n post entrenamiento : [[0.9136279]]\n",
      "PERDIDAAAA despues: 0.0014720429899170995\n",
      "loss en el callback: 0.0058966451324522495, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "ejemplar: [[0.92723835]\n",
      " [0.92566282]\n",
      " [0.92427087]\n",
      " [0.92227244]\n",
      " [0.92073017]\n",
      " [0.91827589]\n",
      " [0.91608673]\n",
      " [0.91400415]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9612395688424776\n",
      "Predicci√≥n : [[0.9118589]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[[0.92723835]\n",
      "  [0.92566282]\n",
      "  [0.92427087]\n",
      "  [0.92227244]\n",
      "  [0.92073017]\n",
      "  [0.91827589]\n",
      "  [0.91608673]\n",
      "  [0.91400415]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0024384495336562395\n",
      "Predicci√≥n post entrenamiento : [[0.9127856]]\n",
      "PERDIDAAAA despues: 0.0023477887734770775\n",
      "loss en el callback: 0.06061454117298126, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "ejemplar: [[0.92566282]\n",
      " [0.92427087]\n",
      " [0.92227244]\n",
      " [0.92073017]\n",
      " [0.91827589]\n",
      " [0.91608673]\n",
      " [0.91400415]\n",
      " [0.91185892]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9925021123407926\n",
      "Predicci√≥n : [[0.9112508]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[[0.92566282]\n",
      "  [0.92427087]\n",
      "  [0.92227244]\n",
      "  [0.92073017]\n",
      "  [0.91827589]\n",
      "  [0.91608673]\n",
      "  [0.91400415]\n",
      "  [0.91185892]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006601767614483833\n",
      "Predicci√≥n post entrenamiento : [[0.91215825]]\n",
      "PERDIDAAAA despues: 0.006455133203417063\n",
      "loss en el callback: 0.046397872269153595, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "ejemplar: [[0.92427087]\n",
      " [0.92227244]\n",
      " [0.92073017]\n",
      " [0.91827589]\n",
      " [0.91608673]\n",
      " [0.91400415]\n",
      " [0.91185892]\n",
      " [0.91125083]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.969048316129792\n",
      "Predicci√≥n : [[0.9105431]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[[0.92427087]\n",
      "  [0.92227244]\n",
      "  [0.92073017]\n",
      "  [0.91827589]\n",
      "  [0.91608673]\n",
      "  [0.91400415]\n",
      "  [0.91185892]\n",
      "  [0.91125083]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0034228628501296043\n",
      "Predicci√≥n post entrenamiento : [[0.9107398]]\n",
      "PERDIDAAAA despues: 0.003399885958060622\n",
      "loss en el callback: 0.0016399205196648836, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "ejemplar: [[0.92227244]\n",
      " [0.92073017]\n",
      " [0.91827589]\n",
      " [0.91608673]\n",
      " [0.91400415]\n",
      " [0.91185892]\n",
      " [0.91125083]\n",
      " [0.91054308]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9715476120161949\n",
      "Predicci√≥n : [[0.90898556]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[[0.92227244]\n",
      "  [0.92073017]\n",
      "  [0.91827589]\n",
      "  [0.91608673]\n",
      "  [0.91400415]\n",
      "  [0.91185892]\n",
      "  [0.91125083]\n",
      "  [0.91054308]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003914009779691696\n",
      "Predicci√≥n post entrenamiento : [[0.90940154]]\n",
      "PERDIDAAAA despues: 0.003862133715301752\n",
      "loss en el callback: 0.008522503077983856, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "ejemplar: [[0.92073017]\n",
      " [0.91827589]\n",
      " [0.91608673]\n",
      " [0.91400415]\n",
      " [0.91185892]\n",
      " [0.91125083]\n",
      " [0.91054308]\n",
      " [0.90898556]]\n",
      "ejemplar: (8, 1)\n",
      "y: 1.0\n",
      "Predicci√≥n : [[0.9076837]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[[0.92073017]\n",
      "  [0.91827589]\n",
      "  [0.91608673]\n",
      "  [0.91400415]\n",
      "  [0.91185892]\n",
      "  [0.91125083]\n",
      "  [0.91054308]\n",
      "  [0.90898556]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008522304706275463\n",
      "Predicci√≥n post entrenamiento : [[0.90852183]]\n",
      "PERDIDAAAA despues: 0.008368255570530891\n",
      "loss en el callback: 0.039045222103595734, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "ejemplar: [[0.91827589]\n",
      " [0.91608673]\n",
      " [0.91400415]\n",
      " [0.91185892]\n",
      " [0.91125083]\n",
      " [0.91054308]\n",
      " [0.90898556]\n",
      " [0.90768367]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9800636522775721\n",
      "Predicci√≥n : [[0.9067379]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[[0.91827589]\n",
      "  [0.91608673]\n",
      "  [0.91400415]\n",
      "  [0.91185892]\n",
      "  [0.91125083]\n",
      "  [0.91054308]\n",
      "  [0.90898556]\n",
      "  [0.90768367]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005376665852963924\n",
      "Predicci√≥n post entrenamiento : [[0.90729904]]\n",
      "PERDIDAAAA despues: 0.005294692236930132\n",
      "loss en el callback: 0.016512751579284668, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "ejemplar: [[0.91608673]\n",
      " [0.91400415]\n",
      " [0.91185892]\n",
      " [0.91125083]\n",
      " [0.91054308]\n",
      " [0.90898556]\n",
      " [0.90768367]\n",
      " [0.90673792]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.911738568848911\n",
      "Predicci√≥n : [[0.905737]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[[0.91608673]\n",
      "  [0.91400415]\n",
      "  [0.91185892]\n",
      "  [0.91125083]\n",
      "  [0.91054308]\n",
      "  [0.90898556]\n",
      "  [0.90768367]\n",
      "  [0.90673792]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.601910430006683e-05\n",
      "Predicci√≥n post entrenamiento : [[0.90484554]]\n",
      "PERDIDAAAA despues: 4.751398228108883e-05\n",
      "loss en el callback: 0.028794923797249794, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "ejemplar: [[0.91400415]\n",
      " [0.91185892]\n",
      " [0.91125083]\n",
      " [0.91054308]\n",
      " [0.90898556]\n",
      " [0.90768367]\n",
      " [0.90673792]\n",
      " [0.90573698]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8910857934126422\n",
      "Predicci√≥n : [[0.90348846]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[[0.91400415]\n",
      "  [0.91185892]\n",
      "  [0.91125083]\n",
      "  [0.91054308]\n",
      "  [0.90898556]\n",
      "  [0.90768367]\n",
      "  [0.90673792]\n",
      "  [0.90573698]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00015382582205347717\n",
      "Predicci√≥n post entrenamiento : [[0.903071]]\n",
      "PERDIDAAAA despues: 0.00014364460366778076\n",
      "loss en el callback: 0.007234514225274324, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "ejemplar: [[0.91185892]\n",
      " [0.91125083]\n",
      " [0.91054308]\n",
      " [0.90898556]\n",
      " [0.90768367]\n",
      " [0.90673792]\n",
      " [0.90573698]\n",
      " [0.90348846]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9181053259687657\n",
      "Predicci√≥n : [[0.90192974]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[[0.91185892]\n",
      "  [0.91125083]\n",
      "  [0.91054308]\n",
      "  [0.90898556]\n",
      "  [0.90768367]\n",
      "  [0.90673792]\n",
      "  [0.90573698]\n",
      "  [0.90348846]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00026164899463765323\n",
      "Predicci√≥n post entrenamiento : [[0.90226686]]\n",
      "PERDIDAAAA despues: 0.00025085630477406085\n",
      "loss en el callback: 0.007135710213333368, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "ejemplar: [[0.91125083]\n",
      " [0.91054308]\n",
      " [0.90898556]\n",
      " [0.90768367]\n",
      " [0.90673792]\n",
      " [0.90573698]\n",
      " [0.90348846]\n",
      " [0.90192974]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9450165163483527\n",
      "Predicci√≥n : [[0.9013873]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[[0.91125083]\n",
      "  [0.91054308]\n",
      "  [0.90898556]\n",
      "  [0.90768367]\n",
      "  [0.90673792]\n",
      "  [0.90573698]\n",
      "  [0.90348846]\n",
      "  [0.90192974]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0019035096047446132\n",
      "Predicci√≥n post entrenamiento : [[0.9016333]]\n",
      "PERDIDAAAA despues: 0.0018821003613993526\n",
      "loss en el callback: 0.002991713583469391, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "ejemplar: [[0.91054308]\n",
      " [0.90898556]\n",
      " [0.90768367]\n",
      " [0.90673792]\n",
      " [0.90573698]\n",
      " [0.90348846]\n",
      " [0.90192974]\n",
      " [0.90138727]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9718193645514037\n",
      "Predicci√≥n : [[0.9005958]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[[0.91054308]\n",
      "  [0.90898556]\n",
      "  [0.90768367]\n",
      "  [0.90673792]\n",
      "  [0.90573698]\n",
      "  [0.90348846]\n",
      "  [0.90192974]\n",
      "  [0.90138727]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005072794854640961\n",
      "Predicci√≥n post entrenamiento : [[0.9017151]]\n",
      "PERDIDAAAA despues: 0.004914604593068361\n",
      "loss en el callback: 0.10252232849597931, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "ejemplar: [[0.90898556]\n",
      " [0.90768367]\n",
      " [0.90673792]\n",
      " [0.90573698]\n",
      " [0.90348846]\n",
      " [0.90192974]\n",
      " [0.90138727]\n",
      " [0.90059578]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9829067192737589\n",
      "Predicci√≥n : [[0.90052104]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[[0.90898556]\n",
      "  [0.90768367]\n",
      "  [0.90673792]\n",
      "  [0.90573698]\n",
      "  [0.90348846]\n",
      "  [0.90192974]\n",
      "  [0.90138727]\n",
      "  [0.90059578]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006787396967411041\n",
      "Predicci√≥n post entrenamiento : [[0.9012778]]\n",
      "PERDIDAAAA despues: 0.006663280539214611\n",
      "loss en el callback: 0.041809629648923874, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "ejemplar: [[0.90768367]\n",
      " [0.90673792]\n",
      " [0.90573698]\n",
      " [0.90348846]\n",
      " [0.90192974]\n",
      " [0.90138727]\n",
      " [0.90059578]\n",
      " [0.90052104]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9782785805154182\n",
      "Predicci√≥n : [[0.9001639]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[[0.90768367]\n",
      "  [0.90673792]\n",
      "  [0.90573698]\n",
      "  [0.90348846]\n",
      "  [0.90192974]\n",
      "  [0.90138727]\n",
      "  [0.90059578]\n",
      "  [0.90052104]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006101904436945915\n",
      "Predicci√≥n post entrenamiento : [[0.8997088]]\n",
      "PERDIDAAAA despues: 0.006173208821564913\n",
      "loss en el callback: 0.007628306280821562, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "ejemplar: [[0.05029815]\n",
      " [0.00860651]\n",
      " [0.        ]\n",
      " [0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.049424632939554\n",
      "Predicci√≥n : [[0.20087117]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.05029815]\n",
      "  [0.00860651]\n",
      "  [0.        ]\n",
      "  [0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022936053574085236\n",
      "Predicci√≥n post entrenamiento : [[0.16863361]]\n",
      "PERDIDAAAA despues: 0.014210780151188374\n",
      "loss en el callback: 0.0219894889742136, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "ejemplar: [[0.00860651]\n",
      " [0.        ]\n",
      " [0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.20087117]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.10789185692558968\n",
      "Predicci√≥n : [[0.16351454]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.00860651]\n",
      "  [0.        ]\n",
      "  [0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.20087117]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0030938826967030764\n",
      "Predicci√≥n post entrenamiento : [[0.14839615]]\n",
      "PERDIDAAAA despues: 0.001640597591176629\n",
      "loss en el callback: 0.004168685991317034, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "ejemplar: [[0.        ]\n",
      " [0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.20087117]\n",
      " [0.16351454]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.13719610119365802\n",
      "Predicci√≥n : [[0.15292768]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[[0.        ]\n",
      "  [0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.20087117]\n",
      "  [0.16351454]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002474828506819904\n",
      "Predicci√≥n post entrenamiento : [[0.1516374]]\n",
      "PERDIDAAAA despues: 0.0002085514715872705\n",
      "loss en el callback: 8.1640224379953e-05, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "ejemplar: [[0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.20087117]\n",
      " [0.16351454]\n",
      " [0.15292768]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.13733736574375907\n",
      "Predicci√≥n : [[0.16111286]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[[0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.20087117]\n",
      "  [0.16351454]\n",
      "  [0.15292768]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005652738618664443\n",
      "Predicci√≥n post entrenamiento : [[0.15737867]]\n",
      "PERDIDAAAA despues: 0.0004016537859570235\n",
      "loss en el callback: 0.0011021506506949663, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "ejemplar: [[0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.20087117]\n",
      " [0.16351454]\n",
      " [0.15292768]\n",
      " [0.16111286]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.13388569841244483\n",
      "Predicci√≥n : [[0.16585016]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[[0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.20087117]\n",
      "  [0.16351454]\n",
      "  [0.15292768]\n",
      "  [0.16111286]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010217271046712995\n",
      "Predicci√≥n post entrenamiento : [[0.1609168]]\n",
      "PERDIDAAAA despues: 0.0007306808256544173\n",
      "loss en el callback: 0.0024559434968978167, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "ejemplar: [[0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.20087117]\n",
      " [0.16351454]\n",
      " [0.15292768]\n",
      " [0.16111286]\n",
      " [0.16585016]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.12684109919971556\n",
      "Predicci√≥n : [[0.17170525]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[[0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.20087117]\n",
      "  [0.16351454]\n",
      "  [0.15292768]\n",
      "  [0.16111286]\n",
      "  [0.16585016]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002012791810557246\n",
      "Predicci√≥n post entrenamiento : [[0.17031032]]\n",
      "PERDIDAAAA despues: 0.0018895731773227453\n",
      "loss en el callback: 0.00043263728730380535, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "ejemplar: [[0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.20087117]\n",
      " [0.16351454]\n",
      " [0.15292768]\n",
      " [0.16111286]\n",
      " [0.16585016]\n",
      " [0.17170525]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14756061137847282\n",
      "Predicci√≥n : [[0.18725404]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[[0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.20087117]\n",
      "  [0.16351454]\n",
      "  [0.15292768]\n",
      "  [0.16111286]\n",
      "  [0.16585016]\n",
      "  [0.17170525]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015755683416500688\n",
      "Predicci√≥n post entrenamiento : [[0.18474658]]\n",
      "PERDIDAAAA despues: 0.0013827960938215256\n",
      "loss en el callback: 0.0015668290434405208, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "ejemplar: [[0.0202993 ]\n",
      " [0.20087117]\n",
      " [0.16351454]\n",
      " [0.15292768]\n",
      " [0.16111286]\n",
      " [0.16585016]\n",
      " [0.17170525]\n",
      " [0.18725404]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19604423494871648\n",
      "Predicci√≥n : [[0.20781852]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[[0.0202993 ]\n",
      "  [0.20087117]\n",
      "  [0.16351454]\n",
      "  [0.15292768]\n",
      "  [0.16111286]\n",
      "  [0.16585016]\n",
      "  [0.17170525]\n",
      "  [0.18725404]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00013863382628187537\n",
      "Predicci√≥n post entrenamiento : [[0.2081103]]\n",
      "PERDIDAAAA despues: 0.00014558996190316975\n",
      "loss en el callback: 2.807768396451138e-05, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "ejemplar: [[0.20087117]\n",
      " [0.16351454]\n",
      " [0.15292768]\n",
      " [0.16111286]\n",
      " [0.16585016]\n",
      " [0.17170525]\n",
      " [0.18725404]\n",
      " [0.20781852]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.21688968214535215\n",
      "Predicci√≥n : [[0.23713894]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[[0.20087117]\n",
      "  [0.16351454]\n",
      "  [0.15292768]\n",
      "  [0.16111286]\n",
      "  [0.16585016]\n",
      "  [0.17170525]\n",
      "  [0.18725404]\n",
      "  [0.20781852]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00041003263322636485\n",
      "Predicci√≥n post entrenamiento : [[0.23457788]]\n",
      "PERDIDAAAA despues: 0.00031287240562960505\n",
      "loss en el callback: 0.001965584931895137, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "ejemplar: [[0.16351454]\n",
      " [0.15292768]\n",
      " [0.16111286]\n",
      " [0.16585016]\n",
      " [0.17170525]\n",
      " [0.18725404]\n",
      " [0.20781852]\n",
      " [0.23713894]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2100969529683796\n",
      "Predicci√≥n : [[0.2284678]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[[0.16351454]\n",
      "  [0.15292768]\n",
      "  [0.16111286]\n",
      "  [0.16585016]\n",
      "  [0.17170525]\n",
      "  [0.18725404]\n",
      "  [0.20781852]\n",
      "  [0.23713894]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00033748819259926677\n",
      "Predicci√≥n post entrenamiento : [[0.22908251]]\n",
      "PERDIDAAAA despues: 0.0003604512894526124\n",
      "loss en el callback: 0.0002345021057408303, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "ejemplar: [[0.15292768]\n",
      " [0.16111286]\n",
      " [0.16585016]\n",
      " [0.17170525]\n",
      " [0.18725404]\n",
      " [0.20781852]\n",
      " [0.23713894]\n",
      " [0.22846781]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2026778474621132\n",
      "Predicci√≥n : [[0.23152575]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[[0.15292768]\n",
      "  [0.16111286]\n",
      "  [0.16585016]\n",
      "  [0.17170525]\n",
      "  [0.18725404]\n",
      "  [0.20781852]\n",
      "  [0.23713894]\n",
      "  [0.22846781]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008322015055455267\n",
      "Predicci√≥n post entrenamiento : [[0.2292106]]\n",
      "PERDIDAAAA despues: 0.0007039870251901448\n",
      "loss en el callback: 0.002689852612093091, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "ejemplar: [[0.16111286]\n",
      " [0.16585016]\n",
      " [0.17170525]\n",
      " [0.18725404]\n",
      " [0.20781852]\n",
      " [0.23713894]\n",
      " [0.22846781]\n",
      " [0.23152575]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19463236562655295\n",
      "Predicci√≥n : [[0.23581348]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[[0.16111286]\n",
      "  [0.16585016]\n",
      "  [0.17170525]\n",
      "  [0.18725404]\n",
      "  [0.20781852]\n",
      "  [0.23713894]\n",
      "  [0.22846781]\n",
      "  [0.23152575]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016958843916654587\n",
      "Predicci√≥n post entrenamiento : [[0.23299444]]\n",
      "PERDIDAAAA despues: 0.001471648458391428\n",
      "loss en el callback: 0.00425685802474618, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "ejemplar: [[0.16585016]\n",
      " [0.17170525]\n",
      " [0.18725404]\n",
      " [0.20781852]\n",
      " [0.23713894]\n",
      " [0.22846781]\n",
      " [0.23152575]\n",
      " [0.23581348]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19407351685692253\n",
      "Predicci√≥n : [[0.24019147]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[[0.16585016]\n",
      "  [0.17170525]\n",
      "  [0.18725404]\n",
      "  [0.20781852]\n",
      "  [0.23713894]\n",
      "  [0.22846781]\n",
      "  [0.23152575]\n",
      "  [0.23581348]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002126866253092885\n",
      "Predicci√≥n post entrenamiento : [[0.23736435]]\n",
      "PERDIDAAAA despues: 0.001874096691608429\n",
      "loss en el callback: 0.0049509769305586815, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "ejemplar: [[0.17170525]\n",
      " [0.18725404]\n",
      " [0.20781852]\n",
      " [0.23713894]\n",
      " [0.22846781]\n",
      " [0.23152575]\n",
      " [0.23581348]\n",
      " [0.24019147]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.20100130115322212\n",
      "Predicci√≥n : [[0.24593033]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[[0.17170525]\n",
      "  [0.18725404]\n",
      "  [0.20781852]\n",
      "  [0.23713894]\n",
      "  [0.22846781]\n",
      "  [0.23152575]\n",
      "  [0.23581348]\n",
      "  [0.24019147]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0020186174660921097\n",
      "Predicci√≥n post entrenamiento : [[0.24541666]]\n",
      "PERDIDAAAA despues: 0.001972723752260208\n",
      "loss en el callback: 0.0002736225724220276, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "ejemplar: [[0.18725404]\n",
      " [0.20781852]\n",
      " [0.23713894]\n",
      " [0.22846781]\n",
      " [0.23152575]\n",
      " [0.23581348]\n",
      " [0.24019147]\n",
      " [0.24593033]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19663820581116015\n",
      "Predicci√≥n : [[0.2551457]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[[0.18725404]\n",
      "  [0.20781852]\n",
      "  [0.23713894]\n",
      "  [0.22846781]\n",
      "  [0.23152575]\n",
      "  [0.23581348]\n",
      "  [0.24019147]\n",
      "  [0.24593033]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003423125948756933\n",
      "Predicci√≥n post entrenamiento : [[0.2532993]]\n",
      "PERDIDAAAA despues: 0.003210478462278843\n",
      "loss en el callback: 0.003203565487638116, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "ejemplar: [[0.20781852]\n",
      " [0.23713894]\n",
      " [0.22846781]\n",
      " [0.23152575]\n",
      " [0.23581348]\n",
      " [0.24019147]\n",
      " [0.24593033]\n",
      " [0.2551457 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1809842308307365\n",
      "Predicci√≥n : [[0.26189414]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[[0.20781852]\n",
      "  [0.23713894]\n",
      "  [0.22846781]\n",
      "  [0.23152575]\n",
      "  [0.23581348]\n",
      "  [0.24019147]\n",
      "  [0.24593033]\n",
      "  [0.2551457 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0065464130602777\n",
      "Predicci√≥n post entrenamiento : [[0.25819448]]\n",
      "PERDIDAAAA despues: 0.0059614223428070545\n",
      "loss en el callback: 0.012797601521015167, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "ejemplar: [[0.23713894]\n",
      " [0.22846781]\n",
      " [0.23152575]\n",
      " [0.23581348]\n",
      " [0.24019147]\n",
      " [0.24593033]\n",
      " [0.2551457 ]\n",
      " [0.26189414]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1653904097109329\n",
      "Predicci√≥n : [[0.2640686]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[[0.23713894]\n",
      "  [0.22846781]\n",
      "  [0.23152575]\n",
      "  [0.23581348]\n",
      "  [0.24019147]\n",
      "  [0.24593033]\n",
      "  [0.2551457 ]\n",
      "  [0.26189414]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009737384505569935\n",
      "Predicci√≥n post entrenamiento : [[0.26218423]]\n",
      "PERDIDAAAA despues: 0.009369042702019215\n",
      "loss en el callback: 0.004909140523523092, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "ejemplar: [[0.22846781]\n",
      " [0.23152575]\n",
      " [0.23581348]\n",
      " [0.24019147]\n",
      " [0.24593033]\n",
      " [0.2551457 ]\n",
      " [0.26189414]\n",
      " [0.2640686 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14985674245174896\n",
      "Predicci√≥n : [[0.2627288]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[[0.22846781]\n",
      "  [0.23152575]\n",
      "  [0.23581348]\n",
      "  [0.24019147]\n",
      "  [0.24593033]\n",
      "  [0.2551457 ]\n",
      "  [0.26189414]\n",
      "  [0.2640686 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012740102596580982\n",
      "Predicci√≥n post entrenamiento : [[0.25962198]]\n",
      "PERDIDAAAA despues: 0.012048406526446342\n",
      "loss en el callback: 0.013111570850014687, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "ejemplar: [[0.23152575]\n",
      " [0.23581348]\n",
      " [0.24019147]\n",
      " [0.24593033]\n",
      " [0.2551457 ]\n",
      " [0.26189414]\n",
      " [0.2640686 ]\n",
      " [0.26272881]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.15043111479831345\n",
      "Predicci√≥n : [[0.2628782]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[[0.23152575]\n",
      "  [0.23581348]\n",
      "  [0.24019147]\n",
      "  [0.24593033]\n",
      "  [0.2551457 ]\n",
      "  [0.26189414]\n",
      "  [0.2640686 ]\n",
      "  [0.26272881]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012644349597394466\n",
      "Predicci√≥n post entrenamiento : [[0.25959247]]\n",
      "PERDIDAAAA despues: 0.011916203424334526\n",
      "loss en el callback: 0.017081456258893013, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "ejemplar: [[0.23581348]\n",
      " [0.24019147]\n",
      " [0.24593033]\n",
      " [0.2551457 ]\n",
      " [0.26189414]\n",
      " [0.2640686 ]\n",
      " [0.26272881]\n",
      " [0.26287821]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.16711352675062616\n",
      "Predicci√≥n : [[0.26324108]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[[0.23581348]\n",
      "  [0.24019147]\n",
      "  [0.24593033]\n",
      "  [0.2551457 ]\n",
      "  [0.26189414]\n",
      "  [0.2640686 ]\n",
      "  [0.26272881]\n",
      "  [0.26287821]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009240507148206234\n",
      "Predicci√≥n post entrenamiento : [[0.25824663]]\n",
      "PERDIDAAAA despues: 0.008305242285132408\n",
      "loss en el callback: 0.02903803251683712, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "ejemplar: [[0.24019147]\n",
      " [0.24593033]\n",
      " [0.2551457 ]\n",
      " [0.26189414]\n",
      " [0.2640686 ]\n",
      " [0.26272881]\n",
      " [0.26287821]\n",
      " [0.26324108]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2022703535675908\n",
      "Predicci√≥n : [[0.26196685]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[[0.24019147]\n",
      "  [0.24593033]\n",
      "  [0.2551457 ]\n",
      "  [0.26189414]\n",
      "  [0.2640686 ]\n",
      "  [0.26272881]\n",
      "  [0.26287821]\n",
      "  [0.26324108]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0035636716056615114\n",
      "Predicci√≥n post entrenamiento : [[0.26139522]]\n",
      "PERDIDAAAA despues: 0.0034957488533109426\n",
      "loss en el callback: 0.0007821392500773072, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "ejemplar: [[0.24593033]\n",
      " [0.2551457 ]\n",
      " [0.26189414]\n",
      " [0.2640686 ]\n",
      " [0.26272881]\n",
      " [0.26287821]\n",
      " [0.26324108]\n",
      " [0.26196685]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.25590159524920725\n",
      "Predicci√≥n : [[0.26505357]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[[0.24593033]\n",
      "  [0.2551457 ]\n",
      "  [0.26189414]\n",
      "  [0.2640686 ]\n",
      "  [0.26272881]\n",
      "  [0.26287821]\n",
      "  [0.26324108]\n",
      "  [0.26196685]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.375847392017022e-05\n",
      "Predicci√≥n post entrenamiento : [[0.26538613]]\n",
      "PERDIDAAAA despues: 8.995630196295679e-05\n",
      "loss en el callback: 0.0002786954282782972, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "ejemplar: [[0.2551457 ]\n",
      " [0.26189414]\n",
      " [0.2640686 ]\n",
      " [0.26272881]\n",
      " [0.26287821]\n",
      " [0.26324108]\n",
      " [0.26196685]\n",
      " [0.26505357]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.292688203599549\n",
      "Predicci√≥n : [[0.2685199]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[[0.2551457 ]\n",
      "  [0.26189414]\n",
      "  [0.2640686 ]\n",
      "  [0.26272881]\n",
      "  [0.26287821]\n",
      "  [0.26324108]\n",
      "  [0.26196685]\n",
      "  [0.26505357]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005841059028171003\n",
      "Predicci√≥n post entrenamiento : [[0.26925135]]\n",
      "PERDIDAAAA despues: 0.0005492856726050377\n",
      "loss en el callback: 0.0012723136460408568, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "ejemplar: [[0.26189414]\n",
      " [0.2640686 ]\n",
      " [0.26272881]\n",
      " [0.26287821]\n",
      " [0.26324108]\n",
      " [0.26196685]\n",
      " [0.26505357]\n",
      " [0.26851991]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31263017861861575\n",
      "Predicci√≥n : [[0.27085534]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[[0.26189414]\n",
      "  [0.2640686 ]\n",
      "  [0.26272881]\n",
      "  [0.26287821]\n",
      "  [0.26324108]\n",
      "  [0.26196685]\n",
      "  [0.26505357]\n",
      "  [0.26851991]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017451371531933546\n",
      "Predicci√≥n post entrenamiento : [[0.2716529]]\n",
      "PERDIDAAAA despues: 0.0016791366506367922\n",
      "loss en el callback: 0.0015416728565469384, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "ejemplar: [[0.2640686 ]\n",
      " [0.26272881]\n",
      " [0.26287821]\n",
      " [0.26324108]\n",
      " [0.26196685]\n",
      " [0.26505357]\n",
      " [0.26851991]\n",
      " [0.27085534]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3109388849116374\n",
      "Predicci√≥n : [[0.27202627]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[[0.2640686 ]\n",
      "  [0.26272881]\n",
      "  [0.26287821]\n",
      "  [0.26324108]\n",
      "  [0.26196685]\n",
      "  [0.26505357]\n",
      "  [0.26851991]\n",
      "  [0.27085534]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015141923213377595\n",
      "Predicci√≥n post entrenamiento : [[0.27269426]]\n",
      "PERDIDAAAA despues: 0.0014626521151512861\n",
      "loss en el callback: 0.0011160437716171145, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "ejemplar: [[0.26272881]\n",
      " [0.26287821]\n",
      " [0.26324108]\n",
      " [0.26196685]\n",
      " [0.26505357]\n",
      " [0.26851991]\n",
      " [0.27085534]\n",
      " [0.27202627]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2876143224786136\n",
      "Predicci√≥n : [[0.27274293]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[[0.26272881]\n",
      "  [0.26287821]\n",
      "  [0.26324108]\n",
      "  [0.26196685]\n",
      "  [0.26505357]\n",
      "  [0.26851991]\n",
      "  [0.27085534]\n",
      "  [0.27202627]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002211582032032311\n",
      "Predicci√≥n post entrenamiento : [[0.27329478]]\n",
      "PERDIDAAAA despues: 0.00020504920394159853\n",
      "loss en el callback: 0.0009739025845192373, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "ejemplar: [[0.26287821]\n",
      " [0.26324108]\n",
      " [0.26196685]\n",
      " [0.26505357]\n",
      " [0.26851991]\n",
      " [0.27085534]\n",
      " [0.27202627]\n",
      " [0.27274293]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.280161647237227\n",
      "Predicci√≥n : [[0.2738398]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[[0.26287821]\n",
      "  [0.26324108]\n",
      "  [0.26196685]\n",
      "  [0.26505357]\n",
      "  [0.26851991]\n",
      "  [0.27085534]\n",
      "  [0.27202627]\n",
      "  [0.27274293]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.996575469500385e-05\n",
      "Predicci√≥n post entrenamiento : [[0.272945]]\n",
      "PERDIDAAAA despues: 5.2080213208682835e-05\n",
      "loss en el callback: 0.0016986444825306535, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "ejemplar: [[0.26324108]\n",
      " [0.26196685]\n",
      " [0.26505357]\n",
      " [0.26851991]\n",
      " [0.27085534]\n",
      " [0.27202627]\n",
      " [0.27274293]\n",
      " [0.2738398 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2885808591874776\n",
      "Predicci√≥n : [[0.27374244]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[[0.26324108]\n",
      "  [0.26196685]\n",
      "  [0.26505357]\n",
      "  [0.26851991]\n",
      "  [0.27085534]\n",
      "  [0.27202627]\n",
      "  [0.27274293]\n",
      "  [0.2738398 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00022017893206793815\n",
      "Predicci√≥n post entrenamiento : [[0.2745394]]\n",
      "PERDIDAAAA despues: 0.00019716241513378918\n",
      "loss en el callback: 0.0026011914014816284, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "ejemplar: [[0.26196685]\n",
      " [0.26505357]\n",
      " [0.26851991]\n",
      " [0.27085534]\n",
      " [0.27202627]\n",
      " [0.27274293]\n",
      " [0.2738398 ]\n",
      " [0.27374244]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2824628234730068\n",
      "Predicci√≥n : [[0.27558374]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[[0.26196685]\n",
      "  [0.26505357]\n",
      "  [0.26851991]\n",
      "  [0.27085534]\n",
      "  [0.27202627]\n",
      "  [0.27274293]\n",
      "  [0.2738398 ]\n",
      "  [0.27374244]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.7321897000074387e-05\n",
      "Predicci√≥n post entrenamiento : [[0.2756981]]\n",
      "PERDIDAAAA despues: 4.576170249492861e-05\n",
      "loss en el callback: 4.400359102874063e-05, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "ejemplar: [[0.26505357]\n",
      " [0.26851991]\n",
      " [0.27085534]\n",
      " [0.27202627]\n",
      " [0.27274293]\n",
      " [0.2738398 ]\n",
      " [0.27374244]\n",
      " [0.27558374]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.26180754009381474\n",
      "Predicci√≥n : [[0.27740476]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[[0.26505357]\n",
      "  [0.26851991]\n",
      "  [0.27085534]\n",
      "  [0.27202627]\n",
      "  [0.27274293]\n",
      "  [0.2738398 ]\n",
      "  [0.27374244]\n",
      "  [0.27558374]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00024327340361196548\n",
      "Predicci√≥n post entrenamiento : [[0.27767622]]\n",
      "PERDIDAAAA despues: 0.00025181545061059296\n",
      "loss en el callback: 0.0003180773346684873, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "ejemplar: [[0.26851991]\n",
      " [0.27085534]\n",
      " [0.27202627]\n",
      " [0.27274293]\n",
      " [0.2738398 ]\n",
      " [0.27374244]\n",
      " [0.27558374]\n",
      " [0.27740476]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2801212859371977\n",
      "Predicci√≥n : [[0.2790925]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[[0.26851991]\n",
      "  [0.27085534]\n",
      "  [0.27202627]\n",
      "  [0.27274293]\n",
      "  [0.2738398 ]\n",
      "  [0.27374244]\n",
      "  [0.27558374]\n",
      "  [0.27740476]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.058441739587579e-06\n",
      "Predicci√≥n post entrenamiento : [[0.27954915]]\n",
      "PERDIDAAAA despues: 3.273498805356212e-07\n",
      "loss en el callback: 0.001079502166248858, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "ejemplar: [[0.27085534]\n",
      " [0.27202627]\n",
      " [0.27274293]\n",
      " [0.2738398 ]\n",
      " [0.27374244]\n",
      " [0.27558374]\n",
      " [0.27740476]\n",
      " [0.27909249]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3374040610031557\n",
      "Predicci√≥n : [[0.280516]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[[0.27085534]\n",
      "  [0.27202627]\n",
      "  [0.27274293]\n",
      "  [0.2738398 ]\n",
      "  [0.27374244]\n",
      "  [0.27558374]\n",
      "  [0.27740476]\n",
      "  [0.27909249]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0032362528145313263\n",
      "Predicci√≥n post entrenamiento : [[0.28167123]]\n",
      "PERDIDAAAA despues: 0.0031061500776559114\n",
      "loss en el callback: 0.006968209054321051, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "ejemplar: [[0.27202627]\n",
      " [0.27274293]\n",
      " [0.2738398 ]\n",
      " [0.27374244]\n",
      " [0.27558374]\n",
      " [0.27740476]\n",
      " [0.27909249]\n",
      " [0.280516  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3482298154676272\n",
      "Predicci√≥n : [[0.28238195]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[[0.27202627]\n",
      "  [0.27274293]\n",
      "  [0.2738398 ]\n",
      "  [0.27374244]\n",
      "  [0.27558374]\n",
      "  [0.27740476]\n",
      "  [0.27909249]\n",
      "  [0.280516  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004335942678153515\n",
      "Predicci√≥n post entrenamiento : [[0.2832293]]\n",
      "PERDIDAAAA despues: 0.004225069656968117\n",
      "loss en el callback: 0.0032393732108175755, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "ejemplar: [[0.27274293]\n",
      " [0.2738398 ]\n",
      " [0.27374244]\n",
      " [0.27558374]\n",
      " [0.27740476]\n",
      " [0.27909249]\n",
      " [0.280516  ]\n",
      " [0.28238195]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31259854933061226\n",
      "Predicci√≥n : [[0.2839324]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[[0.27274293]\n",
      "  [0.2738398 ]\n",
      "  [0.27374244]\n",
      "  [0.27558374]\n",
      "  [0.27740476]\n",
      "  [0.27909249]\n",
      "  [0.280516  ]\n",
      "  [0.28238195]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008217492140829563\n",
      "Predicci√≥n post entrenamiento : [[0.2838067]]\n",
      "PERDIDAAAA despues: 0.0008289703400805593\n",
      "loss en el callback: 6.332257180474699e-05, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "ejemplar: [[0.2738398 ]\n",
      " [0.27374244]\n",
      " [0.27558374]\n",
      " [0.27740476]\n",
      " [0.27909249]\n",
      " [0.280516  ]\n",
      " [0.28238195]\n",
      " [0.28393239]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.34358710169603873\n",
      "Predicci√≥n : [[0.28462678]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[[0.2738398 ]\n",
      "  [0.27374244]\n",
      "  [0.27558374]\n",
      "  [0.27740476]\n",
      "  [0.27909249]\n",
      "  [0.280516  ]\n",
      "  [0.28238195]\n",
      "  [0.28393239]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0034763191360980272\n",
      "Predicci√≥n post entrenamiento : [[0.2847894]]\n",
      "PERDIDAAAA despues: 0.0034571681171655655\n",
      "loss en el callback: 9.843776206253096e-05, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "ejemplar: [[0.27374244]\n",
      " [0.27558374]\n",
      " [0.27740476]\n",
      " [0.27909249]\n",
      " [0.280516  ]\n",
      " [0.28238195]\n",
      " [0.28393239]\n",
      " [0.28462678]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.4411954725639069\n",
      "Predicci√≥n : [[0.28566602]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[[0.27374244]\n",
      "  [0.27558374]\n",
      "  [0.27740476]\n",
      "  [0.27909249]\n",
      "  [0.280516  ]\n",
      "  [0.28238195]\n",
      "  [0.28393239]\n",
      "  [0.28462678]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.024189407005906105\n",
      "Predicci√≥n post entrenamiento : [[0.2877807]]\n",
      "PERDIDAAAA despues: 0.023536087945103645\n",
      "loss en el callback: 0.023820623755455017, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "ejemplar: [[0.27558374]\n",
      " [0.27740476]\n",
      " [0.27909249]\n",
      " [0.280516  ]\n",
      " [0.28238195]\n",
      " [0.28393239]\n",
      " [0.28462678]\n",
      " [0.28566602]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5210953230441133\n",
      "Predicci√≥n : [[0.28901058]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[[0.27558374]\n",
      "  [0.27740476]\n",
      "  [0.27909249]\n",
      "  [0.280516  ]\n",
      "  [0.28238195]\n",
      "  [0.28393239]\n",
      "  [0.28462678]\n",
      "  [0.28566602]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05386333167552948\n",
      "Predicci√≥n post entrenamiento : [[0.29220346]]\n",
      "PERDIDAAAA despues: 0.05239149183034897\n",
      "loss en el callback: 0.051570694893598557, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "ejemplar: [[0.27740476]\n",
      " [0.27909249]\n",
      " [0.280516  ]\n",
      " [0.28238195]\n",
      " [0.28393239]\n",
      " [0.28462678]\n",
      " [0.28566602]\n",
      " [0.28901058]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5832866531366584\n",
      "Predicci√≥n : [[0.29338306]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[[0.27740476]\n",
      "  [0.27909249]\n",
      "  [0.280516  ]\n",
      "  [0.28238195]\n",
      "  [0.28393239]\n",
      "  [0.28462678]\n",
      "  [0.28566602]\n",
      "  [0.28901058]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08404408395290375\n",
      "Predicci√≥n post entrenamiento : [[0.29694444]]\n",
      "PERDIDAAAA despues: 0.08199185878038406\n",
      "loss en el callback: 0.06824864447116852, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "ejemplar: [[0.27909249]\n",
      " [0.280516  ]\n",
      " [0.28238195]\n",
      " [0.28393239]\n",
      " [0.28462678]\n",
      " [0.28566602]\n",
      " [0.28901058]\n",
      " [0.29338306]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6089234523540271\n",
      "Predicci√≥n : [[0.29808667]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[[0.27909249]\n",
      "  [0.280516  ]\n",
      "  [0.28238195]\n",
      "  [0.28393239]\n",
      "  [0.28462678]\n",
      "  [0.28566602]\n",
      "  [0.28901058]\n",
      "  [0.29338306]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09661949425935745\n",
      "Predicci√≥n post entrenamiento : [[0.3021614]]\n",
      "PERDIDAAAA despues: 0.09410294890403748\n",
      "loss en el callback: 0.09933159500360489, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "ejemplar: [[0.280516  ]\n",
      " [0.28238195]\n",
      " [0.28393239]\n",
      " [0.28462678]\n",
      " [0.28566602]\n",
      " [0.28901058]\n",
      " [0.29338306]\n",
      " [0.29808667]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.59800572069622\n",
      "Predicci√≥n : [[0.30333105]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[[0.280516  ]\n",
      "  [0.28238195]\n",
      "  [0.28393239]\n",
      "  [0.28462678]\n",
      "  [0.28566602]\n",
      "  [0.28901058]\n",
      "  [0.29338306]\n",
      "  [0.29808667]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.086833156645298\n",
      "Predicci√≥n post entrenamiento : [[0.30680698]]\n",
      "PERDIDAAAA despues: 0.08479669690132141\n",
      "loss en el callback: 0.07340454310178757, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "ejemplar: [[0.28238195]\n",
      " [0.28393239]\n",
      " [0.28462678]\n",
      " [0.28566602]\n",
      " [0.28901058]\n",
      " [0.29338306]\n",
      " [0.29808667]\n",
      " [0.30333105]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5945301858653699\n",
      "Predicci√≥n : [[0.30813295]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[[0.28238195]\n",
      "  [0.28393239]\n",
      "  [0.28462678]\n",
      "  [0.28566602]\n",
      "  [0.28901058]\n",
      "  [0.29338306]\n",
      "  [0.29808667]\n",
      "  [0.30333105]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08202336728572845\n",
      "Predicci√≥n post entrenamiento : [[0.31135172]]\n",
      "PERDIDAAAA despues: 0.0801900327205658\n",
      "loss en el callback: 0.05165214464068413, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "ejemplar: [[0.28393239]\n",
      " [0.28462678]\n",
      " [0.28566602]\n",
      " [0.28901058]\n",
      " [0.29338306]\n",
      " [0.29808667]\n",
      " [0.30333105]\n",
      " [0.30813295]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5984968478614763\n",
      "Predicci√≥n : [[0.31282604]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[[0.28393239]\n",
      "  [0.28462678]\n",
      "  [0.28566602]\n",
      "  [0.28901058]\n",
      "  [0.29338306]\n",
      "  [0.29808667]\n",
      "  [0.30333105]\n",
      "  [0.30813295]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08160781860351562\n",
      "Predicci√≥n post entrenamiento : [[0.31628993]]\n",
      "PERDIDAAAA despues: 0.07964074611663818\n",
      "loss en el callback: 0.0732775405049324, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "ejemplar: [[0.28462678]\n",
      " [0.28566602]\n",
      " [0.28901058]\n",
      " [0.29338306]\n",
      " [0.29808667]\n",
      " [0.30333105]\n",
      " [0.30813295]\n",
      " [0.31282604]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6213543446734934\n",
      "Predicci√≥n : [[0.31809008]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[[0.28462678]\n",
      "  [0.28566602]\n",
      "  [0.28901058]\n",
      "  [0.29338306]\n",
      "  [0.29808667]\n",
      "  [0.30333105]\n",
      "  [0.30813295]\n",
      "  [0.31282604]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09196921437978745\n",
      "Predicci√≥n post entrenamiento : [[0.3216763]]\n",
      "PERDIDAAAA despues: 0.0898069217801094\n",
      "loss en el callback: 0.08597233146429062, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "ejemplar: [[0.28566602]\n",
      " [0.28901058]\n",
      " [0.29338306]\n",
      " [0.29808667]\n",
      " [0.30333105]\n",
      " [0.30813295]\n",
      " [0.31282604]\n",
      " [0.31809008]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.663102676301421\n",
      "Predicci√≥n : [[0.32413563]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[[0.28566602]\n",
      "  [0.28901058]\n",
      "  [0.29338306]\n",
      "  [0.29808667]\n",
      "  [0.30333105]\n",
      "  [0.30813295]\n",
      "  [0.31282604]\n",
      "  [0.31809008]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1148986667394638\n",
      "Predicci√≥n post entrenamiento : [[0.32796586]]\n",
      "PERDIDAAAA despues: 0.11231669783592224\n",
      "loss en el callback: 0.1148286685347557, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "ejemplar: [[0.28901058]\n",
      " [0.29338306]\n",
      " [0.29808667]\n",
      " [0.30333105]\n",
      " [0.30813295]\n",
      " [0.31282604]\n",
      " [0.31809008]\n",
      " [0.32413563]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6928724338328028\n",
      "Predicci√≥n : [[0.3311678]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[[0.28901058]\n",
      "  [0.29338306]\n",
      "  [0.29808667]\n",
      "  [0.30333105]\n",
      "  [0.30813295]\n",
      "  [0.31282604]\n",
      "  [0.31809008]\n",
      "  [0.32413563]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13083022832870483\n",
      "Predicci√≥n post entrenamiento : [[0.3353847]]\n",
      "PERDIDAAAA despues: 0.1277974545955658\n",
      "loss en el callback: 0.15006855130195618, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "ejemplar: [[0.29338306]\n",
      " [0.29808667]\n",
      " [0.30333105]\n",
      " [0.30813295]\n",
      " [0.31282604]\n",
      " [0.31809008]\n",
      " [0.32413563]\n",
      " [0.33116779]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.710663617267639\n",
      "Predicci√≥n : [[0.33893466]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[[0.29338306]\n",
      "  [0.29808667]\n",
      "  [0.30333105]\n",
      "  [0.30813295]\n",
      "  [0.31282604]\n",
      "  [0.31809008]\n",
      "  [0.32413563]\n",
      "  [0.33116779]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13818241655826569\n",
      "Predicci√≥n post entrenamiento : [[0.3431877]]\n",
      "PERDIDAAAA despues: 0.1350385546684265\n",
      "loss en el callback: 0.13144469261169434, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "ejemplar: [[0.29808667]\n",
      " [0.30333105]\n",
      " [0.30813295]\n",
      " [0.31282604]\n",
      " [0.31809008]\n",
      " [0.32413563]\n",
      " [0.33116779]\n",
      " [0.33893466]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7216820581308059\n",
      "Predicci√≥n : [[0.3469349]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[[0.29808667]\n",
      "  [0.30333105]\n",
      "  [0.30813295]\n",
      "  [0.31282604]\n",
      "  [0.31809008]\n",
      "  [0.32413563]\n",
      "  [0.33116779]\n",
      "  [0.33893466]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14043542742729187\n",
      "Predicci√≥n post entrenamiento : [[0.35096473]]\n",
      "PERDIDAAAA despues: 0.13743135333061218\n",
      "loss en el callback: 0.15476584434509277, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "ejemplar: [[0.30333105]\n",
      " [0.30813295]\n",
      " [0.31282604]\n",
      " [0.31809008]\n",
      " [0.32413563]\n",
      " [0.33116779]\n",
      " [0.33893466]\n",
      " [0.34693491]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7259277564223031\n",
      "Predicci√≥n : [[0.3549119]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[[0.30333105]\n",
      "  [0.30813295]\n",
      "  [0.31282604]\n",
      "  [0.31809008]\n",
      "  [0.32413563]\n",
      "  [0.33116779]\n",
      "  [0.33893466]\n",
      "  [0.34693491]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13765278458595276\n",
      "Predicci√≥n post entrenamiento : [[0.35885492]]\n",
      "PERDIDAAAA despues: 0.13474248349666595\n",
      "loss en el callback: 0.18459771573543549, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "ejemplar: [[0.30813295]\n",
      " [0.31282604]\n",
      " [0.31809008]\n",
      " [0.32413563]\n",
      " [0.33116779]\n",
      " [0.33893466]\n",
      " [0.34693491]\n",
      " [0.35491189]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7404318224413275\n",
      "Predicci√≥n : [[0.36296138]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[[0.30813295]\n",
      "  [0.31282604]\n",
      "  [0.31809008]\n",
      "  [0.32413563]\n",
      "  [0.33116779]\n",
      "  [0.33893466]\n",
      "  [0.34693491]\n",
      "  [0.35491189]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14248394966125488\n",
      "Predicci√≥n post entrenamiento : [[0.36718714]]\n",
      "PERDIDAAAA despues: 0.13931161165237427\n",
      "loss en el callback: 0.14619386196136475, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "ejemplar: [[0.31282604]\n",
      " [0.31809008]\n",
      " [0.32413563]\n",
      " [0.33116779]\n",
      " [0.33893466]\n",
      " [0.34693491]\n",
      " [0.35491189]\n",
      " [0.36296138]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7651942561878792\n",
      "Predicci√≥n : [[0.37165397]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[[0.31282604]\n",
      "  [0.31809008]\n",
      "  [0.32413563]\n",
      "  [0.33116779]\n",
      "  [0.33893466]\n",
      "  [0.34693491]\n",
      "  [0.35491189]\n",
      "  [0.36296138]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.15487393736839294\n",
      "Predicci√≥n post entrenamiento : [[0.3757345]]\n",
      "PERDIDAAAA despues: 0.1516788750886917\n",
      "loss en el callback: 0.16434726119041443, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "ejemplar: [[0.31809008]\n",
      " [0.32413563]\n",
      " [0.33116779]\n",
      " [0.33893466]\n",
      " [0.34693491]\n",
      " [0.35491189]\n",
      " [0.36296138]\n",
      " [0.37165397]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7447890964420396\n",
      "Predicci√≥n : [[0.38071218]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[[0.31809008]\n",
      "  [0.32413563]\n",
      "  [0.33116779]\n",
      "  [0.33893466]\n",
      "  [0.34693491]\n",
      "  [0.35491189]\n",
      "  [0.36296138]\n",
      "  [0.37165397]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13255201280117035\n",
      "Predicci√≥n post entrenamiento : [[0.38458487]]\n",
      "PERDIDAAAA despues: 0.12974710762500763\n",
      "loss en el callback: 0.18671566247940063, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "ejemplar: [[0.32413563]\n",
      " [0.33116779]\n",
      " [0.33893466]\n",
      " [0.34693491]\n",
      " [0.35491189]\n",
      " [0.36296138]\n",
      " [0.37165397]\n",
      " [0.38071218]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6792163432038085\n",
      "Predicci√≥n : [[0.39006996]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[[0.32413563]\n",
      "  [0.33116779]\n",
      "  [0.33893466]\n",
      "  [0.34693491]\n",
      "  [0.35491189]\n",
      "  [0.36296138]\n",
      "  [0.37165397]\n",
      "  [0.38071218]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08360561728477478\n",
      "Predicci√≥n post entrenamiento : [[0.3931594]]\n",
      "PERDIDAAAA despues: 0.08182857185602188\n",
      "loss en el callback: 0.09962622076272964, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "ejemplar: [[0.33116779]\n",
      " [0.33893466]\n",
      " [0.34693491]\n",
      " [0.35491189]\n",
      " [0.36296138]\n",
      " [0.37165397]\n",
      " [0.38071218]\n",
      " [0.39006996]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6746017659154131\n",
      "Predicci√≥n : [[0.39908397]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[[0.33116779]\n",
      "  [0.33893466]\n",
      "  [0.34693491]\n",
      "  [0.35491189]\n",
      "  [0.36296138]\n",
      "  [0.37165397]\n",
      "  [0.38071218]\n",
      "  [0.39006996]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0759100690484047\n",
      "Predicci√≥n post entrenamiento : [[0.40175852]]\n",
      "PERDIDAAAA despues: 0.07444345206022263\n",
      "loss en el callback: 0.05899810045957565, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "ejemplar: [[0.33893466]\n",
      " [0.34693491]\n",
      " [0.35491189]\n",
      " [0.36296138]\n",
      " [0.37165397]\n",
      " [0.38071218]\n",
      " [0.39006996]\n",
      " [0.39908397]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7309453645768532\n",
      "Predicci√≥n : [[0.40797967]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[[0.33893466]\n",
      "  [0.34693491]\n",
      "  [0.35491189]\n",
      "  [0.36296138]\n",
      "  [0.37165397]\n",
      "  [0.38071218]\n",
      "  [0.39006996]\n",
      "  [0.39908397]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10430683195590973\n",
      "Predicci√≥n post entrenamiento : [[0.41128582]]\n",
      "PERDIDAAAA despues: 0.10218221694231033\n",
      "loss en el callback: 0.0988798514008522, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "ejemplar: [[0.34693491]\n",
      " [0.35491189]\n",
      " [0.36296138]\n",
      " [0.37165397]\n",
      " [0.38071218]\n",
      " [0.39006996]\n",
      " [0.39908397]\n",
      " [0.40797967]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7467210055914982\n",
      "Predicci√≥n : [[0.4176932]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[[0.34693491]\n",
      "  [0.35491189]\n",
      "  [0.36296138]\n",
      "  [0.37165397]\n",
      "  [0.38071218]\n",
      "  [0.39006996]\n",
      "  [0.39908397]\n",
      "  [0.40797967]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10825931280851364\n",
      "Predicci√≥n post entrenamiento : [[0.42094457]]\n",
      "PERDIDAAAA despues: 0.10613030195236206\n",
      "loss en el callback: 0.10415640473365784, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "ejemplar: [[0.35491189]\n",
      " [0.36296138]\n",
      " [0.37165397]\n",
      " [0.38071218]\n",
      " [0.39006996]\n",
      " [0.39908397]\n",
      " [0.40797967]\n",
      " [0.4176932 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7219286889593481\n",
      "Predicci√≥n : [[0.42753217]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[[0.35491189]\n",
      "  [0.36296138]\n",
      "  [0.37165397]\n",
      "  [0.38071218]\n",
      "  [0.39006996]\n",
      "  [0.39908397]\n",
      "  [0.40797967]\n",
      "  [0.4176932 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08666932582855225\n",
      "Predicci√≥n post entrenamiento : [[0.4304669]]\n",
      "PERDIDAAAA despues: 0.08494999259710312\n",
      "loss en el callback: 0.08785998076200485, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "ejemplar: [[0.36296138]\n",
      " [0.37165397]\n",
      " [0.38071218]\n",
      " [0.39006996]\n",
      " [0.39908397]\n",
      " [0.40797967]\n",
      " [0.4176932 ]\n",
      " [0.42753217]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7199286701160912\n",
      "Predicci√≥n : [[0.4372923]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[[0.36296138]\n",
      "  [0.37165397]\n",
      "  [0.38071218]\n",
      "  [0.39006996]\n",
      "  [0.39908397]\n",
      "  [0.40797967]\n",
      "  [0.4176932 ]\n",
      "  [0.42753217]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07988332211971283\n",
      "Predicci√≥n post entrenamiento : [[0.44019574]]\n",
      "PERDIDAAAA despues: 0.07825051993131638\n",
      "loss en el callback: 0.1044275090098381, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "ejemplar: [[0.37165397]\n",
      " [0.38071218]\n",
      " [0.39006996]\n",
      " [0.39908397]\n",
      " [0.40797967]\n",
      " [0.4176932 ]\n",
      " [0.42753217]\n",
      " [0.43729231]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7407209490617273\n",
      "Predicci√≥n : [[0.44729978]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[[0.37165397]\n",
      "  [0.38071218]\n",
      "  [0.39006996]\n",
      "  [0.39908397]\n",
      "  [0.40797967]\n",
      "  [0.4176932 ]\n",
      "  [0.42753217]\n",
      "  [0.43729231]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08609597384929657\n",
      "Predicci√≥n post entrenamiento : [[0.45023188]]\n",
      "PERDIDAAAA despues: 0.08438389003276825\n",
      "loss en el callback: 0.09015358239412308, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "ejemplar: [[0.38071218]\n",
      " [0.39006996]\n",
      " [0.39908397]\n",
      " [0.40797967]\n",
      " [0.4176932 ]\n",
      " [0.42753217]\n",
      " [0.43729231]\n",
      " [0.44729978]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.736245501831604\n",
      "Predicci√≥n : [[0.45751044]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[[0.38071218]\n",
      "  [0.39006996]\n",
      "  [0.39908397]\n",
      "  [0.40797967]\n",
      "  [0.4176932 ]\n",
      "  [0.42753217]\n",
      "  [0.43729231]\n",
      "  [0.44729978]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07769323885440826\n",
      "Predicci√≥n post entrenamiento : [[0.46010914]]\n",
      "PERDIDAAAA despues: 0.07625129073858261\n",
      "loss en el callback: 0.06886489689350128, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "ejemplar: [[0.39006996]\n",
      " [0.39908397]\n",
      " [0.40797967]\n",
      " [0.4176932 ]\n",
      " [0.42753217]\n",
      " [0.43729231]\n",
      " [0.44729978]\n",
      " [0.45751044]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7065023284257214\n",
      "Predicci√≥n : [[0.46750998]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[[0.39006996]\n",
      "  [0.39908397]\n",
      "  [0.40797967]\n",
      "  [0.4176932 ]\n",
      "  [0.42753217]\n",
      "  [0.43729231]\n",
      "  [0.44729978]\n",
      "  [0.45751044]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05711733549833298\n",
      "Predicci√≥n post entrenamiento : [[0.46971357]]\n",
      "PERDIDAAAA despues: 0.05606891214847565\n",
      "loss en el callback: 0.048014238476753235, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "ejemplar: [[0.39908397]\n",
      " [0.40797967]\n",
      " [0.4176932 ]\n",
      " [0.42753217]\n",
      " [0.43729231]\n",
      " [0.44729978]\n",
      " [0.45751044]\n",
      " [0.46750998]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6979451506854685\n",
      "Predicci√≥n : [[0.47719184]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[[0.39908397]\n",
      "  [0.40797967]\n",
      "  [0.4176932 ]\n",
      "  [0.42753217]\n",
      "  [0.43729231]\n",
      "  [0.44729978]\n",
      "  [0.45751044]\n",
      "  [0.46750998]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04873203858733177\n",
      "Predicci√≥n post entrenamiento : [[0.47905847]]\n",
      "PERDIDAAAA despues: 0.0479113906621933\n",
      "loss en el callback: 0.03590879589319229, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "ejemplar: [[0.40797967]\n",
      " [0.4176932 ]\n",
      " [0.42753217]\n",
      " [0.43729231]\n",
      " [0.44729978]\n",
      " [0.45751044]\n",
      " [0.46750998]\n",
      " [0.47719184]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7105739686108449\n",
      "Predicci√≥n : [[0.48672876]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[[0.40797967]\n",
      "  [0.4176932 ]\n",
      "  [0.42753217]\n",
      "  [0.43729231]\n",
      "  [0.44729978]\n",
      "  [0.45751044]\n",
      "  [0.46750998]\n",
      "  [0.47719184]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.050106678158044815\n",
      "Predicci√≥n post entrenamiento : [[0.48878574]]\n",
      "PERDIDAAAA despues: 0.04919001832604408\n",
      "loss en el callback: 0.05211509391665459, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "ejemplar: [[0.4176932 ]\n",
      " [0.42753217]\n",
      " [0.43729231]\n",
      " [0.44729978]\n",
      " [0.45751044]\n",
      " [0.46750998]\n",
      " [0.47719184]\n",
      " [0.48672876]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7209621522504839\n",
      "Predicci√≥n : [[0.49671623]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[[0.4176932 ]\n",
      "  [0.42753217]\n",
      "  [0.43729231]\n",
      "  [0.44729978]\n",
      "  [0.45751044]\n",
      "  [0.46750998]\n",
      "  [0.47719184]\n",
      "  [0.48672876]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05028624087572098\n",
      "Predicci√≥n post entrenamiento : [[0.49828652]]\n",
      "PERDIDAAAA despues: 0.04958444461226463\n",
      "loss en el callback: 0.02306569553911686, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "ejemplar: [[0.42753217]\n",
      " [0.43729231]\n",
      " [0.44729978]\n",
      " [0.45751044]\n",
      " [0.46750998]\n",
      " [0.47719184]\n",
      " [0.48672876]\n",
      " [0.49671623]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7291097016043858\n",
      "Predicci√≥n : [[0.5062978]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[[0.42753217]\n",
      "  [0.43729231]\n",
      "  [0.44729978]\n",
      "  [0.45751044]\n",
      "  [0.46750998]\n",
      "  [0.47719184]\n",
      "  [0.48672876]\n",
      "  [0.49671623]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.049645133316516876\n",
      "Predicci√≥n post entrenamiento : [[0.50841093]]\n",
      "PERDIDAAAA despues: 0.04870794713497162\n",
      "loss en el callback: 0.05623848736286163, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "ejemplar: [[0.43729231]\n",
      " [0.44729978]\n",
      " [0.45751044]\n",
      " [0.46750998]\n",
      " [0.47719184]\n",
      " [0.48672876]\n",
      " [0.49671623]\n",
      " [0.50629783]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7674259644168786\n",
      "Predicci√≥n : [[0.51647466]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[[0.43729231]\n",
      "  [0.44729978]\n",
      "  [0.45751044]\n",
      "  [0.46750998]\n",
      "  [0.47719184]\n",
      "  [0.48672876]\n",
      "  [0.49671623]\n",
      "  [0.50629783]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06297654658555984\n",
      "Predicci√≥n post entrenamiento : [[0.5187958]]\n",
      "PERDIDAAAA despues: 0.06181696057319641\n",
      "loss en el callback: 0.06336158514022827, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "ejemplar: [[0.44729978]\n",
      " [0.45751044]\n",
      " [0.46750998]\n",
      " [0.47719184]\n",
      " [0.48672876]\n",
      " [0.49671623]\n",
      " [0.50629783]\n",
      " [0.51647466]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8359109406879621\n",
      "Predicci√≥n : [[0.526932]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[[0.44729978]\n",
      "  [0.45751044]\n",
      "  [0.46750998]\n",
      "  [0.47719184]\n",
      "  [0.48672876]\n",
      "  [0.49671623]\n",
      "  [0.50629783]\n",
      "  [0.51647466]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09546796977519989\n",
      "Predicci√≥n post entrenamiento : [[0.5298489]]\n",
      "PERDIDAAAA despues: 0.09367397427558899\n",
      "loss en el callback: 0.12989658117294312, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "ejemplar: [[0.45751044]\n",
      " [0.46750998]\n",
      " [0.47719184]\n",
      " [0.48672876]\n",
      " [0.49671623]\n",
      " [0.50629783]\n",
      " [0.51647466]\n",
      " [0.526932  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8510103358824123\n",
      "Predicci√≥n : [[0.5379982]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[[0.45751044]\n",
      "  [0.46750998]\n",
      "  [0.47719184]\n",
      "  [0.48672876]\n",
      "  [0.49671623]\n",
      "  [0.50629783]\n",
      "  [0.51647466]\n",
      "  [0.526932  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09797658771276474\n",
      "Predicci√≥n post entrenamiento : [[0.54091156]]\n",
      "PERDIDAAAA despues: 0.09616124629974365\n",
      "loss en el callback: 0.12718255817890167, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "ejemplar: [[0.46750998]\n",
      " [0.47719184]\n",
      " [0.48672876]\n",
      " [0.49671623]\n",
      " [0.50629783]\n",
      " [0.51647466]\n",
      " [0.526932  ]\n",
      " [0.5379982 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8127241500002294\n",
      "Predicci√≥n : [[0.54902333]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[[0.46750998]\n",
      "  [0.47719184]\n",
      "  [0.48672876]\n",
      "  [0.49671623]\n",
      "  [0.50629783]\n",
      "  [0.51647466]\n",
      "  [0.526932  ]\n",
      "  [0.5379982 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06953813135623932\n",
      "Predicci√≥n post entrenamiento : [[0.55133384]]\n",
      "PERDIDAAAA despues: 0.06832490116357803\n",
      "loss en el callback: 0.07254119962453842, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "ejemplar: [[0.47719184]\n",
      " [0.48672876]\n",
      " [0.49671623]\n",
      " [0.50629783]\n",
      " [0.51647466]\n",
      " [0.526932  ]\n",
      " [0.5379982 ]\n",
      " [0.54902333]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7863940290280375\n",
      "Predicci√≥n : [[0.5594716]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[[0.47719184]\n",
      "  [0.48672876]\n",
      "  [0.49671623]\n",
      "  [0.50629783]\n",
      "  [0.51647466]\n",
      "  [0.526932  ]\n",
      "  [0.5379982 ]\n",
      "  [0.54902333]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.051493771374225616\n",
      "Predicci√≥n post entrenamiento : [[0.56174093]]\n",
      "PERDIDAAAA despues: 0.05046899989247322\n",
      "loss en el callback: 0.08661607652902603, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "ejemplar: [[0.48672876]\n",
      " [0.49671623]\n",
      " [0.50629783]\n",
      " [0.51647466]\n",
      " [0.526932  ]\n",
      " [0.5379982 ]\n",
      " [0.54902333]\n",
      " [0.55947161]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7720199729658365\n",
      "Predicci√≥n : [[0.57001555]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[[0.48672876]\n",
      "  [0.49671623]\n",
      "  [0.50629783]\n",
      "  [0.51647466]\n",
      "  [0.526932  ]\n",
      "  [0.5379982 ]\n",
      "  [0.54902333]\n",
      "  [0.55947161]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.040805790573358536\n",
      "Predicci√≥n post entrenamiento : [[0.5716298]]\n",
      "PERDIDAAAA despues: 0.04015621542930603\n",
      "loss en el callback: 0.036843713372945786, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "ejemplar: [[0.49671623]\n",
      " [0.50629783]\n",
      " [0.51647466]\n",
      " [0.526932  ]\n",
      " [0.5379982 ]\n",
      " [0.54902333]\n",
      " [0.55947161]\n",
      " [0.57001555]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8033170564228299\n",
      "Predicci√≥n : [[0.5801201]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[[0.49671623]\n",
      "  [0.50629783]\n",
      "  [0.51647466]\n",
      "  [0.526932  ]\n",
      "  [0.5379982 ]\n",
      "  [0.54902333]\n",
      "  [0.55947161]\n",
      "  [0.57001555]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04981689155101776\n",
      "Predicci√≥n post entrenamiento : [[0.5824935]]\n",
      "PERDIDAAAA despues: 0.048763055354356766\n",
      "loss en el callback: 0.10244482010602951, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "ejemplar: [[0.50629783]\n",
      " [0.51647466]\n",
      " [0.526932  ]\n",
      " [0.5379982 ]\n",
      " [0.54902333]\n",
      " [0.55947161]\n",
      " [0.57001555]\n",
      " [0.58012009]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8802852793990171\n",
      "Predicci√≥n : [[0.5911242]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[[0.50629783]\n",
      "  [0.51647466]\n",
      "  [0.526932  ]\n",
      "  [0.5379982 ]\n",
      "  [0.54902333]\n",
      "  [0.55947161]\n",
      "  [0.57001555]\n",
      "  [0.58012009]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08361413329839706\n",
      "Predicci√≥n post entrenamiento : [[0.5935295]]\n",
      "PERDIDAAAA despues: 0.08222885429859161\n",
      "loss en el callback: 0.07223406434059143, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "ejemplar: [[0.51647466]\n",
      " [0.526932  ]\n",
      " [0.5379982 ]\n",
      " [0.54902333]\n",
      " [0.55947161]\n",
      " [0.57001555]\n",
      " [0.58012009]\n",
      " [0.59112418]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8987051676996881\n",
      "Predicci√≥n : [[0.60244036]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[[0.51647466]\n",
      "  [0.526932  ]\n",
      "  [0.5379982 ]\n",
      "  [0.54902333]\n",
      "  [0.55947161]\n",
      "  [0.57001555]\n",
      "  [0.58012009]\n",
      "  [0.59112418]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08777284622192383\n",
      "Predicci√≥n post entrenamiento : [[0.6050353]]\n",
      "PERDIDAAAA despues: 0.08624199777841568\n",
      "loss en el callback: 0.09516478329896927, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "ejemplar: [[0.526932  ]\n",
      " [0.5379982 ]\n",
      " [0.54902333]\n",
      " [0.55947161]\n",
      " [0.57001555]\n",
      " [0.58012009]\n",
      " [0.59112418]\n",
      " [0.60244036]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8585767213248423\n",
      "Predicci√≥n : [[0.6141087]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[[0.526932  ]\n",
      "  [0.5379982 ]\n",
      "  [0.54902333]\n",
      "  [0.55947161]\n",
      "  [0.57001555]\n",
      "  [0.58012009]\n",
      "  [0.59112418]\n",
      "  [0.60244036]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.059764619916677475\n",
      "Predicci√≥n post entrenamiento : [[0.61550266]]\n",
      "PERDIDAAAA despues: 0.059084996581077576\n",
      "loss en el callback: 0.02218506671488285, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "ejemplar: [[0.5379982 ]\n",
      " [0.54902333]\n",
      " [0.55947161]\n",
      " [0.57001555]\n",
      " [0.58012009]\n",
      " [0.59112418]\n",
      " [0.60244036]\n",
      " [0.61410868]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8308762565987861\n",
      "Predicci√≥n : [[0.6246849]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[[0.5379982 ]\n",
      "  [0.54902333]\n",
      "  [0.55947161]\n",
      "  [0.57001555]\n",
      "  [0.58012009]\n",
      "  [0.59112418]\n",
      "  [0.60244036]\n",
      "  [0.61410868]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.042514875531196594\n",
      "Predicci√≥n post entrenamiento : [[0.62652725]]\n",
      "PERDIDAAAA despues: 0.04175850749015808\n",
      "loss en el callback: 0.0513283796608448, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "ejemplar: [[0.54902333]\n",
      " [0.55947161]\n",
      " [0.57001555]\n",
      " [0.58012009]\n",
      " [0.59112418]\n",
      " [0.60244036]\n",
      " [0.61410868]\n",
      " [0.62468487]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8156037735215196\n",
      "Predicci√≥n : [[0.63566923]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[[0.54902333]\n",
      "  [0.55947161]\n",
      "  [0.57001555]\n",
      "  [0.58012009]\n",
      "  [0.59112418]\n",
      "  [0.60244036]\n",
      "  [0.61410868]\n",
      "  [0.62468487]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03237644582986832\n",
      "Predicci√≥n post entrenamiento : [[0.6372412]]\n",
      "PERDIDAAAA despues: 0.03181321918964386\n",
      "loss en el callback: 0.03331280127167702, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "ejemplar: [[0.55947161]\n",
      " [0.57001555]\n",
      " [0.58012009]\n",
      " [0.59112418]\n",
      " [0.60244036]\n",
      " [0.61410868]\n",
      " [0.62468487]\n",
      " [0.63566923]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8116992058331503\n",
      "Predicci√≥n : [[0.6463508]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[[0.55947161]\n",
      "  [0.57001555]\n",
      "  [0.58012009]\n",
      "  [0.59112418]\n",
      "  [0.60244036]\n",
      "  [0.61410868]\n",
      "  [0.62468487]\n",
      "  [0.63566923]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.027340097352862358\n",
      "Predicci√≥n post entrenamiento : [[0.64825934]]\n",
      "PERDIDAAAA despues: 0.02671259082853794\n",
      "loss en el callback: 0.06756103783845901, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "ejemplar: [[0.57001555]\n",
      " [0.58012009]\n",
      " [0.59112418]\n",
      " [0.60244036]\n",
      " [0.61410868]\n",
      " [0.62468487]\n",
      " [0.63566923]\n",
      " [0.6463508 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8191625535336788\n",
      "Predicci√≥n : [[0.6575002]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[[0.57001555]\n",
      "  [0.58012009]\n",
      "  [0.59112418]\n",
      "  [0.60244036]\n",
      "  [0.61410868]\n",
      "  [0.62468487]\n",
      "  [0.63566923]\n",
      "  [0.6463508 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.026134712621569633\n",
      "Predicci√≥n post entrenamiento : [[0.65902865]]\n",
      "PERDIDAAAA despues: 0.025642866268754005\n",
      "loss en el callback: 0.036613766103982925, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "ejemplar: [[0.58012009]\n",
      " [0.59112418]\n",
      " [0.60244036]\n",
      " [0.61410868]\n",
      " [0.62468487]\n",
      " [0.63566923]\n",
      " [0.6463508 ]\n",
      " [0.65750021]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8218275636038536\n",
      "Predicci√≥n : [[0.66839725]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[[0.58012009]\n",
      "  [0.59112418]\n",
      "  [0.60244036]\n",
      "  [0.61410868]\n",
      "  [0.62468487]\n",
      "  [0.63566923]\n",
      "  [0.6463508 ]\n",
      "  [0.65750021]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02354086935520172\n",
      "Predicci√≥n post entrenamiento : [[0.6698866]]\n",
      "PERDIDAAAA despues: 0.023086067289114\n",
      "loss en el callback: 0.03961234167218208, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "ejemplar: [[0.59112418]\n",
      " [0.60244036]\n",
      " [0.61410868]\n",
      " [0.62468487]\n",
      " [0.63566923]\n",
      " [0.6463508 ]\n",
      " [0.65750021]\n",
      " [0.66839725]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8196942360436743\n",
      "Predicci√≥n : [[0.6795247]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[[0.59112418]\n",
      "  [0.60244036]\n",
      "  [0.61410868]\n",
      "  [0.62468487]\n",
      "  [0.63566923]\n",
      "  [0.6463508 ]\n",
      "  [0.65750021]\n",
      "  [0.66839725]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019647488370537758\n",
      "Predicci√≥n post entrenamiento : [[0.681559]]\n",
      "PERDIDAAAA despues: 0.01908133178949356\n",
      "loss en el callback: 0.11604767292737961, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "ejemplar: [[0.60244036]\n",
      " [0.61410868]\n",
      " [0.62468487]\n",
      " [0.63566923]\n",
      " [0.6463508 ]\n",
      " [0.65750021]\n",
      " [0.66839725]\n",
      " [0.67952472]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8178628420548653\n",
      "Predicci√≥n : [[0.6912469]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[[0.60244036]\n",
      "  [0.61410868]\n",
      "  [0.62468487]\n",
      "  [0.63566923]\n",
      "  [0.6463508 ]\n",
      "  [0.65750021]\n",
      "  [0.66839725]\n",
      "  [0.67952472]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016031596809625626\n",
      "Predicci√≥n post entrenamiento : [[0.6922704]]\n",
      "PERDIDAAAA despues: 0.0157734677195549\n",
      "loss en el callback: 0.015020492486655712, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "ejemplar: [[0.61410868]\n",
      " [0.62468487]\n",
      " [0.63566923]\n",
      " [0.6463508 ]\n",
      " [0.65750021]\n",
      " [0.66839725]\n",
      " [0.67952472]\n",
      " [0.69124693]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8163333816374257\n",
      "Predicci√≥n : [[0.7019153]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[[0.61410868]\n",
      "  [0.62468487]\n",
      "  [0.63566923]\n",
      "  [0.6463508 ]\n",
      "  [0.65750021]\n",
      "  [0.66839725]\n",
      "  [0.67952472]\n",
      "  [0.69124693]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01309148594737053\n",
      "Predicci√≥n post entrenamiento : [[0.70162606]]\n",
      "PERDIDAAAA despues: 0.013157762587070465\n",
      "loss en el callback: 0.0009524945635348558, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "ejemplar: [[0.62468487]\n",
      " [0.63566923]\n",
      " [0.6463508 ]\n",
      " [0.65750021]\n",
      " [0.66839725]\n",
      " [0.67952472]\n",
      " [0.69124693]\n",
      " [0.70191532]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8005556061309519\n",
      "Predicci√≥n : [[0.71111286]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[[0.62468487]\n",
      "  [0.63566923]\n",
      "  [0.6463508 ]\n",
      "  [0.65750021]\n",
      "  [0.66839725]\n",
      "  [0.67952472]\n",
      "  [0.69124693]\n",
      "  [0.70191532]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00800000224262476\n",
      "Predicci√≥n post entrenamiento : [[0.71089387]]\n",
      "PERDIDAAAA despues: 0.008039223961532116\n",
      "loss en el callback: 0.0005926229641772807, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "ejemplar: [[0.63566923]\n",
      " [0.6463508 ]\n",
      " [0.65750021]\n",
      " [0.66839725]\n",
      " [0.67952472]\n",
      " [0.69124693]\n",
      " [0.70191532]\n",
      " [0.71111286]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7705295155354442\n",
      "Predicci√≥n : [[0.72050095]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[[0.63566923]\n",
      "  [0.6463508 ]\n",
      "  [0.65750021]\n",
      "  [0.66839725]\n",
      "  [0.67952472]\n",
      "  [0.69124693]\n",
      "  [0.70191532]\n",
      "  [0.71111286]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002502857008948922\n",
      "Predicci√≥n post entrenamiento : [[0.72176003]]\n",
      "PERDIDAAAA despues: 0.0023784616496413946\n",
      "loss en el callback: 0.03671273961663246, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "ejemplar: [[0.6463508 ]\n",
      " [0.65750021]\n",
      " [0.66839725]\n",
      " [0.67952472]\n",
      " [0.69124693]\n",
      " [0.70191532]\n",
      " [0.71111286]\n",
      " [0.72050095]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7426586795525351\n",
      "Predicci√≥n : [[0.7313709]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[[0.6463508 ]\n",
      "  [0.65750021]\n",
      "  [0.66839725]\n",
      "  [0.67952472]\n",
      "  [0.69124693]\n",
      "  [0.70191532]\n",
      "  [0.71111286]\n",
      "  [0.72050095]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00012741326645482332\n",
      "Predicci√≥n post entrenamiento : [[0.7316843]]\n",
      "PERDIDAAAA despues: 0.00012043630704283714\n",
      "loss en el callback: 0.0017300582258030772, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "ejemplar: [[0.65750021]\n",
      " [0.66839725]\n",
      " [0.67952472]\n",
      " [0.69124693]\n",
      " [0.70191532]\n",
      " [0.71111286]\n",
      " [0.72050095]\n",
      " [0.73137093]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.716943098182225\n",
      "Predicci√≥n : [[0.7413538]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[[0.65750021]\n",
      "  [0.66839725]\n",
      "  [0.67952472]\n",
      "  [0.69124693]\n",
      "  [0.70191532]\n",
      "  [0.71111286]\n",
      "  [0.72050095]\n",
      "  [0.73137093]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005958834663033485\n",
      "Predicci√≥n post entrenamiento : [[0.7404224]]\n",
      "PERDIDAAAA despues: 0.0005512795178219676\n",
      "loss en el callback: 0.011411401443183422, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "ejemplar: [[0.66839725]\n",
      " [0.67952472]\n",
      " [0.69124693]\n",
      " [0.70191532]\n",
      " [0.71111286]\n",
      " [0.72050095]\n",
      " [0.73137093]\n",
      " [0.74135381]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7197051306082382\n",
      "Predicci√≥n : [[0.74998593]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[[0.66839725]\n",
      "  [0.67952472]\n",
      "  [0.69124693]\n",
      "  [0.70191532]\n",
      "  [0.71111286]\n",
      "  [0.72050095]\n",
      "  [0.73137093]\n",
      "  [0.74135381]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009169285767711699\n",
      "Predicci√≥n post entrenamiento : [[0.748125]]\n",
      "PERDIDAAAA despues: 0.000807691365480423\n",
      "loss en el callback: 0.038144901394844055, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "ejemplar: [[0.67952472]\n",
      " [0.69124693]\n",
      " [0.70191532]\n",
      " [0.71111286]\n",
      " [0.72050095]\n",
      " [0.73137093]\n",
      " [0.74135381]\n",
      " [0.74998593]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7509447768305747\n",
      "Predicci√≥n : [[0.75759345]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[[0.67952472]\n",
      "  [0.69124693]\n",
      "  [0.70191532]\n",
      "  [0.71111286]\n",
      "  [0.72050095]\n",
      "  [0.73137093]\n",
      "  [0.74135381]\n",
      "  [0.74998593]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.420467666932382e-05\n",
      "Predicci√≥n post entrenamiento : [[0.75741714]]\n",
      "PERDIDAAAA despues: 4.189130413578823e-05\n",
      "loss en el callback: 0.0005039021489210427, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "ejemplar: [[0.69124693]\n",
      " [0.70191532]\n",
      " [0.71111286]\n",
      " [0.72050095]\n",
      " [0.73137093]\n",
      " [0.74135381]\n",
      " [0.74998593]\n",
      " [0.75759345]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.740278139029679\n",
      "Predicci√≥n : [[0.7666594]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[[0.69124693]\n",
      "  [0.70191532]\n",
      "  [0.71111286]\n",
      "  [0.72050095]\n",
      "  [0.73137093]\n",
      "  [0.74135381]\n",
      "  [0.74998593]\n",
      "  [0.75759345]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006959705497138202\n",
      "Predicci√≥n post entrenamiento : [[0.76627123]]\n",
      "PERDIDAAAA despues: 0.0006756416987627745\n",
      "loss en el callback: 0.002335853176191449, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "ejemplar: [[0.70191532]\n",
      " [0.71111286]\n",
      " [0.72050095]\n",
      " [0.73137093]\n",
      " [0.74135381]\n",
      " [0.74998593]\n",
      " [0.75759345]\n",
      " [0.76665938]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.687705217205551\n",
      "Predicci√≥n : [[0.7750248]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[[0.70191532]\n",
      "  [0.71111286]\n",
      "  [0.72050095]\n",
      "  [0.73137093]\n",
      "  [0.74135381]\n",
      "  [0.74998593]\n",
      "  [0.75759345]\n",
      "  [0.76665938]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0076247043907642365\n",
      "Predicci√≥n post entrenamiento : [[0.77350533]]\n",
      "PERDIDAAAA despues: 0.007361659314483404\n",
      "loss en el callback: 0.03127748891711235, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "ejemplar: [[0.71111286]\n",
      " [0.72050095]\n",
      " [0.73137093]\n",
      " [0.74135381]\n",
      " [0.74998593]\n",
      " [0.75759345]\n",
      " [0.76665938]\n",
      " [0.77502477]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6687695580612426\n",
      "Predicci√≥n : [[0.78195024]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[[0.71111286]\n",
      "  [0.72050095]\n",
      "  [0.73137093]\n",
      "  [0.74135381]\n",
      "  [0.74998593]\n",
      "  [0.75759345]\n",
      "  [0.76665938]\n",
      "  [0.77502477]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012809869833290577\n",
      "Predicci√≥n post entrenamiento : [[0.78062207]]\n",
      "PERDIDAAAA despues: 0.012510987929999828\n",
      "loss en el callback: 0.02658466063439846, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "ejemplar: [[0.72050095]\n",
      " [0.73137093]\n",
      " [0.74135381]\n",
      " [0.74998593]\n",
      " [0.75759345]\n",
      " [0.76665938]\n",
      " [0.77502477]\n",
      " [0.78195024]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6834711615967536\n",
      "Predicci√≥n : [[0.7890897]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[[0.72050095]\n",
      "  [0.73137093]\n",
      "  [0.74135381]\n",
      "  [0.74998593]\n",
      "  [0.75759345]\n",
      "  [0.76665938]\n",
      "  [0.77502477]\n",
      "  [0.78195024]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011155275627970695\n",
      "Predicci√≥n post entrenamiento : [[0.78813976]]\n",
      "PERDIDAAAA despues: 0.010955519042909145\n",
      "loss en el callback: 0.015473688952624798, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "ejemplar: [[0.73137093]\n",
      " [0.74135381]\n",
      " [0.74998593]\n",
      " [0.75759345]\n",
      " [0.76665938]\n",
      " [0.77502477]\n",
      " [0.78195024]\n",
      " [0.78908968]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6877052172055499\n",
      "Predicci√≥n : [[0.79651695]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[[0.73137093]\n",
      "  [0.74135381]\n",
      "  [0.74998593]\n",
      "  [0.75759345]\n",
      "  [0.76665938]\n",
      "  [0.77502477]\n",
      "  [0.78195024]\n",
      "  [0.78908968]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011839994229376316\n",
      "Predicci√≥n post entrenamiento : [[0.79488]]\n",
      "PERDIDAAAA despues: 0.01148642785847187\n",
      "loss en el callback: 0.04006859287619591, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "ejemplar: [[0.74135381]\n",
      " [0.74998593]\n",
      " [0.75759345]\n",
      " [0.76665938]\n",
      " [0.77502477]\n",
      " [0.78195024]\n",
      " [0.78908968]\n",
      " [0.79651695]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6814717248876317\n",
      "Predicci√≥n : [[0.80265266]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[[0.74135381]\n",
      "  [0.74998593]\n",
      "  [0.75759345]\n",
      "  [0.76665938]\n",
      "  [0.77502477]\n",
      "  [0.78195024]\n",
      "  [0.78908968]\n",
      "  [0.79651695]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014684823341667652\n",
      "Predicci√≥n post entrenamiento : [[0.80104375]]\n",
      "PERDIDAAAA despues: 0.01429747324436903\n",
      "loss en el callback: 0.03779871016740799, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "ejemplar: [[0.74998593]\n",
      " [0.75759345]\n",
      " [0.76665938]\n",
      " [0.77502477]\n",
      " [0.78195024]\n",
      " [0.78908968]\n",
      " [0.79651695]\n",
      " [0.80265266]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.689261843882625\n",
      "Predicci√≥n : [[0.8083186]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[[0.74998593]\n",
      "  [0.75759345]\n",
      "  [0.76665938]\n",
      "  [0.77502477]\n",
      "  [0.78195024]\n",
      "  [0.78908968]\n",
      "  [0.79651695]\n",
      "  [0.80265266]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014174512587487698\n",
      "Predicci√≥n post entrenamiento : [[0.806817]]\n",
      "PERDIDAAAA despues: 0.013819211162626743\n",
      "loss en el callback: 0.035546425729990005, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "ejemplar: [[0.75759345]\n",
      " [0.76665938]\n",
      " [0.77502477]\n",
      " [0.78195024]\n",
      " [0.78908968]\n",
      " [0.79651695]\n",
      " [0.80265266]\n",
      " [0.80831861]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7110755741905297\n",
      "Predicci√≥n : [[0.8138575]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[[0.75759345]\n",
      "  [0.76665938]\n",
      "  [0.77502477]\n",
      "  [0.78195024]\n",
      "  [0.78908968]\n",
      "  [0.79651695]\n",
      "  [0.80265266]\n",
      "  [0.80831861]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010564117692410946\n",
      "Predicci√≥n post entrenamiento : [[0.81294674]]\n",
      "PERDIDAAAA despues: 0.010377727448940277\n",
      "loss en el callback: 0.013735298998653889, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "ejemplar: [[0.76665938]\n",
      " [0.77502477]\n",
      " [0.78195024]\n",
      " [0.78908968]\n",
      " [0.79651695]\n",
      " [0.80265266]\n",
      " [0.80831861]\n",
      " [0.8138575 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7349108623046875\n",
      "Predicci√≥n : [[0.81995744]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[[0.76665938]\n",
      "  [0.77502477]\n",
      "  [0.78195024]\n",
      "  [0.78908968]\n",
      "  [0.79651695]\n",
      "  [0.80265266]\n",
      "  [0.80831861]\n",
      "  [0.8138575 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0072329225949943066\n",
      "Predicci√≥n post entrenamiento : [[0.8192789]]\n",
      "PERDIDAAAA despues: 0.007117968052625656\n",
      "loss en el callback: 0.007917220704257488, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "ejemplar: [[0.77502477]\n",
      " [0.78195024]\n",
      " [0.78908968]\n",
      " [0.79651695]\n",
      " [0.80265266]\n",
      " [0.80831861]\n",
      " [0.8138575 ]\n",
      " [0.81995744]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7607677082250986\n",
      "Predicci√≥n : [[0.8257651]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[[0.77502477]\n",
      "  [0.78195024]\n",
      "  [0.78908968]\n",
      "  [0.79651695]\n",
      "  [0.80265266]\n",
      "  [0.80831861]\n",
      "  [0.8138575 ]\n",
      "  [0.81995744]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004224658943712711\n",
      "Predicci√≥n post entrenamiento : [[0.8247525]]\n",
      "PERDIDAAAA despues: 0.004094055853784084\n",
      "loss en el callback: 0.016222205013036728, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "ejemplar: [[0.78195024]\n",
      " [0.78908968]\n",
      " [0.79651695]\n",
      " [0.80265266]\n",
      " [0.80831861]\n",
      " [0.8138575 ]\n",
      " [0.81995744]\n",
      " [0.82576507]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7711170829224028\n",
      "Predicci√≥n : [[0.830785]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[[0.78195024]\n",
      "  [0.78908968]\n",
      "  [0.79651695]\n",
      "  [0.80265266]\n",
      "  [0.80831861]\n",
      "  [0.8138575 ]\n",
      "  [0.81995744]\n",
      "  [0.82576507]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0035602564457803965\n",
      "Predicci√≥n post entrenamiento : [[0.82939345]]\n",
      "PERDIDAAAA despues: 0.0033961336594074965\n",
      "loss en el callback: 0.029031334444880486, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "ejemplar: [[0.78908968]\n",
      " [0.79651695]\n",
      " [0.80265266]\n",
      " [0.80831861]\n",
      " [0.8138575 ]\n",
      " [0.81995744]\n",
      " [0.82576507]\n",
      " [0.83078498]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7659589863965997\n",
      "Predicci√≥n : [[0.83527994]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[[0.78908968]\n",
      "  [0.79651695]\n",
      "  [0.80265266]\n",
      "  [0.80831861]\n",
      "  [0.8138575 ]\n",
      "  [0.81995744]\n",
      "  [0.82576507]\n",
      "  [0.83078498]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00480539770796895\n",
      "Predicci√≥n post entrenamiento : [[0.8348576]]\n",
      "PERDIDAAAA despues: 0.004747019615024328\n",
      "loss en el callback: 0.0034256461076438427, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "ejemplar: [[0.79651695]\n",
      " [0.80265266]\n",
      " [0.80831861]\n",
      " [0.8138575 ]\n",
      " [0.81995744]\n",
      " [0.82576507]\n",
      " [0.83078498]\n",
      " [0.83527994]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7483323528772654\n",
      "Predicci√≥n : [[0.840469]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[[0.79651695]\n",
      "  [0.80265266]\n",
      "  [0.80831861]\n",
      "  [0.8138575 ]\n",
      "  [0.81995744]\n",
      "  [0.82576507]\n",
      "  [0.83078498]\n",
      "  [0.83527994]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008489157073199749\n",
      "Predicci√≥n post entrenamiento : [[0.8398178]]\n",
      "PERDIDAAAA despues: 0.008369585499167442\n",
      "loss en el callback: 0.007755795493721962, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "ejemplar: [[0.80265266]\n",
      " [0.80831861]\n",
      " [0.8138575 ]\n",
      " [0.81995744]\n",
      " [0.82576507]\n",
      " [0.83078498]\n",
      " [0.83527994]\n",
      " [0.840469  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7182371823643998\n",
      "Predicci√≥n : [[0.84498817]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[[0.80265266]\n",
      "  [0.80831861]\n",
      "  [0.8138575 ]\n",
      "  [0.81995744]\n",
      "  [0.82576507]\n",
      "  [0.83078498]\n",
      "  [0.83527994]\n",
      "  [0.840469  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016065817326307297\n",
      "Predicci√≥n post entrenamiento : [[0.84438574]]\n",
      "PERDIDAAAA despues: 0.0159134641289711\n",
      "loss en el callback: 0.00748303160071373, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "ejemplar: [[0.80831861]\n",
      " [0.8138575 ]\n",
      " [0.81995744]\n",
      " [0.82576507]\n",
      " [0.83078498]\n",
      " [0.83527994]\n",
      " [0.840469  ]\n",
      " [0.84498817]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7089416644962148\n",
      "Predicci√≥n : [[0.84939456]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[[0.80831861]\n",
      "  [0.8138575 ]\n",
      "  [0.81995744]\n",
      "  [0.82576507]\n",
      "  [0.83078498]\n",
      "  [0.83527994]\n",
      "  [0.840469  ]\n",
      "  [0.84498817]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01972702331840992\n",
      "Predicci√≥n post entrenamiento : [[0.8491154]]\n",
      "PERDIDAAAA despues: 0.019648674875497818\n",
      "loss en el callback: 0.0018386022420600057, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "ejemplar: [[0.8138575 ]\n",
      " [0.81995744]\n",
      " [0.82576507]\n",
      " [0.83078498]\n",
      " [0.83527994]\n",
      " [0.840469  ]\n",
      " [0.84498817]\n",
      " [0.84939456]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7204457992727099\n",
      "Predicci√≥n : [[0.8540459]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[[0.8138575 ]\n",
      "  [0.81995744]\n",
      "  [0.82576507]\n",
      "  [0.83078498]\n",
      "  [0.83527994]\n",
      "  [0.840469  ]\n",
      "  [0.84498817]\n",
      "  [0.84939456]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017848990857601166\n",
      "Predicci√≥n post entrenamiento : [[0.8529261]]\n",
      "PERDIDAAAA despues: 0.01755101978778839\n",
      "loss en el callback: 0.02389967441558838, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "ejemplar: [[0.81995744]\n",
      " [0.82576507]\n",
      " [0.83078498]\n",
      " [0.83527994]\n",
      " [0.840469  ]\n",
      " [0.84498817]\n",
      " [0.84939456]\n",
      " [0.85404593]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.770615477342717\n",
      "Predicci√≥n : [[0.8577702]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[[0.81995744]\n",
      "  [0.82576507]\n",
      "  [0.83078498]\n",
      "  [0.83527994]\n",
      "  [0.840469  ]\n",
      "  [0.84498817]\n",
      "  [0.84939456]\n",
      "  [0.85404593]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0075959498062729836\n",
      "Predicci√≥n post entrenamiento : [[0.85637957]]\n",
      "PERDIDAAAA despues: 0.007355482783168554\n",
      "loss en el callback: 0.0358441025018692, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "ejemplar: [[0.82576507]\n",
      " [0.83078498]\n",
      " [0.83527994]\n",
      " [0.840469  ]\n",
      " [0.84498817]\n",
      " [0.84939456]\n",
      " [0.85404593]\n",
      " [0.8577702 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8594506987062355\n",
      "Predicci√≥n : [[0.86092305]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[[0.82576507]\n",
      "  [0.83078498]\n",
      "  [0.83527994]\n",
      "  [0.840469  ]\n",
      "  [0.84498817]\n",
      "  [0.84939456]\n",
      "  [0.85404593]\n",
      "  [0.8577702 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.167826096410863e-06\n",
      "Predicci√≥n post entrenamiento : [[0.8613867]]\n",
      "PERDIDAAAA despues: 3.748167500816635e-06\n",
      "loss en el callback: 0.005124207586050034, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "ejemplar: [[0.83078498]\n",
      " [0.83527994]\n",
      " [0.840469  ]\n",
      " [0.84498817]\n",
      " [0.84939456]\n",
      " [0.85404593]\n",
      " [0.8577702 ]\n",
      " [0.86092305]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9065410812466371\n",
      "Predicci√≥n : [[0.8656369]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[[0.83078498]\n",
      "  [0.83527994]\n",
      "  [0.840469  ]\n",
      "  [0.84498817]\n",
      "  [0.84939456]\n",
      "  [0.85404593]\n",
      "  [0.8577702 ]\n",
      "  [0.86092305]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016731555806472898\n",
      "Predicci√≥n post entrenamiento : [[0.86679417]]\n",
      "PERDIDAAAA despues: 0.0015798192471265793\n",
      "loss en el callback: 0.03799555078148842, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "ejemplar: [[0.83527994]\n",
      " [0.840469  ]\n",
      " [0.84498817]\n",
      " [0.84939456]\n",
      " [0.85404593]\n",
      " [0.8577702 ]\n",
      " [0.86092305]\n",
      " [0.86563689]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9118866249639219\n",
      "Predicci√≥n : [[0.8709122]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[[0.83527994]\n",
      "  [0.840469  ]\n",
      "  [0.84498817]\n",
      "  [0.84939456]\n",
      "  [0.85404593]\n",
      "  [0.8577702 ]\n",
      "  [0.86092305]\n",
      "  [0.86563689]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001678904634900391\n",
      "Predicci√≥n post entrenamiento : [[0.8706203]]\n",
      "PERDIDAAAA despues: 0.0017029093578457832\n",
      "loss en el callback: 0.0014346191892400384, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "ejemplar: [[0.840469  ]\n",
      " [0.84498817]\n",
      " [0.84939456]\n",
      " [0.85404593]\n",
      " [0.8577702 ]\n",
      " [0.86092305]\n",
      " [0.86563689]\n",
      " [0.87091219]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.904335569053715\n",
      "Predicci√≥n : [[0.8747222]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[[0.840469  ]\n",
      "  [0.84498817]\n",
      "  [0.84939456]\n",
      "  [0.85404593]\n",
      "  [0.8577702 ]\n",
      "  [0.86092305]\n",
      "  [0.86563689]\n",
      "  [0.87091219]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008769520209170878\n",
      "Predicci√≥n post entrenamiento : [[0.8754711]]\n",
      "PERDIDAAAA despues: 0.0008331561111845076\n",
      "loss en el callback: 0.014589260332286358, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "ejemplar: [[0.84498817]\n",
      " [0.84939456]\n",
      " [0.85404593]\n",
      " [0.8577702 ]\n",
      " [0.86092305]\n",
      " [0.86563689]\n",
      " [0.87091219]\n",
      " [0.87472218]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8838879135160167\n",
      "Predicci√≥n : [[0.8793401]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[[0.84498817]\n",
      "  [0.84939456]\n",
      "  [0.85404593]\n",
      "  [0.8577702 ]\n",
      "  [0.86092305]\n",
      "  [0.86563689]\n",
      "  [0.87091219]\n",
      "  [0.87472218]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.0682255126303062e-05\n",
      "Predicci√≥n post entrenamiento : [[0.8795547]]\n",
      "PERDIDAAAA despues: 1.8776605429593474e-05\n",
      "loss en el callback: 0.0010681170970201492, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "ejemplar: [[0.84939456]\n",
      " [0.85404593]\n",
      " [0.8577702 ]\n",
      " [0.86092305]\n",
      " [0.86563689]\n",
      " [0.87091219]\n",
      " [0.87472218]\n",
      " [0.87934011]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9032153489332012\n",
      "Predicci√≥n : [[0.88334996]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[[0.84939456]\n",
      "  [0.85404593]\n",
      "  [0.8577702 ]\n",
      "  [0.86092305]\n",
      "  [0.86563689]\n",
      "  [0.87091219]\n",
      "  [0.87472218]\n",
      "  [0.87934011]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00039463385473936796\n",
      "Predicci√≥n post entrenamiento : [[0.8826375]]\n",
      "PERDIDAAAA despues: 0.00042344784014858305\n",
      "loss en el callback: 0.008730064146220684, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "ejemplar: [[0.85404593]\n",
      " [0.8577702 ]\n",
      " [0.86092305]\n",
      " [0.86563689]\n",
      " [0.87091219]\n",
      " [0.87472218]\n",
      " [0.87934011]\n",
      " [0.88334996]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9623178753052692\n",
      "Predicci√≥n : [[0.88638324]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[[0.85404593]\n",
      "  [0.8577702 ]\n",
      "  [0.86092305]\n",
      "  [0.86563689]\n",
      "  [0.87091219]\n",
      "  [0.87472218]\n",
      "  [0.87934011]\n",
      "  [0.88334996]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005766070913523436\n",
      "Predicci√≥n post entrenamiento : [[0.8870105]]\n",
      "PERDIDAAAA despues: 0.005671199876815081\n",
      "loss en el callback: 0.009208829142153263, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "ejemplar: [[0.8577702 ]\n",
      " [0.86092305]\n",
      " [0.86563689]\n",
      " [0.87091219]\n",
      " [0.87472218]\n",
      " [0.87934011]\n",
      " [0.88334996]\n",
      " [0.88638324]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.982058820003038\n",
      "Predicci√≥n : [[0.8906284]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[[0.8577702 ]\n",
      "  [0.86092305]\n",
      "  [0.86563689]\n",
      "  [0.87091219]\n",
      "  [0.87472218]\n",
      "  [0.87934011]\n",
      "  [0.88334996]\n",
      "  [0.88638324]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008359522558748722\n",
      "Predicci√≥n post entrenamiento : [[0.8906429]]\n",
      "PERDIDAAAA despues: 0.00835687480866909\n",
      "loss en el callback: 4.078960955666844e-06, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "ejemplar: [[0.86092305]\n",
      " [0.86563689]\n",
      " [0.87091219]\n",
      " [0.87472218]\n",
      " [0.87934011]\n",
      " [0.88334996]\n",
      " [0.88638324]\n",
      " [0.8906284 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9624381830265082\n",
      "Predicci√≥n : [[0.89438534]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[[0.86092305]\n",
      "  [0.86563689]\n",
      "  [0.87091219]\n",
      "  [0.87472218]\n",
      "  [0.87934011]\n",
      "  [0.88334996]\n",
      "  [0.88638324]\n",
      "  [0.8906284 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004631187301129103\n",
      "Predicci√≥n post entrenamiento : [[0.89481944]]\n",
      "PERDIDAAAA despues: 0.004572292324155569\n",
      "loss en el callback: 0.004154074937105179, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "ejemplar: [[0.86563689]\n",
      " [0.87091219]\n",
      " [0.87472218]\n",
      " [0.87934011]\n",
      " [0.88334996]\n",
      " [0.88638324]\n",
      " [0.8906284 ]\n",
      " [0.89438534]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9302512105217627\n",
      "Predicci√≥n : [[0.8988646]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[[0.86563689]\n",
      "  [0.87091219]\n",
      "  [0.87472218]\n",
      "  [0.87934011]\n",
      "  [0.88334996]\n",
      "  [0.88638324]\n",
      "  [0.8906284 ]\n",
      "  [0.89438534]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009851157665252686\n",
      "Predicci√≥n post entrenamiento : [[0.89730084]]\n",
      "PERDIDAAAA despues: 0.001085725030861795\n",
      "loss en el callback: 0.038684338331222534, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "ejemplar: [[0.87091219]\n",
      " [0.87472218]\n",
      " [0.87934011]\n",
      " [0.88334996]\n",
      " [0.88638324]\n",
      " [0.8906284 ]\n",
      " [0.89438534]\n",
      " [0.89886463]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.885497902488802\n",
      "Predicci√≥n : [[0.90121156]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[[0.87091219]\n",
      "  [0.87472218]\n",
      "  [0.87934011]\n",
      "  [0.88334996]\n",
      "  [0.88638324]\n",
      "  [0.8906284 ]\n",
      "  [0.89438534]\n",
      "  [0.89886463]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00024691823637112975\n",
      "Predicci√≥n post entrenamiento : [[0.90077823]]\n",
      "PERDIDAAAA despues: 0.000233487764489837\n",
      "loss en el callback: 0.004222109913825989, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "ejemplar: [[0.87472218]\n",
      " [0.87934011]\n",
      " [0.88334996]\n",
      " [0.88638324]\n",
      " [0.8906284 ]\n",
      " [0.89438534]\n",
      " [0.89886463]\n",
      " [0.90121156]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597025687419927\n",
      "Predicci√≥n : [[0.90434587]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[[0.87472218]\n",
      "  [0.87934011]\n",
      "  [0.88334996]\n",
      "  [0.88638324]\n",
      "  [0.8906284 ]\n",
      "  [0.89438534]\n",
      "  [0.89886463]\n",
      "  [0.90121156]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0019930226262658834\n",
      "Predicci√≥n post entrenamiento : [[0.90373856]]\n",
      "PERDIDAAAA despues: 0.0019391668029129505\n",
      "loss en el callback: 0.0077175237238407135, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "ejemplar: [[0.87934011]\n",
      " [0.88334996]\n",
      " [0.88638324]\n",
      " [0.8906284 ]\n",
      " [0.89438534]\n",
      " [0.89886463]\n",
      " [0.90121156]\n",
      " [0.90434587]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8528652092813349\n",
      "Predicci√≥n : [[0.9073222]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[[0.87934011]\n",
      "  [0.88334996]\n",
      "  [0.88638324]\n",
      "  [0.8906284 ]\n",
      "  [0.89438534]\n",
      "  [0.89886463]\n",
      "  [0.90121156]\n",
      "  [0.90434587]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029655657708644867\n",
      "Predicci√≥n post entrenamiento : [[0.90755266]]\n",
      "PERDIDAAAA despues: 0.0029907161369919777\n",
      "loss en el callback: 0.0014235603157430887, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "ejemplar: [[0.88334996]\n",
      " [0.88638324]\n",
      " [0.8906284 ]\n",
      " [0.89438534]\n",
      " [0.89886463]\n",
      " [0.90121156]\n",
      " [0.90434587]\n",
      " [0.90732223]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8585854533368672\n",
      "Predicci√≥n : [[0.91089416]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[[0.88334996]\n",
      "  [0.88638324]\n",
      "  [0.8906284 ]\n",
      "  [0.89438534]\n",
      "  [0.89886463]\n",
      "  [0.90121156]\n",
      "  [0.90434587]\n",
      "  [0.90732223]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0027361977845430374\n",
      "Predicci√≥n post entrenamiento : [[0.91086]]\n",
      "PERDIDAAAA despues: 0.0027326259296387434\n",
      "loss en el callback: 3.463819302851334e-05, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "ejemplar: [[0.88638324]\n",
      " [0.8906284 ]\n",
      " [0.89438534]\n",
      " [0.89886463]\n",
      " [0.90121156]\n",
      " [0.90434587]\n",
      " [0.90732223]\n",
      " [0.91089416]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8768633009085897\n",
      "Predicci√≥n : [[0.9140829]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[[0.88638324]\n",
      "  [0.8906284 ]\n",
      "  [0.89438534]\n",
      "  [0.89886463]\n",
      "  [0.90121156]\n",
      "  [0.90434587]\n",
      "  [0.90732223]\n",
      "  [0.91089416]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001385297393426299\n",
      "Predicci√≥n post entrenamiento : [[0.91359115]]\n",
      "PERDIDAAAA despues: 0.0013489346019923687\n",
      "loss en el callback: 0.006083369255065918, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "ejemplar: [[0.8906284 ]\n",
      " [0.89438534]\n",
      " [0.89886463]\n",
      " [0.90121156]\n",
      " [0.90434587]\n",
      " [0.90732223]\n",
      " [0.91089416]\n",
      " [0.91408288]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8806463966074481\n",
      "Predicci√≥n : [[0.91694903]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[[0.8906284 ]\n",
      "  [0.89438534]\n",
      "  [0.89886463]\n",
      "  [0.90121156]\n",
      "  [0.90434587]\n",
      "  [0.90732223]\n",
      "  [0.91089416]\n",
      "  [0.91408288]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001317880698479712\n",
      "Predicci√≥n post entrenamiento : [[0.91694766]]\n",
      "PERDIDAAAA despues: 0.00131778116337955\n",
      "loss en el callback: 5.7756551541388035e-08, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "ejemplar: [[0.89438534]\n",
      " [0.89886463]\n",
      " [0.90121156]\n",
      " [0.90434587]\n",
      " [0.90732223]\n",
      " [0.91089416]\n",
      " [0.91408288]\n",
      " [0.91694903]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8699347404334429\n",
      "Predicci√≥n : [[0.92008185]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[[0.89438534]\n",
      "  [0.89886463]\n",
      "  [0.90121156]\n",
      "  [0.90434587]\n",
      "  [0.90732223]\n",
      "  [0.91089416]\n",
      "  [0.91408288]\n",
      "  [0.91694903]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0025147332344204187\n",
      "Predicci√≥n post entrenamiento : [[0.9202619]]\n",
      "PERDIDAAAA despues: 0.0025328253395855427\n",
      "loss en el callback: 0.0008601064328104258, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "ejemplar: [[0.89886463]\n",
      " [0.90121156]\n",
      " [0.90434587]\n",
      " [0.90732223]\n",
      " [0.91089416]\n",
      " [0.91408288]\n",
      " [0.91694903]\n",
      " [0.92008185]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8465135437340043\n",
      "Predicci√≥n : [[0.9232661]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[[0.89886463]\n",
      "  [0.90121156]\n",
      "  [0.90434587]\n",
      "  [0.90732223]\n",
      "  [0.91089416]\n",
      "  [0.91408288]\n",
      "  [0.91694903]\n",
      "  [0.92008185]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0058909528888762\n",
      "Predicci√≥n post entrenamiento : [[0.9220804]]\n",
      "PERDIDAAAA despues: 0.005710345692932606\n",
      "loss en el callback: 0.029936686158180237, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "ejemplar: [[0.90121156]\n",
      " [0.90434587]\n",
      " [0.90732223]\n",
      " [0.91089416]\n",
      " [0.91408288]\n",
      " [0.91694903]\n",
      " [0.92008185]\n",
      " [0.92326611]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8103828065091326\n",
      "Predicci√≥n : [[0.9247129]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[[0.90121156]\n",
      "  [0.90434587]\n",
      "  [0.90732223]\n",
      "  [0.91089416]\n",
      "  [0.91408288]\n",
      "  [0.91694903]\n",
      "  [0.92008185]\n",
      "  [0.92326611]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013071374967694283\n",
      "Predicci√≥n post entrenamiento : [[0.923562]]\n",
      "PERDIDAAAA despues: 0.012809532694518566\n",
      "loss en el callback: 0.030420172959566116, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "ejemplar: [[0.90434587]\n",
      " [0.90732223]\n",
      " [0.91089416]\n",
      " [0.91408288]\n",
      " [0.91694903]\n",
      " [0.92008185]\n",
      " [0.92326611]\n",
      " [0.9247129 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8026111217617493\n",
      "Predicci√≥n : [[0.92639077]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[[0.90434587]\n",
      "  [0.90732223]\n",
      "  [0.91089416]\n",
      "  [0.91408288]\n",
      "  [0.91694903]\n",
      "  [0.92008185]\n",
      "  [0.92326611]\n",
      "  [0.9247129 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015321402810513973\n",
      "Predicci√≥n post entrenamiento : [[0.9264415]]\n",
      "PERDIDAAAA despues: 0.015333962626755238\n",
      "loss en el callback: 8.854293992044404e-05, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "ejemplar: [[0.90732223]\n",
      " [0.91089416]\n",
      " [0.91408288]\n",
      " [0.91694903]\n",
      " [0.92008185]\n",
      " [0.92326611]\n",
      " [0.9247129 ]\n",
      " [0.92639077]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.823198489491854\n",
      "Predicci√≥n : [[0.9292432]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[[0.90732223]\n",
      "  [0.91089416]\n",
      "  [0.91408288]\n",
      "  [0.91694903]\n",
      "  [0.92008185]\n",
      "  [0.92326611]\n",
      "  [0.9247129 ]\n",
      "  [0.92639077]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011245480738580227\n",
      "Predicci√≥n post entrenamiento : [[0.9274857]]\n",
      "PERDIDAAAA despues: 0.010875821113586426\n",
      "loss en el callback: 0.060874707996845245, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "ejemplar: [[0.91089416]\n",
      " [0.91408288]\n",
      " [0.91694903]\n",
      " [0.92008185]\n",
      " [0.92326611]\n",
      " [0.9247129 ]\n",
      " [0.92639077]\n",
      " [0.92924321]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8397204264676091\n",
      "Predicci√≥n : [[0.93027383]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[[0.91089416]\n",
      "  [0.91408288]\n",
      "  [0.91694903]\n",
      "  [0.92008185]\n",
      "  [0.92326611]\n",
      "  [0.9247129 ]\n",
      "  [0.92639077]\n",
      "  [0.92924321]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008199919015169144\n",
      "Predicci√≥n post entrenamiento : [[0.9298412]]\n",
      "PERDIDAAAA despues: 0.008121756836771965\n",
      "loss en el callback: 0.005521525163203478, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "ejemplar: [[0.91408288]\n",
      " [0.91694903]\n",
      " [0.92008185]\n",
      " [0.92326611]\n",
      " [0.9247129 ]\n",
      " [0.92639077]\n",
      " [0.92924321]\n",
      " [0.93027383]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.852176932689015\n",
      "Predicci√≥n : [[0.93240184]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[[0.91408288]\n",
      "  [0.91694903]\n",
      "  [0.92008185]\n",
      "  [0.92326611]\n",
      "  [0.9247129 ]\n",
      "  [0.92639077]\n",
      "  [0.92924321]\n",
      "  [0.93027383]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0064360396936535835\n",
      "Predicci√≥n post entrenamiento : [[0.9317156]]\n",
      "PERDIDAAAA despues: 0.006326405331492424\n",
      "loss en el callback: 0.011230720207095146, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "ejemplar: [[0.91694903]\n",
      " [0.92008185]\n",
      " [0.92326611]\n",
      " [0.9247129 ]\n",
      " [0.92639077]\n",
      " [0.92924321]\n",
      " [0.93027383]\n",
      " [0.93240184]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8615626813481295\n",
      "Predicci√≥n : [[0.93409157]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[[0.91694903]\n",
      "  [0.92008185]\n",
      "  [0.92326611]\n",
      "  [0.9247129 ]\n",
      "  [0.92639077]\n",
      "  [0.92924321]\n",
      "  [0.93027383]\n",
      "  [0.93240184]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0052604409866034985\n",
      "Predicci√≥n post entrenamiento : [[0.9338787]]\n",
      "PERDIDAAAA despues: 0.005229610949754715\n",
      "loss en el callback: 0.0013210027245804667, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "ejemplar: [[0.92008185]\n",
      " [0.92326611]\n",
      " [0.9247129 ]\n",
      " [0.92639077]\n",
      " [0.92924321]\n",
      " [0.93027383]\n",
      " [0.93240184]\n",
      " [0.93409157]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8678776724449532\n",
      "Predicci√≥n : [[0.93610567]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[[0.92008185]\n",
      "  [0.92326611]\n",
      "  [0.9247129 ]\n",
      "  [0.92639077]\n",
      "  [0.92924321]\n",
      "  [0.93027383]\n",
      "  [0.93240184]\n",
      "  [0.93409157]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004655060824006796\n",
      "Predicci√≥n post entrenamiento : [[0.93527967]]\n",
      "PERDIDAAAA despues: 0.004543030168861151\n",
      "loss en el callback: 0.0150162847712636, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "ejemplar: [[0.92326611]\n",
      " [0.9247129 ]\n",
      " [0.92639077]\n",
      " [0.92924321]\n",
      " [0.93027383]\n",
      " [0.93240184]\n",
      " [0.93409157]\n",
      " [0.93610567]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8701963127047843\n",
      "Predicci√≥n : [[0.9372307]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[[0.92326611]\n",
      "  [0.9247129 ]\n",
      "  [0.92639077]\n",
      "  [0.92924321]\n",
      "  [0.93027383]\n",
      "  [0.93240184]\n",
      "  [0.93409157]\n",
      "  [0.93610567]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004493605811148882\n",
      "Predicci√≥n post entrenamiento : [[0.93776315]]\n",
      "PERDIDAAAA despues: 0.004565273877233267\n",
      "loss en el callback: 0.009744052775204182, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "ejemplar: [[0.9247129 ]\n",
      " [0.92639077]\n",
      " [0.92924321]\n",
      " [0.93027383]\n",
      " [0.93240184]\n",
      " [0.93409157]\n",
      " [0.93610567]\n",
      " [0.93723071]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8685186021276227\n",
      "Predicci√≥n : [[0.9393645]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[[0.9247129 ]\n",
      "  [0.92639077]\n",
      "  [0.92924321]\n",
      "  [0.93027383]\n",
      "  [0.93240184]\n",
      "  [0.93409157]\n",
      "  [0.93610567]\n",
      "  [0.93723071]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00501914182677865\n",
      "Predicci√≥n post entrenamiento : [[0.93967336]]\n",
      "PERDIDAAAA despues: 0.005063001532107592\n",
      "loss en el callback: 0.003741861553862691, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "ejemplar: [[0.92639077]\n",
      " [0.92924321]\n",
      " [0.93027383]\n",
      " [0.93240184]\n",
      " [0.93409157]\n",
      " [0.93610567]\n",
      " [0.93723071]\n",
      " [0.93936449]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8529880395838255\n",
      "Predicci√≥n : [[0.94138056]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[[0.92639077]\n",
      "  [0.92924321]\n",
      "  [0.93027383]\n",
      "  [0.93240184]\n",
      "  [0.93409157]\n",
      "  [0.93610567]\n",
      "  [0.93723071]\n",
      "  [0.93936449]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007813232950866222\n",
      "Predicci√≥n post entrenamiento : [[0.9414982]]\n",
      "PERDIDAAAA despues: 0.007834048010408878\n",
      "loss en el callback: 0.00047279431601054966, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "ejemplar: [[0.92924321]\n",
      " [0.93027383]\n",
      " [0.93240184]\n",
      " [0.93409157]\n",
      " [0.93610567]\n",
      " [0.93723071]\n",
      " [0.93936449]\n",
      " [0.94138056]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8236046250733932\n",
      "Predicci√≥n : [[0.94325435]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[[0.92924321]\n",
      "  [0.93027383]\n",
      "  [0.93240184]\n",
      "  [0.93409157]\n",
      "  [0.93610567]\n",
      "  [0.93723071]\n",
      "  [0.93936449]\n",
      "  [0.94138056]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014316053129732609\n",
      "Predicci√≥n post entrenamiento : [[0.9439759]]\n",
      "PERDIDAAAA despues: 0.014489245600998402\n",
      "loss en el callback: 0.030164165422320366, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "ejemplar: [[0.93027383]\n",
      " [0.93240184]\n",
      " [0.93409157]\n",
      " [0.93610567]\n",
      " [0.93723071]\n",
      " [0.93936449]\n",
      " [0.94138056]\n",
      " [0.94325435]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8032508871761479\n",
      "Predicci√≥n : [[0.94543886]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[[0.93027383]\n",
      "  [0.93240184]\n",
      "  [0.93409157]\n",
      "  [0.93610567]\n",
      "  [0.93723071]\n",
      "  [0.93936449]\n",
      "  [0.94138056]\n",
      "  [0.94325435]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02021741308271885\n",
      "Predicci√≥n post entrenamiento : [[0.94515496]]\n",
      "PERDIDAAAA despues: 0.02013676054775715\n",
      "loss en el callback: 0.0027007574681192636, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "ejemplar: [[0.93240184]\n",
      " [0.93409157]\n",
      " [0.93610567]\n",
      " [0.93723071]\n",
      " [0.93936449]\n",
      " [0.94138056]\n",
      " [0.94325435]\n",
      " [0.94543886]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7919268258920897\n",
      "Predicci√≥n : [[0.94682497]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[[0.93240184]\n",
      "  [0.93409157]\n",
      "  [0.93610567]\n",
      "  [0.93723071]\n",
      "  [0.93936449]\n",
      "  [0.94138056]\n",
      "  [0.94325435]\n",
      "  [0.94543886]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.023993441835045815\n",
      "Predicci√≥n post entrenamiento : [[0.9463533]]\n",
      "PERDIDAAAA despues: 0.02384754829108715\n",
      "loss en el callback: 0.007335049100220203, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "ejemplar: [[0.93409157]\n",
      " [0.93610567]\n",
      " [0.93723071]\n",
      " [0.93936449]\n",
      " [0.94138056]\n",
      " [0.94325435]\n",
      " [0.94543886]\n",
      " [0.94682497]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7865023059771536\n",
      "Predicci√≥n : [[0.9479397]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[[0.93409157]\n",
      "  [0.93610567]\n",
      "  [0.93723071]\n",
      "  [0.93936449]\n",
      "  [0.94138056]\n",
      "  [0.94325435]\n",
      "  [0.94543886]\n",
      "  [0.94682497]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02606203220784664\n",
      "Predicci√≥n post entrenamiento : [[0.9481453]]\n",
      "PERDIDAAAA despues: 0.02612844854593277\n",
      "loss en el callback: 0.0019597308710217476, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "ejemplar: [[0.93610567]\n",
      " [0.93723071]\n",
      " [0.93936449]\n",
      " [0.94138056]\n",
      " [0.94325435]\n",
      " [0.94543886]\n",
      " [0.94682497]\n",
      " [0.94793969]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7869773274313391\n",
      "Predicci√≥n : [[0.94976324]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[[0.93610567]\n",
      "  [0.93723071]\n",
      "  [0.93936449]\n",
      "  [0.94138056]\n",
      "  [0.94325435]\n",
      "  [0.94543886]\n",
      "  [0.94682497]\n",
      "  [0.94793969]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.026499245315790176\n",
      "Predicci√≥n post entrenamiento : [[0.94919735]]\n",
      "PERDIDAAAA despues: 0.02631532959640026\n",
      "loss en el callback: 0.010348311625421047, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "ejemplar: [[0.93723071]\n",
      " [0.93936449]\n",
      " [0.94138056]\n",
      " [0.94325435]\n",
      " [0.94543886]\n",
      " [0.94682497]\n",
      " [0.94793969]\n",
      " [0.94976324]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7874362431744556\n",
      "Predicci√≥n : [[0.9507525]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[[0.93723071]\n",
      "  [0.93936449]\n",
      "  [0.94138056]\n",
      "  [0.94325435]\n",
      "  [0.94543886]\n",
      "  [0.94682497]\n",
      "  [0.94793969]\n",
      "  [0.94976324]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02667219750583172\n",
      "Predicci√≥n post entrenamiento : [[0.95076746]]\n",
      "PERDIDAAAA despues: 0.0266770850867033\n",
      "loss en el callback: 8.062792403507046e-06, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "ejemplar: [[0.93936449]\n",
      " [0.94138056]\n",
      " [0.94325435]\n",
      " [0.94543886]\n",
      " [0.94682497]\n",
      " [0.94793969]\n",
      " [0.94976324]\n",
      " [0.9507525 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7878790532065031\n",
      "Predicci√≥n : [[0.95250374]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[[0.93936449]\n",
      "  [0.94138056]\n",
      "  [0.94325435]\n",
      "  [0.94543886]\n",
      "  [0.94682497]\n",
      "  [0.94793969]\n",
      "  [0.94976324]\n",
      "  [0.9507525 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.027101289480924606\n",
      "Predicci√≥n post entrenamiento : [[0.9517714]]\n",
      "PERDIDAAAA despues: 0.026860695332288742\n",
      "loss en el callback: 0.016683995723724365, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "ejemplar: [[0.94138056]\n",
      " [0.94325435]\n",
      " [0.94543886]\n",
      " [0.94682497]\n",
      " [0.94793969]\n",
      " [0.94976324]\n",
      " [0.9507525 ]\n",
      " [0.95250374]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7954532004373992\n",
      "Predicci√≥n : [[0.9534015]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[[0.94138056]\n",
      "  [0.94325435]\n",
      "  [0.94543886]\n",
      "  [0.94682497]\n",
      "  [0.94793969]\n",
      "  [0.94976324]\n",
      "  [0.9507525 ]\n",
      "  [0.95250374]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.024947669357061386\n",
      "Predicci√≥n post entrenamiento : [[0.95262766]]\n",
      "PERDIDAAAA despues: 0.02470381371676922\n",
      "loss en el callback: 0.018796078860759735, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "ejemplar: [[0.94325435]\n",
      " [0.94543886]\n",
      " [0.94682497]\n",
      " [0.94793969]\n",
      " [0.94976324]\n",
      " [0.9507525 ]\n",
      " [0.95250374]\n",
      " [0.95340151]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8101586848671446\n",
      "Predicci√≥n : [[0.9541519]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[[0.94325435]\n",
      "  [0.94543886]\n",
      "  [0.94682497]\n",
      "  [0.94793969]\n",
      "  [0.94976324]\n",
      "  [0.9507525 ]\n",
      "  [0.95250374]\n",
      "  [0.95340151]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.020734058693051338\n",
      "Predicci√≥n post entrenamiento : [[0.95333934]]\n",
      "PERDIDAAAA despues: 0.020500704646110535\n",
      "loss en el callback: 0.02103932574391365, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "ejemplar: [[0.94543886]\n",
      " [0.94682497]\n",
      " [0.94793969]\n",
      " [0.94976324]\n",
      " [0.9507525 ]\n",
      " [0.95250374]\n",
      " [0.95340151]\n",
      " [0.95415193]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7668473230866574\n",
      "Predicci√≥n : [[0.95476466]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[[0.94543886]\n",
      "  [0.94682497]\n",
      "  [0.94793969]\n",
      "  [0.94976324]\n",
      "  [0.9507525 ]\n",
      "  [0.95250374]\n",
      "  [0.95340151]\n",
      "  [0.95415193]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03531293198466301\n",
      "Predicci√≥n post entrenamiento : [[0.95309377]]\n",
      "PERDIDAAAA despues: 0.034687742590904236\n",
      "loss en el callback: 0.07516813278198242, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "ejemplar: [[0.94682497]\n",
      " [0.94793969]\n",
      " [0.94976324]\n",
      " [0.9507525 ]\n",
      " [0.95250374]\n",
      " [0.95340151]\n",
      " [0.95415193]\n",
      " [0.95476466]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6655191150959373\n",
      "Predicci√≥n : [[0.9542926]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[[0.94682497]\n",
      "  [0.94793969]\n",
      "  [0.94976324]\n",
      "  [0.9507525 ]\n",
      "  [0.95250374]\n",
      "  [0.95340151]\n",
      "  [0.95415193]\n",
      "  [0.95476466]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08339012414216995\n",
      "Predicci√≥n post entrenamiento : [[0.95391196]]\n",
      "PERDIDAAAA despues: 0.08317042887210846\n",
      "loss en el callback: 0.008597866632044315, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "ejemplar: [[0.94793969]\n",
      " [0.94976324]\n",
      " [0.9507525 ]\n",
      " [0.95250374]\n",
      " [0.95340151]\n",
      " [0.95415193]\n",
      " [0.95476466]\n",
      " [0.9542926 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6360738003224796\n",
      "Predicci√≥n : [[0.9550623]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[[0.94793969]\n",
      "  [0.94976324]\n",
      "  [0.9507525 ]\n",
      "  [0.95250374]\n",
      "  [0.95340151]\n",
      "  [0.95415193]\n",
      "  [0.95476466]\n",
      "  [0.9542926 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10175366699695587\n",
      "Predicci√≥n post entrenamiento : [[0.95222235]]\n",
      "PERDIDAAAA despues: 0.09994988888502121\n",
      "loss en el callback: 0.22205740213394165, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "ejemplar: [[0.94976324]\n",
      " [0.9507525 ]\n",
      " [0.95250374]\n",
      " [0.95340151]\n",
      " [0.95415193]\n",
      " [0.95476466]\n",
      " [0.9542926 ]\n",
      " [0.95506233]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6785113787662842\n",
      "Predicci√≥n : [[0.95336795]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[[0.94976324]\n",
      "  [0.9507525 ]\n",
      "  [0.95250374]\n",
      "  [0.95340151]\n",
      "  [0.95415193]\n",
      "  [0.95476466]\n",
      "  [0.9542926 ]\n",
      "  [0.95506233]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07554613053798676\n",
      "Predicci√≥n post entrenamiento : [[0.95226014]]\n",
      "PERDIDAAAA despues: 0.07493837922811508\n",
      "loss en el callback: 0.04672687128186226, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "ejemplar: [[0.9507525 ]\n",
      " [0.95250374]\n",
      " [0.95340151]\n",
      " [0.95415193]\n",
      " [0.95476466]\n",
      " [0.9542926 ]\n",
      " [0.95506233]\n",
      " [0.95336795]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6965967339840231\n",
      "Predicci√≥n : [[0.9531482]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[[0.9507525 ]\n",
      "  [0.95250374]\n",
      "  [0.95340151]\n",
      "  [0.95415193]\n",
      "  [0.95476466]\n",
      "  [0.9542926 ]\n",
      "  [0.95506233]\n",
      "  [0.95336795]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06581864506006241\n",
      "Predicci√≥n post entrenamiento : [[0.95164853]]\n",
      "PERDIDAAAA despues: 0.06505141407251358\n",
      "loss en el callback: 0.06866846978664398, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "ejemplar: [[0.95250374]\n",
      " [0.95340151]\n",
      " [0.95415193]\n",
      " [0.95476466]\n",
      " [0.9542926 ]\n",
      " [0.95506233]\n",
      " [0.95336795]\n",
      " [0.95314819]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6903298659756966\n",
      "Predicci√≥n : [[0.9524399]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[[0.95250374]\n",
      "  [0.95340151]\n",
      "  [0.95415193]\n",
      "  [0.95476466]\n",
      "  [0.9542926 ]\n",
      "  [0.95506233]\n",
      "  [0.95336795]\n",
      "  [0.95314819]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06870167702436447\n",
      "Predicci√≥n post entrenamiento : [[0.95166326]]\n",
      "PERDIDAAAA despues: 0.06829515099525452\n",
      "loss en el callback: 0.02509192004799843, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "ejemplar: [[0.95340151]\n",
      " [0.95415193]\n",
      " [0.95476466]\n",
      " [0.9542926 ]\n",
      " [0.95506233]\n",
      " [0.95336795]\n",
      " [0.95314819]\n",
      " [0.9524399 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6970473058045382\n",
      "Predicci√≥n : [[0.9520698]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[[0.95340151]\n",
      "  [0.95415193]\n",
      "  [0.95476466]\n",
      "  [0.9542926 ]\n",
      "  [0.95506233]\n",
      "  [0.95336795]\n",
      "  [0.95314819]\n",
      "  [0.9524399 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06503649055957794\n",
      "Predicci√≥n post entrenamiento : [[0.9497702]]\n",
      "PERDIDAAAA despues: 0.06386887282133102\n",
      "loss en el callback: 0.14929383993148804, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "ejemplar: [[0.95415193]\n",
      " [0.95476466]\n",
      " [0.9542926 ]\n",
      " [0.95506233]\n",
      " [0.95336795]\n",
      " [0.95314819]\n",
      " [0.9524399 ]\n",
      " [0.95206982]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7167490534705484\n",
      "Predicci√≥n : [[0.9499457]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[[0.95415193]\n",
      "  [0.95476466]\n",
      "  [0.9542926 ]\n",
      "  [0.95506233]\n",
      "  [0.95336795]\n",
      "  [0.95314819]\n",
      "  [0.9524399 ]\n",
      "  [0.95206982]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.054380662739276886\n",
      "Predicci√≥n post entrenamiento : [[0.948936]]\n",
      "PERDIDAAAA despues: 0.0539107620716095\n",
      "loss en el callback: 0.039124857634305954, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "ejemplar: [[0.95476466]\n",
      " [0.9542926 ]\n",
      " [0.95506233]\n",
      " [0.95336795]\n",
      " [0.95314819]\n",
      " [0.9524399 ]\n",
      " [0.95206982]\n",
      " [0.94994569]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7490507063998944\n",
      "Predicci√≥n : [[0.94885]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[[0.95476466]\n",
      "  [0.9542926 ]\n",
      "  [0.95506233]\n",
      "  [0.95336795]\n",
      "  [0.95314819]\n",
      "  [0.9524399 ]\n",
      "  [0.95206982]\n",
      "  [0.94994569]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03991976007819176\n",
      "Predicci√≥n post entrenamiento : [[0.946674]]\n",
      "PERDIDAAAA despues: 0.03905497491359711\n",
      "loss en el callback: 0.12911401689052582, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "ejemplar: [[0.9542926 ]\n",
      " [0.95506233]\n",
      " [0.95336795]\n",
      " [0.95314819]\n",
      " [0.9524399 ]\n",
      " [0.95206982]\n",
      " [0.94994569]\n",
      " [0.94884998]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7939522645925762\n",
      "Predicci√≥n : [[0.94629216]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[[0.9542926 ]\n",
      "  [0.95506233]\n",
      "  [0.95336795]\n",
      "  [0.95314819]\n",
      "  [0.9524399 ]\n",
      "  [0.95206982]\n",
      "  [0.94994569]\n",
      "  [0.94884998]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.023207437247037888\n",
      "Predicci√≥n post entrenamiento : [[0.94387376]]\n",
      "PERDIDAAAA despues: 0.022476449608802795\n",
      "loss en el callback: 0.15608304738998413, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "ejemplar: [[0.95506233]\n",
      " [0.95336795]\n",
      " [0.95314819]\n",
      " [0.9524399 ]\n",
      " [0.95206982]\n",
      " [0.94994569]\n",
      " [0.94884998]\n",
      " [0.94629216]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8547447263586395\n",
      "Predicci√≥n : [[0.94343436]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[[0.95506233]\n",
      "  [0.95336795]\n",
      "  [0.95314819]\n",
      "  [0.9524399 ]\n",
      "  [0.95206982]\n",
      "  [0.94994569]\n",
      "  [0.94884998]\n",
      "  [0.94629216]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007865849882364273\n",
      "Predicci√≥n post entrenamiento : [[0.94259495]]\n",
      "PERDIDAAAA despues: 0.007717660162597895\n",
      "loss en el callback: 0.024865681305527687, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "ejemplar: [[0.95336795]\n",
      " [0.95314819]\n",
      " [0.9524399 ]\n",
      " [0.95206982]\n",
      " [0.94994569]\n",
      " [0.94884998]\n",
      " [0.94629216]\n",
      " [0.94343436]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9314280916980849\n",
      "Predicci√≥n : [[0.94167876]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[[0.95336795]\n",
      "  [0.95314819]\n",
      "  [0.9524399 ]\n",
      "  [0.95206982]\n",
      "  [0.94994569]\n",
      "  [0.94884998]\n",
      "  [0.94629216]\n",
      "  [0.94343436]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001050765931722708\n",
      "Predicci√≥n post entrenamiento : [[0.9424353]]\n",
      "PERDIDAAAA despues: 0.00012115953722968698\n",
      "loss en el callback: 0.02977355197072029, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "ejemplar: [[0.95314819]\n",
      " [0.9524399 ]\n",
      " [0.95206982]\n",
      " [0.94994569]\n",
      " [0.94884998]\n",
      " [0.94629216]\n",
      " [0.94343436]\n",
      " [0.94167876]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9627243989762315\n",
      "Predicci√≥n : [[0.94165367]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[[0.95314819]\n",
      "  [0.9524399 ]\n",
      "  [0.95206982]\n",
      "  [0.94994569]\n",
      "  [0.94884998]\n",
      "  [0.94629216]\n",
      "  [0.94343436]\n",
      "  [0.94167876]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00044397517922334373\n",
      "Predicci√≥n post entrenamiento : [[0.9412214]]\n",
      "PERDIDAAAA despues: 0.00046237779315561056\n",
      "loss en el callback: 0.005899455863982439, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "ejemplar: [[0.9524399 ]\n",
      " [0.95206982]\n",
      " [0.94994569]\n",
      " [0.94884998]\n",
      " [0.94629216]\n",
      " [0.94343436]\n",
      " [0.94167876]\n",
      " [0.94165367]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9486336481930799\n",
      "Predicci√≥n : [[0.9401282]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[[0.9524399 ]\n",
      "  [0.95206982]\n",
      "  [0.94994569]\n",
      "  [0.94884998]\n",
      "  [0.94629216]\n",
      "  [0.94343436]\n",
      "  [0.94167876]\n",
      "  [0.94165367]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.234291115310043e-05\n",
      "Predicci√≥n post entrenamiento : [[0.94097143]]\n",
      "PERDIDAAAA despues: 5.870986933587119e-05\n",
      "loss en el callback: 0.0427476242184639, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "ejemplar: [[0.95206982]\n",
      " [0.94994569]\n",
      " [0.94884998]\n",
      " [0.94629216]\n",
      " [0.94343436]\n",
      " [0.94167876]\n",
      " [0.94165367]\n",
      " [0.94012821]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9307145892932484\n",
      "Predicci√≥n : [[0.9396429]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[[0.95206982]\n",
      "  [0.94994569]\n",
      "  [0.94884998]\n",
      "  [0.94629216]\n",
      "  [0.94343436]\n",
      "  [0.94167876]\n",
      "  [0.94165367]\n",
      "  [0.94012821]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.971451850607991e-05\n",
      "Predicci√≥n post entrenamiento : [[0.93982106]]\n",
      "PERDIDAAAA despues: 8.292756683658808e-05\n",
      "loss en el callback: 0.0012693175813183188, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "ejemplar: [[0.94994569]\n",
      " [0.94884998]\n",
      " [0.94629216]\n",
      " [0.94343436]\n",
      " [0.94167876]\n",
      " [0.94165367]\n",
      " [0.94012821]\n",
      " [0.93964291]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.908967222276737\n",
      "Predicci√≥n : [[0.9381269]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[[0.94994569]\n",
      "  [0.94884998]\n",
      "  [0.94629216]\n",
      "  [0.94343436]\n",
      "  [0.94167876]\n",
      "  [0.94165367]\n",
      "  [0.94012821]\n",
      "  [0.93964291]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008502895361743867\n",
      "Predicci√≥n post entrenamiento : [[0.93792856]]\n",
      "PERDIDAAAA despues: 0.0008387604029849172\n",
      "loss en el callback: 0.0014666325878351927, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "ejemplar: [[0.94884998]\n",
      " [0.94629216]\n",
      " [0.94343436]\n",
      " [0.94167876]\n",
      " [0.94165367]\n",
      " [0.94012821]\n",
      " [0.93964291]\n",
      " [0.93812692]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8816379650841193\n",
      "Predicci√≥n : [[0.9363522]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[[0.94884998]\n",
      "  [0.94629216]\n",
      "  [0.94343436]\n",
      "  [0.94167876]\n",
      "  [0.94165367]\n",
      "  [0.94012821]\n",
      "  [0.93964291]\n",
      "  [0.93812692]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002993643982335925\n",
      "Predicci√≥n post entrenamiento : [[0.93522894]]\n",
      "PERDIDAAAA despues: 0.002871990203857422\n",
      "loss en el callback: 0.04258495941758156, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "ejemplar: [[0.94629216]\n",
      " [0.94343436]\n",
      " [0.94167876]\n",
      " [0.94165367]\n",
      " [0.94012821]\n",
      " [0.93964291]\n",
      " [0.93812692]\n",
      " [0.93635219]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8487268177153953\n",
      "Predicci√≥n : [[0.9335116]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[[0.94629216]\n",
      "  [0.94343436]\n",
      "  [0.94167876]\n",
      "  [0.94165367]\n",
      "  [0.94012821]\n",
      "  [0.93964291]\n",
      "  [0.93812692]\n",
      "  [0.93635219]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007188463117927313\n",
      "Predicci√≥n post entrenamiento : [[0.93308735]]\n",
      "PERDIDAAAA despues: 0.0071167005226016045\n",
      "loss en el callback: 0.007216456811875105, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "ejemplar: [[0.94343436]\n",
      " [0.94167876]\n",
      " [0.94165367]\n",
      " [0.94012821]\n",
      " [0.93964291]\n",
      " [0.93812692]\n",
      " [0.93635219]\n",
      " [0.93351161]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.875260685634848\n",
      "Predicci√≥n : [[0.9316542]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[[0.94343436]\n",
      "  [0.94167876]\n",
      "  [0.94165367]\n",
      "  [0.94012821]\n",
      "  [0.93964291]\n",
      "  [0.93812692]\n",
      "  [0.93635219]\n",
      "  [0.93351161]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003180227242410183\n",
      "Predicci√≥n post entrenamiento : [[0.93220854]]\n",
      "PERDIDAAAA despues: 0.003243054961785674\n",
      "loss en el callback: 0.020009465515613556, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "ejemplar: [[0.94167876]\n",
      " [0.94165367]\n",
      " [0.94012821]\n",
      " [0.93964291]\n",
      " [0.93812692]\n",
      " [0.93635219]\n",
      " [0.93351161]\n",
      " [0.93165421]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9612395688424776\n",
      "Predicci√≥n : [[0.9311878]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[[0.94167876]\n",
      "  [0.94165367]\n",
      "  [0.94012821]\n",
      "  [0.93964291]\n",
      "  [0.93812692]\n",
      "  [0.93635219]\n",
      "  [0.93351161]\n",
      "  [0.93165421]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009031087392941117\n",
      "Predicci√≥n post entrenamiento : [[0.9314837]]\n",
      "PERDIDAAAA despues: 0.0008854130282998085\n",
      "loss en el callback: 0.0038715333212167025, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "ejemplar: [[0.94165367]\n",
      " [0.94012821]\n",
      " [0.93964291]\n",
      " [0.93812692]\n",
      " [0.93635219]\n",
      " [0.93351161]\n",
      " [0.93165421]\n",
      " [0.93118781]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9925021123407926\n",
      "Predicci√≥n : [[0.9305957]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[[0.94165367]\n",
      "  [0.94012821]\n",
      "  [0.93964291]\n",
      "  [0.93812692]\n",
      "  [0.93635219]\n",
      "  [0.93351161]\n",
      "  [0.93165421]\n",
      "  [0.93118781]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003832401940599084\n",
      "Predicci√≥n post entrenamiento : [[0.9314978]]\n",
      "PERDIDAAAA despues: 0.0037215224001556635\n",
      "loss en el callback: 0.049630843102931976, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "ejemplar: [[0.94012821]\n",
      " [0.93964291]\n",
      " [0.93812692]\n",
      " [0.93635219]\n",
      " [0.93351161]\n",
      " [0.93165421]\n",
      " [0.93118781]\n",
      " [0.9305957 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.969048316129792\n",
      "Predicci√≥n : [[0.9302368]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[[0.94012821]\n",
      "  [0.93964291]\n",
      "  [0.93812692]\n",
      "  [0.93635219]\n",
      "  [0.93351161]\n",
      "  [0.93165421]\n",
      "  [0.93118781]\n",
      "  [0.9305957 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015063328901305795\n",
      "Predicci√≥n post entrenamiento : [[0.9294013]]\n",
      "PERDIDAAAA despues: 0.001571887987665832\n",
      "loss en el callback: 0.022598573938012123, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "ejemplar: [[0.93964291]\n",
      " [0.93812692]\n",
      " [0.93635219]\n",
      " [0.93351161]\n",
      " [0.93165421]\n",
      " [0.93118781]\n",
      " [0.9305957 ]\n",
      " [0.93023682]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9715476120161949\n",
      "Predicci√≥n : [[0.9281568]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[[0.93964291]\n",
      "  [0.93812692]\n",
      "  [0.93635219]\n",
      "  [0.93351161]\n",
      "  [0.93165421]\n",
      "  [0.93118781]\n",
      "  [0.9305957 ]\n",
      "  [0.93023682]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018827624153345823\n",
      "Predicci√≥n post entrenamiento : [[0.92887044]]\n",
      "PERDIDAAAA despues: 0.0018213402945548296\n",
      "loss en el callback: 0.0277619119733572, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "ejemplar: [[0.93812692]\n",
      " [0.93635219]\n",
      " [0.93351161]\n",
      " [0.93165421]\n",
      " [0.93118781]\n",
      " [0.9305957 ]\n",
      " [0.93023682]\n",
      " [0.92815679]]\n",
      "ejemplar: (8, 1)\n",
      "y: 1.0\n",
      "Predicci√≥n : [[0.92734927]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[[0.93812692]\n",
      "  [0.93635219]\n",
      "  [0.93351161]\n",
      "  [0.93165421]\n",
      "  [0.93118781]\n",
      "  [0.9305957 ]\n",
      "  [0.93023682]\n",
      "  [0.92815679]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005278128664940596\n",
      "Predicci√≥n post entrenamiento : [[0.9276179]]\n",
      "PERDIDAAAA despues: 0.005239167250692844\n",
      "loss en el callback: 0.0029624830931425095, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "ejemplar: [[0.93635219]\n",
      " [0.93351161]\n",
      " [0.93165421]\n",
      " [0.93118781]\n",
      " [0.9305957 ]\n",
      " [0.93023682]\n",
      " [0.92815679]\n",
      " [0.92734927]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9800636522775721\n",
      "Predicci√≥n : [[0.9261055]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[[0.93635219]\n",
      "  [0.93351161]\n",
      "  [0.93165421]\n",
      "  [0.93118781]\n",
      "  [0.9305957 ]\n",
      "  [0.93023682]\n",
      "  [0.92815679]\n",
      "  [0.92734927]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002911485033109784\n",
      "Predicci√≥n post entrenamiento : [[0.9255071]]\n",
      "PERDIDAAAA despues: 0.002976417075842619\n",
      "loss en el callback: 0.012936183251440525, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "ejemplar: [[0.93351161]\n",
      " [0.93165421]\n",
      " [0.93118781]\n",
      " [0.9305957 ]\n",
      " [0.93023682]\n",
      " [0.92815679]\n",
      " [0.92734927]\n",
      " [0.9261055 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.911738568848911\n",
      "Predicci√≥n : [[0.9241088]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[[0.93351161]\n",
      "  [0.93165421]\n",
      "  [0.93118781]\n",
      "  [0.9305957 ]\n",
      "  [0.93023682]\n",
      "  [0.92815679]\n",
      "  [0.92734927]\n",
      "  [0.9261055 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00015302255633287132\n",
      "Predicci√≥n post entrenamiento : [[0.9234838]]\n",
      "PERDIDAAAA despues: 0.00013795006088912487\n",
      "loss en el callback: 0.015390966087579727, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "ejemplar: [[0.93165421]\n",
      " [0.93118781]\n",
      " [0.9305957 ]\n",
      " [0.93023682]\n",
      " [0.92815679]\n",
      " [0.92734927]\n",
      " [0.9261055 ]\n",
      " [0.9241088 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8910857934126422\n",
      "Predicci√≥n : [[0.92254275]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[[0.93165421]\n",
      "  [0.93118781]\n",
      "  [0.9305957 ]\n",
      "  [0.93023682]\n",
      "  [0.92815679]\n",
      "  [0.92734927]\n",
      "  [0.9261055 ]\n",
      "  [0.9241088 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000989539548754692\n",
      "Predicci√≥n post entrenamiento : [[0.92282736]]\n",
      "PERDIDAAAA despues: 0.0010075266472995281\n",
      "loss en el callback: 0.004060107748955488, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "ejemplar: [[0.93118781]\n",
      " [0.9305957 ]\n",
      " [0.93023682]\n",
      " [0.92815679]\n",
      " [0.92734927]\n",
      " [0.9261055 ]\n",
      " [0.9241088 ]\n",
      " [0.92254275]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9181053259687657\n",
      "Predicci√≥n : [[0.9221134]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[[0.93118781]\n",
      "  [0.9305957 ]\n",
      "  [0.93023682]\n",
      "  [0.92815679]\n",
      "  [0.92734927]\n",
      "  [0.9261055 ]\n",
      "  [0.9241088 ]\n",
      "  [0.92254275]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.6064979718066752e-05\n",
      "Predicci√≥n post entrenamiento : [[0.92182505]]\n",
      "PERDIDAAAA despues: 1.383651851938339e-05\n",
      "loss en el callback: 0.003919851500540972, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "ejemplar: [[0.9305957 ]\n",
      " [0.93023682]\n",
      " [0.92815679]\n",
      " [0.92734927]\n",
      " [0.9261055 ]\n",
      " [0.9241088 ]\n",
      " [0.92254275]\n",
      " [0.92211342]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9450165163483527\n",
      "Predicci√≥n : [[0.9209459]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[[0.9305957 ]\n",
      "  [0.93023682]\n",
      "  [0.92815679]\n",
      "  [0.92734927]\n",
      "  [0.9261055 ]\n",
      "  [0.9241088 ]\n",
      "  [0.92254275]\n",
      "  [0.92211342]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000579394749365747\n",
      "Predicci√≥n post entrenamiento : [[0.9202954]]\n",
      "PERDIDAAAA despues: 0.0006111320690251887\n",
      "loss en el callback: 0.01552493590861559, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "ejemplar: [[0.93023682]\n",
      " [0.92815679]\n",
      " [0.92734927]\n",
      " [0.9261055 ]\n",
      " [0.9241088 ]\n",
      " [0.92254275]\n",
      " [0.92211342]\n",
      " [0.92094588]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9718193645514037\n",
      "Predicci√≥n : [[0.91925037]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[[0.93023682]\n",
      "  [0.92815679]\n",
      "  [0.92734927]\n",
      "  [0.9261055 ]\n",
      "  [0.9241088 ]\n",
      "  [0.92254275]\n",
      "  [0.92211342]\n",
      "  [0.92094588]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00276349694468081\n",
      "Predicci√≥n post entrenamiento : [[0.91895103]]\n",
      "PERDIDAAAA despues: 0.002795057836920023\n",
      "loss en el callback: 0.003557440359145403, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "ejemplar: [[0.92815679]\n",
      " [0.92734927]\n",
      " [0.9261055 ]\n",
      " [0.9241088 ]\n",
      " [0.92254275]\n",
      " [0.92211342]\n",
      " [0.92094588]\n",
      " [0.91925037]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9829067192737589\n",
      "Predicci√≥n : [[0.9176431]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[[0.92815679]\n",
      "  [0.92734927]\n",
      "  [0.9261055 ]\n",
      "  [0.9241088 ]\n",
      "  [0.92254275]\n",
      "  [0.92211342]\n",
      "  [0.92094588]\n",
      "  [0.91925037]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004259341396391392\n",
      "Predicci√≥n post entrenamiento : [[0.9182635]]\n",
      "PERDIDAAAA despues: 0.004178743809461594\n",
      "loss en el callback: 0.02154836244881153, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "ejemplar: [[0.92734927]\n",
      " [0.9261055 ]\n",
      " [0.9241088 ]\n",
      " [0.92254275]\n",
      " [0.92211342]\n",
      " [0.92094588]\n",
      " [0.91925037]\n",
      " [0.91764307]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9782785805154182\n",
      "Predicci√≥n : [[0.9171589]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[[0.92734927]\n",
      "  [0.9261055 ]\n",
      "  [0.9241088 ]\n",
      "  [0.92254275]\n",
      "  [0.92211342]\n",
      "  [0.92094588]\n",
      "  [0.91925037]\n",
      "  [0.91764307]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0037356147076934576\n",
      "Predicci√≥n post entrenamiento : [[0.91790783]]\n",
      "PERDIDAAAA despues: 0.0036446265876293182\n",
      "loss en el callback: 0.03539218753576279, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "ejemplar: [[0.05029815]\n",
      " [0.00860651]\n",
      " [0.        ]\n",
      " [0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.049424632939554\n",
      "Predicci√≥n : [[0.1993218]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.05029815]\n",
      "  [0.00860651]\n",
      "  [0.        ]\n",
      "  [0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022469162940979004\n",
      "Predicci√≥n post entrenamiento : [[0.15721433]]\n",
      "PERDIDAAAA despues: 0.011618618853390217\n",
      "loss en el callback: 0.02983977645635605, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "ejemplar: [[0.00860651]\n",
      " [0.        ]\n",
      " [0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.19932181]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.10789185692558968\n",
      "Predicci√≥n : [[0.15209304]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.00860651]\n",
      "  [0.        ]\n",
      "  [0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.19932181]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0019537443295121193\n",
      "Predicci√≥n post entrenamiento : [[0.14435765]]\n",
      "PERDIDAAAA despues: 0.0013297541299834847\n",
      "loss en el callback: 0.001351821469143033, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "ejemplar: [[0.        ]\n",
      " [0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.19932181]\n",
      " [0.15209304]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.13719610119365802\n",
      "Predicci√≥n : [[0.14883123]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[[0.        ]\n",
      "  [0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.19932181]\n",
      "  [0.15209304]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00013537646736949682\n",
      "Predicci√≥n post entrenamiento : [[0.1469243]]\n",
      "PERDIDAAAA despues: 9.463803144171834e-05\n",
      "loss en el callback: 0.00016663369024172425, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "ejemplar: [[0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.19932181]\n",
      " [0.15209304]\n",
      " [0.14883123]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.13733736574375907\n",
      "Predicci√≥n : [[0.15624718]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[[0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.19932181]\n",
      "  [0.15209304]\n",
      "  [0.14883123]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00035758098238147795\n",
      "Predicci√≥n post entrenamiento : [[0.15366864]]\n",
      "PERDIDAAAA despues: 0.0002667103835847229\n",
      "loss en el callback: 0.0005253945710137486, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "ejemplar: [[0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.19932181]\n",
      " [0.15209304]\n",
      " [0.14883123]\n",
      " [0.15624718]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.13388569841244483\n",
      "Predicci√≥n : [[0.16185315]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[[0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.19932181]\n",
      "  [0.15209304]\n",
      "  [0.14883123]\n",
      "  [0.15624718]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000782178423833102\n",
      "Predicci√≥n post entrenamiento : [[0.1587238]]\n",
      "PERDIDAAAA despues: 0.0006169314729049802\n",
      "loss en el callback: 0.0011551091447472572, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "ejemplar: [[0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.19932181]\n",
      " [0.15209304]\n",
      " [0.14883123]\n",
      " [0.15624718]\n",
      " [0.16185315]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.12684109919971556\n",
      "Predicci√≥n : [[0.16907698]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[[0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.19932181]\n",
      "  [0.15209304]\n",
      "  [0.14883123]\n",
      "  [0.15624718]\n",
      "  [0.16185315]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001783869694918394\n",
      "Predicci√≥n post entrenamiento : [[0.16672587]]\n",
      "PERDIDAAAA despues: 0.00159079534932971\n",
      "loss en el callback: 0.0010149111039936543, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "ejemplar: [[0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.19932181]\n",
      " [0.15209304]\n",
      " [0.14883123]\n",
      " [0.15624718]\n",
      " [0.16185315]\n",
      " [0.16907698]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14756061137847282\n",
      "Predicci√≥n : [[0.18307167]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[[0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.19932181]\n",
      "  [0.15209304]\n",
      "  [0.14883123]\n",
      "  [0.15624718]\n",
      "  [0.16185315]\n",
      "  [0.16907698]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012610354460775852\n",
      "Predicci√≥n post entrenamiento : [[0.18199523]]\n",
      "PERDIDAAAA despues: 0.0011857427889481187\n",
      "loss en el callback: 0.00031820227741263807, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "ejemplar: [[0.0202993 ]\n",
      " [0.19932181]\n",
      " [0.15209304]\n",
      " [0.14883123]\n",
      " [0.15624718]\n",
      " [0.16185315]\n",
      " [0.16907698]\n",
      " [0.18307167]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19604423494871648\n",
      "Predicci√≥n : [[0.20431623]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[[0.0202993 ]\n",
      "  [0.19932181]\n",
      "  [0.15209304]\n",
      "  [0.14883123]\n",
      "  [0.15624718]\n",
      "  [0.16185315]\n",
      "  [0.16907698]\n",
      "  [0.18307167]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.84258557157591e-05\n",
      "Predicci√≥n post entrenamiento : [[0.20521376]]\n",
      "PERDIDAAAA despues: 8.408007852267474e-05\n",
      "loss en el callback: 0.000310592440655455, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "ejemplar: [[0.19932181]\n",
      " [0.15209304]\n",
      " [0.14883123]\n",
      " [0.15624718]\n",
      " [0.16185315]\n",
      " [0.16907698]\n",
      " [0.18307167]\n",
      " [0.20431623]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.21688968214535215\n",
      "Predicci√≥n : [[0.2333309]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[[0.19932181]\n",
      "  [0.15209304]\n",
      "  [0.14883123]\n",
      "  [0.15624718]\n",
      "  [0.16185315]\n",
      "  [0.16907698]\n",
      "  [0.18307167]\n",
      "  [0.20431623]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002703139034565538\n",
      "Predicci√≥n post entrenamiento : [[0.23242489]]\n",
      "PERDIDAAAA despues: 0.00024134261184372008\n",
      "loss en el callback: 0.00030795042403042316, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "ejemplar: [[0.15209304]\n",
      " [0.14883123]\n",
      " [0.15624718]\n",
      " [0.16185315]\n",
      " [0.16907698]\n",
      " [0.18307167]\n",
      " [0.20431623]\n",
      " [0.23333091]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2100969529683796\n",
      "Predicci√≥n : [[0.22557643]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[[0.15209304]\n",
      "  [0.14883123]\n",
      "  [0.15624718]\n",
      "  [0.16185315]\n",
      "  [0.16907698]\n",
      "  [0.18307167]\n",
      "  [0.20431623]\n",
      "  [0.23333091]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002396141499048099\n",
      "Predicci√≥n post entrenamiento : [[0.2241158]]\n",
      "PERDIDAAAA despues: 0.0001965281117008999\n",
      "loss en el callback: 0.0008135588723234832, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "ejemplar: [[0.14883123]\n",
      " [0.15624718]\n",
      " [0.16185315]\n",
      " [0.16907698]\n",
      " [0.18307167]\n",
      " [0.20431623]\n",
      " [0.23333091]\n",
      " [0.22557643]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2026778474621132\n",
      "Predicci√≥n : [[0.22801284]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[[0.14883123]\n",
      "  [0.15624718]\n",
      "  [0.16185315]\n",
      "  [0.16907698]\n",
      "  [0.18307167]\n",
      "  [0.20431623]\n",
      "  [0.23333091]\n",
      "  [0.22557643]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006418621633201838\n",
      "Predicci√≥n post entrenamiento : [[0.22853215]]\n",
      "PERDIDAAAA despues: 0.0006684450781904161\n",
      "loss en el callback: 0.0002048972964985296, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "ejemplar: [[0.15624718]\n",
      " [0.16185315]\n",
      " [0.16907698]\n",
      " [0.18307167]\n",
      " [0.20431623]\n",
      " [0.23333091]\n",
      " [0.22557643]\n",
      " [0.22801284]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19463236562655295\n",
      "Predicci√≥n : [[0.23520906]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[[0.15624718]\n",
      "  [0.16185315]\n",
      "  [0.16907698]\n",
      "  [0.18307167]\n",
      "  [0.20431623]\n",
      "  [0.23333091]\n",
      "  [0.22557643]\n",
      "  [0.22801284]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016464682994410396\n",
      "Predicci√≥n post entrenamiento : [[0.23271964]]\n",
      "PERDIDAAAA despues: 0.0014506408479064703\n",
      "loss en el callback: 0.0034090657718479633, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "ejemplar: [[0.16185315]\n",
      " [0.16907698]\n",
      " [0.18307167]\n",
      " [0.20431623]\n",
      " [0.23333091]\n",
      " [0.22557643]\n",
      " [0.22801284]\n",
      " [0.23520906]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19407351685692253\n",
      "Predicci√≥n : [[0.24020799]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[[0.16185315]\n",
      "  [0.16907698]\n",
      "  [0.18307167]\n",
      "  [0.20431623]\n",
      "  [0.23333091]\n",
      "  [0.22557643]\n",
      "  [0.22801284]\n",
      "  [0.23520906]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0021283894311636686\n",
      "Predicci√≥n post entrenamiento : [[0.23863588]]\n",
      "PERDIDAAAA despues: 0.0019858048763126135\n",
      "loss en el callback: 0.0018728170543909073, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "ejemplar: [[0.16907698]\n",
      " [0.18307167]\n",
      " [0.20431623]\n",
      " [0.23333091]\n",
      " [0.22557643]\n",
      " [0.22801284]\n",
      " [0.23520906]\n",
      " [0.24020799]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.20100130115322212\n",
      "Predicci√≥n : [[0.24739031]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[[0.16907698]\n",
      "  [0.18307167]\n",
      "  [0.20431623]\n",
      "  [0.23333091]\n",
      "  [0.22557643]\n",
      "  [0.22801284]\n",
      "  [0.23520906]\n",
      "  [0.24020799]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002151940483599901\n",
      "Predicci√≥n post entrenamiento : [[0.24627995]]\n",
      "PERDIDAAAA despues: 0.002050156472250819\n",
      "loss en el callback: 0.0011805301764979959, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "ejemplar: [[0.18307167]\n",
      " [0.20431623]\n",
      " [0.23333091]\n",
      " [0.22557643]\n",
      " [0.22801284]\n",
      " [0.23520906]\n",
      " [0.24020799]\n",
      " [0.24739031]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19663820581116015\n",
      "Predicci√≥n : [[0.25597206]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[[0.18307167]\n",
      "  [0.20431623]\n",
      "  [0.23333091]\n",
      "  [0.22557643]\n",
      "  [0.22801284]\n",
      "  [0.23520906]\n",
      "  [0.24020799]\n",
      "  [0.24739031]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0035205052699893713\n",
      "Predicci√≥n post entrenamiento : [[0.2541512]]\n",
      "PERDIDAAAA despues: 0.0033077432308346033\n",
      "loss en el callback: 0.00330346985720098, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "ejemplar: [[0.20431623]\n",
      " [0.23333091]\n",
      " [0.22557643]\n",
      " [0.22801284]\n",
      " [0.23520906]\n",
      " [0.24020799]\n",
      " [0.24739031]\n",
      " [0.25597206]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1809842308307365\n",
      "Predicci√≥n : [[0.26314265]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[[0.20431623]\n",
      "  [0.23333091]\n",
      "  [0.22557643]\n",
      "  [0.22801284]\n",
      "  [0.23520906]\n",
      "  [0.24020799]\n",
      "  [0.24739031]\n",
      "  [0.25597206]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006750005297362804\n",
      "Predicci√≥n post entrenamiento : [[0.26071933]]\n",
      "PERDIDAAAA despues: 0.006357686128467321\n",
      "loss en el callback: 0.006549726705998182, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "ejemplar: [[0.23333091]\n",
      " [0.22557643]\n",
      " [0.22801284]\n",
      " [0.23520906]\n",
      " [0.24020799]\n",
      " [0.24739031]\n",
      " [0.25597206]\n",
      " [0.26314265]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1653904097109329\n",
      "Predicci√≥n : [[0.2669826]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[[0.23333091]\n",
      "  [0.22557643]\n",
      "  [0.22801284]\n",
      "  [0.23520906]\n",
      "  [0.24020799]\n",
      "  [0.24739031]\n",
      "  [0.25597206]\n",
      "  [0.26314265]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010320968925952911\n",
      "Predicci√≥n post entrenamiento : [[0.265207]]\n",
      "PERDIDAAAA despues: 0.009963348507881165\n",
      "loss en el callback: 0.00470851780846715, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "ejemplar: [[0.22557643]\n",
      " [0.22801284]\n",
      " [0.23520906]\n",
      " [0.24020799]\n",
      " [0.24739031]\n",
      " [0.25597206]\n",
      " [0.26314265]\n",
      " [0.26698259]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14985674245174896\n",
      "Predicci√≥n : [[0.26634967]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[[0.22557643]\n",
      "  [0.22801284]\n",
      "  [0.23520906]\n",
      "  [0.24020799]\n",
      "  [0.24739031]\n",
      "  [0.25597206]\n",
      "  [0.26314265]\n",
      "  [0.26698259]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013570602051913738\n",
      "Predicci√≥n post entrenamiento : [[0.26435158]]\n",
      "PERDIDAAAA despues: 0.013109066523611546\n",
      "loss en el callback: 0.007198032923042774, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "ejemplar: [[0.22801284]\n",
      " [0.23520906]\n",
      " [0.24020799]\n",
      " [0.24739031]\n",
      " [0.25597206]\n",
      " [0.26314265]\n",
      " [0.26698259]\n",
      " [0.26634967]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.15043111479831345\n",
      "Predicci√≥n : [[0.26820362]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[[0.22801284]\n",
      "  [0.23520906]\n",
      "  [0.24020799]\n",
      "  [0.24739031]\n",
      "  [0.25597206]\n",
      "  [0.26314265]\n",
      "  [0.26698259]\n",
      "  [0.26634967]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013870363123714924\n",
      "Predicci√≥n post entrenamiento : [[0.2649432]]\n",
      "PERDIDAAAA despues: 0.013113020919263363\n",
      "loss en el callback: 0.016458900645375252, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "ejemplar: [[0.23520906]\n",
      " [0.24020799]\n",
      " [0.24739031]\n",
      " [0.25597206]\n",
      " [0.26314265]\n",
      " [0.26698259]\n",
      " [0.26634967]\n",
      " [0.26820362]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.16711352675062616\n",
      "Predicci√≥n : [[0.2695354]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[[0.23520906]\n",
      "  [0.24020799]\n",
      "  [0.24739031]\n",
      "  [0.25597206]\n",
      "  [0.26314265]\n",
      "  [0.26698259]\n",
      "  [0.26634967]\n",
      "  [0.26820362]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010490238666534424\n",
      "Predicci√≥n post entrenamiento : [[0.26532146]]\n",
      "PERDIDAAAA despues: 0.009644798934459686\n",
      "loss en el callback: 0.02298690378665924, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "ejemplar: [[0.24020799]\n",
      " [0.24739031]\n",
      " [0.25597206]\n",
      " [0.26314265]\n",
      " [0.26698259]\n",
      " [0.26634967]\n",
      " [0.26820362]\n",
      " [0.26953539]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2022703535675908\n",
      "Predicci√≥n : [[0.26955473]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[[0.24020799]\n",
      "  [0.24739031]\n",
      "  [0.25597206]\n",
      "  [0.26314265]\n",
      "  [0.26698259]\n",
      "  [0.26634967]\n",
      "  [0.26820362]\n",
      "  [0.26953539]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0045271869748830795\n",
      "Predicci√≥n post entrenamiento : [[0.26802686]]\n",
      "PERDIDAAAA despues: 0.00432391744107008\n",
      "loss en el callback: 0.00424286350607872, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "ejemplar: [[0.24739031]\n",
      " [0.25597206]\n",
      " [0.26314265]\n",
      " [0.26698259]\n",
      " [0.26634967]\n",
      " [0.26820362]\n",
      " [0.26953539]\n",
      " [0.26955473]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.25590159524920725\n",
      "Predicci√≥n : [[0.2722398]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[[0.24739031]\n",
      "  [0.25597206]\n",
      "  [0.26314265]\n",
      "  [0.26698259]\n",
      "  [0.26634967]\n",
      "  [0.26820362]\n",
      "  [0.26953539]\n",
      "  [0.26955473]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00026693675317801535\n",
      "Predicci√≥n post entrenamiento : [[0.2717442]]\n",
      "PERDIDAAAA despues: 0.0002509875630494207\n",
      "loss en el callback: 0.0004732519155368209, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "ejemplar: [[0.25597206]\n",
      " [0.26314265]\n",
      " [0.26698259]\n",
      " [0.26634967]\n",
      " [0.26820362]\n",
      " [0.26953539]\n",
      " [0.26955473]\n",
      " [0.2722398 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.292688203599549\n",
      "Predicci√≥n : [[0.27528915]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[[0.25597206]\n",
      "  [0.26314265]\n",
      "  [0.26698259]\n",
      "  [0.26634967]\n",
      "  [0.26820362]\n",
      "  [0.26953539]\n",
      "  [0.26955473]\n",
      "  [0.2722398 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00030272669391706586\n",
      "Predicci√≥n post entrenamiento : [[0.2755146]]\n",
      "PERDIDAAAA despues: 0.0002949321351479739\n",
      "loss en el callback: 0.00010237709648208693, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "ejemplar: [[0.26314265]\n",
      " [0.26698259]\n",
      " [0.26634967]\n",
      " [0.26820362]\n",
      " [0.26953539]\n",
      " [0.26955473]\n",
      " [0.2722398 ]\n",
      " [0.27528915]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31263017861861575\n",
      "Predicci√≥n : [[0.27784744]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[[0.26314265]\n",
      "  [0.26698259]\n",
      "  [0.26634967]\n",
      "  [0.26820362]\n",
      "  [0.26953539]\n",
      "  [0.26955473]\n",
      "  [0.2722398 ]\n",
      "  [0.27528915]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012098387815058231\n",
      "Predicci√≥n post entrenamiento : [[0.27841702]]\n",
      "PERDIDAAAA despues: 0.0011705399956554174\n",
      "loss en el callback: 0.0006967884837649763, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "ejemplar: [[0.26698259]\n",
      " [0.26634967]\n",
      " [0.26820362]\n",
      " [0.26953539]\n",
      " [0.26955473]\n",
      " [0.2722398 ]\n",
      " [0.27528915]\n",
      " [0.27784744]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3109388849116374\n",
      "Predicci√≥n : [[0.27962494]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[[0.26698259]\n",
      "  [0.26634967]\n",
      "  [0.26820362]\n",
      "  [0.26953539]\n",
      "  [0.26955473]\n",
      "  [0.2722398 ]\n",
      "  [0.27528915]\n",
      "  [0.27784744]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009805638110265136\n",
      "Predicci√≥n post entrenamiento : [[0.28074047]]\n",
      "PERDIDAAAA despues: 0.0009119448950514197\n",
      "loss en el callback: 0.0036349354777485132, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "ejemplar: [[0.26634967]\n",
      " [0.26820362]\n",
      " [0.26953539]\n",
      " [0.26955473]\n",
      " [0.2722398 ]\n",
      " [0.27528915]\n",
      " [0.27784744]\n",
      " [0.27962494]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2876143224786136\n",
      "Predicci√≥n : [[0.2814341]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[[0.26634967]\n",
      "  [0.26820362]\n",
      "  [0.26953539]\n",
      "  [0.26955473]\n",
      "  [0.2722398 ]\n",
      "  [0.27528915]\n",
      "  [0.27784744]\n",
      "  [0.27962494]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.819520497927442e-05\n",
      "Predicci√≥n post entrenamiento : [[0.2818467]]\n",
      "PERDIDAAAA despues: 3.326536898384802e-05\n",
      "loss en el callback: 0.0004740029980894178, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "ejemplar: [[0.26820362]\n",
      " [0.26953539]\n",
      " [0.26955473]\n",
      " [0.2722398 ]\n",
      " [0.27528915]\n",
      " [0.27784744]\n",
      " [0.27962494]\n",
      " [0.28143409]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.280161647237227\n",
      "Predicci√≥n : [[0.2830338]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[[0.26820362]\n",
      "  [0.26953539]\n",
      "  [0.26955473]\n",
      "  [0.2722398 ]\n",
      "  [0.27528915]\n",
      "  [0.27784744]\n",
      "  [0.27962494]\n",
      "  [0.28143409]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.249183338193689e-06\n",
      "Predicci√≥n post entrenamiento : [[0.2836037]]\n",
      "PERDIDAAAA despues: 1.184770189865958e-05\n",
      "loss en el callback: 0.0012501057935878634, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "ejemplar: [[0.26953539]\n",
      " [0.26955473]\n",
      " [0.2722398 ]\n",
      " [0.27528915]\n",
      " [0.27784744]\n",
      " [0.27962494]\n",
      " [0.28143409]\n",
      " [0.28303379]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2885808591874776\n",
      "Predicci√≥n : [[0.28478903]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[[0.26953539]\n",
      "  [0.26955473]\n",
      "  [0.2722398 ]\n",
      "  [0.27528915]\n",
      "  [0.27784744]\n",
      "  [0.27962494]\n",
      "  [0.28143409]\n",
      "  [0.28303379]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.4378042578755412e-05\n",
      "Predicci√≥n post entrenamiento : [[0.28434077]]\n",
      "PERDIDAAAA despues: 1.797841105144471e-05\n",
      "loss en el callback: 0.0005458796513266861, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "ejemplar: [[0.26955473]\n",
      " [0.2722398 ]\n",
      " [0.27528915]\n",
      " [0.27784744]\n",
      " [0.27962494]\n",
      " [0.28143409]\n",
      " [0.28303379]\n",
      " [0.28478903]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2824628234730068\n",
      "Predicci√≥n : [[0.28565586]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[[0.26955473]\n",
      "  [0.2722398 ]\n",
      "  [0.27528915]\n",
      "  [0.27784744]\n",
      "  [0.27962494]\n",
      "  [0.28143409]\n",
      "  [0.28303379]\n",
      "  [0.28478903]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.0195381946687121e-05\n",
      "Predicci√≥n post entrenamiento : [[0.28562307]]\n",
      "PERDIDAAAA despues: 9.987105840991717e-06\n",
      "loss en el callback: 3.820753136096755e-06, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "ejemplar: [[0.2722398 ]\n",
      " [0.27528915]\n",
      " [0.27784744]\n",
      " [0.27962494]\n",
      " [0.28143409]\n",
      " [0.28303379]\n",
      " [0.28478903]\n",
      " [0.28565586]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.26180754009381474\n",
      "Predicci√≥n : [[0.28739762]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[[0.2722398 ]\n",
      "  [0.27528915]\n",
      "  [0.27784744]\n",
      "  [0.27962494]\n",
      "  [0.28143409]\n",
      "  [0.28303379]\n",
      "  [0.28478903]\n",
      "  [0.28565586]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006548528326675296\n",
      "Predicci√≥n post entrenamiento : [[0.2869511]]\n",
      "PERDIDAAAA despues: 0.0006321988184936345\n",
      "loss en el callback: 0.0007443123613484204, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "ejemplar: [[0.27528915]\n",
      " [0.27784744]\n",
      " [0.27962494]\n",
      " [0.28143409]\n",
      " [0.28303379]\n",
      " [0.28478903]\n",
      " [0.28565586]\n",
      " [0.28739762]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2801212859371977\n",
      "Predicci√≥n : [[0.2886014]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[[0.27528915]\n",
      "  [0.27784744]\n",
      "  [0.27962494]\n",
      "  [0.28143409]\n",
      "  [0.28303379]\n",
      "  [0.28478903]\n",
      "  [0.28565586]\n",
      "  [0.28739762]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.191212353063747e-05\n",
      "Predicci√≥n post entrenamiento : [[0.28845492]]\n",
      "PERDIDAAAA despues: 6.944927736185491e-05\n",
      "loss en el callback: 7.660617120563984e-05, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "ejemplar: [[0.27784744]\n",
      " [0.27962494]\n",
      " [0.28143409]\n",
      " [0.28303379]\n",
      " [0.28478903]\n",
      " [0.28565586]\n",
      " [0.28739762]\n",
      " [0.2886014 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3374040610031557\n",
      "Predicci√≥n : [[0.2898488]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[[0.27784744]\n",
      "  [0.27962494]\n",
      "  [0.28143409]\n",
      "  [0.28303379]\n",
      "  [0.28478903]\n",
      "  [0.28565586]\n",
      "  [0.28739762]\n",
      "  [0.2886014 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0022615035995841026\n",
      "Predicci√≥n post entrenamiento : [[0.29107413]]\n",
      "PERDIDAAAA despues: 0.002146463841199875\n",
      "loss en el callback: 0.007738954853266478, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "ejemplar: [[0.27962494]\n",
      " [0.28143409]\n",
      " [0.28303379]\n",
      " [0.28478903]\n",
      " [0.28565586]\n",
      " [0.28739762]\n",
      " [0.2886014 ]\n",
      " [0.2898488 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3482298154676272\n",
      "Predicci√≥n : [[0.2922697]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[[0.27962494]\n",
      "  [0.28143409]\n",
      "  [0.28303379]\n",
      "  [0.28478903]\n",
      "  [0.28565586]\n",
      "  [0.28739762]\n",
      "  [0.2886014 ]\n",
      "  [0.2898488 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003131534904241562\n",
      "Predicci√≥n post entrenamiento : [[0.29255453]]\n",
      "PERDIDAAAA despues: 0.0030997388530522585\n",
      "loss en el callback: 0.00026956474175676703, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "ejemplar: [[0.28143409]\n",
      " [0.28303379]\n",
      " [0.28478903]\n",
      " [0.28565586]\n",
      " [0.28739762]\n",
      " [0.2886014 ]\n",
      " [0.2898488 ]\n",
      " [0.29226971]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31259854933061226\n",
      "Predicci√≥n : [[0.29370022]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[[0.28143409]\n",
      "  [0.28303379]\n",
      "  [0.28478903]\n",
      "  [0.28565586]\n",
      "  [0.28739762]\n",
      "  [0.2886014 ]\n",
      "  [0.2898488 ]\n",
      "  [0.29226971]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00035714718978852034\n",
      "Predicci√≥n post entrenamiento : [[0.2934732]]\n",
      "PERDIDAAAA despues: 0.00036577871651388705\n",
      "loss en el callback: 0.00019442600023467094, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "ejemplar: [[0.28303379]\n",
      " [0.28478903]\n",
      " [0.28565586]\n",
      " [0.28739762]\n",
      " [0.2886014 ]\n",
      " [0.2898488 ]\n",
      " [0.29226971]\n",
      " [0.29370022]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.34358710169603873\n",
      "Predicci√≥n : [[0.2945527]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[[0.28303379]\n",
      "  [0.28478903]\n",
      "  [0.28565586]\n",
      "  [0.28739762]\n",
      "  [0.2886014 ]\n",
      "  [0.2898488 ]\n",
      "  [0.29226971]\n",
      "  [0.29370022]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0024043710436671972\n",
      "Predicci√≥n post entrenamiento : [[0.29551044]]\n",
      "PERDIDAAAA despues: 0.0023113652132451534\n",
      "loss en el callback: 0.005248429719358683, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "ejemplar: [[0.28478903]\n",
      " [0.28565586]\n",
      " [0.28739762]\n",
      " [0.2886014 ]\n",
      " [0.2898488 ]\n",
      " [0.29226971]\n",
      " [0.29370022]\n",
      " [0.29455271]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.4411954725639069\n",
      "Predicci√≥n : [[0.2965632]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[[0.28478903]\n",
      "  [0.28565586]\n",
      "  [0.28739762]\n",
      "  [0.2886014 ]\n",
      "  [0.2898488 ]\n",
      "  [0.29226971]\n",
      "  [0.29370022]\n",
      "  [0.29455271]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02091848850250244\n",
      "Predicci√≥n post entrenamiento : [[0.29796758]]\n",
      "PERDIDAAAA despues: 0.020514223724603653\n",
      "loss en el callback: 0.008690968155860901, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "ejemplar: [[0.28565586]\n",
      " [0.28739762]\n",
      " [0.2886014 ]\n",
      " [0.2898488 ]\n",
      " [0.29226971]\n",
      " [0.29370022]\n",
      " [0.29455271]\n",
      " [0.29656321]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5210953230441133\n",
      "Predicci√≥n : [[0.29895473]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[[0.28565586]\n",
      "  [0.28739762]\n",
      "  [0.2886014 ]\n",
      "  [0.2898488 ]\n",
      "  [0.29226971]\n",
      "  [0.29370022]\n",
      "  [0.29455271]\n",
      "  [0.29656321]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.049346450716257095\n",
      "Predicci√≥n post entrenamiento : [[0.30164602]]\n",
      "PERDIDAAAA despues: 0.04815800115466118\n",
      "loss en el callback: 0.03446797654032707, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "ejemplar: [[0.28739762]\n",
      " [0.2886014 ]\n",
      " [0.2898488 ]\n",
      " [0.29226971]\n",
      " [0.29370022]\n",
      " [0.29455271]\n",
      " [0.29656321]\n",
      " [0.29895473]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5832866531366584\n",
      "Predicci√≥n : [[0.30278003]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[[0.28739762]\n",
      "  [0.2886014 ]\n",
      "  [0.2898488 ]\n",
      "  [0.29226971]\n",
      "  [0.29370022]\n",
      "  [0.29455271]\n",
      "  [0.29656321]\n",
      "  [0.29895473]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07868395745754242\n",
      "Predicci√≥n post entrenamiento : [[0.30652314]]\n",
      "PERDIDAAAA despues: 0.07659803330898285\n",
      "loss en el callback: 0.08887027204036713, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "ejemplar: [[0.2886014 ]\n",
      " [0.2898488 ]\n",
      " [0.29226971]\n",
      " [0.29370022]\n",
      " [0.29455271]\n",
      " [0.29656321]\n",
      " [0.29895473]\n",
      " [0.30278003]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6089234523540271\n",
      "Predicci√≥n : [[0.30763647]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[[0.2886014 ]\n",
      "  [0.2898488 ]\n",
      "  [0.29226971]\n",
      "  [0.29370022]\n",
      "  [0.29455271]\n",
      "  [0.29656321]\n",
      "  [0.29895473]\n",
      "  [0.30278003]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09077383577823639\n",
      "Predicci√≥n post entrenamiento : [[0.3113865]]\n",
      "PERDIDAAAA despues: 0.08852823078632355\n",
      "loss en el callback: 0.06825755536556244, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "ejemplar: [[0.2898488 ]\n",
      " [0.29226971]\n",
      " [0.29370022]\n",
      " [0.29455271]\n",
      " [0.29656321]\n",
      " [0.29895473]\n",
      " [0.30278003]\n",
      " [0.30763647]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.59800572069622\n",
      "Predicci√≥n : [[0.31264353]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[[0.2898488 ]\n",
      "  [0.29226971]\n",
      "  [0.29370022]\n",
      "  [0.29455271]\n",
      "  [0.29656321]\n",
      "  [0.29895473]\n",
      "  [0.30278003]\n",
      "  [0.30763647]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08143157511949539\n",
      "Predicci√≥n post entrenamiento : [[0.31643695]]\n",
      "PERDIDAAAA despues: 0.07928097248077393\n",
      "loss en el callback: 0.09808805584907532, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "ejemplar: [[0.29226971]\n",
      " [0.29370022]\n",
      " [0.29455271]\n",
      " [0.29656321]\n",
      " [0.29895473]\n",
      " [0.30278003]\n",
      " [0.30763647]\n",
      " [0.31264353]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5945301858653699\n",
      "Predicci√≥n : [[0.31790552]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[[0.29226971]\n",
      "  [0.29370022]\n",
      "  [0.29455271]\n",
      "  [0.29656321]\n",
      "  [0.29895473]\n",
      "  [0.30278003]\n",
      "  [0.30763647]\n",
      "  [0.31264353]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07652119547128677\n",
      "Predicci√≥n post entrenamiento : [[0.32122353]]\n",
      "PERDIDAAAA despues: 0.07469651848077774\n",
      "loss en el callback: 0.08957159519195557, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "ejemplar: [[0.29370022]\n",
      " [0.29455271]\n",
      " [0.29656321]\n",
      " [0.29895473]\n",
      " [0.30278003]\n",
      " [0.30763647]\n",
      " [0.31264353]\n",
      " [0.31790552]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5984968478614763\n",
      "Predicci√≥n : [[0.32272005]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[[0.29370022]\n",
      "  [0.29455271]\n",
      "  [0.29656321]\n",
      "  [0.29895473]\n",
      "  [0.30278003]\n",
      "  [0.30763647]\n",
      "  [0.31264353]\n",
      "  [0.31790552]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07605284452438354\n",
      "Predicci√≥n post entrenamiento : [[0.3261098]]\n",
      "PERDIDAAAA despues: 0.07419470697641373\n",
      "loss en el callback: 0.07959163933992386, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "ejemplar: [[0.29455271]\n",
      " [0.29656321]\n",
      " [0.29895473]\n",
      " [0.30278003]\n",
      " [0.30763647]\n",
      " [0.31264353]\n",
      " [0.31790552]\n",
      " [0.32272005]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6213543446734934\n",
      "Predicci√≥n : [[0.32795644]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[[0.29455271]\n",
      "  [0.29656321]\n",
      "  [0.29895473]\n",
      "  [0.30278003]\n",
      "  [0.30763647]\n",
      "  [0.31264353]\n",
      "  [0.31790552]\n",
      "  [0.32272005]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0860823318362236\n",
      "Predicci√≥n post entrenamiento : [[0.3312429]]\n",
      "PERDIDAAAA despues: 0.08416465669870377\n",
      "loss en el callback: 0.07064783573150635, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "ejemplar: [[0.29656321]\n",
      " [0.29895473]\n",
      " [0.30278003]\n",
      " [0.30763647]\n",
      " [0.31264353]\n",
      " [0.31790552]\n",
      " [0.32272005]\n",
      " [0.32795644]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.663102676301421\n",
      "Predicci√≥n : [[0.33371142]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[[0.29656321]\n",
      "  [0.29895473]\n",
      "  [0.30278003]\n",
      "  [0.30763647]\n",
      "  [0.31264353]\n",
      "  [0.31790552]\n",
      "  [0.32272005]\n",
      "  [0.32795644]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10849861055612564\n",
      "Predicci√≥n post entrenamiento : [[0.33731794]]\n",
      "PERDIDAAAA despues: 0.10613569617271423\n",
      "loss en el callback: 0.07751788198947906, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "ejemplar: [[0.29895473]\n",
      " [0.30278003]\n",
      " [0.30763647]\n",
      " [0.31264353]\n",
      " [0.31790552]\n",
      " [0.32272005]\n",
      " [0.32795644]\n",
      " [0.33371142]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6928724338328028\n",
      "Predicci√≥n : [[0.34028742]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[[0.29895473]\n",
      "  [0.30278003]\n",
      "  [0.30763647]\n",
      "  [0.31264353]\n",
      "  [0.31790552]\n",
      "  [0.32272005]\n",
      "  [0.32795644]\n",
      "  [0.33371142]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12431617081165314\n",
      "Predicci√≥n post entrenamiento : [[0.3441894]]\n",
      "PERDIDAAAA despues: 0.12157983332872391\n",
      "loss en el callback: 0.12250486016273499, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "ejemplar: [[0.30278003]\n",
      " [0.30763647]\n",
      " [0.31264353]\n",
      " [0.31790552]\n",
      " [0.32272005]\n",
      " [0.32795644]\n",
      " [0.33371142]\n",
      " [0.34028742]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.710663617267639\n",
      "Predicci√≥n : [[0.34769776]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[[0.30278003]\n",
      "  [0.30763647]\n",
      "  [0.31264353]\n",
      "  [0.31790552]\n",
      "  [0.32272005]\n",
      "  [0.32795644]\n",
      "  [0.33371142]\n",
      "  [0.34028742]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13174420595169067\n",
      "Predicci√≥n post entrenamiento : [[0.35172743]]\n",
      "PERDIDAAAA despues: 0.12883518636226654\n",
      "loss en el callback: 0.13624420762062073, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "ejemplar: [[0.30763647]\n",
      " [0.31264353]\n",
      " [0.31790552]\n",
      " [0.32272005]\n",
      " [0.32795644]\n",
      " [0.33371142]\n",
      " [0.34028742]\n",
      " [0.34769776]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7216820581308059\n",
      "Predicci√≥n : [[0.35555294]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[[0.30763647]\n",
      "  [0.31264353]\n",
      "  [0.31790552]\n",
      "  [0.32272005]\n",
      "  [0.32795644]\n",
      "  [0.33371142]\n",
      "  [0.34028742]\n",
      "  [0.34769776]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13405053317546844\n",
      "Predicci√≥n post entrenamiento : [[0.35960713]]\n",
      "PERDIDAAAA despues: 0.13109827041625977\n",
      "loss en el callback: 0.14715634286403656, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "ejemplar: [[0.31264353]\n",
      " [0.31790552]\n",
      " [0.32272005]\n",
      " [0.32795644]\n",
      " [0.33371142]\n",
      " [0.34028742]\n",
      " [0.34769776]\n",
      " [0.35555294]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7259277564223031\n",
      "Predicci√≥n : [[0.3635914]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[[0.31264353]\n",
      "  [0.31790552]\n",
      "  [0.32272005]\n",
      "  [0.32795644]\n",
      "  [0.33371142]\n",
      "  [0.34028742]\n",
      "  [0.34769776]\n",
      "  [0.35555294]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13128764927387238\n",
      "Predicci√≥n post entrenamiento : [[0.36769316]]\n",
      "PERDIDAAAA despues: 0.12833203375339508\n",
      "loss en el callback: 0.14363186061382294, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "ejemplar: [[0.31790552]\n",
      " [0.32272005]\n",
      " [0.32795644]\n",
      " [0.33371142]\n",
      " [0.34028742]\n",
      " [0.34769776]\n",
      " [0.35555294]\n",
      " [0.3635914 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7404318224413275\n",
      "Predicci√≥n : [[0.37187815]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[[0.31790552]\n",
      "  [0.32272005]\n",
      "  [0.32795644]\n",
      "  [0.33371142]\n",
      "  [0.34028742]\n",
      "  [0.34769776]\n",
      "  [0.35555294]\n",
      "  [0.3635914 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1358318328857422\n",
      "Predicci√≥n post entrenamiento : [[0.37603384]]\n",
      "PERDIDAAAA despues: 0.13278590142726898\n",
      "loss en el callback: 0.15245334804058075, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "ejemplar: [[0.32272005]\n",
      " [0.32795644]\n",
      " [0.33371142]\n",
      " [0.34028742]\n",
      " [0.34769776]\n",
      " [0.35555294]\n",
      " [0.3635914 ]\n",
      " [0.37187815]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7651942561878792\n",
      "Predicci√≥n : [[0.3804504]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[[0.32272005]\n",
      "  [0.32795644]\n",
      "  [0.33371142]\n",
      "  [0.34028742]\n",
      "  [0.34769776]\n",
      "  [0.35555294]\n",
      "  [0.3635914 ]\n",
      "  [0.37187815]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14802782237529755\n",
      "Predicci√≥n post entrenamiento : [[0.384491]]\n",
      "PERDIDAAAA despues: 0.14493495225906372\n",
      "loss en el callback: 0.20919747650623322, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "ejemplar: [[0.32795644]\n",
      " [0.33371142]\n",
      " [0.34028742]\n",
      " [0.34769776]\n",
      " [0.35555294]\n",
      " [0.3635914 ]\n",
      " [0.37187815]\n",
      " [0.3804504 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7447890964420396\n",
      "Predicci√≥n : [[0.38935393]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[[0.32795644]\n",
      "  [0.33371142]\n",
      "  [0.34028742]\n",
      "  [0.34769776]\n",
      "  [0.35555294]\n",
      "  [0.3635914 ]\n",
      "  [0.37187815]\n",
      "  [0.3804504 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12633417546749115\n",
      "Predicci√≥n post entrenamiento : [[0.39302233]]\n",
      "PERDIDAAAA despues: 0.12373987585306168\n",
      "loss en el callback: 0.12459983676671982, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "ejemplar: [[0.33371142]\n",
      " [0.34028742]\n",
      " [0.34769776]\n",
      " [0.35555294]\n",
      " [0.3635914 ]\n",
      " [0.37187815]\n",
      " [0.3804504 ]\n",
      " [0.38935393]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6792163432038085\n",
      "Predicci√≥n : [[0.39835903]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[[0.33371142]\n",
      "  [0.34028742]\n",
      "  [0.34769776]\n",
      "  [0.35555294]\n",
      "  [0.3635914 ]\n",
      "  [0.37187815]\n",
      "  [0.3804504 ]\n",
      "  [0.38935393]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07888081669807434\n",
      "Predicci√≥n post entrenamiento : [[0.4009944]]\n",
      "PERDIDAAAA despues: 0.07740744203329086\n",
      "loss en el callback: 0.051205188035964966, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "ejemplar: [[0.34028742]\n",
      " [0.34769776]\n",
      " [0.35555294]\n",
      " [0.3635914 ]\n",
      " [0.37187815]\n",
      " [0.3804504 ]\n",
      " [0.38935393]\n",
      " [0.39835903]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6746017659154131\n",
      "Predicci√≥n : [[0.4068005]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[[0.34028742]\n",
      "  [0.34769776]\n",
      "  [0.35555294]\n",
      "  [0.3635914 ]\n",
      "  [0.37187815]\n",
      "  [0.3804504 ]\n",
      "  [0.38935393]\n",
      "  [0.39835903]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0717175304889679\n",
      "Predicci√≥n post entrenamiento : [[0.40990466]]\n",
      "PERDIDAAAA despues: 0.07006457448005676\n",
      "loss en el callback: 0.1280840039253235, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "ejemplar: [[0.34769776]\n",
      " [0.35555294]\n",
      " [0.3635914 ]\n",
      " [0.37187815]\n",
      " [0.3804504 ]\n",
      " [0.38935393]\n",
      " [0.39835903]\n",
      " [0.40680051]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7309453645768532\n",
      "Predicci√≥n : [[0.41608503]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[[0.34769776]\n",
      "  [0.35555294]\n",
      "  [0.3635914 ]\n",
      "  [0.37187815]\n",
      "  [0.3804504 ]\n",
      "  [0.38935393]\n",
      "  [0.39835903]\n",
      "  [0.40680051]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09913701564073563\n",
      "Predicci√≥n post entrenamiento : [[0.4189953]]\n",
      "PERDIDAAAA despues: 0.09731283783912659\n",
      "loss en el callback: 0.07029983401298523, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "ejemplar: [[0.35555294]\n",
      " [0.3635914 ]\n",
      " [0.37187815]\n",
      " [0.3804504 ]\n",
      " [0.38935393]\n",
      " [0.39835903]\n",
      " [0.40680051]\n",
      " [0.41608503]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7467210055914982\n",
      "Predicci√≥n : [[0.425424]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[[0.35555294]\n",
      "  [0.3635914 ]\n",
      "  [0.37187815]\n",
      "  [0.3804504 ]\n",
      "  [0.38935393]\n",
      "  [0.39835903]\n",
      "  [0.40680051]\n",
      "  [0.41608503]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1032317727804184\n",
      "Predicci√≥n post entrenamiento : [[0.428887]]\n",
      "PERDIDAAAA despues: 0.10101846605539322\n",
      "loss en el callback: 0.14474281668663025, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "ejemplar: [[0.3635914 ]\n",
      " [0.37187815]\n",
      " [0.3804504 ]\n",
      " [0.38935393]\n",
      " [0.39835903]\n",
      " [0.40680051]\n",
      " [0.41608503]\n",
      " [0.42542401]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7219286889593481\n",
      "Predicci√≥n : [[0.43551123]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[[0.3635914 ]\n",
      "  [0.37187815]\n",
      "  [0.3804504 ]\n",
      "  [0.38935393]\n",
      "  [0.39835903]\n",
      "  [0.40680051]\n",
      "  [0.41608503]\n",
      "  [0.42542401]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08203497529029846\n",
      "Predicci√≥n post entrenamiento : [[0.43837616]]\n",
      "PERDIDAAAA despues: 0.08040205389261246\n",
      "loss en el callback: 0.1030978411436081, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "ejemplar: [[0.37187815]\n",
      " [0.3804504 ]\n",
      " [0.38935393]\n",
      " [0.39835903]\n",
      " [0.40680051]\n",
      " [0.41608503]\n",
      " [0.42542401]\n",
      " [0.43551123]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7199286701160912\n",
      "Predicci√≥n : [[0.4452003]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[[0.37187815]\n",
      "  [0.3804504 ]\n",
      "  [0.38935393]\n",
      "  [0.39835903]\n",
      "  [0.40680051]\n",
      "  [0.41608503]\n",
      "  [0.42542401]\n",
      "  [0.43551123]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07547568529844284\n",
      "Predicci√≥n post entrenamiento : [[0.44803175]]\n",
      "PERDIDAAAA despues: 0.07392793893814087\n",
      "loss en el callback: 0.09462857246398926, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "ejemplar: [[0.3804504 ]\n",
      " [0.38935393]\n",
      " [0.39835903]\n",
      " [0.40680051]\n",
      " [0.41608503]\n",
      " [0.42542401]\n",
      " [0.43551123]\n",
      " [0.44520029]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7407209490617273\n",
      "Predicci√≥n : [[0.4550443]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[[0.3804504 ]\n",
      "  [0.38935393]\n",
      "  [0.39835903]\n",
      "  [0.40680051]\n",
      "  [0.41608503]\n",
      "  [0.42542401]\n",
      "  [0.43551123]\n",
      "  [0.44520029]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08161113411188126\n",
      "Predicci√≥n post entrenamiento : [[0.45804873]]\n",
      "PERDIDAAAA despues: 0.07990357279777527\n",
      "loss en el callback: 0.12648852169513702, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "ejemplar: [[0.38935393]\n",
      " [0.39835903]\n",
      " [0.40680051]\n",
      " [0.41608503]\n",
      " [0.42542401]\n",
      " [0.43551123]\n",
      " [0.44520029]\n",
      " [0.4550443 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.736245501831604\n",
      "Predicci√≥n : [[0.4652263]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[[0.38935393]\n",
      "  [0.39835903]\n",
      "  [0.40680051]\n",
      "  [0.41608503]\n",
      "  [0.42542401]\n",
      "  [0.43551123]\n",
      "  [0.44520029]\n",
      "  [0.4550443 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07345141470432281\n",
      "Predicci√≥n post entrenamiento : [[0.46780336]]\n",
      "PERDIDAAAA despues: 0.07206118851900101\n",
      "loss en el callback: 0.07002199441194534, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "ejemplar: [[0.39835903]\n",
      " [0.40680051]\n",
      " [0.41608503]\n",
      " [0.42542401]\n",
      " [0.43551123]\n",
      " [0.44520029]\n",
      " [0.4550443 ]\n",
      " [0.46522629]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7065023284257214\n",
      "Predicci√≥n : [[0.4751057]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[[0.39835903]\n",
      "  [0.40680051]\n",
      "  [0.41608503]\n",
      "  [0.42542401]\n",
      "  [0.43551123]\n",
      "  [0.44520029]\n",
      "  [0.4550443 ]\n",
      "  [0.46522629]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05354439467191696\n",
      "Predicci√≥n post entrenamiento : [[0.47718182]]\n",
      "PERDIDAAAA despues: 0.05258788913488388\n",
      "loss en el callback: 0.046039190143346786, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "ejemplar: [[0.40680051]\n",
      " [0.41608503]\n",
      " [0.42542401]\n",
      " [0.43551123]\n",
      " [0.44520029]\n",
      " [0.4550443 ]\n",
      " [0.46522629]\n",
      " [0.4751057 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6979451506854685\n",
      "Predicci√≥n : [[0.4846206]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[[0.40680051]\n",
      "  [0.41608503]\n",
      "  [0.42542401]\n",
      "  [0.43551123]\n",
      "  [0.44520029]\n",
      "  [0.4550443 ]\n",
      "  [0.46522629]\n",
      "  [0.4751057 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04550737515091896\n",
      "Predicci√≥n post entrenamiento : [[0.48645672]]\n",
      "PERDIDAAAA despues: 0.04472736641764641\n",
      "loss en el callback: 0.035019613802433014, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "ejemplar: [[0.41608503]\n",
      " [0.42542401]\n",
      " [0.43551123]\n",
      " [0.44520029]\n",
      " [0.4550443 ]\n",
      " [0.46522629]\n",
      " [0.4751057 ]\n",
      " [0.4846206 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7105739686108449\n",
      "Predicci√≥n : [[0.49421653]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[[0.41608503]\n",
      "  [0.42542401]\n",
      "  [0.43551123]\n",
      "  [0.44520029]\n",
      "  [0.4550443 ]\n",
      "  [0.46522629]\n",
      "  [0.4751057 ]\n",
      "  [0.4846206 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.046810541301965714\n",
      "Predicci√≥n post entrenamiento : [[0.49654314]]\n",
      "PERDIDAAAA despues: 0.045809198170900345\n",
      "loss en el callback: 0.06191154569387436, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "ejemplar: [[0.42542401]\n",
      " [0.43551123]\n",
      " [0.44520029]\n",
      " [0.4550443 ]\n",
      " [0.46522629]\n",
      " [0.4751057 ]\n",
      " [0.4846206 ]\n",
      " [0.49421653]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7209621522504839\n",
      "Predicci√≥n : [[0.5044574]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[[0.42542401]\n",
      "  [0.43551123]\n",
      "  [0.44520029]\n",
      "  [0.4550443 ]\n",
      "  [0.46522629]\n",
      "  [0.4751057 ]\n",
      "  [0.4846206 ]\n",
      "  [0.49421653]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.046874307096004486\n",
      "Predicci√≥n post entrenamiento : [[0.50656855]]\n",
      "PERDIDAAAA despues: 0.045964621007442474\n",
      "loss en el callback: 0.055363092571496964, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "ejemplar: [[0.43551123]\n",
      " [0.44520029]\n",
      " [0.4550443 ]\n",
      " [0.46522629]\n",
      " [0.4751057 ]\n",
      " [0.4846206 ]\n",
      " [0.49421653]\n",
      " [0.50445741]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7291097016043858\n",
      "Predicci√≥n : [[0.5146447]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[[0.43551123]\n",
      "  [0.44520029]\n",
      "  [0.4550443 ]\n",
      "  [0.46522629]\n",
      "  [0.4751057 ]\n",
      "  [0.4846206 ]\n",
      "  [0.49421653]\n",
      "  [0.50445741]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04599524661898613\n",
      "Predicci√≥n post entrenamiento : [[0.5166149]]\n",
      "PERDIDAAAA despues: 0.045154035091400146\n",
      "loss en el callback: 0.051576122641563416, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "ejemplar: [[0.44520029]\n",
      " [0.4550443 ]\n",
      " [0.46522629]\n",
      " [0.4751057 ]\n",
      " [0.4846206 ]\n",
      " [0.49421653]\n",
      " [0.50445741]\n",
      " [0.51464468]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7674259644168786\n",
      "Predicci√≥n : [[0.52467376]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[[0.44520029]\n",
      "  [0.4550443 ]\n",
      "  [0.46522629]\n",
      "  [0.4751057 ]\n",
      "  [0.4846206 ]\n",
      "  [0.49421653]\n",
      "  [0.50445741]\n",
      "  [0.51464468]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05892862752079964\n",
      "Predicci√≥n post entrenamiento : [[0.5267873]]\n",
      "PERDIDAAAA despues: 0.057906970381736755\n",
      "loss en el callback: 0.050702232867479324, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "ejemplar: [[0.4550443 ]\n",
      " [0.46522629]\n",
      " [0.4751057 ]\n",
      " [0.4846206 ]\n",
      " [0.49421653]\n",
      " [0.50445741]\n",
      " [0.51464468]\n",
      " [0.52467376]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8359109406879621\n",
      "Predicci√≥n : [[0.5349306]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[[0.4550443 ]\n",
      "  [0.46522629]\n",
      "  [0.4751057 ]\n",
      "  [0.4846206 ]\n",
      "  [0.49421653]\n",
      "  [0.50445741]\n",
      "  [0.51464468]\n",
      "  [0.52467376]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09058915823698044\n",
      "Predicci√≥n post entrenamiento : [[0.53767115]]\n",
      "PERDIDAAAA despues: 0.08894696086645126\n",
      "loss en el callback: 0.0885208323597908, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "ejemplar: [[0.46522629]\n",
      " [0.4751057 ]\n",
      " [0.4846206 ]\n",
      " [0.49421653]\n",
      " [0.50445741]\n",
      " [0.51464468]\n",
      " [0.52467376]\n",
      " [0.53493059]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8510103358824123\n",
      "Predicci√≥n : [[0.5458713]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[[0.46522629]\n",
      "  [0.4751057 ]\n",
      "  [0.4846206 ]\n",
      "  [0.49421653]\n",
      "  [0.50445741]\n",
      "  [0.51464468]\n",
      "  [0.52467376]\n",
      "  [0.53493059]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09310980886220932\n",
      "Predicci√≥n post entrenamiento : [[0.5483803]]\n",
      "PERDIDAAAA despues: 0.09158492088317871\n",
      "loss en el callback: 0.07082535326480865, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "ejemplar: [[0.4751057 ]\n",
      " [0.4846206 ]\n",
      " [0.49421653]\n",
      " [0.50445741]\n",
      " [0.51464468]\n",
      " [0.52467376]\n",
      " [0.53493059]\n",
      " [0.54587132]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8127241500002294\n",
      "Predicci√≥n : [[0.55655956]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[[0.4751057 ]\n",
      "  [0.4846206 ]\n",
      "  [0.49421653]\n",
      "  [0.50445741]\n",
      "  [0.51464468]\n",
      "  [0.52467376]\n",
      "  [0.53493059]\n",
      "  [0.54587132]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0656203106045723\n",
      "Predicci√≥n post entrenamiento : [[0.55912226]]\n",
      "PERDIDAAAA despues: 0.06431392580270767\n",
      "loss en el callback: 0.12404821813106537, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "ejemplar: [[0.4846206 ]\n",
      " [0.49421653]\n",
      " [0.50445741]\n",
      " [0.51464468]\n",
      " [0.52467376]\n",
      " [0.53493059]\n",
      " [0.54587132]\n",
      " [0.55655956]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7863940290280375\n",
      "Predicci√≥n : [[0.56737185]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[[0.4846206 ]\n",
      "  [0.49421653]\n",
      "  [0.50445741]\n",
      "  [0.51464468]\n",
      "  [0.52467376]\n",
      "  [0.53493059]\n",
      "  [0.54587132]\n",
      "  [0.55655956]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04797070473432541\n",
      "Predicci√≥n post entrenamiento : [[0.5699345]]\n",
      "PERDIDAAAA despues: 0.04685471951961517\n",
      "loss en el callback: 0.13153259456157684, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "ejemplar: [[0.49421653]\n",
      " [0.50445741]\n",
      " [0.51464468]\n",
      " [0.52467376]\n",
      " [0.53493059]\n",
      " [0.54587132]\n",
      " [0.55655956]\n",
      " [0.56737185]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7720199729658365\n",
      "Predicci√≥n : [[0.57838196]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[[0.49421653]\n",
      "  [0.50445741]\n",
      "  [0.51464468]\n",
      "  [0.52467376]\n",
      "  [0.53493059]\n",
      "  [0.54587132]\n",
      "  [0.55655956]\n",
      "  [0.56737185]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0374956838786602\n",
      "Predicci√≥n post entrenamiento : [[0.5804578]]\n",
      "PERDIDAAAA despues: 0.036696068942546844\n",
      "loss en el callback: 0.07349897921085358, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "ejemplar: [[0.50445741]\n",
      " [0.51464468]\n",
      " [0.52467376]\n",
      " [0.53493059]\n",
      " [0.54587132]\n",
      " [0.55655956]\n",
      " [0.56737185]\n",
      " [0.57838196]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8033170564228299\n",
      "Predicci√≥n : [[0.5891283]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[[0.50445741]\n",
      "  [0.51464468]\n",
      "  [0.52467376]\n",
      "  [0.53493059]\n",
      "  [0.54587132]\n",
      "  [0.55655956]\n",
      "  [0.56737185]\n",
      "  [0.57838196]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.045876823365688324\n",
      "Predicci√≥n post entrenamiento : [[0.590858]]\n",
      "PERDIDAAAA despues: 0.04513886198401451\n",
      "loss en el callback: 0.03667747974395752, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "ejemplar: [[0.51464468]\n",
      " [0.52467376]\n",
      " [0.53493059]\n",
      " [0.54587132]\n",
      " [0.55655956]\n",
      " [0.56737185]\n",
      " [0.57838196]\n",
      " [0.58912832]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8802852793990171\n",
      "Predicci√≥n : [[0.59962153]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[[0.51464468]\n",
      "  [0.52467376]\n",
      "  [0.53493059]\n",
      "  [0.54587132]\n",
      "  [0.55655956]\n",
      "  [0.56737185]\n",
      "  [0.57838196]\n",
      "  [0.58912832]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07877212762832642\n",
      "Predicci√≥n post entrenamiento : [[0.60203046]]\n",
      "PERDIDAAAA despues: 0.07742574065923691\n",
      "loss en el callback: 0.07244375348091125, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "ejemplar: [[0.52467376]\n",
      " [0.53493059]\n",
      " [0.54587132]\n",
      " [0.55655956]\n",
      " [0.56737185]\n",
      " [0.57838196]\n",
      " [0.58912832]\n",
      " [0.59962153]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8987051676996881\n",
      "Predicci√≥n : [[0.6109275]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[[0.52467376]\n",
      "  [0.53493059]\n",
      "  [0.54587132]\n",
      "  [0.55655956]\n",
      "  [0.56737185]\n",
      "  [0.57838196]\n",
      "  [0.58912832]\n",
      "  [0.59962153]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.082815982401371\n",
      "Predicci√≥n post entrenamiento : [[0.613451]]\n",
      "PERDIDAAAA despues: 0.08136994391679764\n",
      "loss en el callback: 0.07643415033817291, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "ejemplar: [[0.53493059]\n",
      " [0.54587132]\n",
      " [0.55655956]\n",
      " [0.56737185]\n",
      " [0.57838196]\n",
      " [0.58912832]\n",
      " [0.59962153]\n",
      " [0.61092752]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8585767213248423\n",
      "Predicci√≥n : [[0.6225538]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[[0.53493059]\n",
      "  [0.54587132]\n",
      "  [0.55655956]\n",
      "  [0.56737185]\n",
      "  [0.57838196]\n",
      "  [0.58912832]\n",
      "  [0.59962153]\n",
      "  [0.61092752]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.055706802755594254\n",
      "Predicci√≥n post entrenamiento : [[0.62502986]]\n",
      "PERDIDAAAA despues: 0.05454413220286369\n",
      "loss en el callback: 0.13916274905204773, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "ejemplar: [[0.54587132]\n",
      " [0.55655956]\n",
      " [0.56737185]\n",
      " [0.57838196]\n",
      " [0.58912832]\n",
      " [0.59962153]\n",
      " [0.61092752]\n",
      " [0.62255383]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8308762565987861\n",
      "Predicci√≥n : [[0.63431454]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[[0.54587132]\n",
      "  [0.55655956]\n",
      "  [0.56737185]\n",
      "  [0.57838196]\n",
      "  [0.58912832]\n",
      "  [0.59962153]\n",
      "  [0.61092752]\n",
      "  [0.62255383]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.038636498153209686\n",
      "Predicci√≥n post entrenamiento : [[0.6363584]]\n",
      "PERDIDAAAA despues: 0.0378371961414814\n",
      "loss en el callback: 0.06979255378246307, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "ejemplar: [[0.55655956]\n",
      " [0.56737185]\n",
      " [0.57838196]\n",
      " [0.58912832]\n",
      " [0.59962153]\n",
      " [0.61092752]\n",
      " [0.62255383]\n",
      " [0.63431454]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8156037735215196\n",
      "Predicci√≥n : [[0.6456685]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[[0.55655956]\n",
      "  [0.56737185]\n",
      "  [0.57838196]\n",
      "  [0.58912832]\n",
      "  [0.59962153]\n",
      "  [0.61092752]\n",
      "  [0.62255383]\n",
      "  [0.63431454]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.028878001496195793\n",
      "Predicci√≥n post entrenamiento : [[0.6480203]]\n",
      "PERDIDAAAA despues: 0.028084218502044678\n",
      "loss en el callback: 0.09624022245407104, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "ejemplar: [[0.56737185]\n",
      " [0.57838196]\n",
      " [0.58912832]\n",
      " [0.59962153]\n",
      " [0.61092752]\n",
      " [0.62255383]\n",
      " [0.63431454]\n",
      " [0.64566851]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8116992058331503\n",
      "Predicci√≥n : [[0.6574422]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[[0.56737185]\n",
      "  [0.57838196]\n",
      "  [0.58912832]\n",
      "  [0.59962153]\n",
      "  [0.61092752]\n",
      "  [0.62255383]\n",
      "  [0.63431454]\n",
      "  [0.64566851]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.023795221000909805\n",
      "Predicci√≥n post entrenamiento : [[0.65925527]]\n",
      "PERDIDAAAA despues: 0.02323915623128414\n",
      "loss en el callback: 0.05491605028510094, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "ejemplar: [[0.57838196]\n",
      " [0.58912832]\n",
      " [0.59962153]\n",
      " [0.61092752]\n",
      " [0.62255383]\n",
      " [0.63431454]\n",
      " [0.64566851]\n",
      " [0.65744221]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8191625535336788\n",
      "Predicci√≥n : [[0.66878533]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[[0.57838196]\n",
      "  [0.58912832]\n",
      "  [0.59962153]\n",
      "  [0.61092752]\n",
      "  [0.62255383]\n",
      "  [0.63431454]\n",
      "  [0.64566851]\n",
      "  [0.65744221]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02261330559849739\n",
      "Predicci√≥n post entrenamiento : [[0.6699001]]\n",
      "PERDIDAAAA despues: 0.022279271855950356\n",
      "loss en el callback: 0.018272487446665764, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "ejemplar: [[0.58912832]\n",
      " [0.59962153]\n",
      " [0.61092752]\n",
      " [0.62255383]\n",
      " [0.63431454]\n",
      " [0.64566851]\n",
      " [0.65744221]\n",
      " [0.66878533]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8218275636038536\n",
      "Predicci√≥n : [[0.6795108]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[[0.58912832]\n",
      "  [0.59962153]\n",
      "  [0.61092752]\n",
      "  [0.62255383]\n",
      "  [0.63431454]\n",
      "  [0.64566851]\n",
      "  [0.65744221]\n",
      "  [0.66878533]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02025407738983631\n",
      "Predicci√≥n post entrenamiento : [[0.6809275]]\n",
      "PERDIDAAAA despues: 0.019852831959724426\n",
      "loss en el callback: 0.028451740741729736, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "ejemplar: [[0.59962153]\n",
      " [0.61092752]\n",
      " [0.62255383]\n",
      " [0.63431454]\n",
      " [0.64566851]\n",
      " [0.65744221]\n",
      " [0.66878533]\n",
      " [0.67951077]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8196942360436743\n",
      "Predicci√≥n : [[0.6907143]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[[0.59962153]\n",
      "  [0.61092752]\n",
      "  [0.62255383]\n",
      "  [0.63431454]\n",
      "  [0.64566851]\n",
      "  [0.65744221]\n",
      "  [0.66878533]\n",
      "  [0.67951077]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016635820269584656\n",
      "Predicci√≥n post entrenamiento : [[0.69135463]]\n",
      "PERDIDAAAA despues: 0.016471050679683685\n",
      "loss en el callback: 0.004802803508937359, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "ejemplar: [[0.61092752]\n",
      " [0.62255383]\n",
      " [0.63431454]\n",
      " [0.64566851]\n",
      " [0.65744221]\n",
      " [0.66878533]\n",
      " [0.67951077]\n",
      " [0.6907143 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8178628420548653\n",
      "Predicci√≥n : [[0.7014131]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[[0.61092752]\n",
      "  [0.62255383]\n",
      "  [0.63431454]\n",
      "  [0.64566851]\n",
      "  [0.65744221]\n",
      "  [0.66878533]\n",
      "  [0.67951077]\n",
      "  [0.6907143 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013560549356043339\n",
      "Predicci√≥n post entrenamiento : [[0.7020911]]\n",
      "PERDIDAAAA despues: 0.01340310275554657\n",
      "loss en el callback: 0.005844363942742348, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "ejemplar: [[0.62255383]\n",
      " [0.63431454]\n",
      " [0.64566851]\n",
      " [0.65744221]\n",
      " [0.66878533]\n",
      " [0.67951077]\n",
      " [0.6907143 ]\n",
      " [0.70141309]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8163333816374257\n",
      "Predicci√≥n : [[0.7122152]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[[0.62255383]\n",
      "  [0.63431454]\n",
      "  [0.64566851]\n",
      "  [0.65744221]\n",
      "  [0.66878533]\n",
      "  [0.67951077]\n",
      "  [0.6907143 ]\n",
      "  [0.70141309]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01084059290587902\n",
      "Predicci√≥n post entrenamiento : [[0.7133064]]\n",
      "PERDIDAAAA despues: 0.0106145478785038\n",
      "loss en el callback: 0.019675470888614655, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "ejemplar: [[0.63431454]\n",
      " [0.64566851]\n",
      " [0.65744221]\n",
      " [0.66878533]\n",
      " [0.67951077]\n",
      " [0.6907143 ]\n",
      " [0.70141309]\n",
      " [0.71221519]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8005556061309519\n",
      "Predicci√≥n : [[0.7233912]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[[0.63431454]\n",
      "  [0.64566851]\n",
      "  [0.65744221]\n",
      "  [0.66878533]\n",
      "  [0.67951077]\n",
      "  [0.6907143 ]\n",
      "  [0.70141309]\n",
      "  [0.71221519]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005954346619546413\n",
      "Predicci√≥n post entrenamiento : [[0.72504395]]\n",
      "PERDIDAAAA despues: 0.005702007096260786\n",
      "loss en el callback: 0.05549629405140877, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "ejemplar: [[0.64566851]\n",
      " [0.65744221]\n",
      " [0.66878533]\n",
      " [0.67951077]\n",
      " [0.6907143 ]\n",
      " [0.70141309]\n",
      " [0.71221519]\n",
      " [0.72339118]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7705295155354442\n",
      "Predicci√≥n : [[0.7350218]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[[0.64566851]\n",
      "  [0.65744221]\n",
      "  [0.66878533]\n",
      "  [0.67951077]\n",
      "  [0.6907143 ]\n",
      "  [0.70141309]\n",
      "  [0.71221519]\n",
      "  [0.72339118]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012607952812686563\n",
      "Predicci√≥n post entrenamiento : [[0.7364323]]\n",
      "PERDIDAAAA despues: 0.0011626186314970255\n",
      "loss en el callback: 0.04669520631432533, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "ejemplar: [[0.65744221]\n",
      " [0.66878533]\n",
      " [0.67951077]\n",
      " [0.6907143 ]\n",
      " [0.70141309]\n",
      " [0.71221519]\n",
      " [0.72339118]\n",
      " [0.73502183]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7426586795525351\n",
      "Predicci√≥n : [[0.7463859]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[[0.65744221]\n",
      "  [0.66878533]\n",
      "  [0.67951077]\n",
      "  [0.6907143 ]\n",
      "  [0.70141309]\n",
      "  [0.71221519]\n",
      "  [0.72339118]\n",
      "  [0.73502183]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.3892002243665047e-05\n",
      "Predicci√≥n post entrenamiento : [[0.7471992]]\n",
      "PERDIDAAAA despues: 2.0616167603293434e-05\n",
      "loss en el callback: 0.01492688525468111, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "ejemplar: [[0.66878533]\n",
      " [0.67951077]\n",
      " [0.6907143 ]\n",
      " [0.70141309]\n",
      " [0.71221519]\n",
      " [0.72339118]\n",
      " [0.73502183]\n",
      " [0.74638587]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.716943098182225\n",
      "Predicci√≥n : [[0.756993]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[[0.66878533]\n",
      "  [0.67951077]\n",
      "  [0.6907143 ]\n",
      "  [0.70141309]\n",
      "  [0.71221519]\n",
      "  [0.72339118]\n",
      "  [0.73502183]\n",
      "  [0.74638587]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016039953334257007\n",
      "Predicci√≥n post entrenamiento : [[0.7561295]]\n",
      "PERDIDAAAA despues: 0.001535575371235609\n",
      "loss en el callback: 0.010415870696306229, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "ejemplar: [[0.67951077]\n",
      " [0.6907143 ]\n",
      " [0.70141309]\n",
      " [0.71221519]\n",
      " [0.72339118]\n",
      " [0.73502183]\n",
      " [0.74638587]\n",
      " [0.756993  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7197051306082382\n",
      "Predicci√≥n : [[0.76585484]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[[0.67951077]\n",
      "  [0.6907143 ]\n",
      "  [0.70141309]\n",
      "  [0.71221519]\n",
      "  [0.72339118]\n",
      "  [0.73502183]\n",
      "  [0.74638587]\n",
      "  [0.756993  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0021297975908964872\n",
      "Predicci√≥n post entrenamiento : [[0.76566976]]\n",
      "PERDIDAAAA despues: 0.002112749731168151\n",
      "loss en el callback: 0.0005454006604850292, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "ejemplar: [[0.6907143 ]\n",
      " [0.70141309]\n",
      " [0.71221519]\n",
      " [0.72339118]\n",
      " [0.73502183]\n",
      " [0.74638587]\n",
      " [0.756993  ]\n",
      " [0.76585484]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7509447768305747\n",
      "Predicci√≥n : [[0.77548623]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[[0.6907143 ]\n",
      "  [0.70141309]\n",
      "  [0.71221519]\n",
      "  [0.72339118]\n",
      "  [0.73502183]\n",
      "  [0.74638587]\n",
      "  [0.756993  ]\n",
      "  [0.76585484]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006022821762599051\n",
      "Predicci√≥n post entrenamiento : [[0.7741261]]\n",
      "PERDIDAAAA despues: 0.0005373735330067575\n",
      "loss en el callback: 0.022239433601498604, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "ejemplar: [[0.70141309]\n",
      " [0.71221519]\n",
      " [0.72339118]\n",
      " [0.73502183]\n",
      " [0.74638587]\n",
      " [0.756993  ]\n",
      " [0.76585484]\n",
      " [0.77548623]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.740278139029679\n",
      "Predicci√≥n : [[0.7838785]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[[0.70141309]\n",
      "  [0.71221519]\n",
      "  [0.72339118]\n",
      "  [0.73502183]\n",
      "  [0.74638587]\n",
      "  [0.756993  ]\n",
      "  [0.76585484]\n",
      "  [0.77548623]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0019009931711480021\n",
      "Predicci√≥n post entrenamiento : [[0.78297603]]\n",
      "PERDIDAAAA despues: 0.001823111204430461\n",
      "loss en el callback: 0.011843937449157238, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "ejemplar: [[0.71221519]\n",
      " [0.72339118]\n",
      " [0.73502183]\n",
      " [0.74638587]\n",
      " [0.756993  ]\n",
      " [0.76585484]\n",
      " [0.77548623]\n",
      " [0.78387851]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.687705217205551\n",
      "Predicci√≥n : [[0.79275894]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[[0.71221519]\n",
      "  [0.72339118]\n",
      "  [0.73502183]\n",
      "  [0.74638587]\n",
      "  [0.756993  ]\n",
      "  [0.76585484]\n",
      "  [0.77548623]\n",
      "  [0.78387851]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011036284267902374\n",
      "Predicci√≥n post entrenamiento : [[0.79185045]]\n",
      "PERDIDAAAA despues: 0.010846228338778019\n",
      "loss en el callback: 0.012289263308048248, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "ejemplar: [[0.72339118]\n",
      " [0.73502183]\n",
      " [0.74638587]\n",
      " [0.756993  ]\n",
      " [0.76585484]\n",
      " [0.77548623]\n",
      " [0.78387851]\n",
      " [0.79275894]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6687695580612426\n",
      "Predicci√≥n : [[0.8015766]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[[0.72339118]\n",
      "  [0.73502183]\n",
      "  [0.74638587]\n",
      "  [0.756993  ]\n",
      "  [0.76585484]\n",
      "  [0.77548623]\n",
      "  [0.78387851]\n",
      "  [0.79275894]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017637720331549644\n",
      "Predicci√≥n post entrenamiento : [[0.8004383]]\n",
      "PERDIDAAAA despues: 0.017336659133434296\n",
      "loss en el callback: 0.019340507686138153, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "ejemplar: [[0.73502183]\n",
      " [0.74638587]\n",
      " [0.756993  ]\n",
      " [0.76585484]\n",
      " [0.77548623]\n",
      " [0.78387851]\n",
      " [0.79275894]\n",
      " [0.80157661]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6834711615967536\n",
      "Predicci√≥n : [[0.8099177]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[[0.73502183]\n",
      "  [0.74638587]\n",
      "  [0.756993  ]\n",
      "  [0.76585484]\n",
      "  [0.77548623]\n",
      "  [0.78387851]\n",
      "  [0.79275894]\n",
      "  [0.80157661]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015988728031516075\n",
      "Predicci√≥n post entrenamiento : [[0.8090596]]\n",
      "PERDIDAAAA despues: 0.015772465616464615\n",
      "loss en el callback: 0.01403404213488102, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "ejemplar: [[0.74638587]\n",
      " [0.756993  ]\n",
      " [0.76585484]\n",
      " [0.77548623]\n",
      " [0.78387851]\n",
      " [0.79275894]\n",
      " [0.80157661]\n",
      " [0.80991769]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6877052172055499\n",
      "Predicci√≥n : [[0.81805015]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[[0.74638587]\n",
      "  [0.756993  ]\n",
      "  [0.76585484]\n",
      "  [0.77548623]\n",
      "  [0.78387851]\n",
      "  [0.79275894]\n",
      "  [0.80157661]\n",
      "  [0.80991769]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016989799216389656\n",
      "Predicci√≥n post entrenamiento : [[0.8174357]]\n",
      "PERDIDAAAA despues: 0.016829993575811386\n",
      "loss en el callback: 0.008128763176500797, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "ejemplar: [[0.756993  ]\n",
      " [0.76585484]\n",
      " [0.77548623]\n",
      " [0.78387851]\n",
      " [0.79275894]\n",
      " [0.80157661]\n",
      " [0.80991769]\n",
      " [0.81805015]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6814717248876317\n",
      "Predicci√≥n : [[0.825881]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[[0.756993  ]\n",
      "  [0.76585484]\n",
      "  [0.77548623]\n",
      "  [0.78387851]\n",
      "  [0.79275894]\n",
      "  [0.80157661]\n",
      "  [0.80991769]\n",
      "  [0.81805015]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02085404470562935\n",
      "Predicci√≥n post entrenamiento : [[0.82601655]]\n",
      "PERDIDAAAA despues: 0.020893210545182228\n",
      "loss en el callback: 0.0004479577764868736, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "ejemplar: [[0.76585484]\n",
      " [0.77548623]\n",
      " [0.78387851]\n",
      " [0.79275894]\n",
      " [0.80157661]\n",
      " [0.80991769]\n",
      " [0.81805015]\n",
      " [0.825881  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.689261843882625\n",
      "Predicci√≥n : [[0.8340136]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[[0.76585484]\n",
      "  [0.77548623]\n",
      "  [0.78387851]\n",
      "  [0.79275894]\n",
      "  [0.80157661]\n",
      "  [0.80991769]\n",
      "  [0.81805015]\n",
      "  [0.825881  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.020953062921762466\n",
      "Predicci√≥n post entrenamiento : [[0.8338882]]\n",
      "PERDIDAAAA despues: 0.02091677300632\n",
      "loss en el callback: 0.00039910327177494764, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "ejemplar: [[0.77548623]\n",
      " [0.78387851]\n",
      " [0.79275894]\n",
      " [0.80157661]\n",
      " [0.80991769]\n",
      " [0.81805015]\n",
      " [0.825881  ]\n",
      " [0.83401358]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7110755741905297\n",
      "Predicci√≥n : [[0.84184843]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[[0.77548623]\n",
      "  [0.78387851]\n",
      "  [0.79275894]\n",
      "  [0.80157661]\n",
      "  [0.80991769]\n",
      "  [0.81805015]\n",
      "  [0.825881  ]\n",
      "  [0.83401358]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017101533710956573\n",
      "Predicci√≥n post entrenamiento : [[0.8403001]]\n",
      "PERDIDAAAA despues: 0.016698965802788734\n",
      "loss en el callback: 0.03657661750912666, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "ejemplar: [[0.78387851]\n",
      " [0.79275894]\n",
      " [0.80157661]\n",
      " [0.80991769]\n",
      " [0.81805015]\n",
      " [0.825881  ]\n",
      " [0.83401358]\n",
      " [0.84184843]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7349108623046875\n",
      "Predicci√≥n : [[0.8479591]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[[0.78387851]\n",
      "  [0.79275894]\n",
      "  [0.80157661]\n",
      "  [0.80991769]\n",
      "  [0.81805015]\n",
      "  [0.825881  ]\n",
      "  [0.83401358]\n",
      "  [0.84184843]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012779908254742622\n",
      "Predicci√≥n post entrenamiento : [[0.8456035]]\n",
      "PERDIDAAAA despues: 0.012252869084477425\n",
      "loss en el callback: 0.07087745517492294, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "ejemplar: [[0.79275894]\n",
      " [0.80157661]\n",
      " [0.80991769]\n",
      " [0.81805015]\n",
      " [0.825881  ]\n",
      " [0.83401358]\n",
      " [0.84184843]\n",
      " [0.8479591 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7607677082250986\n",
      "Predicci√≥n : [[0.853244]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[[0.79275894]\n",
      "  [0.80157661]\n",
      "  [0.80991769]\n",
      "  [0.81805015]\n",
      "  [0.825881  ]\n",
      "  [0.83401358]\n",
      "  [0.84184843]\n",
      "  [0.8479591 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008551867678761482\n",
      "Predicci√≥n post entrenamiento : [[0.8536033]]\n",
      "PERDIDAAAA despues: 0.008618449792265892\n",
      "loss en el callback: 0.0030358813237398863, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "ejemplar: [[0.80157661]\n",
      " [0.80991769]\n",
      " [0.81805015]\n",
      " [0.825881  ]\n",
      " [0.83401358]\n",
      " [0.84184843]\n",
      " [0.8479591 ]\n",
      " [0.85324401]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7711170829224028\n",
      "Predicci√≥n : [[0.86103314]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[[0.80157661]\n",
      "  [0.80991769]\n",
      "  [0.81805015]\n",
      "  [0.825881  ]\n",
      "  [0.83401358]\n",
      "  [0.84184843]\n",
      "  [0.8479591 ]\n",
      "  [0.85324401]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008084896020591259\n",
      "Predicci√≥n post entrenamiento : [[0.86113364]]\n",
      "PERDIDAAAA despues: 0.008102978579699993\n",
      "loss en el callback: 0.00022183326655067503, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "ejemplar: [[0.80991769]\n",
      " [0.81805015]\n",
      " [0.825881  ]\n",
      " [0.83401358]\n",
      " [0.84184843]\n",
      " [0.8479591 ]\n",
      " [0.85324401]\n",
      " [0.86103314]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7659589863965997\n",
      "Predicci√≥n : [[0.8682867]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[[0.80991769]\n",
      "  [0.81805015]\n",
      "  [0.825881  ]\n",
      "  [0.83401358]\n",
      "  [0.84184843]\n",
      "  [0.8479591 ]\n",
      "  [0.85324401]\n",
      "  [0.86103314]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010470971465110779\n",
      "Predicci√≥n post entrenamiento : [[0.86734325]]\n",
      "PERDIDAAAA despues: 0.010278772562742233\n",
      "loss en el callback: 0.015657829120755196, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "ejemplar: [[0.81805015]\n",
      " [0.825881  ]\n",
      " [0.83401358]\n",
      " [0.84184843]\n",
      " [0.8479591 ]\n",
      " [0.85324401]\n",
      " [0.86103314]\n",
      " [0.86828673]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7483323528772654\n",
      "Predicci√≥n : [[0.87427163]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[[0.81805015]\n",
      "  [0.825881  ]\n",
      "  [0.83401358]\n",
      "  [0.84184843]\n",
      "  [0.8479591 ]\n",
      "  [0.85324401]\n",
      "  [0.86103314]\n",
      "  [0.86828673]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015860695391893387\n",
      "Predicci√≥n post entrenamiento : [[0.87287426]]\n",
      "PERDIDAAAA despues: 0.015510679222643375\n",
      "loss en el callback: 0.03290607035160065, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "ejemplar: [[0.825881  ]\n",
      " [0.83401358]\n",
      " [0.84184843]\n",
      " [0.8479591 ]\n",
      " [0.85324401]\n",
      " [0.86103314]\n",
      " [0.86828673]\n",
      " [0.87427163]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7182371823643998\n",
      "Predicci√≥n : [[0.87956446]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[[0.825881  ]\n",
      "  [0.83401358]\n",
      "  [0.84184843]\n",
      "  [0.8479591 ]\n",
      "  [0.85324401]\n",
      "  [0.86103314]\n",
      "  [0.86828673]\n",
      "  [0.87427163]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.026026498526334763\n",
      "Predicci√≥n post entrenamiento : [[0.8785024]]\n",
      "PERDIDAAAA despues: 0.025684956461191177\n",
      "loss en el callback: 0.02241622470319271, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "ejemplar: [[0.83401358]\n",
      " [0.84184843]\n",
      " [0.8479591 ]\n",
      " [0.85324401]\n",
      " [0.86103314]\n",
      " [0.86828673]\n",
      " [0.87427163]\n",
      " [0.87956446]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7089416644962148\n",
      "Predicci√≥n : [[0.88496786]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[[0.83401358]\n",
      "  [0.84184843]\n",
      "  [0.8479591 ]\n",
      "  [0.85324401]\n",
      "  [0.86103314]\n",
      "  [0.86828673]\n",
      "  [0.87427163]\n",
      "  [0.87956446]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.030985232442617416\n",
      "Predicci√≥n post entrenamiento : [[0.88502526]]\n",
      "PERDIDAAAA despues: 0.031005442142486572\n",
      "loss en el callback: 8.96445126272738e-05, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "ejemplar: [[0.84184843]\n",
      " [0.8479591 ]\n",
      " [0.85324401]\n",
      " [0.86103314]\n",
      " [0.86828673]\n",
      " [0.87427163]\n",
      " [0.87956446]\n",
      " [0.88496786]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7204457992727099\n",
      "Predicci√≥n : [[0.8911034]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[[0.84184843]\n",
      "  [0.8479591 ]\n",
      "  [0.85324401]\n",
      "  [0.86103314]\n",
      "  [0.86828673]\n",
      "  [0.87427163]\n",
      "  [0.87956446]\n",
      "  [0.88496786]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.029124008491635323\n",
      "Predicci√≥n post entrenamiento : [[0.89062077]]\n",
      "PERDIDAAAA despues: 0.028959516435861588\n",
      "loss en el callback: 0.004995817318558693, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "ejemplar: [[0.8479591 ]\n",
      " [0.85324401]\n",
      " [0.86103314]\n",
      " [0.86828673]\n",
      " [0.87427163]\n",
      " [0.87956446]\n",
      " [0.88496786]\n",
      " [0.89110339]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.770615477342717\n",
      "Predicci√≥n : [[0.8963105]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[[0.8479591 ]\n",
      "  [0.85324401]\n",
      "  [0.86103314]\n",
      "  [0.86828673]\n",
      "  [0.87427163]\n",
      "  [0.87956446]\n",
      "  [0.88496786]\n",
      "  [0.89110339]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01579924486577511\n",
      "Predicci√≥n post entrenamiento : [[0.89606744]]\n",
      "PERDIDAAAA despues: 0.015738200396299362\n",
      "loss en el callback: 0.0015312620671465993, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "ejemplar: [[0.85324401]\n",
      " [0.86103314]\n",
      " [0.86828673]\n",
      " [0.87427163]\n",
      " [0.87956446]\n",
      " [0.88496786]\n",
      " [0.89110339]\n",
      " [0.89631051]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8594506987062355\n",
      "Predicci√≥n : [[0.9017972]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[[0.85324401]\n",
      "  [0.86103314]\n",
      "  [0.86828673]\n",
      "  [0.87427163]\n",
      "  [0.87956446]\n",
      "  [0.88496786]\n",
      "  [0.89110339]\n",
      "  [0.89631051]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017932241316884756\n",
      "Predicci√≥n post entrenamiento : [[0.9027856]]\n",
      "PERDIDAAAA despues: 0.0018779137171804905\n",
      "loss en el callback: 0.02869877591729164, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "ejemplar: [[0.86103314]\n",
      " [0.86828673]\n",
      " [0.87427163]\n",
      " [0.87956446]\n",
      " [0.88496786]\n",
      " [0.89110339]\n",
      " [0.89631051]\n",
      " [0.90179718]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9065410812466371\n",
      "Predicci√≥n : [[0.9087777]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[[0.86103314]\n",
      "  [0.86828673]\n",
      "  [0.87427163]\n",
      "  [0.87956446]\n",
      "  [0.88496786]\n",
      "  [0.89110339]\n",
      "  [0.89631051]\n",
      "  [0.90179718]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.0024004849547055e-06\n",
      "Predicci√≥n post entrenamiento : [[0.90919846]]\n",
      "PERDIDAAAA despues: 7.06152968632523e-06\n",
      "loss en el callback: 0.003729271236807108, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "ejemplar: [[0.86828673]\n",
      " [0.87427163]\n",
      " [0.87956446]\n",
      " [0.88496786]\n",
      " [0.89110339]\n",
      " [0.89631051]\n",
      " [0.90179718]\n",
      " [0.90877771]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9118866249639219\n",
      "Predicci√≥n : [[0.9147174]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[[0.86828673]\n",
      "  [0.87427163]\n",
      "  [0.87956446]\n",
      "  [0.88496786]\n",
      "  [0.89110339]\n",
      "  [0.89631051]\n",
      "  [0.90179718]\n",
      "  [0.90877771]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.013110345927998e-06\n",
      "Predicci√≥n post entrenamiento : [[0.9146115]]\n",
      "PERDIDAAAA despues: 7.425003332173219e-06\n",
      "loss en el callback: 0.00021377769007813185, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "ejemplar: [[0.87427163]\n",
      " [0.87956446]\n",
      " [0.88496786]\n",
      " [0.89110339]\n",
      " [0.89631051]\n",
      " [0.90179718]\n",
      " [0.90877771]\n",
      " [0.91471738]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.904335569053715\n",
      "Predicci√≥n : [[0.91972953]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[[0.87427163]\n",
      "  [0.87956446]\n",
      "  [0.88496786]\n",
      "  [0.89110339]\n",
      "  [0.89631051]\n",
      "  [0.90179718]\n",
      "  [0.90877771]\n",
      "  [0.91471738]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00023697438882663846\n",
      "Predicci√≥n post entrenamiento : [[0.9190804]]\n",
      "PERDIDAAAA despues: 0.00021740965894423425\n",
      "loss en el callback: 0.007811831776052713, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "ejemplar: [[0.87956446]\n",
      " [0.88496786]\n",
      " [0.89110339]\n",
      " [0.89631051]\n",
      " [0.90179718]\n",
      " [0.90877771]\n",
      " [0.91471738]\n",
      " [0.91972953]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8838879135160167\n",
      "Predicci√≥n : [[0.9241169]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[[0.87956446]\n",
      "  [0.88496786]\n",
      "  [0.89110339]\n",
      "  [0.89631051]\n",
      "  [0.90179718]\n",
      "  [0.90877771]\n",
      "  [0.91471738]\n",
      "  [0.91972953]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016183742554858327\n",
      "Predicci√≥n post entrenamiento : [[0.9251634]]\n",
      "PERDIDAAAA despues: 0.001703666988760233\n",
      "loss en el callback: 0.032920125871896744, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "ejemplar: [[0.88496786]\n",
      " [0.89110339]\n",
      " [0.89631051]\n",
      " [0.90179718]\n",
      " [0.90877771]\n",
      " [0.91471738]\n",
      " [0.91972953]\n",
      " [0.92411691]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9032153489332012\n",
      "Predicci√≥n : [[0.93031317]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[[0.88496786]\n",
      "  [0.89110339]\n",
      "  [0.89631051]\n",
      "  [0.90179718]\n",
      "  [0.90877771]\n",
      "  [0.91471738]\n",
      "  [0.91972953]\n",
      "  [0.92411691]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000734291912522167\n",
      "Predicci√≥n post entrenamiento : [[0.9300031]]\n",
      "PERDIDAAAA despues: 0.0007175839855335653\n",
      "loss en el callback: 0.001968336757272482, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "ejemplar: [[0.89110339]\n",
      " [0.89631051]\n",
      " [0.90179718]\n",
      " [0.90877771]\n",
      " [0.91471738]\n",
      " [0.91972953]\n",
      " [0.92411691]\n",
      " [0.93031317]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9623178753052692\n",
      "Predicci√≥n : [[0.93524295]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[[0.89110339]\n",
      "  [0.89631051]\n",
      "  [0.90179718]\n",
      "  [0.90877771]\n",
      "  [0.91471738]\n",
      "  [0.91972953]\n",
      "  [0.92411691]\n",
      "  [0.93031317]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007330519729293883\n",
      "Predicci√≥n post entrenamiento : [[0.9344391]]\n",
      "PERDIDAAAA despues: 0.0007772253593429923\n",
      "loss en el callback: 0.010680800303816795, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "ejemplar: [[0.89631051]\n",
      " [0.90179718]\n",
      " [0.90877771]\n",
      " [0.91471738]\n",
      " [0.91972953]\n",
      " [0.92411691]\n",
      " [0.93031317]\n",
      " [0.93524295]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.982058820003038\n",
      "Predicci√≥n : [[0.93955094]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[[0.89631051]\n",
      "  [0.90179718]\n",
      "  [0.90877771]\n",
      "  [0.91471738]\n",
      "  [0.91972953]\n",
      "  [0.92411691]\n",
      "  [0.93031317]\n",
      "  [0.93524295]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018069203943014145\n",
      "Predicci√≥n post entrenamiento : [[0.9387594]]\n",
      "PERDIDAAAA despues: 0.0018748411675915122\n",
      "loss en el callback: 0.010210034437477589, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "ejemplar: [[0.90179718]\n",
      " [0.90877771]\n",
      " [0.91471738]\n",
      " [0.91972953]\n",
      " [0.92411691]\n",
      " [0.93031317]\n",
      " [0.93524295]\n",
      " [0.93955094]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9624381830265082\n",
      "Predicci√≥n : [[0.94397855]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[[0.90179718]\n",
      "  [0.90877771]\n",
      "  [0.91471738]\n",
      "  [0.91972953]\n",
      "  [0.92411691]\n",
      "  [0.93031317]\n",
      "  [0.93524295]\n",
      "  [0.93955094]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00034075751318596303\n",
      "Predicci√≥n post entrenamiento : [[0.9422499]]\n",
      "PERDIDAAAA despues: 0.0004075663164258003\n",
      "loss en el callback: 0.04358639568090439, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "ejemplar: [[0.90877771]\n",
      " [0.91471738]\n",
      " [0.91972953]\n",
      " [0.92411691]\n",
      " [0.93031317]\n",
      " [0.93524295]\n",
      " [0.93955094]\n",
      " [0.94397855]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9302512105217627\n",
      "Predicci√≥n : [[0.947474]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[[0.90877771]\n",
      "  [0.91471738]\n",
      "  [0.91972953]\n",
      "  [0.92411691]\n",
      "  [0.93031317]\n",
      "  [0.93524295]\n",
      "  [0.93955094]\n",
      "  [0.94397855]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00029662559973075986\n",
      "Predicci√≥n post entrenamiento : [[0.94743586]]\n",
      "PERDIDAAAA despues: 0.0002953130460809916\n",
      "loss en el callback: 2.9601345886476338e-05, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "ejemplar: [[0.91471738]\n",
      " [0.91972953]\n",
      " [0.92411691]\n",
      " [0.93031317]\n",
      " [0.93524295]\n",
      " [0.93955094]\n",
      " [0.94397855]\n",
      " [0.947474  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.885497902488802\n",
      "Predicci√≥n : [[0.9521793]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[[0.91471738]\n",
      "  [0.91972953]\n",
      "  [0.92411691]\n",
      "  [0.93031317]\n",
      "  [0.93524295]\n",
      "  [0.93955094]\n",
      "  [0.94397855]\n",
      "  [0.947474  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004446407314389944\n",
      "Predicci√≥n post entrenamiento : [[0.951483]]\n",
      "PERDIDAAAA despues: 0.004354031290858984\n",
      "loss en el callback: 0.009547037072479725, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "ejemplar: [[0.91972953]\n",
      " [0.92411691]\n",
      " [0.93031317]\n",
      " [0.93524295]\n",
      " [0.93955094]\n",
      " [0.94397855]\n",
      " [0.947474  ]\n",
      " [0.95217931]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597025687419927\n",
      "Predicci√≥n : [[0.95594764]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[[0.91972953]\n",
      "  [0.92411691]\n",
      "  [0.93031317]\n",
      "  [0.93524295]\n",
      "  [0.93955094]\n",
      "  [0.94397855]\n",
      "  [0.947474  ]\n",
      "  [0.95217931]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009263109415769577\n",
      "Predicci√≥n post entrenamiento : [[0.9549549]]\n",
      "PERDIDAAAA despues: 0.009073006920516491\n",
      "loss en el callback: 0.01995432749390602, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "ejemplar: [[0.92411691]\n",
      " [0.93031317]\n",
      " [0.93524295]\n",
      " [0.93955094]\n",
      " [0.94397855]\n",
      " [0.947474  ]\n",
      " [0.95217931]\n",
      " [0.95594764]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8528652092813349\n",
      "Predicci√≥n : [[0.95934534]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[[0.92411691]\n",
      "  [0.93031317]\n",
      "  [0.93524295]\n",
      "  [0.93955094]\n",
      "  [0.94397855]\n",
      "  [0.947474  ]\n",
      "  [0.95217931]\n",
      "  [0.95594764]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011338016018271446\n",
      "Predicci√≥n post entrenamiento : [[0.95986134]]\n",
      "PERDIDAAAA despues: 0.011448169127106667\n",
      "loss en el callback: 0.008572296239435673, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "ejemplar: [[0.93031317]\n",
      " [0.93524295]\n",
      " [0.93955094]\n",
      " [0.94397855]\n",
      " [0.947474  ]\n",
      " [0.95217931]\n",
      " [0.95594764]\n",
      " [0.95934534]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8585854533368672\n",
      "Predicci√≥n : [[0.96431917]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[[0.93031317]\n",
      "  [0.93524295]\n",
      "  [0.93955094]\n",
      "  [0.94397855]\n",
      "  [0.947474  ]\n",
      "  [0.95217931]\n",
      "  [0.95594764]\n",
      "  [0.95934534]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011179613880813122\n",
      "Predicci√≥n post entrenamiento : [[0.9647622]]\n",
      "PERDIDAAAA despues: 0.011273498646914959\n",
      "loss en el callback: 0.005759383086115122, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "ejemplar: [[0.93524295]\n",
      " [0.93955094]\n",
      " [0.94397855]\n",
      " [0.947474  ]\n",
      " [0.95217931]\n",
      " [0.95594764]\n",
      " [0.95934534]\n",
      " [0.96431917]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8768633009085897\n",
      "Predicci√≥n : [[0.9687266]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[[0.93524295]\n",
      "  [0.93955094]\n",
      "  [0.94397855]\n",
      "  [0.947474  ]\n",
      "  [0.95217931]\n",
      "  [0.95594764]\n",
      "  [0.95934534]\n",
      "  [0.96431917]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00843886099755764\n",
      "Predicci√≥n post entrenamiento : [[0.9683389]]\n",
      "PERDIDAAAA despues: 0.008367786183953285\n",
      "loss en el callback: 0.00373290479183197, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "ejemplar: [[0.93955094]\n",
      " [0.94397855]\n",
      " [0.947474  ]\n",
      " [0.95217931]\n",
      " [0.95594764]\n",
      " [0.95934534]\n",
      " [0.96431917]\n",
      " [0.96872658]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8806463966074481\n",
      "Predicci√≥n : [[0.972098]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[[0.93955094]\n",
      "  [0.94397855]\n",
      "  [0.947474  ]\n",
      "  [0.95217931]\n",
      "  [0.95594764]\n",
      "  [0.95934534]\n",
      "  [0.96431917]\n",
      "  [0.96872658]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00836339220404625\n",
      "Predicci√≥n post entrenamiento : [[0.971334]]\n",
      "PERDIDAAAA despues: 0.008224235847592354\n",
      "loss en el callback: 0.0127168083563447, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "ejemplar: [[0.94397855]\n",
      " [0.947474  ]\n",
      " [0.95217931]\n",
      " [0.95594764]\n",
      " [0.95934534]\n",
      " [0.96431917]\n",
      " [0.96872658]\n",
      " [0.97209799]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8699347404334429\n",
      "Predicci√≥n : [[0.9750366]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[[0.94397855]\n",
      "  [0.947474  ]\n",
      "  [0.95217931]\n",
      "  [0.95594764]\n",
      "  [0.95934534]\n",
      "  [0.96431917]\n",
      "  [0.96872658]\n",
      "  [0.97209799]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011046405881643295\n",
      "Predicci√≥n post entrenamiento : [[0.9741454]]\n",
      "PERDIDAAAA despues: 0.010859864763915539\n",
      "loss en el callback: 0.01662910170853138, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "ejemplar: [[0.947474  ]\n",
      " [0.95217931]\n",
      " [0.95594764]\n",
      " [0.95934534]\n",
      " [0.96431917]\n",
      " [0.96872658]\n",
      " [0.97209799]\n",
      " [0.97503662]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8465135437340043\n",
      "Predicci√≥n : [[0.9777396]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[[0.947474  ]\n",
      "  [0.95217931]\n",
      "  [0.95594764]\n",
      "  [0.95934534]\n",
      "  [0.96431917]\n",
      "  [0.96872658]\n",
      "  [0.97209799]\n",
      "  [0.97503662]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017220264300704002\n",
      "Predicci√≥n post entrenamiento : [[0.97673243]]\n",
      "PERDIDAAAA despues: 0.016956953331828117\n",
      "loss en el callback: 0.0222821906208992, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "ejemplar: [[0.95217931]\n",
      " [0.95594764]\n",
      " [0.95934534]\n",
      " [0.96431917]\n",
      " [0.96872658]\n",
      " [0.97209799]\n",
      " [0.97503662]\n",
      " [0.97773957]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8103828065091326\n",
      "Predicci√≥n : [[0.9804629]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[[0.95217931]\n",
      "  [0.95594764]\n",
      "  [0.95934534]\n",
      "  [0.96431917]\n",
      "  [0.96872658]\n",
      "  [0.97209799]\n",
      "  [0.97503662]\n",
      "  [0.97773957]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02892724983394146\n",
      "Predicci√≥n post entrenamiento : [[0.9793156]]\n",
      "PERDIDAAAA despues: 0.028538288548588753\n",
      "loss en el callback: 0.03113296627998352, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "ejemplar: [[0.95594764]\n",
      " [0.95934534]\n",
      " [0.96431917]\n",
      " [0.96872658]\n",
      " [0.97209799]\n",
      " [0.97503662]\n",
      " [0.97773957]\n",
      " [0.98046291]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8026111217617493\n",
      "Predicci√≥n : [[0.98281324]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[[0.95594764]\n",
      "  [0.95934534]\n",
      "  [0.96431917]\n",
      "  [0.96872658]\n",
      "  [0.97209799]\n",
      "  [0.97503662]\n",
      "  [0.97773957]\n",
      "  [0.98046291]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03247280791401863\n",
      "Predicci√≥n post entrenamiento : [[0.98023623]]\n",
      "PERDIDAAAA despues: 0.031550683081150055\n",
      "loss en el callback: 0.11485286802053452, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "ejemplar: [[0.95934534]\n",
      " [0.96431917]\n",
      " [0.96872658]\n",
      " [0.97209799]\n",
      " [0.97503662]\n",
      " [0.97773957]\n",
      " [0.98046291]\n",
      " [0.98281324]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.823198489491854\n",
      "Predicci√≥n : [[0.98370785]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[[0.95934534]\n",
      "  [0.96431917]\n",
      "  [0.96872658]\n",
      "  [0.97209799]\n",
      "  [0.97503662]\n",
      "  [0.97773957]\n",
      "  [0.98046291]\n",
      "  [0.98281324]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02576325088739395\n",
      "Predicci√≥n post entrenamiento : [[0.9836788]]\n",
      "PERDIDAAAA despues: 0.025753933936357498\n",
      "loss en el callback: 2.708742795221042e-05, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "ejemplar: [[0.96431917]\n",
      " [0.96872658]\n",
      " [0.97209799]\n",
      " [0.97503662]\n",
      " [0.97773957]\n",
      " [0.98046291]\n",
      " [0.98281324]\n",
      " [0.98370785]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8397204264676091\n",
      "Predicci√≥n : [[0.9871785]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[[0.96431917]\n",
      "  [0.96872658]\n",
      "  [0.97209799]\n",
      "  [0.97503662]\n",
      "  [0.97773957]\n",
      "  [0.98046291]\n",
      "  [0.98281324]\n",
      "  [0.98370785]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.021743884310126305\n",
      "Predicci√≥n post entrenamiento : [[0.98669773]]\n",
      "PERDIDAAAA despues: 0.0216023288667202\n",
      "loss en el callback: 0.006299250293523073, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "ejemplar: [[0.96872658]\n",
      " [0.97209799]\n",
      " [0.97503662]\n",
      " [0.97773957]\n",
      " [0.98046291]\n",
      " [0.98281324]\n",
      " [0.98370785]\n",
      " [0.9871785 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.852176932689015\n",
      "Predicci√≥n : [[0.9897035]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[[0.96872658]\n",
      "  [0.97209799]\n",
      "  [0.97503662]\n",
      "  [0.97773957]\n",
      "  [0.98046291]\n",
      "  [0.98281324]\n",
      "  [0.98370785]\n",
      "  [0.9871785 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01891355775296688\n",
      "Predicci√≥n post entrenamiento : [[0.9887574]]\n",
      "PERDIDAAAA despues: 0.018654223531484604\n",
      "loss en el callback: 0.02078036218881607, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "ejemplar: [[0.97209799]\n",
      " [0.97503662]\n",
      " [0.97773957]\n",
      " [0.98046291]\n",
      " [0.98281324]\n",
      " [0.98370785]\n",
      " [0.9871785 ]\n",
      " [0.98970348]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8615626813481295\n",
      "Predicci√≥n : [[0.9913214]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[[0.97209799]\n",
      "  [0.97503662]\n",
      "  [0.97773957]\n",
      "  [0.98046291]\n",
      "  [0.98281324]\n",
      "  [0.98370785]\n",
      "  [0.9871785 ]\n",
      "  [0.98970348]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01683732494711876\n",
      "Predicci√≥n post entrenamiento : [[0.9917617]]\n",
      "PERDIDAAAA despues: 0.016951782628893852\n",
      "loss en el callback: 0.0065180291421711445, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "ejemplar: [[0.97503662]\n",
      " [0.97773957]\n",
      " [0.98046291]\n",
      " [0.98281324]\n",
      " [0.98370785]\n",
      " [0.9871785 ]\n",
      " [0.98970348]\n",
      " [0.99132138]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8678776724449532\n",
      "Predicci√≥n : [[0.9941004]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[[0.97503662]\n",
      "  [0.97773957]\n",
      "  [0.98046291]\n",
      "  [0.98281324]\n",
      "  [0.98370785]\n",
      "  [0.9871785 ]\n",
      "  [0.98970348]\n",
      "  [0.99132138]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015932178124785423\n",
      "Predicci√≥n post entrenamiento : [[0.99305093]]\n",
      "PERDIDAAAA despues: 0.015668347477912903\n",
      "loss en el callback: 0.025538286194205284, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "ejemplar: [[0.97773957]\n",
      " [0.98046291]\n",
      " [0.98281324]\n",
      " [0.98370785]\n",
      " [0.9871785 ]\n",
      " [0.98970348]\n",
      " [0.99132138]\n",
      " [0.99410039]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8701963127047843\n",
      "Predicci√≥n : [[0.99524474]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[[0.97773957]\n",
      "  [0.98046291]\n",
      "  [0.98281324]\n",
      "  [0.98370785]\n",
      "  [0.9871785 ]\n",
      "  [0.98970348]\n",
      "  [0.99132138]\n",
      "  [0.99410039]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015637101605534554\n",
      "Predicci√≥n post entrenamiento : [[0.9947279]]\n",
      "PERDIDAAAA despues: 0.01550811156630516\n",
      "loss en el callback: 0.007705893367528915, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "ejemplar: [[0.98046291]\n",
      " [0.98281324]\n",
      " [0.98370785]\n",
      " [0.9871785 ]\n",
      " [0.98970348]\n",
      " [0.99132138]\n",
      " [0.99410039]\n",
      " [0.99524474]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8685186021276227\n",
      "Predicci√≥n : [[0.9968142]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[[0.98046291]\n",
      "  [0.98281324]\n",
      "  [0.98370785]\n",
      "  [0.9871785 ]\n",
      "  [0.98970348]\n",
      "  [0.99132138]\n",
      "  [0.99410039]\n",
      "  [0.99524474]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016459761187434196\n",
      "Predicci√≥n post entrenamiento : [[0.99616754]]\n",
      "PERDIDAAAA despues: 0.01629425399005413\n",
      "loss en el callback: 0.012079712934792042, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "ejemplar: [[0.98281324]\n",
      " [0.98370785]\n",
      " [0.9871785 ]\n",
      " [0.98970348]\n",
      " [0.99132138]\n",
      " [0.99410039]\n",
      " [0.99524474]\n",
      " [0.99681419]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8529880395838255\n",
      "Predicci√≥n : [[0.99811137]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[[0.98281324]\n",
      "  [0.98370785]\n",
      "  [0.9871785 ]\n",
      "  [0.98970348]\n",
      "  [0.99132138]\n",
      "  [0.99410039]\n",
      "  [0.99524474]\n",
      "  [0.99681419]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.021060772240161896\n",
      "Predicci√≥n post entrenamiento : [[0.99847096]]\n",
      "PERDIDAAAA despues: 0.02116527408361435\n",
      "loss en el callback: 0.004789354745298624, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "ejemplar: [[0.98370785]\n",
      " [0.9871785 ]\n",
      " [0.98970348]\n",
      " [0.99132138]\n",
      " [0.99410039]\n",
      " [0.99524474]\n",
      " [0.99681419]\n",
      " [0.99811137]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8236046250733932\n",
      "Predicci√≥n : [[1.0003489]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[[0.98370785]\n",
      "  [0.9871785 ]\n",
      "  [0.98970348]\n",
      "  [0.99132138]\n",
      "  [0.99410039]\n",
      "  [0.99524474]\n",
      "  [0.99681419]\n",
      "  [0.99811137]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03123854100704193\n",
      "Predicci√≥n post entrenamiento : [[0.99947095]]\n",
      "PERDIDAAAA despues: 0.03092895820736885\n",
      "loss en el callback: 0.021502958610653877, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "ejemplar: [[0.9871785 ]\n",
      " [0.98970348]\n",
      " [0.99132138]\n",
      " [0.99410039]\n",
      " [0.99524474]\n",
      " [0.99681419]\n",
      " [0.99811137]\n",
      " [1.00034893]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8032508871761479\n",
      "Predicci√≥n : [[1.0016891]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[[0.9871785 ]\n",
      "  [0.98970348]\n",
      "  [0.99132138]\n",
      "  [0.99410039]\n",
      "  [0.99524474]\n",
      "  [0.99681419]\n",
      "  [0.99811137]\n",
      "  [1.00034893]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03937770798802376\n",
      "Predicci√≥n post entrenamiento : [[1.0009134]]\n",
      "PERDIDAAAA despues: 0.039070453494787216\n",
      "loss en el callback: 0.019068505614995956, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "ejemplar: [[0.98970348]\n",
      " [0.99132138]\n",
      " [0.99410039]\n",
      " [0.99524474]\n",
      " [0.99681419]\n",
      " [0.99811137]\n",
      " [1.00034893]\n",
      " [1.00168908]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7919268258920897\n",
      "Predicci√≥n : [[1.0027275]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[[0.98970348]\n",
      "  [0.99132138]\n",
      "  [0.99410039]\n",
      "  [0.99524474]\n",
      "  [0.99681419]\n",
      "  [0.99811137]\n",
      "  [1.00034893]\n",
      "  [1.00168908]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04443693906068802\n",
      "Predicci√≥n post entrenamiento : [[1.0027009]]\n",
      "PERDIDAAAA despues: 0.04442572966217995\n",
      "loss en el callback: 2.706943814700935e-05, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "ejemplar: [[0.99132138]\n",
      " [0.99410039]\n",
      " [0.99524474]\n",
      " [0.99681419]\n",
      " [0.99811137]\n",
      " [1.00034893]\n",
      " [1.00168908]\n",
      " [1.00272751]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7865023059771536\n",
      "Predicci√≥n : [[1.0043108]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[[0.99132138]\n",
      "  [0.99410039]\n",
      "  [0.99524474]\n",
      "  [0.99681419]\n",
      "  [0.99811137]\n",
      "  [1.00034893]\n",
      "  [1.00168908]\n",
      "  [1.00272751]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04744056239724159\n",
      "Predicci√≥n post entrenamiento : [[1.0028102]]\n",
      "PERDIDAAAA despues: 0.046789124608039856\n",
      "loss en el callback: 0.05507587641477585, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "ejemplar: [[0.99410039]\n",
      " [0.99524474]\n",
      " [0.99681419]\n",
      " [0.99811137]\n",
      " [1.00034893]\n",
      " [1.00168908]\n",
      " [1.00272751]\n",
      " [1.00431085]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7869773274313391\n",
      "Predicci√≥n : [[1.0044389]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[[0.99410039]\n",
      "  [0.99524474]\n",
      "  [0.99681419]\n",
      "  [0.99811137]\n",
      "  [1.00034893]\n",
      "  [1.00168908]\n",
      "  [1.00272751]\n",
      "  [1.00431085]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.047289516776800156\n",
      "Predicci√≥n post entrenamiento : [[1.0038086]]\n",
      "PERDIDAAAA despues: 0.04701579734683037\n",
      "loss en el callback: 0.013179472647607327, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "ejemplar: [[0.99524474]\n",
      " [0.99681419]\n",
      " [0.99811137]\n",
      " [1.00034893]\n",
      " [1.00168908]\n",
      " [1.00272751]\n",
      " [1.00431085]\n",
      " [1.00443888]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7874362431744556\n",
      "Predicci√≥n : [[1.0050944]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[[0.99524474]\n",
      "  [0.99681419]\n",
      "  [0.99811137]\n",
      "  [1.00034893]\n",
      "  [1.00168908]\n",
      "  [1.00272751]\n",
      "  [1.00431085]\n",
      "  [1.00443888]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04737507551908493\n",
      "Predicci√≥n post entrenamiento : [[1.0042112]]\n",
      "PERDIDAAAA despues: 0.04699137434363365\n",
      "loss en el callback: 0.024412386119365692, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "ejemplar: [[0.99681419]\n",
      " [0.99811137]\n",
      " [1.00034893]\n",
      " [1.00168908]\n",
      " [1.00272751]\n",
      " [1.00431085]\n",
      " [1.00443888]\n",
      " [1.00509441]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7878790532065031\n",
      "Predicci√≥n : [[1.0055705]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[[0.99681419]\n",
      "  [0.99811137]\n",
      "  [1.00034893]\n",
      "  [1.00168908]\n",
      "  [1.00272751]\n",
      "  [1.00431085]\n",
      "  [1.00443888]\n",
      "  [1.00509441]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04738958179950714\n",
      "Predicci√≥n post entrenamiento : [[1.0050889]]\n",
      "PERDIDAAAA despues: 0.04718013107776642\n",
      "loss en el callback: 0.008411047048866749, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "ejemplar: [[0.99811137]\n",
      " [1.00034893]\n",
      " [1.00168908]\n",
      " [1.00272751]\n",
      " [1.00431085]\n",
      " [1.00443888]\n",
      " [1.00509441]\n",
      " [1.00557053]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7954532004373992\n",
      "Predicci√≥n : [[1.0063819]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[[0.99811137]\n",
      "  [1.00034893]\n",
      "  [1.00168908]\n",
      "  [1.00272751]\n",
      "  [1.00431085]\n",
      "  [1.00443888]\n",
      "  [1.00509441]\n",
      "  [1.00557053]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04449090734124184\n",
      "Predicci√≥n post entrenamiento : [[1.0051308]]\n",
      "PERDIDAAAA despues: 0.0439646877348423\n",
      "loss en el callback: 0.04788218066096306, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "ejemplar: [[1.00034893]\n",
      " [1.00168908]\n",
      " [1.00272751]\n",
      " [1.00431085]\n",
      " [1.00443888]\n",
      " [1.00509441]\n",
      " [1.00557053]\n",
      " [1.00638187]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8101586848671446\n",
      "Predicci√≥n : [[1.0063978]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[[1.00034893]\n",
      "  [1.00168908]\n",
      "  [1.00272751]\n",
      "  [1.00431085]\n",
      "  [1.00443888]\n",
      "  [1.00509441]\n",
      "  [1.00557053]\n",
      "  [1.00638187]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03850981220602989\n",
      "Predicci√≥n post entrenamiento : [[1.0055611]]\n",
      "PERDIDAAAA despues: 0.03818211331963539\n",
      "loss en el callback: 0.02276541478931904, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "ejemplar: [[1.00168908]\n",
      " [1.00272751]\n",
      " [1.00431085]\n",
      " [1.00443888]\n",
      " [1.00509441]\n",
      " [1.00557053]\n",
      " [1.00638187]\n",
      " [1.00639784]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7668473230866574\n",
      "Predicci√≥n : [[1.0064868]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[[1.00168908]\n",
      "  [1.00272751]\n",
      "  [1.00431085]\n",
      "  [1.00443888]\n",
      "  [1.00509441]\n",
      "  [1.00557053]\n",
      "  [1.00638187]\n",
      "  [1.00639784]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.057427071034908295\n",
      "Predicci√≥n post entrenamiento : [[1.0042753]]\n",
      "PERDIDAAAA despues: 0.056372061371803284\n",
      "loss en el callback: 0.12097019702196121, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "ejemplar: [[1.00272751]\n",
      " [1.00431085]\n",
      " [1.00443888]\n",
      " [1.00509441]\n",
      " [1.00557053]\n",
      " [1.00638187]\n",
      " [1.00639784]\n",
      " [1.00648677]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6655191150959373\n",
      "Predicci√≥n : [[1.0050473]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[[1.00272751]\n",
      "  [1.00431085]\n",
      "  [1.00443888]\n",
      "  [1.00509441]\n",
      "  [1.00557053]\n",
      "  [1.00638187]\n",
      "  [1.00639784]\n",
      "  [1.00648677]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11527939885854721\n",
      "Predicci√≥n post entrenamiento : [[1.0028306]]\n",
      "PERDIDAAAA despues: 0.11377905309200287\n",
      "loss en el callback: 0.1398945152759552, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "ejemplar: [[1.00431085]\n",
      " [1.00443888]\n",
      " [1.00509441]\n",
      " [1.00557053]\n",
      " [1.00638187]\n",
      " [1.00639784]\n",
      " [1.00648677]\n",
      " [1.00504732]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6360738003224796\n",
      "Predicci√≥n : [[1.0034827]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[[1.00431085]\n",
      "  [1.00443888]\n",
      "  [1.00509441]\n",
      "  [1.00557053]\n",
      "  [1.00638187]\n",
      "  [1.00639784]\n",
      "  [1.00648677]\n",
      "  [1.00504732]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13498927652835846\n",
      "Predicci√≥n post entrenamiento : [[1.0007079]]\n",
      "PERDIDAAAA despues: 0.13295798003673553\n",
      "loss en el callback: 0.19538742303848267, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "ejemplar: [[1.00443888]\n",
      " [1.00509441]\n",
      " [1.00557053]\n",
      " [1.00638187]\n",
      " [1.00639784]\n",
      " [1.00648677]\n",
      " [1.00504732]\n",
      " [1.0034827 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6785113787662842\n",
      "Predicci√≥n : [[1.00102]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[[1.00443888]\n",
      "  [1.00509441]\n",
      "  [1.00557053]\n",
      "  [1.00638187]\n",
      "  [1.00639784]\n",
      "  [1.00648677]\n",
      "  [1.00504732]\n",
      "  [1.0034827 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10401178151369095\n",
      "Predicci√≥n post entrenamiento : [[0.9989721]]\n",
      "PERDIDAAAA despues: 0.10269508510828018\n",
      "loss en el callback: 0.12486518174409866, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "ejemplar: [[1.00509441]\n",
      " [1.00557053]\n",
      " [1.00638187]\n",
      " [1.00639784]\n",
      " [1.00648677]\n",
      " [1.00504732]\n",
      " [1.0034827 ]\n",
      " [1.00101995]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6965967339840231\n",
      "Predicci√≥n : [[0.99927247]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[[1.00509441]\n",
      "  [1.00557053]\n",
      "  [1.00638187]\n",
      "  [1.00639784]\n",
      "  [1.00648677]\n",
      "  [1.00504732]\n",
      "  [1.0034827 ]\n",
      "  [1.00101995]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09161259233951569\n",
      "Predicci√≥n post entrenamiento : [[0.99651486]]\n",
      "PERDIDAAAA despues: 0.08995087444782257\n",
      "loss en el callback: 0.19285595417022705, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "ejemplar: [[1.00557053]\n",
      " [1.00638187]\n",
      " [1.00639784]\n",
      " [1.00648677]\n",
      " [1.00504732]\n",
      " [1.0034827 ]\n",
      " [1.00101995]\n",
      " [0.99927247]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6903298659756966\n",
      "Predicci√≥n : [[0.9965812]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[[1.00557053]\n",
      "  [1.00638187]\n",
      "  [1.00639784]\n",
      "  [1.00648677]\n",
      "  [1.00504732]\n",
      "  [1.0034827 ]\n",
      "  [1.00101995]\n",
      "  [0.99927247]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09378989040851593\n",
      "Predicci√≥n post entrenamiento : [[0.99513465]]\n",
      "PERDIDAAAA despues: 0.09290596842765808\n",
      "loss en el callback: 0.07248833030462265, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "ejemplar: [[1.00638187]\n",
      " [1.00639784]\n",
      " [1.00648677]\n",
      " [1.00504732]\n",
      " [1.0034827 ]\n",
      " [1.00101995]\n",
      " [0.99927247]\n",
      " [0.9965812 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6970473058045382\n",
      "Predicci√≥n : [[0.9949105]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[[1.00638187]\n",
      "  [1.00639784]\n",
      "  [1.00648677]\n",
      "  [1.00504732]\n",
      "  [1.0034827 ]\n",
      "  [1.00101995]\n",
      "  [0.99927247]\n",
      "  [0.9965812 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08872247487306595\n",
      "Predicci√≥n post entrenamiento : [[0.99420035]]\n",
      "PERDIDAAAA despues: 0.0882999375462532\n",
      "loss en el callback: 0.02361535280942917, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "ejemplar: [[1.00639784]\n",
      " [1.00648677]\n",
      " [1.00504732]\n",
      " [1.0034827 ]\n",
      " [1.00101995]\n",
      " [0.99927247]\n",
      " [0.9965812 ]\n",
      " [0.99491048]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7167490534705484\n",
      "Predicci√≥n : [[0.99347335]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[[1.00639784]\n",
      "  [1.00648677]\n",
      "  [1.00504732]\n",
      "  [1.0034827 ]\n",
      "  [1.00101995]\n",
      "  [0.99927247]\n",
      "  [0.9965812 ]\n",
      "  [0.99491048]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07657632976770401\n",
      "Predicci√≥n post entrenamiento : [[0.99234813]]\n",
      "PERDIDAAAA despues: 0.07595483958721161\n",
      "loss en el callback: 0.047124914824962616, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "ejemplar: [[1.00648677]\n",
      " [1.00504732]\n",
      " [1.0034827 ]\n",
      " [1.00101995]\n",
      " [0.99927247]\n",
      " [0.9965812 ]\n",
      " [0.99491048]\n",
      " [0.99347335]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7490507063998944\n",
      "Predicci√≥n : [[0.99122703]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[[1.00648677]\n",
      "  [1.00504732]\n",
      "  [1.0034827 ]\n",
      "  [1.00101995]\n",
      "  [0.99927247]\n",
      "  [0.9965812 ]\n",
      "  [0.99491048]\n",
      "  [0.99347335]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05864938721060753\n",
      "Predicci√≥n post entrenamiento : [[0.99101377]]\n",
      "PERDIDAAAA despues: 0.05854613706469536\n",
      "loss en el callback: 0.002216530265286565, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "ejemplar: [[1.00504732]\n",
      " [1.0034827 ]\n",
      " [1.00101995]\n",
      " [0.99927247]\n",
      " [0.9965812 ]\n",
      " [0.99491048]\n",
      " [0.99347335]\n",
      " [0.99122703]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7939522645925762\n",
      "Predicci√≥n : [[0.9893862]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[[1.00504732]\n",
      "  [1.0034827 ]\n",
      "  [1.00101995]\n",
      "  [0.99927247]\n",
      "  [0.9965812 ]\n",
      "  [0.99491048]\n",
      "  [0.99347335]\n",
      "  [0.99122703]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03819441422820091\n",
      "Predicci√≥n post entrenamiento : [[0.987822]]\n",
      "PERDIDAAAA despues: 0.037585463374853134\n",
      "loss en el callback: 0.07503027468919754, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "ejemplar: [[1.0034827 ]\n",
      " [1.00101995]\n",
      " [0.99927247]\n",
      " [0.9965812 ]\n",
      " [0.99491048]\n",
      " [0.99347335]\n",
      " [0.99122703]\n",
      " [0.9893862 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8547447263586395\n",
      "Predicci√≥n : [[0.9860552]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[[1.0034827 ]\n",
      "  [1.00101995]\n",
      "  [0.99927247]\n",
      "  [0.9965812 ]\n",
      "  [0.99491048]\n",
      "  [0.99347335]\n",
      "  [0.99122703]\n",
      "  [0.9893862 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017242437228560448\n",
      "Predicci√≥n post entrenamiento : [[0.9854349]]\n",
      "PERDIDAAAA despues: 0.017079917713999748\n",
      "loss en el callback: 0.014521736651659012, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "ejemplar: [[1.00101995]\n",
      " [0.99927247]\n",
      " [0.9965812 ]\n",
      " [0.99491048]\n",
      " [0.99347335]\n",
      " [0.99122703]\n",
      " [0.9893862 ]\n",
      " [0.9860552 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9314280916980849\n",
      "Predicci√≥n : [[0.98353773]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[[1.00101995]\n",
      "  [0.99927247]\n",
      "  [0.9965812 ]\n",
      "  [0.99491048]\n",
      "  [0.99347335]\n",
      "  [0.99122703]\n",
      "  [0.9893862 ]\n",
      "  [0.9860552 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0027154164854437113\n",
      "Predicci√≥n post entrenamiento : [[0.9829831]]\n",
      "PERDIDAAAA despues: 0.0026579219847917557\n",
      "loss en el callback: 0.011143959127366543, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "ejemplar: [[0.99927247]\n",
      " [0.9965812 ]\n",
      " [0.99491048]\n",
      " [0.99347335]\n",
      " [0.99122703]\n",
      " [0.9893862 ]\n",
      " [0.9860552 ]\n",
      " [0.98353773]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9627243989762315\n",
      "Predicci√≥n : [[0.9811945]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[[0.99927247]\n",
      "  [0.9965812 ]\n",
      "  [0.99491048]\n",
      "  [0.99347335]\n",
      "  [0.99122703]\n",
      "  [0.9893862 ]\n",
      "  [0.9860552 ]\n",
      "  [0.98353773]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003411449142731726\n",
      "Predicci√≥n post entrenamiento : [[0.981561]]\n",
      "PERDIDAAAA despues: 0.0003548181557562202\n",
      "loss en el callback: 0.0053742798045277596, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "ejemplar: [[0.9965812 ]\n",
      " [0.99491048]\n",
      " [0.99347335]\n",
      " [0.99122703]\n",
      " [0.9893862 ]\n",
      " [0.9860552 ]\n",
      " [0.98353773]\n",
      " [0.9811945 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9486336481930799\n",
      "Predicci√≥n : [[0.9796724]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[[0.9965812 ]\n",
      "  [0.99491048]\n",
      "  [0.99347335]\n",
      "  [0.99122703]\n",
      "  [0.9893862 ]\n",
      "  [0.9860552 ]\n",
      "  [0.98353773]\n",
      "  [0.9811945 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009634009911678731\n",
      "Predicci√≥n post entrenamiento : [[0.9796026]]\n",
      "PERDIDAAAA despues: 0.0009590730187483132\n",
      "loss en el callback: 0.00019137295021209866, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "ejemplar: [[0.99491048]\n",
      " [0.99347335]\n",
      " [0.99122703]\n",
      " [0.9893862 ]\n",
      " [0.9860552 ]\n",
      " [0.98353773]\n",
      " [0.9811945 ]\n",
      " [0.97967237]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9307145892932484\n",
      "Predicci√≥n : [[0.97786736]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[[0.99491048]\n",
      "  [0.99347335]\n",
      "  [0.99122703]\n",
      "  [0.9893862 ]\n",
      "  [0.9860552 ]\n",
      "  [0.98353773]\n",
      "  [0.9811945 ]\n",
      "  [0.97967237]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002223382471129298\n",
      "Predicci√≥n post entrenamiento : [[0.9772599]]\n",
      "PERDIDAAAA despues: 0.0021664618980139494\n",
      "loss en el callback: 0.012134094722568989, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "ejemplar: [[0.99347335]\n",
      " [0.99122703]\n",
      " [0.9893862 ]\n",
      " [0.9860552 ]\n",
      " [0.98353773]\n",
      " [0.9811945 ]\n",
      " [0.97967237]\n",
      " [0.97786736]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.908967222276737\n",
      "Predicci√≥n : [[0.97538984]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[[0.99347335]\n",
      "  [0.99122703]\n",
      "  [0.9893862 ]\n",
      "  [0.9860552 ]\n",
      "  [0.98353773]\n",
      "  [0.9811945 ]\n",
      "  [0.97967237]\n",
      "  [0.97786736]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004411967471241951\n",
      "Predicci√≥n post entrenamiento : [[0.97481585]]\n",
      "PERDIDAAAA despues: 0.004336044657975435\n",
      "loss en el callback: 0.012675518169999123, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "ejemplar: [[0.99122703]\n",
      " [0.9893862 ]\n",
      " [0.9860552 ]\n",
      " [0.98353773]\n",
      " [0.9811945 ]\n",
      " [0.97967237]\n",
      " [0.97786736]\n",
      " [0.97538984]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8816379650841193\n",
      "Predicci√≥n : [[0.9727174]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[[0.99122703]\n",
      "  [0.9893862 ]\n",
      "  [0.9860552 ]\n",
      "  [0.98353773]\n",
      "  [0.9811945 ]\n",
      "  [0.97967237]\n",
      "  [0.97786736]\n",
      "  [0.97538984]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008295459672808647\n",
      "Predicci√≥n post entrenamiento : [[0.9727808]]\n",
      "PERDIDAAAA despues: 0.00830701645463705\n",
      "loss en el callback: 0.00019477854948490858, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "ejemplar: [[0.9893862 ]\n",
      " [0.9860552 ]\n",
      " [0.98353773]\n",
      " [0.9811945 ]\n",
      " [0.97967237]\n",
      " [0.97786736]\n",
      " [0.97538984]\n",
      " [0.9727174 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8487268177153953\n",
      "Predicci√≥n : [[0.9706619]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[[0.9893862 ]\n",
      "  [0.9860552 ]\n",
      "  [0.98353773]\n",
      "  [0.9811945 ]\n",
      "  [0.97967237]\n",
      "  [0.97786736]\n",
      "  [0.97538984]\n",
      "  [0.9727174 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014868161641061306\n",
      "Predicci√≥n post entrenamiento : [[0.96953535]]\n",
      "PERDIDAAAA despues: 0.014594703912734985\n",
      "loss en el callback: 0.04261861741542816, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "ejemplar: [[0.9860552 ]\n",
      " [0.98353773]\n",
      " [0.9811945 ]\n",
      " [0.97967237]\n",
      " [0.97786736]\n",
      " [0.97538984]\n",
      " [0.9727174 ]\n",
      " [0.97066188]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.875260685634848\n",
      "Predicci√≥n : [[0.96728295]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[[0.9860552 ]\n",
      "  [0.98353773]\n",
      "  [0.9811945 ]\n",
      "  [0.97967237]\n",
      "  [0.97786736]\n",
      "  [0.97538984]\n",
      "  [0.9727174 ]\n",
      "  [0.97066188]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008468092419207096\n",
      "Predicci√≥n post entrenamiento : [[0.96625906]]\n",
      "PERDIDAAAA despues: 0.008280700072646141\n",
      "loss en el callback: 0.035110265016555786, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "ejemplar: [[0.98353773]\n",
      " [0.9811945 ]\n",
      " [0.97967237]\n",
      " [0.97786736]\n",
      " [0.97538984]\n",
      " [0.9727174 ]\n",
      " [0.97066188]\n",
      " [0.96728295]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9612395688424776\n",
      "Predicci√≥n : [[0.9642951]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[[0.98353773]\n",
      "  [0.9811945 ]\n",
      "  [0.97967237]\n",
      "  [0.97786736]\n",
      "  [0.97538984]\n",
      "  [0.9727174 ]\n",
      "  [0.97066188]\n",
      "  [0.96728295]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 9.336159564554691e-06\n",
      "Predicci√≥n post entrenamiento : [[0.96490264]]\n",
      "PERDIDAAAA despues: 1.3418030903267208e-05\n",
      "loss en el callback: 0.019902899861335754, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "ejemplar: [[0.9811945 ]\n",
      " [0.97967237]\n",
      " [0.97786736]\n",
      " [0.97538984]\n",
      " [0.9727174 ]\n",
      " [0.97066188]\n",
      " [0.96728295]\n",
      " [0.96429509]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9925021123407926\n",
      "Predicci√≥n : [[0.96301764]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[[0.9811945 ]\n",
      "  [0.97967237]\n",
      "  [0.97786736]\n",
      "  [0.97538984]\n",
      "  [0.9727174 ]\n",
      "  [0.97066188]\n",
      "  [0.96728295]\n",
      "  [0.96429509]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008693328127264977\n",
      "Predicci√≥n post entrenamiento : [[0.9628736]]\n",
      "PERDIDAAAA despues: 0.0008778489427641034\n",
      "loss en el callback: 0.0007589752203784883, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "ejemplar: [[0.97967237]\n",
      " [0.97786736]\n",
      " [0.97538984]\n",
      " [0.9727174 ]\n",
      " [0.97066188]\n",
      " [0.96728295]\n",
      " [0.96429509]\n",
      " [0.96301764]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.969048316129792\n",
      "Predicci√≥n : [[0.96101224]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[[0.97967237]\n",
      "  [0.97786736]\n",
      "  [0.97538984]\n",
      "  [0.9727174 ]\n",
      "  [0.97066188]\n",
      "  [0.96728295]\n",
      "  [0.96429509]\n",
      "  [0.96301764]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.45785330561921e-05\n",
      "Predicci√≥n post entrenamiento : [[0.9613639]]\n",
      "PERDIDAAAA despues: 5.905015132157132e-05\n",
      "loss en el callback: 0.0055248914286494255, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "ejemplar: [[0.97786736]\n",
      " [0.97538984]\n",
      " [0.9727174 ]\n",
      " [0.97066188]\n",
      " [0.96728295]\n",
      " [0.96429509]\n",
      " [0.96301764]\n",
      " [0.96101224]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9715476120161949\n",
      "Predicci√≥n : [[0.95927507]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[[0.97786736]\n",
      "  [0.97538984]\n",
      "  [0.9727174 ]\n",
      "  [0.97066188]\n",
      "  [0.96728295]\n",
      "  [0.96429509]\n",
      "  [0.96301764]\n",
      "  [0.96101224]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00015061516023706645\n",
      "Predicci√≥n post entrenamiento : [[0.9593221]]\n",
      "PERDIDAAAA despues: 0.0001494630560046062\n",
      "loss en el callback: 0.0001013454093481414, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "ejemplar: [[0.97538984]\n",
      " [0.9727174 ]\n",
      " [0.97066188]\n",
      " [0.96728295]\n",
      " [0.96429509]\n",
      " [0.96301764]\n",
      " [0.96101224]\n",
      " [0.95927507]]\n",
      "ejemplar: (8, 1)\n",
      "y: 1.0\n",
      "Predicci√≥n : [[0.95705855]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[[0.97538984]\n",
      "  [0.9727174 ]\n",
      "  [0.97066188]\n",
      "  [0.96728295]\n",
      "  [0.96429509]\n",
      "  [0.96301764]\n",
      "  [0.96101224]\n",
      "  [0.95927507]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018439681734889746\n",
      "Predicci√≥n post entrenamiento : [[0.9566665]]\n",
      "PERDIDAAAA despues: 0.0018777897348627448\n",
      "loss en el callback: 0.005561245139688253, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "ejemplar: [[0.9727174 ]\n",
      " [0.97066188]\n",
      " [0.96728295]\n",
      " [0.96429509]\n",
      " [0.96301764]\n",
      " [0.96101224]\n",
      " [0.95927507]\n",
      " [0.95705855]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9800636522775721\n",
      "Predicci√≥n : [[0.9544157]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[[0.9727174 ]\n",
      "  [0.97066188]\n",
      "  [0.96728295]\n",
      "  [0.96429509]\n",
      "  [0.96301764]\n",
      "  [0.96101224]\n",
      "  [0.95927507]\n",
      "  [0.95705855]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006578197935596108\n",
      "Predicci√≥n post entrenamiento : [[0.95447767]]\n",
      "PERDIDAAAA despues: 0.0006546438671648502\n",
      "loss en el callback: 0.0001704726309981197, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "ejemplar: [[0.97066188]\n",
      " [0.96728295]\n",
      " [0.96429509]\n",
      " [0.96301764]\n",
      " [0.96101224]\n",
      " [0.95927507]\n",
      " [0.95705855]\n",
      " [0.95441568]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.911738568848911\n",
      "Predicci√≥n : [[0.95231456]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[[0.97066188]\n",
      "  [0.96728295]\n",
      "  [0.96429509]\n",
      "  [0.96301764]\n",
      "  [0.96101224]\n",
      "  [0.95927507]\n",
      "  [0.95705855]\n",
      "  [0.95441568]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001646410208195448\n",
      "Predicci√≥n post entrenamiento : [[0.9508274]]\n",
      "PERDIDAAAA despues: 0.0015279378276318312\n",
      "loss en el callback: 0.07260985672473907, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "ejemplar: [[0.96728295]\n",
      " [0.96429509]\n",
      " [0.96301764]\n",
      " [0.96101224]\n",
      " [0.95927507]\n",
      " [0.95705855]\n",
      " [0.95441568]\n",
      " [0.95231456]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8910857934126422\n",
      "Predicci√≥n : [[0.9485993]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[[0.96728295]\n",
      "  [0.96429509]\n",
      "  [0.96301764]\n",
      "  [0.96101224]\n",
      "  [0.95927507]\n",
      "  [0.95705855]\n",
      "  [0.95441568]\n",
      "  [0.95231456]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003307799808681011\n",
      "Predicci√≥n post entrenamiento : [[0.9484393]]\n",
      "PERDIDAAAA despues: 0.0032894236501306295\n",
      "loss en el callback: 0.001211661845445633, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "ejemplar: [[0.96429509]\n",
      " [0.96301764]\n",
      " [0.96101224]\n",
      " [0.95927507]\n",
      " [0.95705855]\n",
      " [0.95441568]\n",
      " [0.95231456]\n",
      " [0.94859928]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9181053259687657\n",
      "Predicci√≥n : [[0.9465279]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[[0.96429509]\n",
      "  [0.96301764]\n",
      "  [0.96101224]\n",
      "  [0.95927507]\n",
      "  [0.95705855]\n",
      "  [0.95441568]\n",
      "  [0.95231456]\n",
      "  [0.94859928]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008078438695520163\n",
      "Predicci√≥n post entrenamiento : [[0.9464028]]\n",
      "PERDIDAAAA despues: 0.0008007475989870727\n",
      "loss en el callback: 0.000758939131628722, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "ejemplar: [[0.96301764]\n",
      " [0.96101224]\n",
      " [0.95927507]\n",
      " [0.95705855]\n",
      " [0.95441568]\n",
      " [0.95231456]\n",
      " [0.94859928]\n",
      " [0.9465279 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9450165163483527\n",
      "Predicci√≥n : [[0.9447277]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[[0.96301764]\n",
      "  [0.96101224]\n",
      "  [0.95927507]\n",
      "  [0.95705855]\n",
      "  [0.95441568]\n",
      "  [0.95231456]\n",
      "  [0.94859928]\n",
      "  [0.9465279 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.339648616129125e-08\n",
      "Predicci√≥n post entrenamiento : [[0.94531614]]\n",
      "PERDIDAAAA despues: 8.977966103884683e-08\n",
      "loss en el callback: 0.02008298598229885, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "ejemplar: [[0.96101224]\n",
      " [0.95927507]\n",
      " [0.95705855]\n",
      " [0.95441568]\n",
      " [0.95231456]\n",
      " [0.94859928]\n",
      " [0.9465279 ]\n",
      " [0.94472772]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9718193645514037\n",
      "Predicci√≥n : [[0.94338906]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[[0.96101224]\n",
      "  [0.95927507]\n",
      "  [0.95705855]\n",
      "  [0.95441568]\n",
      "  [0.95231456]\n",
      "  [0.94859928]\n",
      "  [0.9465279 ]\n",
      "  [0.94472772]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008082810090854764\n",
      "Predicci√≥n post entrenamiento : [[0.94411385]]\n",
      "PERDIDAAAA despues: 0.0007675942033529282\n",
      "loss en el callback: 0.034710437059402466, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "ejemplar: [[0.95927507]\n",
      " [0.95705855]\n",
      " [0.95441568]\n",
      " [0.95231456]\n",
      " [0.94859928]\n",
      " [0.9465279 ]\n",
      " [0.94472772]\n",
      " [0.94338906]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9829067192737589\n",
      "Predicci√≥n : [[0.942104]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[[0.95927507]\n",
      "  [0.95705855]\n",
      "  [0.95441568]\n",
      "  [0.95231456]\n",
      "  [0.94859928]\n",
      "  [0.9465279 ]\n",
      "  [0.94472772]\n",
      "  [0.94338906]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016648616874590516\n",
      "Predicci√≥n post entrenamiento : [[0.9424564]]\n",
      "PERDIDAAAA despues: 0.0016362247988581657\n",
      "loss en el callback: 0.006917258258908987, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "ejemplar: [[0.95705855]\n",
      " [0.95441568]\n",
      " [0.95231456]\n",
      " [0.94859928]\n",
      " [0.9465279 ]\n",
      " [0.94472772]\n",
      " [0.94338906]\n",
      " [0.94210398]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9782785805154182\n",
      "Predicci√≥n : [[0.94028205]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[[0.95705855]\n",
      "  [0.95441568]\n",
      "  [0.95231456]\n",
      "  [0.94859928]\n",
      "  [0.9465279 ]\n",
      "  [0.94472772]\n",
      "  [0.94338906]\n",
      "  [0.94210398]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014437363715842366\n",
      "Predicci√≥n post entrenamiento : [[0.9408216]]\n",
      "PERDIDAAAA despues: 0.0014030260499566793\n",
      "loss en el callback: 0.017404627054929733, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "ejemplar: [[0.05029815]\n",
      " [0.00860651]\n",
      " [0.        ]\n",
      " [0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.049424632939554\n",
      "Predicci√≥n : [[0.19674885]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.05029815]\n",
      "  [0.00860651]\n",
      "  [0.        ]\n",
      "  [0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.021704426035284996\n",
      "Predicci√≥n post entrenamiento : [[0.1588446]]\n",
      "PERDIDAAAA despues: 0.011972730048000813\n",
      "loss en el callback: 0.025117626413702965, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "ejemplar: [[0.00860651]\n",
      " [0.        ]\n",
      " [0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.19674885]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.10789185692558968\n",
      "Predicci√≥n : [[0.15370043]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.00860651]\n",
      "  [0.        ]\n",
      "  [0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.19674885]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0020984250586479902\n",
      "Predicci√≥n post entrenamiento : [[0.14165308]]\n",
      "PERDIDAAAA despues: 0.0011398198548704386\n",
      "loss en el callback: 0.0027339207008481026, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "ejemplar: [[0.        ]\n",
      " [0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.19674885]\n",
      " [0.15370043]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.13719610119365802\n",
      "Predicci√≥n : [[0.14610972]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[[0.        ]\n",
      "  [0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.19674885]\n",
      "  [0.15370043]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.945264223963022e-05\n",
      "Predicci√≥n post entrenamiento : [[0.14691399]]\n",
      "PERDIDAAAA despues: 9.443751332582906e-05\n",
      "loss en el callback: 4.159189484198578e-05, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "ejemplar: [[0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.19674885]\n",
      " [0.15370043]\n",
      " [0.14610972]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.13733736574375907\n",
      "Predicci√≥n : [[0.15621455]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[[0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.19674885]\n",
      "  [0.15370043]\n",
      "  [0.14610972]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00035634785308502614\n",
      "Predicci√≥n post entrenamiento : [[0.15578659]]\n",
      "PERDIDAAAA despues: 0.00034037360455840826\n",
      "loss en el callback: 1.740605875966139e-05, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "ejemplar: [[0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.19674885]\n",
      " [0.15370043]\n",
      " [0.14610972]\n",
      " [0.15621455]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.13388569841244483\n",
      "Predicci√≥n : [[0.1639317]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[[0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.19674885]\n",
      "  [0.15370043]\n",
      "  [0.14610972]\n",
      "  [0.15621455]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009027621708810329\n",
      "Predicci√≥n post entrenamiento : [[0.16259994]]\n",
      "PERDIDAAAA despues: 0.0008245075587183237\n",
      "loss en el callback: 0.00025409343652427197, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "ejemplar: [[0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.19674885]\n",
      " [0.15370043]\n",
      " [0.14610972]\n",
      " [0.15621455]\n",
      " [0.1639317 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.12684109919971556\n",
      "Predicci√≥n : [[0.17291434]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[[0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.19674885]\n",
      "  [0.15370043]\n",
      "  [0.14610972]\n",
      "  [0.15621455]\n",
      "  [0.1639317 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0021227437537163496\n",
      "Predicci√≥n post entrenamiento : [[0.1694638]]\n",
      "PERDIDAAAA despues: 0.001816694624722004\n",
      "loss en el callback: 0.002146512269973755, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "ejemplar: [[0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.19674885]\n",
      " [0.15370043]\n",
      " [0.14610972]\n",
      " [0.15621455]\n",
      " [0.1639317 ]\n",
      " [0.17291434]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14756061137847282\n",
      "Predicci√≥n : [[0.18579255]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[[0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.19674885]\n",
      "  [0.15370043]\n",
      "  [0.14610972]\n",
      "  [0.15621455]\n",
      "  [0.1639317 ]\n",
      "  [0.17291434]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014616812113672495\n",
      "Predicci√≥n post entrenamiento : [[0.18526804]]\n",
      "PERDIDAAAA despues: 0.0014218505239114165\n",
      "loss en el callback: 9.01460662134923e-05, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "ejemplar: [[0.0202993 ]\n",
      " [0.19674885]\n",
      " [0.15370043]\n",
      " [0.14610972]\n",
      " [0.15621455]\n",
      " [0.1639317 ]\n",
      " [0.17291434]\n",
      " [0.18579255]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19604423494871648\n",
      "Predicci√≥n : [[0.20763008]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[[0.0202993 ]\n",
      "  [0.19674885]\n",
      "  [0.15370043]\n",
      "  [0.14610972]\n",
      "  [0.15621455]\n",
      "  [0.1639317 ]\n",
      "  [0.17291434]\n",
      "  [0.18579255]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00013423184282146394\n",
      "Predicci√≥n post entrenamiento : [[0.20595755]]\n",
      "PERDIDAAAA despues: 9.82737255981192e-05\n",
      "loss en el callback: 0.0007321049924939871, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "ejemplar: [[0.19674885]\n",
      " [0.15370043]\n",
      " [0.14610972]\n",
      " [0.15621455]\n",
      " [0.1639317 ]\n",
      " [0.17291434]\n",
      " [0.18579255]\n",
      " [0.20763008]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.21688968214535215\n",
      "Predicci√≥n : [[0.23416686]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[[0.19674885]\n",
      "  [0.15370043]\n",
      "  [0.14610972]\n",
      "  [0.15621455]\n",
      "  [0.1639317 ]\n",
      "  [0.17291434]\n",
      "  [0.18579255]\n",
      "  [0.20763008]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00029850099235773087\n",
      "Predicci√≥n post entrenamiento : [[0.23479272]]\n",
      "PERDIDAAAA despues: 0.000320519000524655\n",
      "loss en el callback: 0.0001739411527523771, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "ejemplar: [[0.15370043]\n",
      " [0.14610972]\n",
      " [0.15621455]\n",
      " [0.1639317 ]\n",
      " [0.17291434]\n",
      " [0.18579255]\n",
      " [0.20763008]\n",
      " [0.23416686]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2100969529683796\n",
      "Predicci√≥n : [[0.22863881]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[[0.15370043]\n",
      "  [0.14610972]\n",
      "  [0.15621455]\n",
      "  [0.1639317 ]\n",
      "  [0.17291434]\n",
      "  [0.18579255]\n",
      "  [0.20763008]\n",
      "  [0.23416686]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003438004932831973\n",
      "Predicci√≥n post entrenamiento : [[0.2278912]]\n",
      "PERDIDAAAA despues: 0.00031663538538850844\n",
      "loss en el callback: 0.000269478652626276, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "ejemplar: [[0.14610972]\n",
      " [0.15621455]\n",
      " [0.1639317 ]\n",
      " [0.17291434]\n",
      " [0.18579255]\n",
      " [0.20763008]\n",
      " [0.23416686]\n",
      " [0.22863881]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2026778474621132\n",
      "Predicci√≥n : [[0.23173426]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[[0.14610972]\n",
      "  [0.15621455]\n",
      "  [0.1639317 ]\n",
      "  [0.17291434]\n",
      "  [0.18579255]\n",
      "  [0.20763008]\n",
      "  [0.23416686]\n",
      "  [0.22863881]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008442752296105027\n",
      "Predicci√≥n post entrenamiento : [[0.22932063]]\n",
      "PERDIDAAAA despues: 0.0007098379428498447\n",
      "loss en el callback: 0.0027027372270822525, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "ejemplar: [[0.15621455]\n",
      " [0.1639317 ]\n",
      " [0.17291434]\n",
      " [0.18579255]\n",
      " [0.20763008]\n",
      " [0.23416686]\n",
      " [0.22863881]\n",
      " [0.23173426]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19463236562655295\n",
      "Predicci√≥n : [[0.2369809]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[[0.15621455]\n",
      "  [0.1639317 ]\n",
      "  [0.17291434]\n",
      "  [0.18579255]\n",
      "  [0.20763008]\n",
      "  [0.23416686]\n",
      "  [0.22863881]\n",
      "  [0.23173426]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017933982890099287\n",
      "Predicci√≥n post entrenamiento : [[0.23605509]]\n",
      "PERDIDAAAA despues: 0.001715842168778181\n",
      "loss en el callback: 0.0006440044962801039, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "ejemplar: [[0.1639317 ]\n",
      " [0.17291434]\n",
      " [0.18579255]\n",
      " [0.20763008]\n",
      " [0.23416686]\n",
      " [0.22863881]\n",
      " [0.23173426]\n",
      " [0.2369809 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19407351685692253\n",
      "Predicci√≥n : [[0.24411234]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[[0.1639317 ]\n",
      "  [0.17291434]\n",
      "  [0.18579255]\n",
      "  [0.20763008]\n",
      "  [0.23416686]\n",
      "  [0.22863881]\n",
      "  [0.23173426]\n",
      "  [0.2369809 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0025038844905793667\n",
      "Predicci√≥n post entrenamiento : [[0.24401076]]\n",
      "PERDIDAAAA despues: 0.0024937286507338285\n",
      "loss en el callback: 1.1318980796204414e-05, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "ejemplar: [[0.17291434]\n",
      " [0.18579255]\n",
      " [0.20763008]\n",
      " [0.23416686]\n",
      " [0.22863881]\n",
      " [0.23173426]\n",
      " [0.2369809 ]\n",
      " [0.24411234]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.20100130115322212\n",
      "Predicci√≥n : [[0.25295767]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[[0.17291434]\n",
      "  [0.18579255]\n",
      "  [0.20763008]\n",
      "  [0.23416686]\n",
      "  [0.22863881]\n",
      "  [0.23173426]\n",
      "  [0.2369809 ]\n",
      "  [0.24411234]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00269946432672441\n",
      "Predicci√≥n post entrenamiento : [[0.25193292]]\n",
      "PERDIDAAAA despues: 0.002594029763713479\n",
      "loss en el callback: 0.001027181395329535, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "ejemplar: [[0.18579255]\n",
      " [0.20763008]\n",
      " [0.23416686]\n",
      " [0.22863881]\n",
      " [0.23173426]\n",
      " [0.2369809 ]\n",
      " [0.24411234]\n",
      " [0.25295767]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19663820581116015\n",
      "Predicci√≥n : [[0.26145136]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[[0.18579255]\n",
      "  [0.20763008]\n",
      "  [0.23416686]\n",
      "  [0.22863881]\n",
      "  [0.23173426]\n",
      "  [0.2369809 ]\n",
      "  [0.24411234]\n",
      "  [0.25295767]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004200744442641735\n",
      "Predicci√≥n post entrenamiento : [[0.25826153]]\n",
      "PERDIDAAAA despues: 0.0037974335718899965\n",
      "loss en el callback: 0.008207280188798904, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "ejemplar: [[0.20763008]\n",
      " [0.23416686]\n",
      " [0.22863881]\n",
      " [0.23173426]\n",
      " [0.2369809 ]\n",
      " [0.24411234]\n",
      " [0.25295767]\n",
      " [0.26145136]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1809842308307365\n",
      "Predicci√≥n : [[0.2673299]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[[0.20763008]\n",
      "  [0.23416686]\n",
      "  [0.22863881]\n",
      "  [0.23173426]\n",
      "  [0.2369809 ]\n",
      "  [0.24411234]\n",
      "  [0.25295767]\n",
      "  [0.26145136]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007455575279891491\n",
      "Predicci√≥n post entrenamiento : [[0.26548797]]\n",
      "PERDIDAAAA despues: 0.007140882313251495\n",
      "loss en el callback: 0.00415083859115839, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "ejemplar: [[0.23416686]\n",
      " [0.22863881]\n",
      " [0.23173426]\n",
      " [0.2369809 ]\n",
      " [0.24411234]\n",
      " [0.25295767]\n",
      " [0.26145136]\n",
      " [0.2673299 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1653904097109329\n",
      "Predicci√≥n : [[0.27173474]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[[0.23416686]\n",
      "  [0.22863881]\n",
      "  [0.23173426]\n",
      "  [0.2369809 ]\n",
      "  [0.24411234]\n",
      "  [0.25295767]\n",
      "  [0.26145136]\n",
      "  [0.2673299 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011309116147458553\n",
      "Predicci√≥n post entrenamiento : [[0.26914898]]\n",
      "PERDIDAAAA despues: 0.01076583843678236\n",
      "loss en el callback: 0.008674164302647114, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "ejemplar: [[0.22863881]\n",
      " [0.23173426]\n",
      " [0.2369809 ]\n",
      " [0.24411234]\n",
      " [0.25295767]\n",
      " [0.26145136]\n",
      " [0.2673299 ]\n",
      " [0.27173474]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14985674245174896\n",
      "Predicci√≥n : [[0.2708851]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[[0.22863881]\n",
      "  [0.23173426]\n",
      "  [0.2369809 ]\n",
      "  [0.24411234]\n",
      "  [0.25295767]\n",
      "  [0.26145136]\n",
      "  [0.2673299 ]\n",
      "  [0.27173474]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014647864736616611\n",
      "Predicci√≥n post entrenamiento : [[0.26727992]]\n",
      "PERDIDAAAA despues: 0.013788202777504921\n",
      "loss en el callback: 0.017091713845729828, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "ejemplar: [[0.23173426]\n",
      " [0.2369809 ]\n",
      " [0.24411234]\n",
      " [0.25295767]\n",
      " [0.26145136]\n",
      " [0.2673299 ]\n",
      " [0.27173474]\n",
      " [0.27088511]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.15043111479831345\n",
      "Predicci√≥n : [[0.27134433]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[[0.23173426]\n",
      "  [0.2369809 ]\n",
      "  [0.24411234]\n",
      "  [0.25295767]\n",
      "  [0.26145136]\n",
      "  [0.2673299 ]\n",
      "  [0.27173474]\n",
      "  [0.27088511]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014620007015764713\n",
      "Predicci√≥n post entrenamiento : [[0.26784906]]\n",
      "PERDIDAAAA despues: 0.013786974363029003\n",
      "loss en el callback: 0.017475001513957977, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "ejemplar: [[0.2369809 ]\n",
      " [0.24411234]\n",
      " [0.25295767]\n",
      " [0.26145136]\n",
      " [0.2673299 ]\n",
      " [0.27173474]\n",
      " [0.27088511]\n",
      " [0.27134433]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.16711352675062616\n",
      "Predicci√≥n : [[0.2725541]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[[0.2369809 ]\n",
      "  [0.24411234]\n",
      "  [0.25295767]\n",
      "  [0.26145136]\n",
      "  [0.2673299 ]\n",
      "  [0.27173474]\n",
      "  [0.27088511]\n",
      "  [0.27134433]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011117714457213879\n",
      "Predicci√≥n post entrenamiento : [[0.2698388]]\n",
      "PERDIDAAAA despues: 0.01055248361080885\n",
      "loss en el callback: 0.012292028404772282, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "ejemplar: [[0.24411234]\n",
      " [0.25295767]\n",
      " [0.26145136]\n",
      " [0.2673299 ]\n",
      " [0.27173474]\n",
      " [0.27088511]\n",
      " [0.27134433]\n",
      " [0.2725541 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2022703535675908\n",
      "Predicci√≥n : [[0.27466783]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[[0.24411234]\n",
      "  [0.25295767]\n",
      "  [0.26145136]\n",
      "  [0.2673299 ]\n",
      "  [0.27173474]\n",
      "  [0.27088511]\n",
      "  [0.27134433]\n",
      "  [0.2725541 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005241393577307463\n",
      "Predicci√≥n post entrenamiento : [[0.2720557]]\n",
      "PERDIDAAAA despues: 0.004869991913437843\n",
      "loss en el callback: 0.011188514530658722, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "ejemplar: [[0.25295767]\n",
      " [0.26145136]\n",
      " [0.2673299 ]\n",
      " [0.27173474]\n",
      " [0.27088511]\n",
      " [0.27134433]\n",
      " [0.2725541 ]\n",
      " [0.27466783]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.25590159524920725\n",
      "Predicci√≥n : [[0.2764375]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[[0.25295767]\n",
      "  [0.26145136]\n",
      "  [0.2673299 ]\n",
      "  [0.27173474]\n",
      "  [0.27088511]\n",
      "  [0.27134433]\n",
      "  [0.2725541 ]\n",
      "  [0.27466783]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004217226232867688\n",
      "Predicci√≥n post entrenamiento : [[0.27595714]]\n",
      "PERDIDAAAA despues: 0.0004022243956569582\n",
      "loss en el callback: 0.0004788609512615949, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "ejemplar: [[0.26145136]\n",
      " [0.2673299 ]\n",
      " [0.27173474]\n",
      " [0.27088511]\n",
      " [0.27134433]\n",
      " [0.2725541 ]\n",
      " [0.27466783]\n",
      " [0.27643749]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.292688203599549\n",
      "Predicci√≥n : [[0.279275]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[[0.26145136]\n",
      "  [0.2673299 ]\n",
      "  [0.27173474]\n",
      "  [0.27088511]\n",
      "  [0.27134433]\n",
      "  [0.2725541 ]\n",
      "  [0.27466783]\n",
      "  [0.27643749]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001799136953195557\n",
      "Predicci√≥n post entrenamiento : [[0.2793193]]\n",
      "PERDIDAAAA despues: 0.0001787276123650372\n",
      "loss en el callback: 3.8226176002353895e-06, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "ejemplar: [[0.2673299 ]\n",
      " [0.27173474]\n",
      " [0.27088511]\n",
      " [0.27134433]\n",
      " [0.2725541 ]\n",
      " [0.27466783]\n",
      " [0.27643749]\n",
      " [0.279275  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31263017861861575\n",
      "Predicci√≥n : [[0.28138465]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[[0.2673299 ]\n",
      "  [0.27173474]\n",
      "  [0.27088511]\n",
      "  [0.27134433]\n",
      "  [0.2725541 ]\n",
      "  [0.27466783]\n",
      "  [0.27643749]\n",
      "  [0.279275  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009762831032276154\n",
      "Predicci√≥n post entrenamiento : [[0.2826359]]\n",
      "PERDIDAAAA despues: 0.0008996567921712995\n",
      "loss en el callback: 0.004096972290426493, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "ejemplar: [[0.27173474]\n",
      " [0.27088511]\n",
      " [0.27134433]\n",
      " [0.2725541 ]\n",
      " [0.27466783]\n",
      " [0.27643749]\n",
      " [0.279275  ]\n",
      " [0.28138465]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3109388849116374\n",
      "Predicci√≥n : [[0.28382683]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[[0.27173474]\n",
      "  [0.27088511]\n",
      "  [0.27134433]\n",
      "  [0.2725541 ]\n",
      "  [0.27466783]\n",
      "  [0.27643749]\n",
      "  [0.279275  ]\n",
      "  [0.28138465]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007350641535595059\n",
      "Predicci√≥n post entrenamiento : [[0.28514156]]\n",
      "PERDIDAAAA despues: 0.0006655026227235794\n",
      "loss en el callback: 0.005610983353108168, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "ejemplar: [[0.27088511]\n",
      " [0.27134433]\n",
      " [0.2725541 ]\n",
      " [0.27466783]\n",
      " [0.27643749]\n",
      " [0.279275  ]\n",
      " [0.28138465]\n",
      " [0.28382683]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2876143224786136\n",
      "Predicci√≥n : [[0.28567383]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[[0.27088511]\n",
      "  [0.27134433]\n",
      "  [0.2725541 ]\n",
      "  [0.27466783]\n",
      "  [0.27643749]\n",
      "  [0.279275  ]\n",
      "  [0.28138465]\n",
      "  [0.28382683]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.7654967854905408e-06\n",
      "Predicci√≥n post entrenamiento : [[0.28589535]]\n",
      "PERDIDAAAA despues: 2.954851424874505e-06\n",
      "loss en el callback: 0.00015804894792381674, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "ejemplar: [[0.27134433]\n",
      " [0.2725541 ]\n",
      " [0.27466783]\n",
      " [0.27643749]\n",
      " [0.279275  ]\n",
      " [0.28138465]\n",
      " [0.28382683]\n",
      " [0.28567383]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.280161647237227\n",
      "Predicci√≥n : [[0.28695068]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[[0.27134433]\n",
      "  [0.2725541 ]\n",
      "  [0.27466783]\n",
      "  [0.27643749]\n",
      "  [0.279275  ]\n",
      "  [0.28138465]\n",
      "  [0.28382683]\n",
      "  [0.28567383]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.6090910473139957e-05\n",
      "Predicci√≥n post entrenamiento : [[0.2867695]]\n",
      "PERDIDAAAA despues: 4.366381836007349e-05\n",
      "loss en el callback: 8.999587589642033e-05, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "ejemplar: [[0.2725541 ]\n",
      " [0.27466783]\n",
      " [0.27643749]\n",
      " [0.279275  ]\n",
      " [0.28138465]\n",
      " [0.28382683]\n",
      " [0.28567383]\n",
      " [0.28695068]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2885808591874776\n",
      "Predicci√≥n : [[0.28814098]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[[0.2725541 ]\n",
      "  [0.27466783]\n",
      "  [0.27643749]\n",
      "  [0.279275  ]\n",
      "  [0.28138465]\n",
      "  [0.28382683]\n",
      "  [0.28567383]\n",
      "  [0.28695068]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.93496418887662e-07\n",
      "Predicci√≥n post entrenamiento : [[0.2873713]]\n",
      "PERDIDAAAA despues: 1.4630282976213493e-06\n",
      "loss en el callback: 0.0016815701965242624, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "ejemplar: [[0.27466783]\n",
      " [0.27643749]\n",
      " [0.279275  ]\n",
      " [0.28138465]\n",
      " [0.28382683]\n",
      " [0.28567383]\n",
      " [0.28695068]\n",
      " [0.28814098]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2824628234730068\n",
      "Predicci√≥n : [[0.28892988]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[[0.27466783]\n",
      "  [0.27643749]\n",
      "  [0.279275  ]\n",
      "  [0.28138465]\n",
      "  [0.28382683]\n",
      "  [0.28567383]\n",
      "  [0.28695068]\n",
      "  [0.28814098]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.1822662751656026e-05\n",
      "Predicci√≥n post entrenamiento : [[0.28902677]]\n",
      "PERDIDAAAA despues: 4.3085197830805555e-05\n",
      "loss en el callback: 3.4516575396992266e-05, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "ejemplar: [[0.27643749]\n",
      " [0.279275  ]\n",
      " [0.28138465]\n",
      " [0.28382683]\n",
      " [0.28567383]\n",
      " [0.28695068]\n",
      " [0.28814098]\n",
      " [0.28892988]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.26180754009381474\n",
      "Predicci√≥n : [[0.2905699]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[[0.27643749]\n",
      "  [0.279275  ]\n",
      "  [0.28138465]\n",
      "  [0.28382683]\n",
      "  [0.28567383]\n",
      "  [0.28695068]\n",
      "  [0.28814098]\n",
      "  [0.28892988]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008272739360108972\n",
      "Predicci√≥n post entrenamiento : [[0.29002488]]\n",
      "PERDIDAAAA despues: 0.0007962185773067176\n",
      "loss en el callback: 0.0010614264756441116, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "ejemplar: [[0.279275  ]\n",
      " [0.28138465]\n",
      " [0.28382683]\n",
      " [0.28567383]\n",
      " [0.28695068]\n",
      " [0.28814098]\n",
      " [0.28892988]\n",
      " [0.2905699 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2801212859371977\n",
      "Predicci√≥n : [[0.29160953]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[[0.279275  ]\n",
      "  [0.28138465]\n",
      "  [0.28382683]\n",
      "  [0.28567383]\n",
      "  [0.28695068]\n",
      "  [0.28814098]\n",
      "  [0.28892988]\n",
      "  [0.2905699 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00013197941007092595\n",
      "Predicci√≥n post entrenamiento : [[0.29088876]]\n",
      "PERDIDAAAA despues: 0.00011593819363042712\n",
      "loss en el callback: 0.0016861316980794072, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "ejemplar: [[0.28138465]\n",
      " [0.28382683]\n",
      " [0.28567383]\n",
      " [0.28695068]\n",
      " [0.28814098]\n",
      " [0.28892988]\n",
      " [0.2905699 ]\n",
      " [0.29160953]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3374040610031557\n",
      "Predicci√≥n : [[0.29223937]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[[0.28138465]\n",
      "  [0.28382683]\n",
      "  [0.28567383]\n",
      "  [0.28695068]\n",
      "  [0.28814098]\n",
      "  [0.28892988]\n",
      "  [0.2905699 ]\n",
      "  [0.29160953]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0020398504566401243\n",
      "Predicci√≥n post entrenamiento : [[0.29267374]]\n",
      "PERDIDAAAA despues: 0.002000802895054221\n",
      "loss en el callback: 0.0007216804660856724, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "ejemplar: [[0.28382683]\n",
      " [0.28567383]\n",
      " [0.28695068]\n",
      " [0.28814098]\n",
      " [0.28892988]\n",
      " [0.2905699 ]\n",
      " [0.29160953]\n",
      " [0.29223937]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3482298154676272\n",
      "Predicci√≥n : [[0.29390365]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[[0.28382683]\n",
      "  [0.28567383]\n",
      "  [0.28695068]\n",
      "  [0.28814098]\n",
      "  [0.28892988]\n",
      "  [0.2905699 ]\n",
      "  [0.29160953]\n",
      "  [0.29223937]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029513335321098566\n",
      "Predicci√≥n post entrenamiento : [[0.29492208]]\n",
      "PERDIDAAAA despues: 0.002841715235263109\n",
      "loss en el callback: 0.005153484642505646, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "ejemplar: [[0.28567383]\n",
      " [0.28695068]\n",
      " [0.28814098]\n",
      " [0.28892988]\n",
      " [0.2905699 ]\n",
      " [0.29160953]\n",
      " [0.29223937]\n",
      " [0.29390365]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31259854933061226\n",
      "Predicci√≥n : [[0.29591507]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[[0.28567383]\n",
      "  [0.28695068]\n",
      "  [0.28814098]\n",
      "  [0.28892988]\n",
      "  [0.2905699 ]\n",
      "  [0.29160953]\n",
      "  [0.29223937]\n",
      "  [0.29390365]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00027833881904371083\n",
      "Predicci√≥n post entrenamiento : [[0.29591936]]\n",
      "PERDIDAAAA despues: 0.0002781956281978637\n",
      "loss en el callback: 8.01749777679106e-08, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "ejemplar: [[0.28695068]\n",
      " [0.28814098]\n",
      " [0.28892988]\n",
      " [0.2905699 ]\n",
      " [0.29160953]\n",
      " [0.29223937]\n",
      " [0.29390365]\n",
      " [0.29591507]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.34358710169603873\n",
      "Predicci√≥n : [[0.2967761]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[[0.28695068]\n",
      "  [0.28814098]\n",
      "  [0.28892988]\n",
      "  [0.2905699 ]\n",
      "  [0.29160953]\n",
      "  [0.29223937]\n",
      "  [0.29390365]\n",
      "  [0.29591507]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0021912711672484875\n",
      "Predicci√≥n post entrenamiento : [[0.2976766]]\n",
      "PERDIDAAAA despues: 0.002107774605974555\n",
      "loss en el callback: 0.00423281779512763, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "ejemplar: [[0.28814098]\n",
      " [0.28892988]\n",
      " [0.2905699 ]\n",
      " [0.29160953]\n",
      " [0.29223937]\n",
      " [0.29390365]\n",
      " [0.29591507]\n",
      " [0.29677609]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.4411954725639069\n",
      "Predicci√≥n : [[0.29851565]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[[0.28814098]\n",
      "  [0.28892988]\n",
      "  [0.2905699 ]\n",
      "  [0.29160953]\n",
      "  [0.29223937]\n",
      "  [0.29390365]\n",
      "  [0.29591507]\n",
      "  [0.29677609]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0203575287014246\n",
      "Predicci√≥n post entrenamiento : [[0.30036506]]\n",
      "PERDIDAAAA despues: 0.01983320154249668\n",
      "loss en el callback: 0.015377089381217957, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "ejemplar: [[0.28892988]\n",
      " [0.2905699 ]\n",
      " [0.29160953]\n",
      " [0.29223937]\n",
      " [0.29390365]\n",
      " [0.29591507]\n",
      " [0.29677609]\n",
      " [0.29851565]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5210953230441133\n",
      "Predicci√≥n : [[0.30121198]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[[0.28892988]\n",
      "  [0.2905699 ]\n",
      "  [0.29160953]\n",
      "  [0.29223937]\n",
      "  [0.29390365]\n",
      "  [0.29591507]\n",
      "  [0.29677609]\n",
      "  [0.29851565]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04834868758916855\n",
      "Predicci√≥n post entrenamiento : [[0.30415642]]\n",
      "PERDIDAAAA despues: 0.04706249013543129\n",
      "loss en el callback: 0.08022234588861465, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "ejemplar: [[0.2905699 ]\n",
      " [0.29160953]\n",
      " [0.29223937]\n",
      " [0.29390365]\n",
      " [0.29591507]\n",
      " [0.29677609]\n",
      " [0.29851565]\n",
      " [0.30121198]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5832866531366584\n",
      "Predicci√≥n : [[0.30512404]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[[0.2905699 ]\n",
      "  [0.29160953]\n",
      "  [0.29223937]\n",
      "  [0.29390365]\n",
      "  [0.29591507]\n",
      "  [0.29677609]\n",
      "  [0.29851565]\n",
      "  [0.30121198]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0773744285106659\n",
      "Predicci√≥n post entrenamiento : [[0.30875698]]\n",
      "PERDIDAAAA despues: 0.0753665342926979\n",
      "loss en el callback: 0.06819730252027512, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "ejemplar: [[0.29160953]\n",
      " [0.29223937]\n",
      " [0.29390365]\n",
      " [0.29591507]\n",
      " [0.29677609]\n",
      " [0.29851565]\n",
      " [0.30121198]\n",
      " [0.30512404]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6089234523540271\n",
      "Predicci√≥n : [[0.3096861]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[[0.29160953]\n",
      "  [0.29223937]\n",
      "  [0.29390365]\n",
      "  [0.29591507]\n",
      "  [0.29677609]\n",
      "  [0.29851565]\n",
      "  [0.30121198]\n",
      "  [0.30512404]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08954298496246338\n",
      "Predicci√≥n post entrenamiento : [[0.31356117]]\n",
      "PERDIDAAAA despues: 0.0872388705611229\n",
      "loss en el callback: 0.0923052579164505, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "ejemplar: [[0.29223937]\n",
      " [0.29390365]\n",
      " [0.29591507]\n",
      " [0.29677609]\n",
      " [0.29851565]\n",
      " [0.30121198]\n",
      " [0.30512404]\n",
      " [0.30968609]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.59800572069622\n",
      "Predicci√≥n : [[0.31463665]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[[0.29223937]\n",
      "  [0.29390365]\n",
      "  [0.29591507]\n",
      "  [0.29677609]\n",
      "  [0.29851565]\n",
      "  [0.30121198]\n",
      "  [0.30512404]\n",
      "  [0.30968609]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0802980288863182\n",
      "Predicci√≥n post entrenamiento : [[0.3177446]]\n",
      "PERDIDAAAA despues: 0.07854628562927246\n",
      "loss en el callback: 0.038896963000297546, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "ejemplar: [[0.29390365]\n",
      " [0.29591507]\n",
      " [0.29677609]\n",
      " [0.29851565]\n",
      " [0.30121198]\n",
      " [0.30512404]\n",
      " [0.30968609]\n",
      " [0.31463665]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5945301858653699\n",
      "Predicci√≥n : [[0.31915113]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[[0.29390365]\n",
      "  [0.29591507]\n",
      "  [0.29677609]\n",
      "  [0.29851565]\n",
      "  [0.30121198]\n",
      "  [0.30512404]\n",
      "  [0.30968609]\n",
      "  [0.31463665]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07583361119031906\n",
      "Predicci√≥n post entrenamiento : [[0.32245293]]\n",
      "PERDIDAAAA despues: 0.07402601838111877\n",
      "loss en el callback: 0.07096689939498901, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "ejemplar: [[0.29591507]\n",
      " [0.29677609]\n",
      " [0.29851565]\n",
      " [0.30121198]\n",
      " [0.30512404]\n",
      " [0.30968609]\n",
      " [0.31463665]\n",
      " [0.31915113]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5984968478614763\n",
      "Predicci√≥n : [[0.32405874]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[[0.29591507]\n",
      "  [0.29677609]\n",
      "  [0.29851565]\n",
      "  [0.30121198]\n",
      "  [0.30512404]\n",
      "  [0.30968609]\n",
      "  [0.31463665]\n",
      "  [0.31915113]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07531628012657166\n",
      "Predicci√≥n post entrenamiento : [[0.32751486]]\n",
      "PERDIDAAAA despues: 0.07343124598264694\n",
      "loss en el callback: 0.0818304643034935, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "ejemplar: [[0.29677609]\n",
      " [0.29851565]\n",
      " [0.30121198]\n",
      " [0.30512404]\n",
      " [0.30968609]\n",
      " [0.31463665]\n",
      " [0.31915113]\n",
      " [0.32405874]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6213543446734934\n",
      "Predicci√≥n : [[0.32933623]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[[0.29677609]\n",
      "  [0.29851565]\n",
      "  [0.30121198]\n",
      "  [0.30512404]\n",
      "  [0.30968609]\n",
      "  [0.31463665]\n",
      "  [0.31915113]\n",
      "  [0.32405874]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0852745771408081\n",
      "Predicci√≥n post entrenamiento : [[0.33293483]]\n",
      "PERDIDAAAA despues: 0.08318581432104111\n",
      "loss en el callback: 0.08537833392620087, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "ejemplar: [[0.29851565]\n",
      " [0.30121198]\n",
      " [0.30512404]\n",
      " [0.30968609]\n",
      " [0.31463665]\n",
      " [0.31915113]\n",
      " [0.32405874]\n",
      " [0.32933623]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.663102676301421\n",
      "Predicci√≥n : [[0.3353574]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[[0.29851565]\n",
      "  [0.30121198]\n",
      "  [0.30512404]\n",
      "  [0.30968609]\n",
      "  [0.31463665]\n",
      "  [0.31915113]\n",
      "  [0.32405874]\n",
      "  [0.32933623]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10741697251796722\n",
      "Predicci√≥n post entrenamiento : [[0.3388882]]\n",
      "PERDIDAAAA despues: 0.10511503368616104\n",
      "loss en el callback: 0.06523331999778748, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "ejemplar: [[0.30121198]\n",
      " [0.30512404]\n",
      " [0.30968609]\n",
      " [0.31463665]\n",
      " [0.31915113]\n",
      " [0.32405874]\n",
      " [0.32933623]\n",
      " [0.3353574 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6928724338328028\n",
      "Predicci√≥n : [[0.34185457]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[[0.30121198]\n",
      "  [0.30512404]\n",
      "  [0.30968609]\n",
      "  [0.31463665]\n",
      "  [0.31915113]\n",
      "  [0.32405874]\n",
      "  [0.32933623]\n",
      "  [0.3353574 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1232135221362114\n",
      "Predicci√≥n post entrenamiento : [[0.34573904]]\n",
      "PERDIDAAAA despues: 0.1205015778541565\n",
      "loss en el callback: 0.13377244770526886, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "ejemplar: [[0.30512404]\n",
      " [0.30968609]\n",
      " [0.31463665]\n",
      " [0.31915113]\n",
      " [0.32405874]\n",
      " [0.32933623]\n",
      " [0.3353574 ]\n",
      " [0.34185457]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.710663617267639\n",
      "Predicci√≥n : [[0.3491526]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[[0.30512404]\n",
      "  [0.30968609]\n",
      "  [0.31463665]\n",
      "  [0.31915113]\n",
      "  [0.32405874]\n",
      "  [0.32933623]\n",
      "  [0.3353574 ]\n",
      "  [0.34185457]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13069021701812744\n",
      "Predicci√≥n post entrenamiento : [[0.35320902]]\n",
      "PERDIDAAAA despues: 0.12777379155158997\n",
      "loss en el callback: 0.11430269479751587, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "ejemplar: [[0.30968609]\n",
      " [0.31463665]\n",
      " [0.31915113]\n",
      " [0.32405874]\n",
      " [0.32933623]\n",
      " [0.3353574 ]\n",
      " [0.34185457]\n",
      " [0.34915259]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7216820581308059\n",
      "Predicci√≥n : [[0.35688895]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[[0.30968609]\n",
      "  [0.31463665]\n",
      "  [0.31915113]\n",
      "  [0.32405874]\n",
      "  [0.32933623]\n",
      "  [0.3353574 ]\n",
      "  [0.34185457]\n",
      "  [0.34915259]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13307401537895203\n",
      "Predicci√≥n post entrenamiento : [[0.3607842]]\n",
      "PERDIDAAAA despues: 0.13024726510047913\n",
      "loss en el callback: 0.1007232815027237, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "ejemplar: [[0.31463665]\n",
      " [0.31915113]\n",
      " [0.32405874]\n",
      " [0.32933623]\n",
      " [0.3353574 ]\n",
      " [0.34185457]\n",
      " [0.34915259]\n",
      " [0.35688895]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7259277564223031\n",
      "Predicci√≥n : [[0.36466247]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[[0.31463665]\n",
      "  [0.31915113]\n",
      "  [0.32405874]\n",
      "  [0.32933623]\n",
      "  [0.3353574 ]\n",
      "  [0.34185457]\n",
      "  [0.34915259]\n",
      "  [0.35688895]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13051262497901917\n",
      "Predicci√≥n post entrenamiento : [[0.36840123]]\n",
      "PERDIDAAAA despues: 0.12782523036003113\n",
      "loss en el callback: 0.08968447893857956, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "ejemplar: [[0.31915113]\n",
      " [0.32405874]\n",
      " [0.32933623]\n",
      " [0.3353574 ]\n",
      " [0.34185457]\n",
      " [0.34915259]\n",
      " [0.35688895]\n",
      " [0.36466247]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7404318224413275\n",
      "Predicci√≥n : [[0.37247044]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[[0.31915113]\n",
      "  [0.32405874]\n",
      "  [0.32933623]\n",
      "  [0.3353574 ]\n",
      "  [0.34185457]\n",
      "  [0.34915259]\n",
      "  [0.35688895]\n",
      "  [0.36466247]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1353956013917923\n",
      "Predicci√≥n post entrenamiento : [[0.37628472]]\n",
      "PERDIDAAAA despues: 0.13260312378406525\n",
      "loss en el callback: 0.13556264340877533, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "ejemplar: [[0.32405874]\n",
      " [0.32933623]\n",
      " [0.3353574 ]\n",
      " [0.34185457]\n",
      " [0.34915259]\n",
      " [0.35688895]\n",
      " [0.36466247]\n",
      " [0.37247044]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7651942561878792\n",
      "Predicci√≥n : [[0.38074568]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[[0.32405874]\n",
      "  [0.32933623]\n",
      "  [0.3353574 ]\n",
      "  [0.34185457]\n",
      "  [0.34915259]\n",
      "  [0.35688895]\n",
      "  [0.36466247]\n",
      "  [0.37247044]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14780069887638092\n",
      "Predicci√≥n post entrenamiento : [[0.38497132]]\n",
      "PERDIDAAAA despues: 0.14456947147846222\n",
      "loss en el callback: 0.1757478564977646, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "ejemplar: [[0.32933623]\n",
      " [0.3353574 ]\n",
      " [0.34185457]\n",
      " [0.34915259]\n",
      " [0.35688895]\n",
      " [0.36466247]\n",
      " [0.37247044]\n",
      " [0.38074568]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7447890964420396\n",
      "Predicci√≥n : [[0.3898482]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[[0.32933623]\n",
      "  [0.3353574 ]\n",
      "  [0.34185457]\n",
      "  [0.34915259]\n",
      "  [0.35688895]\n",
      "  [0.36466247]\n",
      "  [0.37247044]\n",
      "  [0.38074568]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12598305940628052\n",
      "Predicci√≥n post entrenamiento : [[0.39361954]]\n",
      "PERDIDAAAA despues: 0.1233200803399086\n",
      "loss en el callback: 0.16437678039073944, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "ejemplar: [[0.3353574 ]\n",
      " [0.34185457]\n",
      " [0.34915259]\n",
      " [0.35688895]\n",
      " [0.36466247]\n",
      " [0.37247044]\n",
      " [0.38074568]\n",
      " [0.3898482 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6792163432038085\n",
      "Predicci√≥n : [[0.39894027]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[[0.3353574 ]\n",
      "  [0.34185457]\n",
      "  [0.34915259]\n",
      "  [0.35688895]\n",
      "  [0.36466247]\n",
      "  [0.37247044]\n",
      "  [0.38074568]\n",
      "  [0.3898482 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.078554667532444\n",
      "Predicci√≥n post entrenamiento : [[0.4018667]]\n",
      "PERDIDAAAA despues: 0.07692281156778336\n",
      "loss en el callback: 0.07995607703924179, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "ejemplar: [[0.34185457]\n",
      " [0.34915259]\n",
      " [0.35688895]\n",
      " [0.36466247]\n",
      " [0.37247044]\n",
      " [0.38074568]\n",
      " [0.3898482 ]\n",
      " [0.39894027]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6746017659154131\n",
      "Predicci√≥n : [[0.40756175]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[[0.34185457]\n",
      "  [0.34915259]\n",
      "  [0.35688895]\n",
      "  [0.36466247]\n",
      "  [0.37247044]\n",
      "  [0.38074568]\n",
      "  [0.3898482 ]\n",
      "  [0.39894027]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0713103860616684\n",
      "Predicci√≥n post entrenamiento : [[0.41054377]]\n",
      "PERDIDAAAA despues: 0.06972663849592209\n",
      "loss en el callback: 0.10647308826446533, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "ejemplar: [[0.34915259]\n",
      " [0.35688895]\n",
      " [0.36466247]\n",
      " [0.37247044]\n",
      " [0.38074568]\n",
      " [0.3898482 ]\n",
      " [0.39894027]\n",
      " [0.40756175]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7309453645768532\n",
      "Predicci√≥n : [[0.41659248]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[[0.34915259]\n",
      "  [0.35688895]\n",
      "  [0.36466247]\n",
      "  [0.37247044]\n",
      "  [0.38074568]\n",
      "  [0.3898482 ]\n",
      "  [0.39894027]\n",
      "  [0.40756175]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09881772845983505\n",
      "Predicci√≥n post entrenamiento : [[0.41964075]]\n",
      "PERDIDAAAA despues: 0.09691055119037628\n",
      "loss en el callback: 0.08078877627849579, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "ejemplar: [[0.35688895]\n",
      " [0.36466247]\n",
      " [0.37247044]\n",
      " [0.38074568]\n",
      " [0.3898482 ]\n",
      " [0.39894027]\n",
      " [0.40756175]\n",
      " [0.41659248]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7467210055914982\n",
      "Predicci√≥n : [[0.42592686]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[[0.35688895]\n",
      "  [0.36466247]\n",
      "  [0.37247044]\n",
      "  [0.38074568]\n",
      "  [0.3898482 ]\n",
      "  [0.39894027]\n",
      "  [0.40756175]\n",
      "  [0.41659248]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1029088944196701\n",
      "Predicci√≥n post entrenamiento : [[0.42920086]]\n",
      "PERDIDAAAA despues: 0.10081905871629715\n",
      "loss en el callback: 0.1251932680606842, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "ejemplar: [[0.36466247]\n",
      " [0.37247044]\n",
      " [0.38074568]\n",
      " [0.3898482 ]\n",
      " [0.39894027]\n",
      " [0.40756175]\n",
      " [0.41659248]\n",
      " [0.42592686]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7219286889593481\n",
      "Predicci√≥n : [[0.43567672]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[[0.36466247]\n",
      "  [0.37247044]\n",
      "  [0.38074568]\n",
      "  [0.3898482 ]\n",
      "  [0.39894027]\n",
      "  [0.40756175]\n",
      "  [0.41659248]\n",
      "  [0.42592686]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08194020390510559\n",
      "Predicci√≥n post entrenamiento : [[0.43825734]]\n",
      "PERDIDAAAA despues: 0.08046945184469223\n",
      "loss en el callback: 0.05792391300201416, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "ejemplar: [[0.37247044]\n",
      " [0.38074568]\n",
      " [0.3898482 ]\n",
      " [0.39894027]\n",
      " [0.40756175]\n",
      " [0.41659248]\n",
      " [0.42592686]\n",
      " [0.43567672]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7199286701160912\n",
      "Predicci√≥n : [[0.44496822]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[[0.37247044]\n",
      "  [0.38074568]\n",
      "  [0.3898482 ]\n",
      "  [0.39894027]\n",
      "  [0.40756175]\n",
      "  [0.41659248]\n",
      "  [0.42592686]\n",
      "  [0.43567672]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07560325413942337\n",
      "Predicci√≥n post entrenamiento : [[0.4476681]]\n",
      "PERDIDAAAA despues: 0.07412581890821457\n",
      "loss en el callback: 0.07914634793996811, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "ejemplar: [[0.38074568]\n",
      " [0.3898482 ]\n",
      " [0.39894027]\n",
      " [0.40756175]\n",
      " [0.41659248]\n",
      " [0.42592686]\n",
      " [0.43567672]\n",
      " [0.44496822]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7407209490617273\n",
      "Predicci√≥n : [[0.454665]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[[0.38074568]\n",
      "  [0.3898482 ]\n",
      "  [0.39894027]\n",
      "  [0.40756175]\n",
      "  [0.41659248]\n",
      "  [0.42592686]\n",
      "  [0.43567672]\n",
      "  [0.44496822]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08182799071073532\n",
      "Predicci√≥n post entrenamiento : [[0.45753482]]\n",
      "PERDIDAAAA despues: 0.0801943689584732\n",
      "loss en el callback: 0.10090431571006775, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "ejemplar: [[0.3898482 ]\n",
      " [0.39894027]\n",
      " [0.40756175]\n",
      " [0.41659248]\n",
      " [0.42592686]\n",
      " [0.43567672]\n",
      " [0.44496822]\n",
      " [0.45466501]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.736245501831604\n",
      "Predicci√≥n : [[0.46475837]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[[0.3898482 ]\n",
      "  [0.39894027]\n",
      "  [0.40756175]\n",
      "  [0.41659248]\n",
      "  [0.42592686]\n",
      "  [0.43567672]\n",
      "  [0.44496822]\n",
      "  [0.45466501]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0737052708864212\n",
      "Predicci√≥n post entrenamiento : [[0.46780792]]\n",
      "PERDIDAAAA despues: 0.07205874472856522\n",
      "loss en el callback: 0.12264909595251083, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "ejemplar: [[0.39894027]\n",
      " [0.40756175]\n",
      " [0.41659248]\n",
      " [0.42592686]\n",
      " [0.43567672]\n",
      " [0.44496822]\n",
      " [0.45466501]\n",
      " [0.46475837]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7065023284257214\n",
      "Predicci√≥n : [[0.4750915]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[[0.39894027]\n",
      "  [0.40756175]\n",
      "  [0.41659248]\n",
      "  [0.42592686]\n",
      "  [0.43567672]\n",
      "  [0.44496822]\n",
      "  [0.45466501]\n",
      "  [0.46475837]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.053550973534584045\n",
      "Predicci√≥n post entrenamiento : [[0.47761446]]\n",
      "PERDIDAAAA despues: 0.05238965153694153\n",
      "loss en el callback: 0.09003674238920212, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "ejemplar: [[0.40756175]\n",
      " [0.41659248]\n",
      " [0.42592686]\n",
      " [0.43567672]\n",
      " [0.44496822]\n",
      " [0.45466501]\n",
      " [0.46475837]\n",
      " [0.47509149]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6979451506854685\n",
      "Predicci√≥n : [[0.48498634]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[[0.40756175]\n",
      "  [0.41659248]\n",
      "  [0.42592686]\n",
      "  [0.43567672]\n",
      "  [0.44496822]\n",
      "  [0.45466501]\n",
      "  [0.46475837]\n",
      "  [0.47509149]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04535146802663803\n",
      "Predicci√≥n post entrenamiento : [[0.48720014]]\n",
      "PERDIDAAAA despues: 0.04441346973180771\n",
      "loss en el callback: 0.06089996173977852, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "ejemplar: [[0.41659248]\n",
      " [0.42592686]\n",
      " [0.43567672]\n",
      " [0.44496822]\n",
      " [0.45466501]\n",
      " [0.46475837]\n",
      " [0.47509149]\n",
      " [0.48498634]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7105739686108449\n",
      "Predicci√≥n : [[0.49481732]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[[0.41659248]\n",
      "  [0.42592686]\n",
      "  [0.43567672]\n",
      "  [0.44496822]\n",
      "  [0.45466501]\n",
      "  [0.46475837]\n",
      "  [0.47509149]\n",
      "  [0.48498634]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0465509332716465\n",
      "Predicci√≥n post entrenamiento : [[0.49738657]]\n",
      "PERDIDAAAA despues: 0.04544886574149132\n",
      "loss en el callback: 0.1320968121290207, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "ejemplar: [[0.42592686]\n",
      " [0.43567672]\n",
      " [0.44496822]\n",
      " [0.45466501]\n",
      " [0.46475837]\n",
      " [0.47509149]\n",
      " [0.48498634]\n",
      " [0.49481732]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7209621522504839\n",
      "Predicci√≥n : [[0.5051945]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[[0.42592686]\n",
      "  [0.43567672]\n",
      "  [0.44496822]\n",
      "  [0.45466501]\n",
      "  [0.46475837]\n",
      "  [0.47509149]\n",
      "  [0.48498634]\n",
      "  [0.49481732]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.046555694192647934\n",
      "Predicci√≥n post entrenamiento : [[0.50704974]]\n",
      "PERDIDAAAA despues: 0.045758526772260666\n",
      "loss en el callback: 0.0349358506500721, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "ejemplar: [[0.43567672]\n",
      " [0.44496822]\n",
      " [0.45466501]\n",
      " [0.46475837]\n",
      " [0.47509149]\n",
      " [0.48498634]\n",
      " [0.49481732]\n",
      " [0.50519449]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7291097016043858\n",
      "Predicci√≥n : [[0.51500636]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[[0.43567672]\n",
      "  [0.44496822]\n",
      "  [0.45466501]\n",
      "  [0.46475837]\n",
      "  [0.47509149]\n",
      "  [0.48498634]\n",
      "  [0.49481732]\n",
      "  [0.50519449]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04584024101495743\n",
      "Predicci√≥n post entrenamiento : [[0.51670694]]\n",
      "PERDIDAAAA despues: 0.04511493444442749\n",
      "loss en el callback: 0.03422671929001808, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "ejemplar: [[0.44496822]\n",
      " [0.45466501]\n",
      " [0.46475837]\n",
      " [0.47509149]\n",
      " [0.48498634]\n",
      " [0.49481732]\n",
      " [0.50519449]\n",
      " [0.51500636]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7674259644168786\n",
      "Predicci√≥n : [[0.52473044]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[[0.44496822]\n",
      "  [0.45466501]\n",
      "  [0.46475837]\n",
      "  [0.47509149]\n",
      "  [0.48498634]\n",
      "  [0.49481732]\n",
      "  [0.50519449]\n",
      "  [0.51500636]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0589011125266552\n",
      "Predicci√≥n post entrenamiento : [[0.52689475]]\n",
      "PERDIDAAAA despues: 0.057855259627103806\n",
      "loss en el callback: 0.05575999617576599, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "ejemplar: [[0.45466501]\n",
      " [0.46475837]\n",
      " [0.47509149]\n",
      " [0.48498634]\n",
      " [0.49481732]\n",
      " [0.50519449]\n",
      " [0.51500636]\n",
      " [0.52473044]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8359109406879621\n",
      "Predicci√≥n : [[0.5351202]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[[0.45466501]\n",
      "  [0.46475837]\n",
      "  [0.47509149]\n",
      "  [0.48498634]\n",
      "  [0.49481732]\n",
      "  [0.50519449]\n",
      "  [0.51500636]\n",
      "  [0.52473044]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09047506004571915\n",
      "Predicci√≥n post entrenamiento : [[0.5373825]]\n",
      "PERDIDAAAA despues: 0.08911922574043274\n",
      "loss en el callback: 0.05333820357918739, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "ejemplar: [[0.46475837]\n",
      " [0.47509149]\n",
      " [0.48498634]\n",
      " [0.49481732]\n",
      " [0.50519449]\n",
      " [0.51500636]\n",
      " [0.52473044]\n",
      " [0.53512019]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8510103358824123\n",
      "Predicci√≥n : [[0.54573023]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[[0.46475837]\n",
      "  [0.47509149]\n",
      "  [0.48498634]\n",
      "  [0.49481732]\n",
      "  [0.50519449]\n",
      "  [0.51500636]\n",
      "  [0.52473044]\n",
      "  [0.53512019]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09319593012332916\n",
      "Predicci√≥n post entrenamiento : [[0.5487062]]\n",
      "PERDIDAAAA despues: 0.0913878008723259\n",
      "loss en el callback: 0.11181295663118362, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "ejemplar: [[0.47509149]\n",
      " [0.48498634]\n",
      " [0.49481732]\n",
      " [0.50519449]\n",
      " [0.51500636]\n",
      " [0.52473044]\n",
      " [0.53512019]\n",
      " [0.54573023]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8127241500002294\n",
      "Predicci√≥n : [[0.55708593]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[[0.47509149]\n",
      "  [0.48498634]\n",
      "  [0.49481732]\n",
      "  [0.50519449]\n",
      "  [0.51500636]\n",
      "  [0.52473044]\n",
      "  [0.53512019]\n",
      "  [0.54573023]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06535091251134872\n",
      "Predicci√≥n post entrenamiento : [[0.55949205]]\n",
      "PERDIDAAAA despues: 0.06412650644779205\n",
      "loss en el callback: 0.07577989995479584, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "ejemplar: [[0.48498634]\n",
      " [0.49481732]\n",
      " [0.50519449]\n",
      " [0.51500636]\n",
      " [0.52473044]\n",
      " [0.53512019]\n",
      " [0.54573023]\n",
      " [0.55708593]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7863940290280375\n",
      "Predicci√≥n : [[0.56784624]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[[0.48498634]\n",
      "  [0.49481732]\n",
      "  [0.50519449]\n",
      "  [0.51500636]\n",
      "  [0.52473044]\n",
      "  [0.53512019]\n",
      "  [0.54573023]\n",
      "  [0.55708593]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.047763124108314514\n",
      "Predicci√≥n post entrenamiento : [[0.57034194]]\n",
      "PERDIDAAAA despues: 0.046678490936756134\n",
      "loss en el callback: 0.10415460169315338, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "ejemplar: [[0.49481732]\n",
      " [0.50519449]\n",
      " [0.51500636]\n",
      " [0.52473044]\n",
      " [0.53512019]\n",
      " [0.54573023]\n",
      " [0.55708593]\n",
      " [0.56784624]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7720199729658365\n",
      "Predicci√≥n : [[0.57879925]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[[0.49481732]\n",
      "  [0.50519449]\n",
      "  [0.51500636]\n",
      "  [0.52473044]\n",
      "  [0.53512019]\n",
      "  [0.54573023]\n",
      "  [0.55708593]\n",
      "  [0.56784624]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03733425214886665\n",
      "Predicci√≥n post entrenamiento : [[0.58039606]]\n",
      "PERDIDAAAA despues: 0.036719728261232376\n",
      "loss en el callback: 0.031472258269786835, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "ejemplar: [[0.50519449]\n",
      " [0.51500636]\n",
      " [0.52473044]\n",
      " [0.53512019]\n",
      " [0.54573023]\n",
      " [0.55708593]\n",
      " [0.56784624]\n",
      " [0.57879925]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8033170564228299\n",
      "Predicci√≥n : [[0.5890055]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[[0.50519449]\n",
      "  [0.51500636]\n",
      "  [0.52473044]\n",
      "  [0.53512019]\n",
      "  [0.54573023]\n",
      "  [0.55708593]\n",
      "  [0.56784624]\n",
      "  [0.57879925]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04592946171760559\n",
      "Predicci√≥n post entrenamiento : [[0.59118986]]\n",
      "PERDIDAAAA despues: 0.04499795287847519\n",
      "loss en el callback: 0.08982210606336594, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "ejemplar: [[0.51500636]\n",
      " [0.52473044]\n",
      " [0.53512019]\n",
      " [0.54573023]\n",
      " [0.55708593]\n",
      " [0.56784624]\n",
      " [0.57879925]\n",
      " [0.58900547]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8802852793990171\n",
      "Predicci√≥n : [[0.5998419]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[[0.51500636]\n",
      "  [0.52473044]\n",
      "  [0.53512019]\n",
      "  [0.54573023]\n",
      "  [0.55708593]\n",
      "  [0.56784624]\n",
      "  [0.57879925]\n",
      "  [0.58900547]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07864848524332047\n",
      "Predicci√≥n post entrenamiento : [[0.6025622]]\n",
      "PERDIDAAAA despues: 0.07713010907173157\n",
      "loss en el callback: 0.11852925270795822, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "ejemplar: [[0.52473044]\n",
      " [0.53512019]\n",
      " [0.54573023]\n",
      " [0.55708593]\n",
      " [0.56784624]\n",
      " [0.57879925]\n",
      " [0.58900547]\n",
      " [0.59984189]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8987051676996881\n",
      "Predicci√≥n : [[0.6114333]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[[0.52473044]\n",
      "  [0.53512019]\n",
      "  [0.54573023]\n",
      "  [0.55708593]\n",
      "  [0.56784624]\n",
      "  [0.57879925]\n",
      "  [0.58900547]\n",
      "  [0.59984189]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08252511918544769\n",
      "Predicci√≥n post entrenamiento : [[0.6136852]]\n",
      "PERDIDAAAA despues: 0.08123639971017838\n",
      "loss en el callback: 0.06700395792722702, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "ejemplar: [[0.53512019]\n",
      " [0.54573023]\n",
      " [0.55708593]\n",
      " [0.56784624]\n",
      " [0.57879925]\n",
      " [0.58900547]\n",
      " [0.59984189]\n",
      " [0.61143333]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8585767213248423\n",
      "Predicci√≥n : [[0.6228443]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[[0.53512019]\n",
      "  [0.54573023]\n",
      "  [0.55708593]\n",
      "  [0.56784624]\n",
      "  [0.57879925]\n",
      "  [0.58900547]\n",
      "  [0.59984189]\n",
      "  [0.61143333]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.055569782853126526\n",
      "Predicci√≥n post entrenamiento : [[0.6242472]]\n",
      "PERDIDAAAA despues: 0.0549103245139122\n",
      "loss en el callback: 0.022462010383605957, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "ejemplar: [[0.54573023]\n",
      " [0.55708593]\n",
      " [0.56784624]\n",
      " [0.57879925]\n",
      " [0.58900547]\n",
      " [0.59984189]\n",
      " [0.61143333]\n",
      " [0.62284428]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8308762565987861\n",
      "Predicci√≥n : [[0.6335577]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[[0.54573023]\n",
      "  [0.55708593]\n",
      "  [0.56784624]\n",
      "  [0.57879925]\n",
      "  [0.58900547]\n",
      "  [0.59984189]\n",
      "  [0.61143333]\n",
      "  [0.62284428]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0389346107840538\n",
      "Predicci√≥n post entrenamiento : [[0.6351401]]\n",
      "PERDIDAAAA despues: 0.038312625139951706\n",
      "loss en el callback: 0.040888115763664246, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "ejemplar: [[0.55708593]\n",
      " [0.56784624]\n",
      " [0.57879925]\n",
      " [0.58900547]\n",
      " [0.59984189]\n",
      " [0.61143333]\n",
      " [0.62284428]\n",
      " [0.63355768]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8156037735215196\n",
      "Predicci√≥n : [[0.64456534]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[[0.55708593]\n",
      "  [0.56784624]\n",
      "  [0.57879925]\n",
      "  [0.58900547]\n",
      "  [0.59984189]\n",
      "  [0.61143333]\n",
      "  [0.62284428]\n",
      "  [0.63355768]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02925415150821209\n",
      "Predicci√≥n post entrenamiento : [[0.6457646]]\n",
      "PERDIDAAAA despues: 0.028845354914665222\n",
      "loss en el callback: 0.01666850969195366, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "ejemplar: [[0.56784624]\n",
      " [0.57879925]\n",
      " [0.58900547]\n",
      " [0.59984189]\n",
      " [0.61143333]\n",
      " [0.62284428]\n",
      " [0.63355768]\n",
      " [0.64456534]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8116992058331503\n",
      "Predicci√≥n : [[0.6551099]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[[0.56784624]\n",
      "  [0.57879925]\n",
      "  [0.58900547]\n",
      "  [0.59984189]\n",
      "  [0.61143333]\n",
      "  [0.62284428]\n",
      "  [0.63355768]\n",
      "  [0.64456534]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02452021837234497\n",
      "Predicci√≥n post entrenamiento : [[0.65659326]]\n",
      "PERDIDAAAA despues: 0.02405785582959652\n",
      "loss en el callback: 0.03368609398603439, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "ejemplar: [[0.57879925]\n",
      " [0.58900547]\n",
      " [0.59984189]\n",
      " [0.61143333]\n",
      " [0.62284428]\n",
      " [0.63355768]\n",
      " [0.64456534]\n",
      " [0.65510988]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8191625535336788\n",
      "Predicci√≥n : [[0.6660133]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[[0.57879925]\n",
      "  [0.58900547]\n",
      "  [0.59984189]\n",
      "  [0.61143333]\n",
      "  [0.62284428]\n",
      "  [0.63355768]\n",
      "  [0.64456534]\n",
      "  [0.65510988]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0234546922147274\n",
      "Predicci√≥n post entrenamiento : [[0.6676205]]\n",
      "PERDIDAAAA despues: 0.022964999079704285\n",
      "loss en el callback: 0.042115289717912674, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "ejemplar: [[0.58900547]\n",
      " [0.59984189]\n",
      " [0.61143333]\n",
      " [0.62284428]\n",
      " [0.63355768]\n",
      " [0.64456534]\n",
      " [0.65510988]\n",
      " [0.6660133 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8218275636038536\n",
      "Predicci√≥n : [[0.6770696]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[[0.58900547]\n",
      "  [0.59984189]\n",
      "  [0.61143333]\n",
      "  [0.62284428]\n",
      "  [0.63355768]\n",
      "  [0.64456534]\n",
      "  [0.65510988]\n",
      "  [0.6660133 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.020954875275492668\n",
      "Predicci√≥n post entrenamiento : [[0.6788252]]\n",
      "PERDIDAAAA despues: 0.0204496830701828\n",
      "loss en el callback: 0.05405667424201965, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "ejemplar: [[0.59984189]\n",
      " [0.61143333]\n",
      " [0.62284428]\n",
      " [0.63355768]\n",
      " [0.64456534]\n",
      " [0.65510988]\n",
      " [0.6660133 ]\n",
      " [0.6770696 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8196942360436743\n",
      "Predicci√≥n : [[0.68851477]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[[0.59984189]\n",
      "  [0.61143333]\n",
      "  [0.62284428]\n",
      "  [0.63355768]\n",
      "  [0.64456534]\n",
      "  [0.65510988]\n",
      "  [0.6660133 ]\n",
      "  [0.6770696 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017208049073815346\n",
      "Predicci√≥n post entrenamiento : [[0.68887985]]\n",
      "PERDIDAAAA despues: 0.017112400382757187\n",
      "loss en el callback: 0.0015564756467938423, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "ejemplar: [[0.61143333]\n",
      " [0.62284428]\n",
      " [0.63355768]\n",
      " [0.64456534]\n",
      " [0.65510988]\n",
      " [0.6660133 ]\n",
      " [0.6770696 ]\n",
      " [0.68851477]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8178628420548653\n",
      "Predicci√≥n : [[0.69865465]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[[0.61143333]\n",
      "  [0.62284428]\n",
      "  [0.63355768]\n",
      "  [0.64456534]\n",
      "  [0.65510988]\n",
      "  [0.6660133 ]\n",
      "  [0.6770696 ]\n",
      "  [0.68851477]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014210598543286324\n",
      "Predicci√≥n post entrenamiento : [[0.6999323]]\n",
      "PERDIDAAAA despues: 0.013907624408602715\n",
      "loss en el callback: 0.02869558520615101, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "ejemplar: [[0.62284428]\n",
      " [0.63355768]\n",
      " [0.64456534]\n",
      " [0.65510988]\n",
      " [0.6660133 ]\n",
      " [0.6770696 ]\n",
      " [0.68851477]\n",
      " [0.69865465]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8163333816374257\n",
      "Predicci√≥n : [[0.709578]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[[0.62284428]\n",
      "  [0.63355768]\n",
      "  [0.64456534]\n",
      "  [0.65510988]\n",
      "  [0.6660133 ]\n",
      "  [0.6770696 ]\n",
      "  [0.68851477]\n",
      "  [0.69865465]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011396709829568863\n",
      "Predicci√≥n post entrenamiento : [[0.7105595]]\n",
      "PERDIDAAAA despues: 0.011188110336661339\n",
      "loss en el callback: 0.015609312802553177, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "ejemplar: [[0.63355768]\n",
      " [0.64456534]\n",
      " [0.65510988]\n",
      " [0.6660133 ]\n",
      " [0.6770696 ]\n",
      " [0.68851477]\n",
      " [0.69865465]\n",
      " [0.70957798]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8005556061309519\n",
      "Predicci√≥n : [[0.7200949]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[[0.63355768]\n",
      "  [0.64456534]\n",
      "  [0.65510988]\n",
      "  [0.6660133 ]\n",
      "  [0.6770696 ]\n",
      "  [0.68851477]\n",
      "  [0.69865465]\n",
      "  [0.70957798]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006473918911069632\n",
      "Predicci√≥n post entrenamiento : [[0.7203185]]\n",
      "PERDIDAAAA despues: 0.006437990814447403\n",
      "loss en el callback: 0.0006789178005419672, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "ejemplar: [[0.64456534]\n",
      " [0.65510988]\n",
      " [0.6660133 ]\n",
      " [0.6770696 ]\n",
      " [0.68851477]\n",
      " [0.69865465]\n",
      " [0.70957798]\n",
      " [0.72009492]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7705295155354442\n",
      "Predicci√≥n : [[0.7299163]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[[0.64456534]\n",
      "  [0.65510988]\n",
      "  [0.6660133 ]\n",
      "  [0.6770696 ]\n",
      "  [0.68851477]\n",
      "  [0.69865465]\n",
      "  [0.70957798]\n",
      "  [0.72009492]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016494347946718335\n",
      "Predicci√≥n post entrenamiento : [[0.7297482]]\n",
      "PERDIDAAAA despues: 0.0016631160397082567\n",
      "loss en el callback: 0.00038141151890158653, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "ejemplar: [[0.65510988]\n",
      " [0.6660133 ]\n",
      " [0.6770696 ]\n",
      " [0.68851477]\n",
      " [0.69865465]\n",
      " [0.70957798]\n",
      " [0.72009492]\n",
      " [0.72991627]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7426586795525351\n",
      "Predicci√≥n : [[0.73931694]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[[0.65510988]\n",
      "  [0.6660133 ]\n",
      "  [0.6770696 ]\n",
      "  [0.68851477]\n",
      "  [0.69865465]\n",
      "  [0.70957798]\n",
      "  [0.72009492]\n",
      "  [0.72991627]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.1167188858962618e-05\n",
      "Predicci√≥n post entrenamiento : [[0.73898315]]\n",
      "PERDIDAAAA despues: 1.3509450582205318e-05\n",
      "loss en el callback: 0.0015370238106697798, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "ejemplar: [[0.6660133 ]\n",
      " [0.6770696 ]\n",
      " [0.68851477]\n",
      " [0.69865465]\n",
      " [0.70957798]\n",
      " [0.72009492]\n",
      " [0.72991627]\n",
      " [0.73931694]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.716943098182225\n",
      "Predicci√≥n : [[0.7486267]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[[0.6660133 ]\n",
      "  [0.6770696 ]\n",
      "  [0.68851477]\n",
      "  [0.69865465]\n",
      "  [0.70957798]\n",
      "  [0.72009492]\n",
      "  [0.72991627]\n",
      "  [0.73931694]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001003851997666061\n",
      "Predicci√≥n post entrenamiento : [[0.749087]]\n",
      "PERDIDAAAA despues: 0.0010332297533750534\n",
      "loss en el callback: 0.004072430077940226, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "ejemplar: [[0.6770696 ]\n",
      " [0.68851477]\n",
      " [0.69865465]\n",
      " [0.70957798]\n",
      " [0.72009492]\n",
      " [0.72991627]\n",
      " [0.73931694]\n",
      " [0.74862671]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7197051306082382\n",
      "Predicci√≥n : [[0.7586791]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[[0.6770696 ]\n",
      "  [0.68851477]\n",
      "  [0.69865465]\n",
      "  [0.70957798]\n",
      "  [0.72009492]\n",
      "  [0.72991627]\n",
      "  [0.73931694]\n",
      "  [0.74862671]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015189716359600425\n",
      "Predicci√≥n post entrenamiento : [[0.7589413]]\n",
      "PERDIDAAAA despues: 0.0015394784277305007\n",
      "loss en el callback: 0.0013102275552228093, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "ejemplar: [[0.68851477]\n",
      " [0.69865465]\n",
      " [0.70957798]\n",
      " [0.72009492]\n",
      " [0.72991627]\n",
      " [0.73931694]\n",
      " [0.74862671]\n",
      " [0.75867909]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7509447768305747\n",
      "Predicci√≥n : [[0.76838773]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[[0.68851477]\n",
      "  [0.69865465]\n",
      "  [0.70957798]\n",
      "  [0.72009492]\n",
      "  [0.72991627]\n",
      "  [0.73931694]\n",
      "  [0.74862671]\n",
      "  [0.75867909]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00030425621662288904\n",
      "Predicci√≥n post entrenamiento : [[0.76817983]]\n",
      "PERDIDAAAA despues: 0.00029704661574214697\n",
      "loss en el callback: 0.0006830085185356438, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "ejemplar: [[0.69865465]\n",
      " [0.70957798]\n",
      " [0.72009492]\n",
      " [0.72991627]\n",
      " [0.73931694]\n",
      " [0.74862671]\n",
      " [0.75867909]\n",
      " [0.76838773]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.740278139029679\n",
      "Predicci√≥n : [[0.77730596]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[[0.69865465]\n",
      "  [0.70957798]\n",
      "  [0.72009492]\n",
      "  [0.72991627]\n",
      "  [0.73931694]\n",
      "  [0.74862671]\n",
      "  [0.75867909]\n",
      "  [0.76838773]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013710606144741178\n",
      "Predicci√≥n post entrenamiento : [[0.7766928]]\n",
      "PERDIDAAAA despues: 0.0013260290725156665\n",
      "loss en el callback: 0.005557636264711618, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "ejemplar: [[0.70957798]\n",
      " [0.72009492]\n",
      " [0.72991627]\n",
      " [0.73931694]\n",
      " [0.74862671]\n",
      " [0.75867909]\n",
      " [0.76838773]\n",
      " [0.77730596]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.687705217205551\n",
      "Predicci√≥n : [[0.7857955]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[[0.70957798]\n",
      "  [0.72009492]\n",
      "  [0.72991627]\n",
      "  [0.73931694]\n",
      "  [0.74862671]\n",
      "  [0.75867909]\n",
      "  [0.76838773]\n",
      "  [0.77730596]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009621704928576946\n",
      "Predicci√≥n post entrenamiento : [[0.7859179]]\n",
      "PERDIDAAAA despues: 0.009645726531744003\n",
      "loss en el callback: 0.00031579803908243775, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "ejemplar: [[0.72009492]\n",
      " [0.72991627]\n",
      " [0.73931694]\n",
      " [0.74862671]\n",
      " [0.75867909]\n",
      " [0.76838773]\n",
      " [0.77730596]\n",
      " [0.78579551]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6687695580612426\n",
      "Predicci√≥n : [[0.7947319]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[[0.72009492]\n",
      "  [0.72991627]\n",
      "  [0.73931694]\n",
      "  [0.74862671]\n",
      "  [0.75867909]\n",
      "  [0.76838773]\n",
      "  [0.77730596]\n",
      "  [0.78579551]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015866519883275032\n",
      "Predicci√≥n post entrenamiento : [[0.7943118]]\n",
      "PERDIDAAAA despues: 0.015760865062475204\n",
      "loss en el callback: 0.00305352290160954, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "ejemplar: [[0.72991627]\n",
      " [0.73931694]\n",
      " [0.74862671]\n",
      " [0.75867909]\n",
      " [0.76838773]\n",
      " [0.77730596]\n",
      " [0.78579551]\n",
      " [0.79473191]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6834711615967536\n",
      "Predicci√≥n : [[0.8028783]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[[0.72991627]\n",
      "  [0.73931694]\n",
      "  [0.74862671]\n",
      "  [0.75867909]\n",
      "  [0.76838773]\n",
      "  [0.77730596]\n",
      "  [0.78579551]\n",
      "  [0.79473191]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014258073642849922\n",
      "Predicci√≥n post entrenamiento : [[0.80198795]]\n",
      "PERDIDAAAA despues: 0.014046232216060162\n",
      "loss en el callback: 0.013347294181585312, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "ejemplar: [[0.73931694]\n",
      " [0.74862671]\n",
      " [0.75867909]\n",
      " [0.76838773]\n",
      " [0.77730596]\n",
      " [0.78579551]\n",
      " [0.79473191]\n",
      " [0.80287832]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6877052172055499\n",
      "Predicci√≥n : [[0.81044143]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[[0.73931694]\n",
      "  [0.74862671]\n",
      "  [0.75867909]\n",
      "  [0.76838773]\n",
      "  [0.77730596]\n",
      "  [0.78579551]\n",
      "  [0.79473191]\n",
      "  [0.80287832]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015064178965985775\n",
      "Predicci√≥n post entrenamiento : [[0.8100173]]\n",
      "PERDIDAAAA despues: 0.014960242435336113\n",
      "loss en el callback: 0.0035959603264927864, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "ejemplar: [[0.74862671]\n",
      " [0.75867909]\n",
      " [0.76838773]\n",
      " [0.77730596]\n",
      " [0.78579551]\n",
      " [0.79473191]\n",
      " [0.80287832]\n",
      " [0.81044143]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6814717248876317\n",
      "Predicci√≥n : [[0.8184287]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[[0.74862671]\n",
      "  [0.75867909]\n",
      "  [0.76838773]\n",
      "  [0.77730596]\n",
      "  [0.78579551]\n",
      "  [0.79473191]\n",
      "  [0.80287832]\n",
      "  [0.81044143]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01875721663236618\n",
      "Predicci√≥n post entrenamiento : [[0.8169648]]\n",
      "PERDIDAAAA despues: 0.01835837960243225\n",
      "loss en el callback: 0.03166332468390465, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "ejemplar: [[0.75867909]\n",
      " [0.76838773]\n",
      " [0.77730596]\n",
      " [0.78579551]\n",
      " [0.79473191]\n",
      " [0.80287832]\n",
      " [0.81044143]\n",
      " [0.8184287 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.689261843882625\n",
      "Predicci√≥n : [[0.8253067]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[[0.75867909]\n",
      "  [0.76838773]\n",
      "  [0.77730596]\n",
      "  [0.78579551]\n",
      "  [0.79473191]\n",
      "  [0.80287832]\n",
      "  [0.81044143]\n",
      "  [0.8184287 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018508203327655792\n",
      "Predicci√≥n post entrenamiento : [[0.8257847]]\n",
      "PERDIDAAAA despues: 0.018638482317328453\n",
      "loss en el callback: 0.007383696734905243, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "ejemplar: [[0.76838773]\n",
      " [0.77730596]\n",
      " [0.78579551]\n",
      " [0.79473191]\n",
      " [0.80287832]\n",
      " [0.81044143]\n",
      " [0.8184287 ]\n",
      " [0.82530671]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7110755741905297\n",
      "Predicci√≥n : [[0.8337802]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[[0.76838773]\n",
      "  [0.77730596]\n",
      "  [0.78579551]\n",
      "  [0.79473191]\n",
      "  [0.80287832]\n",
      "  [0.81044143]\n",
      "  [0.8184287 ]\n",
      "  [0.82530671]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015056424774229527\n",
      "Predicci√≥n post entrenamiento : [[0.8320732]]\n",
      "PERDIDAAAA despues: 0.01464042067527771\n",
      "loss en el callback: 0.04568572714924812, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "ejemplar: [[0.77730596]\n",
      " [0.78579551]\n",
      " [0.79473191]\n",
      " [0.80287832]\n",
      " [0.81044143]\n",
      " [0.8184287 ]\n",
      " [0.82530671]\n",
      " [0.83378023]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7349108623046875\n",
      "Predicci√≥n : [[0.83971965]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[[0.77730596]\n",
      "  [0.78579551]\n",
      "  [0.79473191]\n",
      "  [0.80287832]\n",
      "  [0.81044143]\n",
      "  [0.8184287 ]\n",
      "  [0.82530671]\n",
      "  [0.83378023]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010984886437654495\n",
      "Predicci√≥n post entrenamiento : [[0.8388168]]\n",
      "PERDIDAAAA despues: 0.010796451941132545\n",
      "loss en el callback: 0.014254258945584297, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "ejemplar: [[0.78579551]\n",
      " [0.79473191]\n",
      " [0.80287832]\n",
      " [0.81044143]\n",
      " [0.8184287 ]\n",
      " [0.82530671]\n",
      " [0.83378023]\n",
      " [0.83971965]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7607677082250986\n",
      "Predicci√≥n : [[0.8462548]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[[0.78579551]\n",
      "  [0.79473191]\n",
      "  [0.80287832]\n",
      "  [0.81044143]\n",
      "  [0.8184287 ]\n",
      "  [0.82530671]\n",
      "  [0.83378023]\n",
      "  [0.83971965]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007308049127459526\n",
      "Predicci√≥n post entrenamiento : [[0.8443819]]\n",
      "PERDIDAAAA despues: 0.006991339381784201\n",
      "loss en el callback: 0.0511501207947731, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "ejemplar: [[0.79473191]\n",
      " [0.80287832]\n",
      " [0.81044143]\n",
      " [0.8184287 ]\n",
      " [0.82530671]\n",
      " [0.83378023]\n",
      " [0.83971965]\n",
      " [0.84625483]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7711170829224028\n",
      "Predicci√≥n : [[0.8516586]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[[0.79473191]\n",
      "  [0.80287832]\n",
      "  [0.81044143]\n",
      "  [0.8184287 ]\n",
      "  [0.82530671]\n",
      "  [0.83378023]\n",
      "  [0.83971965]\n",
      "  [0.84625483]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006486931815743446\n",
      "Predicci√≥n post entrenamiento : [[0.8511427]]\n",
      "PERDIDAAAA despues: 0.006404098588973284\n",
      "loss en el callback: 0.0046042525209486485, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "ejemplar: [[0.80287832]\n",
      " [0.81044143]\n",
      " [0.8184287 ]\n",
      " [0.82530671]\n",
      " [0.83378023]\n",
      " [0.83971965]\n",
      " [0.84625483]\n",
      " [0.85165858]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7659589863965997\n",
      "Predicci√≥n : [[0.8580534]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[[0.80287832]\n",
      "  [0.81044143]\n",
      "  [0.8184287 ]\n",
      "  [0.82530671]\n",
      "  [0.83378023]\n",
      "  [0.83971965]\n",
      "  [0.84625483]\n",
      "  [0.85165858]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008481382392346859\n",
      "Predicci√≥n post entrenamiento : [[0.857417]]\n",
      "PERDIDAAAA despues: 0.008364570327103138\n",
      "loss en el callback: 0.008095200173556805, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "ejemplar: [[0.81044143]\n",
      " [0.8184287 ]\n",
      " [0.82530671]\n",
      " [0.83378023]\n",
      " [0.83971965]\n",
      " [0.84625483]\n",
      " [0.85165858]\n",
      " [0.85805339]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7483323528772654\n",
      "Predicci√≥n : [[0.8640897]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[[0.81044143]\n",
      "  [0.8184287 ]\n",
      "  [0.82530671]\n",
      "  [0.83378023]\n",
      "  [0.83971965]\n",
      "  [0.84625483]\n",
      "  [0.85165858]\n",
      "  [0.85805339]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013399763032793999\n",
      "Predicci√≥n post entrenamiento : [[0.8622437]]\n",
      "PERDIDAAAA despues: 0.012975791469216347\n",
      "loss en el callback: 0.04982708394527435, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "ejemplar: [[0.8184287 ]\n",
      " [0.82530671]\n",
      " [0.83378023]\n",
      " [0.83971965]\n",
      " [0.84625483]\n",
      " [0.85165858]\n",
      " [0.85805339]\n",
      " [0.86408973]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7182371823643998\n",
      "Predicci√≥n : [[0.8687642]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[[0.8184287 ]\n",
      "  [0.82530671]\n",
      "  [0.83378023]\n",
      "  [0.83971965]\n",
      "  [0.84625483]\n",
      "  [0.85165858]\n",
      "  [0.85805339]\n",
      "  [0.86408973]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022658396512269974\n",
      "Predicci√≥n post entrenamiento : [[0.8677346]]\n",
      "PERDIDAAAA despues: 0.022349487990140915\n",
      "loss en el callback: 0.020787270739674568, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "ejemplar: [[0.82530671]\n",
      " [0.83378023]\n",
      " [0.83971965]\n",
      " [0.84625483]\n",
      " [0.85165858]\n",
      " [0.85805339]\n",
      " [0.86408973]\n",
      " [0.86876422]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7089416644962148\n",
      "Predicci√≥n : [[0.8739048]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[[0.82530671]\n",
      "  [0.83378023]\n",
      "  [0.83971965]\n",
      "  [0.84625483]\n",
      "  [0.85165858]\n",
      "  [0.85805339]\n",
      "  [0.86408973]\n",
      "  [0.86876422]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.027212852612137794\n",
      "Predicci√≥n post entrenamiento : [[0.87362117]]\n",
      "PERDIDAAAA despues: 0.02711934596300125\n",
      "loss en el callback: 0.0019202467519789934, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "ejemplar: [[0.83378023]\n",
      " [0.83971965]\n",
      " [0.84625483]\n",
      " [0.85165858]\n",
      " [0.85805339]\n",
      " [0.86408973]\n",
      " [0.86876422]\n",
      " [0.87390482]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7204457992727099\n",
      "Predicci√≥n : [[0.87966496]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[[0.83378023]\n",
      "  [0.83971965]\n",
      "  [0.84625483]\n",
      "  [0.85165858]\n",
      "  [0.85805339]\n",
      "  [0.86408973]\n",
      "  [0.86876422]\n",
      "  [0.87390482]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02535073645412922\n",
      "Predicci√≥n post entrenamiento : [[0.87862635]]\n",
      "PERDIDAAAA despues: 0.025021081790328026\n",
      "loss en el callback: 0.02092718705534935, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "ejemplar: [[0.83971965]\n",
      " [0.84625483]\n",
      " [0.85165858]\n",
      " [0.85805339]\n",
      " [0.86408973]\n",
      " [0.86876422]\n",
      " [0.87390482]\n",
      " [0.87966496]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.770615477342717\n",
      "Predicci√≥n : [[0.8840059]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[[0.83971965]\n",
      "  [0.84625483]\n",
      "  [0.85165858]\n",
      "  [0.85805339]\n",
      "  [0.86408973]\n",
      "  [0.86876422]\n",
      "  [0.87390482]\n",
      "  [0.87966496]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012857393361628056\n",
      "Predicci√≥n post entrenamiento : [[0.88300025]]\n",
      "PERDIDAAAA despues: 0.01263034250587225\n",
      "loss en el callback: 0.017477912828326225, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "ejemplar: [[0.84625483]\n",
      " [0.85165858]\n",
      " [0.85805339]\n",
      " [0.86408973]\n",
      " [0.86876422]\n",
      " [0.87390482]\n",
      " [0.87966496]\n",
      " [0.8840059 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8594506987062355\n",
      "Predicci√≥n : [[0.88833195]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[[0.84625483]\n",
      "  [0.85165858]\n",
      "  [0.85805339]\n",
      "  [0.86408973]\n",
      "  [0.86876422]\n",
      "  [0.87390482]\n",
      "  [0.87966496]\n",
      "  [0.8840059 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008341267239302397\n",
      "Predicci√≥n post entrenamiento : [[0.8877293]]\n",
      "PERDIDAAAA despues: 0.0007996786152943969\n",
      "loss en el callback: 0.006256397347897291, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "ejemplar: [[0.85165858]\n",
      " [0.85805339]\n",
      " [0.86408973]\n",
      " [0.86876422]\n",
      " [0.87390482]\n",
      " [0.87966496]\n",
      " [0.8840059 ]\n",
      " [0.88833195]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9065410812466371\n",
      "Predicci√≥n : [[0.8927956]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[[0.85165858]\n",
      "  [0.85805339]\n",
      "  [0.86408973]\n",
      "  [0.86876422]\n",
      "  [0.87390482]\n",
      "  [0.87966496]\n",
      "  [0.8840059 ]\n",
      "  [0.88833195]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00018893840024247766\n",
      "Predicci√≥n post entrenamiento : [[0.8932311]]\n",
      "PERDIDAAAA despues: 0.00017715650028549135\n",
      "loss en el callback: 0.004427341744303703, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "ejemplar: [[0.85805339]\n",
      " [0.86408973]\n",
      " [0.86876422]\n",
      " [0.87390482]\n",
      " [0.87966496]\n",
      " [0.8840059 ]\n",
      " [0.88833195]\n",
      " [0.89279562]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9118866249639219\n",
      "Predicci√≥n : [[0.8982931]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[[0.85805339]\n",
      "  [0.86408973]\n",
      "  [0.86876422]\n",
      "  [0.87390482]\n",
      "  [0.87966496]\n",
      "  [0.8840059 ]\n",
      "  [0.88833195]\n",
      "  [0.89279562]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00018478473066352308\n",
      "Predicci√≥n post entrenamiento : [[0.89689046]]\n",
      "PERDIDAAAA despues: 0.00022488513786811382\n",
      "loss en el callback: 0.028102340176701546, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "ejemplar: [[0.86408973]\n",
      " [0.86876422]\n",
      " [0.87390482]\n",
      " [0.87966496]\n",
      " [0.8840059 ]\n",
      " [0.88833195]\n",
      " [0.89279562]\n",
      " [0.89829308]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.904335569053715\n",
      "Predicci√≥n : [[0.9016199]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[[0.86408973]\n",
      "  [0.86876422]\n",
      "  [0.87390482]\n",
      "  [0.87966496]\n",
      "  [0.8840059 ]\n",
      "  [0.88833195]\n",
      "  [0.89279562]\n",
      "  [0.89829308]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.374739652732387e-06\n",
      "Predicci√≥n post entrenamiento : [[0.901645]]\n",
      "PERDIDAAAA despues: 7.239078968268586e-06\n",
      "loss en el callback: 1.2300011803745292e-05, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "ejemplar: [[0.86876422]\n",
      " [0.87390482]\n",
      " [0.87966496]\n",
      " [0.8840059 ]\n",
      " [0.88833195]\n",
      " [0.89279562]\n",
      " [0.89829308]\n",
      " [0.90161991]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8838879135160167\n",
      "Predicci√≥n : [[0.90607226]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[[0.86876422]\n",
      "  [0.87390482]\n",
      "  [0.87966496]\n",
      "  [0.8840059 ]\n",
      "  [0.88833195]\n",
      "  [0.89279562]\n",
      "  [0.89829308]\n",
      "  [0.90161991]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004921463550999761\n",
      "Predicci√≥n post entrenamiento : [[0.9054322]]\n",
      "PERDIDAAAA despues: 0.00046415848191827536\n",
      "loss en el callback: 0.006929339375346899, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "ejemplar: [[0.87390482]\n",
      " [0.87966496]\n",
      " [0.8840059 ]\n",
      " [0.88833195]\n",
      " [0.89279562]\n",
      " [0.89829308]\n",
      " [0.90161991]\n",
      " [0.90607226]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9032153489332012\n",
      "Predicci√≥n : [[0.9098931]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[[0.87390482]\n",
      "  [0.87966496]\n",
      "  [0.8840059 ]\n",
      "  [0.88833195]\n",
      "  [0.89279562]\n",
      "  [0.89829308]\n",
      "  [0.90161991]\n",
      "  [0.90607226]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.459230331121944e-05\n",
      "Predicci√≥n post entrenamiento : [[0.90977865]]\n",
      "PERDIDAAAA despues: 4.307698327465914e-05\n",
      "loss en el callback: 0.0002591290685813874, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "ejemplar: [[0.87966496]\n",
      " [0.8840059 ]\n",
      " [0.88833195]\n",
      " [0.89279562]\n",
      " [0.89829308]\n",
      " [0.90161991]\n",
      " [0.90607226]\n",
      " [0.9098931 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9623178753052692\n",
      "Predicci√≥n : [[0.9141154]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[[0.87966496]\n",
      "  [0.8840059 ]\n",
      "  [0.88833195]\n",
      "  [0.89279562]\n",
      "  [0.89829308]\n",
      "  [0.90161991]\n",
      "  [0.90607226]\n",
      "  [0.9098931 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0023234765976667404\n",
      "Predicci√≥n post entrenamiento : [[0.9150207]]\n",
      "PERDIDAAAA despues: 0.0022370233200490475\n",
      "loss en el callback: 0.020981665700674057, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "ejemplar: [[0.8840059 ]\n",
      " [0.88833195]\n",
      " [0.89279562]\n",
      " [0.89829308]\n",
      " [0.90161991]\n",
      " [0.90607226]\n",
      " [0.9098931 ]\n",
      " [0.91411543]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.982058820003038\n",
      "Predicci√≥n : [[0.91900855]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[[0.8840059 ]\n",
      "  [0.88833195]\n",
      "  [0.89279562]\n",
      "  [0.89829308]\n",
      "  [0.90161991]\n",
      "  [0.90607226]\n",
      "  [0.9098931 ]\n",
      "  [0.91411543]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003975336439907551\n",
      "Predicci√≥n post entrenamiento : [[0.92002314]]\n",
      "PERDIDAAAA despues: 0.003848425578325987\n",
      "loss en el callback: 0.026229480281472206, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "ejemplar: [[0.88833195]\n",
      " [0.89279562]\n",
      " [0.89829308]\n",
      " [0.90161991]\n",
      " [0.90607226]\n",
      " [0.9098931 ]\n",
      " [0.91411543]\n",
      " [0.91900855]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9624381830265082\n",
      "Predicci√≥n : [[0.92402196]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[[0.88833195]\n",
      "  [0.89279562]\n",
      "  [0.89829308]\n",
      "  [0.90161991]\n",
      "  [0.90607226]\n",
      "  [0.9098931 ]\n",
      "  [0.91411543]\n",
      "  [0.91900855]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014758049510419369\n",
      "Predicci√≥n post entrenamiento : [[0.92378986]]\n",
      "PERDIDAAAA despues: 0.001493691699579358\n",
      "loss en el callback: 0.0009520052699372172, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "ejemplar: [[0.89279562]\n",
      " [0.89829308]\n",
      " [0.90161991]\n",
      " [0.90607226]\n",
      " [0.9098931 ]\n",
      " [0.91411543]\n",
      " [0.91900855]\n",
      " [0.92402196]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9302512105217627\n",
      "Predicci√≥n : [[0.92780197]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[[0.89279562]\n",
      "  [0.89829308]\n",
      "  [0.90161991]\n",
      "  [0.90607226]\n",
      "  [0.9098931 ]\n",
      "  [0.91411543]\n",
      "  [0.91900855]\n",
      "  [0.92402196]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.9986514315824024e-06\n",
      "Predicci√≥n post entrenamiento : [[0.9285317]]\n",
      "PERDIDAAAA despues: 2.956593561975751e-06\n",
      "loss en el callback: 0.015414046123623848, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "ejemplar: [[0.89829308]\n",
      " [0.90161991]\n",
      " [0.90607226]\n",
      " [0.9098931 ]\n",
      " [0.91411543]\n",
      " [0.91900855]\n",
      " [0.92402196]\n",
      " [0.92780197]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.885497902488802\n",
      "Predicci√≥n : [[0.9325171]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[[0.89829308]\n",
      "  [0.90161991]\n",
      "  [0.90607226]\n",
      "  [0.9098931 ]\n",
      "  [0.91411543]\n",
      "  [0.91900855]\n",
      "  [0.92402196]\n",
      "  [0.92780197]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0022108035627752542\n",
      "Predicci√≥n post entrenamiento : [[0.9329974]]\n",
      "PERDIDAAAA despues: 0.0022562004160135984\n",
      "loss en el callback: 0.006599598564207554, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "ejemplar: [[0.90161991]\n",
      " [0.90607226]\n",
      " [0.9098931 ]\n",
      " [0.91411543]\n",
      " [0.91900855]\n",
      " [0.92402196]\n",
      " [0.92780197]\n",
      " [0.93251711]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597025687419927\n",
      "Predicci√≥n : [[0.93664795]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[[0.90161991]\n",
      "  [0.90607226]\n",
      "  [0.9098931 ]\n",
      "  [0.91411543]\n",
      "  [0.91900855]\n",
      "  [0.92402196]\n",
      "  [0.92780197]\n",
      "  [0.93251711]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005920588970184326\n",
      "Predicci√≥n post entrenamiento : [[0.9354238]]\n",
      "PERDIDAAAA despues: 0.005733700934797525\n",
      "loss en el callback: 0.02727922424674034, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "ejemplar: [[0.90607226]\n",
      " [0.9098931 ]\n",
      " [0.91411543]\n",
      " [0.91900855]\n",
      " [0.92402196]\n",
      " [0.92780197]\n",
      " [0.93251711]\n",
      " [0.93664795]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8528652092813349\n",
      "Predicci√≥n : [[0.9393437]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[[0.90607226]\n",
      "  [0.9098931 ]\n",
      "  [0.91411543]\n",
      "  [0.91900855]\n",
      "  [0.92402196]\n",
      "  [0.92780197]\n",
      "  [0.93251711]\n",
      "  [0.93664795]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00747852586209774\n",
      "Predicci√≥n post entrenamiento : [[0.93889344]]\n",
      "PERDIDAAAA despues: 0.007400854490697384\n",
      "loss en el callback: 0.004700514953583479, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "ejemplar: [[0.9098931 ]\n",
      " [0.91411543]\n",
      " [0.91900855]\n",
      " [0.92402196]\n",
      " [0.92780197]\n",
      " [0.93251711]\n",
      " [0.93664795]\n",
      " [0.93934369]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8585854533368672\n",
      "Predicci√≥n : [[0.9427863]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[[0.9098931 ]\n",
      "  [0.91411543]\n",
      "  [0.91900855]\n",
      "  [0.92402196]\n",
      "  [0.92780197]\n",
      "  [0.93251711]\n",
      "  [0.93664795]\n",
      "  [0.93934369]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007089774589985609\n",
      "Predicci√≥n post entrenamiento : [[0.94243145]]\n",
      "PERDIDAAAA despues: 0.00703014712780714\n",
      "loss en el callback: 0.0030000002589076757, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "ejemplar: [[0.91411543]\n",
      " [0.91900855]\n",
      " [0.92402196]\n",
      " [0.92780197]\n",
      " [0.93251711]\n",
      " [0.93664795]\n",
      " [0.93934369]\n",
      " [0.94278628]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8768633009085897\n",
      "Predicci√≥n : [[0.9464638]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[[0.91411543]\n",
      "  [0.91900855]\n",
      "  [0.92402196]\n",
      "  [0.92780197]\n",
      "  [0.93251711]\n",
      "  [0.93664795]\n",
      "  [0.93934369]\n",
      "  [0.94278628]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004844232928007841\n",
      "Predicci√≥n post entrenamiento : [[0.94637084]]\n",
      "PERDIDAAAA despues: 0.004831297788769007\n",
      "loss en el callback: 0.00021572552213910967, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "ejemplar: [[0.91900855]\n",
      " [0.92402196]\n",
      " [0.92780197]\n",
      " [0.93251711]\n",
      " [0.93664795]\n",
      " [0.93934369]\n",
      " [0.94278628]\n",
      " [0.94646382]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8806463966074481\n",
      "Predicci√≥n : [[0.950415]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[[0.91900855]\n",
      "  [0.92402196]\n",
      "  [0.92780197]\n",
      "  [0.93251711]\n",
      "  [0.93664795]\n",
      "  [0.93934369]\n",
      "  [0.94278628]\n",
      "  [0.94646382]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004867658484727144\n",
      "Predicci√≥n post entrenamiento : [[0.950034]]\n",
      "PERDIDAAAA despues: 0.004814641084522009\n",
      "loss en el callback: 0.0035845101810991764, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "ejemplar: [[0.92402196]\n",
      " [0.92780197]\n",
      " [0.93251711]\n",
      " [0.93664795]\n",
      " [0.93934369]\n",
      " [0.94278628]\n",
      " [0.94646382]\n",
      " [0.95041502]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8699347404334429\n",
      "Predicci√≥n : [[0.9538596]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[[0.92402196]\n",
      "  [0.92780197]\n",
      "  [0.93251711]\n",
      "  [0.93664795]\n",
      "  [0.93934369]\n",
      "  [0.94278628]\n",
      "  [0.94646382]\n",
      "  [0.95041502]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007043387275189161\n",
      "Predicci√≥n post entrenamiento : [[0.95350146]]\n",
      "PERDIDAAAA despues: 0.006983397528529167\n",
      "loss en el callback: 0.0032071408350020647, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "ejemplar: [[0.92780197]\n",
      " [0.93251711]\n",
      " [0.93664795]\n",
      " [0.93934369]\n",
      " [0.94278628]\n",
      " [0.94646382]\n",
      " [0.95041502]\n",
      " [0.95385963]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8465135437340043\n",
      "Predicci√≥n : [[0.95701253]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[[0.92780197]\n",
      "  [0.93251711]\n",
      "  [0.93664795]\n",
      "  [0.93934369]\n",
      "  [0.94278628]\n",
      "  [0.94646382]\n",
      "  [0.95041502]\n",
      "  [0.95385963]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012210020795464516\n",
      "Predicci√≥n post entrenamiento : [[0.9569316]]\n",
      "PERDIDAAAA despues: 0.012192139402031898\n",
      "loss en el callback: 0.0001950531586771831, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "ejemplar: [[0.93251711]\n",
      " [0.93664795]\n",
      " [0.93934369]\n",
      " [0.94278628]\n",
      " [0.94646382]\n",
      " [0.95041502]\n",
      " [0.95385963]\n",
      " [0.95701253]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8103828065091326\n",
      "Predicci√≥n : [[0.96042913]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[[0.93251711]\n",
      "  [0.93664795]\n",
      "  [0.93934369]\n",
      "  [0.94278628]\n",
      "  [0.94646382]\n",
      "  [0.95041502]\n",
      "  [0.95385963]\n",
      "  [0.95701253]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02251390740275383\n",
      "Predicci√≥n post entrenamiento : [[0.9593045]]\n",
      "PERDIDAAAA despues: 0.02217768132686615\n",
      "loss en el callback: 0.03099956549704075, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "ejemplar: [[0.93664795]\n",
      " [0.93934369]\n",
      " [0.94278628]\n",
      " [0.94646382]\n",
      " [0.95041502]\n",
      " [0.95385963]\n",
      " [0.95701253]\n",
      " [0.96042913]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8026111217617493\n",
      "Predicci√≥n : [[0.9624921]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[[0.93664795]\n",
      "  [0.93934369]\n",
      "  [0.94278628]\n",
      "  [0.94646382]\n",
      "  [0.95041502]\n",
      "  [0.95385963]\n",
      "  [0.95701253]\n",
      "  [0.96042913]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02556193247437477\n",
      "Predicci√≥n post entrenamiento : [[0.9619688]]\n",
      "PERDIDAAAA despues: 0.0253948662430048\n",
      "loss en el callback: 0.007617252878844738, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "ejemplar: [[0.93934369]\n",
      " [0.94278628]\n",
      " [0.94646382]\n",
      " [0.95041502]\n",
      " [0.95385963]\n",
      " [0.95701253]\n",
      " [0.96042913]\n",
      " [0.96249211]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.823198489491854\n",
      "Predicci√≥n : [[0.964962]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[[0.93934369]\n",
      "  [0.94278628]\n",
      "  [0.94646382]\n",
      "  [0.95041502]\n",
      "  [0.95385963]\n",
      "  [0.95701253]\n",
      "  [0.96042913]\n",
      "  [0.96249211]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02009689249098301\n",
      "Predicci√≥n post entrenamiento : [[0.9632829]]\n",
      "PERDIDAAAA despues: 0.019623635336756706\n",
      "loss en el callback: 0.06047213450074196, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "ejemplar: [[0.94278628]\n",
      " [0.94646382]\n",
      " [0.95041502]\n",
      " [0.95385963]\n",
      " [0.95701253]\n",
      " [0.96042913]\n",
      " [0.96249211]\n",
      " [0.96496201]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8397204264676091\n",
      "Predicci√≥n : [[0.96646434]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[[0.94278628]\n",
      "  [0.94646382]\n",
      "  [0.95041502]\n",
      "  [0.95385963]\n",
      "  [0.95701253]\n",
      "  [0.96042913]\n",
      "  [0.96249211]\n",
      "  [0.96496201]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01606401987373829\n",
      "Predicci√≥n post entrenamiento : [[0.9650678]]\n",
      "PERDIDAAAA despues: 0.015711965039372444\n",
      "loss en el callback: 0.04477158561348915, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "ejemplar: [[0.94646382]\n",
      " [0.95041502]\n",
      " [0.95385963]\n",
      " [0.95701253]\n",
      " [0.96042913]\n",
      " [0.96249211]\n",
      " [0.96496201]\n",
      " [0.96646434]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.852176932689015\n",
      "Predicci√≥n : [[0.96821076]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[[0.94646382]\n",
      "  [0.95041502]\n",
      "  [0.95385963]\n",
      "  [0.95701253]\n",
      "  [0.96042913]\n",
      "  [0.96249211]\n",
      "  [0.96496201]\n",
      "  [0.96646434]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013463854789733887\n",
      "Predicci√≥n post entrenamiento : [[0.96687186]]\n",
      "PERDIDAAAA despues: 0.013154932297766209\n",
      "loss en el callback: 0.03770263493061066, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "ejemplar: [[0.95041502]\n",
      " [0.95385963]\n",
      " [0.95701253]\n",
      " [0.96042913]\n",
      " [0.96249211]\n",
      " [0.96496201]\n",
      " [0.96646434]\n",
      " [0.96821076]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8615626813481295\n",
      "Predicci√≥n : [[0.96985406]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[[0.95041502]\n",
      "  [0.95385963]\n",
      "  [0.95701253]\n",
      "  [0.96042913]\n",
      "  [0.96249211]\n",
      "  [0.96496201]\n",
      "  [0.96646434]\n",
      "  [0.96821076]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011727024801075459\n",
      "Predicci√≥n post entrenamiento : [[0.97020596]]\n",
      "PERDIDAAAA despues: 0.01180336531251669\n",
      "loss en el callback: 0.0043767462484538555, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "ejemplar: [[0.95385963]\n",
      " [0.95701253]\n",
      " [0.96042913]\n",
      " [0.96249211]\n",
      " [0.96496201]\n",
      " [0.96646434]\n",
      " [0.96821076]\n",
      " [0.96985406]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8678776724449532\n",
      "Predicci√≥n : [[0.9728719]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[[0.95385963]\n",
      "  [0.95701253]\n",
      "  [0.96042913]\n",
      "  [0.96249211]\n",
      "  [0.96496201]\n",
      "  [0.96646434]\n",
      "  [0.96821076]\n",
      "  [0.96985406]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011023789644241333\n",
      "Predicci√≥n post entrenamiento : [[0.9717697]]\n",
      "PERDIDAAAA despues: 0.010793553665280342\n",
      "loss en el callback: 0.029665987938642502, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "ejemplar: [[0.95701253]\n",
      " [0.96042913]\n",
      " [0.96249211]\n",
      " [0.96496201]\n",
      " [0.96646434]\n",
      " [0.96821076]\n",
      " [0.96985406]\n",
      " [0.9728719 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8701963127047843\n",
      "Predicci√≥n : [[0.9741825]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[[0.95701253]\n",
      "  [0.96042913]\n",
      "  [0.96249211]\n",
      "  [0.96496201]\n",
      "  [0.96646434]\n",
      "  [0.96821076]\n",
      "  [0.96985406]\n",
      "  [0.9728719 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01081311795860529\n",
      "Predicci√≥n post entrenamiento : [[0.9746128]]\n",
      "PERDIDAAAA despues: 0.010902791284024715\n",
      "loss en el callback: 0.007250980008393526, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "ejemplar: [[0.96042913]\n",
      " [0.96249211]\n",
      " [0.96496201]\n",
      " [0.96646434]\n",
      " [0.96821076]\n",
      " [0.96985406]\n",
      " [0.9728719 ]\n",
      " [0.97418249]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8685186021276227\n",
      "Predicci√≥n : [[0.97679085]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[[0.96042913]\n",
      "  [0.96249211]\n",
      "  [0.96496201]\n",
      "  [0.96646434]\n",
      "  [0.96821076]\n",
      "  [0.96985406]\n",
      "  [0.9728719 ]\n",
      "  [0.97418249]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011722881346940994\n",
      "Predicci√≥n post entrenamiento : [[0.9762681]]\n",
      "PERDIDAAAA despues: 0.011609959416091442\n",
      "loss en el callback: 0.007404485251754522, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "ejemplar: [[0.96249211]\n",
      " [0.96496201]\n",
      " [0.96646434]\n",
      " [0.96821076]\n",
      " [0.96985406]\n",
      " [0.9728719 ]\n",
      " [0.97418249]\n",
      " [0.97679085]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8529880395838255\n",
      "Predicci√≥n : [[0.9780805]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[[0.96249211]\n",
      "  [0.96496201]\n",
      "  [0.96646434]\n",
      "  [0.96821076]\n",
      "  [0.96985406]\n",
      "  [0.9728719 ]\n",
      "  [0.97418249]\n",
      "  [0.97679085]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015648121014237404\n",
      "Predicci√≥n post entrenamiento : [[0.97808874]]\n",
      "PERDIDAAAA despues: 0.015650177374482155\n",
      "loss en el callback: 2.350551085328334e-06, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "ejemplar: [[0.96496201]\n",
      " [0.96646434]\n",
      " [0.96821076]\n",
      " [0.96985406]\n",
      " [0.9728719 ]\n",
      " [0.97418249]\n",
      " [0.97679085]\n",
      " [0.97808051]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8236046250733932\n",
      "Predicci√≥n : [[0.97987795]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[[0.96496201]\n",
      "  [0.96646434]\n",
      "  [0.96821076]\n",
      "  [0.96985406]\n",
      "  [0.9728719 ]\n",
      "  [0.97418249]\n",
      "  [0.97679085]\n",
      "  [0.97808051]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.024421345442533493\n",
      "Predicci√≥n post entrenamiento : [[0.97897726]]\n",
      "PERDIDAAAA despues: 0.024140650406479836\n",
      "loss en el callback: 0.024696657434105873, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "ejemplar: [[0.96646434]\n",
      " [0.96821076]\n",
      " [0.96985406]\n",
      " [0.9728719 ]\n",
      " [0.97418249]\n",
      " [0.97679085]\n",
      " [0.97808051]\n",
      " [0.97987795]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8032508871761479\n",
      "Predicci√≥n : [[0.9806169]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[[0.96646434]\n",
      "  [0.96821076]\n",
      "  [0.96985406]\n",
      "  [0.9728719 ]\n",
      "  [0.97418249]\n",
      "  [0.97679085]\n",
      "  [0.97808051]\n",
      "  [0.97987795]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03145870566368103\n",
      "Predicci√≥n post entrenamiento : [[0.9798379]]\n",
      "PERDIDAAAA despues: 0.031182963401079178\n",
      "loss en el callback: 0.01787443459033966, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "ejemplar: [[0.96821076]\n",
      " [0.96985406]\n",
      " [0.9728719 ]\n",
      " [0.97418249]\n",
      " [0.97679085]\n",
      " [0.97808051]\n",
      " [0.97987795]\n",
      " [0.98061693]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7919268258920897\n",
      "Predicci√≥n : [[0.98158795]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[[0.96821076]\n",
      "  [0.96985406]\n",
      "  [0.9728719 ]\n",
      "  [0.97418249]\n",
      "  [0.97679085]\n",
      "  [0.97808051]\n",
      "  [0.97987795]\n",
      "  [0.98061693]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.035971350967884064\n",
      "Predicci√≥n post entrenamiento : [[0.9800937]]\n",
      "PERDIDAAAA despues: 0.03540678694844246\n",
      "loss en el callback: 0.0590401217341423, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "ejemplar: [[0.96985406]\n",
      " [0.9728719 ]\n",
      " [0.97418249]\n",
      " [0.97679085]\n",
      " [0.97808051]\n",
      " [0.97987795]\n",
      " [0.98061693]\n",
      " [0.98158795]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7865023059771536\n",
      "Predicci√≥n : [[0.9818805]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[[0.96985406]\n",
      "  [0.9728719 ]\n",
      "  [0.97418249]\n",
      "  [0.97679085]\n",
      "  [0.97808051]\n",
      "  [0.97987795]\n",
      "  [0.98061693]\n",
      "  [0.98158795]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.038172636181116104\n",
      "Predicci√≥n post entrenamiento : [[0.9814706]]\n",
      "PERDIDAAAA despues: 0.038012631237506866\n",
      "loss en el callback: 0.006319087464362383, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "ejemplar: [[0.9728719 ]\n",
      " [0.97418249]\n",
      " [0.97679085]\n",
      " [0.97808051]\n",
      " [0.97987795]\n",
      " [0.98061693]\n",
      " [0.98158795]\n",
      " [0.98188049]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7869773274313391\n",
      "Predicci√≥n : [[0.98329794]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[[0.9728719 ]\n",
      "  [0.97418249]\n",
      "  [0.97679085]\n",
      "  [0.97808051]\n",
      "  [0.97987795]\n",
      "  [0.98061693]\n",
      "  [0.98158795]\n",
      "  [0.98188049]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.038541775196790695\n",
      "Predicci√≥n post entrenamiento : [[0.9811076]]\n",
      "PERDIDAAAA despues: 0.0376865491271019\n",
      "loss en el callback: 0.12141948193311691, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "ejemplar: [[0.97418249]\n",
      " [0.97679085]\n",
      " [0.97808051]\n",
      " [0.97987795]\n",
      " [0.98061693]\n",
      " [0.98158795]\n",
      " [0.98188049]\n",
      " [0.98329794]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7874362431744556\n",
      "Predicci√≥n : [[0.9825357]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[[0.97418249]\n",
      "  [0.97679085]\n",
      "  [0.97808051]\n",
      "  [0.97987795]\n",
      "  [0.98061693]\n",
      "  [0.98158795]\n",
      "  [0.98188049]\n",
      "  [0.98329794]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03806380555033684\n",
      "Predicci√≥n post entrenamiento : [[0.98050785]]\n",
      "PERDIDAAAA despues: 0.03727664425969124\n",
      "loss en el callback: 0.09881195425987244, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "ejemplar: [[0.97679085]\n",
      " [0.97808051]\n",
      " [0.97987795]\n",
      " [0.98061693]\n",
      " [0.98158795]\n",
      " [0.98188049]\n",
      " [0.98329794]\n",
      " [0.98253572]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7878790532065031\n",
      "Predicci√≥n : [[0.9819439]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[[0.97679085]\n",
      "  [0.97808051]\n",
      "  [0.97987795]\n",
      "  [0.98061693]\n",
      "  [0.98158795]\n",
      "  [0.98188049]\n",
      "  [0.98329794]\n",
      "  [0.98253572]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03766116872429848\n",
      "Predicci√≥n post entrenamiento : [[0.98111963]]\n",
      "PERDIDAAAA despues: 0.037341922521591187\n",
      "loss en el callback: 0.0202809926122427, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "ejemplar: [[0.97808051]\n",
      " [0.97987795]\n",
      " [0.98061693]\n",
      " [0.98158795]\n",
      " [0.98188049]\n",
      " [0.98329794]\n",
      " [0.98253572]\n",
      " [0.98194391]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7954532004373992\n",
      "Predicci√≥n : [[0.9821329]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[[0.97808051]\n",
      "  [0.97987795]\n",
      "  [0.98061693]\n",
      "  [0.98158795]\n",
      "  [0.98188049]\n",
      "  [0.98329794]\n",
      "  [0.98253572]\n",
      "  [0.98194391]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.034849319607019424\n",
      "Predicci√≥n post entrenamiento : [[0.9824679]]\n",
      "PERDIDAAAA despues: 0.03497449681162834\n",
      "loss en el callback: 0.0060717337764799595, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "ejemplar: [[0.97987795]\n",
      " [0.98061693]\n",
      " [0.98158795]\n",
      " [0.98188049]\n",
      " [0.98329794]\n",
      " [0.98253572]\n",
      " [0.98194391]\n",
      " [0.98213291]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8101586848671446\n",
      "Predicci√≥n : [[0.983344]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[[0.97987795]\n",
      "  [0.98061693]\n",
      "  [0.98158795]\n",
      "  [0.98188049]\n",
      "  [0.98329794]\n",
      "  [0.98253572]\n",
      "  [0.98194391]\n",
      "  [0.98213291]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.029993165284395218\n",
      "Predicci√≥n post entrenamiento : [[0.9834249]]\n",
      "PERDIDAAAA despues: 0.03002118691802025\n",
      "loss en el callback: 0.00028373152599669993, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "ejemplar: [[0.98061693]\n",
      " [0.98158795]\n",
      " [0.98188049]\n",
      " [0.98329794]\n",
      " [0.98253572]\n",
      " [0.98194391]\n",
      " [0.98213291]\n",
      " [0.98334402]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7668473230866574\n",
      "Predicci√≥n : [[0.98396134]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[[0.98061693]\n",
      "  [0.98158795]\n",
      "  [0.98188049]\n",
      "  [0.98329794]\n",
      "  [0.98253572]\n",
      "  [0.98194391]\n",
      "  [0.98213291]\n",
      "  [0.98334402]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04713850095868111\n",
      "Predicci√≥n post entrenamiento : [[0.98208266]]\n",
      "PERDIDAAAA despues: 0.04632625728845596\n",
      "loss en el callback: 0.09195861965417862, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "ejemplar: [[0.98158795]\n",
      " [0.98188049]\n",
      " [0.98329794]\n",
      " [0.98253572]\n",
      " [0.98194391]\n",
      " [0.98213291]\n",
      " [0.98334402]\n",
      " [0.98396134]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6655191150959373\n",
      "Predicci√≥n : [[0.9825262]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[[0.98158795]\n",
      "  [0.98188049]\n",
      "  [0.98329794]\n",
      "  [0.98253572]\n",
      "  [0.98194391]\n",
      "  [0.98213291]\n",
      "  [0.98334402]\n",
      "  [0.98396134]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10049347579479218\n",
      "Predicci√≥n post entrenamiento : [[0.98190564]]\n",
      "PERDIDAAAA despues: 0.10010042786598206\n",
      "loss en el callback: 0.018600597977638245, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "ejemplar: [[0.98188049]\n",
      " [0.98329794]\n",
      " [0.98253572]\n",
      " [0.98194391]\n",
      " [0.98213291]\n",
      " [0.98334402]\n",
      " [0.98396134]\n",
      " [0.98252618]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6360738003224796\n",
      "Predicci√≥n : [[0.9821567]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[[0.98188049]\n",
      "  [0.98329794]\n",
      "  [0.98253572]\n",
      "  [0.98194391]\n",
      "  [0.98213291]\n",
      "  [0.98334402]\n",
      "  [0.98396134]\n",
      "  [0.98252618]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11977335065603256\n",
      "Predicci√≥n post entrenamiento : [[0.9806505]]\n",
      "PERDIDAAAA despues: 0.11873307079076767\n",
      "loss en el callback: 0.08347820490598679, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "ejemplar: [[0.98329794]\n",
      " [0.98253572]\n",
      " [0.98194391]\n",
      " [0.98213291]\n",
      " [0.98334402]\n",
      " [0.98396134]\n",
      " [0.98252618]\n",
      " [0.98215669]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6785113787662842\n",
      "Predicci√≥n : [[0.9808671]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[[0.98329794]\n",
      "  [0.98253572]\n",
      "  [0.98194391]\n",
      "  [0.98213291]\n",
      "  [0.98334402]\n",
      "  [0.98396134]\n",
      "  [0.98252618]\n",
      "  [0.98215669]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09141897410154343\n",
      "Predicci√≥n post entrenamiento : [[0.9800315]]\n",
      "PERDIDAAAA despues: 0.09091437608003616\n",
      "loss en el callback: 0.029858935624361038, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "ejemplar: [[0.98253572]\n",
      " [0.98194391]\n",
      " [0.98213291]\n",
      " [0.98334402]\n",
      " [0.98396134]\n",
      " [0.98252618]\n",
      " [0.98215669]\n",
      " [0.98086709]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6965967339840231\n",
      "Predicci√≥n : [[0.9798559]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[[0.98253572]\n",
      "  [0.98194391]\n",
      "  [0.98213291]\n",
      "  [0.98334402]\n",
      "  [0.98396134]\n",
      "  [0.98252618]\n",
      "  [0.98215669]\n",
      "  [0.98086709]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08023574948310852\n",
      "Predicci√≥n post entrenamiento : [[0.9788912]]\n",
      "PERDIDAAAA despues: 0.07969015836715698\n",
      "loss en el callback: 0.03892971947789192, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "ejemplar: [[0.98194391]\n",
      " [0.98213291]\n",
      " [0.98334402]\n",
      " [0.98396134]\n",
      " [0.98252618]\n",
      " [0.98215669]\n",
      " [0.98086709]\n",
      " [0.9798559 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6903298659756966\n",
      "Predicci√≥n : [[0.97889245]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[[0.98194391]\n",
      "  [0.98213291]\n",
      "  [0.98334402]\n",
      "  [0.98396134]\n",
      "  [0.98252618]\n",
      "  [0.98215669]\n",
      "  [0.98086709]\n",
      "  [0.9798559 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08326837420463562\n",
      "Predicci√≥n post entrenamiento : [[0.9757359]]\n",
      "PERDIDAAAA despues: 0.08145661652088165\n",
      "loss en el callback: 0.2583838105201721, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "ejemplar: [[0.98213291]\n",
      " [0.98334402]\n",
      " [0.98396134]\n",
      " [0.98252618]\n",
      " [0.98215669]\n",
      " [0.98086709]\n",
      " [0.9798559 ]\n",
      " [0.97889245]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6970473058045382\n",
      "Predicci√≥n : [[0.9758596]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[[0.98213291]\n",
      "  [0.98334402]\n",
      "  [0.98396134]\n",
      "  [0.98252618]\n",
      "  [0.98215669]\n",
      "  [0.98086709]\n",
      "  [0.9798559 ]\n",
      "  [0.97889245]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07773629575967789\n",
      "Predicci√≥n post entrenamiento : [[0.97385484]]\n",
      "PERDIDAAAA despues: 0.07662241905927658\n",
      "loss en el callback: 0.12051711231470108, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "ejemplar: [[0.98334402]\n",
      " [0.98396134]\n",
      " [0.98252618]\n",
      " [0.98215669]\n",
      " [0.98086709]\n",
      " [0.9798559 ]\n",
      " [0.97889245]\n",
      " [0.97585958]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7167490534705484\n",
      "Predicci√≥n : [[0.9738335]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[[0.98334402]\n",
      "  [0.98396134]\n",
      "  [0.98252618]\n",
      "  [0.98215669]\n",
      "  [0.98086709]\n",
      "  [0.9798559 ]\n",
      "  [0.97889245]\n",
      "  [0.97585958]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06609240174293518\n",
      "Predicci√≥n post entrenamiento : [[0.97189724]]\n",
      "PERDIDAAAA despues: 0.06510058790445328\n",
      "loss en el callback: 0.1148945614695549, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "ejemplar: [[0.98396134]\n",
      " [0.98252618]\n",
      " [0.98215669]\n",
      " [0.98086709]\n",
      " [0.9798559 ]\n",
      " [0.97889245]\n",
      " [0.97585958]\n",
      " [0.9738335 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7490507063998944\n",
      "Predicci√≥n : [[0.97134537]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[[0.98396134]\n",
      "  [0.98252618]\n",
      "  [0.98215669]\n",
      "  [0.98086709]\n",
      "  [0.9798559 ]\n",
      "  [0.97889245]\n",
      "  [0.97585958]\n",
      "  [0.9738335 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04941492900252342\n",
      "Predicci√≥n post entrenamiento : [[0.9699821]]\n",
      "PERDIDAAAA despues: 0.0488106869161129\n",
      "loss en el callback: 0.06178528070449829, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "ejemplar: [[0.98252618]\n",
      " [0.98215669]\n",
      " [0.98086709]\n",
      " [0.9798559 ]\n",
      " [0.97889245]\n",
      " [0.97585958]\n",
      " [0.9738335 ]\n",
      " [0.97134537]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7939522645925762\n",
      "Predicci√≥n : [[0.9689445]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[[0.98252618]\n",
      "  [0.98215669]\n",
      "  [0.98086709]\n",
      "  [0.9798559 ]\n",
      "  [0.97889245]\n",
      "  [0.97585958]\n",
      "  [0.9738335 ]\n",
      "  [0.97134537]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.030622271820902824\n",
      "Predicci√≥n post entrenamiento : [[0.9689719]]\n",
      "PERDIDAAAA despues: 0.030631868168711662\n",
      "loss en el callback: 3.621683572418988e-05, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "ejemplar: [[0.98215669]\n",
      " [0.98086709]\n",
      " [0.9798559 ]\n",
      " [0.97889245]\n",
      " [0.97585958]\n",
      " [0.9738335 ]\n",
      " [0.97134537]\n",
      " [0.96894449]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8547447263586395\n",
      "Predicci√≥n : [[0.9679385]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[[0.98215669]\n",
      "  [0.98086709]\n",
      "  [0.9798559 ]\n",
      "  [0.97889245]\n",
      "  [0.97585958]\n",
      "  [0.9738335 ]\n",
      "  [0.97134537]\n",
      "  [0.96894449]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012812824919819832\n",
      "Predicci√≥n post entrenamiento : [[0.96737957]]\n",
      "PERDIDAAAA despues: 0.012686606496572495\n",
      "loss en el callback: 0.011242560110986233, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "ejemplar: [[0.98086709]\n",
      " [0.9798559 ]\n",
      " [0.97889245]\n",
      " [0.97585958]\n",
      " [0.9738335 ]\n",
      " [0.97134537]\n",
      " [0.96894449]\n",
      " [0.96793848]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9314280916980849\n",
      "Predicci√≥n : [[0.9660012]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[[0.98086709]\n",
      "  [0.9798559 ]\n",
      "  [0.97889245]\n",
      "  [0.97585958]\n",
      "  [0.9738335 ]\n",
      "  [0.97134537]\n",
      "  [0.96894449]\n",
      "  [0.96793848]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001195301883853972\n",
      "Predicci√≥n post entrenamiento : [[0.9653929]]\n",
      "PERDIDAAAA despues: 0.001153608551248908\n",
      "loss en el callback: 0.01247839443385601, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "ejemplar: [[0.9798559 ]\n",
      " [0.97889245]\n",
      " [0.97585958]\n",
      " [0.9738335 ]\n",
      " [0.97134537]\n",
      " [0.96894449]\n",
      " [0.96793848]\n",
      " [0.96600121]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9627243989762315\n",
      "Predicci√≥n : [[0.9638665]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[[0.9798559 ]\n",
      "  [0.97889245]\n",
      "  [0.97585958]\n",
      "  [0.9738335 ]\n",
      "  [0.97134537]\n",
      "  [0.96894449]\n",
      "  [0.96793848]\n",
      "  [0.96600121]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.3043572835158557e-06\n",
      "Predicci√≥n post entrenamiento : [[0.96393603]]\n",
      "PERDIDAAAA despues: 1.468079290134483e-06\n",
      "loss en el callback: 0.00019706283637788147, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "ejemplar: [[0.97889245]\n",
      " [0.97585958]\n",
      " [0.9738335 ]\n",
      " [0.97134537]\n",
      " [0.96894449]\n",
      " [0.96793848]\n",
      " [0.96600121]\n",
      " [0.96386647]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9486336481930799\n",
      "Predicci√≥n : [[0.96214443]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[[0.97889245]\n",
      "  [0.97585958]\n",
      "  [0.9738335 ]\n",
      "  [0.97134537]\n",
      "  [0.96894449]\n",
      "  [0.96793848]\n",
      "  [0.96600121]\n",
      "  [0.96386647]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00018254073802381754\n",
      "Predicci√≥n post entrenamiento : [[0.9623861]]\n",
      "PERDIDAAAA despues: 0.0001891285355668515\n",
      "loss en el callback: 0.0025798433925956488, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "ejemplar: [[0.97585958]\n",
      " [0.9738335 ]\n",
      " [0.97134537]\n",
      " [0.96894449]\n",
      " [0.96793848]\n",
      " [0.96600121]\n",
      " [0.96386647]\n",
      " [0.96214443]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9307145892932484\n",
      "Predicci√≥n : [[0.9602794]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[[0.97585958]\n",
      "  [0.9738335 ]\n",
      "  [0.97134537]\n",
      "  [0.96894449]\n",
      "  [0.96793848]\n",
      "  [0.96600121]\n",
      "  [0.96386647]\n",
      "  [0.96214443]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008740772609598935\n",
      "Predicci√≥n post entrenamiento : [[0.96055394]]\n",
      "PERDIDAAAA despues: 0.0008903859998099506\n",
      "loss en el callback: 0.0036087031476199627, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "ejemplar: [[0.9738335 ]\n",
      " [0.97134537]\n",
      " [0.96894449]\n",
      " [0.96793848]\n",
      " [0.96600121]\n",
      " [0.96386647]\n",
      " [0.96214443]\n",
      " [0.96027941]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.908967222276737\n",
      "Predicci√≥n : [[0.9587121]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[[0.9738335 ]\n",
      "  [0.97134537]\n",
      "  [0.96894449]\n",
      "  [0.96793848]\n",
      "  [0.96600121]\n",
      "  [0.96386647]\n",
      "  [0.96214443]\n",
      "  [0.96027941]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0024745555128902197\n",
      "Predicci√≥n post entrenamiento : [[0.9582425]]\n",
      "PERDIDAAAA despues: 0.002428053179755807\n",
      "loss en el callback: 0.00732064014300704, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "ejemplar: [[0.97134537]\n",
      " [0.96894449]\n",
      " [0.96793848]\n",
      " [0.96600121]\n",
      " [0.96386647]\n",
      " [0.96214443]\n",
      " [0.96027941]\n",
      " [0.9587121 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8816379650841193\n",
      "Predicci√≥n : [[0.9564216]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[[0.97134537]\n",
      "  [0.96894449]\n",
      "  [0.96793848]\n",
      "  [0.96600121]\n",
      "  [0.96386647]\n",
      "  [0.96214443]\n",
      "  [0.96027941]\n",
      "  [0.9587121 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005592590197920799\n",
      "Predicci√≥n post entrenamiento : [[0.9562902]]\n",
      "PERDIDAAAA despues: 0.005572950001806021\n",
      "loss en el callback: 0.0007061846554279327, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "ejemplar: [[0.96894449]\n",
      " [0.96793848]\n",
      " [0.96600121]\n",
      " [0.96386647]\n",
      " [0.96214443]\n",
      " [0.96027941]\n",
      " [0.9587121 ]\n",
      " [0.95642161]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8487268177153953\n",
      "Predicci√≥n : [[0.9546369]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[[0.96894449]\n",
      "  [0.96793848]\n",
      "  [0.96600121]\n",
      "  [0.96386647]\n",
      "  [0.96214443]\n",
      "  [0.96027941]\n",
      "  [0.9587121 ]\n",
      "  [0.95642161]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01121694128960371\n",
      "Predicci√≥n post entrenamiento : [[0.9541554]]\n",
      "PERDIDAAAA despues: 0.011115184985101223\n",
      "loss en el callback: 0.009296653792262077, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "ejemplar: [[0.96793848]\n",
      " [0.96600121]\n",
      " [0.96386647]\n",
      " [0.96214443]\n",
      " [0.96027941]\n",
      " [0.9587121 ]\n",
      " [0.95642161]\n",
      " [0.95463687]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.875260685634848\n",
      "Predicci√≥n : [[0.95266783]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[[0.96793848]\n",
      "  [0.96600121]\n",
      "  [0.96386647]\n",
      "  [0.96214443]\n",
      "  [0.96027941]\n",
      "  [0.9587121 ]\n",
      "  [0.95642161]\n",
      "  [0.95463687]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0059918626211583614\n",
      "Predicci√≥n post entrenamiento : [[0.9527612]]\n",
      "PERDIDAAAA despues: 0.006006321869790554\n",
      "loss en el callback: 0.0004101768718101084, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "ejemplar: [[0.96600121]\n",
      " [0.96386647]\n",
      " [0.96214443]\n",
      " [0.96027941]\n",
      " [0.9587121 ]\n",
      " [0.95642161]\n",
      " [0.95463687]\n",
      " [0.95266783]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9612395688424776\n",
      "Predicci√≥n : [[0.9510458]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[[0.96600121]\n",
      "  [0.96386647]\n",
      "  [0.96214443]\n",
      "  [0.96027941]\n",
      "  [0.9587121 ]\n",
      "  [0.95642161]\n",
      "  [0.95463687]\n",
      "  [0.95266783]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00010391284740762785\n",
      "Predicci√≥n post entrenamiento : [[0.9507601]]\n",
      "PERDIDAAAA despues: 0.00010981888044625521\n",
      "loss en el callback: 0.002935707801952958, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "ejemplar: [[0.96386647]\n",
      " [0.96214443]\n",
      " [0.96027941]\n",
      " [0.9587121 ]\n",
      " [0.95642161]\n",
      " [0.95463687]\n",
      " [0.95266783]\n",
      " [0.95104581]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9925021123407926\n",
      "Predicci√≥n : [[0.9490583]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[[0.96386647]\n",
      "  [0.96214443]\n",
      "  [0.96027941]\n",
      "  [0.9587121 ]\n",
      "  [0.95642161]\n",
      "  [0.95463687]\n",
      "  [0.95266783]\n",
      "  [0.95104581]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001887363730929792\n",
      "Predicci√≥n post entrenamiento : [[0.9498076]]\n",
      "PERDIDAAAA despues: 0.0018228210974484682\n",
      "loss en el callback: 0.03184784576296806, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "ejemplar: [[0.96214443]\n",
      " [0.96027941]\n",
      " [0.9587121 ]\n",
      " [0.95642161]\n",
      " [0.95463687]\n",
      " [0.95266783]\n",
      " [0.95104581]\n",
      " [0.94905829]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.969048316129792\n",
      "Predicci√≥n : [[0.94817907]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[[0.96214443]\n",
      "  [0.96027941]\n",
      "  [0.9587121 ]\n",
      "  [0.95642161]\n",
      "  [0.95463687]\n",
      "  [0.95266783]\n",
      "  [0.95104581]\n",
      "  [0.94905829]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004355258133728057\n",
      "Predicci√≥n post entrenamiento : [[0.9484461]]\n",
      "PERDIDAAAA despues: 0.00042445171857252717\n",
      "loss en el callback: 0.003120670560747385, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "ejemplar: [[0.96027941]\n",
      " [0.9587121 ]\n",
      " [0.95642161]\n",
      " [0.95463687]\n",
      " [0.95266783]\n",
      " [0.95104581]\n",
      " [0.94905829]\n",
      " [0.94817907]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9715476120161949\n",
      "Predicci√≥n : [[0.94678533]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[[0.96027941]\n",
      "  [0.9587121 ]\n",
      "  [0.95642161]\n",
      "  [0.95463687]\n",
      "  [0.95266783]\n",
      "  [0.95104581]\n",
      "  [0.94905829]\n",
      "  [0.94817907]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006131701520644128\n",
      "Predicci√≥n post entrenamiento : [[0.94712704]]\n",
      "PERDIDAAAA despues: 0.0005963637377135456\n",
      "loss en el callback: 0.004877161234617233, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "ejemplar: [[0.9587121 ]\n",
      " [0.95642161]\n",
      " [0.95463687]\n",
      " [0.95266783]\n",
      " [0.95104581]\n",
      " [0.94905829]\n",
      " [0.94817907]\n",
      " [0.94678533]]\n",
      "ejemplar: (8, 1)\n",
      "y: 1.0\n",
      "Predicci√≥n : [[0.9454811]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[[0.9587121 ]\n",
      "  [0.95642161]\n",
      "  [0.95463687]\n",
      "  [0.95266783]\n",
      "  [0.95104581]\n",
      "  [0.94905829]\n",
      "  [0.94817907]\n",
      "  [0.94678533]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029723080806434155\n",
      "Predicci√≥n post entrenamiento : [[0.9461355]]\n",
      "PERDIDAAAA despues: 0.0029013820458203554\n",
      "loss en el callback: 0.02192932553589344, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "ejemplar: [[0.95642161]\n",
      " [0.95463687]\n",
      " [0.95266783]\n",
      " [0.95104581]\n",
      " [0.94905829]\n",
      " [0.94817907]\n",
      " [0.94678533]\n",
      " [0.94548112]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9800636522775721\n",
      "Predicci√≥n : [[0.94443357]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[[0.95642161]\n",
      "  [0.95463687]\n",
      "  [0.95266783]\n",
      "  [0.95104581]\n",
      "  [0.94905829]\n",
      "  [0.94817907]\n",
      "  [0.94678533]\n",
      "  [0.94548112]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001269504544325173\n",
      "Predicci√≥n post entrenamiento : [[0.9442258]]\n",
      "PERDIDAAAA despues: 0.001284354249946773\n",
      "loss en el callback: 0.0017100301338359714, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "ejemplar: [[0.95463687]\n",
      " [0.95266783]\n",
      " [0.95104581]\n",
      " [0.94905829]\n",
      " [0.94817907]\n",
      " [0.94678533]\n",
      " [0.94548112]\n",
      " [0.94443357]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.911738568848911\n",
      "Predicci√≥n : [[0.94269365]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[[0.95463687]\n",
      "  [0.95266783]\n",
      "  [0.95104581]\n",
      "  [0.94905829]\n",
      "  [0.94817907]\n",
      "  [0.94678533]\n",
      "  [0.94548112]\n",
      "  [0.94443357]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009582167258486152\n",
      "Predicci√≥n post entrenamiento : [[0.94333607]]\n",
      "PERDIDAAAA despues: 0.0009984016651287675\n",
      "loss en el callback: 0.026344168931245804, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "ejemplar: [[0.95266783]\n",
      " [0.95104581]\n",
      " [0.94905829]\n",
      " [0.94817907]\n",
      " [0.94678533]\n",
      " [0.94548112]\n",
      " [0.94443357]\n",
      " [0.94269365]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8910857934126422\n",
      "Predicci√≥n : [[0.9418664]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[[0.95266783]\n",
      "  [0.95104581]\n",
      "  [0.94905829]\n",
      "  [0.94817907]\n",
      "  [0.94678533]\n",
      "  [0.94548112]\n",
      "  [0.94443357]\n",
      "  [0.94269365]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002578668761998415\n",
      "Predicci√≥n post entrenamiento : [[0.94212824]]\n",
      "PERDIDAAAA despues: 0.0026053304318338633\n",
      "loss en el callback: 0.003822784870862961, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "ejemplar: [[0.95104581]\n",
      " [0.94905829]\n",
      " [0.94817907]\n",
      " [0.94678533]\n",
      " [0.94548112]\n",
      " [0.94443357]\n",
      " [0.94269365]\n",
      " [0.9418664 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9181053259687657\n",
      "Predicci√≥n : [[0.94079983]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[[0.95104581]\n",
      "  [0.94905829]\n",
      "  [0.94817907]\n",
      "  [0.94678533]\n",
      "  [0.94548112]\n",
      "  [0.94443357]\n",
      "  [0.94269365]\n",
      "  [0.9418664 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005150415818206966\n",
      "Predicci√≥n post entrenamiento : [[0.9402466]]\n",
      "PERDIDAAAA despues: 0.0004902361542917788\n",
      "loss en el callback: 0.01375268492847681, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "ejemplar: [[0.94905829]\n",
      " [0.94817907]\n",
      " [0.94678533]\n",
      " [0.94548112]\n",
      " [0.94443357]\n",
      " [0.94269365]\n",
      " [0.9418664 ]\n",
      " [0.94079983]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9450165163483527\n",
      "Predicci√≥n : [[0.93899184]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[[0.94905829]\n",
      "  [0.94817907]\n",
      "  [0.94678533]\n",
      "  [0.94548112]\n",
      "  [0.94443357]\n",
      "  [0.94269365]\n",
      "  [0.9418664 ]\n",
      "  [0.94079983]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.629651109804399e-05\n",
      "Predicci√≥n post entrenamiento : [[0.93865925]]\n",
      "PERDIDAAAA despues: 4.041465945192613e-05\n",
      "loss en el callback: 0.004381747916340828, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "ejemplar: [[0.94817907]\n",
      " [0.94678533]\n",
      " [0.94548112]\n",
      " [0.94443357]\n",
      " [0.94269365]\n",
      " [0.9418664 ]\n",
      " [0.94079983]\n",
      " [0.93899184]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9718193645514037\n",
      "Predicci√≥n : [[0.93760026]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[[0.94817907]\n",
      "  [0.94678533]\n",
      "  [0.94548112]\n",
      "  [0.94443357]\n",
      "  [0.94269365]\n",
      "  [0.9418664 ]\n",
      "  [0.94079983]\n",
      "  [0.93899184]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011709458194673061\n",
      "Predicci√≥n post entrenamiento : [[0.9379045]]\n",
      "PERDIDAAAA despues: 0.0011502179550006986\n",
      "loss en el callback: 0.004781034309417009, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "ejemplar: [[0.94678533]\n",
      " [0.94548112]\n",
      " [0.94443357]\n",
      " [0.94269365]\n",
      " [0.9418664 ]\n",
      " [0.94079983]\n",
      " [0.93899184]\n",
      " [0.93760026]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9829067192737589\n",
      "Predicci√≥n : [[0.9367415]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[[0.94678533]\n",
      "  [0.94548112]\n",
      "  [0.94443357]\n",
      "  [0.94269365]\n",
      "  [0.9418664 ]\n",
      "  [0.94079983]\n",
      "  [0.93899184]\n",
      "  [0.93760026]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0021312283352017403\n",
      "Predicci√≥n post entrenamiento : [[0.9371405]]\n",
      "PERDIDAAAA despues: 0.0020945428404957056\n",
      "loss en el callback: 0.009666554629802704, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "ejemplar: [[0.94548112]\n",
      " [0.94443357]\n",
      " [0.94269365]\n",
      " [0.9418664 ]\n",
      " [0.94079983]\n",
      " [0.93899184]\n",
      " [0.93760026]\n",
      " [0.93674147]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9782785805154182\n",
      "Predicci√≥n : [[0.93600893]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[[0.94548112]\n",
      "  [0.94443357]\n",
      "  [0.94269365]\n",
      "  [0.9418664 ]\n",
      "  [0.94079983]\n",
      "  [0.93899184]\n",
      "  [0.93760026]\n",
      "  [0.93674147]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017867230344563723\n",
      "Predicci√≥n post entrenamiento : [[0.93515664]]\n",
      "PERDIDAAAA despues: 0.0018595012370496988\n",
      "loss en el callback: 0.026837997138500214, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "ejemplar: [[0.05029815]\n",
      " [0.00860651]\n",
      " [0.        ]\n",
      " [0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.049424632939554\n",
      "Predicci√≥n : [[0.19732593]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.05029815]\n",
      "  [0.00860651]\n",
      "  [0.        ]\n",
      "  [0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.021874792873859406\n",
      "Predicci√≥n post entrenamiento : [[0.16120423]]\n",
      "PERDIDAAAA despues: 0.012494678609073162\n",
      "loss en el callback: 0.024598892778158188, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "ejemplar: [[0.00860651]\n",
      " [0.        ]\n",
      " [0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.19732593]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.10789185692558968\n",
      "Predicci√≥n : [[0.15604283]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.00860651]\n",
      "  [0.        ]\n",
      "  [0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.19732593]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0023185161408036947\n",
      "Predicci√≥n post entrenamiento : [[0.14734387]]\n",
      "PERDIDAAAA despues: 0.0015564615605399013\n",
      "loss en el callback: 0.0016752700321376324, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "ejemplar: [[0.        ]\n",
      " [0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.19732593]\n",
      " [0.15604283]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.13719610119365802\n",
      "Predicci√≥n : [[0.15184109]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[[0.        ]\n",
      "  [0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.19732593]\n",
      "  [0.15604283]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002144758909707889\n",
      "Predicci√≥n post entrenamiento : [[0.14834549]]\n",
      "PERDIDAAAA despues: 0.00012430893548298627\n",
      "loss en el callback: 0.0005221841274760664, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "ejemplar: [[0.02447862]\n",
      " [0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.19732593]\n",
      " [0.15604283]\n",
      " [0.15184109]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.13733736574375907\n",
      "Predicci√≥n : [[0.15773945]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[[0.02447862]\n",
      "  [0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.19732593]\n",
      "  [0.15604283]\n",
      "  [0.15184109]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000416244613006711\n",
      "Predicci√≥n post entrenamiento : [[0.1554672]]\n",
      "PERDIDAAAA despues: 0.0003286905703134835\n",
      "loss en el callback: 0.0004300902073737234, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "ejemplar: [[0.03269448]\n",
      " [0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.19732593]\n",
      " [0.15604283]\n",
      " [0.15184109]\n",
      " [0.15773945]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.13388569841244483\n",
      "Predicci√≥n : [[0.16375881]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[[0.03269448]\n",
      "  [0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.19732593]\n",
      "  [0.15604283]\n",
      "  [0.15184109]\n",
      "  [0.15773945]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008924031862989068\n",
      "Predicci√≥n post entrenamiento : [[0.1616037]]\n",
      "PERDIDAAAA despues: 0.0007682879222556949\n",
      "loss en el callback: 0.000636605080217123, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "ejemplar: [[0.02464758]\n",
      " [0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.19732593]\n",
      " [0.15604283]\n",
      " [0.15184109]\n",
      " [0.15773945]\n",
      " [0.16375881]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.12684109919971556\n",
      "Predicci√≥n : [[0.17213513]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[[0.02464758]\n",
      "  [0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.19732593]\n",
      "  [0.15604283]\n",
      "  [0.15184109]\n",
      "  [0.15773945]\n",
      "  [0.16375881]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0020515492651611567\n",
      "Predicci√≥n post entrenamiento : [[0.16839059]]\n",
      "PERDIDAAAA despues: 0.001726360060274601\n",
      "loss en el callback: 0.00231627793982625, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "ejemplar: [[0.02051585]\n",
      " [0.0202993 ]\n",
      " [0.19732593]\n",
      " [0.15604283]\n",
      " [0.15184109]\n",
      " [0.15773945]\n",
      " [0.16375881]\n",
      " [0.17213513]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14756061137847282\n",
      "Predicci√≥n : [[0.18501204]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[[0.02051585]\n",
      "  [0.0202993 ]\n",
      "  [0.19732593]\n",
      "  [0.15604283]\n",
      "  [0.15184109]\n",
      "  [0.15773945]\n",
      "  [0.16375881]\n",
      "  [0.17213513]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014026097487658262\n",
      "Predicci√≥n post entrenamiento : [[0.18250485]]\n",
      "PERDIDAAAA despues: 0.0012210996355861425\n",
      "loss en el callback: 0.0013963262317702174, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "ejemplar: [[0.0202993 ]\n",
      " [0.19732593]\n",
      " [0.15604283]\n",
      " [0.15184109]\n",
      " [0.15773945]\n",
      " [0.16375881]\n",
      " [0.17213513]\n",
      " [0.18501204]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19604423494871648\n",
      "Predicci√≥n : [[0.20520438]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[[0.0202993 ]\n",
      "  [0.19732593]\n",
      "  [0.15604283]\n",
      "  [0.15184109]\n",
      "  [0.15773945]\n",
      "  [0.16375881]\n",
      "  [0.17213513]\n",
      "  [0.18501204]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.390827861148864e-05\n",
      "Predicci√≥n post entrenamiento : [[0.20505963]]\n",
      "PERDIDAAAA despues: 8.127737237373367e-05\n",
      "loss en el callback: 6.9118600549700204e-06, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "ejemplar: [[0.19732593]\n",
      " [0.15604283]\n",
      " [0.15184109]\n",
      " [0.15773945]\n",
      " [0.16375881]\n",
      " [0.17213513]\n",
      " [0.18501204]\n",
      " [0.20520438]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.21688968214535215\n",
      "Predicci√≥n : [[0.23365925]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[[0.19732593]\n",
      "  [0.15604283]\n",
      "  [0.15184109]\n",
      "  [0.15773945]\n",
      "  [0.16375881]\n",
      "  [0.17213513]\n",
      "  [0.18501204]\n",
      "  [0.20520438]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002812185848597437\n",
      "Predicci√≥n post entrenamiento : [[0.23275657]]\n",
      "PERDIDAAAA despues: 0.00025175820337608457\n",
      "loss en el callback: 0.0002749285486061126, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "ejemplar: [[0.15604283]\n",
      " [0.15184109]\n",
      " [0.15773945]\n",
      " [0.16375881]\n",
      " [0.17213513]\n",
      " [0.18501204]\n",
      " [0.20520438]\n",
      " [0.23365925]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2100969529683796\n",
      "Predicci√≥n : [[0.22673945]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[[0.15604283]\n",
      "  [0.15184109]\n",
      "  [0.15773945]\n",
      "  [0.16375881]\n",
      "  [0.17213513]\n",
      "  [0.18501204]\n",
      "  [0.20520438]\n",
      "  [0.23365925]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00027697268524207175\n",
      "Predicci√≥n post entrenamiento : [[0.22569111]]\n",
      "PERDIDAAAA despues: 0.00024317765200976282\n",
      "loss en el callback: 0.0004769357619807124, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "ejemplar: [[0.15184109]\n",
      " [0.15773945]\n",
      " [0.16375881]\n",
      " [0.17213513]\n",
      " [0.18501204]\n",
      " [0.20520438]\n",
      " [0.23365925]\n",
      " [0.22673945]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2026778474621132\n",
      "Predicci√≥n : [[0.22923364]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[[0.15184109]\n",
      "  [0.15773945]\n",
      "  [0.16375881]\n",
      "  [0.17213513]\n",
      "  [0.18501204]\n",
      "  [0.20520438]\n",
      "  [0.23365925]\n",
      "  [0.22673945]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007052100845612586\n",
      "Predicci√≥n post entrenamiento : [[0.22796682]]\n",
      "PERDIDAAAA despues: 0.0006395319942384958\n",
      "loss en el callback: 0.0008549007470719516, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "ejemplar: [[0.15773945]\n",
      " [0.16375881]\n",
      " [0.17213513]\n",
      " [0.18501204]\n",
      " [0.20520438]\n",
      " [0.23365925]\n",
      " [0.22673945]\n",
      " [0.22923364]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19463236562655295\n",
      "Predicci√≥n : [[0.23441966]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[[0.15773945]\n",
      "  [0.16375881]\n",
      "  [0.17213513]\n",
      "  [0.18501204]\n",
      "  [0.20520438]\n",
      "  [0.23365925]\n",
      "  [0.22673945]\n",
      "  [0.22923364]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015830285847187042\n",
      "Predicci√≥n post entrenamiento : [[0.23333715]]\n",
      "PERDIDAAAA despues: 0.0014980601845309138\n",
      "loss en el callback: 0.0008449984597973526, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "ejemplar: [[0.16375881]\n",
      " [0.17213513]\n",
      " [0.18501204]\n",
      " [0.20520438]\n",
      " [0.23365925]\n",
      " [0.22673945]\n",
      " [0.22923364]\n",
      " [0.23441966]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19407351685692253\n",
      "Predicci√≥n : [[0.24088334]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[[0.16375881]\n",
      "  [0.17213513]\n",
      "  [0.18501204]\n",
      "  [0.20520438]\n",
      "  [0.23365925]\n",
      "  [0.22673945]\n",
      "  [0.22923364]\n",
      "  [0.23441966]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0021911594085395336\n",
      "Predicci√≥n post entrenamiento : [[0.23948681]]\n",
      "PERDIDAAAA despues: 0.0020623677410185337\n",
      "loss en el callback: 0.001579006784595549, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "ejemplar: [[0.17213513]\n",
      " [0.18501204]\n",
      " [0.20520438]\n",
      " [0.23365925]\n",
      " [0.22673945]\n",
      " [0.22923364]\n",
      " [0.23441966]\n",
      " [0.24088334]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.20100130115322212\n",
      "Predicci√≥n : [[0.24817811]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[[0.17213513]\n",
      "  [0.18501204]\n",
      "  [0.20520438]\n",
      "  [0.23365925]\n",
      "  [0.22673945]\n",
      "  [0.22923364]\n",
      "  [0.23441966]\n",
      "  [0.24088334]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0022256511729210615\n",
      "Predicci√≥n post entrenamiento : [[0.24837103]]\n",
      "PERDIDAAAA despues: 0.002243891591206193\n",
      "loss en el callback: 5.277245145407505e-05, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "ejemplar: [[0.18501204]\n",
      " [0.20520438]\n",
      " [0.23365925]\n",
      " [0.22673945]\n",
      " [0.22923364]\n",
      " [0.23441966]\n",
      " [0.24088334]\n",
      " [0.24817811]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19663820581116015\n",
      "Predicci√≥n : [[0.25768802]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[[0.18501204]\n",
      "  [0.20520438]\n",
      "  [0.23365925]\n",
      "  [0.22673945]\n",
      "  [0.22923364]\n",
      "  [0.23441966]\n",
      "  [0.24088334]\n",
      "  [0.24817811]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0037270786706358194\n",
      "Predicci√≥n post entrenamiento : [[0.25553027]]\n",
      "PERDIDAAAA despues: 0.0034682743716984987\n",
      "loss en el callback: 0.00406115036457777, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "ejemplar: [[0.20520438]\n",
      " [0.23365925]\n",
      " [0.22673945]\n",
      " [0.22923364]\n",
      " [0.23441966]\n",
      " [0.24088334]\n",
      " [0.24817811]\n",
      " [0.25768802]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1809842308307365\n",
      "Predicci√≥n : [[0.26431426]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[[0.20520438]\n",
      "  [0.23365925]\n",
      "  [0.22673945]\n",
      "  [0.22923364]\n",
      "  [0.23441966]\n",
      "  [0.24088334]\n",
      "  [0.24817811]\n",
      "  [0.25768802]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006943894550204277\n",
      "Predicci√≥n post entrenamiento : [[0.26252884]]\n",
      "PERDIDAAAA despues: 0.006649523042142391\n",
      "loss en el callback: 0.003638379042968154, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "ejemplar: [[0.23365925]\n",
      " [0.22673945]\n",
      " [0.22923364]\n",
      " [0.23441966]\n",
      " [0.24088334]\n",
      " [0.24817811]\n",
      " [0.25768802]\n",
      " [0.26431426]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1653904097109329\n",
      "Predicci√≥n : [[0.2687794]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[[0.23365925]\n",
      "  [0.22673945]\n",
      "  [0.22923364]\n",
      "  [0.23441966]\n",
      "  [0.24088334]\n",
      "  [0.24817811]\n",
      "  [0.25768802]\n",
      "  [0.26431426]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010689280927181244\n",
      "Predicci√≥n post entrenamiento : [[0.26572514]]\n",
      "PERDIDAAAA despues: 0.010067055933177471\n",
      "loss en el callback: 0.010958579368889332, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "ejemplar: [[0.22673945]\n",
      " [0.22923364]\n",
      " [0.23441966]\n",
      " [0.24088334]\n",
      " [0.24817811]\n",
      " [0.25768802]\n",
      " [0.26431426]\n",
      " [0.2687794 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14985674245174896\n",
      "Predicci√≥n : [[0.26696464]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[[0.22673945]\n",
      "  [0.22923364]\n",
      "  [0.23441966]\n",
      "  [0.24088334]\n",
      "  [0.24817811]\n",
      "  [0.25768802]\n",
      "  [0.26431426]\n",
      "  [0.2687794 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01371425949037075\n",
      "Predicci√≥n post entrenamiento : [[0.26423827]]\n",
      "PERDIDAAAA despues: 0.013083132915198803\n",
      "loss en el callback: 0.011068311519920826, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "ejemplar: [[0.22923364]\n",
      " [0.23441966]\n",
      " [0.24088334]\n",
      " [0.24817811]\n",
      " [0.25768802]\n",
      " [0.26431426]\n",
      " [0.2687794 ]\n",
      " [0.26696464]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.15043111479831345\n",
      "Predicci√≥n : [[0.26803055]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[[0.22923364]\n",
      "  [0.23441966]\n",
      "  [0.24088334]\n",
      "  [0.24817811]\n",
      "  [0.25768802]\n",
      "  [0.26431426]\n",
      "  [0.2687794 ]\n",
      "  [0.26696464]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013829628936946392\n",
      "Predicci√≥n post entrenamiento : [[0.2646715]]\n",
      "PERDIDAAAA despues: 0.01305086724460125\n",
      "loss en el callback: 0.016059445217251778, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "ejemplar: [[0.23441966]\n",
      " [0.24088334]\n",
      " [0.24817811]\n",
      " [0.25768802]\n",
      " [0.26431426]\n",
      " [0.2687794 ]\n",
      " [0.26696464]\n",
      " [0.26803055]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.16711352675062616\n",
      "Predicci√≥n : [[0.2691893]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[[0.23441966]\n",
      "  [0.24088334]\n",
      "  [0.24817811]\n",
      "  [0.25768802]\n",
      "  [0.26431426]\n",
      "  [0.2687794 ]\n",
      "  [0.26696464]\n",
      "  [0.26803055]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01041946280747652\n",
      "Predicci√≥n post entrenamiento : [[0.26756266]]\n",
      "PERDIDAAAA despues: 0.010090027935802937\n",
      "loss en el callback: 0.005396697670221329, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "ejemplar: [[0.24088334]\n",
      " [0.24817811]\n",
      " [0.25768802]\n",
      " [0.26431426]\n",
      " [0.2687794 ]\n",
      " [0.26696464]\n",
      " [0.26803055]\n",
      " [0.2691893 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2022703535675908\n",
      "Predicci√≥n : [[0.2721864]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[[0.24088334]\n",
      "  [0.24817811]\n",
      "  [0.25768802]\n",
      "  [0.26431426]\n",
      "  [0.2687794 ]\n",
      "  [0.26696464]\n",
      "  [0.26803055]\n",
      "  [0.2691893 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004888252820819616\n",
      "Predicci√≥n post entrenamiento : [[0.27069494]]\n",
      "PERDIDAAAA despues: 0.0046819234266877174\n",
      "loss en el callback: 0.004102164413779974, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "ejemplar: [[0.24817811]\n",
      " [0.25768802]\n",
      " [0.26431426]\n",
      " [0.2687794 ]\n",
      " [0.26696464]\n",
      " [0.26803055]\n",
      " [0.2691893 ]\n",
      " [0.2721864 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.25590159524920725\n",
      "Predicci√≥n : [[0.27500767]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[[0.24817811]\n",
      "  [0.25768802]\n",
      "  [0.26431426]\n",
      "  [0.2687794 ]\n",
      "  [0.26696464]\n",
      "  [0.26803055]\n",
      "  [0.2691893 ]\n",
      "  [0.2721864 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00036504154559224844\n",
      "Predicci√≥n post entrenamiento : [[0.2758573]]\n",
      "PERDIDAAAA despues: 0.00039822974940761924\n",
      "loss en el callback: 0.0020339242182672024, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "ejemplar: [[0.25768802]\n",
      " [0.26431426]\n",
      " [0.2687794 ]\n",
      " [0.26696464]\n",
      " [0.26803055]\n",
      " [0.2691893 ]\n",
      " [0.2721864 ]\n",
      " [0.27500767]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.292688203599549\n",
      "Predicci√≥n : [[0.27948827]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[[0.25768802]\n",
      "  [0.26431426]\n",
      "  [0.2687794 ]\n",
      "  [0.26696464]\n",
      "  [0.26803055]\n",
      "  [0.2691893 ]\n",
      "  [0.2721864 ]\n",
      "  [0.27500767]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000174238026374951\n",
      "Predicci√≥n post entrenamiento : [[0.27912012]]\n",
      "PERDIDAAAA despues: 0.0001840926124714315\n",
      "loss en el callback: 0.00025422743055969477, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "ejemplar: [[0.26431426]\n",
      " [0.2687794 ]\n",
      " [0.26696464]\n",
      " [0.26803055]\n",
      " [0.2691893 ]\n",
      " [0.2721864 ]\n",
      " [0.27500767]\n",
      " [0.27948827]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31263017861861575\n",
      "Predicci√≥n : [[0.2813408]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[[0.26431426]\n",
      "  [0.2687794 ]\n",
      "  [0.26696464]\n",
      "  [0.26803055]\n",
      "  [0.2691893 ]\n",
      "  [0.2721864 ]\n",
      "  [0.27500767]\n",
      "  [0.27948827]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009790245676413178\n",
      "Predicci√≥n post entrenamiento : [[0.2820946]]\n",
      "PERDIDAAAA despues: 0.0009324215934611857\n",
      "loss en el callback: 0.0013711246429011226, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "ejemplar: [[0.2687794 ]\n",
      " [0.26696464]\n",
      " [0.26803055]\n",
      " [0.2691893 ]\n",
      " [0.2721864 ]\n",
      " [0.27500767]\n",
      " [0.27948827]\n",
      " [0.28134081]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3109388849116374\n",
      "Predicci√≥n : [[0.28333595]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[[0.2687794 ]\n",
      "  [0.26696464]\n",
      "  [0.26803055]\n",
      "  [0.2691893 ]\n",
      "  [0.2721864 ]\n",
      "  [0.27500767]\n",
      "  [0.27948827]\n",
      "  [0.28134081]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007619223324581981\n",
      "Predicci√≥n post entrenamiento : [[0.2828019]]\n",
      "PERDIDAAAA despues: 0.0007916906615719199\n",
      "loss en el callback: 0.0005675662541761994, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "ejemplar: [[0.26696464]\n",
      " [0.26803055]\n",
      " [0.2691893 ]\n",
      " [0.2721864 ]\n",
      " [0.27500767]\n",
      " [0.27948827]\n",
      " [0.28134081]\n",
      " [0.28333595]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2876143224786136\n",
      "Predicci√≥n : [[0.28343943]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[[0.26696464]\n",
      "  [0.26803055]\n",
      "  [0.2691893 ]\n",
      "  [0.2721864 ]\n",
      "  [0.27500767]\n",
      "  [0.27948827]\n",
      "  [0.28134081]\n",
      "  [0.28333595]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.742969106999226e-05\n",
      "Predicci√≥n post entrenamiento : [[0.2841238]]\n",
      "PERDIDAAAA despues: 1.218364377564285e-05\n",
      "loss en el callback: 0.001468248083256185, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "ejemplar: [[0.26803055]\n",
      " [0.2691893 ]\n",
      " [0.2721864 ]\n",
      " [0.27500767]\n",
      " [0.27948827]\n",
      " [0.28134081]\n",
      " [0.28333595]\n",
      " [0.28343943]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.280161647237227\n",
      "Predicci√≥n : [[0.28559285]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[[0.26803055]\n",
      "  [0.2691893 ]\n",
      "  [0.2721864 ]\n",
      "  [0.27500767]\n",
      "  [0.27948827]\n",
      "  [0.28134081]\n",
      "  [0.28333595]\n",
      "  [0.28343943]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.9497987270588055e-05\n",
      "Predicci√≥n post entrenamiento : [[0.28546208]]\n",
      "PERDIDAAAA despues: 2.8094584195059724e-05\n",
      "loss en el callback: 5.305948434397578e-05, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "ejemplar: [[0.2691893 ]\n",
      " [0.2721864 ]\n",
      " [0.27500767]\n",
      " [0.27948827]\n",
      " [0.28134081]\n",
      " [0.28333595]\n",
      " [0.28343943]\n",
      " [0.28559285]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2885808591874776\n",
      "Predicci√≥n : [[0.2872124]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[[0.2691893 ]\n",
      "  [0.2721864 ]\n",
      "  [0.27500767]\n",
      "  [0.27948827]\n",
      "  [0.28134081]\n",
      "  [0.28333595]\n",
      "  [0.28343943]\n",
      "  [0.28559285]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.8726910866462276e-06\n",
      "Predicci√≥n post entrenamiento : [[0.2880245]]\n",
      "PERDIDAAAA despues: 3.09558203070992e-07\n",
      "loss en el callback: 0.002696071285754442, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "ejemplar: [[0.2721864 ]\n",
      " [0.27500767]\n",
      " [0.27948827]\n",
      " [0.28134081]\n",
      " [0.28333595]\n",
      " [0.28343943]\n",
      " [0.28559285]\n",
      " [0.2872124 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2824628234730068\n",
      "Predicci√≥n : [[0.29006228]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[[0.2721864 ]\n",
      "  [0.27500767]\n",
      "  [0.27948827]\n",
      "  [0.28134081]\n",
      "  [0.28333595]\n",
      "  [0.28343943]\n",
      "  [0.28559285]\n",
      "  [0.2872124 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.775153840659186e-05\n",
      "Predicci√≥n post entrenamiento : [[0.2896483]]\n",
      "PERDIDAAAA despues: 5.163082460057922e-05\n",
      "loss en el callback: 0.00057415128685534, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "ejemplar: [[0.27500767]\n",
      " [0.27948827]\n",
      " [0.28134081]\n",
      " [0.28333595]\n",
      " [0.28343943]\n",
      " [0.28559285]\n",
      " [0.2872124 ]\n",
      " [0.29006228]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.26180754009381474\n",
      "Predicci√≥n : [[0.29155177]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[[0.27500767]\n",
      "  [0.27948827]\n",
      "  [0.28134081]\n",
      "  [0.28333595]\n",
      "  [0.28343943]\n",
      "  [0.28559285]\n",
      "  [0.2872124 ]\n",
      "  [0.29006228]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008847196586430073\n",
      "Predicci√≥n post entrenamiento : [[0.2906877]]\n",
      "PERDIDAAAA despues: 0.0008340647327713668\n",
      "loss en el callback: 0.0022878015879541636, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "ejemplar: [[0.27948827]\n",
      " [0.28134081]\n",
      " [0.28333595]\n",
      " [0.28343943]\n",
      " [0.28559285]\n",
      " [0.2872124 ]\n",
      " [0.29006228]\n",
      " [0.29155177]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2801212859371977\n",
      "Predicci√≥n : [[0.2924523]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[[0.27948827]\n",
      "  [0.28134081]\n",
      "  [0.28333595]\n",
      "  [0.28343943]\n",
      "  [0.28559285]\n",
      "  [0.2872124 ]\n",
      "  [0.29006228]\n",
      "  [0.29155177]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00015205377712845802\n",
      "Predicci√≥n post entrenamiento : [[0.29230064]]\n",
      "PERDIDAAAA despues: 0.00014833644672762603\n",
      "loss en el callback: 8.28130723675713e-05, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "ejemplar: [[0.28134081]\n",
      " [0.28333595]\n",
      " [0.28343943]\n",
      " [0.28559285]\n",
      " [0.2872124 ]\n",
      " [0.29006228]\n",
      " [0.29155177]\n",
      " [0.29245231]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3374040610031557\n",
      "Predicci√≥n : [[0.29348344]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[[0.28134081]\n",
      "  [0.28333595]\n",
      "  [0.28343943]\n",
      "  [0.28559285]\n",
      "  [0.2872124 ]\n",
      "  [0.29006228]\n",
      "  [0.29155177]\n",
      "  [0.29245231]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0019290222553536296\n",
      "Predicci√≥n post entrenamiento : [[0.2950232]]\n",
      "PERDIDAAAA despues: 0.0017961381236091256\n",
      "loss en el callback: 0.019010232761502266, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "ejemplar: [[0.28333595]\n",
      " [0.28343943]\n",
      " [0.28559285]\n",
      " [0.2872124 ]\n",
      " [0.29006228]\n",
      " [0.29155177]\n",
      " [0.29245231]\n",
      " [0.29348344]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3482298154676272\n",
      "Predicci√≥n : [[0.29615495]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[[0.28333595]\n",
      "  [0.28343943]\n",
      "  [0.28559285]\n",
      "  [0.2872124 ]\n",
      "  [0.29006228]\n",
      "  [0.29155177]\n",
      "  [0.29245231]\n",
      "  [0.29348344]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0027117931749671698\n",
      "Predicci√≥n post entrenamiento : [[0.2971268]]\n",
      "PERDIDAAAA despues: 0.0026115193031728268\n",
      "loss en el callback: 0.004323858302086592, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "ejemplar: [[0.28343943]\n",
      " [0.28559285]\n",
      " [0.2872124 ]\n",
      " [0.29006228]\n",
      " [0.29155177]\n",
      " [0.29245231]\n",
      " [0.29348344]\n",
      " [0.29615495]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31259854933061226\n",
      "Predicci√≥n : [[0.29816693]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[[0.28343943]\n",
      "  [0.28559285]\n",
      "  [0.2872124 ]\n",
      "  [0.29006228]\n",
      "  [0.29155177]\n",
      "  [0.29245231]\n",
      "  [0.29348344]\n",
      "  [0.29615495]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00020827181288041174\n",
      "Predicci√≥n post entrenamiento : [[0.298184]]\n",
      "PERDIDAAAA despues: 0.0002077792159980163\n",
      "loss en el callback: 1.2542689091787906e-06, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "ejemplar: [[0.28559285]\n",
      " [0.2872124 ]\n",
      " [0.29006228]\n",
      " [0.29155177]\n",
      " [0.29245231]\n",
      " [0.29348344]\n",
      " [0.29615495]\n",
      " [0.29816693]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.34358710169603873\n",
      "Predicci√≥n : [[0.29958126]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[[0.28559285]\n",
      "  [0.2872124 ]\n",
      "  [0.29006228]\n",
      "  [0.29155177]\n",
      "  [0.29245231]\n",
      "  [0.29348344]\n",
      "  [0.29615495]\n",
      "  [0.29816693]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0019365140469744802\n",
      "Predicci√≥n post entrenamiento : [[0.3010515]]\n",
      "PERDIDAAAA despues: 0.0018092775717377663\n",
      "loss en el callback: 0.0164022296667099, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "ejemplar: [[0.2872124 ]\n",
      " [0.29006228]\n",
      " [0.29155177]\n",
      " [0.29245231]\n",
      " [0.29348344]\n",
      " [0.29615495]\n",
      " [0.29816693]\n",
      " [0.29958126]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.4411954725639069\n",
      "Predicci√≥n : [[0.3023675]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[[0.2872124 ]\n",
      "  [0.29006228]\n",
      "  [0.29155177]\n",
      "  [0.29245231]\n",
      "  [0.29348344]\n",
      "  [0.29615495]\n",
      "  [0.29816693]\n",
      "  [0.29958126]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019273199141025543\n",
      "Predicci√≥n post entrenamiento : [[0.3041615]]\n",
      "PERDIDAAAA despues: 0.018778309226036072\n",
      "loss en el callback: 0.014961671084165573, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "ejemplar: [[0.29006228]\n",
      " [0.29155177]\n",
      " [0.29245231]\n",
      " [0.29348344]\n",
      " [0.29615495]\n",
      " [0.29816693]\n",
      " [0.29958126]\n",
      " [0.30236751]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5210953230441133\n",
      "Predicci√≥n : [[0.305515]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[[0.29006228]\n",
      "  [0.29155177]\n",
      "  [0.29245231]\n",
      "  [0.29348344]\n",
      "  [0.29615495]\n",
      "  [0.29816693]\n",
      "  [0.29958126]\n",
      "  [0.30236751]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0464748851954937\n",
      "Predicci√≥n post entrenamiento : [[0.30848363]]\n",
      "PERDIDAAAA despues: 0.045203737914562225\n",
      "loss en el callback: 0.04892876371741295, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "ejemplar: [[0.29155177]\n",
      " [0.29245231]\n",
      " [0.29348344]\n",
      " [0.29615495]\n",
      " [0.29816693]\n",
      " [0.29958126]\n",
      " [0.30236751]\n",
      " [0.30551499]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5832866531366584\n",
      "Predicci√≥n : [[0.3095953]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[[0.29155177]\n",
      "  [0.29245231]\n",
      "  [0.29348344]\n",
      "  [0.29615495]\n",
      "  [0.29816693]\n",
      "  [0.29958126]\n",
      "  [0.30236751]\n",
      "  [0.30551499]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07490696012973785\n",
      "Predicci√≥n post entrenamiento : [[0.31299362]]\n",
      "PERDIDAAAA despues: 0.07305832207202911\n",
      "loss en el callback: 0.046829089522361755, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "ejemplar: [[0.29245231]\n",
      " [0.29348344]\n",
      " [0.29615495]\n",
      " [0.29816693]\n",
      " [0.29958126]\n",
      " [0.30236751]\n",
      " [0.30551499]\n",
      " [0.30959529]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6089234523540271\n",
      "Predicci√≥n : [[0.31418738]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[[0.29245231]\n",
      "  [0.29348344]\n",
      "  [0.29615495]\n",
      "  [0.29816693]\n",
      "  [0.29958126]\n",
      "  [0.30236751]\n",
      "  [0.30551499]\n",
      "  [0.30959529]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08686934411525726\n",
      "Predicci√≥n post entrenamiento : [[0.31789052]]\n",
      "PERDIDAAAA despues: 0.08470015227794647\n",
      "loss en el callback: 0.06160224974155426, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "ejemplar: [[0.29348344]\n",
      " [0.29615495]\n",
      " [0.29816693]\n",
      " [0.29958126]\n",
      " [0.30236751]\n",
      " [0.30551499]\n",
      " [0.30959529]\n",
      " [0.31418738]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.59800572069622\n",
      "Predicci√≥n : [[0.31937206]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[[0.29348344]\n",
      "  [0.29615495]\n",
      "  [0.29816693]\n",
      "  [0.29958126]\n",
      "  [0.30236751]\n",
      "  [0.30551499]\n",
      "  [0.30959529]\n",
      "  [0.31418738]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0776367112994194\n",
      "Predicci√≥n post entrenamiento : [[0.32248718]]\n",
      "PERDIDAAAA despues: 0.07591046392917633\n",
      "loss en el callback: 0.03920222446322441, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "ejemplar: [[0.29615495]\n",
      " [0.29816693]\n",
      " [0.29958126]\n",
      " [0.30236751]\n",
      " [0.30551499]\n",
      " [0.30959529]\n",
      " [0.31418738]\n",
      " [0.31937206]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5945301858653699\n",
      "Predicci√≥n : [[0.32432806]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[[0.29615495]\n",
      "  [0.29816693]\n",
      "  [0.29958126]\n",
      "  [0.30236751]\n",
      "  [0.30551499]\n",
      "  [0.30959529]\n",
      "  [0.31418738]\n",
      "  [0.31937206]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0730091780424118\n",
      "Predicci√≥n post entrenamiento : [[0.32759604]]\n",
      "PERDIDAAAA despues: 0.07125382870435715\n",
      "loss en el callback: 0.05453910678625107, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "ejemplar: [[0.29816693]\n",
      " [0.29958126]\n",
      " [0.30236751]\n",
      " [0.30551499]\n",
      " [0.30959529]\n",
      " [0.31418738]\n",
      " [0.31937206]\n",
      " [0.32432806]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5984968478614763\n",
      "Predicci√≥n : [[0.329512]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[[0.29816693]\n",
      "  [0.29958126]\n",
      "  [0.30236751]\n",
      "  [0.30551499]\n",
      "  [0.30959529]\n",
      "  [0.31418738]\n",
      "  [0.31937206]\n",
      "  [0.32432806]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07235284894704819\n",
      "Predicci√≥n post entrenamiento : [[0.3327404]]\n",
      "PERDIDAAAA despues: 0.07062649726867676\n",
      "loss en el callback: 0.06945433467626572, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "ejemplar: [[0.29958126]\n",
      " [0.30236751]\n",
      " [0.30551499]\n",
      " [0.30959529]\n",
      " [0.31418738]\n",
      " [0.31937206]\n",
      " [0.32432806]\n",
      " [0.329512  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6213543446734934\n",
      "Predicci√≥n : [[0.33496895]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[[0.29958126]\n",
      "  [0.30236751]\n",
      "  [0.30551499]\n",
      "  [0.30959529]\n",
      "  [0.31418738]\n",
      "  [0.31937206]\n",
      "  [0.32432806]\n",
      "  [0.329512  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08201658725738525\n",
      "Predicci√≥n post entrenamiento : [[0.33807087]]\n",
      "PERDIDAAAA despues: 0.08024952560663223\n",
      "loss en el callback: 0.059938423335552216, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "ejemplar: [[0.30236751]\n",
      " [0.30551499]\n",
      " [0.30959529]\n",
      " [0.31418738]\n",
      " [0.31937206]\n",
      " [0.32432806]\n",
      " [0.329512  ]\n",
      " [0.33496895]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.663102676301421\n",
      "Predicci√≥n : [[0.3408726]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[[0.30236751]\n",
      "  [0.30551499]\n",
      "  [0.30959529]\n",
      "  [0.31418738]\n",
      "  [0.31937206]\n",
      "  [0.32432806]\n",
      "  [0.329512  ]\n",
      "  [0.33496895]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10383223742246628\n",
      "Predicci√≥n post entrenamiento : [[0.34469157]]\n",
      "PERDIDAAAA despues: 0.10138563811779022\n",
      "loss en el callback: 0.12904204428195953, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "ejemplar: [[0.30551499]\n",
      " [0.30959529]\n",
      " [0.31418738]\n",
      " [0.31937206]\n",
      " [0.32432806]\n",
      " [0.329512  ]\n",
      " [0.33496895]\n",
      " [0.34087259]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6928724338328028\n",
      "Predicci√≥n : [[0.3478728]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[[0.30551499]\n",
      "  [0.30959529]\n",
      "  [0.31418738]\n",
      "  [0.31937206]\n",
      "  [0.32432806]\n",
      "  [0.329512  ]\n",
      "  [0.33496895]\n",
      "  [0.34087259]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11902473121881485\n",
      "Predicci√≥n post entrenamiento : [[0.35189086]]\n",
      "PERDIDAAAA despues: 0.11626841127872467\n",
      "loss en el callback: 0.151712566614151, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "ejemplar: [[0.30959529]\n",
      " [0.31418738]\n",
      " [0.31937206]\n",
      " [0.32432806]\n",
      " [0.329512  ]\n",
      " [0.33496895]\n",
      " [0.34087259]\n",
      " [0.34787279]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.710663617267639\n",
      "Predicci√≥n : [[0.35547075]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[[0.30959529]\n",
      "  [0.31418738]\n",
      "  [0.31937206]\n",
      "  [0.32432806]\n",
      "  [0.329512  ]\n",
      "  [0.33496895]\n",
      "  [0.34087259]\n",
      "  [0.34787279]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12616197764873505\n",
      "Predicci√≥n post entrenamiento : [[0.35962084]]\n",
      "PERDIDAAAA despues: 0.12323103100061417\n",
      "loss en el callback: 0.11343304067850113, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "ejemplar: [[0.31418738]\n",
      " [0.31937206]\n",
      " [0.32432806]\n",
      " [0.329512  ]\n",
      " [0.33496895]\n",
      " [0.34087259]\n",
      " [0.34787279]\n",
      " [0.35547075]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7216820581308059\n",
      "Predicci√≥n : [[0.3634801]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[[0.31418738]\n",
      "  [0.31937206]\n",
      "  [0.32432806]\n",
      "  [0.329512  ]\n",
      "  [0.33496895]\n",
      "  [0.34087259]\n",
      "  [0.34787279]\n",
      "  [0.35547075]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12830865383148193\n",
      "Predicci√≥n post entrenamiento : [[0.36738893]]\n",
      "PERDIDAAAA despues: 0.1255236268043518\n",
      "loss en el callback: 0.14857469499111176, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "ejemplar: [[0.31937206]\n",
      " [0.32432806]\n",
      " [0.329512  ]\n",
      " [0.33496895]\n",
      " [0.34087259]\n",
      " [0.34787279]\n",
      " [0.35547075]\n",
      " [0.36348009]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7259277564223031\n",
      "Predicci√≥n : [[0.37149712]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[[0.31937206]\n",
      "  [0.32432806]\n",
      "  [0.329512  ]\n",
      "  [0.33496895]\n",
      "  [0.34087259]\n",
      "  [0.34787279]\n",
      "  [0.35547075]\n",
      "  [0.36348009]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12562108039855957\n",
      "Predicci√≥n post entrenamiento : [[0.37540764]]\n",
      "PERDIDAAAA despues: 0.12286436557769775\n",
      "loss en el callback: 0.14539600908756256, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "ejemplar: [[0.32432806]\n",
      " [0.329512  ]\n",
      " [0.33496895]\n",
      " [0.34087259]\n",
      " [0.34787279]\n",
      " [0.35547075]\n",
      " [0.36348009]\n",
      " [0.37149712]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7404318224413275\n",
      "Predicci√≥n : [[0.37971446]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[[0.32432806]\n",
      "  [0.329512  ]\n",
      "  [0.33496895]\n",
      "  [0.34087259]\n",
      "  [0.34787279]\n",
      "  [0.35547075]\n",
      "  [0.36348009]\n",
      "  [0.37149712]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1301170289516449\n",
      "Predicci√≥n post entrenamiento : [[0.38362554]]\n",
      "PERDIDAAAA despues: 0.12731073796749115\n",
      "loss en el callback: 0.1482456624507904, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "ejemplar: [[0.329512  ]\n",
      " [0.33496895]\n",
      " [0.34087259]\n",
      " [0.34787279]\n",
      " [0.35547075]\n",
      " [0.36348009]\n",
      " [0.37149712]\n",
      " [0.37971446]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7651942561878792\n",
      "Predicci√≥n : [[0.3882826]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[[0.329512  ]\n",
      "  [0.33496895]\n",
      "  [0.34087259]\n",
      "  [0.34787279]\n",
      "  [0.35547075]\n",
      "  [0.36348009]\n",
      "  [0.37149712]\n",
      "  [0.37971446]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14206238090991974\n",
      "Predicci√≥n post entrenamiento : [[0.39198497]]\n",
      "PERDIDAAAA despues: 0.1392851620912552\n",
      "loss en el callback: 0.0861264020204544, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "ejemplar: [[0.33496895]\n",
      " [0.34087259]\n",
      " [0.34787279]\n",
      " [0.35547075]\n",
      " [0.36348009]\n",
      " [0.37149712]\n",
      " [0.37971446]\n",
      " [0.3882826 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7447890964420396\n",
      "Predicci√≥n : [[0.39705262]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[[0.33496895]\n",
      "  [0.34087259]\n",
      "  [0.34787279]\n",
      "  [0.35547075]\n",
      "  [0.36348009]\n",
      "  [0.37149712]\n",
      "  [0.37971446]\n",
      "  [0.3882826 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12092068046331406\n",
      "Predicci√≥n post entrenamiento : [[0.40056992]]\n",
      "PERDIDAAAA despues: 0.11848686635494232\n",
      "loss en el callback: 0.09384629875421524, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "ejemplar: [[0.34087259]\n",
      " [0.34787279]\n",
      " [0.35547075]\n",
      " [0.36348009]\n",
      " [0.37149712]\n",
      " [0.37971446]\n",
      " [0.3882826 ]\n",
      " [0.39705262]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6792163432038085\n",
      "Predicci√≥n : [[0.4061001]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[[0.34087259]\n",
      "  [0.34787279]\n",
      "  [0.35547075]\n",
      "  [0.36348009]\n",
      "  [0.37149712]\n",
      "  [0.37971446]\n",
      "  [0.3882826 ]\n",
      "  [0.39705262]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0745924785733223\n",
      "Predicci√≥n post entrenamiento : [[0.4083633]]\n",
      "PERDIDAAAA despues: 0.0733613520860672\n",
      "loss en el callback: 0.032070502638816833, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "ejemplar: [[0.34787279]\n",
      " [0.35547075]\n",
      " [0.36348009]\n",
      " [0.37149712]\n",
      " [0.37971446]\n",
      " [0.3882826 ]\n",
      " [0.39705262]\n",
      " [0.40610009]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6746017659154131\n",
      "Predicci√≥n : [[0.41435927]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[[0.34787279]\n",
      "  [0.35547075]\n",
      "  [0.36348009]\n",
      "  [0.37149712]\n",
      "  [0.37971446]\n",
      "  [0.3882826 ]\n",
      "  [0.39705262]\n",
      "  [0.40610009]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06772617250680923\n",
      "Predicci√≥n post entrenamiento : [[0.41700286]]\n",
      "PERDIDAAAA despues: 0.06635721027851105\n",
      "loss en el callback: 0.05277665704488754, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "ejemplar: [[0.35547075]\n",
      " [0.36348009]\n",
      " [0.37149712]\n",
      " [0.37971446]\n",
      " [0.3882826 ]\n",
      " [0.39705262]\n",
      " [0.40610009]\n",
      " [0.41435927]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7309453645768532\n",
      "Predicci√≥n : [[0.42328942]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[[0.35547075]\n",
      "  [0.36348009]\n",
      "  [0.37149712]\n",
      "  [0.37971446]\n",
      "  [0.3882826 ]\n",
      "  [0.39705262]\n",
      "  [0.40610009]\n",
      "  [0.41435927]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09465216845273972\n",
      "Predicci√≥n post entrenamiento : [[0.42626235]]\n",
      "PERDIDAAAA despues: 0.09283173084259033\n",
      "loss en el callback: 0.074867844581604, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "ejemplar: [[0.36348009]\n",
      " [0.37149712]\n",
      " [0.37971446]\n",
      " [0.3882826 ]\n",
      " [0.39705262]\n",
      " [0.40610009]\n",
      " [0.41435927]\n",
      " [0.42328942]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7467210055914982\n",
      "Predicci√≥n : [[0.432753]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[[0.36348009]\n",
      "  [0.37149712]\n",
      "  [0.37971446]\n",
      "  [0.3882826 ]\n",
      "  [0.39705262]\n",
      "  [0.40610009]\n",
      "  [0.41435927]\n",
      "  [0.42328942]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09857592731714249\n",
      "Predicci√≥n post entrenamiento : [[0.43569604]]\n",
      "PERDIDAAAA despues: 0.09673655033111572\n",
      "loss en el callback: 0.07106838375329971, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "ejemplar: [[0.37149712]\n",
      " [0.37971446]\n",
      " [0.3882826 ]\n",
      " [0.39705262]\n",
      " [0.40610009]\n",
      " [0.41435927]\n",
      " [0.42328942]\n",
      " [0.432753  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7219286889593481\n",
      "Predicci√≥n : [[0.4423331]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[[0.37149712]\n",
      "  [0.37971446]\n",
      "  [0.3882826 ]\n",
      "  [0.39705262]\n",
      "  [0.40610009]\n",
      "  [0.41435927]\n",
      "  [0.42328942]\n",
      "  [0.432753  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07817370444536209\n",
      "Predicci√≥n post entrenamiento : [[0.44456533]]\n",
      "PERDIDAAAA despues: 0.0769304484128952\n",
      "loss en el callback: 0.03970540314912796, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "ejemplar: [[0.37971446]\n",
      " [0.3882826 ]\n",
      " [0.39705262]\n",
      " [0.40610009]\n",
      " [0.41435927]\n",
      " [0.42328942]\n",
      " [0.432753  ]\n",
      " [0.4423331 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7199286701160912\n",
      "Predicci√≥n : [[0.4513852]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[[0.37971446]\n",
      "  [0.3882826 ]\n",
      "  [0.39705262]\n",
      "  [0.40610009]\n",
      "  [0.41435927]\n",
      "  [0.42328942]\n",
      "  [0.432753  ]\n",
      "  [0.4423331 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07211560010910034\n",
      "Predicci√≥n post entrenamiento : [[0.4538198]]\n",
      "PERDIDAAAA despues: 0.07081393152475357\n",
      "loss en el callback: 0.055674873292446136, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "ejemplar: [[0.3882826 ]\n",
      " [0.39705262]\n",
      " [0.40610009]\n",
      " [0.41435927]\n",
      " [0.42328942]\n",
      " [0.432753  ]\n",
      " [0.4423331 ]\n",
      " [0.4513852 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7407209490617273\n",
      "Predicci√≥n : [[0.46081492]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[[0.3882826 ]\n",
      "  [0.39705262]\n",
      "  [0.40610009]\n",
      "  [0.41435927]\n",
      "  [0.42328942]\n",
      "  [0.432753  ]\n",
      "  [0.4423331 ]\n",
      "  [0.4513852 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07834737002849579\n",
      "Predicci√≥n post entrenamiento : [[0.4637741]]\n",
      "PERDIDAAAA despues: 0.07669954001903534\n",
      "loss en el callback: 0.11844263225793839, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "ejemplar: [[0.39705262]\n",
      " [0.40610009]\n",
      " [0.41435927]\n",
      " [0.42328942]\n",
      " [0.432753  ]\n",
      " [0.4423331 ]\n",
      " [0.4513852 ]\n",
      " [0.46081492]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.736245501831604\n",
      "Predicci√≥n : [[0.47089306]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[[0.39705262]\n",
      "  [0.40610009]\n",
      "  [0.41435927]\n",
      "  [0.42328942]\n",
      "  [0.432753  ]\n",
      "  [0.4423331 ]\n",
      "  [0.4513852 ]\n",
      "  [0.46081492]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07041192799806595\n",
      "Predicci√≥n post entrenamiento : [[0.47359326]]\n",
      "PERDIDAAAA despues: 0.0689861997961998\n",
      "loss en el callback: 0.0949021726846695, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "ejemplar: [[0.40610009]\n",
      " [0.41435927]\n",
      " [0.42328942]\n",
      " [0.432753  ]\n",
      " [0.4423331 ]\n",
      " [0.4513852 ]\n",
      " [0.46081492]\n",
      " [0.47089306]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7065023284257214\n",
      "Predicci√≥n : [[0.48081598]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[[0.40610009]\n",
      "  [0.41435927]\n",
      "  [0.42328942]\n",
      "  [0.432753  ]\n",
      "  [0.4423331 ]\n",
      "  [0.4513852 ]\n",
      "  [0.46081492]\n",
      "  [0.47089306]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0509343259036541\n",
      "Predicci√≥n post entrenamiento : [[0.48285106]]\n",
      "PERDIDAAAA despues: 0.05001988634467125\n",
      "loss en el callback: 0.04266804829239845, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "ejemplar: [[0.41435927]\n",
      " [0.42328942]\n",
      " [0.432753  ]\n",
      " [0.4423331 ]\n",
      " [0.4513852 ]\n",
      " [0.46081492]\n",
      " [0.47089306]\n",
      " [0.48081598]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6979451506854685\n",
      "Predicci√≥n : [[0.49013528]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[[0.41435927]\n",
      "  [0.42328942]\n",
      "  [0.432753  ]\n",
      "  [0.4423331 ]\n",
      "  [0.4513852 ]\n",
      "  [0.46081492]\n",
      "  [0.47089306]\n",
      "  [0.48081598]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.043184950947761536\n",
      "Predicci√≥n post entrenamiento : [[0.49203083]]\n",
      "PERDIDAAAA despues: 0.04240071773529053\n",
      "loss en el callback: 0.04371565952897072, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "ejemplar: [[0.42328942]\n",
      " [0.432753  ]\n",
      " [0.4423331 ]\n",
      " [0.4513852 ]\n",
      " [0.46081492]\n",
      " [0.47089306]\n",
      " [0.48081598]\n",
      " [0.49013528]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7105739686108449\n",
      "Predicci√≥n : [[0.49961045]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[[0.42328942]\n",
      "  [0.432753  ]\n",
      "  [0.4423331 ]\n",
      "  [0.4513852 ]\n",
      "  [0.46081492]\n",
      "  [0.47089306]\n",
      "  [0.48081598]\n",
      "  [0.49013528]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04450560733675957\n",
      "Predicci√≥n post entrenamiento : [[0.5014141]]\n",
      "PERDIDAAAA despues: 0.04374784231185913\n",
      "loss en el callback: 0.03960515186190605, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "ejemplar: [[0.432753  ]\n",
      " [0.4423331 ]\n",
      " [0.4513852 ]\n",
      " [0.46081492]\n",
      " [0.47089306]\n",
      " [0.48081598]\n",
      " [0.49013528]\n",
      " [0.49961045]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7209621522504839\n",
      "Predicci√≥n : [[0.5091653]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[[0.432753  ]\n",
      "  [0.4423331 ]\n",
      "  [0.4513852 ]\n",
      "  [0.46081492]\n",
      "  [0.47089306]\n",
      "  [0.48081598]\n",
      "  [0.49013528]\n",
      "  [0.49961045]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.044857919216156006\n",
      "Predicci√≥n post entrenamiento : [[0.51074326]]\n",
      "PERDIDAAAA despues: 0.04419199004769325\n",
      "loss en el callback: 0.024856358766555786, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "ejemplar: [[0.4423331 ]\n",
      " [0.4513852 ]\n",
      " [0.46081492]\n",
      " [0.47089306]\n",
      " [0.48081598]\n",
      " [0.49013528]\n",
      " [0.49961045]\n",
      " [0.50916529]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7291097016043858\n",
      "Predicci√≥n : [[0.51854926]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[[0.4423331 ]\n",
      "  [0.4513852 ]\n",
      "  [0.46081492]\n",
      "  [0.47089306]\n",
      "  [0.48081598]\n",
      "  [0.49013528]\n",
      "  [0.49961045]\n",
      "  [0.50916529]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04433570057153702\n",
      "Predicci√≥n post entrenamiento : [[0.52056164]]\n",
      "PERDIDAAAA despues: 0.04349229857325554\n",
      "loss en el callback: 0.050231948494911194, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "ejemplar: [[0.4513852 ]\n",
      " [0.46081492]\n",
      " [0.47089306]\n",
      " [0.48081598]\n",
      " [0.49013528]\n",
      " [0.49961045]\n",
      " [0.50916529]\n",
      " [0.51854926]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7674259644168786\n",
      "Predicci√≥n : [[0.5283964]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[[0.4513852 ]\n",
      "  [0.46081492]\n",
      "  [0.47089306]\n",
      "  [0.48081598]\n",
      "  [0.49013528]\n",
      "  [0.49961045]\n",
      "  [0.50916529]\n",
      "  [0.51854926]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.057135116308927536\n",
      "Predicci√≥n post entrenamiento : [[0.5306711]]\n",
      "PERDIDAAAA despues: 0.05605285242199898\n",
      "loss en el callback: 0.060116831213235855, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "ejemplar: [[0.46081492]\n",
      " [0.47089306]\n",
      " [0.48081598]\n",
      " [0.49013528]\n",
      " [0.49961045]\n",
      " [0.50916529]\n",
      " [0.51854926]\n",
      " [0.52839643]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8359109406879621\n",
      "Predicci√≥n : [[0.5386784]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[[0.46081492]\n",
      "  [0.47089306]\n",
      "  [0.48081598]\n",
      "  [0.49013528]\n",
      "  [0.49961045]\n",
      "  [0.50916529]\n",
      "  [0.51854926]\n",
      "  [0.52839643]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0883471667766571\n",
      "Predicci√≥n post entrenamiento : [[0.54106945]]\n",
      "PERDIDAAAA despues: 0.0869314894080162\n",
      "loss en el callback: 0.058166731148958206, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "ejemplar: [[0.47089306]\n",
      " [0.48081598]\n",
      " [0.49013528]\n",
      " [0.49961045]\n",
      " [0.50916529]\n",
      " [0.51854926]\n",
      " [0.52839643]\n",
      " [0.53867841]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8510103358824123\n",
      "Predicci√≥n : [[0.54917085]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[[0.47089306]\n",
      "  [0.48081598]\n",
      "  [0.49013528]\n",
      "  [0.49961045]\n",
      "  [0.50916529]\n",
      "  [0.51854926]\n",
      "  [0.52839643]\n",
      "  [0.53867841]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09110706299543381\n",
      "Predicci√≥n post entrenamiento : [[0.551933]]\n",
      "PERDIDAAAA despues: 0.0894472524523735\n",
      "loss en el callback: 0.08644954860210419, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "ejemplar: [[0.48081598]\n",
      " [0.49013528]\n",
      " [0.49961045]\n",
      " [0.50916529]\n",
      " [0.51854926]\n",
      " [0.52839643]\n",
      " [0.53867841]\n",
      " [0.54917085]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8127241500002294\n",
      "Predicci√≥n : [[0.5599681]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[[0.48081598]\n",
      "  [0.49013528]\n",
      "  [0.49961045]\n",
      "  [0.50916529]\n",
      "  [0.51854926]\n",
      "  [0.52839643]\n",
      "  [0.53867841]\n",
      "  [0.54917085]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06388562172651291\n",
      "Predicci√≥n post entrenamiento : [[0.5622867]]\n",
      "PERDIDAAAA despues: 0.0627189427614212\n",
      "loss en el callback: 0.06723611801862717, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "ejemplar: [[0.49013528]\n",
      " [0.49961045]\n",
      " [0.50916529]\n",
      " [0.51854926]\n",
      " [0.52839643]\n",
      " [0.53867841]\n",
      " [0.54917085]\n",
      " [0.55996811]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7863940290280375\n",
      "Predicci√≥n : [[0.5702971]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[[0.49013528]\n",
      "  [0.49961045]\n",
      "  [0.50916529]\n",
      "  [0.51854926]\n",
      "  [0.52839643]\n",
      "  [0.53867841]\n",
      "  [0.54917085]\n",
      "  [0.55996811]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.046697862446308136\n",
      "Predicci√≥n post entrenamiento : [[0.57226914]]\n",
      "PERDIDAAAA despues: 0.045849453657865524\n",
      "loss en el callback: 0.04917772486805916, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "ejemplar: [[0.49961045]\n",
      " [0.50916529]\n",
      " [0.51854926]\n",
      " [0.52839643]\n",
      " [0.53867841]\n",
      " [0.54917085]\n",
      " [0.55996811]\n",
      " [0.57029712]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7720199729658365\n",
      "Predicci√≥n : [[0.5804361]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[[0.49961045]\n",
      "  [0.50916529]\n",
      "  [0.51854926]\n",
      "  [0.52839643]\n",
      "  [0.53867841]\n",
      "  [0.54917085]\n",
      "  [0.55996811]\n",
      "  [0.57029712]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03670438006520271\n",
      "Predicci√≥n post entrenamiento : [[0.58229285]]\n",
      "PERDIDAAAA despues: 0.03599638119339943\n",
      "loss en el callback: 0.04571088030934334, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "ejemplar: [[0.50916529]\n",
      " [0.51854926]\n",
      " [0.52839643]\n",
      " [0.53867841]\n",
      " [0.54917085]\n",
      " [0.55996811]\n",
      " [0.57029712]\n",
      " [0.58043611]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8033170564228299\n",
      "Predicci√≥n : [[0.5906168]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[[0.50916529]\n",
      "  [0.51854926]\n",
      "  [0.52839643]\n",
      "  [0.53867841]\n",
      "  [0.54917085]\n",
      "  [0.55996811]\n",
      "  [0.57029712]\n",
      "  [0.58043611]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04524139687418938\n",
      "Predicci√≥n post entrenamiento : [[0.5924218]]\n",
      "PERDIDAAAA despues: 0.04447680339217186\n",
      "loss en el callback: 0.03808457776904106, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "ejemplar: [[0.51854926]\n",
      " [0.52839643]\n",
      " [0.53867841]\n",
      " [0.54917085]\n",
      " [0.55996811]\n",
      " [0.57029712]\n",
      " [0.58043611]\n",
      " [0.59061682]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8802852793990171\n",
      "Predicci√≥n : [[0.6009194]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[[0.51854926]\n",
      "  [0.52839643]\n",
      "  [0.53867841]\n",
      "  [0.54917085]\n",
      "  [0.55996811]\n",
      "  [0.57029712]\n",
      "  [0.58043611]\n",
      "  [0.59061682]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07804527133703232\n",
      "Predicci√≥n post entrenamiento : [[0.6035172]]\n",
      "PERDIDAAAA despues: 0.0766005739569664\n",
      "loss en el callback: 0.11454300582408905, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "ejemplar: [[0.52839643]\n",
      " [0.53867841]\n",
      " [0.54917085]\n",
      " [0.55996811]\n",
      " [0.57029712]\n",
      " [0.58043611]\n",
      " [0.59061682]\n",
      " [0.60091943]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8987051676996881\n",
      "Predicci√≥n : [[0.61227304]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[[0.52839643]\n",
      "  [0.53867841]\n",
      "  [0.54917085]\n",
      "  [0.55996811]\n",
      "  [0.57029712]\n",
      "  [0.58043611]\n",
      "  [0.59061682]\n",
      "  [0.60091943]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0820433720946312\n",
      "Predicci√≥n post entrenamiento : [[0.61446035]]\n",
      "PERDIDAAAA despues: 0.08079512417316437\n",
      "loss en el callback: 0.05143941193819046, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "ejemplar: [[0.53867841]\n",
      " [0.54917085]\n",
      " [0.55996811]\n",
      " [0.57029712]\n",
      " [0.58043611]\n",
      " [0.59061682]\n",
      " [0.60091943]\n",
      " [0.61227304]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8585767213248423\n",
      "Predicci√≥n : [[0.6233884]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[[0.53867841]\n",
      "  [0.54917085]\n",
      "  [0.55996811]\n",
      "  [0.57029712]\n",
      "  [0.58043611]\n",
      "  [0.59061682]\n",
      "  [0.60091943]\n",
      "  [0.61227304]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05531353875994682\n",
      "Predicci√≥n post entrenamiento : [[0.62470365]]\n",
      "PERDIDAAAA despues: 0.05469661206007004\n",
      "loss en el callback: 0.01776580885052681, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "ejemplar: [[0.54917085]\n",
      " [0.55996811]\n",
      " [0.57029712]\n",
      " [0.58043611]\n",
      " [0.59061682]\n",
      " [0.60091943]\n",
      " [0.61227304]\n",
      " [0.62338841]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8308762565987861\n",
      "Predicci√≥n : [[0.63370967]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[[0.54917085]\n",
      "  [0.55996811]\n",
      "  [0.57029712]\n",
      "  [0.58043611]\n",
      "  [0.59061682]\n",
      "  [0.60091943]\n",
      "  [0.61227304]\n",
      "  [0.62338841]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03887465223670006\n",
      "Predicci√≥n post entrenamiento : [[0.63552845]]\n",
      "PERDIDAAAA despues: 0.03816075623035431\n",
      "loss en el callback: 0.04882514849305153, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "ejemplar: [[0.55996811]\n",
      " [0.57029712]\n",
      " [0.58043611]\n",
      " [0.59061682]\n",
      " [0.60091943]\n",
      " [0.61227304]\n",
      " [0.62338841]\n",
      " [0.63370967]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8156037735215196\n",
      "Predicci√≥n : [[0.64456886]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[[0.55996811]\n",
      "  [0.57029712]\n",
      "  [0.58043611]\n",
      "  [0.59061682]\n",
      "  [0.60091943]\n",
      "  [0.61227304]\n",
      "  [0.62338841]\n",
      "  [0.63370967]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.029252948239445686\n",
      "Predicci√≥n post entrenamiento : [[0.64656806]]\n",
      "PERDIDAAAA despues: 0.02857307903468609\n",
      "loss en el callback: 0.07273174822330475, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "ejemplar: [[0.57029712]\n",
      " [0.58043611]\n",
      " [0.59061682]\n",
      " [0.60091943]\n",
      " [0.61227304]\n",
      " [0.62338841]\n",
      " [0.63370967]\n",
      " [0.64456886]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8116992058331503\n",
      "Predicci√≥n : [[0.65556735]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[[0.57029712]\n",
      "  [0.58043611]\n",
      "  [0.59061682]\n",
      "  [0.60091943]\n",
      "  [0.61227304]\n",
      "  [0.62338841]\n",
      "  [0.63370967]\n",
      "  [0.64456886]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.024377157911658287\n",
      "Predicci√≥n post entrenamiento : [[0.65686953]]\n",
      "PERDIDAAAA despues: 0.023972230032086372\n",
      "loss en el callback: 0.025678306818008423, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "ejemplar: [[0.58043611]\n",
      " [0.59061682]\n",
      " [0.60091943]\n",
      " [0.61227304]\n",
      " [0.62338841]\n",
      " [0.63370967]\n",
      " [0.64456886]\n",
      " [0.65556735]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8191625535336788\n",
      "Predicci√≥n : [[0.6659601]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[[0.58043611]\n",
      "  [0.59061682]\n",
      "  [0.60091943]\n",
      "  [0.61227304]\n",
      "  [0.62338841]\n",
      "  [0.63370967]\n",
      "  [0.64456886]\n",
      "  [0.65556735]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02347099781036377\n",
      "Predicci√≥n post entrenamiento : [[0.6671187]]\n",
      "PERDIDAAAA despues: 0.023117322474718094\n",
      "loss en el callback: 0.018421895802021027, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "ejemplar: [[0.59061682]\n",
      " [0.60091943]\n",
      " [0.61227304]\n",
      " [0.62338841]\n",
      " [0.63370967]\n",
      " [0.64456886]\n",
      " [0.65556735]\n",
      " [0.66596007]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8218275636038536\n",
      "Predicci√≥n : [[0.6763747]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[[0.59061682]\n",
      "  [0.60091943]\n",
      "  [0.61227304]\n",
      "  [0.62338841]\n",
      "  [0.63370967]\n",
      "  [0.64456886]\n",
      "  [0.65556735]\n",
      "  [0.66596007]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0211565513163805\n",
      "Predicci√≥n post entrenamiento : [[0.6776298]]\n",
      "PERDIDAAAA despues: 0.020792994648218155\n",
      "loss en el callback: 0.022499974817037582, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "ejemplar: [[0.60091943]\n",
      " [0.61227304]\n",
      " [0.62338841]\n",
      " [0.63370967]\n",
      " [0.64456886]\n",
      " [0.65556735]\n",
      " [0.66596007]\n",
      " [0.67637467]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8196942360436743\n",
      "Predicci√≥n : [[0.6870639]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[[0.60091943]\n",
      "  [0.61227304]\n",
      "  [0.62338841]\n",
      "  [0.63370967]\n",
      "  [0.64456886]\n",
      "  [0.65556735]\n",
      "  [0.66596007]\n",
      "  [0.67637467]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017590809613466263\n",
      "Predicci√≥n post entrenamiento : [[0.6877914]]\n",
      "PERDIDAAAA despues: 0.017398351803421974\n",
      "loss en el callback: 0.006983068771660328, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "ejemplar: [[0.61227304]\n",
      " [0.62338841]\n",
      " [0.63370967]\n",
      " [0.64456886]\n",
      " [0.65556735]\n",
      " [0.66596007]\n",
      " [0.67637467]\n",
      " [0.68706387]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8178628420548653\n",
      "Predicci√≥n : [[0.69738483]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[[0.61227304]\n",
      "  [0.62338841]\n",
      "  [0.63370967]\n",
      "  [0.64456886]\n",
      "  [0.65556735]\n",
      "  [0.66596007]\n",
      "  [0.67637467]\n",
      "  [0.68706387]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014514956623315811\n",
      "Predicci√≥n post entrenamiento : [[0.69827104]]\n",
      "PERDIDAAAA despues: 0.014302206225693226\n",
      "loss en el callback: 0.010722149163484573, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "ejemplar: [[0.62338841]\n",
      " [0.63370967]\n",
      " [0.64456886]\n",
      " [0.65556735]\n",
      " [0.66596007]\n",
      " [0.67637467]\n",
      " [0.68706387]\n",
      " [0.69738483]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8163333816374257\n",
      "Predicci√≥n : [[0.70773053]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[[0.62338841]\n",
      "  [0.63370967]\n",
      "  [0.64456886]\n",
      "  [0.65556735]\n",
      "  [0.66596007]\n",
      "  [0.67637467]\n",
      "  [0.68706387]\n",
      "  [0.69738483]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011794572696089745\n",
      "Predicci√≥n post entrenamiento : [[0.7082784]]\n",
      "PERDIDAAAA despues: 0.01167586911469698\n",
      "loss en el callback: 0.003984022419899702, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "ejemplar: [[0.63370967]\n",
      " [0.64456886]\n",
      " [0.65556735]\n",
      " [0.66596007]\n",
      " [0.67637467]\n",
      " [0.68706387]\n",
      " [0.69738483]\n",
      " [0.70773053]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8005556061309519\n",
      "Predicci√≥n : [[0.7176343]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[[0.63370967]\n",
      "  [0.64456886]\n",
      "  [0.65556735]\n",
      "  [0.66596007]\n",
      "  [0.67637467]\n",
      "  [0.68706387]\n",
      "  [0.69738483]\n",
      "  [0.70773053]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006875936407595873\n",
      "Predicci√≥n post entrenamiento : [[0.71803296]]\n",
      "PERDIDAAAA despues: 0.006809984799474478\n",
      "loss en el callback: 0.002190185943618417, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "ejemplar: [[0.64456886]\n",
      " [0.65556735]\n",
      " [0.66596007]\n",
      " [0.67637467]\n",
      " [0.68706387]\n",
      " [0.69738483]\n",
      " [0.70773053]\n",
      " [0.71763432]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7705295155354442\n",
      "Predicci√≥n : [[0.72748154]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[[0.64456886]\n",
      "  [0.65556735]\n",
      "  [0.66596007]\n",
      "  [0.67637467]\n",
      "  [0.68706387]\n",
      "  [0.69738483]\n",
      "  [0.70773053]\n",
      "  [0.71763432]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018531272653490305\n",
      "Predicci√≥n post entrenamiento : [[0.726873]]\n",
      "PERDIDAAAA despues: 0.0019058923935517669\n",
      "loss en el callback: 0.004349415190517902, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "ejemplar: [[0.65556735]\n",
      " [0.66596007]\n",
      " [0.67637467]\n",
      " [0.68706387]\n",
      " [0.69738483]\n",
      " [0.70773053]\n",
      " [0.71763432]\n",
      " [0.72748154]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7426586795525351\n",
      "Predicci√≥n : [[0.7362488]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[[0.65556735]\n",
      "  [0.66596007]\n",
      "  [0.67637467]\n",
      "  [0.68706387]\n",
      "  [0.69738483]\n",
      "  [0.70773053]\n",
      "  [0.71763432]\n",
      "  [0.72748154]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.108660505153239e-05\n",
      "Predicci√≥n post entrenamiento : [[0.73721147]]\n",
      "PERDIDAAAA despues: 2.9672084565390833e-05\n",
      "loss en el callback: 0.017771625891327858, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "ejemplar: [[0.66596007]\n",
      " [0.67637467]\n",
      " [0.68706387]\n",
      " [0.69738483]\n",
      " [0.70773053]\n",
      " [0.71763432]\n",
      " [0.72748154]\n",
      " [0.73624879]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.716943098182225\n",
      "Predicci√≥n : [[0.7464381]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[[0.66596007]\n",
      "  [0.67637467]\n",
      "  [0.68706387]\n",
      "  [0.69738483]\n",
      "  [0.70773053]\n",
      "  [0.71763432]\n",
      "  [0.72748154]\n",
      "  [0.73624879]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008699550526216626\n",
      "Predicci√≥n post entrenamiento : [[0.7465664]]\n",
      "PERDIDAAAA despues: 0.0008775416645221412\n",
      "loss en el callback: 0.0002548597985878587, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "ejemplar: [[0.67637467]\n",
      " [0.68706387]\n",
      " [0.69738483]\n",
      " [0.70773053]\n",
      " [0.71763432]\n",
      " [0.72748154]\n",
      " [0.73624879]\n",
      " [0.74643809]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7197051306082382\n",
      "Predicci√≥n : [[0.7557659]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[[0.67637467]\n",
      "  [0.68706387]\n",
      "  [0.69738483]\n",
      "  [0.70773053]\n",
      "  [0.71763432]\n",
      "  [0.72748154]\n",
      "  [0.73624879]\n",
      "  [0.74643809]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013003820786252618\n",
      "Predicci√≥n post entrenamiento : [[0.75495595]]\n",
      "PERDIDAAAA despues: 0.0012426219182088971\n",
      "loss en el callback: 0.009267883375287056, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "ejemplar: [[0.68706387]\n",
      " [0.69738483]\n",
      " [0.70773053]\n",
      " [0.71763432]\n",
      " [0.72748154]\n",
      " [0.73624879]\n",
      " [0.74643809]\n",
      " [0.75576591]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7509447768305747\n",
      "Predicci√≥n : [[0.7640852]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[[0.68706387]\n",
      "  [0.69738483]\n",
      "  [0.70773053]\n",
      "  [0.71763432]\n",
      "  [0.72748154]\n",
      "  [0.73624879]\n",
      "  [0.74643809]\n",
      "  [0.75576591]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00017266959184780717\n",
      "Predicci√≥n post entrenamiento : [[0.7642748]]\n",
      "PERDIDAAAA despues: 0.0001776884455466643\n",
      "loss en el callback: 0.000649794063065201, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "ejemplar: [[0.69738483]\n",
      " [0.70773053]\n",
      " [0.71763432]\n",
      " [0.72748154]\n",
      " [0.73624879]\n",
      " [0.74643809]\n",
      " [0.75576591]\n",
      " [0.76408517]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.740278139029679\n",
      "Predicci√≥n : [[0.7732102]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[[0.69738483]\n",
      "  [0.70773053]\n",
      "  [0.71763432]\n",
      "  [0.72748154]\n",
      "  [0.73624879]\n",
      "  [0.74643809]\n",
      "  [0.75576591]\n",
      "  [0.76408517]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010845233919098973\n",
      "Predicci√≥n post entrenamiento : [[0.77358496]]\n",
      "PERDIDAAAA despues: 0.0011093453504145145\n",
      "loss en el callback: 0.0024213730357587337, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "ejemplar: [[0.70773053]\n",
      " [0.71763432]\n",
      " [0.72748154]\n",
      " [0.73624879]\n",
      " [0.74643809]\n",
      " [0.75576591]\n",
      " [0.76408517]\n",
      " [0.77321023]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.687705217205551\n",
      "Predicci√≥n : [[0.78236896]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[[0.70773053]\n",
      "  [0.71763432]\n",
      "  [0.72748154]\n",
      "  [0.73624879]\n",
      "  [0.74643809]\n",
      "  [0.75576591]\n",
      "  [0.76408517]\n",
      "  [0.77321023]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008961223065853119\n",
      "Predicci√≥n post entrenamiento : [[0.78155947]]\n",
      "PERDIDAAAA despues: 0.008808620274066925\n",
      "loss en el callback: 0.011481777764856815, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "ejemplar: [[0.71763432]\n",
      " [0.72748154]\n",
      " [0.73624879]\n",
      " [0.74643809]\n",
      " [0.75576591]\n",
      " [0.76408517]\n",
      " [0.77321023]\n",
      " [0.78236896]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6687695580612426\n",
      "Predicci√≥n : [[0.79012704]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[[0.71763432]\n",
      "  [0.72748154]\n",
      "  [0.73624879]\n",
      "  [0.74643809]\n",
      "  [0.75576591]\n",
      "  [0.76408517]\n",
      "  [0.77321023]\n",
      "  [0.78236896]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014727642759680748\n",
      "Predicci√≥n post entrenamiento : [[0.7882671]]\n",
      "PERDIDAAAA despues: 0.014279661700129509\n",
      "loss en el callback: 0.04686155915260315, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "ejemplar: [[0.72748154]\n",
      " [0.73624879]\n",
      " [0.74643809]\n",
      " [0.75576591]\n",
      " [0.76408517]\n",
      " [0.77321023]\n",
      " [0.78236896]\n",
      " [0.79012704]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6834711615967536\n",
      "Predicci√≥n : [[0.7966805]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[[0.72748154]\n",
      "  [0.73624879]\n",
      "  [0.74643809]\n",
      "  [0.75576591]\n",
      "  [0.76408517]\n",
      "  [0.77321023]\n",
      "  [0.78236896]\n",
      "  [0.79012704]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012816361151635647\n",
      "Predicci√≥n post entrenamiento : [[0.7958593]]\n",
      "PERDIDAAAA despues: 0.012631092220544815\n",
      "loss en el callback: 0.011217295192182064, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "ejemplar: [[0.73624879]\n",
      " [0.74643809]\n",
      " [0.75576591]\n",
      " [0.76408517]\n",
      " [0.77321023]\n",
      " [0.78236896]\n",
      " [0.79012704]\n",
      " [0.79668051]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6877052172055499\n",
      "Predicci√≥n : [[0.80407315]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[[0.73624879]\n",
      "  [0.74643809]\n",
      "  [0.75576591]\n",
      "  [0.76408517]\n",
      "  [0.77321023]\n",
      "  [0.78236896]\n",
      "  [0.79012704]\n",
      "  [0.79668051]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013541496358811855\n",
      "Predicci√≥n post entrenamiento : [[0.80256045]]\n",
      "PERDIDAAAA despues: 0.013191724196076393\n",
      "loss en el callback: 0.03179085627198219, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "ejemplar: [[0.74643809]\n",
      " [0.75576591]\n",
      " [0.76408517]\n",
      " [0.77321023]\n",
      " [0.78236896]\n",
      " [0.79012704]\n",
      " [0.79668051]\n",
      " [0.80407315]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6814717248876317\n",
      "Predicci√≥n : [[0.8108095]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[[0.74643809]\n",
      "  [0.75576591]\n",
      "  [0.76408517]\n",
      "  [0.77321023]\n",
      "  [0.78236896]\n",
      "  [0.79012704]\n",
      "  [0.79668051]\n",
      "  [0.80407315]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016728263348340988\n",
      "Predicci√≥n post entrenamiento : [[0.80866987]]\n",
      "PERDIDAAAA despues: 0.016179371625185013\n",
      "loss en el callback: 0.05904470011591911, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "ejemplar: [[0.75576591]\n",
      " [0.76408517]\n",
      " [0.77321023]\n",
      " [0.78236896]\n",
      " [0.79012704]\n",
      " [0.79668051]\n",
      " [0.80407315]\n",
      " [0.81080949]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.689261843882625\n",
      "Predicci√≥n : [[0.81647724]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[[0.75576591]\n",
      "  [0.76408517]\n",
      "  [0.77321023]\n",
      "  [0.78236896]\n",
      "  [0.79012704]\n",
      "  [0.79668051]\n",
      "  [0.80407315]\n",
      "  [0.81080949]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016183754429221153\n",
      "Predicci√≥n post entrenamiento : [[0.81486106]]\n",
      "PERDIDAAAA despues: 0.015775160863995552\n",
      "loss en el callback: 0.041730545461177826, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "ejemplar: [[0.76408517]\n",
      " [0.77321023]\n",
      " [0.78236896]\n",
      " [0.79012704]\n",
      " [0.79668051]\n",
      " [0.80407315]\n",
      " [0.81080949]\n",
      " [0.81647724]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7110755741905297\n",
      "Predicci√≥n : [[0.8223469]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[[0.76408517]\n",
      "  [0.77321023]\n",
      "  [0.78236896]\n",
      "  [0.79012704]\n",
      "  [0.79668051]\n",
      "  [0.80407315]\n",
      "  [0.81080949]\n",
      "  [0.81647724]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01238130684942007\n",
      "Predicci√≥n post entrenamiento : [[0.82110065]]\n",
      "PERDIDAAAA despues: 0.012105511501431465\n",
      "loss en el callback: 0.026123670861124992, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "ejemplar: [[0.77321023]\n",
      " [0.78236896]\n",
      " [0.79012704]\n",
      " [0.79668051]\n",
      " [0.80407315]\n",
      " [0.81080949]\n",
      " [0.81647724]\n",
      " [0.82234693]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7349108623046875\n",
      "Predicci√≥n : [[0.82844317]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[[0.77321023]\n",
      "  [0.78236896]\n",
      "  [0.79012704]\n",
      "  [0.79668051]\n",
      "  [0.80407315]\n",
      "  [0.81080949]\n",
      "  [0.81647724]\n",
      "  [0.82234693]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008748295716941357\n",
      "Predicci√≥n post entrenamiento : [[0.82810694]]\n",
      "PERDIDAAAA despues: 0.008685511536896229\n",
      "loss en el callback: 0.0022090496495366096, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "ejemplar: [[0.78236896]\n",
      " [0.79012704]\n",
      " [0.79668051]\n",
      " [0.80407315]\n",
      " [0.81080949]\n",
      " [0.81647724]\n",
      " [0.82234693]\n",
      " [0.82844317]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7607677082250986\n",
      "Predicci√≥n : [[0.83497715]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[[0.78236896]\n",
      "  [0.79012704]\n",
      "  [0.79668051]\n",
      "  [0.80407315]\n",
      "  [0.81080949]\n",
      "  [0.81647724]\n",
      "  [0.82234693]\n",
      "  [0.82844317]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00550704263150692\n",
      "Predicci√≥n post entrenamiento : [[0.8348065]]\n",
      "PERDIDAAAA despues: 0.005481744650751352\n",
      "loss en el callback: 0.0006294173072092235, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "ejemplar: [[0.79012704]\n",
      " [0.79668051]\n",
      " [0.80407315]\n",
      " [0.81080949]\n",
      " [0.81647724]\n",
      " [0.82234693]\n",
      " [0.82844317]\n",
      " [0.83497715]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7711170829224028\n",
      "Predicci√≥n : [[0.8410637]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[[0.79012704]\n",
      "  [0.79668051]\n",
      "  [0.80407315]\n",
      "  [0.81080949]\n",
      "  [0.81647724]\n",
      "  [0.82234693]\n",
      "  [0.82844317]\n",
      "  [0.83497715]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004892525263130665\n",
      "Predicci√≥n post entrenamiento : [[0.841085]]\n",
      "PERDIDAAAA despues: 0.004895510617643595\n",
      "loss en el callback: 9.525791938358452e-06, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "ejemplar: [[0.79668051]\n",
      " [0.80407315]\n",
      " [0.81080949]\n",
      " [0.81647724]\n",
      " [0.82234693]\n",
      " [0.82844317]\n",
      " [0.83497715]\n",
      " [0.84106368]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7659589863965997\n",
      "Predicci√≥n : [[0.84701383]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[[0.79668051]\n",
      "  [0.80407315]\n",
      "  [0.81080949]\n",
      "  [0.81647724]\n",
      "  [0.82234693]\n",
      "  [0.82844317]\n",
      "  [0.83497715]\n",
      "  [0.84106368]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006569891236722469\n",
      "Predicci√≥n post entrenamiento : [[0.84646416]]\n",
      "PERDIDAAAA despues: 0.006481085903942585\n",
      "loss en el callback: 0.00589948333799839, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "ejemplar: [[0.80407315]\n",
      " [0.81080949]\n",
      " [0.81647724]\n",
      " [0.82234693]\n",
      " [0.82844317]\n",
      " [0.83497715]\n",
      " [0.84106368]\n",
      " [0.84701383]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7483323528772654\n",
      "Predicci√≥n : [[0.85234624]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[[0.80407315]\n",
      "  [0.81080949]\n",
      "  [0.81647724]\n",
      "  [0.82234693]\n",
      "  [0.82844317]\n",
      "  [0.83497715]\n",
      "  [0.84106368]\n",
      "  [0.84701383]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01081888284534216\n",
      "Predicci√≥n post entrenamiento : [[0.8517456]]\n",
      "PERDIDAAAA despues: 0.010694295167922974\n",
      "loss en el callback: 0.007474495563656092, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "ejemplar: [[0.81080949]\n",
      " [0.81647724]\n",
      " [0.82234693]\n",
      " [0.82844317]\n",
      " [0.83497715]\n",
      " [0.84106368]\n",
      " [0.84701383]\n",
      " [0.85234624]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7182371823643998\n",
      "Predicci√≥n : [[0.8573053]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[[0.81080949]\n",
      "  [0.81647724]\n",
      "  [0.82234693]\n",
      "  [0.82844317]\n",
      "  [0.83497715]\n",
      "  [0.84106368]\n",
      "  [0.84701383]\n",
      "  [0.85234624]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019339943304657936\n",
      "Predicci√≥n post entrenamiento : [[0.8566482]]\n",
      "PERDIDAAAA despues: 0.019157618284225464\n",
      "loss en el callback: 0.008405504748225212, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "ejemplar: [[0.81647724]\n",
      " [0.82234693]\n",
      " [0.82844317]\n",
      " [0.83497715]\n",
      " [0.84106368]\n",
      " [0.84701383]\n",
      " [0.85234624]\n",
      " [0.85730529]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7089416644962148\n",
      "Predicci√≥n : [[0.86201304]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[[0.81647724]\n",
      "  [0.82234693]\n",
      "  [0.82844317]\n",
      "  [0.83497715]\n",
      "  [0.84106368]\n",
      "  [0.84701383]\n",
      "  [0.85234624]\n",
      "  [0.85730529]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.023430854082107544\n",
      "Predicci√≥n post entrenamiento : [[0.8614657]]\n",
      "PERDIDAAAA despues: 0.023263586685061455\n",
      "loss en el callback: 0.006174313835799694, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "ejemplar: [[0.82234693]\n",
      " [0.82844317]\n",
      " [0.83497715]\n",
      " [0.84106368]\n",
      " [0.84701383]\n",
      " [0.85234624]\n",
      " [0.85730529]\n",
      " [0.86201304]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7204457992727099\n",
      "Predicci√≥n : [[0.86690176]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[[0.82234693]\n",
      "  [0.82844317]\n",
      "  [0.83497715]\n",
      "  [0.84106368]\n",
      "  [0.84701383]\n",
      "  [0.85234624]\n",
      "  [0.85730529]\n",
      "  [0.86201304]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.021449344232678413\n",
      "Predicci√≥n post entrenamiento : [[0.86650336]]\n",
      "PERDIDAAAA despues: 0.02133280597627163\n",
      "loss en el callback: 0.003555215196684003, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "ejemplar: [[0.82844317]\n",
      " [0.83497715]\n",
      " [0.84106368]\n",
      " [0.84701383]\n",
      " [0.85234624]\n",
      " [0.85730529]\n",
      " [0.86201304]\n",
      " [0.86690176]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.770615477342717\n",
      "Predicci√≥n : [[0.87193143]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[[0.82844317]\n",
      "  [0.83497715]\n",
      "  [0.84106368]\n",
      "  [0.84701383]\n",
      "  [0.85234624]\n",
      "  [0.85730529]\n",
      "  [0.86201304]\n",
      "  [0.86690176]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010264926590025425\n",
      "Predicci√≥n post entrenamiento : [[0.8698163]]\n",
      "PERDIDAAAA despues: 0.009840807877480984\n",
      "loss en el callback: 0.06424332410097122, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "ejemplar: [[0.83497715]\n",
      " [0.84106368]\n",
      " [0.84701383]\n",
      " [0.85234624]\n",
      " [0.85730529]\n",
      " [0.86201304]\n",
      " [0.86690176]\n",
      " [0.87193143]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8594506987062355\n",
      "Predicci√≥n : [[0.8751277]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[[0.83497715]\n",
      "  [0.84106368]\n",
      "  [0.84701383]\n",
      "  [0.85234624]\n",
      "  [0.85730529]\n",
      "  [0.86201304]\n",
      "  [0.86690176]\n",
      "  [0.87193143]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00024576755822636187\n",
      "Predicci√≥n post entrenamiento : [[0.874955]]\n",
      "PERDIDAAAA despues: 0.0002403833350399509\n",
      "loss en el callback: 0.0005743841174989939, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "ejemplar: [[0.84106368]\n",
      " [0.84701383]\n",
      " [0.85234624]\n",
      " [0.85730529]\n",
      " [0.86201304]\n",
      " [0.86690176]\n",
      " [0.87193143]\n",
      " [0.87512767]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9065410812466371\n",
      "Predicci√≥n : [[0.8799589]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[[0.84106368]\n",
      "  [0.84701383]\n",
      "  [0.85234624]\n",
      "  [0.85730529]\n",
      "  [0.86201304]\n",
      "  [0.86690176]\n",
      "  [0.87193143]\n",
      "  [0.87512767]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007066123653203249\n",
      "Predicci√≥n post entrenamiento : [[0.8802324]]\n",
      "PERDIDAAAA despues: 0.0006921485182829201\n",
      "loss en el callback: 0.0014900080859661102, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "ejemplar: [[0.84701383]\n",
      " [0.85234624]\n",
      " [0.85730529]\n",
      " [0.86201304]\n",
      " [0.86690176]\n",
      " [0.87193143]\n",
      " [0.87512767]\n",
      " [0.87995893]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9118866249639219\n",
      "Predicci√≥n : [[0.88497347]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[[0.84701383]\n",
      "  [0.85234624]\n",
      "  [0.85730529]\n",
      "  [0.86201304]\n",
      "  [0.86690176]\n",
      "  [0.87193143]\n",
      "  [0.87512767]\n",
      "  [0.87995893]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007243184954859316\n",
      "Predicci√≥n post entrenamiento : [[0.88560545]]\n",
      "PERDIDAAAA despues: 0.000690700311679393\n",
      "loss en el callback: 0.008363785222172737, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "ejemplar: [[0.85234624]\n",
      " [0.85730529]\n",
      " [0.86201304]\n",
      " [0.86690176]\n",
      " [0.87193143]\n",
      " [0.87512767]\n",
      " [0.87995893]\n",
      " [0.88497347]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.904335569053715\n",
      "Predicci√≥n : [[0.8900553]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[[0.85234624]\n",
      "  [0.85730529]\n",
      "  [0.86201304]\n",
      "  [0.86690176]\n",
      "  [0.87193143]\n",
      "  [0.87512767]\n",
      "  [0.87995893]\n",
      "  [0.88497347]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00020392581063788384\n",
      "Predicci√≥n post entrenamiento : [[0.8907784]]\n",
      "PERDIDAAAA despues: 0.00018379594257567078\n",
      "loss en el callback: 0.012379317544400692, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "ejemplar: [[0.85730529]\n",
      " [0.86201304]\n",
      " [0.86690176]\n",
      " [0.87193143]\n",
      " [0.87512767]\n",
      " [0.87995893]\n",
      " [0.88497347]\n",
      " [0.8900553 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8838879135160167\n",
      "Predicci√≥n : [[0.8950622]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[[0.85730529]\n",
      "  [0.86201304]\n",
      "  [0.86690176]\n",
      "  [0.87193143]\n",
      "  [0.87512767]\n",
      "  [0.87995893]\n",
      "  [0.88497347]\n",
      "  [0.8900553 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00012486545892897993\n",
      "Predicci√≥n post entrenamiento : [[0.8943627]]\n",
      "PERDIDAAAA despues: 0.00010972145537380129\n",
      "loss en el callback: 0.008467412553727627, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "ejemplar: [[0.86201304]\n",
      " [0.86690176]\n",
      " [0.87193143]\n",
      " [0.87512767]\n",
      " [0.87995893]\n",
      " [0.88497347]\n",
      " [0.8900553 ]\n",
      " [0.89506221]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9032153489332012\n",
      "Predicci√≥n : [[0.89856243]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[[0.86201304]\n",
      "  [0.86690176]\n",
      "  [0.87193143]\n",
      "  [0.87512767]\n",
      "  [0.87995893]\n",
      "  [0.88497347]\n",
      "  [0.8900553 ]\n",
      "  [0.89506221]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.164964098483324e-05\n",
      "Predicci√≥n post entrenamiento : [[0.89929444]]\n",
      "PERDIDAAAA despues: 1.5373556379927322e-05\n",
      "loss en el callback: 0.013840253464877605, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "ejemplar: [[0.86690176]\n",
      " [0.87193143]\n",
      " [0.87512767]\n",
      " [0.87995893]\n",
      " [0.88497347]\n",
      " [0.8900553 ]\n",
      " [0.89506221]\n",
      " [0.89856243]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9623178753052692\n",
      "Predicci√≥n : [[0.9034716]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[[0.86690176]\n",
      "  [0.87193143]\n",
      "  [0.87512767]\n",
      "  [0.87995893]\n",
      "  [0.88497347]\n",
      "  [0.8900553 ]\n",
      "  [0.89506221]\n",
      "  [0.89856243]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0034628864377737045\n",
      "Predicci√≥n post entrenamiento : [[0.9040615]]\n",
      "PERDIDAAAA despues: 0.0033938067499548197\n",
      "loss en el callback: 0.007472238969057798, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "ejemplar: [[0.87193143]\n",
      " [0.87512767]\n",
      " [0.87995893]\n",
      " [0.88497347]\n",
      " [0.8900553 ]\n",
      " [0.89506221]\n",
      " [0.89856243]\n",
      " [0.90347159]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.982058820003038\n",
      "Predicci√≥n : [[0.9081588]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[[0.87193143]\n",
      "  [0.87512767]\n",
      "  [0.87995893]\n",
      "  [0.88497347]\n",
      "  [0.8900553 ]\n",
      "  [0.89506221]\n",
      "  [0.89856243]\n",
      "  [0.90347159]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005461216438561678\n",
      "Predicci√≥n post entrenamiento : [[0.9080368]]\n",
      "PERDIDAAAA despues: 0.0054792556911706924\n",
      "loss en el callback: 0.0002540364221204072, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "ejemplar: [[0.87512767]\n",
      " [0.87995893]\n",
      " [0.88497347]\n",
      " [0.8900553 ]\n",
      " [0.89506221]\n",
      " [0.89856243]\n",
      " [0.90347159]\n",
      " [0.90815878]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9624381830265082\n",
      "Predicci√≥n : [[0.91200405]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[[0.87512767]\n",
      "  [0.87995893]\n",
      "  [0.88497347]\n",
      "  [0.8900553 ]\n",
      "  [0.89506221]\n",
      "  [0.89856243]\n",
      "  [0.90347159]\n",
      "  [0.90815878]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002543599810451269\n",
      "Predicci√≥n post entrenamiento : [[0.9132126]]\n",
      "PERDIDAAAA despues: 0.0024231565184891224\n",
      "loss en el callback: 0.04718432575464249, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "ejemplar: [[0.87995893]\n",
      " [0.88497347]\n",
      " [0.8900553 ]\n",
      " [0.89506221]\n",
      " [0.89856243]\n",
      " [0.90347159]\n",
      " [0.90815878]\n",
      " [0.91200405]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9302512105217627\n",
      "Predicci√≥n : [[0.91757727]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[[0.87995893]\n",
      "  [0.88497347]\n",
      "  [0.8900553 ]\n",
      "  [0.89506221]\n",
      "  [0.89856243]\n",
      "  [0.90347159]\n",
      "  [0.90815878]\n",
      "  [0.91200405]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00016062810027506202\n",
      "Predicci√≥n post entrenamiento : [[0.91847014]]\n",
      "PERDIDAAAA despues: 0.00013879283505957574\n",
      "loss en el callback: 0.021735183894634247, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "ejemplar: [[0.88497347]\n",
      " [0.8900553 ]\n",
      " [0.89506221]\n",
      " [0.89856243]\n",
      " [0.90347159]\n",
      " [0.90815878]\n",
      " [0.91200405]\n",
      " [0.91757727]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.885497902488802\n",
      "Predicci√≥n : [[0.9227989]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[[0.88497347]\n",
      "  [0.8900553 ]\n",
      "  [0.89506221]\n",
      "  [0.89856243]\n",
      "  [0.90347159]\n",
      "  [0.90815878]\n",
      "  [0.91200405]\n",
      "  [0.91757727]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013913604198023677\n",
      "Predicci√≥n post entrenamiento : [[0.92369217]]\n",
      "PERDIDAAAA despues: 0.0014587999321520329\n",
      "loss en el callback: 0.029230646789073944, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "ejemplar: [[0.8900553 ]\n",
      " [0.89506221]\n",
      " [0.89856243]\n",
      " [0.90347159]\n",
      " [0.90815878]\n",
      " [0.91200405]\n",
      " [0.91757727]\n",
      " [0.92279887]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597025687419927\n",
      "Predicci√≥n : [[0.9279214]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[[0.8900553 ]\n",
      "  [0.89506221]\n",
      "  [0.89856243]\n",
      "  [0.90347159]\n",
      "  [0.90815878]\n",
      "  [0.91200405]\n",
      "  [0.91757727]\n",
      "  [0.92279887]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004653808195143938\n",
      "Predicci√≥n post entrenamiento : [[0.9271752]]\n",
      "PERDIDAAAA despues: 0.0045525566674768925\n",
      "loss en el callback: 0.010995158925652504, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "ejemplar: [[0.89506221]\n",
      " [0.89856243]\n",
      " [0.90347159]\n",
      " [0.90815878]\n",
      " [0.91200405]\n",
      " [0.91757727]\n",
      " [0.92279887]\n",
      " [0.92792141]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8528652092813349\n",
      "Predicci√≥n : [[0.9312748]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[[0.89506221]\n",
      "  [0.89856243]\n",
      "  [0.90347159]\n",
      "  [0.90815878]\n",
      "  [0.91200405]\n",
      "  [0.91757727]\n",
      "  [0.92279887]\n",
      "  [0.92792141]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0061480579897761345\n",
      "Predicci√≥n post entrenamiento : [[0.92928344]]\n",
      "PERDIDAAAA despues: 0.005839744582772255\n",
      "loss en el callback: 0.06799338757991791, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "ejemplar: [[0.89856243]\n",
      " [0.90347159]\n",
      " [0.90815878]\n",
      " [0.91200405]\n",
      " [0.91757727]\n",
      " [0.92279887]\n",
      " [0.92792141]\n",
      " [0.93127477]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8585854533368672\n",
      "Predicci√≥n : [[0.9332632]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[[0.89856243]\n",
      "  [0.90347159]\n",
      "  [0.90815878]\n",
      "  [0.91200405]\n",
      "  [0.91757727]\n",
      "  [0.92279887]\n",
      "  [0.92792141]\n",
      "  [0.93127477]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005576759576797485\n",
      "Predicci√≥n post entrenamiento : [[0.93249685]]\n",
      "PERDIDAAAA despues: 0.005462890490889549\n",
      "loss en el callback: 0.013020791113376617, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "ejemplar: [[0.90347159]\n",
      " [0.90815878]\n",
      " [0.91200405]\n",
      " [0.91757727]\n",
      " [0.92279887]\n",
      " [0.92792141]\n",
      " [0.93127477]\n",
      " [0.93326318]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8768633009085897\n",
      "Predicci√≥n : [[0.936781]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[[0.90347159]\n",
      "  [0.90815878]\n",
      "  [0.91200405]\n",
      "  [0.91757727]\n",
      "  [0.92279887]\n",
      "  [0.92792141]\n",
      "  [0.93127477]\n",
      "  [0.93326318]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003590129315853119\n",
      "Predicci√≥n post entrenamiento : [[0.9361887]]\n",
      "PERDIDAAAA despues: 0.0035195027012377977\n",
      "loss en el callback: 0.0077029005624353886, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "ejemplar: [[0.90815878]\n",
      " [0.91200405]\n",
      " [0.91757727]\n",
      " [0.92279887]\n",
      " [0.92792141]\n",
      " [0.93127477]\n",
      " [0.93326318]\n",
      " [0.93678099]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8806463966074481\n",
      "Predicci√≥n : [[0.940374]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[[0.90815878]\n",
      "  [0.91200405]\n",
      "  [0.91757727]\n",
      "  [0.92279887]\n",
      "  [0.92792141]\n",
      "  [0.93127477]\n",
      "  [0.93326318]\n",
      "  [0.93678099]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0035673873499035835\n",
      "Predicci√≥n post entrenamiento : [[0.9396984]]\n",
      "PERDIDAAAA despues: 0.0034871376119554043\n",
      "loss en el callback: 0.01052840705960989, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "ejemplar: [[0.91200405]\n",
      " [0.91757727]\n",
      " [0.92279887]\n",
      " [0.92792141]\n",
      " [0.93127477]\n",
      " [0.93326318]\n",
      " [0.93678099]\n",
      " [0.94037402]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8699347404334429\n",
      "Predicci√≥n : [[0.943796]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[[0.91200405]\n",
      "  [0.91757727]\n",
      "  [0.92279887]\n",
      "  [0.92792141]\n",
      "  [0.93127477]\n",
      "  [0.93326318]\n",
      "  [0.93678099]\n",
      "  [0.94037402]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005455482751131058\n",
      "Predicci√≥n post entrenamiento : [[0.9433949]]\n",
      "PERDIDAAAA despues: 0.005396395456045866\n",
      "loss en el callback: 0.004094384144991636, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "ejemplar: [[0.91757727]\n",
      " [0.92279887]\n",
      " [0.92792141]\n",
      " [0.93127477]\n",
      " [0.93326318]\n",
      " [0.93678099]\n",
      " [0.94037402]\n",
      " [0.94379598]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8465135437340043\n",
      "Predicci√≥n : [[0.9475956]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[[0.91757727]\n",
      "  [0.92279887]\n",
      "  [0.92792141]\n",
      "  [0.93127477]\n",
      "  [0.93326318]\n",
      "  [0.93678099]\n",
      "  [0.94037402]\n",
      "  [0.94379598]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010217576287686825\n",
      "Predicci√≥n post entrenamiento : [[0.94738615]]\n",
      "PERDIDAAAA despues: 0.010175276547670364\n",
      "loss en el callback: 0.0010831811232492328, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "ejemplar: [[0.92279887]\n",
      " [0.92792141]\n",
      " [0.93127477]\n",
      " [0.93326318]\n",
      " [0.93678099]\n",
      " [0.94037402]\n",
      " [0.94379598]\n",
      " [0.9475956 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8103828065091326\n",
      "Predicci√≥n : [[0.95114154]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[[0.92279887]\n",
      "  [0.92792141]\n",
      "  [0.93127477]\n",
      "  [0.93326318]\n",
      "  [0.93678099]\n",
      "  [0.94037402]\n",
      "  [0.94379598]\n",
      "  [0.9475956 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01981302723288536\n",
      "Predicci√≥n post entrenamiento : [[0.94878036]]\n",
      "PERDIDAAAA despues: 0.019153889268636703\n",
      "loss en el callback: 0.10528773069381714, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "ejemplar: [[0.92792141]\n",
      " [0.93127477]\n",
      " [0.93326318]\n",
      " [0.93678099]\n",
      " [0.94037402]\n",
      " [0.94379598]\n",
      " [0.9475956 ]\n",
      " [0.95114154]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8026111217617493\n",
      "Predicci√≥n : [[0.95209306]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[[0.92792141]\n",
      "  [0.93127477]\n",
      "  [0.93326318]\n",
      "  [0.93678099]\n",
      "  [0.94037402]\n",
      "  [0.94379598]\n",
      "  [0.9475956 ]\n",
      "  [0.95114154]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02234485372900963\n",
      "Predicci√≥n post entrenamiento : [[0.95139486]]\n",
      "PERDIDAAAA despues: 0.02213660255074501\n",
      "loss en el callback: 0.01212704461067915, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "ejemplar: [[0.93127477]\n",
      " [0.93326318]\n",
      " [0.93678099]\n",
      " [0.94037402]\n",
      " [0.94379598]\n",
      " [0.9475956 ]\n",
      " [0.95114154]\n",
      " [0.95209306]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.823198489491854\n",
      "Predicci√≥n : [[0.954207]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[[0.93127477]\n",
      "  [0.93326318]\n",
      "  [0.93678099]\n",
      "  [0.94037402]\n",
      "  [0.94379598]\n",
      "  [0.9475956 ]\n",
      "  [0.95114154]\n",
      "  [0.95209306]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0171632282435894\n",
      "Predicci√≥n post entrenamiento : [[0.9530007]]\n",
      "PERDIDAAAA despues: 0.016848618164658546\n",
      "loss en el callback: 0.03674154728651047, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "ejemplar: [[0.93326318]\n",
      " [0.93678099]\n",
      " [0.94037402]\n",
      " [0.94379598]\n",
      " [0.9475956 ]\n",
      " [0.95114154]\n",
      " [0.95209306]\n",
      " [0.954207  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8397204264676091\n",
      "Predicci√≥n : [[0.95575005]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[[0.93326318]\n",
      "  [0.93678099]\n",
      "  [0.94037402]\n",
      "  [0.94379598]\n",
      "  [0.9475956 ]\n",
      "  [0.95114154]\n",
      "  [0.95209306]\n",
      "  [0.954207  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013462873175740242\n",
      "Predicci√≥n post entrenamiento : [[0.95515]]\n",
      "PERDIDAAAA despues: 0.01332398783415556\n",
      "loss en el callback: 0.009077572263777256, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "ejemplar: [[0.93678099]\n",
      " [0.94037402]\n",
      " [0.94379598]\n",
      " [0.9475956 ]\n",
      " [0.95114154]\n",
      " [0.95209306]\n",
      " [0.954207  ]\n",
      " [0.95575005]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.852176932689015\n",
      "Predicci√≥n : [[0.95820916]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[[0.93678099]\n",
      "  [0.94037402]\n",
      "  [0.94379598]\n",
      "  [0.9475956 ]\n",
      "  [0.95114154]\n",
      "  [0.95209306]\n",
      "  [0.954207  ]\n",
      "  [0.95575005]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011242838576436043\n",
      "Predicci√≥n post entrenamiento : [[0.95845026]]\n",
      "PERDIDAAAA despues: 0.011294025927782059\n",
      "loss en el callback: 0.002010174561291933, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "ejemplar: [[0.94037402]\n",
      " [0.94379598]\n",
      " [0.9475956 ]\n",
      " [0.95114154]\n",
      " [0.95209306]\n",
      " [0.954207  ]\n",
      " [0.95575005]\n",
      " [0.95820916]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8615626813481295\n",
      "Predicci√≥n : [[0.9613676]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[[0.94037402]\n",
      "  [0.94379598]\n",
      "  [0.9475956 ]\n",
      "  [0.95114154]\n",
      "  [0.95209306]\n",
      "  [0.954207  ]\n",
      "  [0.95575005]\n",
      "  [0.95820916]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009961025789380074\n",
      "Predicci√≥n post entrenamiento : [[0.96058667]]\n",
      "PERDIDAAAA despues: 0.009805751964449883\n",
      "loss en el callback: 0.014720757491886616, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "ejemplar: [[0.94379598]\n",
      " [0.9475956 ]\n",
      " [0.95114154]\n",
      " [0.95209306]\n",
      " [0.954207  ]\n",
      " [0.95575005]\n",
      " [0.95820916]\n",
      " [0.96136761]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8678776724449532\n",
      "Predicci√≥n : [[0.9632762]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[[0.94379598]\n",
      "  [0.9475956 ]\n",
      "  [0.95114154]\n",
      "  [0.95209306]\n",
      "  [0.954207  ]\n",
      "  [0.95575005]\n",
      "  [0.95820916]\n",
      "  [0.96136761]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009100882336497307\n",
      "Predicci√≥n post entrenamiento : [[0.9632238]]\n",
      "PERDIDAAAA despues: 0.009090889245271683\n",
      "loss en el callback: 9.320288518210873e-05, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "ejemplar: [[0.9475956 ]\n",
      " [0.95114154]\n",
      " [0.95209306]\n",
      " [0.954207  ]\n",
      " [0.95575005]\n",
      " [0.95820916]\n",
      " [0.96136761]\n",
      " [0.96327621]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8701963127047843\n",
      "Predicci√≥n : [[0.96566963]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[[0.9475956 ]\n",
      "  [0.95114154]\n",
      "  [0.95209306]\n",
      "  [0.954207  ]\n",
      "  [0.95575005]\n",
      "  [0.95820916]\n",
      "  [0.96136761]\n",
      "  [0.96327621]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009115149267017841\n",
      "Predicci√≥n post entrenamiento : [[0.96478176]]\n",
      "PERDIDAAAA despues: 0.008946401067078114\n",
      "loss en el callback: 0.021324433386325836, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "ejemplar: [[0.95114154]\n",
      " [0.95209306]\n",
      " [0.954207  ]\n",
      " [0.95575005]\n",
      " [0.95820916]\n",
      " [0.96136761]\n",
      " [0.96327621]\n",
      " [0.96566963]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8685186021276227\n",
      "Predicci√≥n : [[0.96681446]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[[0.95114154]\n",
      "  [0.95209306]\n",
      "  [0.954207  ]\n",
      "  [0.95575005]\n",
      "  [0.95820916]\n",
      "  [0.96136761]\n",
      "  [0.96327621]\n",
      "  [0.96566963]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009662077762186527\n",
      "Predicci√≥n post entrenamiento : [[0.96660984]]\n",
      "PERDIDAAAA despues: 0.009621892124414444\n",
      "loss en el callback: 0.0011676277499645948, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "ejemplar: [[0.95209306]\n",
      " [0.954207  ]\n",
      " [0.95575005]\n",
      " [0.95820916]\n",
      " [0.96136761]\n",
      " [0.96327621]\n",
      " [0.96566963]\n",
      " [0.96681446]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8529880395838255\n",
      "Predicci√≥n : [[0.96823925]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[[0.95209306]\n",
      "  [0.954207  ]\n",
      "  [0.95575005]\n",
      "  [0.95820916]\n",
      "  [0.96136761]\n",
      "  [0.96327621]\n",
      "  [0.96566963]\n",
      "  [0.96681446]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013282835483551025\n",
      "Predicci√≥n post entrenamiento : [[0.9673545]]\n",
      "PERDIDAAAA despues: 0.01307967584580183\n",
      "loss en el callback: 0.02271876484155655, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "ejemplar: [[0.954207  ]\n",
      " [0.95575005]\n",
      " [0.95820916]\n",
      " [0.96136761]\n",
      " [0.96327621]\n",
      " [0.96566963]\n",
      " [0.96681446]\n",
      " [0.96823925]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8236046250733932\n",
      "Predicci√≥n : [[0.9692954]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[[0.954207  ]\n",
      "  [0.95575005]\n",
      "  [0.95820916]\n",
      "  [0.96136761]\n",
      "  [0.96327621]\n",
      "  [0.96566963]\n",
      "  [0.96681446]\n",
      "  [0.96823925]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.021225791424512863\n",
      "Predicci√≥n post entrenamiento : [[0.96716875]]\n",
      "PERDIDAAAA despues: 0.02061065286397934\n",
      "loss en el callback: 0.09677910059690475, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "ejemplar: [[0.95575005]\n",
      " [0.95820916]\n",
      " [0.96136761]\n",
      " [0.96327621]\n",
      " [0.96566963]\n",
      " [0.96681446]\n",
      " [0.96823925]\n",
      " [0.96929538]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8032508871761479\n",
      "Predicci√≥n : [[0.96910864]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[[0.95575005]\n",
      "  [0.95820916]\n",
      "  [0.96136761]\n",
      "  [0.96327621]\n",
      "  [0.96566963]\n",
      "  [0.96681446]\n",
      "  [0.96823925]\n",
      "  [0.96929538]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02750878781080246\n",
      "Predicci√≥n post entrenamiento : [[0.9679587]]\n",
      "PERDIDAAAA despues: 0.02712865360081196\n",
      "loss en el callback: 0.03472454100847244, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "ejemplar: [[0.95820916]\n",
      " [0.96136761]\n",
      " [0.96327621]\n",
      " [0.96566963]\n",
      " [0.96681446]\n",
      " [0.96823925]\n",
      " [0.96929538]\n",
      " [0.96910864]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7919268258920897\n",
      "Predicci√≥n : [[0.97003293]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[[0.95820916]\n",
      "  [0.96136761]\n",
      "  [0.96327621]\n",
      "  [0.96566963]\n",
      "  [0.96681446]\n",
      "  [0.96823925]\n",
      "  [0.96929538]\n",
      "  [0.96910864]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03172179311513901\n",
      "Predicci√≥n post entrenamiento : [[0.9686723]]\n",
      "PERDIDAAAA despues: 0.031238961964845657\n",
      "loss en el callback: 0.04897071048617363, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "ejemplar: [[0.96136761]\n",
      " [0.96327621]\n",
      " [0.96566963]\n",
      " [0.96681446]\n",
      " [0.96823925]\n",
      " [0.96929538]\n",
      " [0.96910864]\n",
      " [0.97003293]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7865023059771536\n",
      "Predicci√≥n : [[0.97057843]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[[0.96136761]\n",
      "  [0.96327621]\n",
      "  [0.96566963]\n",
      "  [0.96681446]\n",
      "  [0.96823925]\n",
      "  [0.96929538]\n",
      "  [0.96910864]\n",
      "  [0.97003293]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03388402238488197\n",
      "Predicci√≥n post entrenamiento : [[0.96905607]]\n",
      "PERDIDAAAA despues: 0.03332587704062462\n",
      "loss en el callback: 0.059499889612197876, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "ejemplar: [[0.96327621]\n",
      " [0.96566963]\n",
      " [0.96681446]\n",
      " [0.96823925]\n",
      " [0.96929538]\n",
      " [0.96910864]\n",
      " [0.97003293]\n",
      " [0.97057843]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7869773274313391\n",
      "Predicci√≥n : [[0.9705074]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[[0.96327621]\n",
      "  [0.96566963]\n",
      "  [0.96681446]\n",
      "  [0.96823925]\n",
      "  [0.96929538]\n",
      "  [0.96910864]\n",
      "  [0.97003293]\n",
      "  [0.97057843]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03368327394127846\n",
      "Predicci√≥n post entrenamiento : [[0.9681329]]\n",
      "PERDIDAAAA despues: 0.03281733766198158\n",
      "loss en el callback: 0.11907804012298584, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "ejemplar: [[0.96566963]\n",
      " [0.96681446]\n",
      " [0.96823925]\n",
      " [0.96929538]\n",
      " [0.96910864]\n",
      " [0.97003293]\n",
      " [0.97057843]\n",
      " [0.97050738]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7874362431744556\n",
      "Predicci√≥n : [[0.96938676]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[[0.96566963]\n",
      "  [0.96681446]\n",
      "  [0.96823925]\n",
      "  [0.96929538]\n",
      "  [0.96910864]\n",
      "  [0.97003293]\n",
      "  [0.97057843]\n",
      "  [0.97050738]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.033105988055467606\n",
      "Predicci√≥n post entrenamiento : [[0.96794206]]\n",
      "PERDIDAAAA despues: 0.032582350075244904\n",
      "loss en el callback: 0.05523083359003067, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "ejemplar: [[0.96681446]\n",
      " [0.96823925]\n",
      " [0.96929538]\n",
      " [0.96910864]\n",
      " [0.97003293]\n",
      " [0.97057843]\n",
      " [0.97050738]\n",
      " [0.96938676]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7878790532065031\n",
      "Predicci√≥n : [[0.96877664]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[[0.96681446]\n",
      "  [0.96823925]\n",
      "  [0.96929538]\n",
      "  [0.96910864]\n",
      "  [0.97003293]\n",
      "  [0.97057843]\n",
      "  [0.97050738]\n",
      "  [0.96938676]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.032723940908908844\n",
      "Predicci√≥n post entrenamiento : [[0.96700424]]\n",
      "PERDIDAAAA despues: 0.032085832208395004\n",
      "loss en el callback: 0.0869913250207901, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "ejemplar: [[0.96823925]\n",
      " [0.96929538]\n",
      " [0.96910864]\n",
      " [0.97003293]\n",
      " [0.97057843]\n",
      " [0.97050738]\n",
      " [0.96938676]\n",
      " [0.96877664]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7954532004373992\n",
      "Predicci√≥n : [[0.96768457]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[[0.96823925]\n",
      "  [0.96929538]\n",
      "  [0.96910864]\n",
      "  [0.97003293]\n",
      "  [0.97057843]\n",
      "  [0.97050738]\n",
      "  [0.96938676]\n",
      "  [0.96877664]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02966364659368992\n",
      "Predicci√≥n post entrenamiento : [[0.96704733]]\n",
      "PERDIDAAAA despues: 0.02944454923272133\n",
      "loss en el callback: 0.013629811815917492, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "ejemplar: [[0.96929538]\n",
      " [0.96910864]\n",
      " [0.97003293]\n",
      " [0.97057843]\n",
      " [0.97050738]\n",
      " [0.96938676]\n",
      " [0.96877664]\n",
      " [0.96768457]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8101586848671446\n",
      "Predicci√≥n : [[0.96742094]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[[0.96929538]\n",
      "  [0.96910864]\n",
      "  [0.97003293]\n",
      "  [0.97057843]\n",
      "  [0.97050738]\n",
      "  [0.96938676]\n",
      "  [0.96877664]\n",
      "  [0.96768457]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02473141998052597\n",
      "Predicci√≥n post entrenamiento : [[0.9662329]]\n",
      "PERDIDAAAA despues: 0.024359164759516716\n",
      "loss en el callback: 0.04003452509641647, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "ejemplar: [[0.96910864]\n",
      " [0.97003293]\n",
      " [0.97057843]\n",
      " [0.97050738]\n",
      " [0.96938676]\n",
      " [0.96877664]\n",
      " [0.96768457]\n",
      " [0.96742094]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7668473230866574\n",
      "Predicci√≥n : [[0.9663244]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[[0.96910864]\n",
      "  [0.97003293]\n",
      "  [0.97057843]\n",
      "  [0.97050738]\n",
      "  [0.96938676]\n",
      "  [0.96877664]\n",
      "  [0.96768457]\n",
      "  [0.96742094]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03979110345244408\n",
      "Predicci√≥n post entrenamiento : [[0.9663992]]\n",
      "PERDIDAAAA despues: 0.03982095420360565\n",
      "loss en el callback: 0.00027108078938908875, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "ejemplar: [[0.97003293]\n",
      " [0.97057843]\n",
      " [0.97050738]\n",
      " [0.96938676]\n",
      " [0.96877664]\n",
      " [0.96768457]\n",
      " [0.96742094]\n",
      " [0.96632439]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6655191150959373\n",
      "Predicci√≥n : [[0.9664989]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[[0.97003293]\n",
      "  [0.97057843]\n",
      "  [0.97050738]\n",
      "  [0.96938676]\n",
      "  [0.96877664]\n",
      "  [0.96768457]\n",
      "  [0.96742094]\n",
      "  [0.96632439]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09058883786201477\n",
      "Predicci√≥n post entrenamiento : [[0.96499723]]\n",
      "PERDIDAAAA despues: 0.08968713879585266\n",
      "loss en el callback: 0.07465200126171112, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "ejemplar: [[0.97057843]\n",
      " [0.97050738]\n",
      " [0.96938676]\n",
      " [0.96877664]\n",
      " [0.96768457]\n",
      " [0.96742094]\n",
      " [0.96632439]\n",
      " [0.96649891]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6360738003224796\n",
      "Predicci√≥n : [[0.96474737]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[[0.97057843]\n",
      "  [0.97050738]\n",
      "  [0.96938676]\n",
      "  [0.96877664]\n",
      "  [0.96768457]\n",
      "  [0.96742094]\n",
      "  [0.96632439]\n",
      "  [0.96649891]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10802629590034485\n",
      "Predicci√≥n post entrenamiento : [[0.9628714]]\n",
      "PERDIDAAAA despues: 0.10679663717746735\n",
      "loss en el callback: 0.11991894990205765, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "ejemplar: [[0.97050738]\n",
      " [0.96938676]\n",
      " [0.96877664]\n",
      " [0.96768457]\n",
      " [0.96742094]\n",
      " [0.96632439]\n",
      " [0.96649891]\n",
      " [0.96474737]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6785113787662842\n",
      "Predicci√≥n : [[0.96231055]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[[0.97050738]\n",
      "  [0.96938676]\n",
      "  [0.96877664]\n",
      "  [0.96768457]\n",
      "  [0.96742094]\n",
      "  [0.96632439]\n",
      "  [0.96649891]\n",
      "  [0.96474737]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08054196834564209\n",
      "Predicci√≥n post entrenamiento : [[0.9592076]]\n",
      "PERDIDAAAA despues: 0.07879036664962769\n",
      "loss en el callback: 0.2432786375284195, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "ejemplar: [[0.96938676]\n",
      " [0.96877664]\n",
      " [0.96768457]\n",
      " [0.96742094]\n",
      " [0.96632439]\n",
      " [0.96649891]\n",
      " [0.96474737]\n",
      " [0.96231055]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6965967339840231\n",
      "Predicci√≥n : [[0.95845485]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[[0.96938676]\n",
      "  [0.96877664]\n",
      "  [0.96768457]\n",
      "  [0.96742094]\n",
      "  [0.96632439]\n",
      "  [0.96649891]\n",
      "  [0.96474737]\n",
      "  [0.96231055]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06856966763734818\n",
      "Predicci√≥n post entrenamiento : [[0.95723104]]\n",
      "PERDIDAAAA despues: 0.06793023645877838\n",
      "loss en el callback: 0.0513884611427784, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "ejemplar: [[0.96877664]\n",
      " [0.96768457]\n",
      " [0.96742094]\n",
      " [0.96632439]\n",
      " [0.96649891]\n",
      " [0.96474737]\n",
      " [0.96231055]\n",
      " [0.95845485]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6903298659756966\n",
      "Predicci√≥n : [[0.95653546]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[[0.96877664]\n",
      "  [0.96768457]\n",
      "  [0.96742094]\n",
      "  [0.96632439]\n",
      "  [0.96649891]\n",
      "  [0.96474737]\n",
      "  [0.96231055]\n",
      "  [0.95845485]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07086542248725891\n",
      "Predicci√≥n post entrenamiento : [[0.95512193]]\n",
      "PERDIDAAAA despues: 0.0701148509979248\n",
      "loss en el callback: 0.07274743914604187, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "ejemplar: [[0.96768457]\n",
      " [0.96742094]\n",
      " [0.96632439]\n",
      " [0.96649891]\n",
      " [0.96474737]\n",
      " [0.96231055]\n",
      " [0.95845485]\n",
      " [0.95653546]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6970473058045382\n",
      "Predicci√≥n : [[0.9542953]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[[0.96768457]\n",
      "  [0.96742094]\n",
      "  [0.96632439]\n",
      "  [0.96649891]\n",
      "  [0.96474737]\n",
      "  [0.96231055]\n",
      "  [0.95845485]\n",
      "  [0.95653546]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06617652624845505\n",
      "Predicci√≥n post entrenamiento : [[0.9522767]]\n",
      "PERDIDAAAA despues: 0.06514205038547516\n",
      "loss en el callback: 0.13115185499191284, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "ejemplar: [[0.96742094]\n",
      " [0.96632439]\n",
      " [0.96649891]\n",
      " [0.96474737]\n",
      " [0.96231055]\n",
      " [0.95845485]\n",
      " [0.95653546]\n",
      " [0.95429528]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7167490534705484\n",
      "Predicci√≥n : [[0.95138776]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[[0.96742094]\n",
      "  [0.96632439]\n",
      "  [0.96649891]\n",
      "  [0.96474737]\n",
      "  [0.96231055]\n",
      "  [0.95845485]\n",
      "  [0.95653546]\n",
      "  [0.95429528]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05505531653761864\n",
      "Predicci√≥n post entrenamiento : [[0.94994116]]\n",
      "PERDIDAAAA despues: 0.05437855049967766\n",
      "loss en el callback: 0.07799319177865982, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "ejemplar: [[0.96632439]\n",
      " [0.96649891]\n",
      " [0.96474737]\n",
      " [0.96231055]\n",
      " [0.95845485]\n",
      " [0.95653546]\n",
      " [0.95429528]\n",
      " [0.95138776]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7490507063998944\n",
      "Predicci√≥n : [[0.94867635]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[[0.96632439]\n",
      "  [0.96649891]\n",
      "  [0.96474737]\n",
      "  [0.96231055]\n",
      "  [0.95845485]\n",
      "  [0.95653546]\n",
      "  [0.95429528]\n",
      "  [0.95138776]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03985041007399559\n",
      "Predicci√≥n post entrenamiento : [[0.9475145]]\n",
      "PERDIDAAAA despues: 0.03938787803053856\n",
      "loss en el callback: 0.04421970993280411, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "ejemplar: [[0.96649891]\n",
      " [0.96474737]\n",
      " [0.96231055]\n",
      " [0.95845485]\n",
      " [0.95653546]\n",
      " [0.95429528]\n",
      " [0.95138776]\n",
      " [0.94867635]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7939522645925762\n",
      "Predicci√≥n : [[0.94601125]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[[0.96649891]\n",
      "  [0.96474737]\n",
      "  [0.96231055]\n",
      "  [0.95845485]\n",
      "  [0.95653546]\n",
      "  [0.95429528]\n",
      "  [0.95138776]\n",
      "  [0.94867635]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.023121926933526993\n",
      "Predicci√≥n post entrenamiento : [[0.9453071]]\n",
      "PERDIDAAAA despues: 0.022908272221684456\n",
      "loss en el callback: 0.018480870872735977, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "ejemplar: [[0.96474737]\n",
      " [0.96231055]\n",
      " [0.95845485]\n",
      " [0.95653546]\n",
      " [0.95429528]\n",
      " [0.95138776]\n",
      " [0.94867635]\n",
      " [0.94601125]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8547447263586395\n",
      "Predicci√≥n : [[0.94311565]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[[0.96474737]\n",
      "  [0.96231055]\n",
      "  [0.95845485]\n",
      "  [0.95653546]\n",
      "  [0.95429528]\n",
      "  [0.95138776]\n",
      "  [0.94867635]\n",
      "  [0.94601125]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007809419184923172\n",
      "Predicci√≥n post entrenamiento : [[0.9419867]]\n",
      "PERDIDAAAA despues: 0.00761115737259388\n",
      "loss en el callback: 0.041103560477495193, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "ejemplar: [[0.96231055]\n",
      " [0.95845485]\n",
      " [0.95653546]\n",
      " [0.95429528]\n",
      " [0.95138776]\n",
      " [0.94867635]\n",
      " [0.94601125]\n",
      " [0.94311565]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9314280916980849\n",
      "Predicci√≥n : [[0.9395585]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[[0.96231055]\n",
      "  [0.95845485]\n",
      "  [0.95653546]\n",
      "  [0.95429528]\n",
      "  [0.95138776]\n",
      "  [0.94867635]\n",
      "  [0.94601125]\n",
      "  [0.94311565]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.61039084661752e-05\n",
      "Predicci√≥n post entrenamiento : [[0.93887746]]\n",
      "PERDIDAAAA despues: 5.549339039134793e-05\n",
      "loss en el callback: 0.014611255377531052, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "ejemplar: [[0.95845485]\n",
      " [0.95653546]\n",
      " [0.95429528]\n",
      " [0.95138776]\n",
      " [0.94867635]\n",
      " [0.94601125]\n",
      " [0.94311565]\n",
      " [0.93955851]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9627243989762315\n",
      "Predicci√≥n : [[0.9363736]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[[0.95845485]\n",
      "  [0.95653546]\n",
      "  [0.95429528]\n",
      "  [0.95138776]\n",
      "  [0.94867635]\n",
      "  [0.94601125]\n",
      "  [0.94311565]\n",
      "  [0.93955851]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006943644839338958\n",
      "Predicci√≥n post entrenamiento : [[0.9363572]]\n",
      "PERDIDAAAA despues: 0.0006952285766601562\n",
      "loss en el callback: 1.0598192602628842e-05, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "ejemplar: [[0.95653546]\n",
      " [0.95429528]\n",
      " [0.95138776]\n",
      " [0.94867635]\n",
      " [0.94601125]\n",
      " [0.94311565]\n",
      " [0.93955851]\n",
      " [0.93637359]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9486336481930799\n",
      "Predicci√≥n : [[0.93417436]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[[0.95653546]\n",
      "  [0.95429528]\n",
      "  [0.95138776]\n",
      "  [0.94867635]\n",
      "  [0.94601125]\n",
      "  [0.94311565]\n",
      "  [0.93955851]\n",
      "  [0.93637359]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002090717025566846\n",
      "Predicci√≥n post entrenamiento : [[0.93422526]]\n",
      "PERDIDAAAA despues: 0.00020760226470883936\n",
      "loss en el callback: 9.51068359427154e-05, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "ejemplar: [[0.95429528]\n",
      " [0.95138776]\n",
      " [0.94867635]\n",
      " [0.94601125]\n",
      " [0.94311565]\n",
      " [0.93955851]\n",
      " [0.93637359]\n",
      " [0.93417436]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9307145892932484\n",
      "Predicci√≥n : [[0.9318239]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[[0.95429528]\n",
      "  [0.95138776]\n",
      "  [0.94867635]\n",
      "  [0.94601125]\n",
      "  [0.94311565]\n",
      "  [0.93955851]\n",
      "  [0.93637359]\n",
      "  [0.93417436]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.2305509926591185e-06\n",
      "Predicci√≥n post entrenamiento : [[0.9323386]]\n",
      "PERDIDAAAA despues: 2.6373375021648826e-06\n",
      "loss en el callback: 0.01228381972759962, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "ejemplar: [[0.95138776]\n",
      " [0.94867635]\n",
      " [0.94601125]\n",
      " [0.94311565]\n",
      " [0.93955851]\n",
      " [0.93637359]\n",
      " [0.93417436]\n",
      " [0.93182391]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.908967222276737\n",
      "Predicci√≥n : [[0.92977303]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[[0.95138776]\n",
      "  [0.94867635]\n",
      "  [0.94601125]\n",
      "  [0.94311565]\n",
      "  [0.93955851]\n",
      "  [0.93637359]\n",
      "  [0.93417436]\n",
      "  [0.93182391]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00043288280721753836\n",
      "Predicci√≥n post entrenamiento : [[0.92913854]]\n",
      "PERDIDAAAA despues: 0.00040688313310965896\n",
      "loss en el callback: 0.014298742637038231, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "ejemplar: [[0.94867635]\n",
      " [0.94601125]\n",
      " [0.94311565]\n",
      " [0.93955851]\n",
      " [0.93637359]\n",
      " [0.93417436]\n",
      " [0.93182391]\n",
      " [0.92977303]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8816379650841193\n",
      "Predicci√≥n : [[0.9265883]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[[0.94867635]\n",
      "  [0.94601125]\n",
      "  [0.94311565]\n",
      "  [0.93955851]\n",
      "  [0.93637359]\n",
      "  [0.93417436]\n",
      "  [0.93182391]\n",
      "  [0.92977303]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0020205299369990826\n",
      "Predicci√≥n post entrenamiento : [[0.92680305]]\n",
      "PERDIDAAAA despues: 0.002039882820099592\n",
      "loss en el callback: 0.0024418768007308245, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "ejemplar: [[0.94601125]\n",
      " [0.94311565]\n",
      " [0.93955851]\n",
      " [0.93637359]\n",
      " [0.93417436]\n",
      " [0.93182391]\n",
      " [0.92977303]\n",
      " [0.9265883 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8487268177153953\n",
      "Predicci√≥n : [[0.92422086]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[[0.94601125]\n",
      "  [0.94311565]\n",
      "  [0.93955851]\n",
      "  [0.93637359]\n",
      "  [0.93417436]\n",
      "  [0.93182391]\n",
      "  [0.92977303]\n",
      "  [0.9265883 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005699351895600557\n",
      "Predicci√≥n post entrenamiento : [[0.92339885]]\n",
      "PERDIDAAAA despues: 0.0055759139358997345\n",
      "loss en el callback: 0.024372560903429985, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "ejemplar: [[0.94311565]\n",
      " [0.93955851]\n",
      " [0.93637359]\n",
      " [0.93417436]\n",
      " [0.93182391]\n",
      " [0.92977303]\n",
      " [0.9265883 ]\n",
      " [0.92422086]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.875260685634848\n",
      "Predicci√≥n : [[0.920781]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[[0.94311565]\n",
      "  [0.93955851]\n",
      "  [0.93637359]\n",
      "  [0.93417436]\n",
      "  [0.93182391]\n",
      "  [0.92977303]\n",
      "  [0.9265883 ]\n",
      "  [0.92422086]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0020720981992781162\n",
      "Predicci√≥n post entrenamiento : [[0.9197916]]\n",
      "PERDIDAAAA despues: 0.0019829983357340097\n",
      "loss en el callback: 0.030385753139853477, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "ejemplar: [[0.93955851]\n",
      " [0.93637359]\n",
      " [0.93417436]\n",
      " [0.93182391]\n",
      " [0.92977303]\n",
      " [0.9265883 ]\n",
      " [0.92422086]\n",
      " [0.92078102]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9612395688424776\n",
      "Predicci√≥n : [[0.91721165]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[[0.93955851]\n",
      "  [0.93637359]\n",
      "  [0.93417436]\n",
      "  [0.93182391]\n",
      "  [0.92977303]\n",
      "  [0.9265883 ]\n",
      "  [0.92422086]\n",
      "  [0.92078102]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00193845818284899\n",
      "Predicci√≥n post entrenamiento : [[0.91738605]]\n",
      "PERDIDAAAA despues: 0.0019231312908232212\n",
      "loss en el callback: 0.001272377441637218, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "ejemplar: [[0.93637359]\n",
      " [0.93417436]\n",
      " [0.93182391]\n",
      " [0.92977303]\n",
      " [0.9265883 ]\n",
      " [0.92422086]\n",
      " [0.92078102]\n",
      " [0.91721165]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9925021123407926\n",
      "Predicci√≥n : [[0.915044]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[[0.93637359]\n",
      "  [0.93417436]\n",
      "  [0.93182391]\n",
      "  [0.92977303]\n",
      "  [0.9265883 ]\n",
      "  [0.92422086]\n",
      "  [0.92078102]\n",
      "  [0.91721165]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005999754648655653\n",
      "Predicci√≥n post entrenamiento : [[0.9151317]]\n",
      "PERDIDAAAA despues: 0.005986179690808058\n",
      "loss en el callback: 0.00028835455304943025, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "ejemplar: [[0.93417436]\n",
      " [0.93182391]\n",
      " [0.92977303]\n",
      " [0.9265883 ]\n",
      " [0.92422086]\n",
      " [0.92078102]\n",
      " [0.91721165]\n",
      " [0.91504401]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.969048316129792\n",
      "Predicci√≥n : [[0.9129442]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[[0.93417436]\n",
      "  [0.93182391]\n",
      "  [0.92977303]\n",
      "  [0.9265883 ]\n",
      "  [0.92422086]\n",
      "  [0.92078102]\n",
      "  [0.91721165]\n",
      "  [0.91504401]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0031476726289838552\n",
      "Predicci√≥n post entrenamiento : [[0.9125302]]\n",
      "PERDIDAAAA despues: 0.0031942997593432665\n",
      "loss en el callback: 0.005786573980003595, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "ejemplar: [[0.93182391]\n",
      " [0.92977303]\n",
      " [0.9265883 ]\n",
      " [0.92422086]\n",
      " [0.92078102]\n",
      " [0.91721165]\n",
      " [0.91504401]\n",
      " [0.9129442 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9715476120161949\n",
      "Predicci√≥n : [[0.9102187]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[[0.93182391]\n",
      "  [0.92977303]\n",
      "  [0.9265883 ]\n",
      "  [0.92422086]\n",
      "  [0.92078102]\n",
      "  [0.91721165]\n",
      "  [0.91504401]\n",
      "  [0.9129442 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0037612325977534056\n",
      "Predicci√≥n post entrenamiento : [[0.9105661]]\n",
      "PERDIDAAAA despues: 0.003718744730576873\n",
      "loss en el callback: 0.0054726130329072475, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "ejemplar: [[0.92977303]\n",
      " [0.9265883 ]\n",
      " [0.92422086]\n",
      " [0.92078102]\n",
      " [0.91721165]\n",
      " [0.91504401]\n",
      " [0.9129442 ]\n",
      " [0.91021872]]\n",
      "ejemplar: (8, 1)\n",
      "y: 1.0\n",
      "Predicci√≥n : [[0.908149]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[[0.92977303]\n",
      "  [0.9265883 ]\n",
      "  [0.92422086]\n",
      "  [0.92078102]\n",
      "  [0.91721165]\n",
      "  [0.91504401]\n",
      "  [0.9129442 ]\n",
      "  [0.91021872]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008436605334281921\n",
      "Predicci√≥n post entrenamiento : [[0.90862817]]\n",
      "PERDIDAAAA despues: 0.008348812349140644\n",
      "loss en el callback: 0.010480561293661594, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "ejemplar: [[0.9265883 ]\n",
      " [0.92422086]\n",
      " [0.92078102]\n",
      " [0.91721165]\n",
      " [0.91504401]\n",
      " [0.9129442 ]\n",
      " [0.91021872]\n",
      " [0.908149  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9800636522775721\n",
      "Predicci√≥n : [[0.9060068]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[[0.9265883 ]\n",
      "  [0.92422086]\n",
      "  [0.92078102]\n",
      "  [0.91721165]\n",
      "  [0.91504401]\n",
      "  [0.9129442 ]\n",
      "  [0.91021872]\n",
      "  [0.908149  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005484418943524361\n",
      "Predicci√≥n post entrenamiento : [[0.90675753]]\n",
      "PERDIDAAAA despues: 0.005373790860176086\n",
      "loss en el callback: 0.03201359137892723, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "ejemplar: [[0.92422086]\n",
      " [0.92078102]\n",
      " [0.91721165]\n",
      " [0.91504401]\n",
      " [0.9129442 ]\n",
      " [0.91021872]\n",
      " [0.908149  ]\n",
      " [0.90600681]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.911738568848911\n",
      "Predicci√≥n : [[0.9042534]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[[0.92422086]\n",
      "  [0.92078102]\n",
      "  [0.91721165]\n",
      "  [0.91504401]\n",
      "  [0.9129442 ]\n",
      "  [0.91021872]\n",
      "  [0.908149  ]\n",
      "  [0.90600681]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.602748933597468e-05\n",
      "Predicci√≥n post entrenamiento : [[0.9049452]]\n",
      "PERDIDAAAA despues: 4.615000943886116e-05\n",
      "loss en el callback: 0.03138633072376251, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "ejemplar: [[0.92078102]\n",
      " [0.91721165]\n",
      " [0.91504401]\n",
      " [0.9129442 ]\n",
      " [0.91021872]\n",
      " [0.908149  ]\n",
      " [0.90600681]\n",
      " [0.90425342]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8910857934126422\n",
      "Predicci√≥n : [[0.9023604]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[[0.92078102]\n",
      "  [0.91721165]\n",
      "  [0.91504401]\n",
      "  [0.9129442 ]\n",
      "  [0.91021872]\n",
      "  [0.908149  ]\n",
      "  [0.90600681]\n",
      "  [0.90425342]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00012711607269011438\n",
      "Predicci√≥n post entrenamiento : [[0.9025863]]\n",
      "PERDIDAAAA despues: 0.00013226098963059485\n",
      "loss en el callback: 0.002580539556220174, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "ejemplar: [[0.91721165]\n",
      " [0.91504401]\n",
      " [0.9129442 ]\n",
      " [0.91021872]\n",
      " [0.908149  ]\n",
      " [0.90600681]\n",
      " [0.90425342]\n",
      " [0.90236038]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9181053259687657\n",
      "Predicci√≥n : [[0.90025496]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[[0.91721165]\n",
      "  [0.91504401]\n",
      "  [0.9129442 ]\n",
      "  [0.91021872]\n",
      "  [0.908149  ]\n",
      "  [0.90600681]\n",
      "  [0.90425342]\n",
      "  [0.90236038]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00031863461481407285\n",
      "Predicci√≥n post entrenamiento : [[0.89990807]]\n",
      "PERDIDAAAA despues: 0.0003311394830234349\n",
      "loss en el callback: 0.005198175553232431, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "ejemplar: [[0.91504401]\n",
      " [0.9129442 ]\n",
      " [0.91021872]\n",
      " [0.908149  ]\n",
      " [0.90600681]\n",
      " [0.90425342]\n",
      " [0.90236038]\n",
      " [0.90025496]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9450165163483527\n",
      "Predicci√≥n : [[0.89792985]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[[0.91504401]\n",
      "  [0.9129442 ]\n",
      "  [0.91021872]\n",
      "  [0.908149  ]\n",
      "  [0.90600681]\n",
      "  [0.90425342]\n",
      "  [0.90236038]\n",
      "  [0.90025496]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002217153087258339\n",
      "Predicci√≥n post entrenamiento : [[0.89890164]]\n",
      "PERDIDAAAA despues: 0.0021265805698931217\n",
      "loss en el callback: 0.06539906561374664, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "ejemplar: [[0.9129442 ]\n",
      " [0.91021872]\n",
      " [0.908149  ]\n",
      " [0.90600681]\n",
      " [0.90425342]\n",
      " [0.90236038]\n",
      " [0.90025496]\n",
      " [0.89792985]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9718193645514037\n",
      "Predicci√≥n : [[0.8969259]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[[0.9129442 ]\n",
      "  [0.91021872]\n",
      "  [0.908149  ]\n",
      "  [0.90600681]\n",
      "  [0.90425342]\n",
      "  [0.90236038]\n",
      "  [0.90025496]\n",
      "  [0.89792985]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005609023384749889\n",
      "Predicci√≥n post entrenamiento : [[0.8967522]]\n",
      "PERDIDAAAA despues: 0.005635078996419907\n",
      "loss en el callback: 0.0013657292583957314, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "ejemplar: [[0.91021872]\n",
      " [0.908149  ]\n",
      " [0.90600681]\n",
      " [0.90425342]\n",
      " [0.90236038]\n",
      " [0.90025496]\n",
      " [0.89792985]\n",
      " [0.89692593]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9829067192737589\n",
      "Predicci√≥n : [[0.89477295]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[[0.91021872]\n",
      "  [0.908149  ]\n",
      "  [0.90600681]\n",
      "  [0.90425342]\n",
      "  [0.90236038]\n",
      "  [0.90025496]\n",
      "  [0.89792985]\n",
      "  [0.89692593]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0077675580978393555\n",
      "Predicci√≥n post entrenamiento : [[0.8955634]]\n",
      "PERDIDAAAA despues: 0.007628847844898701\n",
      "loss en el callback: 0.0399385541677475, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "ejemplar: [[0.908149  ]\n",
      " [0.90600681]\n",
      " [0.90425342]\n",
      " [0.90236038]\n",
      " [0.90025496]\n",
      " [0.89792985]\n",
      " [0.89692593]\n",
      " [0.89477295]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9782785805154182\n",
      "Predicci√≥n : [[0.8937761]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[[0.908149  ]\n",
      "  [0.90600681]\n",
      "  [0.90425342]\n",
      "  [0.90236038]\n",
      "  [0.90025496]\n",
      "  [0.89792985]\n",
      "  [0.89692593]\n",
      "  [0.89477295]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00714066531509161\n",
      "Predicci√≥n post entrenamiento : [[0.89378804]]\n",
      "PERDIDAAAA despues: 0.007138650864362717\n",
      "loss en el callback: 6.479144303739304e-06, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1628165367086364,\n",
       " 0.1653862960422161,\n",
       " 0.16666166312900257,\n",
       " 0.17148016624537035,\n",
       " 0.1674780584903026,\n",
       " 0.1695225267698576,\n",
       " 0.17350987433092135,\n",
       " 0.183654518908884,\n",
       " 0.17850311942997601,\n",
       " 0.17343887212009387]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(components_e_n[0])\n",
    "#entr.entrena_LM_pred(networks[0],0,entrenamiento_8_1,15 ,lr=0.5,Œª =0.1,batch_size=8,decay_factor=5) #EPOCAS\n",
    "#entr.cerrar_escritor()\n",
    "import src.modelos.LSTM.entrenamientos as entrena_lstm\n",
    "x = components_e_n[0]\n",
    "y = y_entrenamiento_n[0]\n",
    "entrena_lstm.entrena(networks[0],np.reshape(components_e_n[0], (components_e_n[0].shape[0],1)),y_entrenamiento_n[0],8)\n",
    "#torch.save(networks[0].state_dict(), 'models/red_A5.pth') #Salvamos el estado actual del modelo\n",
    "\n",
    "# entr.entrena_LM_pred(red_D5,1,entrenamiento_8_1,EPOCAS)\n",
    "# torch.save(red_D5.state_dict(), 'models/red_D5_datos_originales_pred.pth') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entr.entrena_LM_pred(red_D4,2,entrenamiento_8_1,EPOCAS)\n",
    "# torch.save(red_D4.state_dict(), 'models/red_D4_datos_originales_pred.pth')\n",
    "\n",
    "# entr.entrena_LM_pred(red_D3,3,entrenamiento_8_1,EPOCAS)\n",
    "# torch.save(red_D3.state_dict(), 'models/red_D3_datos_originales_pred.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entr.entrena_LM_pred(red_D2,3,entrenamiento_8_1,EPOCAS)\n",
    "# torch.save(red_D2.state_dict(), 'models/red_D2_datos_originales_pred.pth') \n",
    "# entr.entrena_LM_pred(red_D1,3,entrenamiento_8_1,EPOCAS)\n",
    "# torch.save(red_D1.state_dict(), 'models/red_D1_datos_originales_pred.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entr.entrena_LM_pred(red_D4,4,entrenamiento_8_1,EPOCAS)\n",
    "# entr.entrena_LM_pred(red_D5,5,entrenamiento_8_1,EPOCAS)\n",
    "\n",
    "# torch.save(red_A1.state_dict(), redes[\"red_A1\"]) #Salvamos el estado actual del modelo\n",
    "# torch.save(red_D1.state_dict(), redes[\"red_D1\"]) \n",
    "# torch.save(red_D1.state_dict(), redes[\"red_D2\"]) \n",
    "# torch.save(red_D1.state_dict(), redes[\"red_D3\"]) \n",
    "# torch.save(red_D1.state_dict(), redes[\"red_D4\"])\n",
    "# torch.save(red_D1.state_dict(), redes[\"red_D5\"]) \n",
    "\n",
    "# torch.save(red_A1.state_dict(), redes['models/red_A1_n.pth']) #Salvamos el estado actual del modelo\n",
    "# torch.save(red_D1.state_dict(), redes['models/red_D1_n.pth']) \n",
    "# torch.save(red_D2.state_dict(), redes['models/red_D2_n.pth']) \n",
    "#torch.save(red_D3.state_dict(), redes['models/red_D3_n.pth']) \n",
    "# torch.save(red_D4.state_dict(), 'models/red_D4_n.pth')\n",
    "# torch.save(red_D5.state_dict(), redes['models/red_D5_n.pth']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicci√≥n del conjunto de prueba\n",
    "usando los datos predictivos para la recurrencia\n",
    "\n",
    "6. Predict  the  future  price  for  each  point  in  the  testing data set as follows:\n",
    "a) Decompose its preceding price data as described in step 2.  \n",
    "b) Normalize the decomposed features using Eq. (3). \n",
    "c) Predict one step for each component. (El contenido se guarda en el arreglo 'predicciones')\n",
    "d) De-normalize and aggregate the predicted values. \n",
    "e) Repeat steps a, b and c until all the testing dataset \n",
    "points are forecasted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2400x800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perdidas predictivas: []\n"
     ]
    }
   ],
   "source": [
    "perdidas_predictivas = []\n",
    "plt.figure(figsize=(24, 8))\n",
    "\n",
    "\n",
    "\n",
    "aprox_coef = True\n",
    "index = 1\n",
    "predicciones = []\n",
    "\n",
    "for _ in range(len(components_e_n)):\n",
    "    #predicciones.append(utls.genera_prediccion_predictiva(entrenamiento_8_1[_][0][:8],8,len(entrenamiento_8_1[_]),networks[_]))\n",
    "\n",
    "    red_ap_X_entrenamiento_n = components_e_n[_][:8]\n",
    "    red_ap_precios_predichos_n = utls.genera_prediccion_predictiva(red_ap_X_entrenamiento_n,8,182,networks[_])\n",
    "\n",
    "    #perdidas_predictivas.append(criterion(predicciones[_], torch.tensor(components_e_n[_])))\n",
    "    plt.subplot(2, 3, index)\n",
    "    plt.plot(components_e_n[_])\n",
    "    plt.plot(red_ap_precios_predichos_n,  label = f\"Perdida: {1}\", color='#DA0C81' if aprox_coef else '#610C9F')#float(perdidas_predictivas[_])\n",
    "    plt.title('Coeficientes de Aproximaci√≥n' if aprox_coef else 'Coeficientes de Detalle')\n",
    "    aprox_coef = False\n",
    "    plt.legend()\n",
    "    index = index + 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Perdidas predictivas: \" + str(perdidas_predictivas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2400x800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perdidas predictivas: []\n"
     ]
    }
   ],
   "source": [
    "perdidas_predictivas = []\n",
    "plt.figure(figsize=(24, 8))\n",
    "\n",
    "aprox_coef = True\n",
    "index = 1\n",
    "predicciones = []\n",
    "\n",
    "for _ in range(len(components_p_n)):\n",
    "    #predicciones.append(utls.genera_prediccion_predictiva(prueba_8_1[_][0][:8],8,len(prueba_8_1[_]),networks[_]))\n",
    "\n",
    "    red_ap_X_prueba_n = components_p_n[_][:8]\n",
    "    red_ap_precios_predichos_n = utls.genera_prediccion_predictiva(red_ap_X_prueba_n,8,len(components_p_n[_]),networks[_])\n",
    "\n",
    "    #perdidas_predictivas.append(criterion(predicciones[_], torch.tensor(components_e_n[_])))\n",
    "    plt.subplot(2, 3, index)\n",
    "    plt.plot(components_p_n[_])\n",
    "    plt.plot(red_ap_precios_predichos_n,  label = f\"Perdida: {1}\", color='#DA0C81' if aprox_coef else '#610C9F')#float(perdidas_predictivas[_])\n",
    "\n",
    "    # perdidas_predictivas.append(criterion(predicciones[_], torch.tensor(components_p_n[_])))\n",
    "    # plt.subplot(2, 3, index)\n",
    "    # plt.plot(components_p_n[_])\n",
    "    # plt.plot(predicciones[_].detach().numpy(),  label = f\"Perdida: {float(perdidas_predictivas[_])}\", color='#DA0C81' if aprox_coef else '#610C9F')\n",
    "    plt.title('Coeficientes de Aproximaci√≥n' if aprox_coef else 'Coeficientes de Detalle')\n",
    "    aprox_coef = False\n",
    "    plt.legend()\n",
    "    index = index + 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Perdidas predictivas: \" + str(perdidas_predictivas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Reconstruimos la se√±al original usadno el conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicciones' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mpredicciones\u001b[49m)):\n\u001b[0;32m      2\u001b[0m     predicciones[i] \u001b[38;5;241m=\u001b[39m predicciones[i][\u001b[38;5;241m8\u001b[39m:]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(predicciones[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predicciones' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(len(predicciones)):\n",
    "    predicciones[i] = predicciones[i][8:]\n",
    "print(predicciones[0])\n",
    "\n",
    "#components_p_n = [utls.normalizar(vect) for vect in components_p]\n",
    "predicciones_d = [utls.desnormalizar(vect.detach().numpy(),np.max(components_p[0]),np.min(components_p[0])) for vect in predicciones]\n",
    "# D5_p = [utls.desnormalizar(vect) for vect in predicciones[1].detach().numpy()]\n",
    "# D4_p = [utls.desnormalizar(vect) for vect in predicciones[2].detach().numpy()]\n",
    "# D3_p = [utls.desnormalizar(vect) for vect in predicciones[3].detach().numpy()]\n",
    "# D2_p = [utls.desnormalizar(vect) for vect in predicciones[4].detach().numpy()]\n",
    "# D1_p = [utls.desnormalizar(vect) for vect in predicciones[5].detach().numpy()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(predicciones_d[0])),predicciones_d[0])\n",
    "plt.plot(range(len(components_p[0])),components_p[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cA_p = [utls.desnormalizar(vect) for vect in utls.genera_prediccion_1(coeffs_n_prueba_8_1[0],red_A1,8).detach().numpy()]\n",
    "# cD_1_p = [utls.desnormalizar(vect) for vect in utls.genera_prediccion_1(coeffs_n_prueba_8_1[1],red_D1,8).detach().numpy()]\n",
    "# cD_2_p = [utls.desnormalizar(vect) for vect in utls.genera_prediccion_1(coeffs_n_prueba_8_1[2],red_D2,8).detach().numpy()]\n",
    "# cD_3_p = [utls.desnormalizar(vect) for vect in utls.genera_prediccion_1(coeffs_n_prueba_8_1[3],red_D3,8).detach().numpy()]\n",
    "# cD_4_p = [utls.desnormalizar(vect) for vect in utls.genera_prediccion_1(coeffs_n_prueba_8_1[4],red_D4,8).detach().numpy()]\n",
    "# cD_5_p = [utls.desnormalizar(vect) for vect in utls.genera_prediccion_1(coeffs_n_prueba_8_1[5],red_D5,8).detach().numpy()]\n",
    "\n",
    "# cA_p1 = [utls.desnormalizar(vect) for vect in utls.genera_prediccion_1(prueba_8_1[0],red_A1,8).detach().numpy()]\n",
    "# cD_1_p1 = [utls.desnormalizar(vect) for vect in utls.genera_prediccion_1(prueba_8_1[1],red_D1,8).detach().numpy()]\n",
    "# cD_2_p1 = [utls.desnormalizar(vect) for vect in utls.genera_prediccion_1(prueba_8_1[2],red_D2,8).detach().numpy()]\n",
    "# cD_3_p1 = [utls.desnormalizar(vect) for vect in utls.genera_prediccion_1(prueba_8_1[3],red_D3,8).detach().numpy()]\n",
    "# cD_4_p1 = [utls.desnormalizar(vect) for vect in utls.genera_prediccion_1(prueba_8_1[4],red_D4,8).detach().numpy()]\n",
    "# cD_5_p1 = [utls.desnormalizar(vect) for vect in utls.genera_prediccion_1(prueba_8_1[5],red_D5,8).detach().numpy()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n",
      "78\n",
      "78\n",
      "78\n",
      "78\n",
      "78\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.plot(range(108), [utls.desnormalizar(vect) for vect in utls.genera_prediccion(pruebas_ordenadas[0],red_A1).detach().numpy().tolist()[0]])\n",
    "# Mostrar el gr√°fico\n",
    "#plt.show()\n",
    "\n",
    "#coeffs_pp = [np.array(c) for c in [cA,cD_1,cD_2,cD_3,cD_4,cD_5]]\n",
    "#coeffs_pp = [np.array(c) for c in [A5_p,D5_p,D4_p,D3_p,D2_p,D1_p]]\n",
    "# #print([len(i) for i in coeffs])\n",
    "# #print([len(i) for i in coeffs_p])\n",
    "\n",
    "# # for i, c in enumerate(coeffs_prueba):\n",
    "# #     print(f'Forma de c{i}: {np.shape(c)}')\n",
    "# for i, c in enumerate(coeffs_n_prueba_8_1):\n",
    "#     print(f'Forma de c{i}: {np.shape(c)}')\n",
    "# for i, c in enumerate(prueba_8_1):\n",
    "#     print(f'Forma de c{i}: {np.shape(c)}')\n",
    "#rec = pywt.waverec(coeffs_pp, 'bior3.5', mode=mode)\n",
    "for i in predicciones_d:\n",
    "    print(len(i))\n",
    "(A5_rec, D5_rec, D4_rec, D3_rec, D2_rec, D1_rec) = predicciones_d\n",
    "# c_prueba = cierre[int(len(cierre) * 0.7):]\n",
    "rec = A5_rec + D5_rec + D4_rec + D3_rec + D2_rec + D1_rec\n",
    "plt.plot(range(len(cierre_p)),cierre_p) #Se√±al original\n",
    "plt.plot(range(len(rec)),rec) #Se√±al predicha\n",
    "\n",
    "# #plt.plot(range(len(cA)),cA)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
