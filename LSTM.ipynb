{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import src.utilerias.reader as rd\n",
    "import src.utilerias.utilerias as utls\n",
    "\n",
    "# Llamamos a la función antes de ejecutar el script\n",
    "logs_dir = 'logs/LSTM/estandar'\n",
    "logs_dir_auto_pred = 'logs/LSTM/auto_predictiva'\n",
    "utls.eliminar_archivos_registro(logs_dir)\n",
    "utls.eliminar_archivos_registro(logs_dir_auto_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATOS = 'cierre.csv'#Grupo Financiero Inbursa\n",
    "# DATOS = 'Datos históricos COMI 03012016_27122020.csv' #Datos originales\n",
    "DATOS = 'datos/Datos históricos COMI 3ene16-31dic2020 semanal.csv' #Datos semanales\n",
    "# DATOS = 'Datos históricos COMI_prueba 30jun19-31dic2020.csv' #Datos semanales de prueba\n",
    "# DATOS = 'Datos históricos COMI3ene2016_27dic2020_diario.csv' #Datos originales diarios de prueba\n",
    "# DATOS = 'Datos históricos COMI_prueba 30jun19-31dic2020_DIARIO.csv' #Datos diarios de prueba\n",
    "\n",
    "cierre = rd.leer_archivo(DATOS).astype(float)\n",
    "c_entrenamiento = np.array(cierre[:int(len(cierre) * 0.7)])\n",
    "\n",
    "#Se convierte en un arreglo bidimensional\n",
    "c_entrenamiento = np.reshape(c_entrenamiento, (c_entrenamiento.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "m_m_s = MinMaxScaler(feature_range=(0,1))\n",
    "c_entrenamiento_n = m_m_s.fit_transform(c_entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se crean los conjuntos de entradas y salidas para la red, que funcionaran para predecir y comparar con las salidas esperadas a la hora de realizar el entrenamiento\n",
    "time_steps = 8\n",
    "N = len(c_entrenamiento_n) #182\n",
    "X_entrenamiento_n = []\n",
    "y_entrenamiento_n = []\n",
    "for i in range(time_steps, N):\n",
    "    X_entrenamiento_n.append(c_entrenamiento_n[i-time_steps:i, 0])#toma paquetes de 8 en 8\n",
    "    y_entrenamiento_n.append(c_entrenamiento_n[i, 0])#se toma el elemento 8+1\n",
    "X_entrenamiento_n, y_entrenamiento_n = np.array(X_entrenamiento_n), np.array(y_entrenamiento_n)\n",
    "\n",
    "#Se le da una tercera dimension al conjunto de entradas de entrenamiento\n",
    "X_entrenamiento_n = np.reshape(X_entrenamiento_n, (X_entrenamiento_n.shape[0], X_entrenamiento_n.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.models import load_model\n",
    "\n",
    "#red = load_model('redes/DWT_LSTM/auto_predictiva/LSTM_prueba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.5072 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0180s vs `on_train_batch_end` time: 0.0388s). Check your callbacks.\n",
      "6/6 [==============================] - 1s 5ms/step\n",
      "6/6 [==============================] - 8s 373ms/step - loss: 0.4922\n",
      "Epoch 2/60\n",
      "6/6 [==============================] - 0s 6ms/steposs: 0.46\n",
      "6/6 [==============================] - 1s 97ms/step - loss: 0.4689\n",
      "Epoch 3/60\n",
      "6/6 [==============================] - 0s 9ms/steposs: 0.44\n",
      "6/6 [==============================] - 1s 109ms/step - loss: 0.4453\n",
      "Epoch 4/60\n",
      "6/6 [==============================] - 0s 6ms/steposs: 0.41\n",
      "6/6 [==============================] - 1s 113ms/step - loss: 0.4205\n",
      "Epoch 5/60\n",
      "6/6 [==============================] - 0s 9ms/steposs: 0.38\n",
      "6/6 [==============================] - 1s 131ms/step - loss: 0.3904\n",
      "Epoch 6/60\n",
      "6/6 [==============================] - 0s 8ms/steposs: 0.36\n",
      "6/6 [==============================] - 1s 128ms/step - loss: 0.3592\n",
      "Epoch 7/60\n",
      "6/6 [==============================] - 0s 7ms/steposs: 0.32\n",
      "6/6 [==============================] - 1s 107ms/step - loss: 0.3251\n",
      "Epoch 8/60\n",
      "6/6 [==============================] - 0s 7ms/steposs: 0.28\n",
      "6/6 [==============================] - 1s 114ms/step - loss: 0.2791\n",
      "Epoch 9/60\n",
      "6/6 [==============================] - 0s 8ms/steposs: 0.24\n",
      "6/6 [==============================] - 1s 115ms/step - loss: 0.2363\n",
      "Epoch 10/60\n",
      "6/6 [==============================] - 0s 8ms/steposs: 0.19\n",
      "6/6 [==============================] - 1s 104ms/step - loss: 0.1909\n",
      "Epoch 11/60\n",
      "6/6 [==============================] - 0s 6ms/steposs: 0.13\n",
      "6/6 [==============================] - 0s 89ms/step - loss: 0.1352\n",
      "Epoch 12/60\n",
      "6/6 [==============================] - 0s 6ms/steposs: 0.08\n",
      "6/6 [==============================] - 0s 96ms/step - loss: 0.0897\n",
      "Epoch 13/60\n",
      "6/6 [==============================] - 0s 6ms/steposs: 0.05\n",
      "6/6 [==============================] - 0s 93ms/step - loss: 0.0488\n",
      "Epoch 14/60\n",
      "6/6 [==============================] - 0s 7ms/steposs: 0.02\n",
      "6/6 [==============================] - 1s 106ms/step - loss: 0.0239\n",
      "Epoch 15/60\n",
      "6/6 [==============================] - 0s 7ms/steposs: 0.01\n",
      "6/6 [==============================] - 1s 98ms/step - loss: 0.0185\n",
      "Epoch 16/60\n",
      "6/6 [==============================] - 0s 7ms/steposs: 0.02\n",
      "6/6 [==============================] - 1s 98ms/step - loss: 0.0217\n",
      "Epoch 17/60\n",
      "6/6 [==============================] - 0s 8ms/steposs: 0.02\n",
      "6/6 [==============================] - 1s 111ms/step - loss: 0.0200\n",
      "Epoch 18/60\n",
      "6/6 [==============================] - 0s 5ms/steposs: 0.02\n",
      "6/6 [==============================] - 0s 85ms/step - loss: 0.0197\n",
      "Epoch 19/60\n",
      "6/6 [==============================] - 0s 6ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 83ms/step - loss: 0.0164\n",
      "Epoch 20/60\n",
      "6/6 [==============================] - 0s 6ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 82ms/step - loss: 0.0183\n",
      "Epoch 21/60\n",
      "6/6 [==============================] - 0s 5ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 0.0163\n",
      "Epoch 22/60\n",
      "6/6 [==============================] - 0s 5ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 86ms/step - loss: 0.0168\n",
      "Epoch 23/60\n",
      "6/6 [==============================] - 0s 8ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 90ms/step - loss: 0.0157\n",
      "Epoch 24/60\n",
      "6/6 [==============================] - 0s 5ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 81ms/step - loss: 0.0162\n",
      "Epoch 25/60\n",
      "6/6 [==============================] - 0s 7ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 92ms/step - loss: 0.0153\n",
      "Epoch 26/60\n",
      "6/6 [==============================] - 0s 6ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 86ms/step - loss: 0.0174\n",
      "Epoch 27/60\n",
      "6/6 [==============================] - 0s 5ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 83ms/step - loss: 0.0141\n",
      "Epoch 28/60\n",
      "6/6 [==============================] - 0s 6ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 92ms/step - loss: 0.0169\n",
      "Epoch 29/60\n",
      "6/6 [==============================] - 0s 5ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 80ms/step - loss: 0.0157\n",
      "Epoch 30/60\n",
      "6/6 [==============================] - 0s 5ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 81ms/step - loss: 0.0149\n",
      "Epoch 31/60\n",
      "6/6 [==============================] - 0s 6ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 84ms/step - loss: 0.0183\n",
      "Epoch 32/60\n",
      "6/6 [==============================] - 0s 6ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 83ms/step - loss: 0.0165\n",
      "Epoch 33/60\n",
      "6/6 [==============================] - 0s 6ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 82ms/step - loss: 0.0150\n",
      "Epoch 34/60\n",
      "6/6 [==============================] - 0s 6ms/steposs: 0.01\n",
      "6/6 [==============================] - 1s 96ms/step - loss: 0.0144\n",
      "Epoch 35/60\n",
      "6/6 [==============================] - 0s 5ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 81ms/step - loss: 0.0166\n",
      "Epoch 36/60\n",
      "6/6 [==============================] - 0s 6ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 80ms/step - loss: 0.0154\n",
      "Epoch 37/60\n",
      "6/6 [==============================] - 0s 5ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 0.0150\n",
      "Epoch 38/60\n",
      "6/6 [==============================] - 0s 5ms/steposs: 0.01\n",
      "6/6 [==============================] - 1s 122ms/step - loss: 0.0152\n",
      "Epoch 39/60\n",
      "6/6 [==============================] - 0s 4ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 81ms/step - loss: 0.0142\n",
      "Epoch 40/60\n",
      "6/6 [==============================] - 0s 5ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 84ms/step - loss: 0.0139\n",
      "Epoch 41/60\n",
      "6/6 [==============================] - 0s 5ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 82ms/step - loss: 0.0138\n",
      "Epoch 42/60\n",
      "6/6 [==============================] - 0s 6ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 84ms/step - loss: 0.0157\n",
      "Epoch 43/60\n",
      "6/6 [==============================] - 0s 5ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 85ms/step - loss: 0.0138\n",
      "Epoch 44/60\n",
      "6/6 [==============================] - 0s 5ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 81ms/step - loss: 0.0155\n",
      "Epoch 45/60\n",
      "6/6 [==============================] - 0s 5ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 88ms/step - loss: 0.0139\n",
      "Epoch 46/60\n",
      "6/6 [==============================] - 0s 7ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 90ms/step - loss: 0.0139\n",
      "Epoch 47/60\n",
      "6/6 [==============================] - 0s 6ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 88ms/step - loss: 0.0138\n",
      "Epoch 48/60\n",
      "6/6 [==============================] - 0s 7ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 82ms/step - loss: 0.0125\n",
      "Epoch 49/60\n",
      "6/6 [==============================] - 0s 7ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 95ms/step - loss: 0.0142\n",
      "Epoch 50/60\n",
      "6/6 [==============================] - 0s 7ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 85ms/step - loss: 0.0124\n",
      "Epoch 51/60\n",
      "6/6 [==============================] - 0s 7ms/steposs: 0.01\n",
      "6/6 [==============================] - 1s 98ms/step - loss: 0.0137\n",
      "Epoch 52/60\n",
      "6/6 [==============================] - 0s 8ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 91ms/step - loss: 0.0127\n",
      "Epoch 53/60\n",
      "6/6 [==============================] - 0s 6ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 85ms/step - loss: 0.0140\n",
      "Epoch 54/60\n",
      "6/6 [==============================] - 0s 5ms/steposs: 0.01\n",
      "6/6 [==============================] - 1s 99ms/step - loss: 0.0145\n",
      "Epoch 55/60\n",
      "6/6 [==============================] - 0s 6ms/steposs: 0.01\n",
      "6/6 [==============================] - 1s 96ms/step - loss: 0.0139\n",
      "Epoch 56/60\n",
      "6/6 [==============================] - 0s 7ms/steposs: 0.01\n",
      "6/6 [==============================] - 1s 110ms/step - loss: 0.0126\n",
      "Epoch 57/60\n",
      "6/6 [==============================] - 0s 6ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 91ms/step - loss: 0.0135\n",
      "Epoch 58/60\n",
      "6/6 [==============================] - 0s 7ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 85ms/step - loss: 0.0123\n",
      "Epoch 59/60\n",
      "6/6 [==============================] - 0s 5ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 0.0148\n",
      "Epoch 60/60\n",
      "6/6 [==============================] - 0s 5ms/steposs: 0.01\n",
      "6/6 [==============================] - 0s 86ms/step - loss: 0.0134\n"
     ]
    }
   ],
   "source": [
    "from src.modelos.recurrente.LSTM.LSTM import red_LSTM\n",
    "from src.modelos.recurrente.GRU.GRU import red_GRU\n",
    "from src.modelos.auto_regresivo.NARNN_keras.NARNN import NARNN\n",
    "from keras.callbacks import TensorBoard\n",
    "import src.modelos.recurrente.entrenamientos.entrenamiento as entr\n",
    "\n",
    "red = red_LSTM(input_dim = X_entrenamiento_n.shape[1],output_dim= 1)\n",
    "\n",
    "#red = red_GRU(input_dim = X_entrenamiento_n.shape[1],output_dim= 1)\n",
    "#red = NARNN(input_dim = X_entrenamiento_n.shape[1],output_dim= 1)\n",
    "red.compile(optimizer=Adam(learning_rate=0.0001),loss='mean_squared_error')# mejor, , SGD(learning_rate=0.1)\n",
    "history = red.fit(X_entrenamiento_n,y_entrenamiento_n,epochs=60,batch_size=32,\n",
    "                  callbacks=[entr.CalendarizadorPesos(logs_dir + f'/red_LSTM'), \n",
    "                                   entr.CalendarizadorPredicciones(logs_dir + f'/red_LSTM', X_entrenamiento_n, y_entrenamiento_n),\n",
    "                                   TensorBoard(log_dir=logs_dir + f'/red_LSTM', histogram_freq=1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "precios_reales = cierre[int(len(cierre) * 0.7):] #verdaderos valores del conjunto de prueba\n",
    "precios_reales = np.reshape(precios_reales, (precios_reales.shape[0], 1)) #se le da una dimension mas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "#toma los ultimos 86 elementos, los ultimos 8 de entrenamiento y todos los de prueba  \n",
    "c_prueba = cierre[len(cierre) - len(precios_reales) - time_steps:]\n",
    "\n",
    "c_prueba = np.array(c_prueba).reshape(-1,1) #(86,1)\n",
    "\n",
    "m_m_s_prueba = MinMaxScaler(feature_range=(0,1))\n",
    "# se normalizan los datos usandlo los parametros que se le dieron a m_m_s\n",
    "c_prueba_n = m_m_s_prueba.fit_transform(c_prueba)\n",
    "\n",
    "X_prueba_n = []\n",
    "for i in range(time_steps, len(c_prueba_n)):\n",
    "    X_prueba_n.append(c_prueba_n[i-time_steps:i, 0]) # se toman en paquetes de 8 \n",
    "X_prueba_n = np.array(X_prueba_n)\n",
    "X_prueba_n = np.reshape(X_prueba_n, (X_prueba_n.shape[0], X_prueba_n.shape[1], 1))#(78, 8, 1)\n",
    "\n",
    "precios_predichos = red.predict(X_prueba_n)\n",
    "s_normalizar = precios_predichos\n",
    "\n",
    "#Se desnormalizan los datos\n",
    "precios_predichos = m_m_s_prueba.inverse_transform(precios_predichos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#La normalización funciona correctamente\n",
    "plt.plot(precios_reales, color = 'black', label = 'COMI original Stock prices')\n",
    "plt.plot(precios_predichos, color = 'green', label = 'Predicted COMI closing Stock prices')\n",
    "plt.title('COMI Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('COMI Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo entrenado\n",
    "# red.save('models/LSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y_entrenamiento_n.size)\n",
    "# plt.plot(y_entrenamiento_n)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_cierre_s_pred = c_entrenamiento_n\n",
    "\n",
    "# loss_m = []\n",
    "# for epoch in range(100):  # Número de épocas\n",
    "#     ts_cierre_s_pred = c_entrenamiento_n[:time_steps]#se obtienen los primeros time_steps(8) elementos del trainig set\n",
    "#     loss = []\n",
    "#     X_train_c_pred = []\n",
    "#     # print(f\"grtrt: {ts_cierre_s_pred}\")\n",
    "#     for i in range(time_steps, N):\n",
    "#         # Obtener las características y la etiqueta actual\n",
    "#         x_actual = ts_cierre_s_pred[i-time_steps:i,0]\n",
    "#         X_train_c_pred.append(x_actual)\n",
    "#         x_actual = x_actual.reshape(1,time_steps,1)\n",
    "\n",
    "#         y_actual = np.array([y_entrenamiento_n[i-time_steps]])\n",
    "\n",
    "#         print(f\"x_actual: {x_actual}\")\n",
    "#         print(f\"y_actual: {y_actual}\")\n",
    "        \n",
    "#         # Entrenar el modelo con las nuevas características y la etiqueta real\n",
    "#         #loss.append(red.train_on_batch(x_actual, y_actual))\n",
    "\n",
    "#         # Predicción del modelo\n",
    "#         #prediccion = red.predict(x_actual)#.reshape(1,1,1)\n",
    "#         prediccion = red(x_actual)\n",
    "        \n",
    "#         # Agregar la predicción a las características para el siguiente paso\n",
    "#         # print(ts_cierre_s_pred)\n",
    "#         print(f\"prediccion: {prediccion}\")\n",
    "#         ts_cierre_s_pred = np.concatenate([ts_cierre_s_pred, prediccion])\n",
    "\n",
    "\n",
    "\n",
    "#     # print(f\"mean: {np.mean(np.array(loss))}\")\n",
    "#     # loss_m.append(np.mean(np.array(loss)))\n",
    "#     X_train_c_pred = np.array(X_train_c_pred)\n",
    "#     X_train_c_pred = np.reshape(X_train_c_pred, (X_train_c_pred.shape[0], X_train_c_pred.shape[1], 1))\n",
    "#     history = red.fit(X_train_c_pred, y_entrenamiento_n, epochs=1, batch_size=32)\n",
    "#     loss = history.history['loss']\n",
    "#     loss_m.append(loss)\n",
    "#     loss_m.append(mean_squared_error(c_entrenamiento_n,ts_cierre_s_pred[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_entrenamiento: [0.04610616 0.10422317 0.1542038  0.15575358 0.12553274 0.14567997\n",
      " 0.14645486 0.19604804 0.2305308  0.20844634 0.21193336 0.207284\n",
      " 0.19294847 0.19682294 0.21425804 0.18132507 0.17512592 0.14800465\n",
      " 0.15885316 0.19217358 0.18597443 0.26695079 0.29252228 0.31770632\n",
      " 0.31266951 0.28903526 0.28283611 0.29949632 0.27586207 0.27469973\n",
      " 0.27547462 0.33475397 0.35567609 0.3366912  0.33359163 0.3847346\n",
      " 0.57109647 0.59628051 0.57458349 0.60635413 0.58465711 0.56877179\n",
      " 0.64277412 0.66175901 0.67299496 0.7105773  0.7039907  0.7272375\n",
      " 0.72258814 0.77179388 0.72452538 0.67105773 0.67376986 0.71445176\n",
      " 0.74389771 0.72258814 0.69934134 0.73731112 0.7214258  0.71871368\n",
      " 0.6741573  0.69856645 0.72103836 0.72258814 0.75629601 0.82758621\n",
      " 0.83882216 0.79426579 0.78380473 0.76791941 0.78457962 0.87872917\n",
      " 0.8756296  0.84889578 0.81828749 0.82681131 0.78535451 0.78922898\n",
      " 0.8341728  0.81247578 0.80123983 0.80317706 0.7934909  0.76017048\n",
      " 0.73537389 0.71018985 0.71212708 0.7396358  0.73614878 0.66757071\n",
      " 0.66989539 0.69662921 0.65594731 0.67880666 0.67609454 0.72956219\n",
      " 0.70127857 0.76753196 0.75513367 0.74506005 0.7520341  0.7098024\n",
      " 0.69043007 0.75435878 0.7222007  0.84850833 0.905463   0.8822162\n",
      " 0.90778768 0.88957768 0.87485471 0.91321193 1.         0.97055405\n",
      " 0.88880279 0.87795428 0.84889578 0.8341728  0.85509492 0.87524215\n",
      " 0.85703216 0.85005812 0.84269663 0.82293685 0.77450601 0.78419217\n",
      " 0.85974429 0.85432003 0.83688493 0.82991089 0.887253   0.85974429\n",
      " 0.83959706 0.78380473 0.81828749 0.79116621 0.76055792 0.79155366\n",
      " 0.7686943  0.7686943  0.79891515 0.79000387 0.76017048 0.68539326\n",
      " 0.60519179 0.66485858 0.70786517 0.66485858 0.71135219 0.67725688\n",
      " 0.76210771 0.80705153 0.81518791 0.90623789 0.95970554 0.9643549\n",
      " 0.8880279  0.89267726 0.87524215 0.85083301 0.84889578 0.96241767\n",
      " 0.96784192 0.94072065 0.97249128 0.99690043 0.95118171 0.89577683\n",
      " 0.8814413  0.9170864  0.91979853 0.96164277 0.96822937 0.95776831]\n",
      "0\n",
      "ejemplar: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.23865102]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0370735228061676\n",
      "Predicción post entrenamiento : [[0.21983974]]\n",
      "PERDIDAAAA despues: 0.030183356255292892\n",
      "loss en el callback: 0.02112138830125332, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "ejemplar: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23865102]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.20461912]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23865102]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010079347528517246\n",
      "Predicción post entrenamiento : [[0.19527425]]\n",
      "PERDIDAAAA despues: 0.008290299214422703\n",
      "loss en el callback: 0.0051224143244326115, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "ejemplar: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23865102]\n",
      " [0.20461912]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.19945309]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23865102]\n",
      "  [0.20461912]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002047497546300292\n",
      "Predicción post entrenamiento : [[0.19203515]]\n",
      "PERDIDAAAA despues: 0.0014312111306935549\n",
      "loss en el callback: 0.004324411042034626, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "ejemplar: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23865102]\n",
      " [0.20461912]\n",
      " [0.19945309]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.20364293]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23865102]\n",
      "  [0.20461912]\n",
      "  [0.19945309]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0022933899890631437\n",
      "Predicción post entrenamiento : [[0.19764055]]\n",
      "PERDIDAAAA despues: 0.0017545182490721345\n",
      "loss en el callback: 0.004997658543288708, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "ejemplar: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23865102]\n",
      " [0.20461912]\n",
      " [0.19945309]\n",
      " [0.20364293]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.21068697]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23865102]\n",
      "  [0.20461912]\n",
      "  [0.19945309]\n",
      "  [0.20364293]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007251241244375706\n",
      "Predicción post entrenamiento : [[0.20378232]]\n",
      "PERDIDAAAA despues: 0.006122995633631945\n",
      "loss en el callback: 0.010796288028359413, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "ejemplar: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23865102]\n",
      " [0.20461912]\n",
      " [0.19945309]\n",
      " [0.20364293]\n",
      " [0.21068697]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.21457383]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23865102]\n",
      "  [0.20461912]\n",
      "  [0.19945309]\n",
      "  [0.20364293]\n",
      "  [0.21068697]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004746364429593086\n",
      "Predicción post entrenamiento : [[0.21166864]]\n",
      "PERDIDAAAA despues: 0.004354505334049463\n",
      "loss en el callback: 0.00348748080432415, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "ejemplar: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.23865102]\n",
      " [0.20461912]\n",
      " [0.19945309]\n",
      " [0.20364293]\n",
      " [0.21068697]\n",
      " [0.21457383]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.2336066]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23865102]\n",
      "  [0.20461912]\n",
      "  [0.19945309]\n",
      "  [0.20364293]\n",
      "  [0.21068697]\n",
      "  [0.21457383]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007595427799969912\n",
      "Predicción post entrenamiento : [[0.22807157]]\n",
      "PERDIDAAAA despues: 0.006661287974566221\n",
      "loss en el callback: 0.012037048116326332, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "ejemplar: [[0.04223169]\n",
      " [0.23865102]\n",
      " [0.20461912]\n",
      " [0.19945309]\n",
      " [0.20364293]\n",
      " [0.21068697]\n",
      " [0.21457383]\n",
      " [0.23360661]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.25469226]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[[0.04223169]\n",
      "  [0.23865102]\n",
      "  [0.20461912]\n",
      "  [0.19945309]\n",
      "  [0.20364293]\n",
      "  [0.21068697]\n",
      "  [0.21457383]\n",
      "  [0.23360661]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003439144464209676\n",
      "Predicción post entrenamiento : [[0.25045744]]\n",
      "PERDIDAAAA despues: 0.002960382727906108\n",
      "loss en el callback: 0.008719627745449543, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "ejemplar: [[0.23865102]\n",
      " [0.20461912]\n",
      " [0.19945309]\n",
      " [0.20364293]\n",
      " [0.21068697]\n",
      " [0.21457383]\n",
      " [0.23360661]\n",
      " [0.25469226]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.28203598]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[[0.23865102]\n",
      "  [0.20461912]\n",
      "  [0.19945309]\n",
      "  [0.20364293]\n",
      "  [0.21068697]\n",
      "  [0.21457383]\n",
      "  [0.23360661]\n",
      "  [0.25469226]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0026527834124863148\n",
      "Predicción post entrenamiento : [[0.27933255]]\n",
      "PERDIDAAAA despues: 0.002381610684096813\n",
      "loss en el callback: 0.004840325564146042, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "ejemplar: [[0.20461912]\n",
      " [0.19945309]\n",
      " [0.20364293]\n",
      " [0.21068697]\n",
      " [0.21457383]\n",
      " [0.23360661]\n",
      " [0.25469226]\n",
      " [0.28203598]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.2746796]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[[0.20461912]\n",
      "  [0.19945309]\n",
      "  [0.20364293]\n",
      "  [0.21068697]\n",
      "  [0.21457383]\n",
      "  [0.23360661]\n",
      "  [0.25469226]\n",
      "  [0.28203598]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0043868450447916985\n",
      "Predicción post entrenamiento : [[0.27259344]]\n",
      "PERDIDAAAA despues: 0.004114850424230099\n",
      "loss en el callback: 0.004034343641251326, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "ejemplar: [[0.19945309]\n",
      " [0.20364293]\n",
      " [0.21068697]\n",
      " [0.21457383]\n",
      " [0.23360661]\n",
      " [0.25469226]\n",
      " [0.28203598]\n",
      " [0.2746796 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.2756948]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[[0.19945309]\n",
      "  [0.20364293]\n",
      "  [0.21068697]\n",
      "  [0.21457383]\n",
      "  [0.23360661]\n",
      "  [0.25469226]\n",
      "  [0.28203598]\n",
      "  [0.2746796 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004065519664436579\n",
      "Predicción post entrenamiento : [[0.27468413]]\n",
      "PERDIDAAAA despues: 0.003937659319490194\n",
      "loss en el callback: 0.0012620114721357822, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "ejemplar: [[0.20364293]\n",
      " [0.21068697]\n",
      " [0.21457383]\n",
      " [0.23360661]\n",
      " [0.25469226]\n",
      " [0.28203598]\n",
      " [0.2746796 ]\n",
      " [0.27569479]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.2807625]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[[0.20364293]\n",
      "  [0.21068697]\n",
      "  [0.21457383]\n",
      "  [0.23360661]\n",
      "  [0.25469226]\n",
      "  [0.28203598]\n",
      "  [0.2746796 ]\n",
      "  [0.27569479]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005399088375270367\n",
      "Predicción post entrenamiento : [[0.27840275]]\n",
      "PERDIDAAAA despues: 0.005057875532656908\n",
      "loss en el callback: 0.006680178921669722, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "ejemplar: [[0.21068697]\n",
      " [0.21457383]\n",
      " [0.23360661]\n",
      " [0.25469226]\n",
      " [0.28203598]\n",
      " [0.2746796 ]\n",
      " [0.27569479]\n",
      " [0.28076249]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.285915]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[[0.21068697]\n",
      "  [0.21457383]\n",
      "  [0.23360661]\n",
      "  [0.25469226]\n",
      "  [0.28203598]\n",
      "  [0.2746796 ]\n",
      "  [0.27569479]\n",
      "  [0.28076249]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00864277221262455\n",
      "Predicción post entrenamiento : [[0.28382102]]\n",
      "PERDIDAAAA despues: 0.008257818408310413\n",
      "loss en el callback: 0.006874920800328255, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "ejemplar: [[0.21457383]\n",
      " [0.23360661]\n",
      " [0.25469226]\n",
      " [0.28203598]\n",
      " [0.2746796 ]\n",
      " [0.27569479]\n",
      " [0.28076249]\n",
      " [0.28591499]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.29224908]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[[0.21457383]\n",
      "  [0.23360661]\n",
      "  [0.25469226]\n",
      "  [0.28203598]\n",
      "  [0.2746796 ]\n",
      "  [0.27569479]\n",
      "  [0.28076249]\n",
      "  [0.28591499]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009106148965656757\n",
      "Predicción post entrenamiento : [[0.28856567]]\n",
      "PERDIDAAAA despues: 0.008416727185249329\n",
      "loss en el callback: 0.017617784440517426, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "ejemplar: [[0.23360661]\n",
      " [0.25469226]\n",
      " [0.28203598]\n",
      " [0.2746796 ]\n",
      " [0.27569479]\n",
      " [0.28076249]\n",
      " [0.28591499]\n",
      " [0.29224908]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.29852608]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[[0.23360661]\n",
      "  [0.25469226]\n",
      "  [0.28203598]\n",
      "  [0.2746796 ]\n",
      "  [0.27569479]\n",
      "  [0.28076249]\n",
      "  [0.28591499]\n",
      "  [0.29224908]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0071011013351380825\n",
      "Predicción post entrenamiento : [[0.2985288]]\n",
      "PERDIDAAAA despues: 0.007101558614522219\n",
      "loss en el callback: 2.3264878024065183e-08, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "ejemplar: [[0.25469226]\n",
      " [0.28203598]\n",
      " [0.2746796 ]\n",
      " [0.27569479]\n",
      " [0.28076249]\n",
      " [0.28591499]\n",
      " [0.29224908]\n",
      " [0.29852608]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.30666965]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[[0.25469226]\n",
      "  [0.28203598]\n",
      "  [0.2746796 ]\n",
      "  [0.27569479]\n",
      "  [0.28076249]\n",
      "  [0.28591499]\n",
      "  [0.29224908]\n",
      "  [0.29852608]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015711266547441483\n",
      "Predicción post entrenamiento : [[0.30400145]]\n",
      "PERDIDAAAA despues: 0.015049495734274387\n",
      "loss en el callback: 0.015534067526459694, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "ejemplar: [[0.28203598]\n",
      " [0.2746796 ]\n",
      " [0.27569479]\n",
      " [0.28076249]\n",
      " [0.28591499]\n",
      " [0.29224908]\n",
      " [0.29852608]\n",
      " [0.30666965]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.30933106]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[[0.28203598]\n",
      "  [0.2746796 ]\n",
      "  [0.27569479]\n",
      "  [0.28076249]\n",
      "  [0.28591499]\n",
      "  [0.29224908]\n",
      "  [0.29852608]\n",
      "  [0.30666965]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01801101677119732\n",
      "Predicción post entrenamiento : [[0.3063404]]\n",
      "PERDIDAAAA despues: 0.017217237502336502\n",
      "loss en el callback: 0.019398467615246773, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "ejemplar: [[0.2746796 ]\n",
      " [0.27569479]\n",
      " [0.28076249]\n",
      " [0.28591499]\n",
      " [0.29224908]\n",
      " [0.29852608]\n",
      " [0.30666965]\n",
      " [0.30933106]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.30695137]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[[0.2746796 ]\n",
      "  [0.27569479]\n",
      "  [0.28076249]\n",
      "  [0.28591499]\n",
      "  [0.29224908]\n",
      "  [0.29852608]\n",
      "  [0.30666965]\n",
      "  [0.30933106]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.025264060124754906\n",
      "Predicción post entrenamiento : [[0.3048381]]\n",
      "PERDIDAAAA despues: 0.02459672838449478\n",
      "loss en el callback: 0.015401076525449753, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "ejemplar: [[0.27569479]\n",
      " [0.28076249]\n",
      " [0.28591499]\n",
      " [0.29224908]\n",
      " [0.29852608]\n",
      " [0.30666965]\n",
      " [0.30933106]\n",
      " [0.30695137]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.30776572]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[[0.27569479]\n",
      "  [0.28076249]\n",
      "  [0.28591499]\n",
      "  [0.29224908]\n",
      "  [0.29852608]\n",
      "  [0.30666965]\n",
      "  [0.30933106]\n",
      "  [0.30695137]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022174952551722527\n",
      "Predicción post entrenamiento : [[0.30674887]]\n",
      "PERDIDAAAA despues: 0.021873140707612038\n",
      "loss en el callback: 0.004799363203346729, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "ejemplar: [[0.28076249]\n",
      " [0.28591499]\n",
      " [0.29224908]\n",
      " [0.29852608]\n",
      " [0.30666965]\n",
      " [0.30933106]\n",
      " [0.30695137]\n",
      " [0.30776572]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.31047067]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[[0.28076249]\n",
      "  [0.28591499]\n",
      "  [0.29224908]\n",
      "  [0.29852608]\n",
      "  [0.30666965]\n",
      "  [0.30933106]\n",
      "  [0.30695137]\n",
      "  [0.30776572]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013994203880429268\n",
      "Predicción post entrenamiento : [[0.3082885]]\n",
      "PERDIDAAAA despues: 0.013482680544257164\n",
      "loss en el callback: 0.014114257879555225, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "ejemplar: [[0.28591499]\n",
      " [0.29224908]\n",
      " [0.29852608]\n",
      " [0.30666965]\n",
      " [0.30933106]\n",
      " [0.30695137]\n",
      " [0.30776572]\n",
      " [0.31047067]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.31193444]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[[0.28591499]\n",
      "  [0.29224908]\n",
      "  [0.29852608]\n",
      "  [0.30666965]\n",
      "  [0.30933106]\n",
      "  [0.30695137]\n",
      "  [0.30776572]\n",
      "  [0.31047067]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015865923836827278\n",
      "Predicción post entrenamiento : [[0.3084215]]\n",
      "PERDIDAAAA despues: 0.014993282034993172\n",
      "loss en el callback: 0.0332784578204155, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "ejemplar: [[0.29224908]\n",
      " [0.29852608]\n",
      " [0.30666965]\n",
      " [0.30933106]\n",
      " [0.30695137]\n",
      " [0.30776572]\n",
      " [0.31047067]\n",
      " [0.31193444]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.31184882]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[[0.29224908]\n",
      "  [0.29852608]\n",
      "  [0.30666965]\n",
      "  [0.30933106]\n",
      "  [0.30695137]\n",
      "  [0.30776572]\n",
      "  [0.31047067]\n",
      "  [0.31193444]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0020158332772552967\n",
      "Predicción post entrenamiento : [[0.3113446]]\n",
      "PERDIDAAAA despues: 0.001970810117200017\n",
      "loss en el callback: 0.0009506870992481709, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "ejemplar: [[0.29852608]\n",
      " [0.30666965]\n",
      " [0.30933106]\n",
      " [0.30695137]\n",
      " [0.30776572]\n",
      " [0.31047067]\n",
      " [0.31193444]\n",
      " [0.31184882]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.3141474]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[[0.29852608]\n",
      "  [0.30666965]\n",
      "  [0.30933106]\n",
      "  [0.30695137]\n",
      "  [0.30776572]\n",
      "  [0.31047067]\n",
      "  [0.31193444]\n",
      "  [0.31184882]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004676463140640408\n",
      "Predicción post entrenamiento : [[0.31408203]]\n",
      "PERDIDAAAA despues: 0.00046482260222546756\n",
      "loss en el callback: 1.9005357899004593e-05, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "ejemplar: [[0.30666965]\n",
      " [0.30933106]\n",
      " [0.30695137]\n",
      " [0.30776572]\n",
      " [0.31047067]\n",
      " [0.31193444]\n",
      " [0.31184882]\n",
      " [0.31414741]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.31608665]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[[0.30666965]\n",
      "  [0.30933106]\n",
      "  [0.30695137]\n",
      "  [0.30776572]\n",
      "  [0.31047067]\n",
      "  [0.31193444]\n",
      "  [0.31184882]\n",
      "  [0.31414741]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.6233205971948337e-06\n",
      "Predicción post entrenamiento : [[0.31628156]]\n",
      "PERDIDAAAA despues: 2.0299401057854993e-06\n",
      "loss en el callback: 0.00017993207438848913, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "ejemplar: [[0.30933106]\n",
      " [0.30695137]\n",
      " [0.30776572]\n",
      " [0.31047067]\n",
      " [0.31193444]\n",
      " [0.31184882]\n",
      " [0.31414741]\n",
      " [0.31608665]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.31690168]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[[0.30933106]\n",
      "  [0.30695137]\n",
      "  [0.30776572]\n",
      "  [0.31047067]\n",
      "  [0.31193444]\n",
      "  [0.31184882]\n",
      "  [0.31414741]\n",
      "  [0.31608665]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.7911248505697586e-05\n",
      "Predicción post entrenamiento : [[0.31665874]]\n",
      "PERDIDAAAA despues: 1.591387263033539e-05\n",
      "loss en el callback: 0.00024720211513340473, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "ejemplar: [[0.30695137]\n",
      " [0.30776572]\n",
      " [0.31047067]\n",
      " [0.31193444]\n",
      " [0.31184882]\n",
      " [0.31414741]\n",
      " [0.31608665]\n",
      " [0.31690168]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.3169201]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[[0.30695137]\n",
      "  [0.30776572]\n",
      "  [0.31047067]\n",
      "  [0.31193444]\n",
      "  [0.31184882]\n",
      "  [0.31414741]\n",
      "  [0.31608665]\n",
      "  [0.31690168]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007775643607601523\n",
      "Predicción post entrenamiento : [[0.31630987]]\n",
      "PERDIDAAAA despues: 0.0007439042674377561\n",
      "loss en el callback: 0.0017756747547537088, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "ejemplar: [[0.30776572]\n",
      " [0.31047067]\n",
      " [0.31193444]\n",
      " [0.31184882]\n",
      " [0.31414741]\n",
      " [0.31608665]\n",
      " [0.31690168]\n",
      " [0.3169201 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.31730506]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[[0.30776572]\n",
      "  [0.31047067]\n",
      "  [0.31193444]\n",
      "  [0.31184882]\n",
      "  [0.31414741]\n",
      "  [0.31608665]\n",
      "  [0.31690168]\n",
      "  [0.3169201 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011881084647029638\n",
      "Predicción post entrenamiento : [[0.31785795]]\n",
      "PERDIDAAAA despues: 0.0012265293626114726\n",
      "loss en el callback: 0.003000520868226886, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "ejemplar: [[0.31047067]\n",
      " [0.31193444]\n",
      " [0.31184882]\n",
      " [0.31414741]\n",
      " [0.31608665]\n",
      " [0.31690168]\n",
      " [0.3169201 ]\n",
      " [0.31730506]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.3189717]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[[0.31047067]\n",
      "  [0.31193444]\n",
      "  [0.31184882]\n",
      "  [0.31414741]\n",
      "  [0.31608665]\n",
      "  [0.31690168]\n",
      "  [0.3169201 ]\n",
      "  [0.31730506]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00037929005338810384\n",
      "Predicción post entrenamiento : [[0.31884205]]\n",
      "PERDIDAAAA despues: 0.0003742573026102036\n",
      "loss en el callback: 0.00011061420809710398, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "ejemplar: [[0.31193444]\n",
      " [0.31184882]\n",
      " [0.31414741]\n",
      " [0.31608665]\n",
      " [0.31690168]\n",
      " [0.3169201 ]\n",
      " [0.31730506]\n",
      " [0.31897169]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.31964934]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[[0.31193444]\n",
      "  [0.31184882]\n",
      "  [0.31414741]\n",
      "  [0.31608665]\n",
      "  [0.31690168]\n",
      "  [0.3169201 ]\n",
      "  [0.31730506]\n",
      "  [0.31897169]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0019173250766471028\n",
      "Predicción post entrenamiento : [[0.31838673]]\n",
      "PERDIDAAAA despues: 0.0018083471804857254\n",
      "loss en el callback: 0.007858513854444027, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "ejemplar: [[0.31184882]\n",
      " [0.31414741]\n",
      " [0.31608665]\n",
      " [0.31690168]\n",
      " [0.3169201 ]\n",
      " [0.31730506]\n",
      " [0.31897169]\n",
      " [0.31964934]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.31910834]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[[0.31184882]\n",
      "  [0.31414741]\n",
      "  [0.31608665]\n",
      "  [0.31690168]\n",
      "  [0.3169201 ]\n",
      "  [0.31730506]\n",
      "  [0.31897169]\n",
      "  [0.31964934]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0019721253775060177\n",
      "Predicción post entrenamiento : [[0.31743723]]\n",
      "PERDIDAAAA despues: 0.0018264950485900044\n",
      "loss en el callback: 0.01400890201330185, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "ejemplar: [[0.31414741]\n",
      " [0.31608665]\n",
      " [0.31690168]\n",
      " [0.3169201 ]\n",
      " [0.31730506]\n",
      " [0.31897169]\n",
      " [0.31964934]\n",
      " [0.31910834]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.3183927]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[[0.31414741]\n",
      "  [0.31608665]\n",
      "  [0.31690168]\n",
      "  [0.3169201 ]\n",
      "  [0.31730506]\n",
      "  [0.31897169]\n",
      "  [0.31964934]\n",
      "  [0.31910834]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018419621046632528\n",
      "Predicción post entrenamiento : [[0.3178306]]\n",
      "PERDIDAAAA despues: 0.0017940293764695525\n",
      "loss en el callback: 0.002053330186754465, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "ejemplar: [[0.31608665]\n",
      " [0.31690168]\n",
      " [0.3169201 ]\n",
      " [0.31730506]\n",
      " [0.31897169]\n",
      " [0.31964934]\n",
      " [0.31910834]\n",
      " [0.31839269]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.31849125]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[[0.31608665]\n",
      "  [0.31690168]\n",
      "  [0.3169201 ]\n",
      "  [0.31730506]\n",
      "  [0.31897169]\n",
      "  [0.31964934]\n",
      "  [0.31910834]\n",
      "  [0.31839269]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00026447573327459395\n",
      "Predicción post entrenamiento : [[0.31892622]]\n",
      "PERDIDAAAA despues: 0.000250517507083714\n",
      "loss en el callback: 0.0017289923271164298, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "ejemplar: [[0.31690168]\n",
      " [0.3169201 ]\n",
      " [0.31730506]\n",
      " [0.31897169]\n",
      " [0.31964934]\n",
      " [0.31910834]\n",
      " [0.31839269]\n",
      " [0.31849125]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.31930235]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[[0.31690168]\n",
      "  [0.3169201 ]\n",
      "  [0.31730506]\n",
      "  [0.31897169]\n",
      "  [0.31964934]\n",
      "  [0.31910834]\n",
      "  [0.31839269]\n",
      "  [0.31849125]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013230486074462533\n",
      "Predicción post entrenamiento : [[0.31985682]]\n",
      "PERDIDAAAA despues: 0.0012830195482820272\n",
      "loss en el callback: 0.002716096816584468, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "ejemplar: [[0.3169201 ]\n",
      " [0.31730506]\n",
      " [0.31897169]\n",
      " [0.31964934]\n",
      " [0.31910834]\n",
      " [0.31839269]\n",
      " [0.31849125]\n",
      " [0.31930235]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.32014376]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[[0.3169201 ]\n",
      "  [0.31730506]\n",
      "  [0.31897169]\n",
      "  [0.31964934]\n",
      "  [0.31910834]\n",
      "  [0.31839269]\n",
      "  [0.31849125]\n",
      "  [0.31930235]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002738178300205618\n",
      "Predicción post entrenamiento : [[0.32057557]]\n",
      "PERDIDAAAA despues: 0.00025971370632760227\n",
      "loss en el callback: 0.0019290563650429249, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "ejemplar: [[0.31730506]\n",
      " [0.31897169]\n",
      " [0.31964934]\n",
      " [0.31910834]\n",
      " [0.31839269]\n",
      " [0.31849125]\n",
      " [0.31930235]\n",
      " [0.32014376]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.32093215]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[[0.31730506]\n",
      "  [0.31897169]\n",
      "  [0.31964934]\n",
      "  [0.31910834]\n",
      "  [0.31839269]\n",
      "  [0.31849125]\n",
      "  [0.31930235]\n",
      "  [0.32014376]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001602626871317625\n",
      "Predicción post entrenamiento : [[0.32120988]]\n",
      "PERDIDAAAA despues: 0.00015330803580582142\n",
      "loss en el callback: 0.0008136464166454971, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "ejemplar: [[0.31897169]\n",
      " [0.31964934]\n",
      " [0.31910834]\n",
      " [0.31839269]\n",
      " [0.31849125]\n",
      " [0.31930235]\n",
      " [0.32014376]\n",
      " [0.32093215]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.3215608]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[[0.31897169]\n",
      "  [0.31964934]\n",
      "  [0.31910834]\n",
      "  [0.31839269]\n",
      "  [0.31849125]\n",
      "  [0.31930235]\n",
      "  [0.32014376]\n",
      "  [0.32093215]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0039909291081130505\n",
      "Predicción post entrenamiento : [[0.32190284]]\n",
      "PERDIDAAAA despues: 0.003947829827666283\n",
      "loss en el callback: 0.0010004442883655429, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "ejemplar: [[0.31964934]\n",
      " [0.31910834]\n",
      " [0.31839269]\n",
      " [0.31849125]\n",
      " [0.31930235]\n",
      " [0.32014376]\n",
      " [0.32093215]\n",
      " [0.3215608 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.32196188]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[[0.31964934]\n",
      "  [0.31910834]\n",
      "  [0.31839269]\n",
      "  [0.31849125]\n",
      "  [0.31930235]\n",
      "  [0.32014376]\n",
      "  [0.32093215]\n",
      "  [0.3215608 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06206804886460304\n",
      "Predicción post entrenamiento : [[0.32429814]]\n",
      "PERDIDAAAA despues: 0.060909420251846313\n",
      "loss en el callback: 0.050811126828193665, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "ejemplar: [[0.31910834]\n",
      " [0.31839269]\n",
      " [0.31849125]\n",
      " [0.31930235]\n",
      " [0.32014376]\n",
      " [0.32093215]\n",
      " [0.3215608 ]\n",
      " [0.32196188]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.32425812]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[[0.31910834]\n",
      "  [0.31839269]\n",
      "  [0.31849125]\n",
      "  [0.31930235]\n",
      "  [0.32014376]\n",
      "  [0.32093215]\n",
      "  [0.3215608 ]\n",
      "  [0.32196188]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07399618625640869\n",
      "Predicción post entrenamiento : [[0.32687646]]\n",
      "PERDIDAAAA despues: 0.0725785419344902\n",
      "loss en el callback: 0.06804712861776352, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "ejemplar: [[0.31839269]\n",
      " [0.31849125]\n",
      " [0.31930235]\n",
      " [0.32014376]\n",
      " [0.32093215]\n",
      " [0.3215608 ]\n",
      " [0.32196188]\n",
      " [0.32425812]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.3270245]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[[0.31839269]\n",
      "  [0.31849125]\n",
      "  [0.31930235]\n",
      "  [0.32014376]\n",
      "  [0.32093215]\n",
      "  [0.3215608 ]\n",
      "  [0.32196188]\n",
      "  [0.32425812]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06128544732928276\n",
      "Predicción post entrenamiento : [[0.329533]]\n",
      "PERDIDAAAA despues: 0.06004972755908966\n",
      "loss en el callback: 0.07127203047275543, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "ejemplar: [[0.31849125]\n",
      " [0.31930235]\n",
      " [0.32014376]\n",
      " [0.32093215]\n",
      " [0.3215608 ]\n",
      " [0.32196188]\n",
      " [0.32425812]\n",
      " [0.32702449]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.3299707]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[[0.31849125]\n",
      "  [0.31930235]\n",
      "  [0.32014376]\n",
      "  [0.32093215]\n",
      "  [0.3215608 ]\n",
      "  [0.32196188]\n",
      "  [0.32425812]\n",
      "  [0.32702449]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07638780027627945\n",
      "Predicción post entrenamiento : [[0.3323262]]\n",
      "PERDIDAAAA despues: 0.07509129494428635\n",
      "loss en el callback: 0.13482487201690674, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "ejemplar: [[0.31930235]\n",
      " [0.32014376]\n",
      " [0.32093215]\n",
      " [0.3215608 ]\n",
      " [0.32196188]\n",
      " [0.32425812]\n",
      " [0.32702449]\n",
      " [0.32997069]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.33295032]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[[0.31930235]\n",
      "  [0.32014376]\n",
      "  [0.32093215]\n",
      "  [0.3215608 ]\n",
      "  [0.32196188]\n",
      "  [0.32425812]\n",
      "  [0.32702449]\n",
      "  [0.32997069]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06335631757974625\n",
      "Predicción post entrenamiento : [[0.33534053]]\n",
      "PERDIDAAAA despues: 0.06215876713395119\n",
      "loss en el callback: 0.09744562208652496, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "ejemplar: [[0.32014376]\n",
      " [0.32093215]\n",
      " [0.3215608 ]\n",
      " [0.32196188]\n",
      " [0.32425812]\n",
      " [0.32702449]\n",
      " [0.32997069]\n",
      " [0.33295032]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.33605996]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[[0.32014376]\n",
      "  [0.32093215]\n",
      "  [0.3215608 ]\n",
      "  [0.32196188]\n",
      "  [0.32425812]\n",
      "  [0.32702449]\n",
      "  [0.32997069]\n",
      "  [0.33295032]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05415479093790054\n",
      "Predicción post entrenamiento : [[0.33761045]]\n",
      "PERDIDAAAA despues: 0.0534355603158474\n",
      "loss en el callback: 0.024083757773041725, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "ejemplar: [[0.32093215]\n",
      " [0.3215608 ]\n",
      " [0.32196188]\n",
      " [0.32425812]\n",
      " [0.32702449]\n",
      " [0.32997069]\n",
      " [0.33295032]\n",
      " [0.33605996]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.3384808]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[[0.32093215]\n",
      "  [0.3215608 ]\n",
      "  [0.32196188]\n",
      "  [0.32425812]\n",
      "  [0.32702449]\n",
      "  [0.32997069]\n",
      "  [0.33295032]\n",
      "  [0.33605996]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09259441494941711\n",
      "Predicción post entrenamiento : [[0.34108773]]\n",
      "PERDIDAAAA despues: 0.09101466834545135\n",
      "loss en el callback: 0.09935835003852844, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "ejemplar: [[0.3215608 ]\n",
      " [0.32196188]\n",
      " [0.32425812]\n",
      " [0.32702449]\n",
      " [0.32997069]\n",
      " [0.33295032]\n",
      " [0.33605996]\n",
      " [0.3384808 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.34219137]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[[0.3215608 ]\n",
      "  [0.32196188]\n",
      "  [0.32425812]\n",
      "  [0.32702449]\n",
      "  [0.32997069]\n",
      "  [0.33295032]\n",
      "  [0.33605996]\n",
      "  [0.3384808 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10212348401546478\n",
      "Predicción post entrenamiento : [[0.34479776]]\n",
      "PERDIDAAAA despues: 0.10046444088220596\n",
      "loss en el callback: 0.08689585328102112, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "ejemplar: [[0.32196188]\n",
      " [0.32425812]\n",
      " [0.32702449]\n",
      " [0.32997069]\n",
      " [0.33295032]\n",
      " [0.33605996]\n",
      " [0.3384808 ]\n",
      " [0.34219137]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.34624994]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[[0.32196188]\n",
      "  [0.32425812]\n",
      "  [0.32702449]\n",
      "  [0.32997069]\n",
      "  [0.33295032]\n",
      "  [0.33605996]\n",
      "  [0.3384808 ]\n",
      "  [0.34219137]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10676231980323792\n",
      "Predicción post entrenamiento : [[0.34877306]]\n",
      "PERDIDAAAA despues: 0.10511984676122665\n",
      "loss en el callback: 0.10078775882720947, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "ejemplar: [[0.32425812]\n",
      " [0.32702449]\n",
      " [0.32997069]\n",
      " [0.33295032]\n",
      " [0.33605996]\n",
      " [0.3384808 ]\n",
      " [0.34219137]\n",
      " [0.34624994]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.35071468]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[[0.32425812]\n",
      "  [0.32702449]\n",
      "  [0.32997069]\n",
      "  [0.33295032]\n",
      "  [0.33605996]\n",
      "  [0.3384808 ]\n",
      "  [0.34219137]\n",
      "  [0.34624994]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1295011043548584\n",
      "Predicción post entrenamiento : [[0.35349807]]\n",
      "PERDIDAAAA despues: 0.1275055855512619\n",
      "loss en el callback: 0.1902458369731903, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "ejemplar: [[0.32702449]\n",
      " [0.32997069]\n",
      " [0.33295032]\n",
      " [0.33605996]\n",
      " [0.3384808 ]\n",
      " [0.34219137]\n",
      " [0.34624994]\n",
      " [0.35071468]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.35559747]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[[0.32702449]\n",
      "  [0.32997069]\n",
      "  [0.33295032]\n",
      "  [0.33605996]\n",
      "  [0.3384808 ]\n",
      "  [0.34219137]\n",
      "  [0.34624994]\n",
      "  [0.35071468]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1213778406381607\n",
      "Predicción post entrenamiento : [[0.35826507]]\n",
      "PERDIDAAAA despues: 0.119526207447052\n",
      "loss en el callback: 0.09516000002622604, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "ejemplar: [[0.32997069]\n",
      " [0.33295032]\n",
      " [0.33605996]\n",
      " [0.3384808 ]\n",
      " [0.34219137]\n",
      " [0.34624994]\n",
      " [0.35071468]\n",
      " [0.35559747]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.36046785]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[[0.32997069]\n",
      "  [0.33295032]\n",
      "  [0.33605996]\n",
      "  [0.3384808 ]\n",
      "  [0.34219137]\n",
      "  [0.34624994]\n",
      "  [0.35071468]\n",
      "  [0.35559747]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13451999425888062\n",
      "Predicción post entrenamiento : [[0.3633965]]\n",
      "PERDIDAAAA despues: 0.13238029181957245\n",
      "loss en el callback: 0.13749325275421143, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "ejemplar: [[0.33295032]\n",
      " [0.33605996]\n",
      " [0.3384808 ]\n",
      " [0.34219137]\n",
      " [0.34624994]\n",
      " [0.35071468]\n",
      " [0.35559747]\n",
      " [0.36046785]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.3657131]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[[0.33295032]\n",
      "  [0.33605996]\n",
      "  [0.3384808 ]\n",
      "  [0.34219137]\n",
      "  [0.34624994]\n",
      "  [0.35071468]\n",
      "  [0.35559747]\n",
      "  [0.36046785]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1273597925901413\n",
      "Predicción post entrenamiento : [[0.36838987]]\n",
      "PERDIDAAAA despues: 0.12545639276504517\n",
      "loss en el callback: 0.11531767249107361, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "ejemplar: [[0.33605996]\n",
      " [0.3384808 ]\n",
      " [0.34219137]\n",
      " [0.34624994]\n",
      " [0.35071468]\n",
      " [0.35559747]\n",
      " [0.36046785]\n",
      " [0.36571309]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.37087166]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[[0.33605996]\n",
      "  [0.3384808 ]\n",
      "  [0.34219137]\n",
      "  [0.34624994]\n",
      "  [0.35071468]\n",
      "  [0.35559747]\n",
      "  [0.36046785]\n",
      "  [0.36571309]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.16073864698410034\n",
      "Predicción post entrenamiento : [[0.37376818]]\n",
      "PERDIDAAAA despues: 0.1584244817495346\n",
      "loss en el callback: 0.15729917585849762, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "ejemplar: [[0.3384808 ]\n",
      " [0.34219137]\n",
      " [0.34624994]\n",
      " [0.35071468]\n",
      " [0.35559747]\n",
      " [0.36046785]\n",
      " [0.36571309]\n",
      " [0.37087166]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.37645438]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[[0.3384808 ]\n",
      "  [0.34219137]\n",
      "  [0.34624994]\n",
      "  [0.35071468]\n",
      "  [0.35559747]\n",
      "  [0.36046785]\n",
      "  [0.36571309]\n",
      "  [0.37087166]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12115342915058136\n",
      "Predicción post entrenamiento : [[0.37897497]]\n",
      "PERDIDAAAA despues: 0.11940509080886841\n",
      "loss en el callback: 0.17670083045959473, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "ejemplar: [[0.34219137]\n",
      " [0.34624994]\n",
      " [0.35071468]\n",
      " [0.35559747]\n",
      " [0.36046785]\n",
      " [0.36571309]\n",
      " [0.37087166]\n",
      " [0.37645438]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.38209805]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[[0.34219137]\n",
      "  [0.34624994]\n",
      "  [0.35071468]\n",
      "  [0.35559747]\n",
      "  [0.36046785]\n",
      "  [0.36571309]\n",
      "  [0.37087166]\n",
      "  [0.37645438]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08349768072366714\n",
      "Predicción post entrenamiento : [[0.38404122]]\n",
      "PERDIDAAAA despues: 0.08237846195697784\n",
      "loss en el callback: 0.0621749684214592, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "ejemplar: [[0.34624994]\n",
      " [0.35071468]\n",
      " [0.35559747]\n",
      " [0.36046785]\n",
      " [0.36571309]\n",
      " [0.37087166]\n",
      " [0.37645438]\n",
      " [0.38209805]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.3873978]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[[0.34624994]\n",
      "  [0.35071468]\n",
      "  [0.35559747]\n",
      "  [0.36046785]\n",
      "  [0.36571309]\n",
      "  [0.37087166]\n",
      "  [0.37645438]\n",
      "  [0.38209805]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08200894296169281\n",
      "Predicción post entrenamiento : [[0.38959372]]\n",
      "PERDIDAAAA despues: 0.0807560607790947\n",
      "loss en el callback: 0.12425334751605988, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "ejemplar: [[0.35071468]\n",
      " [0.35559747]\n",
      " [0.36046785]\n",
      " [0.36571309]\n",
      " [0.37087166]\n",
      " [0.37645438]\n",
      " [0.38209805]\n",
      " [0.3873978 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.3931612]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[[0.35071468]\n",
      "  [0.35559747]\n",
      "  [0.36046785]\n",
      "  [0.36571309]\n",
      "  [0.37087166]\n",
      "  [0.37645438]\n",
      "  [0.38209805]\n",
      "  [0.3873978 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1032276377081871\n",
      "Predicción post entrenamiento : [[0.39539763]]\n",
      "PERDIDAAAA despues: 0.10179555416107178\n",
      "loss en el callback: 0.11004532873630524, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "ejemplar: [[0.35559747]\n",
      " [0.36046785]\n",
      " [0.36571309]\n",
      " [0.37087166]\n",
      " [0.37645438]\n",
      " [0.38209805]\n",
      " [0.3873978 ]\n",
      " [0.39316121]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.39913076]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[[0.35559747]\n",
      "  [0.36046785]\n",
      "  [0.36571309]\n",
      "  [0.37087166]\n",
      "  [0.37645438]\n",
      "  [0.38209805]\n",
      "  [0.3873978 ]\n",
      "  [0.39316121]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1188642680644989\n",
      "Predicción post entrenamiento : [[0.40136263]]\n",
      "PERDIDAAAA despues: 0.11733029782772064\n",
      "loss en el callback: 0.08171866834163666, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "ejemplar: [[0.36046785]\n",
      " [0.36571309]\n",
      " [0.37087166]\n",
      " [0.37645438]\n",
      " [0.38209805]\n",
      " [0.3873978 ]\n",
      " [0.39316121]\n",
      " [0.39913076]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.40520284]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[[0.36046785]\n",
      "  [0.36571309]\n",
      "  [0.37087166]\n",
      "  [0.37645438]\n",
      "  [0.38209805]\n",
      "  [0.3873978 ]\n",
      "  [0.39316121]\n",
      "  [0.39913076]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10073342174291611\n",
      "Predicción post entrenamiento : [[0.40757617]]\n",
      "PERDIDAAAA despues: 0.09923252463340759\n",
      "loss en el callback: 0.12251178175210953, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "ejemplar: [[0.36571309]\n",
      " [0.37087166]\n",
      " [0.37645438]\n",
      " [0.38209805]\n",
      " [0.3873978 ]\n",
      " [0.39316121]\n",
      " [0.39913076]\n",
      " [0.40520284]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.4115568]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[[0.36571309]\n",
      "  [0.37087166]\n",
      "  [0.37645438]\n",
      "  [0.38209805]\n",
      "  [0.3873978 ]\n",
      "  [0.39316121]\n",
      "  [0.39913076]\n",
      "  [0.40520284]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08281994611024857\n",
      "Predicción post entrenamiento : [[0.413079]]\n",
      "PERDIDAAAA despues: 0.08194614201784134\n",
      "loss en el callback: 0.03168897703289986, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "ejemplar: [[0.37087166]\n",
      " [0.37645438]\n",
      " [0.38209805]\n",
      " [0.3873978 ]\n",
      " [0.39316121]\n",
      " [0.39913076]\n",
      " [0.40520284]\n",
      " [0.41155681]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.41714558]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[[0.37087166]\n",
      "  [0.37645438]\n",
      "  [0.38209805]\n",
      "  [0.3873978 ]\n",
      "  [0.39316121]\n",
      "  [0.39913076]\n",
      "  [0.40520284]\n",
      "  [0.41155681]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10250597447156906\n",
      "Predicción post entrenamiento : [[0.41929922]]\n",
      "PERDIDAAAA despues: 0.10113157331943512\n",
      "loss en el callback: 0.10266244411468506, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "ejemplar: [[0.37645438]\n",
      " [0.38209805]\n",
      " [0.3873978 ]\n",
      " [0.39316121]\n",
      " [0.39913076]\n",
      " [0.40520284]\n",
      " [0.41155681]\n",
      " [0.41714558]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.42349908]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[[0.37645438]\n",
      "  [0.38209805]\n",
      "  [0.3873978 ]\n",
      "  [0.39316121]\n",
      "  [0.39913076]\n",
      "  [0.40520284]\n",
      "  [0.41155681]\n",
      "  [0.41714558]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08876035362482071\n",
      "Predicción post entrenamiento : [[0.42538202]]\n",
      "PERDIDAAAA despues: 0.08764193952083588\n",
      "loss en el callback: 0.06697830557823181, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "ejemplar: [[0.38209805]\n",
      " [0.3873978 ]\n",
      " [0.39316121]\n",
      " [0.39913076]\n",
      " [0.40520284]\n",
      " [0.41155681]\n",
      " [0.41714558]\n",
      " [0.42349908]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.4296437]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[[0.38209805]\n",
      "  [0.3873978 ]\n",
      "  [0.39316121]\n",
      "  [0.39913076]\n",
      "  [0.40520284]\n",
      "  [0.41155681]\n",
      "  [0.41714558]\n",
      "  [0.42349908]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.083561472594738\n",
      "Predicción post entrenamiento : [[0.43165714]]\n",
      "PERDIDAAAA despues: 0.08240146934986115\n",
      "loss en el callback: 0.14341901242733002, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "ejemplar: [[0.3873978 ]\n",
      " [0.39316121]\n",
      " [0.39913076]\n",
      " [0.40520284]\n",
      " [0.41155681]\n",
      " [0.41714558]\n",
      " [0.42349908]\n",
      " [0.42964369]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.4359851]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[[0.3873978 ]\n",
      "  [0.39316121]\n",
      "  [0.39913076]\n",
      "  [0.40520284]\n",
      "  [0.41155681]\n",
      "  [0.41714558]\n",
      "  [0.42349908]\n",
      "  [0.42964369]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.056726012378931046\n",
      "Predicción post entrenamiento : [[0.43698144]]\n",
      "PERDIDAAAA despues: 0.05625239759683609\n",
      "loss en el callback: 0.01600763574242592, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "ejemplar: [[0.39316121]\n",
      " [0.39913076]\n",
      " [0.40520284]\n",
      " [0.41155681]\n",
      " [0.41714558]\n",
      " [0.42349908]\n",
      " [0.42964369]\n",
      " [0.43598509]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.44147614]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[[0.39316121]\n",
      "  [0.39913076]\n",
      "  [0.40520284]\n",
      "  [0.41155681]\n",
      "  [0.41714558]\n",
      "  [0.42349908]\n",
      "  [0.42964369]\n",
      "  [0.43598509]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06609541922807693\n",
      "Predicción post entrenamiento : [[0.44270238]]\n",
      "PERDIDAAAA despues: 0.06546641141176224\n",
      "loss en el callback: 0.026180926710367203, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "ejemplar: [[0.39913076]\n",
      " [0.40520284]\n",
      " [0.41155681]\n",
      " [0.41714558]\n",
      " [0.42349908]\n",
      " [0.42964369]\n",
      " [0.43598509]\n",
      " [0.44147614]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.4472789]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[[0.39913076]\n",
      "  [0.40520284]\n",
      "  [0.41155681]\n",
      "  [0.41714558]\n",
      "  [0.42349908]\n",
      "  [0.42964369]\n",
      "  [0.43598509]\n",
      "  [0.44147614]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07494423538446426\n",
      "Predicción post entrenamiento : [[0.44919407]]\n",
      "PERDIDAAAA despues: 0.07389930635690689\n",
      "loss en el callback: 0.1418572962284088, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "ejemplar: [[0.40520284]\n",
      " [0.41155681]\n",
      " [0.41714558]\n",
      " [0.42349908]\n",
      " [0.42964369]\n",
      " [0.43598509]\n",
      " [0.44147614]\n",
      " [0.44727889]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.45381147]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[[0.40520284]\n",
      "  [0.41155681]\n",
      "  [0.41714558]\n",
      "  [0.42349908]\n",
      "  [0.42964369]\n",
      "  [0.43598509]\n",
      "  [0.44147614]\n",
      "  [0.44727889]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07224088907241821\n",
      "Predicción post entrenamiento : [[0.4557166]]\n",
      "PERDIDAAAA despues: 0.07122040539979935\n",
      "loss en el callback: 0.0984162837266922, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "ejemplar: [[0.41155681]\n",
      " [0.41714558]\n",
      " [0.42349908]\n",
      " [0.42964369]\n",
      " [0.43598509]\n",
      " [0.44147614]\n",
      " [0.44727889]\n",
      " [0.45381147]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.46035117]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[[0.41155681]\n",
      "  [0.41714558]\n",
      "  [0.42349908]\n",
      "  [0.42964369]\n",
      "  [0.43598509]\n",
      "  [0.44147614]\n",
      "  [0.44727889]\n",
      "  [0.45381147]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08758336305618286\n",
      "Predicción post entrenamiento : [[0.46229705]]\n",
      "PERDIDAAAA despues: 0.08643540740013123\n",
      "loss en el callback: 0.09812220185995102, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "ejemplar: [[0.41714558]\n",
      " [0.42349908]\n",
      " [0.42964369]\n",
      " [0.43598509]\n",
      " [0.44147614]\n",
      " [0.44727889]\n",
      " [0.45381147]\n",
      " [0.46035117]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.46688125]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[[0.41714558]\n",
      "  [0.42349908]\n",
      "  [0.42964369]\n",
      "  [0.43598509]\n",
      "  [0.44147614]\n",
      "  [0.44727889]\n",
      "  [0.45381147]\n",
      "  [0.46035117]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1301080882549286\n",
      "Predicción post entrenamiento : [[0.46907118]]\n",
      "PERDIDAAAA despues: 0.12853305041790009\n",
      "loss en el callback: 0.10562824457883835, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "ejemplar: [[0.42349908]\n",
      " [0.42964369]\n",
      " [0.43598509]\n",
      " [0.44147614]\n",
      " [0.44727889]\n",
      " [0.45381147]\n",
      " [0.46035117]\n",
      " [0.46688125]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.47379017]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[[0.42349908]\n",
      "  [0.42964369]\n",
      "  [0.43598509]\n",
      "  [0.44147614]\n",
      "  [0.44727889]\n",
      "  [0.45381147]\n",
      "  [0.46035117]\n",
      "  [0.46688125]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13324837386608124\n",
      "Predicción post entrenamiento : [[0.47621328]]\n",
      "PERDIDAAAA despues: 0.1314852237701416\n",
      "loss en el callback: 0.1823771893978119, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "ejemplar: [[0.42964369]\n",
      " [0.43598509]\n",
      " [0.44147614]\n",
      " [0.44727889]\n",
      " [0.45381147]\n",
      " [0.46035117]\n",
      " [0.46688125]\n",
      " [0.47379017]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.48090643]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[[0.42964369]\n",
      "  [0.43598509]\n",
      "  [0.44147614]\n",
      "  [0.44727889]\n",
      "  [0.45381147]\n",
      "  [0.46035117]\n",
      "  [0.46688125]\n",
      "  [0.47379017]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09819409996271133\n",
      "Predicción post entrenamiento : [[0.4827895]]\n",
      "PERDIDAAAA despues: 0.09701749682426453\n",
      "loss en el callback: 0.09130334854125977, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "ejemplar: [[0.43598509]\n",
      " [0.44147614]\n",
      " [0.44727889]\n",
      " [0.45381147]\n",
      " [0.46035117]\n",
      " [0.46688125]\n",
      " [0.47379017]\n",
      " [0.48090643]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.48751783]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[[0.43598509]\n",
      "  [0.44147614]\n",
      "  [0.44727889]\n",
      "  [0.45381147]\n",
      "  [0.46035117]\n",
      "  [0.46688125]\n",
      "  [0.47379017]\n",
      "  [0.48090643]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08778591454029083\n",
      "Predicción post entrenamiento : [[0.48933247]]\n",
      "PERDIDAAAA despues: 0.08671390265226364\n",
      "loss en el callback: 0.09320861846208572, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "ejemplar: [[0.44147614]\n",
      " [0.44727889]\n",
      " [0.45381147]\n",
      " [0.46035117]\n",
      " [0.46688125]\n",
      " [0.47379017]\n",
      " [0.48090643]\n",
      " [0.48751783]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.4940712]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[[0.44147614]\n",
      "  [0.44727889]\n",
      "  [0.45381147]\n",
      "  [0.46035117]\n",
      "  [0.46688125]\n",
      "  [0.47379017]\n",
      "  [0.48090643]\n",
      "  [0.48751783]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07499285787343979\n",
      "Predicción post entrenamiento : [[0.49598753]]\n",
      "PERDIDAAAA despues: 0.07394695281982422\n",
      "loss en el callback: 0.13874875009059906, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "ejemplar: [[0.44727889]\n",
      " [0.45381147]\n",
      " [0.46035117]\n",
      " [0.46688125]\n",
      " [0.47379017]\n",
      " [0.48090643]\n",
      " [0.48751783]\n",
      " [0.49407119]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.5009682]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[[0.44727889]\n",
      "  [0.45381147]\n",
      "  [0.46035117]\n",
      "  [0.46688125]\n",
      "  [0.47379017]\n",
      "  [0.48090643]\n",
      "  [0.48751783]\n",
      "  [0.49407119]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08043543249368668\n",
      "Predicción post entrenamiento : [[0.50271684]]\n",
      "PERDIDAAAA despues: 0.07944663614034653\n",
      "loss en el callback: 0.08962447941303253, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "ejemplar: [[0.45381147]\n",
      " [0.46035117]\n",
      " [0.46688125]\n",
      " [0.47379017]\n",
      " [0.48090643]\n",
      " [0.48751783]\n",
      " [0.49407119]\n",
      " [0.50096822]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.50790936]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[[0.45381147]\n",
      "  [0.46035117]\n",
      "  [0.46688125]\n",
      "  [0.47379017]\n",
      "  [0.48090643]\n",
      "  [0.48751783]\n",
      "  [0.49407119]\n",
      "  [0.50096822]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1375073343515396\n",
      "Predicción post entrenamiento : [[0.50963074]]\n",
      "PERDIDAAAA despues: 0.1362336426973343\n",
      "loss en el callback: 0.05904342234134674, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "ejemplar: [[0.46035117]\n",
      " [0.46688125]\n",
      " [0.47379017]\n",
      " [0.48090643]\n",
      " [0.48751783]\n",
      " [0.49407119]\n",
      " [0.50096822]\n",
      " [0.50790936]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.51488805]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[[0.46035117]\n",
      "  [0.46688125]\n",
      "  [0.47379017]\n",
      "  [0.48090643]\n",
      "  [0.48751783]\n",
      "  [0.49407119]\n",
      "  [0.50096822]\n",
      "  [0.50790936]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1301344633102417\n",
      "Predicción post entrenamiento : [[0.5171038]]\n",
      "PERDIDAAAA despues: 0.1285407543182373\n",
      "loss en el callback: 0.16712141036987305, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "ejemplar: [[0.46688125]\n",
      " [0.47379017]\n",
      " [0.48090643]\n",
      " [0.48751783]\n",
      " [0.49407119]\n",
      " [0.50096822]\n",
      " [0.50790936]\n",
      " [0.51488805]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.5224363]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[[0.46688125]\n",
      "  [0.47379017]\n",
      "  [0.48090643]\n",
      "  [0.48751783]\n",
      "  [0.49407119]\n",
      "  [0.50096822]\n",
      "  [0.50790936]\n",
      "  [0.51488805]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10657578706741333\n",
      "Predicción post entrenamiento : [[0.5244239]]\n",
      "PERDIDAAAA despues: 0.1052820086479187\n",
      "loss en el callback: 0.10995781421661377, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "ejemplar: [[0.47379017]\n",
      " [0.48090643]\n",
      " [0.48751783]\n",
      " [0.49407119]\n",
      " [0.50096822]\n",
      " [0.50790936]\n",
      " [0.51488805]\n",
      " [0.52243632]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.5298484]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[[0.47379017]\n",
      "  [0.48090643]\n",
      "  [0.48751783]\n",
      "  [0.49407119]\n",
      "  [0.50096822]\n",
      "  [0.50790936]\n",
      "  [0.51488805]\n",
      "  [0.52243632]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08319710940122604\n",
      "Predicción post entrenamiento : [[0.53138167]]\n",
      "PERDIDAAAA despues: 0.08231495320796967\n",
      "loss en el callback: 0.06016889959573746, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "ejemplar: [[0.48090643]\n",
      " [0.48751783]\n",
      " [0.49407119]\n",
      " [0.50096822]\n",
      " [0.50790936]\n",
      " [0.51488805]\n",
      " [0.52243632]\n",
      " [0.5298484 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.5368208]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[[0.48090643]\n",
      "  [0.48751783]\n",
      "  [0.49407119]\n",
      "  [0.50096822]\n",
      "  [0.50790936]\n",
      "  [0.51488805]\n",
      "  [0.52243632]\n",
      "  [0.5298484 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08409447968006134\n",
      "Predicción post entrenamiento : [[0.5381267]]\n",
      "PERDIDAAAA despues: 0.08333880454301834\n",
      "loss en el callback: 0.038517650216817856, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "ejemplar: [[0.48751783]\n",
      " [0.49407119]\n",
      " [0.50096822]\n",
      " [0.50790936]\n",
      " [0.51488805]\n",
      " [0.52243632]\n",
      " [0.5298484 ]\n",
      " [0.53682083]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.54353744]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[[0.48751783]\n",
      "  [0.49407119]\n",
      "  [0.50096822]\n",
      "  [0.50790936]\n",
      "  [0.51488805]\n",
      "  [0.52243632]\n",
      "  [0.5298484 ]\n",
      "  [0.53682083]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05847549065947533\n",
      "Predicción post entrenamiento : [[0.5449709]]\n",
      "PERDIDAAAA despues: 0.05778425931930542\n",
      "loss en el callback: 0.07688884437084198, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "ejemplar: [[0.49407119]\n",
      " [0.50096822]\n",
      " [0.50790936]\n",
      " [0.51488805]\n",
      " [0.52243632]\n",
      " [0.5298484 ]\n",
      " [0.53682083]\n",
      " [0.54353744]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.5504865]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[[0.49407119]\n",
      "  [0.50096822]\n",
      "  [0.50790936]\n",
      "  [0.51488805]\n",
      "  [0.52243632]\n",
      "  [0.5298484 ]\n",
      "  [0.53682083]\n",
      "  [0.54353744]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05699796602129936\n",
      "Predicción post entrenamiento : [[0.5516059]]\n",
      "PERDIDAAAA despues: 0.05646473541855812\n",
      "loss en el callback: 0.03192285820841789, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "ejemplar: [[0.50096822]\n",
      " [0.50790936]\n",
      " [0.51488805]\n",
      " [0.52243632]\n",
      " [0.5298484 ]\n",
      " [0.53682083]\n",
      " [0.54353744]\n",
      " [0.55048651]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.5572594]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[[0.50096822]\n",
      "  [0.50790936]\n",
      "  [0.51488805]\n",
      "  [0.52243632]\n",
      "  [0.5298484 ]\n",
      "  [0.53682083]\n",
      "  [0.54353744]\n",
      "  [0.55048651]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07668103277683258\n",
      "Predicción post entrenamiento : [[0.5586194]]\n",
      "PERDIDAAAA despues: 0.0759296789765358\n",
      "loss en el callback: 0.04681749269366264, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "ejemplar: [[0.50790936]\n",
      " [0.51488805]\n",
      " [0.52243632]\n",
      " [0.5298484 ]\n",
      " [0.53682083]\n",
      " [0.54353744]\n",
      " [0.55048651]\n",
      " [0.55725938]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.56433904]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[[0.50790936]\n",
      "  [0.51488805]\n",
      "  [0.52243632]\n",
      "  [0.5298484 ]\n",
      "  [0.53682083]\n",
      "  [0.54353744]\n",
      "  [0.55048651]\n",
      "  [0.55725938]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06157185137271881\n",
      "Predicción post entrenamiento : [[0.56578887]]\n",
      "PERDIDAAAA despues: 0.06085444241762161\n",
      "loss en el callback: 0.06603948771953583, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "ejemplar: [[0.51488805]\n",
      " [0.52243632]\n",
      " [0.5298484 ]\n",
      " [0.53682083]\n",
      " [0.54353744]\n",
      " [0.55048651]\n",
      " [0.55725938]\n",
      " [0.56433904]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.5715646]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[[0.51488805]\n",
      "  [0.52243632]\n",
      "  [0.5298484 ]\n",
      "  [0.53682083]\n",
      "  [0.54353744]\n",
      "  [0.55048651]\n",
      "  [0.55725938]\n",
      "  [0.56433904]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.052750714123249054\n",
      "Predicción post entrenamiento : [[0.57248896]]\n",
      "PERDIDAAAA despues: 0.05232696607708931\n",
      "loss en el callback: 0.020552881062030792, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "ejemplar: [[0.52243632]\n",
      " [0.5298484 ]\n",
      " [0.53682083]\n",
      " [0.54353744]\n",
      " [0.55048651]\n",
      " [0.55725938]\n",
      " [0.56433904]\n",
      " [0.57156461]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.5783072]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[[0.52243632]\n",
      "  [0.5298484 ]\n",
      "  [0.53682083]\n",
      "  [0.54353744]\n",
      "  [0.55048651]\n",
      "  [0.55725938]\n",
      "  [0.56433904]\n",
      "  [0.57156461]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.050566449761390686\n",
      "Predicción post entrenamiento : [[0.5792647]]\n",
      "PERDIDAAAA despues: 0.0501367449760437\n",
      "loss en el callback: 0.02370358631014824, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "ejemplar: [[0.5298484 ]\n",
      " [0.53682083]\n",
      " [0.54353744]\n",
      " [0.55048651]\n",
      " [0.55725938]\n",
      " [0.56433904]\n",
      " [0.57156461]\n",
      " [0.57830721]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.5849736]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[[0.5298484 ]\n",
      "  [0.53682083]\n",
      "  [0.54353744]\n",
      "  [0.55048651]\n",
      "  [0.55725938]\n",
      "  [0.56433904]\n",
      "  [0.57156461]\n",
      "  [0.57830721]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.043479468673467636\n",
      "Predicción post entrenamiento : [[0.586142]]\n",
      "PERDIDAAAA despues: 0.042993560433387756\n",
      "loss en el callback: 0.0422859787940979, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "ejemplar: [[0.53682083]\n",
      " [0.54353744]\n",
      " [0.55048651]\n",
      " [0.55725938]\n",
      " [0.56433904]\n",
      " [0.57156461]\n",
      " [0.57830721]\n",
      " [0.58497357]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.5917531]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[[0.53682083]\n",
      "  [0.54353744]\n",
      "  [0.55048651]\n",
      "  [0.55725938]\n",
      "  [0.56433904]\n",
      "  [0.57156461]\n",
      "  [0.57830721]\n",
      "  [0.58497357]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.028364399448037148\n",
      "Predicción post entrenamiento : [[0.5926956]]\n",
      "PERDIDAAAA despues: 0.028047829866409302\n",
      "loss en el callback: 0.02750309370458126, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "ejemplar: [[0.54353744]\n",
      " [0.55048651]\n",
      " [0.55725938]\n",
      " [0.56433904]\n",
      " [0.57156461]\n",
      " [0.57830721]\n",
      " [0.58497357]\n",
      " [0.59175313]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.598305]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[[0.54353744]\n",
      "  [0.55048651]\n",
      "  [0.55725938]\n",
      "  [0.56433904]\n",
      "  [0.57156461]\n",
      "  [0.57830721]\n",
      "  [0.58497357]\n",
      "  [0.59175313]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018787890672683716\n",
      "Predicción post entrenamiento : [[0.59931046]]\n",
      "PERDIDAAAA despues: 0.018513264134526253\n",
      "loss en el callback: 0.039752423763275146, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "ejemplar: [[0.55048651]\n",
      " [0.55725938]\n",
      " [0.56433904]\n",
      " [0.57156461]\n",
      " [0.57830721]\n",
      " [0.58497357]\n",
      " [0.59175313]\n",
      " [0.59830499]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.60497916]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[[0.55048651]\n",
      "  [0.55725938]\n",
      "  [0.56433904]\n",
      "  [0.57156461]\n",
      "  [0.57830721]\n",
      "  [0.58497357]\n",
      "  [0.59175313]\n",
      "  [0.59830499]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011069283820688725\n",
      "Predicción post entrenamiento : [[0.6051687]]\n",
      "PERDIDAAAA despues: 0.011029435321688652\n",
      "loss en el callback: 0.000965270446613431, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "ejemplar: [[0.55725938]\n",
      " [0.56433904]\n",
      " [0.57156461]\n",
      " [0.57830721]\n",
      " [0.58497357]\n",
      " [0.59175313]\n",
      " [0.59830499]\n",
      " [0.60497916]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.6108324]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[[0.55725938]\n",
      "  [0.56433904]\n",
      "  [0.57156461]\n",
      "  [0.57830721]\n",
      "  [0.58497357]\n",
      "  [0.59175313]\n",
      "  [0.59830499]\n",
      "  [0.60497916]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01026061549782753\n",
      "Predicción post entrenamiento : [[0.6113168]]\n",
      "PERDIDAAAA despues: 0.01016271486878395\n",
      "loss en el callback: 0.007627993822097778, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "ejemplar: [[0.56433904]\n",
      " [0.57156461]\n",
      " [0.57830721]\n",
      " [0.58497357]\n",
      " [0.59175313]\n",
      " [0.59830499]\n",
      " [0.60497916]\n",
      " [0.61083239]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.61700726]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[[0.56433904]\n",
      "  [0.57156461]\n",
      "  [0.57830721]\n",
      "  [0.58497357]\n",
      "  [0.59175313]\n",
      "  [0.59830499]\n",
      "  [0.60497916]\n",
      "  [0.61083239]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015037765726447105\n",
      "Predicción post entrenamiento : [[0.6171597]]\n",
      "PERDIDAAAA despues: 0.015000395476818085\n",
      "loss en el callback: 0.0006412559887394309, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "ejemplar: [[0.57156461]\n",
      " [0.57830721]\n",
      " [0.58497357]\n",
      " [0.59175313]\n",
      " [0.59830499]\n",
      " [0.60497916]\n",
      " [0.61083239]\n",
      " [0.61700726]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.6227784]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[[0.57156461]\n",
      "  [0.57830721]\n",
      "  [0.58497357]\n",
      "  [0.59175313]\n",
      "  [0.59830499]\n",
      "  [0.60497916]\n",
      "  [0.61083239]\n",
      "  [0.61700726]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012852838262915611\n",
      "Predicción post entrenamiento : [[0.6232084]]\n",
      "PERDIDAAAA despues: 0.012755527161061764\n",
      "loss en el callback: 0.005677557550370693, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "ejemplar: [[0.57830721]\n",
      " [0.58497357]\n",
      " [0.59175313]\n",
      " [0.59830499]\n",
      " [0.60497916]\n",
      " [0.61083239]\n",
      " [0.61700726]\n",
      " [0.62277842]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.62868357]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[[0.57830721]\n",
      "  [0.58497357]\n",
      "  [0.59175313]\n",
      "  [0.59830499]\n",
      "  [0.60497916]\n",
      "  [0.61083239]\n",
      "  [0.61700726]\n",
      "  [0.62277842]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015122098848223686\n",
      "Predicción post entrenamiento : [[0.62946683]]\n",
      "PERDIDAAAA despues: 0.0014519055839627981\n",
      "loss en el callback: 0.032722990959882736, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "ejemplar: [[0.58497357]\n",
      " [0.59175313]\n",
      " [0.59830499]\n",
      " [0.60497916]\n",
      " [0.61083239]\n",
      " [0.61700726]\n",
      " [0.62277842]\n",
      " [0.62868357]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.6348837]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[[0.58497357]\n",
      "  [0.59175313]\n",
      "  [0.59830499]\n",
      "  [0.60497916]\n",
      "  [0.61083239]\n",
      "  [0.61700726]\n",
      "  [0.62277842]\n",
      "  [0.62868357]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012258196948096156\n",
      "Predicción post entrenamiento : [[0.63489676]]\n",
      "PERDIDAAAA despues: 0.0012249058345332742\n",
      "loss en el callback: 5.604757461696863e-06, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "ejemplar: [[0.59175313]\n",
      " [0.59830499]\n",
      " [0.60497916]\n",
      " [0.61083239]\n",
      " [0.61700726]\n",
      " [0.62277842]\n",
      " [0.62868357]\n",
      " [0.6348837 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.6402436]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[[0.59175313]\n",
      "  [0.59830499]\n",
      "  [0.60497916]\n",
      "  [0.61083239]\n",
      "  [0.61700726]\n",
      "  [0.62277842]\n",
      "  [0.62868357]\n",
      "  [0.6348837 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003179339924827218\n",
      "Predicción post entrenamiento : [[0.6400066]]\n",
      "PERDIDAAAA despues: 0.003206121502444148\n",
      "loss en el callback: 0.001609418774023652, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "ejemplar: [[0.59830499]\n",
      " [0.60497916]\n",
      " [0.61083239]\n",
      " [0.61700726]\n",
      " [0.62277842]\n",
      " [0.62868357]\n",
      " [0.6348837 ]\n",
      " [0.64024359]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.6452204]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[[0.59830499]\n",
      "  [0.60497916]\n",
      "  [0.61083239]\n",
      "  [0.61700726]\n",
      "  [0.62277842]\n",
      "  [0.62868357]\n",
      "  [0.6348837 ]\n",
      "  [0.64024359]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00011506699956953526\n",
      "Predicción post entrenamiento : [[0.6452192]]\n",
      "PERDIDAAAA despues: 0.00011509257456054911\n",
      "loss en el callback: 6.950148190298933e-08, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "ejemplar: [[0.60497916]\n",
      " [0.61083239]\n",
      " [0.61700726]\n",
      " [0.62277842]\n",
      " [0.62868357]\n",
      " [0.6348837 ]\n",
      " [0.64024359]\n",
      " [0.6452204 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.65031874]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[[0.60497916]\n",
      "  [0.61083239]\n",
      "  [0.61700726]\n",
      "  [0.62277842]\n",
      "  [0.62868357]\n",
      "  [0.6348837 ]\n",
      "  [0.64024359]\n",
      "  [0.6452204 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008115616510622203\n",
      "Predicción post entrenamiento : [[0.6509907]]\n",
      "PERDIDAAAA despues: 0.000773726380430162\n",
      "loss en el callback: 0.022799009457230568, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "ejemplar: [[0.61083239]\n",
      " [0.61700726]\n",
      " [0.62277842]\n",
      " [0.62868357]\n",
      " [0.6348837 ]\n",
      " [0.64024359]\n",
      " [0.6452204 ]\n",
      " [0.65031874]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.6559039]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[[0.61083239]\n",
      "  [0.61700726]\n",
      "  [0.62277842]\n",
      "  [0.62868357]\n",
      "  [0.6348837 ]\n",
      "  [0.64024359]\n",
      "  [0.6452204 ]\n",
      "  [0.65031874]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004076625918969512\n",
      "Predicción post entrenamiento : [[0.6565111]]\n",
      "PERDIDAAAA despues: 0.00038350970135070384\n",
      "loss en el callback: 0.019486740231513977, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "ejemplar: [[0.61700726]\n",
      " [0.62277842]\n",
      " [0.62868357]\n",
      " [0.6348837 ]\n",
      " [0.64024359]\n",
      " [0.6452204 ]\n",
      " [0.65031874]\n",
      " [0.65590388]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.66140944]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[[0.61700726]\n",
      "  [0.62277842]\n",
      "  [0.62868357]\n",
      "  [0.6348837 ]\n",
      "  [0.64024359]\n",
      "  [0.6452204 ]\n",
      "  [0.65031874]\n",
      "  [0.65590388]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004644793923944235\n",
      "Predicción post entrenamiento : [[0.6616274]]\n",
      "PERDIDAAAA despues: 0.004615130368620157\n",
      "loss en el callback: 0.001653431449085474, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "ejemplar: [[0.62277842]\n",
      " [0.62868357]\n",
      " [0.6348837 ]\n",
      " [0.64024359]\n",
      " [0.6452204 ]\n",
      " [0.65031874]\n",
      " [0.65590388]\n",
      " [0.66140944]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.66640204]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[[0.62277842]\n",
      "  [0.62868357]\n",
      "  [0.6348837 ]\n",
      "  [0.64024359]\n",
      "  [0.6452204 ]\n",
      "  [0.65031874]\n",
      "  [0.65590388]\n",
      "  [0.66140944]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012163720093667507\n",
      "Predicción post entrenamiento : [[0.6659051]]\n",
      "PERDIDAAAA despues: 0.0012512808898463845\n",
      "loss en el callback: 0.007540497928857803, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "ejemplar: [[0.62868357]\n",
      " [0.6348837 ]\n",
      " [0.64024359]\n",
      " [0.6452204 ]\n",
      " [0.65031874]\n",
      " [0.65590388]\n",
      " [0.66140944]\n",
      " [0.66640204]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.67062736]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[[0.62868357]\n",
      "  [0.6348837 ]\n",
      "  [0.64024359]\n",
      "  [0.6452204 ]\n",
      "  [0.65031874]\n",
      "  [0.65590388]\n",
      "  [0.66140944]\n",
      "  [0.66640204]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009390508756041527\n",
      "Predicción post entrenamiento : [[0.6715755]]\n",
      "PERDIDAAAA despues: 0.009207651019096375\n",
      "loss en el callback: 0.04695690795779228, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "ejemplar: [[0.6348837 ]\n",
      " [0.64024359]\n",
      " [0.6452204 ]\n",
      " [0.65031874]\n",
      " [0.65590388]\n",
      " [0.66140944]\n",
      " [0.66640204]\n",
      " [0.67062736]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.6761831]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[[0.6348837 ]\n",
      "  [0.64024359]\n",
      "  [0.6452204 ]\n",
      "  [0.65031874]\n",
      "  [0.65590388]\n",
      "  [0.66140944]\n",
      "  [0.66640204]\n",
      "  [0.67062736]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0062331948429346085\n",
      "Predicción post entrenamiento : [[0.67679137]]\n",
      "PERDIDAAAA despues: 0.006137518677860498\n",
      "loss en el callback: 0.01572435535490513, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "ejemplar: [[0.64024359]\n",
      " [0.6452204 ]\n",
      " [0.65031874]\n",
      " [0.65590388]\n",
      " [0.66140944]\n",
      " [0.66640204]\n",
      " [0.67062736]\n",
      " [0.6761831 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.6811724]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[[0.64024359]\n",
      "  [0.6452204 ]\n",
      "  [0.65031874]\n",
      "  [0.65590388]\n",
      "  [0.66140944]\n",
      "  [0.66640204]\n",
      "  [0.67062736]\n",
      "  [0.6761831 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004081632476300001\n",
      "Predicción post entrenamiento : [[0.6817698]]\n",
      "PERDIDAAAA despues: 0.004005654249340296\n",
      "loss en el callback: 0.016260627657175064, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "ejemplar: [[0.6452204 ]\n",
      " [0.65031874]\n",
      " [0.65590388]\n",
      " [0.66140944]\n",
      " [0.66640204]\n",
      " [0.67062736]\n",
      " [0.6761831 ]\n",
      " [0.68117237]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.6861089]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[[0.6452204 ]\n",
      "  [0.65031874]\n",
      "  [0.65590388]\n",
      "  [0.66140944]\n",
      "  [0.66640204]\n",
      "  [0.67062736]\n",
      "  [0.6761831 ]\n",
      "  [0.68117237]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004346129484474659\n",
      "Predicción post entrenamiento : [[0.6866665]]\n",
      "PERDIDAAAA despues: 0.004272920545190573\n",
      "loss en el callback: 0.01388307474553585, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "ejemplar: [[0.65031874]\n",
      " [0.65590388]\n",
      " [0.66140944]\n",
      " [0.66640204]\n",
      " [0.67062736]\n",
      " [0.6761831 ]\n",
      " [0.68117237]\n",
      " [0.68610889]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.691054]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[[0.65031874]\n",
      "  [0.65590388]\n",
      "  [0.66140944]\n",
      "  [0.66640204]\n",
      "  [0.67062736]\n",
      "  [0.6761831 ]\n",
      "  [0.68117237]\n",
      "  [0.68610889]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003515025891829282\n",
      "Predicción post entrenamiento : [[0.69168717]]\n",
      "PERDIDAAAA despues: 0.0003281612880527973\n",
      "loss en el callback: 0.02217155694961548, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "ejemplar: [[0.65590388]\n",
      " [0.66140944]\n",
      " [0.66640204]\n",
      " [0.67062736]\n",
      " [0.6761831 ]\n",
      " [0.68117237]\n",
      " [0.68610889]\n",
      " [0.69105399]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.69608706]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[[0.65590388]\n",
      "  [0.66140944]\n",
      "  [0.66640204]\n",
      "  [0.67062736]\n",
      "  [0.6761831 ]\n",
      "  [0.68117237]\n",
      "  [0.68610889]\n",
      "  [0.69105399]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.200184437446296e-05\n",
      "Predicción post entrenamiento : [[0.69580424]]\n",
      "PERDIDAAAA despues: 2.8881951948278584e-05\n",
      "loss en el callback: 0.002810659119859338, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "ejemplar: [[0.66140944]\n",
      " [0.66640204]\n",
      " [0.67062736]\n",
      " [0.6761831 ]\n",
      " [0.68117237]\n",
      " [0.68610889]\n",
      " [0.69105399]\n",
      " [0.69608706]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.7000758]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[[0.66140944]\n",
      "  [0.66640204]\n",
      "  [0.67062736]\n",
      "  [0.6761831 ]\n",
      "  [0.68117237]\n",
      "  [0.68610889]\n",
      "  [0.69105399]\n",
      "  [0.69608706]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002946640131995082\n",
      "Predicción post entrenamiento : [[0.70057756]]\n",
      "PERDIDAAAA despues: 0.0028924187645316124\n",
      "loss en el callback: 0.010936113074421883, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "ejemplar: [[0.66640204]\n",
      " [0.67062736]\n",
      " [0.6761831 ]\n",
      " [0.68117237]\n",
      " [0.68610889]\n",
      " [0.69105399]\n",
      " [0.69608706]\n",
      " [0.70007581]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.70471627]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[[0.66640204]\n",
      "  [0.67062736]\n",
      "  [0.6761831 ]\n",
      "  [0.68117237]\n",
      "  [0.68610889]\n",
      "  [0.69105399]\n",
      "  [0.69608706]\n",
      "  [0.70007581]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000305705179926008\n",
      "Predicción post entrenamiento : [[0.704517]]\n",
      "PERDIDAAAA despues: 0.00031271271291188896\n",
      "loss en el callback: 0.00141283986158669, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "ejemplar: [[0.67062736]\n",
      " [0.6761831 ]\n",
      " [0.68117237]\n",
      " [0.68610889]\n",
      " [0.69105399]\n",
      " [0.69608706]\n",
      " [0.70007581]\n",
      " [0.70471627]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.70863473]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[[0.67062736]\n",
      "  [0.6761831 ]\n",
      "  [0.68117237]\n",
      "  [0.68610889]\n",
      "  [0.69105399]\n",
      "  [0.69608706]\n",
      "  [0.70007581]\n",
      "  [0.70471627]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019564630463719368\n",
      "Predicción post entrenamiento : [[0.70921755]]\n",
      "PERDIDAAAA despues: 0.019401930272579193\n",
      "loss en el callback: 0.012919037602841854, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "ejemplar: [[0.6761831 ]\n",
      " [0.68117237]\n",
      " [0.68610889]\n",
      " [0.69105399]\n",
      " [0.69608706]\n",
      " [0.70007581]\n",
      " [0.70471627]\n",
      " [0.70863473]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.71350604]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[[0.6761831 ]\n",
      "  [0.68117237]\n",
      "  [0.68610889]\n",
      "  [0.69105399]\n",
      "  [0.69608706]\n",
      "  [0.70007581]\n",
      "  [0.70471627]\n",
      "  [0.70863473]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03684746474027634\n",
      "Predicción post entrenamiento : [[0.71417534]]\n",
      "PERDIDAAAA despues: 0.03659095987677574\n",
      "loss en el callback: 0.015010032802820206, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "ejemplar: [[0.68117237]\n",
      " [0.68610889]\n",
      " [0.69105399]\n",
      " [0.69608706]\n",
      " [0.70007581]\n",
      " [0.70471627]\n",
      " [0.70863473]\n",
      " [0.71350604]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.7182768]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[[0.68117237]\n",
      "  [0.68610889]\n",
      "  [0.69105399]\n",
      "  [0.69608706]\n",
      "  [0.70007581]\n",
      "  [0.70471627]\n",
      "  [0.70863473]\n",
      "  [0.71350604]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.026876132935285568\n",
      "Predicción post entrenamiento : [[0.7186702]]\n",
      "PERDIDAAAA despues: 0.02674730308353901\n",
      "loss en el callback: 0.005383302457630634, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "ejemplar: [[0.68610889]\n",
      " [0.69105399]\n",
      " [0.69608706]\n",
      " [0.70007581]\n",
      " [0.70471627]\n",
      " [0.70863473]\n",
      " [0.71350604]\n",
      " [0.7182768 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.722696]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[[0.68610889]\n",
      "  [0.69105399]\n",
      "  [0.69608706]\n",
      "  [0.70007581]\n",
      "  [0.70471627]\n",
      "  [0.70863473]\n",
      "  [0.71350604]\n",
      "  [0.7182768 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03425892814993858\n",
      "Predicción post entrenamiento : [[0.72365355]]\n",
      "PERDIDAAAA despues: 0.03390537574887276\n",
      "loss en el callback: 0.04075256735086441, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "ejemplar: [[0.69105399]\n",
      " [0.69608706]\n",
      " [0.70007581]\n",
      " [0.70471627]\n",
      " [0.70863473]\n",
      " [0.71350604]\n",
      " [0.7182768 ]\n",
      " [0.72269601]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.7275977]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[[0.69105399]\n",
      "  [0.69608706]\n",
      "  [0.70007581]\n",
      "  [0.70471627]\n",
      "  [0.70863473]\n",
      "  [0.71350604]\n",
      "  [0.7182768 ]\n",
      "  [0.72269601]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02623751200735569\n",
      "Predicción post entrenamiento : [[0.7287768]]\n",
      "PERDIDAAAA despues: 0.025856921449303627\n",
      "loss en el callback: 0.08019371330738068, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "ejemplar: [[0.69608706]\n",
      " [0.70007581]\n",
      " [0.70471627]\n",
      " [0.70863473]\n",
      " [0.71350604]\n",
      " [0.7182768 ]\n",
      " [0.72269601]\n",
      " [0.72759771]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.73262143]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[[0.69608706]\n",
      "  [0.70007581]\n",
      "  [0.70471627]\n",
      "  [0.70863473]\n",
      "  [0.71350604]\n",
      "  [0.7182768 ]\n",
      "  [0.72269601]\n",
      "  [0.72759771]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02023029886186123\n",
      "Predicción post entrenamiento : [[0.7331861]]\n",
      "PERDIDAAAA despues: 0.02006998099386692\n",
      "loss en el callback: 0.013486549258232117, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "ejemplar: [[0.70007581]\n",
      " [0.70471627]\n",
      " [0.70863473]\n",
      " [0.71350604]\n",
      " [0.7182768 ]\n",
      " [0.72269601]\n",
      " [0.72759771]\n",
      " [0.73262143]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.7368985]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[[0.70007581]\n",
      "  [0.70471627]\n",
      "  [0.70863473]\n",
      "  [0.71350604]\n",
      "  [0.7182768 ]\n",
      "  [0.72269601]\n",
      "  [0.72759771]\n",
      "  [0.73262143]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.031086435541510582\n",
      "Predicción post entrenamiento : [[0.7377042]]\n",
      "PERDIDAAAA despues: 0.030802961438894272\n",
      "loss en el callback: 0.028041481971740723, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "ejemplar: [[0.70471627]\n",
      " [0.70863473]\n",
      " [0.71350604]\n",
      " [0.7182768 ]\n",
      " [0.72269601]\n",
      " [0.72759771]\n",
      " [0.73262143]\n",
      " [0.73689848]]\n",
      "ejemplar: (8, 1)\n",
      "y: 1.0\n",
      "Predicción : [[0.7415617]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[[0.70471627]\n",
      "  [0.70863473]\n",
      "  [0.71350604]\n",
      "  [0.7182768 ]\n",
      "  [0.72269601]\n",
      "  [0.72759771]\n",
      "  [0.73262143]\n",
      "  [0.73689848]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06679034978151321\n",
      "Predicción post entrenamiento : [[0.7431716]]\n",
      "PERDIDAAAA despues: 0.0659608393907547\n",
      "loss en el callback: 0.1883470118045807, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "ejemplar: [[0.70863473]\n",
      " [0.71350604]\n",
      " [0.7182768 ]\n",
      " [0.72269601]\n",
      " [0.72759771]\n",
      " [0.73262143]\n",
      " [0.73689848]\n",
      " [0.74156171]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.74702525]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[[0.70863473]\n",
      "  [0.71350604]\n",
      "  [0.7182768 ]\n",
      "  [0.72269601]\n",
      "  [0.72759771]\n",
      "  [0.73262143]\n",
      "  [0.73689848]\n",
      "  [0.74156171]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04996512457728386\n",
      "Predicción post entrenamiento : [[0.7480565]]\n",
      "PERDIDAAAA despues: 0.04950517416000366\n",
      "loss en el callback: 0.045736853033304214, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "ejemplar: [[0.71350604]\n",
      " [0.7182768 ]\n",
      " [0.72269601]\n",
      " [0.72759771]\n",
      " [0.73262143]\n",
      " [0.73689848]\n",
      " [0.74156171]\n",
      " [0.74702525]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.7521109]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[[0.71350604]\n",
      "  [0.7182768 ]\n",
      "  [0.72269601]\n",
      "  [0.72759771]\n",
      "  [0.73262143]\n",
      "  [0.73689848]\n",
      "  [0.74156171]\n",
      "  [0.74702525]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018684666603803635\n",
      "Predicción post entrenamiento : [[0.7529634]]\n",
      "PERDIDAAAA despues: 0.018452327698469162\n",
      "loss en el callback: 0.03831290453672409, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "ejemplar: [[0.7182768 ]\n",
      " [0.72269601]\n",
      " [0.72759771]\n",
      " [0.73262143]\n",
      " [0.73689848]\n",
      " [0.74156171]\n",
      " [0.74702525]\n",
      " [0.7521109 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.75699097]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[[0.7182768 ]\n",
      "  [0.72269601]\n",
      "  [0.72759771]\n",
      "  [0.73262143]\n",
      "  [0.73689848]\n",
      "  [0.74156171]\n",
      "  [0.74702525]\n",
      "  [0.7521109 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014632128179073334\n",
      "Predicción post entrenamiento : [[0.7581184]]\n",
      "PERDIDAAAA despues: 0.014360645785927773\n",
      "loss en el callback: 0.08110953867435455, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "ejemplar: [[0.72269601]\n",
      " [0.72759771]\n",
      " [0.73262143]\n",
      " [0.73689848]\n",
      " [0.74156171]\n",
      " [0.74702525]\n",
      " [0.7521109 ]\n",
      " [0.75699097]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.7621513]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[[0.72269601]\n",
      "  [0.72759771]\n",
      "  [0.73262143]\n",
      "  [0.73689848]\n",
      "  [0.74156171]\n",
      "  [0.74702525]\n",
      "  [0.7521109 ]\n",
      "  [0.75699097]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007524606306105852\n",
      "Predicción post entrenamiento : [[0.7625298]]\n",
      "PERDIDAAAA despues: 0.007459085434675217\n",
      "loss en el callback: 0.006805243901908398, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "ejemplar: [[0.72759771]\n",
      " [0.73262143]\n",
      " [0.73689848]\n",
      " [0.74156171]\n",
      " [0.74702525]\n",
      " [0.7521109 ]\n",
      " [0.75699097]\n",
      " [0.7621513 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.7666741]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[[0.72759771]\n",
      "  [0.73262143]\n",
      "  [0.73689848]\n",
      "  [0.74156171]\n",
      "  [0.74702525]\n",
      "  [0.7521109 ]\n",
      "  [0.75699097]\n",
      "  [0.7621513 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004556072410196066\n",
      "Predicción post entrenamiento : [[0.76713157]]\n",
      "PERDIDAAAA despues: 0.004494525026530027\n",
      "loss en el callback: 0.010942883789539337, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "ejemplar: [[0.73262143]\n",
      " [0.73689848]\n",
      " [0.74156171]\n",
      " [0.74702525]\n",
      " [0.7521109 ]\n",
      " [0.75699097]\n",
      " [0.7621513 ]\n",
      " [0.7666741 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.77127546]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[[0.73262143]\n",
      "  [0.73689848]\n",
      "  [0.74156171]\n",
      "  [0.74702525]\n",
      "  [0.7521109 ]\n",
      "  [0.75699097]\n",
      "  [0.7621513 ]\n",
      "  [0.7666741 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0070257000625133514\n",
      "Predicción post entrenamiento : [[0.77195174]]\n",
      "PERDIDAAAA despues: 0.0069127874448895454\n",
      "loss en el callback: 0.025550993159413338, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "ejemplar: [[0.73689848]\n",
      " [0.74156171]\n",
      " [0.74702525]\n",
      " [0.7521109 ]\n",
      " [0.75699097]\n",
      " [0.7621513 ]\n",
      " [0.7666741 ]\n",
      " [0.77127546]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.7760645]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[[0.73689848]\n",
      "  [0.74156171]\n",
      "  [0.74702525]\n",
      "  [0.7521109 ]\n",
      "  [0.75699097]\n",
      "  [0.7621513 ]\n",
      "  [0.7666741 ]\n",
      "  [0.77127546]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009836208075284958\n",
      "Predicción post entrenamiento : [[0.77683234]]\n",
      "PERDIDAAAA despues: 0.009684494696557522\n",
      "loss en el callback: 0.038092996925115585, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "ejemplar: [[0.74156171]\n",
      " [0.74702525]\n",
      " [0.7521109 ]\n",
      " [0.75699097]\n",
      " [0.7621513 ]\n",
      " [0.7666741 ]\n",
      " [0.77127546]\n",
      " [0.77606452]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.78111553]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[[0.74156171]\n",
      "  [0.74702525]\n",
      "  [0.7521109 ]\n",
      "  [0.75699097]\n",
      "  [0.7621513 ]\n",
      "  [0.7666741 ]\n",
      "  [0.77127546]\n",
      "  [0.77606452]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005763337481766939\n",
      "Predicción post entrenamiento : [[0.7813886]]\n",
      "PERDIDAAAA despues: 0.0057219541631639\n",
      "loss en el callback: 0.0035316559951752424, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "ejemplar: [[0.74702525]\n",
      " [0.7521109 ]\n",
      " [0.75699097]\n",
      " [0.7621513 ]\n",
      " [0.7666741 ]\n",
      " [0.77127546]\n",
      " [0.77606452]\n",
      " [0.78111553]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.78575146]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[[0.74702525]\n",
      "  [0.7521109 ]\n",
      "  [0.75699097]\n",
      "  [0.7621513 ]\n",
      "  [0.7666741 ]\n",
      "  [0.77127546]\n",
      "  [0.77606452]\n",
      "  [0.78111553]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004135348834097385\n",
      "Predicción post entrenamiento : [[0.7861965]]\n",
      "PERDIDAAAA despues: 0.004078312776982784\n",
      "loss en el callback: 0.01105546671897173, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "ejemplar: [[0.7521109 ]\n",
      " [0.75699097]\n",
      " [0.7621513 ]\n",
      " [0.7666741 ]\n",
      " [0.77127546]\n",
      " [0.77606452]\n",
      " [0.78111553]\n",
      " [0.78575146]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.7904177]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[[0.7521109 ]\n",
      "  [0.75699097]\n",
      "  [0.7621513 ]\n",
      "  [0.7666741 ]\n",
      "  [0.77127546]\n",
      "  [0.77606452]\n",
      "  [0.78111553]\n",
      "  [0.78575146]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0027330871671438217\n",
      "Predicción post entrenamiento : [[0.79049945]]\n",
      "PERDIDAAAA despues: 0.002724543446674943\n",
      "loss en el callback: 0.00030806497670710087, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "ejemplar: [[0.75699097]\n",
      " [0.7621513 ]\n",
      " [0.7666741 ]\n",
      " [0.77127546]\n",
      " [0.77606452]\n",
      " [0.78111553]\n",
      " [0.78575146]\n",
      " [0.79041767]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.7946549]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[[0.75699097]\n",
      "  [0.7621513 ]\n",
      "  [0.7666741 ]\n",
      "  [0.77127546]\n",
      "  [0.77606452]\n",
      "  [0.78111553]\n",
      "  [0.78575146]\n",
      "  [0.79041767]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007998673827387393\n",
      "Predicción post entrenamiento : [[0.7946076]]\n",
      "PERDIDAAAA despues: 0.0008025465649552643\n",
      "loss en el callback: 0.00011133063526358455, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "ejemplar: [[0.7621513 ]\n",
      " [0.7666741 ]\n",
      " [0.77127546]\n",
      " [0.77606452]\n",
      " [0.78111553]\n",
      " [0.78575146]\n",
      " [0.79041767]\n",
      " [0.79465491]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.798738]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[[0.7621513 ]\n",
      "  [0.7666741 ]\n",
      "  [0.77127546]\n",
      "  [0.77606452]\n",
      "  [0.78111553]\n",
      "  [0.78575146]\n",
      "  [0.79041767]\n",
      "  [0.79465491]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005871884059160948\n",
      "Predicción post entrenamiento : [[0.7987565]]\n",
      "PERDIDAAAA despues: 0.000588084221817553\n",
      "loss en el callback: 1.8074575564241968e-05, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "ejemplar: [[0.7666741 ]\n",
      " [0.77127546]\n",
      " [0.77606452]\n",
      " [0.78111553]\n",
      " [0.78575146]\n",
      " [0.79041767]\n",
      " [0.79465491]\n",
      " [0.798738  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.8027709]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[[0.7666741 ]\n",
      "  [0.77127546]\n",
      "  [0.77606452]\n",
      "  [0.78111553]\n",
      "  [0.78575146]\n",
      "  [0.79041767]\n",
      "  [0.79465491]\n",
      "  [0.798738  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00034517061430960894\n",
      "Predicción post entrenamiento : [[0.8027461]]\n",
      "PERDIDAAAA despues: 0.0003442498855292797\n",
      "loss en el callback: 3.15871111524757e-05, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "ejemplar: [[0.77127546]\n",
      " [0.77606452]\n",
      " [0.78111553]\n",
      " [0.78575146]\n",
      " [0.79041767]\n",
      " [0.79465491]\n",
      " [0.798738  ]\n",
      " [0.80277091]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.8067936]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[[0.77127546]\n",
      "  [0.77606452]\n",
      "  [0.78111553]\n",
      "  [0.78575146]\n",
      "  [0.79041767]\n",
      "  [0.79465491]\n",
      "  [0.798738  ]\n",
      "  [0.80277091]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002803780836984515\n",
      "Predicción post entrenamiento : [[0.80726975]]\n",
      "PERDIDAAAA despues: 0.0027535792905837297\n",
      "loss en el callback: 0.013211707584559917, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "ejemplar: [[0.77606452]\n",
      " [0.78111553]\n",
      " [0.78575146]\n",
      " [0.79041767]\n",
      " [0.79465491]\n",
      " [0.798738  ]\n",
      " [0.80277091]\n",
      " [0.80679357]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.81131536]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[[0.77606452]\n",
      "  [0.78111553]\n",
      "  [0.78575146]\n",
      "  [0.79041767]\n",
      "  [0.79465491]\n",
      "  [0.798738  ]\n",
      "  [0.80277091]\n",
      "  [0.80679357]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018494034884497523\n",
      "Predicción post entrenamiento : [[0.81164795]]\n",
      "PERDIDAAAA despues: 0.0018209079280495644\n",
      "loss en el callback: 0.006225413642823696, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "ejemplar: [[0.78111553]\n",
      " [0.78575146]\n",
      " [0.79041767]\n",
      " [0.79465491]\n",
      " [0.798738  ]\n",
      " [0.80277091]\n",
      " [0.80679357]\n",
      " [0.81131536]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.8156194]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[[0.78111553]\n",
      "  [0.78575146]\n",
      "  [0.79041767]\n",
      "  [0.79465491]\n",
      "  [0.798738  ]\n",
      "  [0.80277091]\n",
      "  [0.80679357]\n",
      "  [0.81131536]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004522217786870897\n",
      "Predicción post entrenamiento : [[0.8161261]]\n",
      "PERDIDAAAA despues: 0.00043092810665257275\n",
      "loss en el callback: 0.0160969290882349, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "ejemplar: [[0.78575146]\n",
      " [0.79041767]\n",
      " [0.79465491]\n",
      " [0.798738  ]\n",
      " [0.80277091]\n",
      " [0.80679357]\n",
      " [0.81131536]\n",
      " [0.81561941]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.8199237]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[[0.78575146]\n",
      "  [0.79041767]\n",
      "  [0.79465491]\n",
      "  [0.798738  ]\n",
      "  [0.80277091]\n",
      "  [0.80679357]\n",
      "  [0.81131536]\n",
      "  [0.81561941]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 9.974367276299745e-05\n",
      "Predicción post entrenamiento : [[0.818834]]\n",
      "PERDIDAAAA despues: 0.00012269699072930962\n",
      "loss en el callback: 0.04199345037341118, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "ejemplar: [[0.79041767]\n",
      " [0.79465491]\n",
      " [0.798738  ]\n",
      " [0.80277091]\n",
      " [0.80679357]\n",
      " [0.81131536]\n",
      " [0.81561941]\n",
      " [0.8199237 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.82253736]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[[0.79041767]\n",
      "  [0.79465491]\n",
      "  [0.798738  ]\n",
      "  [0.80277091]\n",
      "  [0.80679357]\n",
      "  [0.81131536]\n",
      "  [0.81561941]\n",
      "  [0.8199237 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004188111983239651\n",
      "Predicción post entrenamiento : [[0.8230232]]\n",
      "PERDIDAAAA despues: 0.004125465638935566\n",
      "loss en el callback: 0.01376851461827755, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "ejemplar: [[0.79465491]\n",
      " [0.798738  ]\n",
      " [0.80277091]\n",
      " [0.80679357]\n",
      " [0.81131536]\n",
      " [0.81561941]\n",
      " [0.8199237 ]\n",
      " [0.82253736]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.82660264]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[[0.79465491]\n",
      "  [0.798738  ]\n",
      "  [0.80277091]\n",
      "  [0.80679357]\n",
      "  [0.81131536]\n",
      "  [0.81561941]\n",
      "  [0.8199237 ]\n",
      "  [0.82253736]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001098370412364602\n",
      "Predicción post entrenamiento : [[0.82692945]]\n",
      "PERDIDAAAA despues: 0.0010768150677904487\n",
      "loss en el callback: 0.006088716443628073, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "ejemplar: [[0.798738  ]\n",
      " [0.80277091]\n",
      " [0.80679357]\n",
      " [0.81131536]\n",
      " [0.81561941]\n",
      " [0.8199237 ]\n",
      " [0.82253736]\n",
      " [0.82660264]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.83047676]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[[0.798738  ]\n",
      "  [0.80277091]\n",
      "  [0.80679357]\n",
      "  [0.81131536]\n",
      "  [0.81561941]\n",
      "  [0.8199237 ]\n",
      "  [0.82253736]\n",
      "  [0.82660264]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.31796060083434e-05\n",
      "Predicción post entrenamiento : [[0.83075374]]\n",
      "PERDIDAAAA despues: 7.820400060154498e-05\n",
      "loss en el callback: 0.004488085862249136, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "ejemplar: [[0.80277091]\n",
      " [0.80679357]\n",
      " [0.81131536]\n",
      " [0.81561941]\n",
      " [0.8199237 ]\n",
      " [0.82253736]\n",
      " [0.82660264]\n",
      " [0.83047676]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.83429694]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[[0.80277091]\n",
      "  [0.80679357]\n",
      "  [0.81131536]\n",
      "  [0.81561941]\n",
      "  [0.8199237 ]\n",
      "  [0.82253736]\n",
      "  [0.82660264]\n",
      "  [0.83047676]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0025494650471955538\n",
      "Predicción post entrenamiento : [[0.8338442]]\n",
      "PERDIDAAAA despues: 0.0025039485190063715\n",
      "loss en el callback: 0.010218262672424316, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "ejemplar: [[0.80679357]\n",
      " [0.81131536]\n",
      " [0.81561941]\n",
      " [0.8199237 ]\n",
      " [0.82253736]\n",
      " [0.82660264]\n",
      " [0.83047676]\n",
      " [0.83429694]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.83738273]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[[0.80679357]\n",
      "  [0.81131536]\n",
      "  [0.81561941]\n",
      "  [0.8199237 ]\n",
      "  [0.82253736]\n",
      "  [0.82660264]\n",
      "  [0.83047676]\n",
      "  [0.83429694]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003646282711997628\n",
      "Predicción post entrenamiento : [[0.8366136]]\n",
      "PERDIDAAAA despues: 0.0003358460671734065\n",
      "loss en el callback: 0.02584371529519558, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "ejemplar: [[0.81131536]\n",
      " [0.81561941]\n",
      " [0.8199237 ]\n",
      " [0.82253736]\n",
      " [0.82660264]\n",
      " [0.83047676]\n",
      " [0.83429694]\n",
      " [0.83738273]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.8401302]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[[0.81131536]\n",
      "  [0.81561941]\n",
      "  [0.8199237 ]\n",
      "  [0.82253736]\n",
      "  [0.82660264]\n",
      "  [0.83047676]\n",
      "  [0.83429694]\n",
      "  [0.83738273]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0023974755313247442\n",
      "Predicción post entrenamiento : [[0.8394359]]\n",
      "PERDIDAAAA despues: 0.00232996279373765\n",
      "loss en el callback: 0.02357521280646324, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "ejemplar: [[0.81561941]\n",
      " [0.8199237 ]\n",
      " [0.82253736]\n",
      " [0.82660264]\n",
      " [0.83047676]\n",
      " [0.83429694]\n",
      " [0.83738273]\n",
      " [0.84013021]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.842765]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[[0.81561941]\n",
      "  [0.8199237 ]\n",
      "  [0.82253736]\n",
      "  [0.82660264]\n",
      "  [0.83047676]\n",
      "  [0.83429694]\n",
      "  [0.83738273]\n",
      "  [0.84013021]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006757994648069143\n",
      "Predicción post entrenamiento : [[0.8424281]]\n",
      "PERDIDAAAA despues: 0.00670271972194314\n",
      "loss en el callback: 0.006229299120604992, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "ejemplar: [[0.8199237 ]\n",
      " [0.82253736]\n",
      " [0.82660264]\n",
      " [0.83047676]\n",
      " [0.83429694]\n",
      " [0.83738273]\n",
      " [0.84013021]\n",
      " [0.84276497]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.8455804]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[[0.8199237 ]\n",
      "  [0.82253736]\n",
      "  [0.82660264]\n",
      "  [0.83047676]\n",
      "  [0.83429694]\n",
      "  [0.83738273]\n",
      "  [0.84013021]\n",
      "  [0.84276497]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029188867192715406\n",
      "Predicción post entrenamiento : [[0.84510624]]\n",
      "PERDIDAAAA despues: 0.00286787748336792\n",
      "loss en el callback: 0.011982182040810585, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "ejemplar: [[0.82253736]\n",
      " [0.82660264]\n",
      " [0.83047676]\n",
      " [0.83429694]\n",
      " [0.83738273]\n",
      " [0.84013021]\n",
      " [0.84276497]\n",
      " [0.8455804 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.84803504]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[[0.82253736]\n",
      "  [0.82660264]\n",
      "  [0.83047676]\n",
      "  [0.83429694]\n",
      "  [0.83738273]\n",
      "  [0.84013021]\n",
      "  [0.84276497]\n",
      "  [0.8455804 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006294955499470234\n",
      "Predicción post entrenamiento : [[0.8477521]]\n",
      "PERDIDAAAA despues: 0.0062501379288733006\n",
      "loss en el callback: 0.004456802736967802, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "ejemplar: [[0.82660264]\n",
      " [0.83047676]\n",
      " [0.83429694]\n",
      " [0.83738273]\n",
      " [0.84013021]\n",
      " [0.84276497]\n",
      " [0.8455804 ]\n",
      " [0.84803504]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.8508732]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[[0.82660264]\n",
      "  [0.83047676]\n",
      "  [0.83429694]\n",
      "  [0.83738273]\n",
      "  [0.84013021]\n",
      "  [0.84276497]\n",
      "  [0.8455804 ]\n",
      "  [0.84803504]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00675337016582489\n",
      "Predicción post entrenamiento : [[0.85118353]]\n",
      "PERDIDAAAA despues: 0.0068044764921069145\n",
      "loss en el callback: 0.008149875327944756, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "ejemplar: [[0.83047676]\n",
      " [0.83429694]\n",
      " [0.83738273]\n",
      " [0.84013021]\n",
      " [0.84276497]\n",
      " [0.8455804 ]\n",
      " [0.84803504]\n",
      " [0.85087317]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.8540868]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[[0.83047676]\n",
      "  [0.83429694]\n",
      "  [0.83738273]\n",
      "  [0.84013021]\n",
      "  [0.84276497]\n",
      "  [0.8455804 ]\n",
      "  [0.84803504]\n",
      "  [0.85087317]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00304391304962337\n",
      "Predicción post entrenamiento : [[0.8540084]]\n",
      "PERDIDAAAA despues: 0.0030352638568729162\n",
      "loss en el callback: 0.0003889402432832867, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "ejemplar: [[0.83429694]\n",
      " [0.83738273]\n",
      " [0.84013021]\n",
      " [0.84276497]\n",
      " [0.8455804 ]\n",
      " [0.84803504]\n",
      " [0.85087317]\n",
      " [0.85408682]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.85669076]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[[0.83429694]\n",
      "  [0.83738273]\n",
      "  [0.84013021]\n",
      "  [0.84276497]\n",
      "  [0.8455804 ]\n",
      "  [0.84803504]\n",
      "  [0.85087317]\n",
      "  [0.85408682]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004447138402611017\n",
      "Predicción post entrenamiento : [[0.85623074]]\n",
      "PERDIDAAAA despues: 0.004385994281619787\n",
      "loss en el callback: 0.011950911022722721, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "ejemplar: [[0.83738273]\n",
      " [0.84013021]\n",
      " [0.84276497]\n",
      " [0.8455804 ]\n",
      " [0.84803504]\n",
      " [0.85087317]\n",
      " [0.85408682]\n",
      " [0.85669076]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.85866106]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[[0.83738273]\n",
      "  [0.84013021]\n",
      "  [0.84276497]\n",
      "  [0.8455804 ]\n",
      "  [0.84803504]\n",
      "  [0.85087317]\n",
      "  [0.85408682]\n",
      "  [0.85669076]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009700397029519081\n",
      "Predicción post entrenamiento : [[0.8577478]]\n",
      "PERDIDAAAA despues: 0.009521336294710636\n",
      "loss en el callback: 0.04092765972018242, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "ejemplar: [[0.84013021]\n",
      " [0.84276497]\n",
      " [0.8455804 ]\n",
      " [0.84803504]\n",
      " [0.85087317]\n",
      " [0.85408682]\n",
      " [0.85669076]\n",
      " [0.85866106]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.8600894]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[[0.84013021]\n",
      "  [0.84276497]\n",
      "  [0.8455804 ]\n",
      "  [0.84803504]\n",
      "  [0.85087317]\n",
      "  [0.85408682]\n",
      "  [0.85669076]\n",
      "  [0.85866106]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03051874414086342\n",
      "Predicción post entrenamiento : [[0.8593964]]\n",
      "PERDIDAAAA despues: 0.030277086421847343\n",
      "loss en el callback: 0.028412001207470894, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "ejemplar: [[0.84276497]\n",
      " [0.8455804 ]\n",
      " [0.84803504]\n",
      " [0.85087317]\n",
      " [0.85408682]\n",
      " [0.85669076]\n",
      " [0.85866106]\n",
      " [0.86008942]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.8617205]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[[0.84276497]\n",
      "  [0.8455804 ]\n",
      "  [0.84803504]\n",
      "  [0.85087317]\n",
      "  [0.85408682]\n",
      "  [0.85669076]\n",
      "  [0.85866106]\n",
      "  [0.86008942]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06580699235200882\n",
      "Predicción post entrenamiento : [[0.86074257]]\n",
      "PERDIDAAAA despues: 0.06530620902776718\n",
      "loss en el callback: 0.05990557745099068, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "ejemplar: [[0.8455804 ]\n",
      " [0.84803504]\n",
      " [0.85087317]\n",
      " [0.85408682]\n",
      " [0.85669076]\n",
      " [0.85866106]\n",
      " [0.86008942]\n",
      " [0.8617205 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.8630587]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[[0.8455804 ]\n",
      "  [0.84803504]\n",
      "  [0.85087317]\n",
      "  [0.85408682]\n",
      "  [0.85669076]\n",
      "  [0.85866106]\n",
      "  [0.86008942]\n",
      "  [0.8617205 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.039283283054828644\n",
      "Predicción post entrenamiento : [[0.8622422]]\n",
      "PERDIDAAAA despues: 0.038960300385951996\n",
      "loss en el callback: 0.04028046131134033, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "ejemplar: [[0.84803504]\n",
      " [0.85087317]\n",
      " [0.85408682]\n",
      " [0.85669076]\n",
      " [0.85866106]\n",
      " [0.86008942]\n",
      " [0.8617205 ]\n",
      " [0.86305869]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.8644699]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[[0.84803504]\n",
      "  [0.85087317]\n",
      "  [0.85408682]\n",
      "  [0.85669076]\n",
      "  [0.85866106]\n",
      "  [0.86008942]\n",
      "  [0.8617205 ]\n",
      "  [0.86305869]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.024525035172700882\n",
      "Predicción post entrenamiento : [[0.8635203]]\n",
      "PERDIDAAAA despues: 0.024228524416685104\n",
      "loss en el callback: 0.05095721036195755, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "ejemplar: [[0.85087317]\n",
      " [0.85408682]\n",
      " [0.85669076]\n",
      " [0.85866106]\n",
      " [0.86008942]\n",
      " [0.8617205 ]\n",
      " [0.86305869]\n",
      " [0.86446989]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.8657103]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[[0.85087317]\n",
      "  [0.85408682]\n",
      "  [0.85669076]\n",
      "  [0.85866106]\n",
      "  [0.86008942]\n",
      "  [0.8617205 ]\n",
      "  [0.86305869]\n",
      "  [0.86446989]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04034142196178436\n",
      "Predicción post entrenamiento : [[0.8656013]]\n",
      "PERDIDAAAA despues: 0.04029763862490654\n",
      "loss en el callback: 0.0010474639711901546, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "ejemplar: [[0.85408682]\n",
      " [0.85669076]\n",
      " [0.85866106]\n",
      " [0.86008942]\n",
      " [0.8617205 ]\n",
      " [0.86305869]\n",
      " [0.86446989]\n",
      " [0.86571032]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.8675992]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[[0.85408682]\n",
      "  [0.85669076]\n",
      "  [0.85866106]\n",
      "  [0.86008942]\n",
      "  [0.8617205 ]\n",
      "  [0.86305869]\n",
      "  [0.86446989]\n",
      "  [0.86571032]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.024413131177425385\n",
      "Predicción post entrenamiento : [[0.86729604]]\n",
      "PERDIDAAAA despues: 0.02431849017739296\n",
      "loss en el callback: 0.006648021284490824, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "ejemplar: [[0.85669076]\n",
      " [0.85866106]\n",
      " [0.86008942]\n",
      " [0.8617205 ]\n",
      " [0.86305869]\n",
      " [0.86446989]\n",
      " [0.86571032]\n",
      " [0.86759919]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.8689359]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[[0.85669076]\n",
      "  [0.85866106]\n",
      "  [0.86008942]\n",
      "  [0.8617205 ]\n",
      "  [0.86305869]\n",
      "  [0.86446989]\n",
      "  [0.86571032]\n",
      "  [0.86759919]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03674083948135376\n",
      "Predicción post entrenamiento : [[0.8687031]]\n",
      "PERDIDAAAA despues: 0.03665166348218918\n",
      "loss en el callback: 0.004376762080937624, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "ejemplar: [[0.85866106]\n",
      " [0.86008942]\n",
      " [0.8617205 ]\n",
      " [0.86305869]\n",
      " [0.86446989]\n",
      " [0.86571032]\n",
      " [0.86759919]\n",
      " [0.86893588]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.8700849]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[[0.85866106]\n",
      "  [0.86008942]\n",
      "  [0.8617205 ]\n",
      "  [0.86305869]\n",
      "  [0.86446989]\n",
      "  [0.86571032]\n",
      "  [0.86759919]\n",
      "  [0.86893588]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011659065261483192\n",
      "Predicción post entrenamiento : [[0.8691908]]\n",
      "PERDIDAAAA despues: 0.01146678626537323\n",
      "loss en el callback: 0.0461360439658165, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "ejemplar: [[0.86008942]\n",
      " [0.8617205 ]\n",
      " [0.86305869]\n",
      " [0.86446989]\n",
      " [0.86571032]\n",
      " [0.86759919]\n",
      " [0.86893588]\n",
      " [0.87008488]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.87044674]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[[0.86008942]\n",
      "  [0.8617205 ]\n",
      "  [0.86305869]\n",
      "  [0.86446989]\n",
      "  [0.86571032]\n",
      "  [0.86759919]\n",
      "  [0.86893588]\n",
      "  [0.87008488]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004018951673060656\n",
      "Predicción post entrenamiento : [[0.86999786]]\n",
      "PERDIDAAAA despues: 0.003962239250540733\n",
      "loss en el callback: 0.012166183441877365, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "ejemplar: [[0.8617205 ]\n",
      " [0.86305869]\n",
      " [0.86446989]\n",
      " [0.86571032]\n",
      " [0.86759919]\n",
      " [0.86893588]\n",
      " [0.87008488]\n",
      " [0.87044674]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.8712525]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[[0.8617205 ]\n",
      "  [0.86305869]\n",
      "  [0.86446989]\n",
      "  [0.86571032]\n",
      "  [0.86759919]\n",
      "  [0.86893588]\n",
      "  [0.87008488]\n",
      "  [0.87044674]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003143233247101307\n",
      "Predicción post entrenamiento : [[0.87170833]]\n",
      "PERDIDAAAA despues: 0.0031945558730512857\n",
      "loss en el callback: 0.02219197526574135, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "ejemplar: [[0.86305869]\n",
      " [0.86446989]\n",
      " [0.86571032]\n",
      " [0.86759919]\n",
      " [0.86893588]\n",
      " [0.87008488]\n",
      " [0.87044674]\n",
      " [0.87125248]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.87289214]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[[0.86305869]\n",
      "  [0.86446989]\n",
      "  [0.86571032]\n",
      "  [0.86759919]\n",
      "  [0.86893588]\n",
      "  [0.87008488]\n",
      "  [0.87044674]\n",
      "  [0.87125248]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011119396658614278\n",
      "Predicción post entrenamiento : [[0.8726744]]\n",
      "PERDIDAAAA despues: 0.0011265082284808159\n",
      "loss en el callback: 0.0029195824172347784, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "ejemplar: [[0.86446989]\n",
      " [0.86571032]\n",
      " [0.86759919]\n",
      " [0.86893588]\n",
      " [0.87008488]\n",
      " [0.87044674]\n",
      " [0.87125248]\n",
      " [0.87289214]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.8738468]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[[0.86446989]\n",
      "  [0.86571032]\n",
      "  [0.86759919]\n",
      "  [0.86893588]\n",
      "  [0.87008488]\n",
      "  [0.87044674]\n",
      "  [0.87125248]\n",
      "  [0.87289214]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007371716666966677\n",
      "Predicción post entrenamiento : [[0.8744506]]\n",
      "PERDIDAAAA despues: 0.007268399465829134\n",
      "loss en el callback: 0.030579209327697754, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "ejemplar: [[0.86571032]\n",
      " [0.86759919]\n",
      " [0.86893588]\n",
      " [0.87008488]\n",
      " [0.87044674]\n",
      " [0.87125248]\n",
      " [0.87289214]\n",
      " [0.87384683]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.8755765]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[[0.86571032]\n",
      "  [0.86759919]\n",
      "  [0.86893588]\n",
      "  [0.87008488]\n",
      "  [0.87044674]\n",
      "  [0.87125248]\n",
      "  [0.87289214]\n",
      "  [0.87384683]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00788160040974617\n",
      "Predicción post entrenamiento : [[0.876014]]\n",
      "PERDIDAAAA despues: 0.007804110646247864\n",
      "loss en el callback: 0.013698859140276909, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "ejemplar: [[0.86759919]\n",
      " [0.86893588]\n",
      " [0.87008488]\n",
      " [0.87044674]\n",
      " [0.87125248]\n",
      " [0.87289214]\n",
      " [0.87384683]\n",
      " [0.8755765 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.8771256]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[[0.86759919]\n",
      "  [0.86893588]\n",
      "  [0.87008488]\n",
      "  [0.87044674]\n",
      "  [0.87125248]\n",
      "  [0.87289214]\n",
      "  [0.87384683]\n",
      "  [0.8755765 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00011885983258252963\n",
      "Predicción post entrenamiento : [[0.87635773]]\n",
      "PERDIDAAAA despues: 0.00013619291712529957\n",
      "loss en el callback: 0.030587902292609215, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "ejemplar: [[0.86893588]\n",
      " [0.87008488]\n",
      " [0.87044674]\n",
      " [0.87125248]\n",
      " [0.87289214]\n",
      " [0.87384683]\n",
      " [0.8755765 ]\n",
      " [0.87712562]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.87726957]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[[0.86893588]\n",
      "  [0.87008488]\n",
      "  [0.87044674]\n",
      "  [0.87125248]\n",
      "  [0.87289214]\n",
      "  [0.87384683]\n",
      "  [0.8755765 ]\n",
      "  [0.87712562]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00023739664175081998\n",
      "Predicción post entrenamiento : [[0.8771735]]\n",
      "PERDIDAAAA despues: 0.00024036670220084488\n",
      "loss en el callback: 0.000627489760518074, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "ejemplar: [[0.87008488]\n",
      " [0.87044674]\n",
      " [0.87125248]\n",
      " [0.87289214]\n",
      " [0.87384683]\n",
      " [0.8755765 ]\n",
      " [0.87712562]\n",
      " [0.87726957]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.87801594]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[[0.87008488]\n",
      "  [0.87044674]\n",
      "  [0.87125248]\n",
      "  [0.87289214]\n",
      "  [0.87384683]\n",
      "  [0.8755765 ]\n",
      "  [0.87712562]\n",
      "  [0.87726957]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.69375401432626e-06\n",
      "Predicción post entrenamiento : [[0.87765825]]\n",
      "PERDIDAAAA despues: 5.837414846610045e-06\n",
      "loss en el callback: 0.007533305324614048, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "ejemplar: [[0.87044674]\n",
      " [0.87125248]\n",
      " [0.87289214]\n",
      " [0.87384683]\n",
      " [0.8755765 ]\n",
      " [0.87712562]\n",
      " [0.87726957]\n",
      " [0.87801594]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.87847984]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[[0.87044674]\n",
      "  [0.87125248]\n",
      "  [0.87289214]\n",
      "  [0.87384683]\n",
      "  [0.8755765 ]\n",
      "  [0.87712562]\n",
      "  [0.87726957]\n",
      "  [0.87801594]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007643477292731404\n",
      "Predicción post entrenamiento : [[0.87870795]]\n",
      "PERDIDAAAA despues: 0.0007770126685500145\n",
      "loss en el callback: 0.0048338668420910835, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "ejemplar: [[0.87125248]\n",
      " [0.87289214]\n",
      " [0.87384683]\n",
      " [0.8755765 ]\n",
      " [0.87712562]\n",
      " [0.87726957]\n",
      " [0.87801594]\n",
      " [0.87847984]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.8797239]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[[0.87125248]\n",
      "  [0.87289214]\n",
      "  [0.87384683]\n",
      "  [0.8755765 ]\n",
      "  [0.87712562]\n",
      "  [0.87726957]\n",
      "  [0.87801594]\n",
      "  [0.87847984]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00095037289429456\n",
      "Predicción post entrenamiento : [[0.88004744]]\n",
      "PERDIDAAAA despues: 0.0009704254334792495\n",
      "loss en el callback: 0.010898596607148647, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "ejemplar: [[0.87289214]\n",
      " [0.87384683]\n",
      " [0.8755765 ]\n",
      " [0.87712562]\n",
      " [0.87726957]\n",
      " [0.87801594]\n",
      " [0.87847984]\n",
      " [0.87972391]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.8811495]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[[0.87289214]\n",
      "  [0.87384683]\n",
      "  [0.8755765 ]\n",
      "  [0.87712562]\n",
      "  [0.87726957]\n",
      "  [0.87801594]\n",
      "  [0.87847984]\n",
      "  [0.87972391]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0066045187413692474\n",
      "Predicción post entrenamiento : [[0.8812437]]\n",
      "PERDIDAAAA despues: 0.00658921105787158\n",
      "loss en el callback: 0.0005986716132611036, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "ejemplar: [[0.87384683]\n",
      " [0.8755765 ]\n",
      " [0.87712562]\n",
      " [0.87726957]\n",
      " [0.87801594]\n",
      " [0.87847984]\n",
      " [0.87972391]\n",
      " [0.88114947]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.88219583]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[[0.87384683]\n",
      "  [0.8755765 ]\n",
      "  [0.87712562]\n",
      "  [0.87726957]\n",
      "  [0.87801594]\n",
      "  [0.87847984]\n",
      "  [0.87972391]\n",
      "  [0.88114947]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007335253059864044\n",
      "Predicción post entrenamiento : [[0.8827129]]\n",
      "PERDIDAAAA despues: 0.007246950641274452\n",
      "loss en el callback: 0.020876793190836906, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "ejemplar: [[0.8755765 ]\n",
      " [0.87712562]\n",
      " [0.87726957]\n",
      " [0.87801594]\n",
      " [0.87847984]\n",
      " [0.87972391]\n",
      " [0.88114947]\n",
      " [0.88219583]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.8836764]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[[0.8755765 ]\n",
      "  [0.87712562]\n",
      "  [0.87726957]\n",
      "  [0.87801594]\n",
      "  [0.87847984]\n",
      "  [0.87972391]\n",
      "  [0.88114947]\n",
      "  [0.88219583]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003254048526287079\n",
      "Predicción post entrenamiento : [[0.8835722]]\n",
      "PERDIDAAAA despues: 0.0032659461721777916\n",
      "loss en el callback: 0.0006907535716891289, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "ejemplar: [[0.87712562]\n",
      " [0.87726957]\n",
      " [0.87801594]\n",
      " [0.87847984]\n",
      " [0.87972391]\n",
      " [0.88114947]\n",
      " [0.88219583]\n",
      " [0.88367641]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.88433063]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[[0.87712562]\n",
      "  [0.87726957]\n",
      "  [0.87801594]\n",
      "  [0.87847984]\n",
      "  [0.87972391]\n",
      "  [0.88114947]\n",
      "  [0.88219583]\n",
      "  [0.88367641]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007772297598421574\n",
      "Predicción post entrenamiento : [[0.8846716]]\n",
      "PERDIDAAAA despues: 0.007712288293987513\n",
      "loss en el callback: 0.009775390848517418, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "ejemplar: [[0.87726957]\n",
      " [0.87801594]\n",
      " [0.87847984]\n",
      " [0.87972391]\n",
      " [0.88114947]\n",
      " [0.88219583]\n",
      " [0.88367641]\n",
      " [0.88433063]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.8852561]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[[0.87726957]\n",
      "  [0.87801594]\n",
      "  [0.87847984]\n",
      "  [0.87972391]\n",
      "  [0.88114947]\n",
      "  [0.88219583]\n",
      "  [0.88367641]\n",
      "  [0.88433063]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012464456260204315\n",
      "Predicción post entrenamiento : [[0.8857963]]\n",
      "PERDIDAAAA despues: 0.012344127520918846\n",
      "loss en el callback: 0.024097977206110954, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "ejemplar: [[0.87801594]\n",
      " [0.87847984]\n",
      " [0.87972391]\n",
      " [0.88114947]\n",
      " [0.88219583]\n",
      " [0.88367641]\n",
      " [0.88433063]\n",
      " [0.88525611]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.88659036]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[[0.87801594]\n",
      "  [0.87847984]\n",
      "  [0.87972391]\n",
      "  [0.88114947]\n",
      "  [0.88219583]\n",
      "  [0.88367641]\n",
      "  [0.88433063]\n",
      "  [0.88525611]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004172042477875948\n",
      "Predicción post entrenamiento : [[0.88666886]]\n",
      "PERDIDAAAA despues: 0.004161907825618982\n",
      "loss en el callback: 0.000409076688811183, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "ejemplar: [[0.87847984]\n",
      " [0.87972391]\n",
      " [0.88114947]\n",
      " [0.88219583]\n",
      " [0.88367641]\n",
      " [0.88433063]\n",
      " [0.88525611]\n",
      " [0.88659036]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.887543]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[[0.87847984]\n",
      "  [0.87972391]\n",
      "  [0.88114947]\n",
      "  [0.88219583]\n",
      "  [0.88367641]\n",
      "  [0.88433063]\n",
      "  [0.88525611]\n",
      "  [0.88659036]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.779522664146498e-05\n",
      "Predicción post entrenamiento : [[0.88760173]]\n",
      "PERDIDAAAA despues: 6.683185347355902e-05\n",
      "loss en el callback: 0.0002504052536096424, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "ejemplar: [[0.87972391]\n",
      " [0.88114947]\n",
      " [0.88219583]\n",
      " [0.88367641]\n",
      " [0.88433063]\n",
      " [0.88525611]\n",
      " [0.88659036]\n",
      " [0.88754302]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.8886478]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[[0.87972391]\n",
      "  [0.88114947]\n",
      "  [0.88219583]\n",
      "  [0.88367641]\n",
      "  [0.88433063]\n",
      "  [0.88525611]\n",
      "  [0.88659036]\n",
      "  [0.88754302]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.19336354045663e-05\n",
      "Predicción post entrenamiento : [[0.8886794]]\n",
      "PERDIDAAAA despues: 5.2389947086339816e-05\n",
      "loss en el callback: 8.195557893486694e-05, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "ejemplar: [[0.88114947]\n",
      " [0.88219583]\n",
      " [0.88367641]\n",
      " [0.88433063]\n",
      " [0.88525611]\n",
      " [0.88659036]\n",
      " [0.88754302]\n",
      " [0.88864779]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.8896979]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[[0.88114947]\n",
      "  [0.88219583]\n",
      "  [0.88367641]\n",
      "  [0.88433063]\n",
      "  [0.88525611]\n",
      "  [0.88659036]\n",
      "  [0.88754302]\n",
      "  [0.88864779]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007501306245103478\n",
      "Predicción post entrenamiento : [[0.89010555]]\n",
      "PERDIDAAAA despues: 0.0007279677083715796\n",
      "loss en el callback: 0.016444485634565353, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "ejemplar: [[0.88219583]\n",
      " [0.88367641]\n",
      " [0.88433063]\n",
      " [0.88525611]\n",
      " [0.88659036]\n",
      " [0.88754302]\n",
      " [0.88864779]\n",
      " [0.88969791]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.8910371]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[[0.88219583]\n",
      "  [0.88367641]\n",
      "  [0.88433063]\n",
      "  [0.88525611]\n",
      "  [0.88659036]\n",
      "  [0.88754302]\n",
      "  [0.88864779]\n",
      "  [0.88969791]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008272207924164832\n",
      "Predicción post entrenamiento : [[0.8910831]]\n",
      "PERDIDAAAA despues: 0.0008245760109275579\n",
      "loss en el callback: 0.00016941898502409458, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "ejemplar: [[0.88367641]\n",
      " [0.88433063]\n",
      " [0.88525611]\n",
      " [0.88659036]\n",
      " [0.88754302]\n",
      " [0.88864779]\n",
      " [0.88969791]\n",
      " [0.89103711]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.8920207]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[[0.88367641]\n",
      "  [0.88433063]\n",
      "  [0.88525611]\n",
      "  [0.88659036]\n",
      "  [0.88754302]\n",
      "  [0.88864779]\n",
      "  [0.88969791]\n",
      "  [0.89103711]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004847236908972263\n",
      "Predicción post entrenamiento : [[0.892333]]\n",
      "PERDIDAAAA despues: 0.004803852643817663\n",
      "loss en el callback: 0.008443888276815414, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "ejemplar: [[0.88433063]\n",
      " [0.88525611]\n",
      " [0.88659036]\n",
      " [0.88754302]\n",
      " [0.88864779]\n",
      " [0.88969791]\n",
      " [0.89103711]\n",
      " [0.8920207 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.8931584]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[[0.88433063]\n",
      "  [0.88525611]\n",
      "  [0.88659036]\n",
      "  [0.88754302]\n",
      "  [0.88864779]\n",
      "  [0.88969791]\n",
      "  [0.89103711]\n",
      "  [0.8920207 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005635651759803295\n",
      "Predicción post entrenamiento : [[0.89402694]]\n",
      "PERDIDAAAA despues: 0.005505999084562063\n",
      "loss en el callback: 0.11796298623085022, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "ejemplar: [[0.88525611]\n",
      " [0.88659036]\n",
      " [0.88754302]\n",
      " [0.88864779]\n",
      " [0.88969791]\n",
      " [0.89103711]\n",
      " [0.8920207 ]\n",
      " [0.89315838]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.8949607]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[[0.88525611]\n",
      "  [0.88659036]\n",
      "  [0.88754302]\n",
      "  [0.88864779]\n",
      "  [0.88969791]\n",
      "  [0.89103711]\n",
      "  [0.8920207 ]\n",
      "  [0.89315838]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003944796975702047\n",
      "Predicción post entrenamiento : [[0.8946482]]\n",
      "PERDIDAAAA despues: 0.003984150476753712\n",
      "loss en el callback: 0.006298124324530363, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "ejemplar: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.24208659]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03840832784771919\n",
      "Predicción post entrenamiento : [[0.21506463]]\n",
      "PERDIDAAAA despues: 0.02854696474969387\n",
      "loss en el callback: 0.03291037678718567, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "ejemplar: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.24208659]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.19962439]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24208659]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009101392701268196\n",
      "Predicción post entrenamiento : [[0.1881314]]\n",
      "PERDIDAAAA despues: 0.00704059237614274\n",
      "loss en el callback: 0.0067674219608306885, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "ejemplar: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.24208659]\n",
      " [0.19962439]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.1923775]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24208659]\n",
      "  [0.19962439]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014572306536138058\n",
      "Predicción post entrenamiento : [[0.18856353]]\n",
      "PERDIDAAAA despues: 0.001180590596050024\n",
      "loss en el callback: 0.0013914760202169418, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "ejemplar: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.24208659]\n",
      " [0.19962439]\n",
      " [0.19237749]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.20032991]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24208659]\n",
      "  [0.19962439]\n",
      "  [0.19237749]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0019870493561029434\n",
      "Predicción post entrenamiento : [[0.19728555]]\n",
      "PERDIDAAAA despues: 0.0017249041702598333\n",
      "loss en el callback: 0.0015608255052939057, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "ejemplar: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.24208659]\n",
      " [0.19962439]\n",
      " [0.19237749]\n",
      " [0.20032991]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.21046707]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24208659]\n",
      "  [0.19962439]\n",
      "  [0.19237749]\n",
      "  [0.20032991]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007213839329779148\n",
      "Predicción post entrenamiento : [[0.20372559]]\n",
      "PERDIDAAAA despues: 0.006114121060818434\n",
      "loss en el callback: 0.009890878573060036, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "ejemplar: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.24208659]\n",
      " [0.19962439]\n",
      " [0.19237749]\n",
      " [0.20032991]\n",
      " [0.21046707]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.21452814]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24208659]\n",
      "  [0.19962439]\n",
      "  [0.19237749]\n",
      "  [0.20032991]\n",
      "  [0.21046707]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0047400714829564095\n",
      "Predicción post entrenamiento : [[0.21147224]]\n",
      "PERDIDAAAA despues: 0.004328623879700899\n",
      "loss en el callback: 0.0035556789953261614, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "ejemplar: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.24208659]\n",
      " [0.19962439]\n",
      " [0.19237749]\n",
      " [0.20032991]\n",
      " [0.21046707]\n",
      " [0.21452814]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.23353331]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24208659]\n",
      "  [0.19962439]\n",
      "  [0.19237749]\n",
      "  [0.20032991]\n",
      "  [0.21046707]\n",
      "  [0.21452814]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007582657039165497\n",
      "Predicción post entrenamiento : [[0.22979231]]\n",
      "PERDIDAAAA despues: 0.006945131346583366\n",
      "loss en el callback: 0.006798592861741781, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "ejemplar: [[0.04223169]\n",
      " [0.24208659]\n",
      " [0.19962439]\n",
      " [0.19237749]\n",
      " [0.20032991]\n",
      " [0.21046707]\n",
      " [0.21452814]\n",
      " [0.23353331]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.2565719]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[[0.04223169]\n",
      "  [0.24208659]\n",
      "  [0.19962439]\n",
      "  [0.19237749]\n",
      "  [0.20032991]\n",
      "  [0.21046707]\n",
      "  [0.21452814]\n",
      "  [0.23353331]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0036631368566304445\n",
      "Predicción post entrenamiento : [[0.25388822]]\n",
      "PERDIDAAAA despues: 0.003345486707985401\n",
      "loss en el callback: 0.004112014081329107, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "ejemplar: [[0.24208659]\n",
      " [0.19962439]\n",
      " [0.19237749]\n",
      " [0.20032991]\n",
      " [0.21046707]\n",
      " [0.21452814]\n",
      " [0.23353331]\n",
      " [0.25657189]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.28569666]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[[0.24208659]\n",
      "  [0.19962439]\n",
      "  [0.19237749]\n",
      "  [0.20032991]\n",
      "  [0.21046707]\n",
      "  [0.21452814]\n",
      "  [0.23353331]\n",
      "  [0.25657189]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0030432718340307474\n",
      "Predicción post entrenamiento : [[0.28400192]]\n",
      "PERDIDAAAA despues: 0.0028591605369001627\n",
      "loss en el callback: 0.001968646189197898, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "ejemplar: [[0.19962439]\n",
      " [0.19237749]\n",
      " [0.20032991]\n",
      " [0.21046707]\n",
      " [0.21452814]\n",
      " [0.23353331]\n",
      " [0.25657189]\n",
      " [0.28569666]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.27812666]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[[0.19962439]\n",
      "  [0.19237749]\n",
      "  [0.20032991]\n",
      "  [0.21046707]\n",
      "  [0.21452814]\n",
      "  [0.23353331]\n",
      "  [0.25657189]\n",
      "  [0.28569666]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004855346865952015\n",
      "Predicción post entrenamiento : [[0.2752239]]\n",
      "PERDIDAAAA despues: 0.0044592441990971565\n",
      "loss en el callback: 0.006644248031079769, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "ejemplar: [[0.19237749]\n",
      " [0.20032991]\n",
      " [0.21046707]\n",
      " [0.21452814]\n",
      " [0.23353331]\n",
      " [0.25657189]\n",
      " [0.28569666]\n",
      " [0.27812666]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.27906585]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[[0.19237749]\n",
      "  [0.20032991]\n",
      "  [0.21046707]\n",
      "  [0.21452814]\n",
      "  [0.23353331]\n",
      "  [0.25657189]\n",
      "  [0.28569666]\n",
      "  [0.27812666]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004506770987063646\n",
      "Predicción post entrenamiento : [[0.2745006]]\n",
      "PERDIDAAAA despues: 0.003914660774171352\n",
      "loss en el callback: 0.015505027025938034, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "ejemplar: [[0.20032991]\n",
      " [0.21046707]\n",
      " [0.21452814]\n",
      " [0.23353331]\n",
      " [0.25657189]\n",
      " [0.28569666]\n",
      " [0.27812666]\n",
      " [0.27906585]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.2820752]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[[0.20032991]\n",
      "  [0.21046707]\n",
      "  [0.21452814]\n",
      "  [0.23353331]\n",
      "  [0.25657189]\n",
      "  [0.28569666]\n",
      "  [0.27812666]\n",
      "  [0.27906585]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005593722686171532\n",
      "Predicción post entrenamiento : [[0.2802025]]\n",
      "PERDIDAAAA despues: 0.005317108239978552\n",
      "loss en el callback: 0.00427287770435214, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "ejemplar: [[0.21046707]\n",
      " [0.21452814]\n",
      " [0.23353331]\n",
      " [0.25657189]\n",
      " [0.28569666]\n",
      " [0.27812666]\n",
      " [0.27906585]\n",
      " [0.2820752 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.28873602]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[[0.21046707]\n",
      "  [0.21452814]\n",
      "  [0.23353331]\n",
      "  [0.25657189]\n",
      "  [0.28569666]\n",
      "  [0.27812666]\n",
      "  [0.27906585]\n",
      "  [0.2820752 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009175253100693226\n",
      "Predicción post entrenamiento : [[0.28570107]]\n",
      "PERDIDAAAA despues: 0.008603042922914028\n",
      "loss en el callback: 0.011829810217022896, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "ejemplar: [[0.21452814]\n",
      " [0.23353331]\n",
      " [0.25657189]\n",
      " [0.28569666]\n",
      " [0.27812666]\n",
      " [0.27906585]\n",
      " [0.2820752 ]\n",
      " [0.28873602]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.29468346]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[[0.21452814]\n",
      "  [0.23353331]\n",
      "  [0.25657189]\n",
      "  [0.28569666]\n",
      "  [0.27812666]\n",
      "  [0.27906585]\n",
      "  [0.2820752 ]\n",
      "  [0.28873602]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009576680138707161\n",
      "Predicción post entrenamiento : [[0.29223615]]\n",
      "PERDIDAAAA despues: 0.009103680029511452\n",
      "loss en el callback: 0.009580962359905243, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "ejemplar: [[0.23353331]\n",
      " [0.25657189]\n",
      " [0.28569666]\n",
      " [0.27812666]\n",
      " [0.27906585]\n",
      " [0.2820752 ]\n",
      " [0.28873602]\n",
      " [0.29468346]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.30285567]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[[0.23353331]\n",
      "  [0.25657189]\n",
      "  [0.28569666]\n",
      "  [0.27812666]\n",
      "  [0.27906585]\n",
      "  [0.2820752 ]\n",
      "  [0.28873602]\n",
      "  [0.29468346]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007849539630115032\n",
      "Predicción post entrenamiento : [[0.29799837]]\n",
      "PERDIDAAAA despues: 0.0070124417543411255\n",
      "loss en el callback: 0.028714025393128395, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "ejemplar: [[0.25657189]\n",
      " [0.28569666]\n",
      " [0.27812666]\n",
      " [0.27906585]\n",
      " [0.2820752 ]\n",
      " [0.28873602]\n",
      " [0.29468346]\n",
      " [0.30285567]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.30684486]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[[0.25657189]\n",
      "  [0.28569666]\n",
      "  [0.27812666]\n",
      "  [0.27906585]\n",
      "  [0.2820752 ]\n",
      "  [0.28873602]\n",
      "  [0.29468346]\n",
      "  [0.30285567]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015755219385027885\n",
      "Predicción post entrenamiento : [[0.30463442]]\n",
      "PERDIDAAAA despues: 0.015205197967588902\n",
      "loss en el callback: 0.011043189093470573, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "ejemplar: [[0.28569666]\n",
      " [0.27812666]\n",
      " [0.27906585]\n",
      " [0.2820752 ]\n",
      " [0.28873602]\n",
      " [0.29468346]\n",
      " [0.30285567]\n",
      " [0.30684486]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.3102643]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[[0.28569666]\n",
      "  [0.27812666]\n",
      "  [0.27906585]\n",
      "  [0.2820752 ]\n",
      "  [0.28873602]\n",
      "  [0.29468346]\n",
      "  [0.30285567]\n",
      "  [0.30684486]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018262377008795738\n",
      "Predicción post entrenamiento : [[0.30677512]]\n",
      "PERDIDAAAA despues: 0.01733151078224182\n",
      "loss en el callback: 0.02449500560760498, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "ejemplar: [[0.27812666]\n",
      " [0.27906585]\n",
      " [0.2820752 ]\n",
      " [0.28873602]\n",
      " [0.29468346]\n",
      " [0.30285567]\n",
      " [0.30684486]\n",
      " [0.31026429]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.30720007]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[[0.27812666]\n",
      "  [0.27906585]\n",
      "  [0.2820752 ]\n",
      "  [0.28873602]\n",
      "  [0.29468346]\n",
      "  [0.30285567]\n",
      "  [0.30684486]\n",
      "  [0.31026429]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.025343183428049088\n",
      "Predicción post entrenamiento : [[0.30380413]]\n",
      "PERDIDAAAA despues: 0.024273477494716644\n",
      "loss en el callback: 0.02814127318561077, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "ejemplar: [[0.27906585]\n",
      " [0.2820752 ]\n",
      " [0.28873602]\n",
      " [0.29468346]\n",
      " [0.30285567]\n",
      " [0.30684486]\n",
      " [0.31026429]\n",
      " [0.30720007]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.306567]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[[0.27906585]\n",
      "  [0.2820752 ]\n",
      "  [0.28873602]\n",
      "  [0.29468346]\n",
      "  [0.30285567]\n",
      "  [0.30684486]\n",
      "  [0.31026429]\n",
      "  [0.30720007]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.021819382905960083\n",
      "Predicción post entrenamiento : [[0.30354625]]\n",
      "PERDIDAAAA despues: 0.020936090499162674\n",
      "loss en el callback: 0.025169603526592255, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "ejemplar: [[0.2820752 ]\n",
      " [0.28873602]\n",
      " [0.29468346]\n",
      " [0.30285567]\n",
      " [0.30684486]\n",
      " [0.31026429]\n",
      " [0.30720007]\n",
      " [0.30656701]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.30704772]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[[0.2820752 ]\n",
      "  [0.28873602]\n",
      "  [0.29468346]\n",
      "  [0.30285567]\n",
      "  [0.30684486]\n",
      "  [0.31026429]\n",
      "  [0.30720007]\n",
      "  [0.30656701]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013196071609854698\n",
      "Predicción post entrenamiento : [[0.30614313]]\n",
      "PERDIDAAAA despues: 0.012989061884582043\n",
      "loss en el callback: 0.003595577785745263, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "ejemplar: [[0.28873602]\n",
      " [0.29468346]\n",
      " [0.30285567]\n",
      " [0.30684486]\n",
      " [0.31026429]\n",
      " [0.30720007]\n",
      " [0.30656701]\n",
      " [0.30704772]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.30992168]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[[0.28873602]\n",
      "  [0.29468346]\n",
      "  [0.30285567]\n",
      "  [0.30684486]\n",
      "  [0.31026429]\n",
      "  [0.30720007]\n",
      "  [0.30656701]\n",
      "  [0.30704772]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015362920239567757\n",
      "Predicción post entrenamiento : [[0.30775565]]\n",
      "PERDIDAAAA despues: 0.014830664731562138\n",
      "loss en el callback: 0.015206689946353436, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "ejemplar: [[0.29468346]\n",
      " [0.30285567]\n",
      " [0.30684486]\n",
      " [0.31026429]\n",
      " [0.30720007]\n",
      " [0.30656701]\n",
      " [0.30704772]\n",
      " [0.30992168]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.31088862]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[[0.29468346]\n",
      "  [0.30285567]\n",
      "  [0.30684486]\n",
      "  [0.31026429]\n",
      "  [0.30720007]\n",
      "  [0.30656701]\n",
      "  [0.30704772]\n",
      "  [0.30992168]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0019305330934002995\n",
      "Predicción post entrenamiento : [[0.3103982]]\n",
      "PERDIDAAAA despues: 0.0018876770045608282\n",
      "loss en el callback: 0.0009527741931378841, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "ejemplar: [[0.30285567]\n",
      " [0.30684486]\n",
      " [0.31026429]\n",
      " [0.30720007]\n",
      " [0.30656701]\n",
      " [0.30704772]\n",
      " [0.30992168]\n",
      " [0.31088862]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.3128333]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[[0.30285567]\n",
      "  [0.30684486]\n",
      "  [0.31026429]\n",
      "  [0.30720007]\n",
      "  [0.30656701]\n",
      "  [0.30704772]\n",
      "  [0.30992168]\n",
      "  [0.31088862]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00041253786184825003\n",
      "Predicción post entrenamiento : [[0.31271827]]\n",
      "PERDIDAAAA despues: 0.0004078780475538224\n",
      "loss en el callback: 5.93395197938662e-05, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "ejemplar: [[0.30684486]\n",
      " [0.31026429]\n",
      " [0.30720007]\n",
      " [0.30656701]\n",
      " [0.30704772]\n",
      " [0.30992168]\n",
      " [0.31088862]\n",
      " [0.31283331]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.31376708]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[[0.30684486]\n",
      "  [0.31026429]\n",
      "  [0.30720007]\n",
      "  [0.30656701]\n",
      "  [0.30704772]\n",
      "  [0.30992168]\n",
      "  [0.31088862]\n",
      "  [0.31283331]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.5517620340688154e-05\n",
      "Predicción post entrenamiento : [[0.31424105]]\n",
      "PERDIDAAAA despues: 1.2008062185486779e-05\n",
      "loss en el callback: 0.0011952297063544393, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "ejemplar: [[0.31026429]\n",
      " [0.30720007]\n",
      " [0.30656701]\n",
      " [0.30704772]\n",
      " [0.30992168]\n",
      " [0.31088862]\n",
      " [0.31283331]\n",
      " [0.31376708]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.31462836]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[[0.31026429]\n",
      "  [0.30720007]\n",
      "  [0.30656701]\n",
      "  [0.30704772]\n",
      "  [0.30992168]\n",
      "  [0.31088862]\n",
      "  [0.31283331]\n",
      "  [0.31376708]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.837081749225035e-06\n",
      "Predicción post entrenamiento : [[0.31536904]]\n",
      "PERDIDAAAA despues: 7.287430889846291e-06\n",
      "loss en el callback: 0.0035640771966427565, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "ejemplar: [[0.30720007]\n",
      " [0.30656701]\n",
      " [0.30704772]\n",
      " [0.30992168]\n",
      " [0.31088862]\n",
      " [0.31283331]\n",
      " [0.31376708]\n",
      " [0.31462836]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.31514612]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[[0.30720007]\n",
      "  [0.30656701]\n",
      "  [0.30704772]\n",
      "  [0.30992168]\n",
      "  [0.31088862]\n",
      "  [0.31283331]\n",
      "  [0.31376708]\n",
      "  [0.31462836]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006817769026383758\n",
      "Predicción post entrenamiento : [[0.31522912]]\n",
      "PERDIDAAAA despues: 0.000686118146404624\n",
      "loss en el callback: 4.35791807831265e-05, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "ejemplar: [[0.30656701]\n",
      " [0.30704772]\n",
      " [0.30992168]\n",
      " [0.31088862]\n",
      " [0.31283331]\n",
      " [0.31376708]\n",
      " [0.31462836]\n",
      " [0.31514612]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.31581658]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[[0.30656701]\n",
      "  [0.30704772]\n",
      "  [0.30992168]\n",
      "  [0.31088862]\n",
      "  [0.31283331]\n",
      "  [0.31376708]\n",
      "  [0.31462836]\n",
      "  [0.31514612]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010877115419134498\n",
      "Predicción post entrenamiento : [[0.31585008]]\n",
      "PERDIDAAAA despues: 0.0010899221524596214\n",
      "loss en el callback: 7.379758699244121e-06, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "ejemplar: [[0.30704772]\n",
      " [0.30992168]\n",
      " [0.31088862]\n",
      " [0.31283331]\n",
      " [0.31376708]\n",
      " [0.31462836]\n",
      " [0.31514612]\n",
      " [0.31581658]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.31682473]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[[0.30704772]\n",
      "  [0.30992168]\n",
      "  [0.31088862]\n",
      "  [0.31283331]\n",
      "  [0.31376708]\n",
      "  [0.31462836]\n",
      "  [0.31514612]\n",
      "  [0.31581658]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003002738521900028\n",
      "Predicción post entrenamiento : [[0.31578895]]\n",
      "PERDIDAAAA despues: 0.0002654498384799808\n",
      "loss en el callback: 0.005132667254656553, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "ejemplar: [[0.30992168]\n",
      " [0.31088862]\n",
      " [0.31283331]\n",
      " [0.31376708]\n",
      " [0.31462836]\n",
      " [0.31514612]\n",
      " [0.31581658]\n",
      " [0.31682473]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.31694058]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[[0.30992168]\n",
      "  [0.31088862]\n",
      "  [0.31283331]\n",
      "  [0.31376708]\n",
      "  [0.31462836]\n",
      "  [0.31514612]\n",
      "  [0.31581658]\n",
      "  [0.31682473]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016874438151717186\n",
      "Predicción post entrenamiento : [[0.3167919]]\n",
      "PERDIDAAAA despues: 0.0016752504743635654\n",
      "loss en el callback: 0.0001631086051929742, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "ejemplar: [[0.31088862]\n",
      " [0.31283331]\n",
      " [0.31376708]\n",
      " [0.31462836]\n",
      " [0.31514612]\n",
      " [0.31581658]\n",
      " [0.31682473]\n",
      " [0.31694058]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.3175771]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[[0.31088862]\n",
      "  [0.31283331]\n",
      "  [0.31376708]\n",
      "  [0.31462836]\n",
      "  [0.31514612]\n",
      "  [0.31581658]\n",
      "  [0.31682473]\n",
      "  [0.31694058]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018384694121778011\n",
      "Predicción post entrenamiento : [[0.31710926]]\n",
      "PERDIDAAAA despues: 0.0017985689919441938\n",
      "loss en el callback: 0.0015545738860964775, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "ejemplar: [[0.31283331]\n",
      " [0.31376708]\n",
      " [0.31462836]\n",
      " [0.31514612]\n",
      " [0.31581658]\n",
      " [0.31682473]\n",
      " [0.31694058]\n",
      " [0.31757709]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.31788936]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[[0.31283331]\n",
      "  [0.31376708]\n",
      "  [0.31462836]\n",
      "  [0.31514612]\n",
      "  [0.31581658]\n",
      "  [0.31682473]\n",
      "  [0.31694058]\n",
      "  [0.31757709]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017990113701671362\n",
      "Predicción post entrenamiento : [[0.31692767]]\n",
      "PERDIDAAAA despues: 0.0017183565068989992\n",
      "loss en el callback: 0.006027307361364365, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "ejemplar: [[0.31376708]\n",
      " [0.31462836]\n",
      " [0.31514612]\n",
      " [0.31581658]\n",
      " [0.31682473]\n",
      " [0.31694058]\n",
      " [0.31757709]\n",
      " [0.31788936]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.31746265]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[[0.31376708]\n",
      "  [0.31462836]\n",
      "  [0.31514612]\n",
      "  [0.31581658]\n",
      "  [0.31682473]\n",
      "  [0.31694058]\n",
      "  [0.31757709]\n",
      "  [0.31788936]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002989893255289644\n",
      "Predicción post entrenamiento : [[0.31670368]]\n",
      "PERDIDAAAA despues: 0.00032581272535026073\n",
      "loss en el callback: 0.003345584962517023, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "ejemplar: [[0.31462836]\n",
      " [0.31514612]\n",
      " [0.31581658]\n",
      " [0.31682473]\n",
      " [0.31694058]\n",
      " [0.31757709]\n",
      " [0.31788936]\n",
      " [0.31746265]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.3171735]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[[0.31462836]\n",
      "  [0.31514612]\n",
      "  [0.31581658]\n",
      "  [0.31682473]\n",
      "  [0.31694058]\n",
      "  [0.31757709]\n",
      "  [0.31788936]\n",
      "  [0.31746265]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001482448191381991\n",
      "Predicción post entrenamiento : [[0.31768158]]\n",
      "PERDIDAAAA despues: 0.0014435823541134596\n",
      "loss en el callback: 0.0022857123985886574, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "ejemplar: [[0.31514612]\n",
      " [0.31581658]\n",
      " [0.31682473]\n",
      " [0.31694058]\n",
      " [0.31757709]\n",
      " [0.31788936]\n",
      " [0.31746265]\n",
      " [0.31717351]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.31807742]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[[0.31514612]\n",
      "  [0.31581658]\n",
      "  [0.31682473]\n",
      "  [0.31694058]\n",
      "  [0.31757709]\n",
      "  [0.31788936]\n",
      "  [0.31746265]\n",
      "  [0.31717351]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00034647301072254777\n",
      "Predicción post entrenamiento : [[0.31802338]]\n",
      "PERDIDAAAA despues: 0.00034848740324378014\n",
      "loss en el callback: 2.36324813158717e-05, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "ejemplar: [[0.31581658]\n",
      " [0.31682473]\n",
      " [0.31694058]\n",
      " [0.31757709]\n",
      " [0.31788936]\n",
      " [0.31746265]\n",
      " [0.31717351]\n",
      " [0.31807742]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.31839976]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[[0.31581658]\n",
      "  [0.31682473]\n",
      "  [0.31694058]\n",
      "  [0.31757709]\n",
      "  [0.31788936]\n",
      "  [0.31746265]\n",
      "  [0.31717351]\n",
      "  [0.31807742]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00023079330276232213\n",
      "Predicción post entrenamiento : [[0.3186878]]\n",
      "PERDIDAAAA despues: 0.00022212455223780125\n",
      "loss en el callback: 0.0008426645072177052, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "ejemplar: [[0.31682473]\n",
      " [0.31694058]\n",
      " [0.31757709]\n",
      " [0.31788936]\n",
      " [0.31746265]\n",
      " [0.31717351]\n",
      " [0.31807742]\n",
      " [0.31839976]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.31899682]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[[0.31682473]\n",
      "  [0.31694058]\n",
      "  [0.31757709]\n",
      "  [0.31788936]\n",
      "  [0.31746265]\n",
      "  [0.31717351]\n",
      "  [0.31807742]\n",
      "  [0.31839976]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004321456421166658\n",
      "Predicción post entrenamiento : [[0.31996742]]\n",
      "PERDIDAAAA despues: 0.0041947877034544945\n",
      "loss en el callback: 0.012087640352547169, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "ejemplar: [[0.31694058]\n",
      " [0.31757709]\n",
      " [0.31788936]\n",
      " [0.31746265]\n",
      " [0.31717351]\n",
      " [0.31807742]\n",
      " [0.31839976]\n",
      " [0.31899682]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.32011792]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[[0.31694058]\n",
      "  [0.31757709]\n",
      "  [0.31788936]\n",
      "  [0.31746265]\n",
      "  [0.31717351]\n",
      "  [0.31807742]\n",
      "  [0.31839976]\n",
      "  [0.31899682]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06299024075269699\n",
      "Predicción post entrenamiento : [[0.32246637]]\n",
      "PERDIDAAAA despues: 0.06181693077087402\n",
      "loss en el callback: 0.0451277457177639, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "ejemplar: [[0.31757709]\n",
      " [0.31788936]\n",
      " [0.31746265]\n",
      " [0.31717351]\n",
      " [0.31807742]\n",
      " [0.31839976]\n",
      " [0.31899682]\n",
      " [0.32011792]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.3226454]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[[0.31757709]\n",
      "  [0.31788936]\n",
      "  [0.31746265]\n",
      "  [0.31717351]\n",
      "  [0.31807742]\n",
      "  [0.31839976]\n",
      "  [0.31899682]\n",
      "  [0.32011792]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07487618178129196\n",
      "Predicción post entrenamiento : [[0.32518813]]\n",
      "PERDIDAAAA despues: 0.07349108159542084\n",
      "loss en el callback: 0.058474913239479065, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "ejemplar: [[0.31788936]\n",
      " [0.31746265]\n",
      " [0.31717351]\n",
      " [0.31807742]\n",
      " [0.31839976]\n",
      " [0.31899682]\n",
      " [0.32011792]\n",
      " [0.3226454 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.3253014]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[[0.31788936]\n",
      "  [0.31746265]\n",
      "  [0.31717351]\n",
      "  [0.31807742]\n",
      "  [0.31839976]\n",
      "  [0.31899682]\n",
      "  [0.32011792]\n",
      "  [0.3226454 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0621415451169014\n",
      "Predicción post entrenamiento : [[0.32731795]]\n",
      "PERDIDAAAA despues: 0.061140235513448715\n",
      "loss en el callback: 0.03554448112845421, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "ejemplar: [[0.31746265]\n",
      " [0.31717351]\n",
      " [0.31807742]\n",
      " [0.31839976]\n",
      " [0.31899682]\n",
      " [0.32011792]\n",
      " [0.3226454 ]\n",
      " [0.32530141]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.32746813]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[[0.31746265]\n",
      "  [0.31717351]\n",
      "  [0.31807742]\n",
      "  [0.31839976]\n",
      "  [0.31899682]\n",
      "  [0.32011792]\n",
      "  [0.3226454 ]\n",
      "  [0.32530141]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07777739316225052\n",
      "Predicción post entrenamiento : [[0.33011353]]\n",
      "PERDIDAAAA despues: 0.07630886137485504\n",
      "loss en el callback: 0.10723621398210526, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "ejemplar: [[0.31717351]\n",
      " [0.31807742]\n",
      " [0.31839976]\n",
      " [0.31899682]\n",
      " [0.32011792]\n",
      " [0.3226454 ]\n",
      " [0.32530141]\n",
      " [0.32746813]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.33052367]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[[0.31717351]\n",
      "  [0.31807742]\n",
      "  [0.31839976]\n",
      "  [0.31899682]\n",
      "  [0.32011792]\n",
      "  [0.3226454 ]\n",
      "  [0.32530141]\n",
      "  [0.32746813]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06458381563425064\n",
      "Predicción post entrenamiento : [[0.3327534]]\n",
      "PERDIDAAAA despues: 0.0634554922580719\n",
      "loss en el callback: 0.05233369022607803, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "ejemplar: [[0.31807742]\n",
      " [0.31839976]\n",
      " [0.31899682]\n",
      " [0.32011792]\n",
      " [0.3226454 ]\n",
      " [0.32530141]\n",
      " [0.32746813]\n",
      " [0.33052367]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.33348113]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[[0.31807742]\n",
      "  [0.31839976]\n",
      "  [0.31899682]\n",
      "  [0.32011792]\n",
      "  [0.3226454 ]\n",
      "  [0.32530141]\n",
      "  [0.32746813]\n",
      "  [0.33052367]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05536168813705444\n",
      "Predicción post entrenamiento : [[0.33562657]]\n",
      "PERDIDAAAA despues: 0.054356686770915985\n",
      "loss en el callback: 0.0828157290816307, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "ejemplar: [[0.31839976]\n",
      " [0.31899682]\n",
      " [0.32011792]\n",
      " [0.3226454 ]\n",
      " [0.32530141]\n",
      " [0.32746813]\n",
      " [0.33052367]\n",
      " [0.33348113]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.33649302]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[[0.31839976]\n",
      "  [0.31899682]\n",
      "  [0.32011792]\n",
      "  [0.3226454 ]\n",
      "  [0.32530141]\n",
      "  [0.32746813]\n",
      "  [0.33052367]\n",
      "  [0.33348113]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09380810707807541\n",
      "Predicción post entrenamiento : [[0.33909175]]\n",
      "PERDIDAAAA despues: 0.09222297370433807\n",
      "loss en el callback: 0.09788284450769424, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "ejemplar: [[0.31899682]\n",
      " [0.32011792]\n",
      " [0.3226454 ]\n",
      " [0.32530141]\n",
      " [0.32746813]\n",
      " [0.33052367]\n",
      " [0.33348113]\n",
      " [0.33649302]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.34029895]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[[0.31899682]\n",
      "  [0.32011792]\n",
      "  [0.3226454 ]\n",
      "  [0.32530141]\n",
      "  [0.32746813]\n",
      "  [0.33052367]\n",
      "  [0.33348113]\n",
      "  [0.33649302]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10333657264709473\n",
      "Predicción post entrenamiento : [[0.34291926]]\n",
      "PERDIDAAAA despues: 0.10165879130363464\n",
      "loss en el callback: 0.07775872945785522, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "ejemplar: [[0.32011792]\n",
      " [0.3226454 ]\n",
      " [0.32530141]\n",
      " [0.32746813]\n",
      " [0.33052367]\n",
      " [0.33348113]\n",
      " [0.33649302]\n",
      " [0.34029895]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.3444971]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[[0.32011792]\n",
      "  [0.3226454 ]\n",
      "  [0.32530141]\n",
      "  [0.32746813]\n",
      "  [0.33052367]\n",
      "  [0.33348113]\n",
      "  [0.33649302]\n",
      "  [0.34029895]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10791084170341492\n",
      "Predicción post entrenamiento : [[0.34727833]]\n",
      "PERDIDAAAA despues: 0.10609133541584015\n",
      "loss en el callback: 0.12348344177007675, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "ejemplar: [[0.3226454 ]\n",
      " [0.32530141]\n",
      " [0.32746813]\n",
      " [0.33052367]\n",
      " [0.33348113]\n",
      " [0.33649302]\n",
      " [0.34029895]\n",
      " [0.34449711]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.34919757]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[[0.3226454 ]\n",
      "  [0.32530141]\n",
      "  [0.32746813]\n",
      "  [0.33052367]\n",
      "  [0.33348113]\n",
      "  [0.33649302]\n",
      "  [0.34029895]\n",
      "  [0.34449711]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13059531152248383\n",
      "Predicción post entrenamiento : [[0.3520507]]\n",
      "PERDIDAAAA despues: 0.12854133546352386\n",
      "loss en el callback: 0.10211538523435593, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "ejemplar: [[0.32530141]\n",
      " [0.32746813]\n",
      " [0.33052367]\n",
      " [0.33348113]\n",
      " [0.33649302]\n",
      " [0.34029895]\n",
      " [0.34449711]\n",
      " [0.34919757]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.35407034]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[[0.32530141]\n",
      "  [0.32746813]\n",
      "  [0.33052367]\n",
      "  [0.33348113]\n",
      "  [0.33649302]\n",
      "  [0.34029895]\n",
      "  [0.34449711]\n",
      "  [0.34919757]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1224442571401596\n",
      "Predicción post entrenamiento : [[0.3568897]]\n",
      "PERDIDAAAA despues: 0.12047910690307617\n",
      "loss en el callback: 0.10908596217632294, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "ejemplar: [[0.32746813]\n",
      " [0.33052367]\n",
      " [0.33348113]\n",
      " [0.33649302]\n",
      " [0.34029895]\n",
      " [0.34449711]\n",
      " [0.34919757]\n",
      " [0.35407034]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.35903454]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[[0.32746813]\n",
      "  [0.33052367]\n",
      "  [0.33348113]\n",
      "  [0.33649302]\n",
      "  [0.34029895]\n",
      "  [0.34449711]\n",
      "  [0.34919757]\n",
      "  [0.35407034]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13557343184947968\n",
      "Predicción post entrenamiento : [[0.3619392]]\n",
      "PERDIDAAAA despues: 0.13344286382198334\n",
      "loss en el callback: 0.11744120717048645, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "ejemplar: [[0.33052367]\n",
      " [0.33348113]\n",
      " [0.33649302]\n",
      " [0.34029895]\n",
      " [0.34449711]\n",
      " [0.34919757]\n",
      " [0.35407034]\n",
      " [0.35903454]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.3643875]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[[0.33052367]\n",
      "  [0.33348113]\n",
      "  [0.33649302]\n",
      "  [0.34029895]\n",
      "  [0.34449711]\n",
      "  [0.34919757]\n",
      "  [0.35407034]\n",
      "  [0.35903454]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12830767035484314\n",
      "Predicción post entrenamiento : [[0.36711702]]\n",
      "PERDIDAAAA despues: 0.1263597011566162\n",
      "loss en el callback: 0.10762899369001389, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "ejemplar: [[0.33348113]\n",
      " [0.33649302]\n",
      " [0.34029895]\n",
      " [0.34449711]\n",
      " [0.34919757]\n",
      " [0.35407034]\n",
      " [0.35903454]\n",
      " [0.36438751]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.36975047]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[[0.33348113]\n",
      "  [0.33649302]\n",
      "  [0.34029895]\n",
      "  [0.34449711]\n",
      "  [0.34919757]\n",
      "  [0.35407034]\n",
      "  [0.35903454]\n",
      "  [0.36438751]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.16163891553878784\n",
      "Predicción post entrenamiento : [[0.37276927]]\n",
      "PERDIDAAAA despues: 0.15922066569328308\n",
      "loss en el callback: 0.126766175031662, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "ejemplar: [[0.33649302]\n",
      " [0.34029895]\n",
      " [0.34449711]\n",
      " [0.34919757]\n",
      " [0.35407034]\n",
      " [0.35903454]\n",
      " [0.36438751]\n",
      " [0.36975047]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.37568277]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[[0.33649302]\n",
      "  [0.34029895]\n",
      "  [0.34449711]\n",
      "  [0.34919757]\n",
      "  [0.35407034]\n",
      "  [0.35903454]\n",
      "  [0.36438751]\n",
      "  [0.36975047]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12169117480516434\n",
      "Predicción post entrenamiento : [[0.37832263]]\n",
      "PERDIDAAAA despues: 0.1198563501238823\n",
      "loss en el callback: 0.1640666425228119, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "ejemplar: [[0.34029895]\n",
      " [0.34449711]\n",
      " [0.34919757]\n",
      " [0.35407034]\n",
      " [0.35903454]\n",
      " [0.36438751]\n",
      " [0.36975047]\n",
      " [0.37568277]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.38158557]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[[0.34029895]\n",
      "  [0.34449711]\n",
      "  [0.34919757]\n",
      "  [0.35407034]\n",
      "  [0.35903454]\n",
      "  [0.36438751]\n",
      "  [0.36975047]\n",
      "  [0.37568277]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08379411697387695\n",
      "Predicción post entrenamiento : [[0.38381442]]\n",
      "PERDIDAAAA despues: 0.08250869810581207\n",
      "loss en el callback: 0.11844851821660995, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "ejemplar: [[0.34449711]\n",
      " [0.34919757]\n",
      " [0.35407034]\n",
      " [0.35903454]\n",
      " [0.36438751]\n",
      " [0.36975047]\n",
      " [0.37568277]\n",
      " [0.38158557]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.38732466]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[[0.34449711]\n",
      "  [0.34919757]\n",
      "  [0.35407034]\n",
      "  [0.35903454]\n",
      "  [0.36438751]\n",
      "  [0.36975047]\n",
      "  [0.37568277]\n",
      "  [0.38158557]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08205083757638931\n",
      "Predicción post entrenamiento : [[0.38958228]]\n",
      "PERDIDAAAA despues: 0.08076256513595581\n",
      "loss en el callback: 0.11042480170726776, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "ejemplar: [[0.34919757]\n",
      " [0.35407034]\n",
      " [0.35903454]\n",
      " [0.36438751]\n",
      " [0.36975047]\n",
      " [0.37568277]\n",
      " [0.38158557]\n",
      " [0.38732466]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.3933119]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[[0.34919757]\n",
      "  [0.35407034]\n",
      "  [0.35903454]\n",
      "  [0.36438751]\n",
      "  [0.36975047]\n",
      "  [0.37568277]\n",
      "  [0.38158557]\n",
      "  [0.38732466]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10313083976507187\n",
      "Predicción post entrenamiento : [[0.39553246]]\n",
      "PERDIDAAAA despues: 0.10170953720808029\n",
      "loss en el callback: 0.09645532071590424, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "ejemplar: [[0.35407034]\n",
      " [0.35903454]\n",
      " [0.36438751]\n",
      " [0.36975047]\n",
      " [0.37568277]\n",
      " [0.38158557]\n",
      " [0.38732466]\n",
      " [0.39331189]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.39941785]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[[0.35407034]\n",
      "  [0.35903454]\n",
      "  [0.36438751]\n",
      "  [0.36975047]\n",
      "  [0.37568277]\n",
      "  [0.38158557]\n",
      "  [0.38732466]\n",
      "  [0.39331189]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1186663955450058\n",
      "Predicción post entrenamiento : [[0.40193048]]\n",
      "PERDIDAAAA despues: 0.11694160103797913\n",
      "loss en el callback: 0.12302959710359573, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "ejemplar: [[0.35903454]\n",
      " [0.36438751]\n",
      " [0.36975047]\n",
      " [0.37568277]\n",
      " [0.38158557]\n",
      " [0.38732466]\n",
      " [0.39331189]\n",
      " [0.39941785]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.40597415]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[[0.35903454]\n",
      "  [0.36438751]\n",
      "  [0.36975047]\n",
      "  [0.37568277]\n",
      "  [0.38158557]\n",
      "  [0.38732466]\n",
      "  [0.39331189]\n",
      "  [0.39941785]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10024441033601761\n",
      "Predicción post entrenamiento : [[0.40808636]]\n",
      "PERDIDAAAA despues: 0.0989113599061966\n",
      "loss en el callback: 0.0775621309876442, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "ejemplar: [[0.36438751]\n",
      " [0.36975047]\n",
      " [0.37568277]\n",
      " [0.38158557]\n",
      " [0.38732466]\n",
      " [0.39331189]\n",
      " [0.39941785]\n",
      " [0.40597415]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.41230804]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[[0.36438751]\n",
      "  [0.36975047]\n",
      "  [0.37568277]\n",
      "  [0.38158557]\n",
      "  [0.38732466]\n",
      "  [0.39331189]\n",
      "  [0.39941785]\n",
      "  [0.40597415]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08238812536001205\n",
      "Predicción post entrenamiento : [[0.41388357]]\n",
      "PERDIDAAAA despues: 0.08148615062236786\n",
      "loss en el callback: 0.040622368454933167, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "ejemplar: [[0.36975047]\n",
      " [0.37568277]\n",
      " [0.38158557]\n",
      " [0.38732466]\n",
      " [0.39331189]\n",
      " [0.39941785]\n",
      " [0.40597415]\n",
      " [0.41230804]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.41823128]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[[0.36975047]\n",
      "  [0.37568277]\n",
      "  [0.38158557]\n",
      "  [0.38732466]\n",
      "  [0.39331189]\n",
      "  [0.39941785]\n",
      "  [0.40597415]\n",
      "  [0.41230804]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10181194543838501\n",
      "Predicción post entrenamiento : [[0.42053625]]\n",
      "PERDIDAAAA despues: 0.10034631937742233\n",
      "loss en el callback: 0.17664723098278046, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "ejemplar: [[0.37568277]\n",
      " [0.38158557]\n",
      " [0.38732466]\n",
      " [0.39331189]\n",
      " [0.39941785]\n",
      " [0.40597415]\n",
      " [0.41230804]\n",
      " [0.41823128]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.4250392]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[[0.37568277]\n",
      "  [0.38158557]\n",
      "  [0.38732466]\n",
      "  [0.39331189]\n",
      "  [0.39941785]\n",
      "  [0.40597415]\n",
      "  [0.41230804]\n",
      "  [0.41823128]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08784503489732742\n",
      "Predicción post entrenamiento : [[0.42698777]]\n",
      "PERDIDAAAA despues: 0.08669377118349075\n",
      "loss en el callback: 0.08033816516399384, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "ejemplar: [[0.38158557]\n",
      " [0.38732466]\n",
      " [0.39331189]\n",
      " [0.39941785]\n",
      " [0.40597415]\n",
      " [0.41230804]\n",
      " [0.41823128]\n",
      " [0.4250392 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.43154007]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[[0.38158557]\n",
      "  [0.38732466]\n",
      "  [0.39331189]\n",
      "  [0.39941785]\n",
      "  [0.40597415]\n",
      "  [0.41230804]\n",
      "  [0.41823128]\n",
      "  [0.4250392 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08246869593858719\n",
      "Predicción post entrenamiento : [[0.43371084]]\n",
      "PERDIDAAAA despues: 0.08122663199901581\n",
      "loss en el callback: 0.15444183349609375, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "ejemplar: [[0.38732466]\n",
      " [0.39331189]\n",
      " [0.39941785]\n",
      " [0.40597415]\n",
      " [0.41230804]\n",
      " [0.41823128]\n",
      " [0.4250392 ]\n",
      " [0.43154007]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.43833697]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[[0.38732466]\n",
      "  [0.39331189]\n",
      "  [0.39941785]\n",
      "  [0.40597415]\n",
      "  [0.41230804]\n",
      "  [0.41823128]\n",
      "  [0.4250392 ]\n",
      "  [0.43154007]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05561123788356781\n",
      "Predicción post entrenamiento : [[0.4398727]]\n",
      "PERDIDAAAA despues: 0.05488927662372589\n",
      "loss en el callback: 0.047077078372240067, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "ejemplar: [[0.39331189]\n",
      " [0.39941785]\n",
      " [0.40597415]\n",
      " [0.41230804]\n",
      " [0.41823128]\n",
      " [0.4250392 ]\n",
      " [0.43154007]\n",
      " [0.43833697]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.44463432]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[[0.39331189]\n",
      "  [0.39941785]\n",
      "  [0.40597415]\n",
      "  [0.41230804]\n",
      "  [0.41823128]\n",
      "  [0.4250392 ]\n",
      "  [0.43154007]\n",
      "  [0.43833697]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06448151916265488\n",
      "Predicción post entrenamiento : [[0.44603842]]\n",
      "PERDIDAAAA despues: 0.06377039849758148\n",
      "loss en el callback: 0.034581251442432404, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "ejemplar: [[0.39941785]\n",
      " [0.40597415]\n",
      " [0.41230804]\n",
      " [0.41823128]\n",
      " [0.4250392 ]\n",
      " [0.43154007]\n",
      " [0.43833697]\n",
      " [0.44463432]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.45090187]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[[0.39941785]\n",
      "  [0.40597415]\n",
      "  [0.41230804]\n",
      "  [0.41823128]\n",
      "  [0.4250392 ]\n",
      "  [0.43154007]\n",
      "  [0.43833697]\n",
      "  [0.44463432]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07297371327877045\n",
      "Predicción post entrenamiento : [[0.4525482]]\n",
      "PERDIDAAAA despues: 0.07208695262670517\n",
      "loss en el callback: 0.05777120590209961, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "ejemplar: [[0.40597415]\n",
      " [0.41230804]\n",
      " [0.41823128]\n",
      " [0.4250392 ]\n",
      " [0.43154007]\n",
      " [0.43833697]\n",
      " [0.44463432]\n",
      " [0.45090187]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.45750287]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[[0.40597415]\n",
      "  [0.41230804]\n",
      "  [0.41823128]\n",
      "  [0.4250392 ]\n",
      "  [0.43154007]\n",
      "  [0.43833697]\n",
      "  [0.44463432]\n",
      "  [0.45090187]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07027018815279007\n",
      "Predicción post entrenamiento : [[0.45935583]]\n",
      "PERDIDAAAA despues: 0.06929124146699905\n",
      "loss en el callback: 0.0879129022359848, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "ejemplar: [[0.41230804]\n",
      " [0.41823128]\n",
      " [0.4250392 ]\n",
      " [0.43154007]\n",
      " [0.43833697]\n",
      " [0.44463432]\n",
      " [0.45090187]\n",
      " [0.45750287]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.4643038]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[[0.41230804]\n",
      "  [0.41823128]\n",
      "  [0.4250392 ]\n",
      "  [0.43154007]\n",
      "  [0.43833697]\n",
      "  [0.44463432]\n",
      "  [0.45090187]\n",
      "  [0.45750287]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08525947481393814\n",
      "Predicción post entrenamiento : [[0.4659275]]\n",
      "PERDIDAAAA despues: 0.08431388437747955\n",
      "loss en el callback: 0.05735153704881668, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "ejemplar: [[0.41823128]\n",
      " [0.4250392 ]\n",
      " [0.43154007]\n",
      " [0.43833697]\n",
      " [0.44463432]\n",
      " [0.45090187]\n",
      " [0.45750287]\n",
      " [0.46430379]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.47092447]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[[0.41823128]\n",
      "  [0.4250392 ]\n",
      "  [0.43154007]\n",
      "  [0.43833697]\n",
      "  [0.44463432]\n",
      "  [0.45090187]\n",
      "  [0.45750287]\n",
      "  [0.46430379]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12720762193202972\n",
      "Predicción post entrenamiento : [[0.4731549]]\n",
      "PERDIDAAAA despues: 0.12562157213687897\n",
      "loss en el callback: 0.10110456496477127, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "ejemplar: [[0.4250392 ]\n",
      " [0.43154007]\n",
      " [0.43833697]\n",
      " [0.44463432]\n",
      " [0.45090187]\n",
      " [0.45750287]\n",
      " [0.46430379]\n",
      " [0.47092447]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.4783136]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[[0.4250392 ]\n",
      "  [0.43154007]\n",
      "  [0.43833697]\n",
      "  [0.44463432]\n",
      "  [0.45090187]\n",
      "  [0.45750287]\n",
      "  [0.46430379]\n",
      "  [0.47092447]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12996643781661987\n",
      "Predicción post entrenamiento : [[0.48060977]]\n",
      "PERDIDAAAA despues: 0.12831613421440125\n",
      "loss en el callback: 0.1315670609474182, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "ejemplar: [[0.43154007]\n",
      " [0.43833697]\n",
      " [0.44463432]\n",
      " [0.45090187]\n",
      " [0.45750287]\n",
      " [0.46430379]\n",
      " [0.47092447]\n",
      " [0.4783136 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.48573434]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[[0.43154007]\n",
      "  [0.43833697]\n",
      "  [0.44463432]\n",
      "  [0.45090187]\n",
      "  [0.45750287]\n",
      "  [0.46430379]\n",
      "  [0.47092447]\n",
      "  [0.4783136 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09519166499376297\n",
      "Predicción post entrenamiento : [[0.48782122]]\n",
      "PERDIDAAAA despues: 0.09390828758478165\n",
      "loss en el callback: 0.13728666305541992, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "ejemplar: [[0.43833697]\n",
      " [0.44463432]\n",
      " [0.45090187]\n",
      " [0.45750287]\n",
      " [0.46430379]\n",
      " [0.47092447]\n",
      " [0.4783136 ]\n",
      " [0.48573434]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.49299178]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[[0.43833697]\n",
      "  [0.44463432]\n",
      "  [0.45090187]\n",
      "  [0.45750287]\n",
      "  [0.46430379]\n",
      "  [0.47092447]\n",
      "  [0.4783136 ]\n",
      "  [0.48573434]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08457216620445251\n",
      "Predicción post entrenamiento : [[0.49464664]]\n",
      "PERDIDAAAA despues: 0.08361238986253738\n",
      "loss en el callback: 0.06251800060272217, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "ejemplar: [[0.44463432]\n",
      " [0.45090187]\n",
      " [0.45750287]\n",
      " [0.46430379]\n",
      " [0.47092447]\n",
      " [0.4783136 ]\n",
      " [0.48573434]\n",
      " [0.49299178]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.4998089]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[[0.44463432]\n",
      "  [0.45090187]\n",
      "  [0.45750287]\n",
      "  [0.46430379]\n",
      "  [0.47092447]\n",
      "  [0.4783136 ]\n",
      "  [0.48573434]\n",
      "  [0.49299178]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07188324630260468\n",
      "Predicción post entrenamiento : [[0.5013377]]\n",
      "PERDIDAAAA despues: 0.07106581330299377\n",
      "loss en el callback: 0.052645985037088394, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "ejemplar: [[0.45090187]\n",
      " [0.45750287]\n",
      " [0.46430379]\n",
      " [0.47092447]\n",
      " [0.4783136 ]\n",
      " [0.48573434]\n",
      " [0.49299178]\n",
      " [0.49980891]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.5066338]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[[0.45090187]\n",
      "  [0.45750287]\n",
      "  [0.46430379]\n",
      "  [0.47092447]\n",
      "  [0.4783136 ]\n",
      "  [0.48573434]\n",
      "  [0.49299178]\n",
      "  [0.49980891]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07725387811660767\n",
      "Predicción post entrenamiento : [[0.5084253]]\n",
      "PERDIDAAAA despues: 0.07626122236251831\n",
      "loss en el callback: 0.09755215793848038, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "ejemplar: [[0.45750287]\n",
      " [0.46430379]\n",
      " [0.47092447]\n",
      " [0.4783136 ]\n",
      " [0.48573434]\n",
      " [0.49299178]\n",
      " [0.49980891]\n",
      " [0.50663382]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.51389545]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[[0.45750287]\n",
      "  [0.46430379]\n",
      "  [0.47092447]\n",
      "  [0.4783136 ]\n",
      "  [0.48573434]\n",
      "  [0.49299178]\n",
      "  [0.49980891]\n",
      "  [0.50663382]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1331036388874054\n",
      "Predicción post entrenamiento : [[0.5160942]]\n",
      "PERDIDAAAA despues: 0.1315041184425354\n",
      "loss en el callback: 0.11569877713918686, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "ejemplar: [[0.46430379]\n",
      " [0.47092447]\n",
      " [0.4783136 ]\n",
      " [0.48573434]\n",
      " [0.49299178]\n",
      " [0.49980891]\n",
      " [0.50663382]\n",
      " [0.51389545]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.52168596]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[[0.46430379]\n",
      "  [0.47092447]\n",
      "  [0.4783136 ]\n",
      "  [0.48573434]\n",
      "  [0.49299178]\n",
      "  [0.49980891]\n",
      "  [0.50663382]\n",
      "  [0.51389545]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1252761036157608\n",
      "Predicción post entrenamiento : [[0.5238981]]\n",
      "PERDIDAAAA despues: 0.12371503561735153\n",
      "loss en el callback: 0.16697612404823303, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "ejemplar: [[0.47092447]\n",
      " [0.4783136 ]\n",
      " [0.48573434]\n",
      " [0.49299178]\n",
      " [0.49980891]\n",
      " [0.50663382]\n",
      " [0.51389545]\n",
      " [0.52168596]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.5295827]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[[0.47092447]\n",
      "  [0.4783136 ]\n",
      "  [0.48573434]\n",
      "  [0.49299178]\n",
      "  [0.49980891]\n",
      "  [0.50663382]\n",
      "  [0.51389545]\n",
      "  [0.52168596]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10196086019277573\n",
      "Predicción post entrenamiento : [[0.5315536]]\n",
      "PERDIDAAAA despues: 0.10070604830980301\n",
      "loss en el callback: 0.1227775290608406, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "ejemplar: [[0.4783136 ]\n",
      " [0.48573434]\n",
      " [0.49299178]\n",
      " [0.49980891]\n",
      " [0.50663382]\n",
      " [0.51389545]\n",
      " [0.52168596]\n",
      " [0.52958268]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.53739595]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[[0.4783136 ]\n",
      "  [0.48573434]\n",
      "  [0.49299178]\n",
      "  [0.49980891]\n",
      "  [0.50663382]\n",
      "  [0.51389545]\n",
      "  [0.52168596]\n",
      "  [0.52958268]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0789000540971756\n",
      "Predicción post entrenamiento : [[0.53905827]]\n",
      "PERDIDAAAA despues: 0.07796896249055862\n",
      "loss en el callback: 0.0793924480676651, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "ejemplar: [[0.48573434]\n",
      " [0.49299178]\n",
      " [0.49980891]\n",
      " [0.50663382]\n",
      " [0.51389545]\n",
      " [0.52168596]\n",
      " [0.52958268]\n",
      " [0.53739595]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.54488915]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[[0.48573434]\n",
      "  [0.49299178]\n",
      "  [0.49980891]\n",
      "  [0.50663382]\n",
      "  [0.51389545]\n",
      "  [0.52168596]\n",
      "  [0.52958268]\n",
      "  [0.53739595]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07948010414838791\n",
      "Predicción post entrenamiento : [[0.54666173]]\n",
      "PERDIDAAAA despues: 0.07848379015922546\n",
      "loss en el callback: 0.0953838974237442, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "ejemplar: [[0.49299178]\n",
      " [0.49980891]\n",
      " [0.50663382]\n",
      " [0.51389545]\n",
      " [0.52168596]\n",
      " [0.52958268]\n",
      " [0.53739595]\n",
      " [0.54488915]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.55248153]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[[0.49299178]\n",
      "  [0.49980891]\n",
      "  [0.50663382]\n",
      "  [0.51389545]\n",
      "  [0.52168596]\n",
      "  [0.52958268]\n",
      "  [0.53739595]\n",
      "  [0.54488915]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.054229818284511566\n",
      "Predicción post entrenamiento : [[0.5541927]]\n",
      "PERDIDAAAA despues: 0.05343576520681381\n",
      "loss en el callback: 0.11785566061735153, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "ejemplar: [[0.49980891]\n",
      " [0.50663382]\n",
      " [0.51389545]\n",
      " [0.52168596]\n",
      " [0.52958268]\n",
      " [0.53739595]\n",
      " [0.54488915]\n",
      " [0.55248153]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.5600557]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[[0.49980891]\n",
      "  [0.50663382]\n",
      "  [0.51389545]\n",
      "  [0.52168596]\n",
      "  [0.52958268]\n",
      "  [0.53739595]\n",
      "  [0.54488915]\n",
      "  [0.55248153]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.052520401775836945\n",
      "Predicción post entrenamiento : [[0.5614635]]\n",
      "PERDIDAAAA despues: 0.05187712237238884\n",
      "loss en el callback: 0.05834166333079338, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "ejemplar: [[0.50663382]\n",
      " [0.51389545]\n",
      " [0.52168596]\n",
      " [0.52958268]\n",
      " [0.53739595]\n",
      " [0.54488915]\n",
      " [0.55248153]\n",
      " [0.56005567]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.56750417]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[[0.50663382]\n",
      "  [0.51389545]\n",
      "  [0.52168596]\n",
      "  [0.52958268]\n",
      "  [0.53739595]\n",
      "  [0.54488915]\n",
      "  [0.55248153]\n",
      "  [0.56005567]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07111214846372604\n",
      "Predicción post entrenamiento : [[0.56879693]]\n",
      "PERDIDAAAA despues: 0.07042434066534042\n",
      "loss en el callback: 0.03957981988787651, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "ejemplar: [[0.51389545]\n",
      " [0.52168596]\n",
      " [0.52958268]\n",
      " [0.53739595]\n",
      " [0.54488915]\n",
      " [0.55248153]\n",
      " [0.56005567]\n",
      " [0.56750417]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.57504505]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[[0.51389545]\n",
      "  [0.52168596]\n",
      "  [0.52958268]\n",
      "  [0.53739595]\n",
      "  [0.54488915]\n",
      "  [0.55248153]\n",
      "  [0.56005567]\n",
      "  [0.56750417]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05637336149811745\n",
      "Predicción post entrenamiento : [[0.57658315]]\n",
      "PERDIDAAAA despues: 0.05564534291625023\n",
      "loss en el callback: 0.08083606511354446, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "ejemplar: [[0.52168596]\n",
      " [0.52958268]\n",
      " [0.53739595]\n",
      " [0.54488915]\n",
      " [0.55248153]\n",
      " [0.56005567]\n",
      " [0.56750417]\n",
      " [0.57504505]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.5829504]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[[0.52168596]\n",
      "  [0.52958268]\n",
      "  [0.53739595]\n",
      "  [0.54488915]\n",
      "  [0.55248153]\n",
      "  [0.56005567]\n",
      "  [0.56750417]\n",
      "  [0.57504505]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.047650277614593506\n",
      "Predicción post entrenamiento : [[0.58452433]]\n",
      "PERDIDAAAA despues: 0.04696561396121979\n",
      "loss en el callback: 0.09869539737701416, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "ejemplar: [[0.52958268]\n",
      " [0.53739595]\n",
      " [0.54488915]\n",
      " [0.55248153]\n",
      " [0.56005567]\n",
      " [0.56750417]\n",
      " [0.57504505]\n",
      " [0.58295041]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.59088105]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[[0.52958268]\n",
      "  [0.53739595]\n",
      "  [0.54488915]\n",
      "  [0.55248153]\n",
      "  [0.56005567]\n",
      "  [0.56750417]\n",
      "  [0.57504505]\n",
      "  [0.58295041]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04506959393620491\n",
      "Predicción post entrenamiento : [[0.59250003]]\n",
      "PERDIDAAAA despues: 0.04438481107354164\n",
      "loss en el callback: 0.14429718255996704, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "ejemplar: [[0.53739595]\n",
      " [0.54488915]\n",
      " [0.55248153]\n",
      " [0.56005567]\n",
      " [0.56750417]\n",
      " [0.57504505]\n",
      " [0.58295041]\n",
      " [0.59088105]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.59881145]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[[0.53739595]\n",
      "  [0.54488915]\n",
      "  [0.55248153]\n",
      "  [0.56005567]\n",
      "  [0.56750417]\n",
      "  [0.57504505]\n",
      "  [0.58295041]\n",
      "  [0.59088105]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.037900082767009735\n",
      "Predicción post entrenamiento : [[0.59978]]\n",
      "PERDIDAAAA despues: 0.03752389922738075\n",
      "loss en el callback: 0.02456851489841938, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "ejemplar: [[0.54488915]\n",
      " [0.55248153]\n",
      " [0.56005567]\n",
      " [0.56750417]\n",
      " [0.57504505]\n",
      " [0.58295041]\n",
      " [0.59088105]\n",
      " [0.59881145]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.6060605]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[[0.54488915]\n",
      "  [0.55248153]\n",
      "  [0.56005567]\n",
      "  [0.56750417]\n",
      "  [0.57504505]\n",
      "  [0.58295041]\n",
      "  [0.59088105]\n",
      "  [0.59881145]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.023749878630042076\n",
      "Predicción post entrenamiento : [[0.60652536]]\n",
      "PERDIDAAAA despues: 0.023606816306710243\n",
      "loss en el callback: 0.005375188775360584, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "ejemplar: [[0.55248153]\n",
      " [0.56005567]\n",
      " [0.56750417]\n",
      " [0.57504505]\n",
      " [0.58295041]\n",
      " [0.59088105]\n",
      " [0.59881145]\n",
      " [0.6060605 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.61285686]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[[0.55248153]\n",
      "  [0.56005567]\n",
      "  [0.56750417]\n",
      "  [0.57504505]\n",
      "  [0.58295041]\n",
      "  [0.59088105]\n",
      "  [0.59881145]\n",
      "  [0.6060605 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015010427683591843\n",
      "Predicción post entrenamiento : [[0.61371964]]\n",
      "PERDIDAAAA despues: 0.014799761585891247\n",
      "loss en el callback: 0.028582872822880745, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "ejemplar: [[0.56005567]\n",
      " [0.56750417]\n",
      " [0.57504505]\n",
      " [0.58295041]\n",
      " [0.59088105]\n",
      " [0.59881145]\n",
      " [0.6060605 ]\n",
      " [0.61285686]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.6200807]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[[0.56005567]\n",
      "  [0.56750417]\n",
      "  [0.57504505]\n",
      "  [0.58295041]\n",
      "  [0.59088105]\n",
      "  [0.59881145]\n",
      "  [0.6060605 ]\n",
      "  [0.61285686]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008119652047753334\n",
      "Predicción post entrenamiento : [[0.6209779]]\n",
      "PERDIDAAAA despues: 0.007958770729601383\n",
      "loss en el callback: 0.03483625501394272, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "ejemplar: [[0.56750417]\n",
      " [0.57504505]\n",
      " [0.58295041]\n",
      " [0.59088105]\n",
      " [0.59881145]\n",
      " [0.6060605 ]\n",
      " [0.61285686]\n",
      " [0.62008071]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.6273677]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[[0.56750417]\n",
      "  [0.57504505]\n",
      "  [0.58295041]\n",
      "  [0.59088105]\n",
      "  [0.59881145]\n",
      "  [0.6060605 ]\n",
      "  [0.61285686]\n",
      "  [0.62008071]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007184158079326153\n",
      "Predicción post entrenamiento : [[0.62783563]]\n",
      "PERDIDAAAA despues: 0.007105050142854452\n",
      "loss en el callback: 0.007071056868880987, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "ejemplar: [[0.57504505]\n",
      " [0.58295041]\n",
      " [0.59088105]\n",
      " [0.59881145]\n",
      " [0.6060605 ]\n",
      " [0.61285686]\n",
      " [0.62008071]\n",
      " [0.62736768]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.63427633]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[[0.57504505]\n",
      "  [0.58295041]\n",
      "  [0.59088105]\n",
      "  [0.59881145]\n",
      "  [0.6060605 ]\n",
      "  [0.61285686]\n",
      "  [0.62008071]\n",
      "  [0.62736768]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011100622825324535\n",
      "Predicción post entrenamiento : [[0.6350386]]\n",
      "PERDIDAAAA despues: 0.010940576903522015\n",
      "loss en el callback: 0.02087998017668724, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "ejemplar: [[0.58295041]\n",
      " [0.59088105]\n",
      " [0.59881145]\n",
      " [0.6060605 ]\n",
      " [0.61285686]\n",
      " [0.62008071]\n",
      " [0.62736768]\n",
      " [0.63427633]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.6414924]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[[0.58295041]\n",
      "  [0.59088105]\n",
      "  [0.59881145]\n",
      "  [0.6060605 ]\n",
      "  [0.61285686]\n",
      "  [0.62008071]\n",
      "  [0.62736768]\n",
      "  [0.63427633]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008959824219346046\n",
      "Predicción post entrenamiento : [[0.64170235]]\n",
      "PERDIDAAAA despues: 0.008920126594603062\n",
      "loss en el callback: 0.0011186518240720034, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "ejemplar: [[0.59088105]\n",
      " [0.59881145]\n",
      " [0.6060605 ]\n",
      " [0.61285686]\n",
      " [0.62008071]\n",
      " [0.62736768]\n",
      " [0.63427633]\n",
      " [0.64149243]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.6480484]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[[0.59088105]\n",
      "  [0.59881145]\n",
      "  [0.6060605 ]\n",
      "  [0.61285686]\n",
      "  [0.62008071]\n",
      "  [0.62736768]\n",
      "  [0.63427633]\n",
      "  [0.64149243]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00038112056790851057\n",
      "Predicción post entrenamiento : [[0.6480818]]\n",
      "PERDIDAAAA despues: 0.00037981843343004584\n",
      "loss en el callback: 3.449941868893802e-05, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "ejemplar: [[0.59881145]\n",
      " [0.6060605 ]\n",
      " [0.61285686]\n",
      " [0.62008071]\n",
      " [0.62736768]\n",
      " [0.63427633]\n",
      " [0.64149243]\n",
      " [0.6480484 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.65427476]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[[0.59881145]\n",
      "  [0.6060605 ]\n",
      "  [0.61285686]\n",
      "  [0.62008071]\n",
      "  [0.62736768]\n",
      "  [0.63427633]\n",
      "  [0.64149243]\n",
      "  [0.6480484 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00024400466645602137\n",
      "Predicción post entrenamiento : [[0.65429395]]\n",
      "PERDIDAAAA despues: 0.00024340543313883245\n",
      "loss en el callback: 1.2081082786608022e-05, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "ejemplar: [[0.6060605 ]\n",
      " [0.61285686]\n",
      " [0.62008071]\n",
      " [0.62736768]\n",
      " [0.63427633]\n",
      " [0.64149243]\n",
      " [0.6480484 ]\n",
      " [0.65427476]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.66029143]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[[0.6060605 ]\n",
      "  [0.61285686]\n",
      "  [0.62008071]\n",
      "  [0.62736768]\n",
      "  [0.63427633]\n",
      "  [0.64149243]\n",
      "  [0.6480484 ]\n",
      "  [0.65427476]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013204351998865604\n",
      "Predicción post entrenamiento : [[0.66040564]]\n",
      "PERDIDAAAA despues: 0.0013121485244482756\n",
      "loss en el callback: 0.00044060320942662656, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "ejemplar: [[0.61285686]\n",
      " [0.62008071]\n",
      " [0.62736768]\n",
      " [0.63427633]\n",
      " [0.64149243]\n",
      " [0.6480484 ]\n",
      " [0.65427476]\n",
      " [0.66029143]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.6663452]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[[0.61285686]\n",
      "  [0.62008071]\n",
      "  [0.62736768]\n",
      "  [0.63427633]\n",
      "  [0.64149243]\n",
      "  [0.6480484 ]\n",
      "  [0.65427476]\n",
      "  [0.66029143]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00010811531683430076\n",
      "Predicción post entrenamiento : [[0.6669316]]\n",
      "PERDIDAAAA despues: 0.00012065488408552483\n",
      "loss en el callback: 0.017748510465025902, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "ejemplar: [[0.62008071]\n",
      " [0.62736768]\n",
      " [0.63427633]\n",
      " [0.64149243]\n",
      " [0.6480484 ]\n",
      " [0.65427476]\n",
      " [0.66029143]\n",
      " [0.66634518]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.67290473]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[[0.62008071]\n",
      "  [0.62736768]\n",
      "  [0.63427633]\n",
      "  [0.64149243]\n",
      "  [0.6480484 ]\n",
      "  [0.65427476]\n",
      "  [0.66029143]\n",
      "  [0.66634518]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.483281034277752e-05\n",
      "Predicción post entrenamiento : [[0.6717063]]\n",
      "PERDIDAAAA despues: 5.041488111601211e-05\n",
      "loss en el callback: 0.034061845391988754, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "ejemplar: [[0.62736768]\n",
      " [0.63427633]\n",
      " [0.64149243]\n",
      " [0.6480484 ]\n",
      " [0.65427476]\n",
      " [0.66029143]\n",
      " [0.66634518]\n",
      " [0.67290473]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.6775681]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[[0.62736768]\n",
      "  [0.63427633]\n",
      "  [0.64149243]\n",
      "  [0.6480484 ]\n",
      "  [0.65427476]\n",
      "  [0.66029143]\n",
      "  [0.66634518]\n",
      "  [0.67290473]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.171337882828084e-06\n",
      "Predicción post entrenamiento : [[0.6770266]]\n",
      "PERDIDAAAA despues: 8.688056141181733e-07\n",
      "loss en el callback: 0.007911430671811104, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "ejemplar: [[0.63427633]\n",
      " [0.64149243]\n",
      " [0.6480484 ]\n",
      " [0.65427476]\n",
      " [0.66029143]\n",
      " [0.66634518]\n",
      " [0.67290473]\n",
      " [0.67756808]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.6827112]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[[0.63427633]\n",
      "  [0.64149243]\n",
      "  [0.6480484 ]\n",
      "  [0.65427476]\n",
      "  [0.66029143]\n",
      "  [0.66634518]\n",
      "  [0.67290473]\n",
      "  [0.67756808]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002195014152675867\n",
      "Predicción post entrenamiento : [[0.6831247]]\n",
      "PERDIDAAAA despues: 0.00215643597766757\n",
      "loss en el callback: 0.006899878848344088, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "ejemplar: [[0.64149243]\n",
      " [0.6480484 ]\n",
      " [0.65427476]\n",
      " [0.66029143]\n",
      " [0.66634518]\n",
      " [0.67290473]\n",
      " [0.67756808]\n",
      " [0.68271118]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.68867457]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[[0.64149243]\n",
      "  [0.6480484 ]\n",
      "  [0.65427476]\n",
      "  [0.66029143]\n",
      "  [0.66634518]\n",
      "  [0.67290473]\n",
      "  [0.67756808]\n",
      "  [0.68271118]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00015886077017057687\n",
      "Predicción post entrenamiento : [[0.6887596]]\n",
      "PERDIDAAAA despues: 0.0001567239232826978\n",
      "loss en el callback: 0.000265826762188226, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "ejemplar: [[0.6480484 ]\n",
      " [0.65427476]\n",
      " [0.66029143]\n",
      " [0.66634518]\n",
      " [0.67290473]\n",
      " [0.67756808]\n",
      " [0.68271118]\n",
      " [0.68867457]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.69403553]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[[0.6480484 ]\n",
      "  [0.65427476]\n",
      "  [0.66029143]\n",
      "  [0.66634518]\n",
      "  [0.67290473]\n",
      "  [0.67756808]\n",
      "  [0.68271118]\n",
      "  [0.68867457]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005401729606091976\n",
      "Predicción post entrenamiento : [[0.69435745]]\n",
      "PERDIDAAAA despues: 0.005354512948542833\n",
      "loss en el callback: 0.003739550244063139, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "ejemplar: [[0.65427476]\n",
      " [0.66029143]\n",
      " [0.66634518]\n",
      " [0.67290473]\n",
      " [0.67756808]\n",
      " [0.68271118]\n",
      " [0.68867457]\n",
      " [0.69403553]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.69947433]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[[0.65427476]\n",
      "  [0.66029143]\n",
      "  [0.66634518]\n",
      "  [0.67290473]\n",
      "  [0.67756808]\n",
      "  [0.68271118]\n",
      "  [0.68867457]\n",
      "  [0.69403553]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0030979637522250414\n",
      "Predicción post entrenamiento : [[0.6993505]]\n",
      "PERDIDAAAA despues: 0.0031117666512727737\n",
      "loss en el callback: 0.0004530536534730345, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "ejemplar: [[0.66029143]\n",
      " [0.66634518]\n",
      " [0.67290473]\n",
      " [0.67756808]\n",
      " [0.68271118]\n",
      " [0.68867457]\n",
      " [0.69403553]\n",
      " [0.69947433]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.70435286]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[[0.66029143]\n",
      "  [0.66634518]\n",
      "  [0.67290473]\n",
      "  [0.67756808]\n",
      "  [0.68271118]\n",
      "  [0.68867457]\n",
      "  [0.69403553]\n",
      "  [0.69947433]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016570737352594733\n",
      "Predicción post entrenamiento : [[0.7042224]]\n",
      "PERDIDAAAA despues: 0.0016677132807672024\n",
      "loss en el callback: 0.0005304432706907392, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "ejemplar: [[0.66634518]\n",
      " [0.67290473]\n",
      " [0.67756808]\n",
      " [0.68271118]\n",
      " [0.68867457]\n",
      " [0.69403553]\n",
      " [0.69947433]\n",
      " [0.70435286]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.7091307]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[[0.66634518]\n",
      "  [0.67290473]\n",
      "  [0.67756808]\n",
      "  [0.68271118]\n",
      "  [0.68867457]\n",
      "  [0.69403553]\n",
      "  [0.69947433]\n",
      "  [0.70435286]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001840698649175465\n",
      "Predicción post entrenamiento : [[0.7086684]]\n",
      "PERDIDAAAA despues: 0.0018805802101269364\n",
      "loss en el callback: 0.006182156968861818, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "ejemplar: [[0.67290473]\n",
      " [0.67756808]\n",
      " [0.68271118]\n",
      " [0.68867457]\n",
      " [0.69403553]\n",
      " [0.69947433]\n",
      " [0.70435286]\n",
      " [0.7091307 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.7134376]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[[0.67290473]\n",
      "  [0.67756808]\n",
      "  [0.68271118]\n",
      "  [0.68867457]\n",
      "  [0.69403553]\n",
      "  [0.69947433]\n",
      "  [0.70435286]\n",
      "  [0.7091307 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.3214880709710997e-05\n",
      "Predicción post entrenamiento : [[0.7136154]]\n",
      "PERDIDAAAA despues: 1.4539185031026136e-05\n",
      "loss en el callback: 0.0013217610539868474, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "ejemplar: [[0.67756808]\n",
      " [0.68271118]\n",
      " [0.68867457]\n",
      " [0.69403553]\n",
      " [0.69947433]\n",
      " [0.70435286]\n",
      " [0.7091307 ]\n",
      " [0.71343762]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.718068]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[[0.67756808]\n",
      "  [0.68271118]\n",
      "  [0.68867457]\n",
      "  [0.69403553]\n",
      "  [0.69947433]\n",
      "  [0.70435286]\n",
      "  [0.7091307 ]\n",
      "  [0.71343762]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007638567476533353\n",
      "Predicción post entrenamiento : [[0.7179108]]\n",
      "PERDIDAAAA despues: 0.0007551933522336185\n",
      "loss en el callback: 0.0009566122316755354, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "ejemplar: [[0.68271118]\n",
      " [0.68867457]\n",
      " [0.69403553]\n",
      " [0.69947433]\n",
      " [0.70435286]\n",
      " [0.7091307 ]\n",
      " [0.71343762]\n",
      " [0.718068  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.72250694]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[[0.68271118]\n",
      "  [0.68867457]\n",
      "  [0.69403553]\n",
      "  [0.69947433]\n",
      "  [0.70435286]\n",
      "  [0.7091307 ]\n",
      "  [0.71343762]\n",
      "  [0.718068  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010145389242097735\n",
      "Predicción post entrenamiento : [[0.72121984]]\n",
      "PERDIDAAAA despues: 0.0010981886880472302\n",
      "loss en el callback: 0.04194324091076851, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "ejemplar: [[0.68867457]\n",
      " [0.69403553]\n",
      " [0.69947433]\n",
      " [0.70435286]\n",
      " [0.7091307 ]\n",
      " [0.71343762]\n",
      " [0.718068  ]\n",
      " [0.72250694]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.72581846]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[[0.68867457]\n",
      "  [0.69403553]\n",
      "  [0.69947433]\n",
      "  [0.70435286]\n",
      "  [0.7091307 ]\n",
      "  [0.71343762]\n",
      "  [0.718068  ]\n",
      "  [0.72250694]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.3088212654110976e-05\n",
      "Predicción post entrenamiento : [[0.7258112]]\n",
      "PERDIDAAAA despues: 1.3035651136306114e-05\n",
      "loss en el callback: 2.2105095922597684e-06, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "ejemplar: [[0.69403553]\n",
      " [0.69947433]\n",
      " [0.70435286]\n",
      " [0.7091307 ]\n",
      " [0.71343762]\n",
      " [0.718068  ]\n",
      " [0.72250694]\n",
      " [0.72581846]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.7301526]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[[0.69403553]\n",
      "  [0.69947433]\n",
      "  [0.70435286]\n",
      "  [0.7091307 ]\n",
      "  [0.71343762]\n",
      "  [0.718068  ]\n",
      "  [0.72250694]\n",
      "  [0.72581846]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014008083380758762\n",
      "Predicción post entrenamiento : [[0.7307327]]\n",
      "PERDIDAAAA despues: 0.013871110044419765\n",
      "loss en el callback: 0.01383297611027956, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "ejemplar: [[0.69947433]\n",
      " [0.70435286]\n",
      " [0.7091307 ]\n",
      " [0.71343762]\n",
      " [0.718068  ]\n",
      " [0.72250694]\n",
      " [0.72581846]\n",
      " [0.73015261]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.734914]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[[0.69947433]\n",
      "  [0.70435286]\n",
      "  [0.7091307 ]\n",
      "  [0.71343762]\n",
      "  [0.718068  ]\n",
      "  [0.72250694]\n",
      "  [0.72581846]\n",
      "  [0.73015261]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.029086953029036522\n",
      "Predicción post entrenamiento : [[0.73467904]]\n",
      "PERDIDAAAA despues: 0.02916715294122696\n",
      "loss en el callback: 0.001423677196726203, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "ejemplar: [[0.70435286]\n",
      " [0.7091307 ]\n",
      " [0.71343762]\n",
      " [0.718068  ]\n",
      " [0.72250694]\n",
      " [0.72581846]\n",
      " [0.73015261]\n",
      " [0.734914  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.73862934]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[[0.70435286]\n",
      "  [0.7091307 ]\n",
      "  [0.71343762]\n",
      "  [0.718068  ]\n",
      "  [0.72250694]\n",
      "  [0.72581846]\n",
      "  [0.73015261]\n",
      "  [0.734914  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02061719074845314\n",
      "Predicción post entrenamiento : [[0.73869824]]\n",
      "PERDIDAAAA despues: 0.020597407594323158\n",
      "loss en el callback: 0.00014476405340246856, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "ejemplar: [[0.7091307 ]\n",
      " [0.71343762]\n",
      " [0.718068  ]\n",
      " [0.72250694]\n",
      " [0.72581846]\n",
      " [0.73015261]\n",
      " [0.734914  ]\n",
      " [0.73862934]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.7425227]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[[0.7091307 ]\n",
      "  [0.71343762]\n",
      "  [0.718068  ]\n",
      "  [0.72250694]\n",
      "  [0.72581846]\n",
      "  [0.73015261]\n",
      "  [0.734914  ]\n",
      "  [0.73862934]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02731250785291195\n",
      "Predicción post entrenamiento : [[0.7429675]]\n",
      "PERDIDAAAA despues: 0.027165696024894714\n",
      "loss en el callback: 0.006737000308930874, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "ejemplar: [[0.71343762]\n",
      " [0.718068  ]\n",
      " [0.72250694]\n",
      " [0.72581846]\n",
      " [0.73015261]\n",
      " [0.734914  ]\n",
      " [0.73862934]\n",
      " [0.74252272]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.7466625]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[[0.71343762]\n",
      "  [0.718068  ]\n",
      "  [0.72250694]\n",
      "  [0.72581846]\n",
      "  [0.73015261]\n",
      "  [0.734914  ]\n",
      "  [0.73862934]\n",
      "  [0.74252272]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.020424751564860344\n",
      "Predicción post entrenamiento : [[0.74739486]]\n",
      "PERDIDAAAA despues: 0.02021595649421215\n",
      "loss en el callback: 0.02216898277401924, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "ejemplar: [[0.718068  ]\n",
      " [0.72250694]\n",
      " [0.72581846]\n",
      " [0.73015261]\n",
      " [0.734914  ]\n",
      " [0.73862934]\n",
      " [0.74252272]\n",
      " [0.7466625 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.75106347]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[[0.718068  ]\n",
      "  [0.72250694]\n",
      "  [0.72581846]\n",
      "  [0.73015261]\n",
      "  [0.734914  ]\n",
      "  [0.73862934]\n",
      "  [0.74252272]\n",
      "  [0.7466625 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015324265696108341\n",
      "Predicción post entrenamiento : [[0.7517521]]\n",
      "PERDIDAAAA despues: 0.015154251828789711\n",
      "loss en el callback: 0.02005542628467083, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "ejemplar: [[0.72250694]\n",
      " [0.72581846]\n",
      " [0.73015261]\n",
      " [0.734914  ]\n",
      " [0.73862934]\n",
      " [0.74252272]\n",
      " [0.7466625 ]\n",
      " [0.75106347]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.7552954]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[[0.72250694]\n",
      "  [0.72581846]\n",
      "  [0.73015261]\n",
      "  [0.734914  ]\n",
      "  [0.73862934]\n",
      "  [0.74252272]\n",
      "  [0.7466625 ]\n",
      "  [0.75106347]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02493763528764248\n",
      "Predicción post entrenamiento : [[0.7556397]]\n",
      "PERDIDAAAA despues: 0.024829020723700523\n",
      "loss en el callback: 0.004160415846854448, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "ejemplar: [[0.72581846]\n",
      " [0.73015261]\n",
      " [0.734914  ]\n",
      " [0.73862934]\n",
      " [0.74252272]\n",
      " [0.7466625 ]\n",
      " [0.75106347]\n",
      " [0.7552954 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 1.0\n",
      "Predicción : [[0.75909495]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[[0.72581846]\n",
      "  [0.73015261]\n",
      "  [0.734914  ]\n",
      "  [0.73862934]\n",
      "  [0.74252272]\n",
      "  [0.7466625 ]\n",
      "  [0.75106347]\n",
      "  [0.7552954 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.058035239577293396\n",
      "Predicción post entrenamiento : [[0.75946844]]\n",
      "PERDIDAAAA despues: 0.05785543471574783\n",
      "loss en el callback: 0.004317530896514654, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "ejemplar: [[0.73015261]\n",
      " [0.734914  ]\n",
      " [0.73862934]\n",
      " [0.74252272]\n",
      " [0.7466625 ]\n",
      " [0.75106347]\n",
      " [0.7552954 ]\n",
      " [0.75909495]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.76313907]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[[0.73015261]\n",
      "  [0.734914  ]\n",
      "  [0.73862934]\n",
      "  [0.74252272]\n",
      "  [0.7466625 ]\n",
      "  [0.75106347]\n",
      "  [0.7552954 ]\n",
      "  [0.75909495]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04302097484469414\n",
      "Predicción post entrenamiento : [[0.7637982]]\n",
      "PERDIDAAAA despues: 0.042747993022203445\n",
      "loss en el callback: 0.015877708792686462, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "ejemplar: [[0.734914  ]\n",
      " [0.73862934]\n",
      " [0.74252272]\n",
      " [0.7466625 ]\n",
      " [0.75106347]\n",
      " [0.7552954 ]\n",
      " [0.75909495]\n",
      " [0.76313907]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.76742524]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[[0.734914  ]\n",
      "  [0.73862934]\n",
      "  [0.74252272]\n",
      "  [0.7466625 ]\n",
      "  [0.75106347]\n",
      "  [0.7552954 ]\n",
      "  [0.75909495]\n",
      "  [0.76313907]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01473250426352024\n",
      "Predicción post entrenamiento : [[0.76791126]]\n",
      "PERDIDAAAA despues: 0.014614757150411606\n",
      "loss en el callback: 0.010046467185020447, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "ejemplar: [[0.73862934]\n",
      " [0.74252272]\n",
      " [0.7466625 ]\n",
      " [0.75106347]\n",
      " [0.7552954 ]\n",
      " [0.75909495]\n",
      " [0.76313907]\n",
      " [0.76742524]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.7713666]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[[0.73862934]\n",
      "  [0.74252272]\n",
      "  [0.7466625 ]\n",
      "  [0.75106347]\n",
      "  [0.7552954 ]\n",
      "  [0.75909495]\n",
      "  [0.76313907]\n",
      "  [0.76742524]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011360939592123032\n",
      "Predicción post entrenamiento : [[0.77140063]]\n",
      "PERDIDAAAA despues: 0.011353685520589352\n",
      "loss en el callback: 4.2164108890574425e-05, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "ejemplar: [[0.74252272]\n",
      " [0.7466625 ]\n",
      " [0.75106347]\n",
      " [0.7552954 ]\n",
      " [0.75909495]\n",
      " [0.76313907]\n",
      " [0.76742524]\n",
      " [0.7713666 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.7749536]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[[0.74252272]\n",
      "  [0.7466625 ]\n",
      "  [0.75106347]\n",
      "  [0.7552954 ]\n",
      "  [0.75909495]\n",
      "  [0.76313907]\n",
      "  [0.76742524]\n",
      "  [0.7713666 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005467446520924568\n",
      "Predicción post entrenamiento : [[0.7749732]]\n",
      "PERDIDAAAA despues: 0.005464546848088503\n",
      "loss en el callback: 1.4958993233449291e-05, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "ejemplar: [[0.7466625 ]\n",
      " [0.75106347]\n",
      " [0.7552954 ]\n",
      " [0.75909495]\n",
      " [0.76313907]\n",
      " [0.76742524]\n",
      " [0.7713666 ]\n",
      " [0.7749536 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.7785843]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[[0.7466625 ]\n",
      "  [0.75106347]\n",
      "  [0.7552954 ]\n",
      "  [0.75909495]\n",
      "  [0.76313907]\n",
      "  [0.76742524]\n",
      "  [0.7713666 ]\n",
      "  [0.7749536 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003090079640969634\n",
      "Predicción post entrenamiento : [[0.7788528]]\n",
      "PERDIDAAAA despues: 0.0030602985061705112\n",
      "loss en el callback: 0.0033758715726435184, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "ejemplar: [[0.75106347]\n",
      " [0.7552954 ]\n",
      " [0.75909495]\n",
      " [0.76313907]\n",
      " [0.76742524]\n",
      " [0.7713666 ]\n",
      " [0.7749536 ]\n",
      " [0.7785843 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.78245085]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[[0.75106347]\n",
      "  [0.7552954 ]\n",
      "  [0.75909495]\n",
      "  [0.76313907]\n",
      "  [0.76742524]\n",
      "  [0.7713666 ]\n",
      "  [0.7749536 ]\n",
      "  [0.7785843 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005277158692479134\n",
      "Predicción post entrenamiento : [[0.7825329]]\n",
      "PERDIDAAAA despues: 0.005265249405056238\n",
      "loss en el callback: 0.00028359098359942436, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "ejemplar: [[0.7552954 ]\n",
      " [0.75909495]\n",
      " [0.76313907]\n",
      " [0.76742524]\n",
      " [0.7713666 ]\n",
      " [0.7749536 ]\n",
      " [0.7785843 ]\n",
      " [0.78245085]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.78603095]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[[0.7552954 ]\n",
      "  [0.75909495]\n",
      "  [0.76313907]\n",
      "  [0.76742524]\n",
      "  [0.7713666 ]\n",
      "  [0.7749536 ]\n",
      "  [0.7785843 ]\n",
      "  [0.78245085]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007958643138408661\n",
      "Predicción post entrenamiento : [[0.78627187]]\n",
      "PERDIDAAAA despues: 0.007915714755654335\n",
      "loss en el callback: 0.002530450001358986, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "ejemplar: [[0.75909495]\n",
      " [0.76313907]\n",
      " [0.76742524]\n",
      " [0.7713666 ]\n",
      " [0.7749536 ]\n",
      " [0.7785843 ]\n",
      " [0.78245085]\n",
      " [0.78603095]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.78969264]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[[0.75909495]\n",
      "  [0.76313907]\n",
      "  [0.76742524]\n",
      "  [0.7713666 ]\n",
      "  [0.7749536 ]\n",
      "  [0.7785843 ]\n",
      "  [0.78245085]\n",
      "  [0.78603095]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004534613806754351\n",
      "Predicción post entrenamiento : [[0.7897991]]\n",
      "PERDIDAAAA despues: 0.004520287737250328\n",
      "loss en el callback: 0.00047587871085852385, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "ejemplar: [[0.76313907]\n",
      " [0.76742524]\n",
      " [0.7713666 ]\n",
      " [0.7749536 ]\n",
      " [0.7785843 ]\n",
      " [0.78245085]\n",
      " [0.78603095]\n",
      " [0.78969264]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.79324234]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[[0.76313907]\n",
      "  [0.76742524]\n",
      "  [0.7713666 ]\n",
      "  [0.7749536 ]\n",
      "  [0.7785843 ]\n",
      "  [0.78245085]\n",
      "  [0.78603095]\n",
      "  [0.78969264]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0032280355226248503\n",
      "Predicción post entrenamiento : [[0.793247]]\n",
      "PERDIDAAAA despues: 0.0032275072298943996\n",
      "loss en el callback: 8.566260021325434e-07, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "ejemplar: [[0.76742524]\n",
      " [0.7713666 ]\n",
      " [0.7749536 ]\n",
      " [0.7785843 ]\n",
      " [0.78245085]\n",
      " [0.78603095]\n",
      " [0.78969264]\n",
      " [0.79324234]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.79663485]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[[0.76742524]\n",
      "  [0.7713666 ]\n",
      "  [0.7749536 ]\n",
      "  [0.7785843 ]\n",
      "  [0.78245085]\n",
      "  [0.78603095]\n",
      "  [0.78969264]\n",
      "  [0.79324234]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002121685305610299\n",
      "Predicción post entrenamiento : [[0.7969764]]\n",
      "PERDIDAAAA despues: 0.002090338384732604\n",
      "loss en el callback: 0.006269831210374832, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "ejemplar: [[0.7713666 ]\n",
      " [0.7749536 ]\n",
      " [0.7785843 ]\n",
      " [0.78245085]\n",
      " [0.78603095]\n",
      " [0.78969264]\n",
      " [0.79324234]\n",
      " [0.79663485]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.80022234]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[[0.7713666 ]\n",
      "  [0.7749536 ]\n",
      "  [0.7785843 ]\n",
      "  [0.78245085]\n",
      "  [0.78603095]\n",
      "  [0.78969264]\n",
      "  [0.79324234]\n",
      "  [0.79663485]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005159483407624066\n",
      "Predicción post entrenamiento : [[0.8002436]]\n",
      "PERDIDAAAA despues: 0.000514982093591243\n",
      "loss en el callback: 2.2468728275271133e-05, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "ejemplar: [[0.7749536 ]\n",
      " [0.7785843 ]\n",
      " [0.78245085]\n",
      " [0.78603095]\n",
      " [0.78969264]\n",
      " [0.79324234]\n",
      " [0.79663485]\n",
      " [0.80022234]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.8034166]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[[0.7749536 ]\n",
      "  [0.7785843 ]\n",
      "  [0.78245085]\n",
      "  [0.78603095]\n",
      "  [0.78969264]\n",
      "  [0.79324234]\n",
      "  [0.79663485]\n",
      "  [0.80022234]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008358214981853962\n",
      "Predicción post entrenamiento : [[0.8035497]]\n",
      "PERDIDAAAA despues: 0.0008435350027866662\n",
      "loss en el callback: 0.001000206801109016, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "ejemplar: [[0.7785843 ]\n",
      " [0.78245085]\n",
      " [0.78603095]\n",
      " [0.78969264]\n",
      " [0.79324234]\n",
      " [0.79663485]\n",
      " [0.80022234]\n",
      " [0.80341661]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.80673236]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[[0.7785843 ]\n",
      "  [0.78245085]\n",
      "  [0.78603095]\n",
      "  [0.78969264]\n",
      "  [0.79324234]\n",
      "  [0.79663485]\n",
      "  [0.80022234]\n",
      "  [0.80341661]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005080611445009708\n",
      "Predicción post entrenamiento : [[0.80694467]]\n",
      "PERDIDAAAA despues: 0.0005176773411221802\n",
      "loss en el callback: 0.002645724220201373, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "ejemplar: [[0.78245085]\n",
      " [0.78603095]\n",
      " [0.78969264]\n",
      " [0.79324234]\n",
      " [0.79663485]\n",
      " [0.80022234]\n",
      " [0.80341661]\n",
      " [0.80673236]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.8101173]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[[0.78245085]\n",
      "  [0.78603095]\n",
      "  [0.78969264]\n",
      "  [0.79324234]\n",
      "  [0.79663485]\n",
      "  [0.80022234]\n",
      "  [0.80341661]\n",
      "  [0.80673236]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0024628397077322006\n",
      "Predicción post entrenamiento : [[0.8103071]]\n",
      "PERDIDAAAA despues: 0.002444039098918438\n",
      "loss en el callback: 0.0018130977405235171, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "ejemplar: [[0.78603095]\n",
      " [0.78969264]\n",
      " [0.79324234]\n",
      " [0.79663485]\n",
      " [0.80022234]\n",
      " [0.80341661]\n",
      " [0.80673236]\n",
      " [0.8101173 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.81339145]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[[0.78603095]\n",
      "  [0.78969264]\n",
      "  [0.79324234]\n",
      "  [0.79663485]\n",
      "  [0.80022234]\n",
      "  [0.80341661]\n",
      "  [0.80673236]\n",
      "  [0.8101173 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001675150473602116\n",
      "Predicción post entrenamiento : [[0.81295484]]\n",
      "PERDIDAAAA despues: 0.0017110803164541721\n",
      "loss en el callback: 0.008153351955115795, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "ejemplar: [[0.78969264]\n",
      " [0.79324234]\n",
      " [0.79663485]\n",
      " [0.80022234]\n",
      " [0.80341661]\n",
      " [0.80673236]\n",
      " [0.8101173 ]\n",
      " [0.81339145]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.8160099]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[[0.78969264]\n",
      "  [0.79324234]\n",
      "  [0.79663485]\n",
      "  [0.80022234]\n",
      "  [0.80341661]\n",
      "  [0.80673236]\n",
      "  [0.8101173 ]\n",
      "  [0.81339145]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004357671714387834\n",
      "Predicción post entrenamiento : [[0.8160028]]\n",
      "PERDIDAAAA despues: 0.00043606333201751113\n",
      "loss en el callback: 2.486051243977272e-06, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "ejemplar: [[0.79324234]\n",
      " [0.79663485]\n",
      " [0.80022234]\n",
      " [0.80341661]\n",
      " [0.80673236]\n",
      " [0.8101173 ]\n",
      " [0.81339145]\n",
      " [0.81600988]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.81899095]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[[0.79324234]\n",
      "  [0.79663485]\n",
      "  [0.80022234]\n",
      "  [0.80341661]\n",
      "  [0.80673236]\n",
      "  [0.8101173 ]\n",
      "  [0.81339145]\n",
      "  [0.81600988]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00011924483987968415\n",
      "Predicción post entrenamiento : [[0.8192879]]\n",
      "PERDIDAAAA despues: 0.00011284766515018418\n",
      "loss en el callback: 0.005732816178351641, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "ejemplar: [[0.79663485]\n",
      " [0.80022234]\n",
      " [0.80341661]\n",
      " [0.80673236]\n",
      " [0.8101173 ]\n",
      " [0.81339145]\n",
      " [0.81600988]\n",
      " [0.81899095]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.8222191]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[[0.79663485]\n",
      "  [0.80022234]\n",
      "  [0.80341661]\n",
      "  [0.80673236]\n",
      "  [0.8101173 ]\n",
      "  [0.81339145]\n",
      "  [0.81600988]\n",
      "  [0.81899095]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004229409620165825\n",
      "Predicción post entrenamiento : [[0.8227211]]\n",
      "PERDIDAAAA despues: 0.004164361394941807\n",
      "loss en el callback: 0.014311046339571476, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "ejemplar: [[0.80022234]\n",
      " [0.80341661]\n",
      " [0.80673236]\n",
      " [0.8101173 ]\n",
      " [0.81339145]\n",
      " [0.81600988]\n",
      " [0.81899095]\n",
      " [0.82221907]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.8256198]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[[0.80022234]\n",
      "  [0.80341661]\n",
      "  [0.80673236]\n",
      "  [0.8101173 ]\n",
      "  [0.81339145]\n",
      "  [0.81600988]\n",
      "  [0.81899095]\n",
      "  [0.82221907]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011644810438156128\n",
      "Predicción post entrenamiento : [[0.8250663]]\n",
      "PERDIDAAAA despues: 0.0012025624746456742\n",
      "loss en el callback: 0.012430314905941486, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "ejemplar: [[0.80341661]\n",
      " [0.80673236]\n",
      " [0.8101173 ]\n",
      " [0.81339145]\n",
      " [0.81600988]\n",
      " [0.81899095]\n",
      " [0.82221907]\n",
      " [0.82561982]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.82786286]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[[0.80341661]\n",
      "  [0.80673236]\n",
      "  [0.8101173 ]\n",
      "  [0.81339145]\n",
      "  [0.81600988]\n",
      "  [0.81899095]\n",
      "  [0.82221907]\n",
      "  [0.82561982]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00013769115321338177\n",
      "Predicción post entrenamiento : [[0.8280411]]\n",
      "PERDIDAAAA despues: 0.00013354043767321855\n",
      "loss en el callback: 0.0017930322792381048, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "ejemplar: [[0.80673236]\n",
      " [0.8101173 ]\n",
      " [0.81339145]\n",
      " [0.81600988]\n",
      " [0.81899095]\n",
      " [0.82221907]\n",
      " [0.82561982]\n",
      " [0.82786286]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.83082366]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[[0.80673236]\n",
      "  [0.8101173 ]\n",
      "  [0.81339145]\n",
      "  [0.81600988]\n",
      "  [0.81899095]\n",
      "  [0.82221907]\n",
      "  [0.82561982]\n",
      "  [0.82786286]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0022107812110334635\n",
      "Predicción post entrenamiento : [[0.8306898]]\n",
      "PERDIDAAAA despues: 0.00219820998609066\n",
      "loss en el callback: 0.000923328974749893, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "ejemplar: [[0.8101173 ]\n",
      " [0.81339145]\n",
      " [0.81600988]\n",
      " [0.81899095]\n",
      " [0.82221907]\n",
      " [0.82561982]\n",
      " [0.82786286]\n",
      " [0.83082366]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.8334112]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[[0.8101173 ]\n",
      "  [0.81339145]\n",
      "  [0.81600988]\n",
      "  [0.81899095]\n",
      "  [0.82221907]\n",
      "  [0.82561982]\n",
      "  [0.82786286]\n",
      "  [0.83082366]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002287270617671311\n",
      "Predicción post entrenamiento : [[0.8329895]]\n",
      "PERDIDAAAA despues: 0.00021614944853354245\n",
      "loss en el callback: 0.008349422365427017, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "ejemplar: [[0.81339145]\n",
      " [0.81600988]\n",
      " [0.81899095]\n",
      " [0.82221907]\n",
      " [0.82561982]\n",
      " [0.82786286]\n",
      " [0.83082366]\n",
      " [0.83341122]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.835611]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[[0.81339145]\n",
      "  [0.81600988]\n",
      "  [0.81899095]\n",
      "  [0.82221907]\n",
      "  [0.82561982]\n",
      "  [0.82786286]\n",
      "  [0.83082366]\n",
      "  [0.83341122]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0019753403030335903\n",
      "Predicción post entrenamiento : [[0.8358078]]\n",
      "PERDIDAAAA despues: 0.001992873614653945\n",
      "loss en el callback: 0.002511703409254551, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "ejemplar: [[0.81600988]\n",
      " [0.81899095]\n",
      " [0.82221907]\n",
      " [0.82561982]\n",
      " [0.82786286]\n",
      " [0.83082366]\n",
      " [0.83341122]\n",
      " [0.83561099]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.8383367]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[[0.81600988]\n",
      "  [0.81899095]\n",
      "  [0.82221907]\n",
      "  [0.82561982]\n",
      "  [0.82786286]\n",
      "  [0.83082366]\n",
      "  [0.83341122]\n",
      "  [0.83561099]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006049534771591425\n",
      "Predicción post entrenamiento : [[0.8381768]]\n",
      "PERDIDAAAA despues: 0.006024683825671673\n",
      "loss en el callback: 0.001538150361739099, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "ejemplar: [[0.81899095]\n",
      " [0.82221907]\n",
      " [0.82561982]\n",
      " [0.82786286]\n",
      " [0.83082366]\n",
      " [0.83341122]\n",
      " [0.83561099]\n",
      " [0.83833671]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.84077257]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[[0.81899095]\n",
      "  [0.82221907]\n",
      "  [0.82561982]\n",
      "  [0.82786286]\n",
      "  [0.83082366]\n",
      "  [0.83341122]\n",
      "  [0.83561099]\n",
      "  [0.83833671]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002422499470412731\n",
      "Predicción post entrenamiento : [[0.8400973]]\n",
      "PERDIDAAAA despues: 0.0023564842995256186\n",
      "loss en el callback: 0.02143056131899357, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "ejemplar: [[0.82221907]\n",
      " [0.82561982]\n",
      " [0.82786286]\n",
      " [0.83082366]\n",
      " [0.83341122]\n",
      " [0.83561099]\n",
      " [0.83833671]\n",
      " [0.84077257]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.84264994]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[[0.82221907]\n",
      "  [0.82561982]\n",
      "  [0.82786286]\n",
      "  [0.83082366]\n",
      "  [0.83341122]\n",
      "  [0.83561099]\n",
      "  [0.83833671]\n",
      "  [0.84077257]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005469439085572958\n",
      "Predicción post entrenamiento : [[0.8423884]]\n",
      "PERDIDAAAA despues: 0.005430821795016527\n",
      "loss en el callback: 0.004112436436116695, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "ejemplar: [[0.82561982]\n",
      " [0.82786286]\n",
      " [0.83082366]\n",
      " [0.83341122]\n",
      " [0.83561099]\n",
      " [0.83833671]\n",
      " [0.84077257]\n",
      " [0.84264994]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.84480214]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[[0.82561982]\n",
      "  [0.82786286]\n",
      "  [0.83082366]\n",
      "  [0.83341122]\n",
      "  [0.83561099]\n",
      "  [0.83833671]\n",
      "  [0.84077257]\n",
      "  [0.84264994]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005792406387627125\n",
      "Predicción post entrenamiento : [[0.843704]]\n",
      "PERDIDAAAA despues: 0.005626455415040255\n",
      "loss en el callback: 0.05323930084705353, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "ejemplar: [[0.82786286]\n",
      " [0.83082366]\n",
      " [0.83341122]\n",
      " [0.83561099]\n",
      " [0.83833671]\n",
      " [0.84077257]\n",
      " [0.84264994]\n",
      " [0.84480214]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.84589297]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[[0.82786286]\n",
      "  [0.83082366]\n",
      "  [0.83341122]\n",
      "  [0.83561099]\n",
      "  [0.83833671]\n",
      "  [0.84077257]\n",
      "  [0.84264994]\n",
      "  [0.84480214]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0022069152910262346\n",
      "Predicción post entrenamiento : [[0.84550554]]\n",
      "PERDIDAAAA despues: 0.002170664258301258\n",
      "loss en el callback: 0.00899981427937746, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "ejemplar: [[0.83082366]\n",
      " [0.83341122]\n",
      " [0.83561099]\n",
      " [0.83833671]\n",
      " [0.84077257]\n",
      " [0.84264994]\n",
      " [0.84480214]\n",
      " [0.84589297]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.84774643]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[[0.83082366]\n",
      "  [0.83341122]\n",
      "  [0.83561099]\n",
      "  [0.83833671]\n",
      "  [0.84077257]\n",
      "  [0.84264994]\n",
      "  [0.84480214]\n",
      "  [0.84589297]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0033342004753649235\n",
      "Predicción post entrenamiento : [[0.8474007]]\n",
      "PERDIDAAAA despues: 0.0032943959813565016\n",
      "loss en el callback: 0.007110175676643848, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "ejemplar: [[0.83341122]\n",
      " [0.83561099]\n",
      " [0.83833671]\n",
      " [0.84077257]\n",
      " [0.84264994]\n",
      " [0.84480214]\n",
      " [0.84589297]\n",
      " [0.84774643]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.84947395]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[[0.83341122]\n",
      "  [0.83561099]\n",
      "  [0.83833671]\n",
      "  [0.84077257]\n",
      "  [0.84264994]\n",
      "  [0.84480214]\n",
      "  [0.84589297]\n",
      "  [0.84774643]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007975113578140736\n",
      "Predicción post entrenamiento : [[0.8486653]]\n",
      "PERDIDAAAA despues: 0.007831335999071598\n",
      "loss en el callback: 0.033204011619091034, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "ejemplar: [[0.83561099]\n",
      " [0.83833671]\n",
      " [0.84077257]\n",
      " [0.84264994]\n",
      " [0.84480214]\n",
      " [0.84589297]\n",
      " [0.84774643]\n",
      " [0.84947395]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.85062903]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[[0.83561099]\n",
      "  [0.83833671]\n",
      "  [0.84077257]\n",
      "  [0.84264994]\n",
      "  [0.84480214]\n",
      "  [0.84589297]\n",
      "  [0.84774643]\n",
      "  [0.84947395]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.027302855625748634\n",
      "Predicción post entrenamiento : [[0.8485609]]\n",
      "PERDIDAAAA despues: 0.02662368305027485\n",
      "loss en el callback: 0.17463235557079315, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "ejemplar: [[0.83833671]\n",
      " [0.84077257]\n",
      " [0.84264994]\n",
      " [0.84480214]\n",
      " [0.84589297]\n",
      " [0.84774643]\n",
      " [0.84947395]\n",
      " [0.85062903]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.8504818]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[[0.83833671]\n",
      "  [0.84077257]\n",
      "  [0.84264994]\n",
      "  [0.84480214]\n",
      "  [0.84589297]\n",
      "  [0.84774643]\n",
      "  [0.84947395]\n",
      "  [0.85062903]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06016720458865166\n",
      "Predicción post entrenamiento : [[0.84953433]]\n",
      "PERDIDAAAA despues: 0.059703290462493896\n",
      "loss en el callback: 0.05722211301326752, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "ejemplar: [[0.84077257]\n",
      " [0.84264994]\n",
      " [0.84480214]\n",
      " [0.84589297]\n",
      " [0.84774643]\n",
      " [0.84947395]\n",
      " [0.85062903]\n",
      " [0.85048181]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.8512243]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[[0.84077257]\n",
      "  [0.84264994]\n",
      "  [0.84480214]\n",
      "  [0.84589297]\n",
      "  [0.84774643]\n",
      "  [0.84947395]\n",
      "  [0.85062903]\n",
      "  [0.85048181]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03473218157887459\n",
      "Predicción post entrenamiento : [[0.8508942]]\n",
      "PERDIDAAAA despues: 0.03460925817489624\n",
      "loss en el callback: 0.008031198754906654, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "ejemplar: [[0.84264994]\n",
      " [0.84480214]\n",
      " [0.84589297]\n",
      " [0.84774643]\n",
      " [0.84947395]\n",
      " [0.85062903]\n",
      " [0.85048181]\n",
      " [0.8512243 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.85236704]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[[0.84264994]\n",
      "  [0.84480214]\n",
      "  [0.84589297]\n",
      "  [0.84774643]\n",
      "  [0.84947395]\n",
      "  [0.85062903]\n",
      "  [0.85048181]\n",
      "  [0.8512243 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.020880788564682007\n",
      "Predicción post entrenamiento : [[0.85194606]]\n",
      "PERDIDAAAA despues: 0.020759299397468567\n",
      "loss en el callback: 0.011708584614098072, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "ejemplar: [[0.84480214]\n",
      " [0.84589297]\n",
      " [0.84774643]\n",
      " [0.84947395]\n",
      " [0.85062903]\n",
      " [0.85048181]\n",
      " [0.8512243 ]\n",
      " [0.85236704]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.85329694]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[[0.84480214]\n",
      "  [0.84589297]\n",
      "  [0.84774643]\n",
      "  [0.84947395]\n",
      "  [0.85062903]\n",
      "  [0.85048181]\n",
      "  [0.8512243 ]\n",
      "  [0.85236704]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03550901263952255\n",
      "Predicción post entrenamiento : [[0.8532891]]\n",
      "PERDIDAAAA despues: 0.03550606966018677\n",
      "loss en el callback: 5.77279070057557e-06, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "ejemplar: [[0.84589297]\n",
      " [0.84774643]\n",
      " [0.84947395]\n",
      " [0.85062903]\n",
      " [0.85048181]\n",
      " [0.8512243 ]\n",
      " [0.85236704]\n",
      " [0.85329694]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.85439575]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[[0.84589297]\n",
      "  [0.84774643]\n",
      "  [0.84947395]\n",
      "  [0.85062903]\n",
      "  [0.85048181]\n",
      "  [0.8512243 ]\n",
      "  [0.85236704]\n",
      "  [0.85329694]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.020461464300751686\n",
      "Predicción post entrenamiento : [[0.8535055]]\n",
      "PERDIDAAAA despues: 0.020207567140460014\n",
      "loss en el callback: 0.047357071191072464, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "ejemplar: [[0.84774643]\n",
      " [0.84947395]\n",
      " [0.85062903]\n",
      " [0.85048181]\n",
      " [0.8512243 ]\n",
      " [0.85236704]\n",
      " [0.85329694]\n",
      " [0.85439575]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.8546119]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[[0.84774643]\n",
      "  [0.84947395]\n",
      "  [0.85062903]\n",
      "  [0.85048181]\n",
      "  [0.8512243 ]\n",
      "  [0.85236704]\n",
      "  [0.85329694]\n",
      "  [0.85439575]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.031454794108867645\n",
      "Predicción post entrenamiento : [[0.8543197]]\n",
      "PERDIDAAAA despues: 0.031351238489151\n",
      "loss en el callback: 0.007074646186083555, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "ejemplar: [[0.84947395]\n",
      " [0.85062903]\n",
      " [0.85048181]\n",
      " [0.8512243 ]\n",
      " [0.85236704]\n",
      " [0.85329694]\n",
      " [0.85439575]\n",
      " [0.85461187]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.85519135]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[[0.84947395]\n",
      "  [0.85062903]\n",
      "  [0.85048181]\n",
      "  [0.8512243 ]\n",
      "  [0.85236704]\n",
      "  [0.85329694]\n",
      "  [0.85439575]\n",
      "  [0.85461187]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008664560504257679\n",
      "Predicción post entrenamiento : [[0.8551107]]\n",
      "PERDIDAAAA despues: 0.008649553172290325\n",
      "loss en el callback: 0.0005131198558956385, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "ejemplar: [[0.85062903]\n",
      " [0.85048181]\n",
      " [0.8512243 ]\n",
      " [0.85236704]\n",
      " [0.85329694]\n",
      " [0.85439575]\n",
      " [0.85461187]\n",
      " [0.85519135]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.8557399]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[[0.85062903]\n",
      "  [0.85048181]\n",
      "  [0.8512243 ]\n",
      "  [0.85236704]\n",
      "  [0.85329694]\n",
      "  [0.85439575]\n",
      "  [0.85461187]\n",
      "  [0.85519135]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002370555652305484\n",
      "Predicción post entrenamiento : [[0.85479903]]\n",
      "PERDIDAAAA despues: 0.0022798231802880764\n",
      "loss en el callback: 0.0470372810959816, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "ejemplar: [[0.85048181]\n",
      " [0.8512243 ]\n",
      " [0.85236704]\n",
      " [0.85329694]\n",
      " [0.85439575]\n",
      " [0.85461187]\n",
      " [0.85519135]\n",
      " [0.85573989]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.8553119]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[[0.85048181]\n",
      "  [0.8512243 ]\n",
      "  [0.85236704]\n",
      "  [0.85329694]\n",
      "  [0.85439575]\n",
      "  [0.85461187]\n",
      "  [0.85519135]\n",
      "  [0.85573989]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016099305357784033\n",
      "Predicción post entrenamiento : [[0.8551302]]\n",
      "PERDIDAAAA despues: 0.0015953844413161278\n",
      "loss en el callback: 0.002119269920513034, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "ejemplar: [[0.8512243 ]\n",
      " [0.85236704]\n",
      " [0.85329694]\n",
      " [0.85439575]\n",
      " [0.85461187]\n",
      " [0.85519135]\n",
      " [0.85573989]\n",
      " [0.85531187]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.85587174]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[[0.8512243 ]\n",
      "  [0.85236704]\n",
      "  [0.85329694]\n",
      "  [0.85439575]\n",
      "  [0.85461187]\n",
      "  [0.85519135]\n",
      "  [0.85573989]\n",
      "  [0.85531187]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0025367503985762596\n",
      "Predicción post entrenamiento : [[0.85622245]]\n",
      "PERDIDAAAA despues: 0.0025015452411025763\n",
      "loss en el callback: 0.009645176120102406, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "ejemplar: [[0.85236704]\n",
      " [0.85329694]\n",
      " [0.85439575]\n",
      " [0.85461187]\n",
      " [0.85519135]\n",
      " [0.85573989]\n",
      " [0.85531187]\n",
      " [0.85587174]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.8569564]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[[0.85236704]\n",
      "  [0.85329694]\n",
      "  [0.85439575]\n",
      "  [0.85461187]\n",
      "  [0.85519135]\n",
      "  [0.85573989]\n",
      "  [0.85531187]\n",
      "  [0.85587174]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010557379573583603\n",
      "Predicción post entrenamiento : [[0.8577432]]\n",
      "PERDIDAAAA despues: 0.010396316647529602\n",
      "loss en el callback: 0.05269914120435715, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "ejemplar: [[0.85329694]\n",
      " [0.85439575]\n",
      " [0.85461187]\n",
      " [0.85519135]\n",
      " [0.85573989]\n",
      " [0.85531187]\n",
      " [0.85587174]\n",
      " [0.85695642]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.85833836]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[[0.85329694]\n",
      "  [0.85439575]\n",
      "  [0.85461187]\n",
      "  [0.85519135]\n",
      "  [0.85573989]\n",
      "  [0.85531187]\n",
      "  [0.85587174]\n",
      "  [0.85695642]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011239501647651196\n",
      "Predicción post entrenamiento : [[0.8589174]]\n",
      "PERDIDAAAA despues: 0.011117057874798775\n",
      "loss en el callback: 0.02380252256989479, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "ejemplar: [[0.85439575]\n",
      " [0.85461187]\n",
      " [0.85519135]\n",
      " [0.85573989]\n",
      " [0.85531187]\n",
      " [0.85587174]\n",
      " [0.85695642]\n",
      " [0.85833836]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.85940814]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[[0.85439575]\n",
      "  [0.85461187]\n",
      "  [0.85519135]\n",
      "  [0.85573989]\n",
      "  [0.85531187]\n",
      "  [0.85587174]\n",
      "  [0.85695642]\n",
      "  [0.85833836]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000819091044832021\n",
      "Predicción post entrenamiento : [[0.8597156]]\n",
      "PERDIDAAAA despues: 0.0008015877683646977\n",
      "loss en el callback: 0.007213338278234005, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "ejemplar: [[0.85461187]\n",
      " [0.85519135]\n",
      " [0.85573989]\n",
      " [0.85531187]\n",
      " [0.85587174]\n",
      " [0.85695642]\n",
      " [0.85833836]\n",
      " [0.85940814]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.8600472]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[[0.85461187]\n",
      "  [0.85519135]\n",
      "  [0.85573989]\n",
      "  [0.85531187]\n",
      "  [0.85587174]\n",
      "  [0.85695642]\n",
      "  [0.85833836]\n",
      "  [0.85940814]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010647185845300555\n",
      "Predicción post entrenamiento : [[0.86012536]]\n",
      "PERDIDAAAA despues: 0.0010596251813694835\n",
      "loss en el callback: 0.00039943677256815135, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "ejemplar: [[0.85519135]\n",
      " [0.85573989]\n",
      " [0.85531187]\n",
      " [0.85587174]\n",
      " [0.85695642]\n",
      " [0.85833836]\n",
      " [0.85940814]\n",
      " [0.86004722]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.86054164]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[[0.85519135]\n",
      "  [0.85573989]\n",
      "  [0.85531187]\n",
      "  [0.85587174]\n",
      "  [0.85695642]\n",
      "  [0.85833836]\n",
      "  [0.85940814]\n",
      "  [0.86004722]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00021610563271678984\n",
      "Predicción post entrenamiento : [[0.86052674]]\n",
      "PERDIDAAAA despues: 0.0002165439655072987\n",
      "loss en el callback: 1.5518795407842845e-05, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "ejemplar: [[0.85573989]\n",
      " [0.85531187]\n",
      " [0.85587174]\n",
      " [0.85695642]\n",
      " [0.85833836]\n",
      " [0.85940814]\n",
      " [0.86004722]\n",
      " [0.86054164]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.860954]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[[0.85573989]\n",
      "  [0.85531187]\n",
      "  [0.85587174]\n",
      "  [0.85695642]\n",
      "  [0.85833836]\n",
      "  [0.85940814]\n",
      "  [0.86004722]\n",
      "  [0.86054164]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00010243439464829862\n",
      "Predicción post entrenamiento : [[0.8608628]]\n",
      "PERDIDAAAA despues: 0.00010059674241347238\n",
      "loss en el callback: 0.0005809912690892816, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "ejemplar: [[0.85531187]\n",
      " [0.85587174]\n",
      " [0.85695642]\n",
      " [0.85833836]\n",
      " [0.85940814]\n",
      " [0.86004722]\n",
      " [0.86054164]\n",
      " [0.86095399]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.861326]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[[0.85531187]\n",
      "  [0.85587174]\n",
      "  [0.85695642]\n",
      "  [0.85833836]\n",
      "  [0.85940814]\n",
      "  [0.86004722]\n",
      "  [0.86054164]\n",
      "  [0.86095399]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00015450964565388858\n",
      "Predicción post entrenamiento : [[0.86126363]]\n",
      "PERDIDAAAA despues: 0.00015296357742045075\n",
      "loss en el callback: 0.00029186109895817935, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "ejemplar: [[0.85587174]\n",
      " [0.85695642]\n",
      " [0.85833836]\n",
      " [0.85940814]\n",
      " [0.86004722]\n",
      " [0.86054164]\n",
      " [0.86095399]\n",
      " [0.86132598]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.8620482]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[[0.85587174]\n",
      "  [0.85695642]\n",
      "  [0.85833836]\n",
      "  [0.85940814]\n",
      "  [0.86004722]\n",
      "  [0.86054164]\n",
      "  [0.86095399]\n",
      "  [0.86132598]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010074026882648468\n",
      "Predicción post entrenamiento : [[0.86223733]]\n",
      "PERDIDAAAA despues: 0.010036097839474678\n",
      "loss en el callback: 0.002429045969620347, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "ejemplar: [[0.85695642]\n",
      " [0.85833836]\n",
      " [0.85940814]\n",
      " [0.86004722]\n",
      " [0.86054164]\n",
      " [0.86095399]\n",
      " [0.86132598]\n",
      " [0.86204821]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.86309874]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[[0.85695642]\n",
      "  [0.85833836]\n",
      "  [0.85940814]\n",
      "  [0.86004722]\n",
      "  [0.86054164]\n",
      "  [0.86095399]\n",
      "  [0.86132598]\n",
      "  [0.86204821]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010971134528517723\n",
      "Predicción post entrenamiento : [[0.863966]]\n",
      "PERDIDAAAA despues: 0.010790210217237473\n",
      "loss en el callback: 0.07997012138366699, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "ejemplar: [[0.85833836]\n",
      " [0.85940814]\n",
      " [0.86004722]\n",
      " [0.86054164]\n",
      " [0.86095399]\n",
      " [0.86132598]\n",
      " [0.86204821]\n",
      " [0.86309874]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.8647516]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[[0.85833836]\n",
      "  [0.85940814]\n",
      "  [0.86004722]\n",
      "  [0.86054164]\n",
      "  [0.86095399]\n",
      "  [0.86132598]\n",
      "  [0.86204821]\n",
      "  [0.86309874]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0057713040150702\n",
      "Predicción post entrenamiento : [[0.8651126]]\n",
      "PERDIDAAAA despues: 0.005716580897569656\n",
      "loss en el callback: 0.010485578328371048, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "ejemplar: [[0.85940814]\n",
      " [0.86004722]\n",
      " [0.86054164]\n",
      " [0.86095399]\n",
      " [0.86132598]\n",
      " [0.86204821]\n",
      " [0.86309874]\n",
      " [0.86475158]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.8657218]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[[0.85940814]\n",
      "  [0.86004722]\n",
      "  [0.86054164]\n",
      "  [0.86095399]\n",
      "  [0.86132598]\n",
      "  [0.86204821]\n",
      "  [0.86309874]\n",
      "  [0.86475158]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011399714276194572\n",
      "Predicción post entrenamiento : [[0.8663366]]\n",
      "PERDIDAAAA despues: 0.011268815957009792\n",
      "loss en el callback: 0.03236859664320946, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "ejemplar: [[0.86004722]\n",
      " [0.86054164]\n",
      " [0.86095399]\n",
      " [0.86132598]\n",
      " [0.86204821]\n",
      " [0.86309874]\n",
      " [0.86475158]\n",
      " [0.86572182]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.8668408]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[[0.86004722]\n",
      "  [0.86054164]\n",
      "  [0.86095399]\n",
      "  [0.86132598]\n",
      "  [0.86204821]\n",
      "  [0.86309874]\n",
      "  [0.86475158]\n",
      "  [0.86572182]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016915515065193176\n",
      "Predicción post entrenamiento : [[0.86740077]]\n",
      "PERDIDAAAA despues: 0.016770165413618088\n",
      "loss en el callback: 0.025472622364759445, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "ejemplar: [[0.86054164]\n",
      " [0.86095399]\n",
      " [0.86132598]\n",
      " [0.86204821]\n",
      " [0.86309874]\n",
      " [0.86475158]\n",
      " [0.86572182]\n",
      " [0.86684078]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.86792475]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[[0.86054164]\n",
      "  [0.86095399]\n",
      "  [0.86132598]\n",
      "  [0.86204821]\n",
      "  [0.86309874]\n",
      "  [0.86475158]\n",
      "  [0.86572182]\n",
      "  [0.86684078]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006931721232831478\n",
      "Predicción post entrenamiento : [[0.86833715]]\n",
      "PERDIDAAAA despues: 0.006863220129162073\n",
      "loss en el callback: 0.014911581762135029, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "ejemplar: [[0.86095399]\n",
      " [0.86132598]\n",
      " [0.86204821]\n",
      " [0.86309874]\n",
      " [0.86475158]\n",
      " [0.86572182]\n",
      " [0.86684078]\n",
      " [0.86792475]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.86894614]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[[0.86095399]\n",
      "  [0.86132598]\n",
      "  [0.86204821]\n",
      "  [0.86309874]\n",
      "  [0.86475158]\n",
      "  [0.86572182]\n",
      "  [0.86684078]\n",
      "  [0.86792475]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007198850507847965\n",
      "Predicción post entrenamiento : [[0.8692126]]\n",
      "PERDIDAAAA despues: 0.0007056557224132121\n",
      "loss en el callback: 0.0063895778730511665, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "ejemplar: [[0.86132598]\n",
      " [0.86204821]\n",
      " [0.86309874]\n",
      " [0.86475158]\n",
      " [0.86572182]\n",
      " [0.86684078]\n",
      " [0.86792475]\n",
      " [0.86894614]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.8699598]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[[0.86132598]\n",
      "  [0.86204821]\n",
      "  [0.86309874]\n",
      "  [0.86475158]\n",
      "  [0.86572182]\n",
      "  [0.86684078]\n",
      "  [0.86792475]\n",
      "  [0.86894614]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001318253780482337\n",
      "Predicción post entrenamiento : [[0.86967635]]\n",
      "PERDIDAAAA despues: 0.00013841390318702906\n",
      "loss en el callback: 0.005861820187419653, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "ejemplar: [[0.86204821]\n",
      " [0.86309874]\n",
      " [0.86475158]\n",
      " [0.86572182]\n",
      " [0.86684078]\n",
      " [0.86792475]\n",
      " [0.86894614]\n",
      " [0.86995977]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.8706033]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[[0.86204821]\n",
      "  [0.86309874]\n",
      "  [0.86475158]\n",
      "  [0.86572182]\n",
      "  [0.86684078]\n",
      "  [0.86792475]\n",
      "  [0.86894614]\n",
      "  [0.86995977]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002160678617656231\n",
      "Predicción post entrenamiento : [[0.87057847]]\n",
      "PERDIDAAAA despues: 0.002162989927455783\n",
      "loss en el callback: 4.59849507024046e-05, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "ejemplar: [[0.86309874]\n",
      " [0.86475158]\n",
      " [0.86572182]\n",
      " [0.86684078]\n",
      " [0.86792475]\n",
      " [0.86894614]\n",
      " [0.86995977]\n",
      " [0.87060332]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.8716099]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[[0.86309874]\n",
      "  [0.86475158]\n",
      "  [0.86572182]\n",
      "  [0.86684078]\n",
      "  [0.86792475]\n",
      "  [0.86894614]\n",
      "  [0.86995977]\n",
      "  [0.87060332]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002322143642231822\n",
      "Predicción post entrenamiento : [[0.87189996]]\n",
      "PERDIDAAAA despues: 0.002294274978339672\n",
      "loss en el callback: 0.007489725947380066, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "ejemplar: [[0.86475158]\n",
      " [0.86572182]\n",
      " [0.86684078]\n",
      " [0.86792475]\n",
      " [0.86894614]\n",
      " [0.86995977]\n",
      " [0.87060332]\n",
      " [0.87160993]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.8729491]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[[0.86475158]\n",
      "  [0.86572182]\n",
      "  [0.86684078]\n",
      "  [0.86792475]\n",
      "  [0.86894614]\n",
      "  [0.86995977]\n",
      "  [0.87060332]\n",
      "  [0.87160993]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007866568863391876\n",
      "Predicción post entrenamiento : [[0.87374794]]\n",
      "PERDIDAAAA despues: 0.007725506089627743\n",
      "loss en el callback: 0.09197843074798584, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "ejemplar: [[0.86572182]\n",
      " [0.86684078]\n",
      " [0.86792475]\n",
      " [0.86894614]\n",
      " [0.86995977]\n",
      " [0.87060332]\n",
      " [0.87160993]\n",
      " [0.87294912]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.8746396]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[[0.86572182]\n",
      "  [0.86684078]\n",
      "  [0.86792475]\n",
      "  [0.86894614]\n",
      "  [0.86995977]\n",
      "  [0.87060332]\n",
      "  [0.87160993]\n",
      "  [0.87294912]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008759047836065292\n",
      "Predicción post entrenamiento : [[0.8753252]]\n",
      "PERDIDAAAA despues: 0.008631180971860886\n",
      "loss en el callback: 0.05952140688896179, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "ejemplar: [[0.86684078]\n",
      " [0.86792475]\n",
      " [0.86894614]\n",
      " [0.86995977]\n",
      " [0.87060332]\n",
      " [0.87160993]\n",
      " [0.87294912]\n",
      " [0.87463957]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.8762312]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[[0.86684078]\n",
      "  [0.86792475]\n",
      "  [0.86894614]\n",
      "  [0.86995977]\n",
      "  [0.87060332]\n",
      "  [0.87160993]\n",
      "  [0.87294912]\n",
      "  [0.87463957]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006648303009569645\n",
      "Predicción post entrenamiento : [[0.87638944]]\n",
      "PERDIDAAAA despues: 0.006622521672397852\n",
      "loss en el callback: 0.0018465644679963589, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "ejemplar: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.23302631]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03493914380669594\n",
      "Predicción post entrenamiento : [[0.19444515]]\n",
      "PERDIDAAAA despues: 0.02200445532798767\n",
      "loss en el callback: 0.04666745662689209, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "ejemplar: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23302631]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.17894658]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23302631]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005583588965237141\n",
      "Predicción post entrenamiento : [[0.17123327]]\n",
      "PERDIDAAAA despues: 0.004490353167057037\n",
      "loss en el callback: 0.0030785012058913708, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "ejemplar: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23302631]\n",
      " [0.17894658]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.17530961]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23302631]\n",
      "  [0.17894658]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004454552545212209\n",
      "Predicción post entrenamiento : [[0.17560585]]\n",
      "PERDIDAAAA despues: 0.00045804757974110544\n",
      "loss en el callback: 1.1282512787147425e-05, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "ejemplar: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23302631]\n",
      " [0.17894658]\n",
      " [0.17530961]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.18699123]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23302631]\n",
      "  [0.17894658]\n",
      "  [0.17530961]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009757906082086265\n",
      "Predicción post entrenamiento : [[0.18324442]]\n",
      "PERDIDAAAA despues: 0.0007557462668046355\n",
      "loss en el callback: 0.0020305681973695755, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "ejemplar: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23302631]\n",
      " [0.17894658]\n",
      " [0.17530961]\n",
      " [0.18699123]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.19567719]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23302631]\n",
      "  [0.17894658]\n",
      "  [0.17530961]\n",
      "  [0.18699123]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004920243285596371\n",
      "Predicción post entrenamiento : [[0.19384342]]\n",
      "PERDIDAAAA despues: 0.004666348919272423\n",
      "loss en el callback: 0.0011751860147342086, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "ejemplar: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.23302631]\n",
      " [0.17894658]\n",
      " [0.17530961]\n",
      " [0.18699123]\n",
      " [0.19567719]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.20346382]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23302631]\n",
      "  [0.17894658]\n",
      "  [0.17530961]\n",
      "  [0.18699123]\n",
      "  [0.19567719]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0033389742020517588\n",
      "Predicción post entrenamiento : [[0.20311378]]\n",
      "PERDIDAAAA despues: 0.003298643045127392\n",
      "loss en el callback: 7.096677290974185e-05, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "ejemplar: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.23302631]\n",
      " [0.17894658]\n",
      " [0.17530961]\n",
      " [0.18699123]\n",
      " [0.19567719]\n",
      " [0.20346382]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.22358474]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23302631]\n",
      "  [0.17894658]\n",
      "  [0.17530961]\n",
      "  [0.18699123]\n",
      "  [0.19567719]\n",
      "  [0.20346382]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005949019454419613\n",
      "Predicción post entrenamiento : [[0.22053476]]\n",
      "PERDIDAAAA despues: 0.005487831775099039\n",
      "loss en el callback: 0.004734022542834282, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "ejemplar: [[0.04223169]\n",
      " [0.23302631]\n",
      " [0.17894658]\n",
      " [0.17530961]\n",
      " [0.18699123]\n",
      " [0.19567719]\n",
      " [0.20346382]\n",
      " [0.22358474]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.24523252]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[[0.04223169]\n",
      "  [0.23302631]\n",
      "  [0.17894658]\n",
      "  [0.17530961]\n",
      "  [0.18699123]\n",
      "  [0.19567719]\n",
      "  [0.20346382]\n",
      "  [0.22358474]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0024191136471927166\n",
      "Predicción post entrenamiento : [[0.24314919]]\n",
      "PERDIDAAAA despues: 0.0022185188718140125\n",
      "loss en el callback: 0.002670911606401205, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "ejemplar: [[0.23302631]\n",
      " [0.17894658]\n",
      " [0.17530961]\n",
      " [0.18699123]\n",
      " [0.19567719]\n",
      " [0.20346382]\n",
      " [0.22358474]\n",
      " [0.24523252]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.27238667]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[[0.23302631]\n",
      "  [0.17894658]\n",
      "  [0.17530961]\n",
      "  [0.18699123]\n",
      "  [0.19567719]\n",
      "  [0.20346382]\n",
      "  [0.22358474]\n",
      "  [0.24523252]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001751914038322866\n",
      "Predicción post entrenamiento : [[0.27058604]]\n",
      "PERDIDAAAA despues: 0.0016044226940721273\n",
      "loss en el callback: 0.00216320320032537, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "ejemplar: [[0.17894658]\n",
      " [0.17530961]\n",
      " [0.18699123]\n",
      " [0.19567719]\n",
      " [0.20346382]\n",
      " [0.22358474]\n",
      " [0.24523252]\n",
      " [0.27238667]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.26361752]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[[0.17894658]\n",
      "  [0.17530961]\n",
      "  [0.18699123]\n",
      "  [0.19567719]\n",
      "  [0.20346382]\n",
      "  [0.22358474]\n",
      "  [0.24523252]\n",
      "  [0.27238667]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003043858800083399\n",
      "Predicción post entrenamiento : [[0.26049262]]\n",
      "PERDIDAAAA despues: 0.002708815736696124\n",
      "loss en el callback: 0.006924569606781006, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "ejemplar: [[0.17530961]\n",
      " [0.18699123]\n",
      " [0.19567719]\n",
      " [0.20346382]\n",
      " [0.22358474]\n",
      " [0.24523252]\n",
      " [0.27238667]\n",
      " [0.26361752]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.26573637]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[[0.17530961]\n",
      "  [0.18699123]\n",
      "  [0.19567719]\n",
      "  [0.20346382]\n",
      "  [0.22358474]\n",
      "  [0.24523252]\n",
      "  [0.27238667]\n",
      "  [0.26361752]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002894764067605138\n",
      "Predicción post entrenamiento : [[0.26348788]]\n",
      "PERDIDAAAA despues: 0.0026578682009130716\n",
      "loss en el callback: 0.004864213988184929, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "ejemplar: [[0.18699123]\n",
      " [0.19567719]\n",
      " [0.20346382]\n",
      " [0.22358474]\n",
      " [0.24523252]\n",
      " [0.27238667]\n",
      " [0.26361752]\n",
      " [0.26573637]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.27196163]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[[0.18699123]\n",
      "  [0.19567719]\n",
      "  [0.20346382]\n",
      "  [0.22358474]\n",
      "  [0.24523252]\n",
      "  [0.27238667]\n",
      "  [0.26361752]\n",
      "  [0.26573637]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004183195065706968\n",
      "Predicción post entrenamiento : [[0.26899484]]\n",
      "PERDIDAAAA despues: 0.0038082271348685026\n",
      "loss en el callback: 0.009158728644251823, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "ejemplar: [[0.19567719]\n",
      " [0.20346382]\n",
      " [0.22358474]\n",
      " [0.24523252]\n",
      " [0.27238667]\n",
      " [0.26361752]\n",
      " [0.26573637]\n",
      " [0.27196163]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.27775407]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[[0.19567719]\n",
      "  [0.20346382]\n",
      "  [0.22358474]\n",
      "  [0.24523252]\n",
      "  [0.27238667]\n",
      "  [0.26361752]\n",
      "  [0.26573637]\n",
      "  [0.27196163]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00719198863953352\n",
      "Predicción post entrenamiento : [[0.27637678]]\n",
      "PERDIDAAAA despues: 0.006960282567888498\n",
      "loss en el callback: 0.0031330676283687353, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "ejemplar: [[0.20346382]\n",
      " [0.22358474]\n",
      " [0.24523252]\n",
      " [0.27238667]\n",
      " [0.26361752]\n",
      " [0.26573637]\n",
      " [0.27196163]\n",
      " [0.27775407]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.28596023]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[[0.20346382]\n",
      "  [0.22358474]\n",
      "  [0.24523252]\n",
      "  [0.27238667]\n",
      "  [0.26361752]\n",
      "  [0.26573637]\n",
      "  [0.27196163]\n",
      "  [0.27775407]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007945455610752106\n",
      "Predicción post entrenamiento : [[0.28495005]]\n",
      "PERDIDAAAA despues: 0.0077663869597017765\n",
      "loss en el callback: 0.002052492927759886, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "ejemplar: [[0.22358474]\n",
      " [0.24523252]\n",
      " [0.27238667]\n",
      " [0.26361752]\n",
      " [0.26573637]\n",
      " [0.27196163]\n",
      " [0.27775407]\n",
      " [0.28596023]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.29545483]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[[0.22358474]\n",
      "  [0.24523252]\n",
      "  [0.27238667]\n",
      "  [0.26361752]\n",
      "  [0.26573637]\n",
      "  [0.27196163]\n",
      "  [0.27775407]\n",
      "  [0.28596023]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00659291772171855\n",
      "Predicción post entrenamiento : [[0.29430875]]\n",
      "PERDIDAAAA despues: 0.006408115848898888\n",
      "loss en el callback: 0.0028540953062474728, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "ejemplar: [[0.24523252]\n",
      " [0.27238667]\n",
      " [0.26361752]\n",
      " [0.26573637]\n",
      " [0.27196163]\n",
      " [0.27775407]\n",
      " [0.28596023]\n",
      " [0.29545483]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.3028114]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[[0.24523252]\n",
      "  [0.27238667]\n",
      "  [0.26361752]\n",
      "  [0.26573637]\n",
      "  [0.27196163]\n",
      "  [0.27775407]\n",
      "  [0.28596023]\n",
      "  [0.29545483]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014758933335542679\n",
      "Predicción post entrenamiento : [[0.30050424]]\n",
      "PERDIDAAAA despues: 0.014203676022589207\n",
      "loss en el callback: 0.01179712638258934, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "ejemplar: [[0.27238667]\n",
      " [0.26361752]\n",
      " [0.26573637]\n",
      " [0.27196163]\n",
      " [0.27775407]\n",
      " [0.28596023]\n",
      " [0.29545483]\n",
      " [0.30281141]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.3061196]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[[0.27238667]\n",
      "  [0.26361752]\n",
      "  [0.26573637]\n",
      "  [0.27196163]\n",
      "  [0.27775407]\n",
      "  [0.28596023]\n",
      "  [0.29545483]\n",
      "  [0.30281141]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017159340903162956\n",
      "Predicción post entrenamiento : [[0.3029962]]\n",
      "PERDIDAAAA despues: 0.016350803896784782\n",
      "loss en el callback: 0.019758932292461395, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "ejemplar: [[0.26361752]\n",
      " [0.26573637]\n",
      " [0.27196163]\n",
      " [0.27775407]\n",
      " [0.28596023]\n",
      " [0.29545483]\n",
      " [0.30281141]\n",
      " [0.30611959]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.30395624]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[[0.26361752]\n",
      "  [0.26573637]\n",
      "  [0.27196163]\n",
      "  [0.27775407]\n",
      "  [0.28596023]\n",
      "  [0.29545483]\n",
      "  [0.30281141]\n",
      "  [0.30611959]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.024320898577570915\n",
      "Predicción post entrenamiento : [[0.30170235]]\n",
      "PERDIDAAAA despues: 0.02362298220396042\n",
      "loss en el callback: 0.016277549788355827, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "ejemplar: [[0.26573637]\n",
      " [0.27196163]\n",
      " [0.27775407]\n",
      " [0.28596023]\n",
      " [0.29545483]\n",
      " [0.30281141]\n",
      " [0.30611959]\n",
      " [0.30395624]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.30555972]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[[0.26573637]\n",
      "  [0.27196163]\n",
      "  [0.27775407]\n",
      "  [0.28596023]\n",
      "  [0.29545483]\n",
      "  [0.30281141]\n",
      "  [0.30611959]\n",
      "  [0.30395624]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02152281627058983\n",
      "Predicción post entrenamiento : [[0.3027674]]\n",
      "PERDIDAAAA despues: 0.02071130834519863\n",
      "loss en el callback: 0.02113531157374382, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "ejemplar: [[0.27196163]\n",
      " [0.27775407]\n",
      " [0.28596023]\n",
      " [0.29545483]\n",
      " [0.30281141]\n",
      " [0.30611959]\n",
      " [0.30395624]\n",
      " [0.30555972]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.3074504]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[[0.27196163]\n",
      "  [0.27775407]\n",
      "  [0.28596023]\n",
      "  [0.29545483]\n",
      "  [0.30281141]\n",
      "  [0.30611959]\n",
      "  [0.30395624]\n",
      "  [0.30555972]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013288750313222408\n",
      "Predicción post entrenamiento : [[0.30597386]]\n",
      "PERDIDAAAA despues: 0.012950505129992962\n",
      "loss en el callback: 0.0075294203124940395, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "ejemplar: [[0.27775407]\n",
      " [0.28596023]\n",
      " [0.29545483]\n",
      " [0.30281141]\n",
      " [0.30611959]\n",
      " [0.30395624]\n",
      " [0.30555972]\n",
      " [0.30745041]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.31055817]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[[0.27775407]\n",
      "  [0.28596023]\n",
      "  [0.29545483]\n",
      "  [0.30281141]\n",
      "  [0.30611959]\n",
      "  [0.30395624]\n",
      "  [0.30555972]\n",
      "  [0.30745041]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015521107241511345\n",
      "Predicción post entrenamiento : [[0.3079941]]\n",
      "PERDIDAAAA despues: 0.014888797886669636\n",
      "loss en el callback: 0.02106405608355999, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "ejemplar: [[0.28596023]\n",
      " [0.29545483]\n",
      " [0.30281141]\n",
      " [0.30611959]\n",
      " [0.30395624]\n",
      " [0.30555972]\n",
      " [0.30745041]\n",
      " [0.31055817]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.31242278]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[[0.28596023]\n",
      "  [0.29545483]\n",
      "  [0.30281141]\n",
      "  [0.30611959]\n",
      "  [0.30395624]\n",
      "  [0.30555972]\n",
      "  [0.30745041]\n",
      "  [0.31055817]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002067702356725931\n",
      "Predicción post entrenamiento : [[0.31267303]]\n",
      "PERDIDAAAA despues: 0.0020905237179249525\n",
      "loss en el callback: 0.0003175842866767198, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "ejemplar: [[0.29545483]\n",
      " [0.30281141]\n",
      " [0.30611959]\n",
      " [0.30395624]\n",
      " [0.30555972]\n",
      " [0.30745041]\n",
      " [0.31055817]\n",
      " [0.31242278]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.31623653]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[[0.29545483]\n",
      "  [0.30281141]\n",
      "  [0.30611959]\n",
      "  [0.30395624]\n",
      "  [0.30555972]\n",
      "  [0.30745041]\n",
      "  [0.31055817]\n",
      "  [0.31242278]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005623653996735811\n",
      "Predicción post entrenamiento : [[0.315923]]\n",
      "PERDIDAAAA despues: 0.0005475938669405878\n",
      "loss en el callback: 0.00041165456059388816, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "ejemplar: [[0.30281141]\n",
      " [0.30611959]\n",
      " [0.30395624]\n",
      " [0.30555972]\n",
      " [0.30745041]\n",
      " [0.31055817]\n",
      " [0.31242278]\n",
      " [0.31623653]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.31809446]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[[0.30281141]\n",
      "  [0.30611959]\n",
      "  [0.30395624]\n",
      "  [0.30555972]\n",
      "  [0.30745041]\n",
      "  [0.31055817]\n",
      "  [0.31242278]\n",
      "  [0.31623653]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.506568878539838e-07\n",
      "Predicción post entrenamiento : [[0.3189212]]\n",
      "PERDIDAAAA despues: 1.4759617670279113e-06\n",
      "loss en el callback: 0.004246145021170378, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "ejemplar: [[0.30611959]\n",
      " [0.30395624]\n",
      " [0.30555972]\n",
      " [0.30745041]\n",
      " [0.31055817]\n",
      " [0.31242278]\n",
      " [0.31623653]\n",
      " [0.31809446]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.31995323]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[[0.30611959]\n",
      "  [0.30395624]\n",
      "  [0.30555972]\n",
      "  [0.30745041]\n",
      "  [0.31055817]\n",
      "  [0.31242278]\n",
      "  [0.31623653]\n",
      "  [0.31809446]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.3052539442433044e-05\n",
      "Predicción post entrenamiento : [[0.319941]]\n",
      "PERDIDAAAA despues: 5.287468957249075e-05\n",
      "loss en el callback: 7.27663405086787e-07, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "ejemplar: [[0.30395624]\n",
      " [0.30555972]\n",
      " [0.30745041]\n",
      " [0.31055817]\n",
      " [0.31242278]\n",
      " [0.31623653]\n",
      " [0.31809446]\n",
      " [0.31995323]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.32061964]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[[0.30395624]\n",
      "  [0.30555972]\n",
      "  [0.30745041]\n",
      "  [0.31055817]\n",
      "  [0.31242278]\n",
      "  [0.31623653]\n",
      "  [0.31809446]\n",
      "  [0.31995323]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009975731372833252\n",
      "Predicción post entrenamiento : [[0.32021502]]\n",
      "PERDIDAAAA despues: 0.0009721771930344403\n",
      "loss en el callback: 0.000835451006423682, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "ejemplar: [[0.30555972]\n",
      " [0.30745041]\n",
      " [0.31055817]\n",
      " [0.31242278]\n",
      " [0.31623653]\n",
      " [0.31809446]\n",
      " [0.31995323]\n",
      " [0.32061964]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.32178164]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[[0.30555972]\n",
      "  [0.30745041]\n",
      "  [0.31055817]\n",
      "  [0.31242278]\n",
      "  [0.31623653]\n",
      "  [0.31809446]\n",
      "  [0.31995323]\n",
      "  [0.32061964]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015167540404945612\n",
      "Predicción post entrenamiento : [[0.3210768]]\n",
      "PERDIDAAAA despues: 0.0014623511815443635\n",
      "loss en el callback: 0.002482145791873336, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "ejemplar: [[0.30745041]\n",
      " [0.31055817]\n",
      " [0.31242278]\n",
      " [0.31623653]\n",
      " [0.31809446]\n",
      " [0.31995323]\n",
      " [0.32061964]\n",
      " [0.32178164]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.32278684]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[[0.30745041]\n",
      "  [0.31055817]\n",
      "  [0.31242278]\n",
      "  [0.31623653]\n",
      "  [0.31809446]\n",
      "  [0.31995323]\n",
      "  [0.32061964]\n",
      "  [0.32178164]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005424480768851936\n",
      "Predicción post entrenamiento : [[0.32318798]]\n",
      "PERDIDAAAA despues: 0.0005612944951280951\n",
      "loss en el callback: 0.0012260284274816513, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "ejemplar: [[0.31055817]\n",
      " [0.31242278]\n",
      " [0.31623653]\n",
      " [0.31809446]\n",
      " [0.31995323]\n",
      " [0.32061964]\n",
      " [0.32178164]\n",
      " [0.32278684]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.3249691]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[[0.31055817]\n",
      "  [0.31242278]\n",
      "  [0.31623653]\n",
      "  [0.31809446]\n",
      "  [0.31995323]\n",
      "  [0.32061964]\n",
      "  [0.32178164]\n",
      "  [0.32278684]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0024115019477903843\n",
      "Predicción post entrenamiento : [[0.3245835]]\n",
      "PERDIDAAAA despues: 0.0023737780284136534\n",
      "loss en el callback: 0.0009541987092234194, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "ejemplar: [[0.31242278]\n",
      " [0.31623653]\n",
      " [0.31809446]\n",
      " [0.31995323]\n",
      " [0.32061964]\n",
      " [0.32178164]\n",
      " [0.32278684]\n",
      " [0.32496911]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.32613114]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[[0.31242278]\n",
      "  [0.31623653]\n",
      "  [0.31809446]\n",
      "  [0.31995323]\n",
      "  [0.32061964]\n",
      "  [0.32178164]\n",
      "  [0.32278684]\n",
      "  [0.32496911]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002645190805196762\n",
      "Predicción post entrenamiento : [[0.32515278]]\n",
      "PERDIDAAAA despues: 0.0025455120485275984\n",
      "loss en el callback: 0.00602946849539876, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "ejemplar: [[0.31623653]\n",
      " [0.31809446]\n",
      " [0.31995323]\n",
      " [0.32061964]\n",
      " [0.32178164]\n",
      " [0.32278684]\n",
      " [0.32496911]\n",
      " [0.32613114]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.32669264]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[[0.31623653]\n",
      "  [0.31809446]\n",
      "  [0.31995323]\n",
      "  [0.32061964]\n",
      "  [0.32178164]\n",
      "  [0.32278684]\n",
      "  [0.32496911]\n",
      "  [0.32613114]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002623286796733737\n",
      "Predicción post entrenamiento : [[0.32588682]]\n",
      "PERDIDAAAA despues: 0.0025413907133042812\n",
      "loss en el callback: 0.004129876848310232, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "ejemplar: [[0.31809446]\n",
      " [0.31995323]\n",
      " [0.32061964]\n",
      " [0.32178164]\n",
      " [0.32278684]\n",
      " [0.32496911]\n",
      " [0.32613114]\n",
      " [0.32669264]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.32693866]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[[0.31809446]\n",
      "  [0.31995323]\n",
      "  [0.32061964]\n",
      "  [0.32178164]\n",
      "  [0.32278684]\n",
      "  [0.32496911]\n",
      "  [0.32613114]\n",
      "  [0.32669264]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.107893568696454e-05\n",
      "Predicción post entrenamiento : [[0.32749993]]\n",
      "PERDIDAAAA despues: 5.2621013310272247e-05\n",
      "loss en el callback: 0.003372471546754241, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "ejemplar: [[0.31995323]\n",
      " [0.32061964]\n",
      " [0.32178164]\n",
      " [0.32278684]\n",
      " [0.32496911]\n",
      " [0.32613114]\n",
      " [0.32669264]\n",
      " [0.32693866]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.32842934]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[[0.31995323]\n",
      "  [0.32061964]\n",
      "  [0.32178164]\n",
      "  [0.32278684]\n",
      "  [0.32496911]\n",
      "  [0.32613114]\n",
      "  [0.32669264]\n",
      "  [0.32693866]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007423850474879146\n",
      "Predicción post entrenamiento : [[0.32808945]]\n",
      "PERDIDAAAA despues: 0.0007610226748511195\n",
      "loss en el callback: 0.0007363639888353646, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "ejemplar: [[0.32061964]\n",
      " [0.32178164]\n",
      " [0.32278684]\n",
      " [0.32496911]\n",
      " [0.32613114]\n",
      " [0.32669264]\n",
      " [0.32693866]\n",
      " [0.32842934]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.3288682]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[[0.32061964]\n",
      "  [0.32178164]\n",
      "  [0.32278684]\n",
      "  [0.32496911]\n",
      "  [0.32613114]\n",
      "  [0.32669264]\n",
      "  [0.32693866]\n",
      "  [0.32842934]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.119917816249654e-05\n",
      "Predicción post entrenamiento : [[0.329079]]\n",
      "PERDIDAAAA despues: 5.794556636828929e-05\n",
      "loss en el callback: 0.00039548921631649137, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "ejemplar: [[0.32178164]\n",
      " [0.32278684]\n",
      " [0.32496911]\n",
      " [0.32613114]\n",
      " [0.32669264]\n",
      " [0.32693866]\n",
      " [0.32842934]\n",
      " [0.32886821]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.3299544]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[[0.32178164]\n",
      "  [0.32278684]\n",
      "  [0.32496911]\n",
      "  [0.32613114]\n",
      "  [0.32669264]\n",
      "  [0.32693866]\n",
      "  [0.32842934]\n",
      "  [0.32886821]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.3229618161858525e-05\n",
      "Predicción post entrenamiento : [[0.32950988]]\n",
      "PERDIDAAAA despues: 1.6660731489537284e-05\n",
      "loss en el callback: 0.0015074551338329911, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "ejemplar: [[0.32278684]\n",
      " [0.32496911]\n",
      " [0.32613114]\n",
      " [0.32669264]\n",
      " [0.32693866]\n",
      " [0.32842934]\n",
      " [0.32886821]\n",
      " [0.32995439]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.33037022]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[[0.32278684]\n",
      "  [0.32496911]\n",
      "  [0.32613114]\n",
      "  [0.32669264]\n",
      "  [0.32693866]\n",
      "  [0.32842934]\n",
      "  [0.32886821]\n",
      "  [0.32995439]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029554860666394234\n",
      "Predicción post entrenamiento : [[0.33094624]]\n",
      "PERDIDAAAA despues: 0.0028931880369782448\n",
      "loss en el callback: 0.002929600654169917, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "ejemplar: [[0.32496911]\n",
      " [0.32613114]\n",
      " [0.32669264]\n",
      " [0.32693866]\n",
      " [0.32842934]\n",
      " [0.32886821]\n",
      " [0.32995439]\n",
      " [0.33037022]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.33181262]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[[0.32496911]\n",
      "  [0.32613114]\n",
      "  [0.32669264]\n",
      "  [0.32693866]\n",
      "  [0.32842934]\n",
      "  [0.32886821]\n",
      "  [0.32995439]\n",
      "  [0.33037022]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05725676566362381\n",
      "Predicción post entrenamiento : [[0.3345013]]\n",
      "PERDIDAAAA despues: 0.05597728118300438\n",
      "loss en el callback: 0.07986991107463837, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "ejemplar: [[0.32613114]\n",
      " [0.32669264]\n",
      " [0.32693866]\n",
      " [0.32842934]\n",
      " [0.32886821]\n",
      " [0.32995439]\n",
      " [0.33037022]\n",
      " [0.33181262]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.33509082]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[[0.32613114]\n",
      "  [0.32669264]\n",
      "  [0.32693866]\n",
      "  [0.32842934]\n",
      "  [0.32886821]\n",
      "  [0.32995439]\n",
      "  [0.33037022]\n",
      "  [0.33181262]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06822005659341812\n",
      "Predicción post entrenamiento : [[0.33763984]]\n",
      "PERDIDAAAA despues: 0.0668950006365776\n",
      "loss en el callback: 0.0567547082901001, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "ejemplar: [[0.32669264]\n",
      " [0.32693866]\n",
      " [0.32842934]\n",
      " [0.32886821]\n",
      " [0.32995439]\n",
      " [0.33037022]\n",
      " [0.33181262]\n",
      " [0.33509082]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.33816227]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[[0.32669264]\n",
      "  [0.32693866]\n",
      "  [0.32842934]\n",
      "  [0.32886821]\n",
      "  [0.32995439]\n",
      "  [0.33037022]\n",
      "  [0.33181262]\n",
      "  [0.33509082]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05589498206973076\n",
      "Predicción post entrenamiento : [[0.34053245]]\n",
      "PERDIDAAAA despues: 0.05477987974882126\n",
      "loss en el callback: 0.06662905961275101, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "ejemplar: [[0.32693866]\n",
      " [0.32842934]\n",
      " [0.32886821]\n",
      " [0.32995439]\n",
      " [0.33037022]\n",
      " [0.33181262]\n",
      " [0.33509082]\n",
      " [0.33816227]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.34115112]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[[0.32693866]\n",
      "  [0.32842934]\n",
      "  [0.32886821]\n",
      "  [0.32995439]\n",
      "  [0.33037022]\n",
      "  [0.33181262]\n",
      "  [0.33509082]\n",
      "  [0.33816227]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07033263146877289\n",
      "Predicción post entrenamiento : [[0.3438168]]\n",
      "PERDIDAAAA despues: 0.06892585009336472\n",
      "loss en el callback: 0.09539739042520523, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "ejemplar: [[0.32842934]\n",
      " [0.32886821]\n",
      " [0.32995439]\n",
      " [0.33037022]\n",
      " [0.33181262]\n",
      " [0.33509082]\n",
      " [0.33816227]\n",
      " [0.34115112]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.34466404]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[[0.32842934]\n",
      "  [0.32886821]\n",
      "  [0.32995439]\n",
      "  [0.33037022]\n",
      "  [0.33181262]\n",
      "  [0.33509082]\n",
      "  [0.33816227]\n",
      "  [0.34115112]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.057596687227487564\n",
      "Predicción post entrenamiento : [[0.34688205]]\n",
      "PERDIDAAAA despues: 0.05653699114918709\n",
      "loss en el callback: 0.07691963762044907, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "ejemplar: [[0.32886821]\n",
      " [0.32995439]\n",
      " [0.33037022]\n",
      " [0.33181262]\n",
      " [0.33509082]\n",
      " [0.33816227]\n",
      " [0.34115112]\n",
      " [0.34466404]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.3477501]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[[0.32886821]\n",
      "  [0.32995439]\n",
      "  [0.33037022]\n",
      "  [0.33181262]\n",
      "  [0.33509082]\n",
      "  [0.33816227]\n",
      "  [0.34115112]\n",
      "  [0.34466404]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04885058477520943\n",
      "Predicción post entrenamiento : [[0.34918466]]\n",
      "PERDIDAAAA despues: 0.0482185035943985\n",
      "loss en el callback: 0.018462829291820526, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "ejemplar: [[0.32995439]\n",
      " [0.33037022]\n",
      " [0.33181262]\n",
      " [0.33509082]\n",
      " [0.33816227]\n",
      " [0.34115112]\n",
      " [0.34466404]\n",
      " [0.3477501 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.35037962]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[[0.32995439]\n",
      "  [0.33037022]\n",
      "  [0.33181262]\n",
      "  [0.33509082]\n",
      "  [0.33816227]\n",
      "  [0.34115112]\n",
      "  [0.34466404]\n",
      "  [0.3477501 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08549454063177109\n",
      "Predicción post entrenamiento : [[0.35303816]]\n",
      "PERDIDAAAA despues: 0.08394691348075867\n",
      "loss en el callback: 0.09666653722524643, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "ejemplar: [[0.33037022]\n",
      " [0.33181262]\n",
      " [0.33509082]\n",
      " [0.33816227]\n",
      " [0.34115112]\n",
      " [0.34466404]\n",
      " [0.3477501 ]\n",
      " [0.35037962]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.3545044]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[[0.33037022]\n",
      "  [0.33181262]\n",
      "  [0.33509082]\n",
      "  [0.33816227]\n",
      "  [0.34115112]\n",
      "  [0.34466404]\n",
      "  [0.3477501 ]\n",
      "  [0.35037962]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.094405397772789\n",
      "Predicción post entrenamiento : [[0.35712665]]\n",
      "PERDIDAAAA despues: 0.09280087798833847\n",
      "loss en el callback: 0.10146860778331757, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "ejemplar: [[0.33181262]\n",
      " [0.33509082]\n",
      " [0.33816227]\n",
      " [0.34115112]\n",
      " [0.34466404]\n",
      " [0.3477501 ]\n",
      " [0.35037962]\n",
      " [0.35450441]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.35910293]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[[0.33181262]\n",
      "  [0.33509082]\n",
      "  [0.33816227]\n",
      "  [0.34115112]\n",
      "  [0.34466404]\n",
      "  [0.3477501 ]\n",
      "  [0.35037962]\n",
      "  [0.35450441]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09852821379899979\n",
      "Predicción post entrenamiento : [[0.36183855]]\n",
      "PERDIDAAAA despues: 0.09681832045316696\n",
      "loss en el callback: 0.09721136093139648, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "ejemplar: [[0.33509082]\n",
      " [0.33816227]\n",
      " [0.34115112]\n",
      " [0.34466404]\n",
      " [0.3477501 ]\n",
      " [0.35037962]\n",
      " [0.35450441]\n",
      " [0.35910293]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.36418733]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[[0.33509082]\n",
      "  [0.33816227]\n",
      "  [0.34115112]\n",
      "  [0.34466404]\n",
      "  [0.3477501 ]\n",
      "  [0.35037962]\n",
      "  [0.35450441]\n",
      "  [0.35910293]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11998602002859116\n",
      "Predicción post entrenamiento : [[0.36718717]]\n",
      "PERDIDAAAA despues: 0.1179167851805687\n",
      "loss en el callback: 0.1375865489244461, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "ejemplar: [[0.33816227]\n",
      " [0.34115112]\n",
      " [0.34466404]\n",
      " [0.3477501 ]\n",
      " [0.35037962]\n",
      " [0.35450441]\n",
      " [0.35910293]\n",
      " [0.36418733]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.36955374]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[[0.33816227]\n",
      "  [0.34115112]\n",
      "  [0.34466404]\n",
      "  [0.3477501 ]\n",
      "  [0.35037962]\n",
      "  [0.35450441]\n",
      "  [0.35910293]\n",
      "  [0.36418733]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11184807866811752\n",
      "Predicción post entrenamiento : [[0.37229002]]\n",
      "PERDIDAAAA despues: 0.11002534627914429\n",
      "loss en el callback: 0.13242365419864655, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "ejemplar: [[0.34115112]\n",
      " [0.34466404]\n",
      " [0.3477501 ]\n",
      " [0.35037962]\n",
      " [0.35450441]\n",
      " [0.35910293]\n",
      " [0.36418733]\n",
      " [0.36955374]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.37476164]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[[0.34115112]\n",
      "  [0.34466404]\n",
      "  [0.3477501 ]\n",
      "  [0.35037962]\n",
      "  [0.35450441]\n",
      "  [0.35910293]\n",
      "  [0.36418733]\n",
      "  [0.36955374]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1242392435669899\n",
      "Predicción post entrenamiento : [[0.37760425]]\n",
      "PERDIDAAAA despues: 0.12224342674016953\n",
      "loss en el callback: 0.2173021137714386, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "ejemplar: [[0.34466404]\n",
      " [0.3477501 ]\n",
      " [0.35037962]\n",
      " [0.35450441]\n",
      " [0.35910293]\n",
      " [0.36418733]\n",
      " [0.36955374]\n",
      " [0.37476164]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.38026065]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[[0.34466404]\n",
      "  [0.3477501 ]\n",
      "  [0.35037962]\n",
      "  [0.35450441]\n",
      "  [0.35910293]\n",
      "  [0.36418733]\n",
      "  [0.36955374]\n",
      "  [0.37476164]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11718810349702835\n",
      "Predicción post entrenamiento : [[0.38302538]]\n",
      "PERDIDAAAA despues: 0.11530286073684692\n",
      "loss en el callback: 0.10700106620788574, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "ejemplar: [[0.3477501 ]\n",
      " [0.35037962]\n",
      " [0.35450441]\n",
      " [0.35910293]\n",
      " [0.36418733]\n",
      " [0.36955374]\n",
      " [0.37476164]\n",
      " [0.38026065]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.3858168]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[[0.3477501 ]\n",
      "  [0.35037962]\n",
      "  [0.35450441]\n",
      "  [0.35910293]\n",
      "  [0.36418733]\n",
      "  [0.36955374]\n",
      "  [0.37476164]\n",
      "  [0.38026065]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1489783078432083\n",
      "Predicción post entrenamiento : [[0.3888874]]\n",
      "PERDIDAAAA despues: 0.14661738276481628\n",
      "loss en el callback: 0.14900948107242584, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "ejemplar: [[0.35037962]\n",
      " [0.35450441]\n",
      " [0.35910293]\n",
      " [0.36418733]\n",
      " [0.36955374]\n",
      " [0.37476164]\n",
      " [0.38026065]\n",
      " [0.38581681]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.39198706]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[[0.35037962]\n",
      "  [0.35450441]\n",
      "  [0.35910293]\n",
      "  [0.36418733]\n",
      "  [0.36955374]\n",
      "  [0.37476164]\n",
      "  [0.38026065]\n",
      "  [0.38581681]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11058174818754196\n",
      "Predicción post entrenamiento : [[0.3947323]]\n",
      "PERDIDAAAA despues: 0.10876348614692688\n",
      "loss en el callback: 0.15398068726062775, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "ejemplar: [[0.35450441]\n",
      " [0.35910293]\n",
      " [0.36418733]\n",
      " [0.36955374]\n",
      " [0.37476164]\n",
      " [0.38026065]\n",
      " [0.38581681]\n",
      " [0.39198706]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.39834175]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[[0.35450441]\n",
      "  [0.35910293]\n",
      "  [0.36418733]\n",
      "  [0.36955374]\n",
      "  [0.37476164]\n",
      "  [0.38026065]\n",
      "  [0.38581681]\n",
      "  [0.39198706]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0743739902973175\n",
      "Predicción post entrenamiento : [[0.40034583]]\n",
      "PERDIDAAAA despues: 0.07328491657972336\n",
      "loss en el callback: 0.06852099299430847, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "ejemplar: [[0.35910293]\n",
      " [0.36418733]\n",
      " [0.36955374]\n",
      " [0.37476164]\n",
      " [0.38026065]\n",
      " [0.38581681]\n",
      " [0.39198706]\n",
      " [0.39834175]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.4042113]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[[0.35910293]\n",
      "  [0.36418733]\n",
      "  [0.36955374]\n",
      "  [0.37476164]\n",
      "  [0.38026065]\n",
      "  [0.38581681]\n",
      "  [0.39198706]\n",
      "  [0.39834175]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07266179472208023\n",
      "Predicción post entrenamiento : [[0.40608045]]\n",
      "PERDIDAAAA despues: 0.07165760546922684\n",
      "loss en el callback: 0.054461851716041565, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "ejemplar: [[0.36418733]\n",
      " [0.36955374]\n",
      " [0.37476164]\n",
      " [0.38026065]\n",
      " [0.38581681]\n",
      " [0.39198706]\n",
      " [0.39834175]\n",
      " [0.40421131]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.41014984]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[[0.36418733]\n",
      "  [0.36955374]\n",
      "  [0.37476164]\n",
      "  [0.38026065]\n",
      "  [0.38581681]\n",
      "  [0.39198706]\n",
      "  [0.39834175]\n",
      "  [0.40421131]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09259967505931854\n",
      "Predicción post entrenamiento : [[0.41226894]]\n",
      "PERDIDAAAA despues: 0.09131447970867157\n",
      "loss en el callback: 0.07795990258455276, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "ejemplar: [[0.36955374]\n",
      " [0.37476164]\n",
      " [0.38026065]\n",
      " [0.38581681]\n",
      " [0.39198706]\n",
      " [0.39834175]\n",
      " [0.40421131]\n",
      " [0.41014984]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.4164738]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[[0.36955374]\n",
      "  [0.37476164]\n",
      "  [0.38026065]\n",
      "  [0.38581681]\n",
      "  [0.39198706]\n",
      "  [0.39834175]\n",
      "  [0.40421131]\n",
      "  [0.41014984]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10720642656087875\n",
      "Predicción post entrenamiento : [[0.4187934]]\n",
      "PERDIDAAAA despues: 0.10569282621145248\n",
      "loss en el callback: 0.0789828673005104, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "ejemplar: [[0.37476164]\n",
      " [0.38026065]\n",
      " [0.38581681]\n",
      " [0.39198706]\n",
      " [0.39834175]\n",
      " [0.40421131]\n",
      " [0.41014984]\n",
      " [0.41647381]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.42310175]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[[0.37476164]\n",
      "  [0.38026065]\n",
      "  [0.38581681]\n",
      "  [0.39198706]\n",
      "  [0.39834175]\n",
      "  [0.40421131]\n",
      "  [0.41014984]\n",
      "  [0.41647381]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08969208598136902\n",
      "Predicción post entrenamiento : [[0.4254038]]\n",
      "PERDIDAAAA despues: 0.08831851929426193\n",
      "loss en el callback: 0.12598788738250732, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "ejemplar: [[0.38026065]\n",
      " [0.38581681]\n",
      " [0.39198706]\n",
      " [0.39834175]\n",
      " [0.40421131]\n",
      " [0.41014984]\n",
      " [0.41647381]\n",
      " [0.42310175]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.42988622]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[[0.38026065]\n",
      "  [0.38581681]\n",
      "  [0.39198706]\n",
      "  [0.39834175]\n",
      "  [0.40421131]\n",
      "  [0.41014984]\n",
      "  [0.41647381]\n",
      "  [0.42310175]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07260607182979584\n",
      "Predicción post entrenamiento : [[0.43182448]]\n",
      "PERDIDAAAA despues: 0.07156528532505035\n",
      "loss en el callback: 0.06952889263629913, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "ejemplar: [[0.38581681]\n",
      " [0.39198706]\n",
      " [0.39834175]\n",
      " [0.40421131]\n",
      " [0.41014984]\n",
      " [0.41647381]\n",
      " [0.42310175]\n",
      " [0.42988622]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.43645006]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[[0.38581681]\n",
      "  [0.39198706]\n",
      "  [0.39834175]\n",
      "  [0.40421131]\n",
      "  [0.41014984]\n",
      "  [0.41647381]\n",
      "  [0.42310175]\n",
      "  [0.42988622]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09051737934350967\n",
      "Predicción post entrenamiento : [[0.4387409]]\n",
      "PERDIDAAAA despues: 0.08914417028427124\n",
      "loss en el callback: 0.14596015214920044, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "ejemplar: [[0.39198706]\n",
      " [0.39834175]\n",
      " [0.40421131]\n",
      " [0.41014984]\n",
      " [0.41647381]\n",
      " [0.42310175]\n",
      " [0.42988622]\n",
      " [0.43645006]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.4435308]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[[0.39198706]\n",
      "  [0.39834175]\n",
      "  [0.40421131]\n",
      "  [0.41014984]\n",
      "  [0.41647381]\n",
      "  [0.42310175]\n",
      "  [0.42988622]\n",
      "  [0.43645006]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07722564786672592\n",
      "Predicción post entrenamiento : [[0.44557205]]\n",
      "PERDIDAAAA despues: 0.07609531283378601\n",
      "loss en el callback: 0.09585023671388626, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "ejemplar: [[0.39834175]\n",
      " [0.40421131]\n",
      " [0.41014984]\n",
      " [0.41647381]\n",
      " [0.42310175]\n",
      " [0.42988622]\n",
      " [0.43645006]\n",
      " [0.4435308 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.45041022]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[[0.39834175]\n",
      "  [0.40421131]\n",
      "  [0.41014984]\n",
      "  [0.41647381]\n",
      "  [0.42310175]\n",
      "  [0.42988622]\n",
      "  [0.43645006]\n",
      "  [0.4435308 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07198675721883774\n",
      "Predicción post entrenamiento : [[0.45252272]]\n",
      "PERDIDAAAA despues: 0.07085763663053513\n",
      "loss en el callback: 0.12411156296730042, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "ejemplar: [[0.40421131]\n",
      " [0.41014984]\n",
      " [0.41647381]\n",
      " [0.42310175]\n",
      " [0.42988622]\n",
      " [0.43645006]\n",
      " [0.4435308 ]\n",
      " [0.45041022]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.45738512]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[[0.40421131]\n",
      "  [0.41014984]\n",
      "  [0.41647381]\n",
      "  [0.42310175]\n",
      "  [0.42988622]\n",
      "  [0.43645006]\n",
      "  [0.4435308 ]\n",
      "  [0.45041022]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04699018597602844\n",
      "Predicción post entrenamiento : [[0.459047]]\n",
      "PERDIDAAAA despues: 0.046272456645965576\n",
      "loss en el callback: 0.07360546290874481, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "ejemplar: [[0.41014984]\n",
      " [0.41647381]\n",
      " [0.42310175]\n",
      " [0.42988622]\n",
      " [0.43645006]\n",
      " [0.4435308 ]\n",
      " [0.45041022]\n",
      " [0.45738512]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.46407613]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[[0.41014984]\n",
      "  [0.41647381]\n",
      "  [0.42310175]\n",
      "  [0.42988622]\n",
      "  [0.43645006]\n",
      "  [0.4435308 ]\n",
      "  [0.45041022]\n",
      "  [0.45738512]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05498570203781128\n",
      "Predicción post entrenamiento : [[0.46591833]]\n",
      "PERDIDAAAA despues: 0.054125141352415085\n",
      "loss en el callback: 0.11742401123046875, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "ejemplar: [[0.41647381]\n",
      " [0.42310175]\n",
      " [0.42988622]\n",
      " [0.43645006]\n",
      " [0.4435308 ]\n",
      " [0.45041022]\n",
      " [0.45738512]\n",
      " [0.46407613]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.47113568]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[[0.41647381]\n",
      "  [0.42310175]\n",
      "  [0.42988622]\n",
      "  [0.43645006]\n",
      "  [0.4435308 ]\n",
      "  [0.45041022]\n",
      "  [0.45738512]\n",
      "  [0.46407613]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06245134398341179\n",
      "Predicción post entrenamiento : [[0.47271246]]\n",
      "PERDIDAAAA despues: 0.061665743589401245\n",
      "loss en el callback: 0.04773186519742012, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "ejemplar: [[0.42310175]\n",
      " [0.42988622]\n",
      " [0.43645006]\n",
      " [0.4435308 ]\n",
      " [0.45041022]\n",
      " [0.45738512]\n",
      " [0.46407613]\n",
      " [0.47113568]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.47805536]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[[0.42310175]\n",
      "  [0.42988622]\n",
      "  [0.43645006]\n",
      "  [0.4435308 ]\n",
      "  [0.45041022]\n",
      "  [0.45738512]\n",
      "  [0.46407613]\n",
      "  [0.47113568]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.059796273708343506\n",
      "Predicción post entrenamiento : [[0.47963563]]\n",
      "PERDIDAAAA despues: 0.05902591347694397\n",
      "loss en el callback: 0.051183704286813736, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "ejemplar: [[0.42988622]\n",
      " [0.43645006]\n",
      " [0.4435308 ]\n",
      " [0.45041022]\n",
      " [0.45738512]\n",
      " [0.46407613]\n",
      " [0.47113568]\n",
      " [0.47805536]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.4850485]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[[0.42988622]\n",
      "  [0.43645006]\n",
      "  [0.4435308 ]\n",
      "  [0.45041022]\n",
      "  [0.45738512]\n",
      "  [0.46407613]\n",
      "  [0.47113568]\n",
      "  [0.47805536]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0735752284526825\n",
      "Predicción post entrenamiento : [[0.48680583]]\n",
      "PERDIDAAAA despues: 0.07262497395277023\n",
      "loss en el callback: 0.07174581289291382, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "ejemplar: [[0.43645006]\n",
      " [0.4435308 ]\n",
      " [0.45041022]\n",
      " [0.45738512]\n",
      " [0.46407613]\n",
      " [0.47113568]\n",
      " [0.47805536]\n",
      " [0.4850485 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.49226072]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[[0.43645006]\n",
      "  [0.4435308 ]\n",
      "  [0.45041022]\n",
      "  [0.45738512]\n",
      "  [0.46407613]\n",
      "  [0.47113568]\n",
      "  [0.47805536]\n",
      "  [0.4850485 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11244319379329681\n",
      "Predicción post entrenamiento : [[0.49444768]]\n",
      "PERDIDAAAA despues: 0.1109813004732132\n",
      "loss en el callback: 0.12232446670532227, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "ejemplar: [[0.4435308 ]\n",
      " [0.45041022]\n",
      " [0.45738512]\n",
      " [0.46407613]\n",
      " [0.47113568]\n",
      " [0.47805536]\n",
      " [0.4850485 ]\n",
      " [0.49226072]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.5000097]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[[0.4435308 ]\n",
      "  [0.45041022]\n",
      "  [0.45738512]\n",
      "  [0.46407613]\n",
      "  [0.47113568]\n",
      "  [0.47805536]\n",
      "  [0.4850485 ]\n",
      "  [0.49226072]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11479388922452927\n",
      "Predicción post entrenamiento : [[0.5021533]]\n",
      "PERDIDAAAA despues: 0.11334595084190369\n",
      "loss en el callback: 0.10595103353261948, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "ejemplar: [[0.45041022]\n",
      " [0.45738512]\n",
      " [0.46407613]\n",
      " [0.47113568]\n",
      " [0.47805536]\n",
      " [0.4850485 ]\n",
      " [0.49226072]\n",
      " [0.50000972]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.50770926]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[[0.45041022]\n",
      "  [0.45738512]\n",
      "  [0.46407613]\n",
      "  [0.47113568]\n",
      "  [0.47805536]\n",
      "  [0.4850485 ]\n",
      "  [0.49226072]\n",
      "  [0.50000972]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08211465179920197\n",
      "Predicción post entrenamiento : [[0.50933385]]\n",
      "PERDIDAAAA despues: 0.0811862200498581\n",
      "loss en el callback: 0.061192095279693604, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "ejemplar: [[0.45738512]\n",
      " [0.46407613]\n",
      " [0.47113568]\n",
      " [0.47805536]\n",
      " [0.4850485 ]\n",
      " [0.49226072]\n",
      " [0.50000972]\n",
      " [0.50770926]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.51494277]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[[0.45738512]\n",
      "  [0.46407613]\n",
      "  [0.47113568]\n",
      "  [0.47805536]\n",
      "  [0.4850485 ]\n",
      "  [0.49226072]\n",
      "  [0.50000972]\n",
      "  [0.50770926]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07228674739599228\n",
      "Predicción post entrenamiento : [[0.5167063]]\n",
      "PERDIDAAAA despues: 0.07134156674146652\n",
      "loss en el callback: 0.0751480981707573, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "ejemplar: [[0.46407613]\n",
      " [0.47113568]\n",
      " [0.47805536]\n",
      " [0.4850485 ]\n",
      " [0.49226072]\n",
      " [0.50000972]\n",
      " [0.50770926]\n",
      " [0.51494277]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.5223639]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[[0.46407613]\n",
      "  [0.47113568]\n",
      "  [0.47805536]\n",
      "  [0.4850485 ]\n",
      "  [0.49226072]\n",
      "  [0.50000972]\n",
      "  [0.50770926]\n",
      "  [0.51494277]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.060297515243291855\n",
      "Predicción post entrenamiento : [[0.5236907]]\n",
      "PERDIDAAAA despues: 0.05964766815304756\n",
      "loss en el callback: 0.04238327965140343, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "ejemplar: [[0.47113568]\n",
      " [0.47805536]\n",
      " [0.4850485 ]\n",
      " [0.49226072]\n",
      " [0.50000972]\n",
      " [0.50770926]\n",
      " [0.51494277]\n",
      " [0.5223639 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.52948916]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[[0.47113568]\n",
      "  [0.47805536]\n",
      "  [0.4850485 ]\n",
      "  [0.49226072]\n",
      "  [0.50000972]\n",
      "  [0.50770926]\n",
      "  [0.51494277]\n",
      "  [0.5223639 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06507115066051483\n",
      "Predicción post entrenamiento : [[0.530668]]\n",
      "PERDIDAAAA despues: 0.06447111070156097\n",
      "loss en el callback: 0.028643004596233368, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "ejemplar: [[0.47805536]\n",
      " [0.4850485 ]\n",
      " [0.49226072]\n",
      " [0.50000972]\n",
      " [0.50770926]\n",
      " [0.51494277]\n",
      " [0.5223639 ]\n",
      " [0.52948916]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.536539]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[[0.47805536]\n",
      "  [0.4850485 ]\n",
      "  [0.49226072]\n",
      "  [0.50000972]\n",
      "  [0.50770926]\n",
      "  [0.51494277]\n",
      "  [0.5223639 ]\n",
      "  [0.52948916]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11709409952163696\n",
      "Predicción post entrenamiento : [[0.53864694]]\n",
      "PERDIDAAAA despues: 0.11565592139959335\n",
      "loss en el callback: 0.11893940716981888, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "ejemplar: [[0.4850485 ]\n",
      " [0.49226072]\n",
      " [0.50000972]\n",
      " [0.50770926]\n",
      " [0.51494277]\n",
      " [0.5223639 ]\n",
      " [0.52948916]\n",
      " [0.53653902]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.5446426]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[[0.4850485 ]\n",
      "  [0.49226072]\n",
      "  [0.50000972]\n",
      "  [0.50770926]\n",
      "  [0.51494277]\n",
      "  [0.5223639 ]\n",
      "  [0.52948916]\n",
      "  [0.53653902]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10955237597227097\n",
      "Predicción post entrenamiento : [[0.54665375]]\n",
      "PERDIDAAAA despues: 0.10822511464357376\n",
      "loss en el callback: 0.09788332879543304, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "ejemplar: [[0.49226072]\n",
      " [0.50000972]\n",
      " [0.50770926]\n",
      " [0.51494277]\n",
      " [0.5223639 ]\n",
      " [0.52948916]\n",
      " [0.53653902]\n",
      " [0.54464263]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.55277205]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[[0.49226072]\n",
      "  [0.50000972]\n",
      "  [0.50770926]\n",
      "  [0.51494277]\n",
      "  [0.5223639 ]\n",
      "  [0.52948916]\n",
      "  [0.53653902]\n",
      "  [0.54464263]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08768927305936813\n",
      "Predicción post entrenamiento : [[0.55451435]]\n",
      "PERDIDAAAA despues: 0.08666042983531952\n",
      "loss en el callback: 0.07465767115354538, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "ejemplar: [[0.50000972]\n",
      " [0.50770926]\n",
      " [0.51494277]\n",
      " [0.5223639 ]\n",
      " [0.52948916]\n",
      " [0.53653902]\n",
      " [0.54464263]\n",
      " [0.55277205]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.560715]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[[0.50000972]\n",
      "  [0.50770926]\n",
      "  [0.51494277]\n",
      "  [0.5223639 ]\n",
      "  [0.52948916]\n",
      "  [0.53653902]\n",
      "  [0.54464263]\n",
      "  [0.55277205]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06634357571601868\n",
      "Predicción post entrenamiento : [[0.56183827]]\n",
      "PERDIDAAAA despues: 0.06576620042324066\n",
      "loss en el callback: 0.026951856911182404, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "ejemplar: [[0.50770926]\n",
      " [0.51494277]\n",
      " [0.5223639 ]\n",
      " [0.52948916]\n",
      " [0.53653902]\n",
      " [0.54464263]\n",
      " [0.55277205]\n",
      " [0.56071502]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.5679924]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[[0.50770926]\n",
      "  [0.51494277]\n",
      "  [0.5223639 ]\n",
      "  [0.52948916]\n",
      "  [0.53653902]\n",
      "  [0.54464263]\n",
      "  [0.55277205]\n",
      "  [0.56071502]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06698723882436752\n",
      "Predicción post entrenamiento : [[0.56982833]]\n",
      "PERDIDAAAA despues: 0.06604025512933731\n",
      "loss en el callback: 0.12248299270868301, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "ejemplar: [[0.51494277]\n",
      " [0.5223639 ]\n",
      " [0.52948916]\n",
      " [0.53653902]\n",
      " [0.54464263]\n",
      " [0.55277205]\n",
      " [0.56071502]\n",
      " [0.56799239]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.5759505]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[[0.51494277]\n",
      "  [0.5223639 ]\n",
      "  [0.52948916]\n",
      "  [0.53653902]\n",
      "  [0.54464263]\n",
      "  [0.55277205]\n",
      "  [0.56071502]\n",
      "  [0.56799239]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04385003075003624\n",
      "Predicción post entrenamiento : [[0.5772569]]\n",
      "PERDIDAAAA despues: 0.043304599821567535\n",
      "loss en el callback: 0.05075502023100853, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "ejemplar: [[0.5223639 ]\n",
      " [0.52948916]\n",
      " [0.53653902]\n",
      " [0.54464263]\n",
      " [0.55277205]\n",
      " [0.56071502]\n",
      " [0.56799239]\n",
      " [0.5759505 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.5834758]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[[0.5223639 ]\n",
      "  [0.52948916]\n",
      "  [0.53653902]\n",
      "  [0.54464263]\n",
      "  [0.55277205]\n",
      "  [0.56071502]\n",
      "  [0.56799239]\n",
      "  [0.5759505 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.042334359139204025\n",
      "Predicción post entrenamiento : [[0.58483523]]\n",
      "PERDIDAAAA despues: 0.04177680239081383\n",
      "loss en el callback: 0.05691443756222725, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "ejemplar: [[0.52948916]\n",
      " [0.53653902]\n",
      " [0.54464263]\n",
      " [0.55277205]\n",
      " [0.56071502]\n",
      " [0.56799239]\n",
      " [0.5759505 ]\n",
      " [0.58347583]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.5911234]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[[0.52948916]\n",
      "  [0.53653902]\n",
      "  [0.54464263]\n",
      "  [0.55277205]\n",
      "  [0.56071502]\n",
      "  [0.56799239]\n",
      "  [0.5759505 ]\n",
      "  [0.58347583]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05907300114631653\n",
      "Predicción post entrenamiento : [[0.5918642]]\n",
      "PERDIDAAAA despues: 0.058713436126708984\n",
      "loss en el callback: 0.01114314142614603, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "ejemplar: [[0.53653902]\n",
      " [0.54464263]\n",
      " [0.55277205]\n",
      " [0.56071502]\n",
      " [0.56799239]\n",
      " [0.5759505 ]\n",
      " [0.58347583]\n",
      " [0.5911234 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.5983132]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[[0.53653902]\n",
      "  [0.54464263]\n",
      "  [0.55277205]\n",
      "  [0.56071502]\n",
      "  [0.56799239]\n",
      "  [0.5759505 ]\n",
      "  [0.58347583]\n",
      "  [0.5911234 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04586561396718025\n",
      "Predicción post entrenamiento : [[0.59976]]\n",
      "PERDIDAAAA despues: 0.045248012989759445\n",
      "loss en el callback: 0.06723111122846603, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "ejemplar: [[0.54464263]\n",
      " [0.55277205]\n",
      " [0.56071502]\n",
      " [0.56799239]\n",
      " [0.5759505 ]\n",
      " [0.58347583]\n",
      " [0.5911234 ]\n",
      " [0.59831321]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.6064096]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[[0.54464263]\n",
      "  [0.55277205]\n",
      "  [0.56071502]\n",
      "  [0.56799239]\n",
      "  [0.5759505 ]\n",
      "  [0.58347583]\n",
      "  [0.5911234 ]\n",
      "  [0.59831321]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03795882314443588\n",
      "Predicción post entrenamiento : [[0.6076923]]\n",
      "PERDIDAAAA despues: 0.037460651248693466\n",
      "loss en el callback: 0.046567678451538086, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "ejemplar: [[0.55277205]\n",
      " [0.56071502]\n",
      " [0.56799239]\n",
      " [0.5759505 ]\n",
      " [0.58347583]\n",
      " [0.5911234 ]\n",
      " [0.59831321]\n",
      " [0.60640961]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.6142746]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[[0.55277205]\n",
      "  [0.56071502]\n",
      "  [0.56799239]\n",
      "  [0.5759505 ]\n",
      "  [0.58347583]\n",
      "  [0.5911234 ]\n",
      "  [0.59831321]\n",
      "  [0.60640961]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03568413108587265\n",
      "Predicción post entrenamiento : [[0.6156415]]\n",
      "PERDIDAAAA despues: 0.03516959398984909\n",
      "loss en el callback: 0.06901612132787704, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "ejemplar: [[0.56071502]\n",
      " [0.56799239]\n",
      " [0.5759505 ]\n",
      " [0.58347583]\n",
      " [0.5911234 ]\n",
      " [0.59831321]\n",
      " [0.60640961]\n",
      " [0.61427462]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.62213075]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[[0.56071502]\n",
      "  [0.56799239]\n",
      "  [0.5759505 ]\n",
      "  [0.58347583]\n",
      "  [0.5911234 ]\n",
      "  [0.59831321]\n",
      "  [0.60640961]\n",
      "  [0.61427462]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.029364295303821564\n",
      "Predicción post entrenamiento : [[0.6232923]]\n",
      "PERDIDAAAA despues: 0.02896755002439022\n",
      "loss en el callback: 0.04210726544260979, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "ejemplar: [[0.56799239]\n",
      " [0.5759505 ]\n",
      " [0.58347583]\n",
      " [0.5911234 ]\n",
      " [0.59831321]\n",
      " [0.60640961]\n",
      " [0.61427462]\n",
      " [0.62213075]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.6297235]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[[0.56799239]\n",
      "  [0.5759505 ]\n",
      "  [0.58347583]\n",
      "  [0.5911234 ]\n",
      "  [0.59831321]\n",
      "  [0.60640961]\n",
      "  [0.61427462]\n",
      "  [0.62213075]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017016412690281868\n",
      "Predicción post entrenamiento : [[0.63055325]]\n",
      "PERDIDAAAA despues: 0.016800621524453163\n",
      "loss en el callback: 0.020574335008859634, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "ejemplar: [[0.5759505 ]\n",
      " [0.58347583]\n",
      " [0.5911234 ]\n",
      " [0.59831321]\n",
      " [0.60640961]\n",
      " [0.61427462]\n",
      " [0.62213075]\n",
      " [0.62972349]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.6370996]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[[0.5759505 ]\n",
      "  [0.58347583]\n",
      "  [0.5911234 ]\n",
      "  [0.59831321]\n",
      "  [0.60640961]\n",
      "  [0.61427462]\n",
      "  [0.62213075]\n",
      "  [0.62972349]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009657836519181728\n",
      "Predicción post entrenamiento : [[0.6372185]]\n",
      "PERDIDAAAA despues: 0.009634490124881268\n",
      "loss en el callback: 0.00037024726043455303, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "ejemplar: [[0.58347583]\n",
      " [0.5911234 ]\n",
      " [0.59831321]\n",
      " [0.60640961]\n",
      " [0.61427462]\n",
      " [0.62213075]\n",
      " [0.62972349]\n",
      " [0.63709962]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.6437078]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[[0.58347583]\n",
      "  [0.5911234 ]\n",
      "  [0.59831321]\n",
      "  [0.60640961]\n",
      "  [0.61427462]\n",
      "  [0.62213075]\n",
      "  [0.62972349]\n",
      "  [0.63709962]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004419857170432806\n",
      "Predicción post entrenamiento : [[0.6442468]]\n",
      "PERDIDAAAA despues: 0.004348479676991701\n",
      "loss en el callback: 0.009176083840429783, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "ejemplar: [[0.5911234 ]\n",
      " [0.59831321]\n",
      " [0.60640961]\n",
      " [0.61427462]\n",
      " [0.62213075]\n",
      " [0.62972349]\n",
      " [0.63709962]\n",
      " [0.64370781]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.6507838]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[[0.5911234 ]\n",
      "  [0.59831321]\n",
      "  [0.60640961]\n",
      "  [0.61427462]\n",
      "  [0.62213075]\n",
      "  [0.62972349]\n",
      "  [0.63709962]\n",
      "  [0.64370781]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0037630018778145313\n",
      "Predicción post entrenamiento : [[0.65060943]]\n",
      "PERDIDAAAA despues: 0.0037844220642000437\n",
      "loss en el callback: 0.0007234076620079577, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "ejemplar: [[0.59831321]\n",
      " [0.60640961]\n",
      " [0.61427462]\n",
      " [0.62213075]\n",
      " [0.62972349]\n",
      " [0.63709962]\n",
      " [0.64370781]\n",
      " [0.65078378]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.6571511]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[[0.59831321]\n",
      "  [0.60640961]\n",
      "  [0.61427462]\n",
      "  [0.62213075]\n",
      "  [0.62972349]\n",
      "  [0.63709962]\n",
      "  [0.64370781]\n",
      "  [0.65078378]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006803729571402073\n",
      "Predicción post entrenamiento : [[0.6577292]]\n",
      "PERDIDAAAA despues: 0.006708693690598011\n",
      "loss en el callback: 0.011835726909339428, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "ejemplar: [[0.60640961]\n",
      " [0.61427462]\n",
      " [0.62213075]\n",
      " [0.62972349]\n",
      " [0.63709962]\n",
      " [0.64370781]\n",
      " [0.65078378]\n",
      " [0.6571511 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.66437966]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[[0.60640961]\n",
      "  [0.61427462]\n",
      "  [0.62213075]\n",
      "  [0.62972349]\n",
      "  [0.63709962]\n",
      "  [0.64370781]\n",
      "  [0.65078378]\n",
      "  [0.6571511 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005150806158781052\n",
      "Predicción post entrenamiento : [[0.66468084]]\n",
      "PERDIDAAAA despues: 0.005107665900141001\n",
      "loss en el callback: 0.002677520038560033, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "ejemplar: [[0.61427462]\n",
      " [0.62213075]\n",
      " [0.62972349]\n",
      " [0.63709962]\n",
      " [0.64370781]\n",
      " [0.65078378]\n",
      " [0.6571511 ]\n",
      " [0.66437966]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.67117363]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[[0.61427462]\n",
      "  [0.62213075]\n",
      "  [0.62972349]\n",
      "  [0.63709962]\n",
      "  [0.64370781]\n",
      "  [0.65078378]\n",
      "  [0.6571511 ]\n",
      "  [0.66437966]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.2981046893401071e-05\n",
      "Predicción post entrenamiento : [[0.6715]]\n",
      "PERDIDAAAA despues: 1.5439532944583334e-05\n",
      "loss en el callback: 0.004027034621685743, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "ejemplar: [[0.62213075]\n",
      " [0.62972349]\n",
      " [0.63709962]\n",
      " [0.64370781]\n",
      " [0.65078378]\n",
      " [0.6571511 ]\n",
      " [0.66437966]\n",
      " [0.67117363]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.67784667]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[[0.62213075]\n",
      "  [0.62972349]\n",
      "  [0.63709962]\n",
      "  [0.64370781]\n",
      "  [0.65078378]\n",
      "  [0.6571511 ]\n",
      "  [0.66437966]\n",
      "  [0.67117363]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.322252738755196e-05\n",
      "Predicción post entrenamiento : [[0.67805845]]\n",
      "PERDIDAAAA despues: 6.663514068350196e-05\n",
      "loss en el callback: 0.0015360284596681595, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "ejemplar: [[0.62972349]\n",
      " [0.63709962]\n",
      " [0.64370781]\n",
      " [0.65078378]\n",
      " [0.6571511 ]\n",
      " [0.66437966]\n",
      " [0.67117363]\n",
      " [0.67784667]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.6842156]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[[0.62972349]\n",
      "  [0.63709962]\n",
      "  [0.64370781]\n",
      "  [0.65078378]\n",
      "  [0.6571511 ]\n",
      "  [0.66437966]\n",
      "  [0.67117363]\n",
      "  [0.67784667]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001540979865239933\n",
      "Predicción post entrenamiento : [[0.68506306]]\n",
      "PERDIDAAAA despues: 0.00013377610594034195\n",
      "loss en el callback: 0.042785514146089554, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "ejemplar: [[0.63709962]\n",
      " [0.64370781]\n",
      " [0.65078378]\n",
      " [0.6571511 ]\n",
      " [0.66437966]\n",
      " [0.67117363]\n",
      " [0.67784667]\n",
      " [0.68421561]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.6910592]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[[0.63709962]\n",
      "  [0.64370781]\n",
      "  [0.65078378]\n",
      "  [0.6571511 ]\n",
      "  [0.66437966]\n",
      "  [0.67117363]\n",
      "  [0.67784667]\n",
      "  [0.68421561]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012328416341915727\n",
      "Predicción post entrenamiento : [[0.6901307]]\n",
      "PERDIDAAAA despues: 0.0011685036588460207\n",
      "loss en el callback: 0.021959610283374786, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "ejemplar: [[0.64370781]\n",
      " [0.65078378]\n",
      " [0.6571511 ]\n",
      " [0.66437966]\n",
      " [0.67117363]\n",
      " [0.67784667]\n",
      " [0.68421561]\n",
      " [0.69105917]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.69598687]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[[0.64370781]\n",
      "  [0.65078378]\n",
      "  [0.6571511 ]\n",
      "  [0.66437966]\n",
      "  [0.67117363]\n",
      "  [0.67784667]\n",
      "  [0.68421561]\n",
      "  [0.69105917]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000295159436063841\n",
      "Predicción post entrenamiento : [[0.69575834]]\n",
      "PERDIDAAAA despues: 0.00028735946398228407\n",
      "loss en el callback: 0.0016550847794860601, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "ejemplar: [[0.65078378]\n",
      " [0.6571511 ]\n",
      " [0.66437966]\n",
      " [0.67117363]\n",
      " [0.67784667]\n",
      " [0.68421561]\n",
      " [0.69105917]\n",
      " [0.69598687]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.7016545]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[[0.65078378]\n",
      "  [0.6571511 ]\n",
      "  [0.66437966]\n",
      "  [0.67117363]\n",
      "  [0.67784667]\n",
      "  [0.68421561]\n",
      "  [0.69105917]\n",
      "  [0.69598687]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006533116684295237\n",
      "Predicción post entrenamiento : [[0.70176893]]\n",
      "PERDIDAAAA despues: 0.0006591749261133373\n",
      "loss en el callback: 0.0005040038377046585, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "ejemplar: [[0.6571511 ]\n",
      " [0.66437966]\n",
      " [0.67117363]\n",
      " [0.67784667]\n",
      " [0.68421561]\n",
      " [0.69105917]\n",
      " [0.69598687]\n",
      " [0.70165449]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.70755595]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[[0.6571511 ]\n",
      "  [0.66437966]\n",
      "  [0.67117363]\n",
      "  [0.67784667]\n",
      "  [0.68421561]\n",
      "  [0.69105917]\n",
      "  [0.69598687]\n",
      "  [0.70165449]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00048427344881929457\n",
      "Predicción post entrenamiento : [[0.7072658]]\n",
      "PERDIDAAAA despues: 0.0004971280577592552\n",
      "loss en el callback: 0.0021886297035962343, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "ejemplar: [[0.66437966]\n",
      " [0.67117363]\n",
      " [0.67784667]\n",
      " [0.68421561]\n",
      " [0.69105917]\n",
      " [0.69598687]\n",
      " [0.70165449]\n",
      " [0.70755595]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.7130944]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[[0.66437966]\n",
      "  [0.67117363]\n",
      "  [0.67784667]\n",
      "  [0.68421561]\n",
      "  [0.69105917]\n",
      "  [0.69598687]\n",
      "  [0.70165449]\n",
      "  [0.70755595]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001396142179146409\n",
      "Predicción post entrenamiento : [[0.7129178]]\n",
      "PERDIDAAAA despues: 0.00013547184062190354\n",
      "loss en el callback: 0.0010118638165295124, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "ejemplar: [[0.67117363]\n",
      " [0.67784667]\n",
      " [0.68421561]\n",
      " [0.69105917]\n",
      " [0.69598687]\n",
      " [0.70165449]\n",
      " [0.70755595]\n",
      " [0.71309441]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.7185175]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[[0.67117363]\n",
      "  [0.67784667]\n",
      "  [0.68421561]\n",
      "  [0.69105917]\n",
      "  [0.69598687]\n",
      "  [0.70165449]\n",
      "  [0.70755595]\n",
      "  [0.71309441]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0024024220183491707\n",
      "Predicción post entrenamiento : [[0.7184686]]\n",
      "PERDIDAAAA despues: 0.00240721576847136\n",
      "loss en el callback: 7.462163921445608e-05, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "ejemplar: [[0.67784667]\n",
      " [0.68421561]\n",
      " [0.69105917]\n",
      " [0.69598687]\n",
      " [0.70165449]\n",
      " [0.70755595]\n",
      " [0.71309441]\n",
      " [0.71851748]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.7238951]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[[0.67784667]\n",
      "  [0.68421561]\n",
      "  [0.69105917]\n",
      "  [0.69598687]\n",
      "  [0.70165449]\n",
      "  [0.70755595]\n",
      "  [0.71309441]\n",
      "  [0.71851748]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009758510859683156\n",
      "Predicción post entrenamiento : [[0.723621]]\n",
      "PERDIDAAAA despues: 0.000993048888631165\n",
      "loss en el callback: 0.0021551463287323713, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "ejemplar: [[0.68421561]\n",
      " [0.69105917]\n",
      " [0.69598687]\n",
      " [0.70165449]\n",
      " [0.70755595]\n",
      " [0.71309441]\n",
      " [0.71851748]\n",
      " [0.72389507]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.72885394]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[[0.68421561]\n",
      "  [0.69105917]\n",
      "  [0.69598687]\n",
      "  [0.70165449]\n",
      "  [0.70755595]\n",
      "  [0.71309441]\n",
      "  [0.71851748]\n",
      "  [0.72389507]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002626372152008116\n",
      "Predicción post entrenamiento : [[0.7289818]]\n",
      "PERDIDAAAA despues: 0.0002585095935501158\n",
      "loss en el callback: 0.0005427090800367296, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "ejemplar: [[0.69105917]\n",
      " [0.69598687]\n",
      " [0.70165449]\n",
      " [0.70755595]\n",
      " [0.71309441]\n",
      " [0.71851748]\n",
      " [0.72389507]\n",
      " [0.72885394]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.7340542]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[[0.69105917]\n",
      "  [0.69598687]\n",
      "  [0.70165449]\n",
      "  [0.70755595]\n",
      "  [0.71309441]\n",
      "  [0.71851748]\n",
      "  [0.72389507]\n",
      "  [0.72885394]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003232753660995513\n",
      "Predicción post entrenamiento : [[0.73452425]]\n",
      "PERDIDAAAA despues: 0.00030659371986985207\n",
      "loss en el callback: 0.008911965414881706, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "ejemplar: [[0.69598687]\n",
      " [0.70165449]\n",
      " [0.70755595]\n",
      " [0.71309441]\n",
      " [0.71851748]\n",
      " [0.72389507]\n",
      " [0.72885394]\n",
      " [0.73405421]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.7392626]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[[0.69598687]\n",
      "  [0.70165449]\n",
      "  [0.70755595]\n",
      "  [0.71309441]\n",
      "  [0.71851748]\n",
      "  [0.72389507]\n",
      "  [0.72885394]\n",
      "  [0.73405421]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008679028833284974\n",
      "Predicción post entrenamiento : [[0.7388352]]\n",
      "PERDIDAAAA despues: 0.0008429050212725997\n",
      "loss en el callback: 0.005925754550844431, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "ejemplar: [[0.70165449]\n",
      " [0.70755595]\n",
      " [0.71309441]\n",
      " [0.71851748]\n",
      " [0.72389507]\n",
      " [0.72885394]\n",
      " [0.73405421]\n",
      " [0.73926258]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.7437167]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[[0.70165449]\n",
      "  [0.70755595]\n",
      "  [0.71309441]\n",
      "  [0.71851748]\n",
      "  [0.72389507]\n",
      "  [0.72885394]\n",
      "  [0.73405421]\n",
      "  [0.73926258]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002839469350874424\n",
      "Predicción post entrenamiento : [[0.74310404]]\n",
      "PERDIDAAAA despues: 0.0027745498809963465\n",
      "loss en el callback: 0.012337466701865196, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "ejemplar: [[0.70755595]\n",
      " [0.71309441]\n",
      " [0.71851748]\n",
      " [0.72389507]\n",
      " [0.72885394]\n",
      " [0.73405421]\n",
      " [0.73926258]\n",
      " [0.74371672]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.7479215]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[[0.70755595]\n",
      "  [0.71309441]\n",
      "  [0.71851748]\n",
      "  [0.72389507]\n",
      "  [0.72885394]\n",
      "  [0.73405421]\n",
      "  [0.73926258]\n",
      "  [0.74371672]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.1438084736000746e-05\n",
      "Predicción post entrenamiento : [[0.7482856]]\n",
      "PERDIDAAAA despues: 3.68834771506954e-05\n",
      "loss en el callback: 0.005366627126932144, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "ejemplar: [[0.71309441]\n",
      " [0.71851748]\n",
      " [0.72389507]\n",
      " [0.72885394]\n",
      " [0.73405421]\n",
      " [0.73926258]\n",
      " [0.74371672]\n",
      " [0.74792153]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.75294065]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[[0.71309441]\n",
      "  [0.71851748]\n",
      "  [0.72389507]\n",
      "  [0.72885394]\n",
      "  [0.73405421]\n",
      "  [0.73926258]\n",
      "  [0.74371672]\n",
      "  [0.74792153]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009449453209526837\n",
      "Predicción post entrenamiento : [[0.75293374]]\n",
      "PERDIDAAAA despues: 0.0009445202886126935\n",
      "loss en el callback: 1.8782417328111478e-06, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "ejemplar: [[0.71851748]\n",
      " [0.72389507]\n",
      " [0.72885394]\n",
      " [0.73405421]\n",
      " [0.73926258]\n",
      " [0.74371672]\n",
      " [0.74792153]\n",
      " [0.75294065]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.7574828]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[[0.71851748]\n",
      "  [0.72389507]\n",
      "  [0.72885394]\n",
      "  [0.73405421]\n",
      "  [0.73926258]\n",
      "  [0.74371672]\n",
      "  [0.74792153]\n",
      "  [0.75294065]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008285647258162498\n",
      "Predicción post entrenamiento : [[0.75843376]]\n",
      "PERDIDAAAA despues: 0.008113433606922626\n",
      "loss en el callback: 0.041360899806022644, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "ejemplar: [[0.72389507]\n",
      " [0.72885394]\n",
      " [0.73405421]\n",
      " [0.73926258]\n",
      " [0.74371672]\n",
      " [0.74792153]\n",
      " [0.75294065]\n",
      " [0.75748283]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.7628748]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[[0.72389507]\n",
      "  [0.72885394]\n",
      "  [0.73405421]\n",
      "  [0.73926258]\n",
      "  [0.74371672]\n",
      "  [0.74792153]\n",
      "  [0.75294065]\n",
      "  [0.75748283]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02033139392733574\n",
      "Predicción post entrenamiento : [[0.7633342]]\n",
      "PERDIDAAAA despues: 0.020200585946440697\n",
      "loss en el callback: 0.007816868834197521, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "ejemplar: [[0.72885394]\n",
      " [0.73405421]\n",
      " [0.73926258]\n",
      " [0.74371672]\n",
      " [0.74792153]\n",
      " [0.75294065]\n",
      " [0.75748283]\n",
      " [0.76287478]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.7676504]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[[0.72885394]\n",
      "  [0.73405421]\n",
      "  [0.73926258]\n",
      "  [0.74371672]\n",
      "  [0.74792153]\n",
      "  [0.75294065]\n",
      "  [0.75748283]\n",
      "  [0.76287478]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013125319965183735\n",
      "Predicción post entrenamiento : [[0.7684257]]\n",
      "PERDIDAAAA despues: 0.012948280200362206\n",
      "loss en el callback: 0.025657834485173225, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "ejemplar: [[0.73405421]\n",
      " [0.73926258]\n",
      " [0.74371672]\n",
      " [0.74792153]\n",
      " [0.75294065]\n",
      " [0.75748283]\n",
      " [0.76287478]\n",
      " [0.76765043]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.7727106]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[[0.73405421]\n",
      "  [0.73926258]\n",
      "  [0.74371672]\n",
      "  [0.74792153]\n",
      "  [0.75294065]\n",
      "  [0.75748283]\n",
      "  [0.76287478]\n",
      "  [0.76765043]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018245812505483627\n",
      "Predicción post entrenamiento : [[0.77329546]]\n",
      "PERDIDAAAA despues: 0.01808815635740757\n",
      "loss en el callback: 0.013193750753998756, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "ejemplar: [[0.73926258]\n",
      " [0.74371672]\n",
      " [0.74792153]\n",
      " [0.75294065]\n",
      " [0.75748283]\n",
      " [0.76287478]\n",
      " [0.76765043]\n",
      " [0.77271062]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.77747536]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[[0.73926258]\n",
      "  [0.74371672]\n",
      "  [0.74792153]\n",
      "  [0.75294065]\n",
      "  [0.75748283]\n",
      "  [0.76287478]\n",
      "  [0.76765043]\n",
      "  [0.77271062]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01256693247705698\n",
      "Predicción post entrenamiento : [[0.7772268]]\n",
      "PERDIDAAAA despues: 0.012622720561921597\n",
      "loss en el callback: 0.001856798306107521, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "ejemplar: [[0.74371672]\n",
      " [0.74792153]\n",
      " [0.75294065]\n",
      " [0.75748283]\n",
      " [0.76287478]\n",
      " [0.76765043]\n",
      " [0.77271062]\n",
      " [0.77747536]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.78128886]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[[0.74371672]\n",
      "  [0.74792153]\n",
      "  [0.75294065]\n",
      "  [0.75748283]\n",
      "  [0.76287478]\n",
      "  [0.76765043]\n",
      "  [0.77271062]\n",
      "  [0.77747536]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008754562586545944\n",
      "Predicción post entrenamiento : [[0.7814404]]\n",
      "PERDIDAAAA despues: 0.008726232685148716\n",
      "loss en el callback: 0.0007951341685838997, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "ejemplar: [[0.74792153]\n",
      " [0.75294065]\n",
      " [0.75748283]\n",
      " [0.76287478]\n",
      " [0.76765043]\n",
      " [0.77271062]\n",
      " [0.77747536]\n",
      " [0.78128886]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.78558713]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[[0.74792153]\n",
      "  [0.75294065]\n",
      "  [0.75748283]\n",
      "  [0.76287478]\n",
      "  [0.76765043]\n",
      "  [0.77271062]\n",
      "  [0.77747536]\n",
      "  [0.78128886]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016288092359900475\n",
      "Predicción post entrenamiento : [[0.78605306]]\n",
      "PERDIDAAAA despues: 0.016169380396604538\n",
      "loss en el callback: 0.007425929419696331, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "ejemplar: [[0.75294065]\n",
      " [0.75748283]\n",
      " [0.76287478]\n",
      " [0.76765043]\n",
      " [0.77271062]\n",
      " [0.77747536]\n",
      " [0.78128886]\n",
      " [0.78558713]]\n",
      "ejemplar: (8, 1)\n",
      "y: 1.0\n",
      "Predicción : [[0.790363]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[[0.75294065]\n",
      "  [0.75748283]\n",
      "  [0.76287478]\n",
      "  [0.76765043]\n",
      "  [0.77271062]\n",
      "  [0.77747536]\n",
      "  [0.78128886]\n",
      "  [0.78558713]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04394766688346863\n",
      "Predicción post entrenamiento : [[0.7916249]]\n",
      "PERDIDAAAA despues: 0.043420180678367615\n",
      "loss en el callback: 0.06882862746715546, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "ejemplar: [[0.75748283]\n",
      " [0.76287478]\n",
      " [0.76765043]\n",
      " [0.77271062]\n",
      " [0.77747536]\n",
      " [0.78128886]\n",
      " [0.78558713]\n",
      " [0.79036301]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.7958781]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[[0.75748283]\n",
      "  [0.76287478]\n",
      "  [0.76765043]\n",
      "  [0.77271062]\n",
      "  [0.77747536]\n",
      "  [0.78128886]\n",
      "  [0.78558713]\n",
      "  [0.79036301]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.030511684715747833\n",
      "Predicción post entrenamiento : [[0.79675347]]\n",
      "PERDIDAAAA despues: 0.030206644907593727\n",
      "loss en el callback: 0.03140764310956001, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "ejemplar: [[0.76287478]\n",
      " [0.76765043]\n",
      " [0.77271062]\n",
      " [0.77747536]\n",
      " [0.78128886]\n",
      " [0.78558713]\n",
      " [0.79036301]\n",
      " [0.79587811]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.80106586]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[[0.76287478]\n",
      "  [0.76765043]\n",
      "  [0.77271062]\n",
      "  [0.77747536]\n",
      "  [0.78128886]\n",
      "  [0.78558713]\n",
      "  [0.79036301]\n",
      "  [0.79587811]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007697764318436384\n",
      "Predicción post entrenamiento : [[0.8012634]]\n",
      "PERDIDAAAA despues: 0.0076631419360637665\n",
      "loss en el callback: 0.0014108779141679406, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "ejemplar: [[0.76765043]\n",
      " [0.77271062]\n",
      " [0.77747536]\n",
      " [0.78128886]\n",
      " [0.78558713]\n",
      " [0.79036301]\n",
      " [0.79587811]\n",
      " [0.80106586]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.80539536]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[[0.76765043]\n",
      "  [0.77271062]\n",
      "  [0.77747536]\n",
      "  [0.78128886]\n",
      "  [0.78558713]\n",
      "  [0.79036301]\n",
      "  [0.79587811]\n",
      "  [0.80106586]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005264799576252699\n",
      "Predicción post entrenamiento : [[0.80508983]]\n",
      "PERDIDAAAA despues: 0.0053092315793037415\n",
      "loss en el callback: 0.0028778514824807644, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "ejemplar: [[0.77271062]\n",
      " [0.77747536]\n",
      " [0.78128886]\n",
      " [0.78558713]\n",
      " [0.79036301]\n",
      " [0.79587811]\n",
      " [0.80106586]\n",
      " [0.80539536]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.8091921]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[[0.77271062]\n",
      "  [0.77747536]\n",
      "  [0.78128886]\n",
      "  [0.78558713]\n",
      "  [0.79036301]\n",
      "  [0.79587811]\n",
      "  [0.80106586]\n",
      "  [0.80539536]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015763811534270644\n",
      "Predicción post entrenamiento : [[0.8090866]]\n",
      "PERDIDAAAA despues: 0.0015847698086872697\n",
      "loss en el callback: 0.00039695805753581226, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "ejemplar: [[0.77747536]\n",
      " [0.78128886]\n",
      " [0.78558713]\n",
      " [0.79036301]\n",
      " [0.79587811]\n",
      " [0.80106586]\n",
      " [0.80539536]\n",
      " [0.80919212]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.81307685]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[[0.77747536]\n",
      "  [0.78128886]\n",
      "  [0.78558713]\n",
      "  [0.79036301]\n",
      "  [0.79587811]\n",
      "  [0.80106586]\n",
      "  [0.80539536]\n",
      "  [0.80919212]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00044503831304609776\n",
      "Predicción post entrenamiento : [[0.8126428]]\n",
      "PERDIDAAAA despues: 0.00046353970537893474\n",
      "loss en el callback: 0.006337579805403948, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "ejemplar: [[0.78128886]\n",
      " [0.78558713]\n",
      " [0.79036301]\n",
      " [0.79587811]\n",
      " [0.80106586]\n",
      " [0.80539536]\n",
      " [0.80919212]\n",
      " [0.81307685]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.8165895]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[[0.78128886]\n",
      "  [0.78558713]\n",
      "  [0.79036301]\n",
      "  [0.79587811]\n",
      "  [0.80106586]\n",
      "  [0.80539536]\n",
      "  [0.80919212]\n",
      "  [0.81307685]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014826685655862093\n",
      "Predicción post entrenamiento : [[0.8162892]]\n",
      "PERDIDAAAA despues: 0.0015058841090649366\n",
      "loss en el callback: 0.003279489930719137, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "ejemplar: [[0.78558713]\n",
      " [0.79036301]\n",
      " [0.79587811]\n",
      " [0.80106586]\n",
      " [0.80539536]\n",
      " [0.80919212]\n",
      " [0.81307685]\n",
      " [0.81658947]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.82044786]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[[0.78558713]\n",
      "  [0.79036301]\n",
      "  [0.79587811]\n",
      "  [0.80106586]\n",
      "  [0.80539536]\n",
      "  [0.80919212]\n",
      "  [0.81307685]\n",
      "  [0.81658947]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0030024165753275156\n",
      "Predicción post entrenamiento : [[0.81946015]]\n",
      "PERDIDAAAA despues: 0.0031116337049752474\n",
      "loss en el callback: 0.02888067625463009, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "ejemplar: [[0.79036301]\n",
      " [0.79587811]\n",
      " [0.80106586]\n",
      " [0.80539536]\n",
      " [0.80919212]\n",
      " [0.81307685]\n",
      " [0.81658947]\n",
      " [0.82044786]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.82369375]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[[0.79036301]\n",
      "  [0.79587811]\n",
      "  [0.80106586]\n",
      "  [0.80539536]\n",
      "  [0.80919212]\n",
      "  [0.81307685]\n",
      "  [0.81658947]\n",
      "  [0.82044786]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011114507215097547\n",
      "Predicción post entrenamiento : [[0.8237181]]\n",
      "PERDIDAAAA despues: 0.0011098298709839582\n",
      "loss en el callback: 2.6735551728052087e-05, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "ejemplar: [[0.79587811]\n",
      " [0.80106586]\n",
      " [0.80539536]\n",
      " [0.80919212]\n",
      " [0.81307685]\n",
      " [0.81658947]\n",
      " [0.82044786]\n",
      " [0.82369375]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.82786065]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[[0.79587811]\n",
      "  [0.80106586]\n",
      "  [0.80539536]\n",
      "  [0.80919212]\n",
      "  [0.81307685]\n",
      "  [0.81658947]\n",
      "  [0.82044786]\n",
      "  [0.82369375]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004927283152937889\n",
      "Predicción post entrenamiento : [[0.82854986]]\n",
      "PERDIDAAAA despues: 0.00046260596718639135\n",
      "loss en el callback: 0.030589299276471138, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "ejemplar: [[0.80106586]\n",
      " [0.80539536]\n",
      " [0.80919212]\n",
      " [0.81307685]\n",
      " [0.81658947]\n",
      " [0.82044786]\n",
      " [0.82369375]\n",
      " [0.82786065]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.83233833]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[[0.80106586]\n",
      "  [0.80539536]\n",
      "  [0.80919212]\n",
      "  [0.81307685]\n",
      "  [0.81658947]\n",
      "  [0.82044786]\n",
      "  [0.82369375]\n",
      "  [0.82786065]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001072938393917866\n",
      "Predicción post entrenamiento : [[0.8322163]]\n",
      "PERDIDAAAA despues: 0.00010983636457240209\n",
      "loss en el callback: 0.0006593371508643031, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "ejemplar: [[0.80539536]\n",
      " [0.80919212]\n",
      " [0.81307685]\n",
      " [0.81658947]\n",
      " [0.82044786]\n",
      " [0.82369375]\n",
      " [0.82786065]\n",
      " [0.83233833]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.83567154]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[[0.80539536]\n",
      "  [0.80919212]\n",
      "  [0.81307685]\n",
      "  [0.81658947]\n",
      "  [0.82044786]\n",
      "  [0.82369375]\n",
      "  [0.82786065]\n",
      "  [0.83233833]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00016217287338804454\n",
      "Predicción post entrenamiento : [[0.83645135]]\n",
      "PERDIDAAAA despues: 0.00018264222308062017\n",
      "loss en el callback: 0.045774057507514954, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "ejemplar: [[0.80919212]\n",
      " [0.81307685]\n",
      " [0.81658947]\n",
      " [0.82044786]\n",
      " [0.82369375]\n",
      " [0.82786065]\n",
      " [0.83233833]\n",
      " [0.83567154]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.83976656]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[[0.80919212]\n",
      "  [0.81307685]\n",
      "  [0.81658947]\n",
      "  [0.82044786]\n",
      "  [0.82369375]\n",
      "  [0.82786065]\n",
      "  [0.83233833]\n",
      "  [0.83567154]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004258936736732721\n",
      "Predicción post entrenamiento : [[0.8393694]]\n",
      "PERDIDAAAA despues: 0.004207258578389883\n",
      "loss en el callback: 0.007641295436769724, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "ejemplar: [[0.81307685]\n",
      " [0.81658947]\n",
      " [0.82044786]\n",
      " [0.82369375]\n",
      " [0.82786065]\n",
      " [0.83233833]\n",
      " [0.83567154]\n",
      " [0.83976656]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.8426792]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[[0.81307685]\n",
      "  [0.81658947]\n",
      "  [0.82044786]\n",
      "  [0.82369375]\n",
      "  [0.82786065]\n",
      "  [0.83233833]\n",
      "  [0.83567154]\n",
      "  [0.83976656]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0034207359421998262\n",
      "Predicción post entrenamiento : [[0.8429501]]\n",
      "PERDIDAAAA despues: 0.003452498000115156\n",
      "loss en el callback: 0.004638028796762228, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "ejemplar: [[0.81658947]\n",
      " [0.82044786]\n",
      " [0.82369375]\n",
      " [0.82786065]\n",
      " [0.83233833]\n",
      " [0.83567154]\n",
      " [0.83976656]\n",
      " [0.8426792 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.84623057]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[[0.81658947]\n",
      "  [0.82044786]\n",
      "  [0.82369375]\n",
      "  [0.82786065]\n",
      "  [0.83233833]\n",
      "  [0.83567154]\n",
      "  [0.83976656]\n",
      "  [0.8426792 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00018262126832269132\n",
      "Predicción post entrenamiento : [[0.84595007]]\n",
      "PERDIDAAAA despues: 0.00019028114911634475\n",
      "loss en el callback: 0.003350547980517149, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "ejemplar: [[0.82044786]\n",
      " [0.82369375]\n",
      " [0.82786065]\n",
      " [0.83233833]\n",
      " [0.83567154]\n",
      " [0.83976656]\n",
      " [0.8426792 ]\n",
      " [0.84623057]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.8493012]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[[0.82044786]\n",
      "  [0.82369375]\n",
      "  [0.82786065]\n",
      "  [0.83233833]\n",
      "  [0.83567154]\n",
      "  [0.83976656]\n",
      "  [0.8426792 ]\n",
      "  [0.84623057]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.518865767342504e-05\n",
      "Predicción post entrenamiento : [[0.84898585]]\n",
      "PERDIDAAAA despues: 2.8453672712203115e-05\n",
      "loss en el callback: 0.00400967663154006, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "ejemplar: [[0.82369375]\n",
      " [0.82786065]\n",
      " [0.83233833]\n",
      " [0.83567154]\n",
      " [0.83976656]\n",
      " [0.8426792 ]\n",
      " [0.84623057]\n",
      " [0.84930122]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.8523088]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[[0.82369375]\n",
      "  [0.82786065]\n",
      "  [0.83233833]\n",
      "  [0.83567154]\n",
      "  [0.83976656]\n",
      "  [0.8426792 ]\n",
      "  [0.84623057]\n",
      "  [0.84930122]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00023789650003891438\n",
      "Predicción post entrenamiento : [[0.85206485]]\n",
      "PERDIDAAAA despues: 0.00023043033434078097\n",
      "loss en el callback: 0.0025713250506669283, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "ejemplar: [[0.82786065]\n",
      " [0.83233833]\n",
      " [0.83567154]\n",
      " [0.83976656]\n",
      " [0.8426792 ]\n",
      " [0.84623057]\n",
      " [0.84930122]\n",
      " [0.85230881]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.8555127]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[[0.82786065]\n",
      "  [0.83233833]\n",
      "  [0.83567154]\n",
      "  [0.83976656]\n",
      "  [0.8426792 ]\n",
      "  [0.84623057]\n",
      "  [0.84930122]\n",
      "  [0.85230881]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006554523715749383\n",
      "Predicción post entrenamiento : [[0.8550044]]\n",
      "PERDIDAAAA despues: 0.0006296835490502417\n",
      "loss en el callback: 0.01099319662898779, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "ejemplar: [[0.83233833]\n",
      " [0.83567154]\n",
      " [0.83976656]\n",
      " [0.8426792 ]\n",
      " [0.84623057]\n",
      " [0.84930122]\n",
      " [0.85230881]\n",
      " [0.85551268]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.858304]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[[0.83233833]\n",
      "  [0.83567154]\n",
      "  [0.83976656]\n",
      "  [0.8426792 ]\n",
      "  [0.84623057]\n",
      "  [0.84930122]\n",
      "  [0.85230881]\n",
      "  [0.85551268]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008380424696952105\n",
      "Predicción post entrenamiento : [[0.85754806]]\n",
      "PERDIDAAAA despues: 0.0008823827956803143\n",
      "loss en el callback: 0.022389139980077744, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "ejemplar: [[0.83567154]\n",
      " [0.83976656]\n",
      " [0.8426792 ]\n",
      " [0.84623057]\n",
      " [0.84930122]\n",
      " [0.85230881]\n",
      " [0.85551268]\n",
      " [0.85830402]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.86056495]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[[0.83567154]\n",
      "  [0.83976656]\n",
      "  [0.8426792 ]\n",
      "  [0.84623057]\n",
      "  [0.84930122]\n",
      "  [0.85230881]\n",
      "  [0.85551268]\n",
      "  [0.85830402]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.734446742484579e-07\n",
      "Predicción post entrenamiento : [[0.8604538]]\n",
      "PERDIDAAAA despues: 5.033534762333147e-07\n",
      "loss en el callback: 0.0005983478622511029, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "ejemplar: [[0.83976656]\n",
      " [0.8426792 ]\n",
      " [0.84623057]\n",
      " [0.84930122]\n",
      " [0.85230881]\n",
      " [0.85551268]\n",
      " [0.85830402]\n",
      " [0.86056495]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.8634547]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[[0.83976656]\n",
      "  [0.8426792 ]\n",
      "  [0.84623057]\n",
      "  [0.84930122]\n",
      "  [0.85230881]\n",
      "  [0.85551268]\n",
      "  [0.85830402]\n",
      "  [0.86056495]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005691876285709441\n",
      "Predicción post entrenamiento : [[0.86315435]]\n",
      "PERDIDAAAA despues: 0.000554946658667177\n",
      "loss en el callback: 0.004042231477797031, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "ejemplar: [[0.8426792 ]\n",
      " [0.84623057]\n",
      " [0.84930122]\n",
      " [0.85230881]\n",
      " [0.85551268]\n",
      " [0.85830402]\n",
      " [0.86056495]\n",
      " [0.8634547 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.8658978]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[[0.8426792 ]\n",
      "  [0.84623057]\n",
      "  [0.84930122]\n",
      "  [0.85230881]\n",
      "  [0.85551268]\n",
      "  [0.85830402]\n",
      "  [0.86056495]\n",
      "  [0.8634547 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006739270407706499\n",
      "Predicción post entrenamiento : [[0.865305]]\n",
      "PERDIDAAAA despues: 0.006642297375947237\n",
      "loss en el callback: 0.01681128516793251, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "ejemplar: [[0.84623057]\n",
      " [0.84930122]\n",
      " [0.85230881]\n",
      " [0.85551268]\n",
      " [0.85830402]\n",
      " [0.86056495]\n",
      " [0.8634547 ]\n",
      " [0.86589777]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.86807543]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[[0.84623057]\n",
      "  [0.84930122]\n",
      "  [0.85230881]\n",
      "  [0.85551268]\n",
      "  [0.85830402]\n",
      "  [0.86056495]\n",
      "  [0.8634547 ]\n",
      "  [0.86589777]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00247883889824152\n",
      "Predicción post entrenamiento : [[0.86761576]]\n",
      "PERDIDAAAA despues: 0.0024332778993993998\n",
      "loss en el callback: 0.01048042718321085, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "ejemplar: [[0.84930122]\n",
      " [0.85230881]\n",
      " [0.85551268]\n",
      " [0.85830402]\n",
      " [0.86056495]\n",
      " [0.8634547 ]\n",
      " [0.86589777]\n",
      " [0.86807543]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.8702126]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[[0.84930122]\n",
      "  [0.85230881]\n",
      "  [0.85551268]\n",
      "  [0.85830402]\n",
      "  [0.86056495]\n",
      "  [0.8634547 ]\n",
      "  [0.86589777]\n",
      "  [0.86807543]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006248337682336569\n",
      "Predicción post entrenamiento : [[0.86989415]]\n",
      "PERDIDAAAA despues: 0.006198091898113489\n",
      "loss en el callback: 0.00500412005931139, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "ejemplar: [[0.85230881]\n",
      " [0.85551268]\n",
      " [0.85830402]\n",
      " [0.86056495]\n",
      " [0.8634547 ]\n",
      " [0.86589777]\n",
      " [0.86807543]\n",
      " [0.87021261]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.8724101]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[[0.85230881]\n",
      "  [0.85551268]\n",
      "  [0.85830402]\n",
      "  [0.86056495]\n",
      "  [0.8634547 ]\n",
      "  [0.86589777]\n",
      "  [0.86807543]\n",
      "  [0.87021261]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012510907836258411\n",
      "Predicción post entrenamiento : [[0.871937]]\n",
      "PERDIDAAAA despues: 0.012405287474393845\n",
      "loss en el callback: 0.01217658631503582, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "ejemplar: [[0.85551268]\n",
      " [0.85830402]\n",
      " [0.86056495]\n",
      " [0.8634547 ]\n",
      " [0.86589777]\n",
      " [0.86807543]\n",
      " [0.87021261]\n",
      " [0.87241012]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.87435716]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[[0.85551268]\n",
      "  [0.85830402]\n",
      "  [0.86056495]\n",
      "  [0.8634547 ]\n",
      "  [0.86589777]\n",
      "  [0.86807543]\n",
      "  [0.87021261]\n",
      "  [0.87241012]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006856417749077082\n",
      "Predicción post entrenamiento : [[0.87397486]]\n",
      "PERDIDAAAA despues: 0.0067932517267763615\n",
      "loss en el callback: 0.0079000573605299, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "ejemplar: [[0.85830402]\n",
      " [0.86056495]\n",
      " [0.8634547 ]\n",
      " [0.86589777]\n",
      " [0.86807543]\n",
      " [0.87021261]\n",
      " [0.87241012]\n",
      " [0.87435716]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.8762091]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[[0.85830402]\n",
      "  [0.86056495]\n",
      "  [0.8634547 ]\n",
      "  [0.86589777]\n",
      "  [0.86807543]\n",
      "  [0.87021261]\n",
      "  [0.87241012]\n",
      "  [0.87435716]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011559432372450829\n",
      "Predicción post entrenamiento : [[0.87551314]]\n",
      "PERDIDAAAA despues: 0.011410268023610115\n",
      "loss en el callback: 0.02312234416604042, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "ejemplar: [[0.86056495]\n",
      " [0.8634547 ]\n",
      " [0.86589777]\n",
      " [0.86807543]\n",
      " [0.87021261]\n",
      " [0.87241012]\n",
      " [0.87435716]\n",
      " [0.87620908]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.8776356]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[[0.86056495]\n",
      "  [0.8634547 ]\n",
      "  [0.86589777]\n",
      "  [0.86807543]\n",
      "  [0.87021261]\n",
      "  [0.87241012]\n",
      "  [0.87435716]\n",
      "  [0.87620908]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011868210509419441\n",
      "Predicción post entrenamiento : [[0.8774474]]\n",
      "PERDIDAAAA despues: 0.01182724628597498\n",
      "loss en el callback: 0.002372663002461195, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "ejemplar: [[0.8634547 ]\n",
      " [0.86589777]\n",
      " [0.86807543]\n",
      " [0.87021261]\n",
      " [0.87241012]\n",
      " [0.87435716]\n",
      " [0.87620908]\n",
      " [0.8776356 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.8795755]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[[0.8634547 ]\n",
      "  [0.86589777]\n",
      "  [0.86807543]\n",
      "  [0.87021261]\n",
      "  [0.87241012]\n",
      "  [0.87435716]\n",
      "  [0.87620908]\n",
      "  [0.8776356 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006506090983748436\n",
      "Predicción post entrenamiento : [[0.8787564]]\n",
      "PERDIDAAAA despues: 0.006374625954777002\n",
      "loss en el callback: 0.02981390245258808, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "ejemplar: [[0.86589777]\n",
      " [0.86807543]\n",
      " [0.87021261]\n",
      " [0.87241012]\n",
      " [0.87435716]\n",
      " [0.87620908]\n",
      " [0.8776356 ]\n",
      " [0.87957549]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.88068897]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[[0.86589777]\n",
      "  [0.86807543]\n",
      "  [0.87021261]\n",
      "  [0.87241012]\n",
      "  [0.87435716]\n",
      "  [0.87620908]\n",
      "  [0.8776356 ]\n",
      "  [0.87957549]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008223782293498516\n",
      "Predicción post entrenamiento : [[0.8799839]]\n",
      "PERDIDAAAA despues: 0.008096401579678059\n",
      "loss en el callback: 0.02304341457784176, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "ejemplar: [[0.86807543]\n",
      " [0.87021261]\n",
      " [0.87241012]\n",
      " [0.87435716]\n",
      " [0.87620908]\n",
      " [0.8776356 ]\n",
      " [0.87957549]\n",
      " [0.88068897]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.8818019]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[[0.86807543]\n",
      "  [0.87021261]\n",
      "  [0.87241012]\n",
      "  [0.87435716]\n",
      "  [0.87620908]\n",
      "  [0.8776356 ]\n",
      "  [0.87957549]\n",
      "  [0.88068897]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014794208109378815\n",
      "Predicción post entrenamiento : [[0.8817076]]\n",
      "PERDIDAAAA despues: 0.014771278947591782\n",
      "loss en el callback: 0.0006161078345030546, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "ejemplar: [[0.87021261]\n",
      " [0.87241012]\n",
      " [0.87435716]\n",
      " [0.87620908]\n",
      " [0.8776356 ]\n",
      " [0.87957549]\n",
      " [0.88068897]\n",
      " [0.8818019 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.88345]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[[0.87021261]\n",
      "  [0.87241012]\n",
      "  [0.87435716]\n",
      "  [0.87620908]\n",
      "  [0.8776356 ]\n",
      "  [0.87957549]\n",
      "  [0.88068897]\n",
      "  [0.8818019 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03922645375132561\n",
      "Predicción post entrenamiento : [[0.8823927]]\n",
      "PERDIDAAAA despues: 0.03880877420306206\n",
      "loss en el callback: 0.05821320042014122, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "ejemplar: [[0.87241012]\n",
      " [0.87435716]\n",
      " [0.87620908]\n",
      " [0.8776356 ]\n",
      " [0.87957549]\n",
      " [0.88068897]\n",
      " [0.8818019 ]\n",
      " [0.88344997]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.88403845]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[[0.87241012]\n",
      "  [0.87435716]\n",
      "  [0.87620908]\n",
      "  [0.8776356 ]\n",
      "  [0.87957549]\n",
      "  [0.88068897]\n",
      "  [0.8818019 ]\n",
      "  [0.88344997]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07775547355413437\n",
      "Predicción post entrenamiento : [[0.8827032]]\n",
      "PERDIDAAAA despues: 0.07701258361339569\n",
      "loss en el callback: 0.09662110358476639, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "ejemplar: [[0.87435716]\n",
      " [0.87620908]\n",
      " [0.8776356 ]\n",
      " [0.87957549]\n",
      " [0.88068897]\n",
      " [0.8818019 ]\n",
      " [0.88344997]\n",
      " [0.88403845]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.88419884]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[[0.87435716]\n",
      "  [0.87620908]\n",
      "  [0.8776356 ]\n",
      "  [0.87957549]\n",
      "  [0.88068897]\n",
      "  [0.8818019 ]\n",
      "  [0.88344997]\n",
      "  [0.88403845]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.048110153526067734\n",
      "Predicción post entrenamiento : [[0.8832616]]\n",
      "PERDIDAAAA despues: 0.04769988730549812\n",
      "loss en el callback: 0.05182769149541855, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "ejemplar: [[0.87620908]\n",
      " [0.8776356 ]\n",
      " [0.87957549]\n",
      " [0.88068897]\n",
      " [0.8818019 ]\n",
      " [0.88344997]\n",
      " [0.88403845]\n",
      " [0.88419884]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.8846316]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[[0.87620908]\n",
      "  [0.8776356 ]\n",
      "  [0.87957549]\n",
      "  [0.88068897]\n",
      "  [0.8818019 ]\n",
      "  [0.88344997]\n",
      "  [0.88403845]\n",
      "  [0.88419884]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.031246358528733253\n",
      "Predicción post entrenamiento : [[0.8839652]]\n",
      "PERDIDAAAA despues: 0.031011216342449188\n",
      "loss en el callback: 0.026895171031355858, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "ejemplar: [[0.8776356 ]\n",
      " [0.87957549]\n",
      " [0.88068897]\n",
      " [0.8818019 ]\n",
      " [0.88344997]\n",
      " [0.88403845]\n",
      " [0.88419884]\n",
      " [0.88463157]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.8851896]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[[0.8776356 ]\n",
      "  [0.87957549]\n",
      "  [0.88068897]\n",
      "  [0.8818019 ]\n",
      "  [0.88344997]\n",
      "  [0.88403845]\n",
      "  [0.88419884]\n",
      "  [0.88463157]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.048545755445957184\n",
      "Predicción post entrenamiento : [[0.8847442]]\n",
      "PERDIDAAAA despues: 0.04834969714283943\n",
      "loss en el callback: 0.014052816666662693, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "ejemplar: [[0.87957549]\n",
      " [0.88068897]\n",
      " [0.8818019 ]\n",
      " [0.88344997]\n",
      " [0.88403845]\n",
      " [0.88419884]\n",
      " [0.88463157]\n",
      " [0.88518959]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.88589424]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[[0.87957549]\n",
      "  [0.88068897]\n",
      "  [0.8818019 ]\n",
      "  [0.88344997]\n",
      "  [0.88403845]\n",
      "  [0.88419884]\n",
      "  [0.88463157]\n",
      "  [0.88518959]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.030464934185147285\n",
      "Predicción post entrenamiento : [[0.88541776]]\n",
      "PERDIDAAAA despues: 0.030298829078674316\n",
      "loss en el callback: 0.016225667670369148, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "ejemplar: [[0.88068897]\n",
      " [0.8818019 ]\n",
      " [0.88344997]\n",
      " [0.88403845]\n",
      " [0.88419884]\n",
      " [0.88463157]\n",
      " [0.88518959]\n",
      " [0.88589424]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.88630724]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[[0.88068897]\n",
      "  [0.8818019 ]\n",
      "  [0.88344997]\n",
      "  [0.88403845]\n",
      "  [0.88419884]\n",
      "  [0.88463157]\n",
      "  [0.88518959]\n",
      "  [0.88589424]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04370205104351044\n",
      "Predicción post entrenamiento : [[0.88577276]]\n",
      "PERDIDAAAA despues: 0.04347887262701988\n",
      "loss en el callback: 0.020730264484882355, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "ejemplar: [[0.8818019 ]\n",
      " [0.88344997]\n",
      " [0.88403845]\n",
      " [0.88419884]\n",
      " [0.88463157]\n",
      " [0.88518959]\n",
      " [0.88589424]\n",
      " [0.88630724]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.8865788]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[[0.8818019 ]\n",
      "  [0.88344997]\n",
      "  [0.88403845]\n",
      "  [0.88419884]\n",
      "  [0.88463157]\n",
      "  [0.88518959]\n",
      "  [0.88589424]\n",
      "  [0.88630724]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01549304649233818\n",
      "Predicción post entrenamiento : [[0.88560647]]\n",
      "PERDIDAAAA despues: 0.015251938253641129\n",
      "loss en el callback: 0.04911474883556366, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "ejemplar: [[0.88344997]\n",
      " [0.88403845]\n",
      " [0.88419884]\n",
      " [0.88463157]\n",
      " [0.88518959]\n",
      " [0.88589424]\n",
      " [0.88630724]\n",
      " [0.8865788 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.8862972]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[[0.88344997]\n",
      "  [0.88403845]\n",
      "  [0.88419884]\n",
      "  [0.88463157]\n",
      "  [0.88518959]\n",
      "  [0.88589424]\n",
      "  [0.88630724]\n",
      "  [0.8865788 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006279878783971071\n",
      "Predicción post entrenamiento : [[0.8864791]]\n",
      "PERDIDAAAA despues: 0.006308733951300383\n",
      "loss en el callback: 0.0030097695998847485, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "ejemplar: [[0.88403845]\n",
      " [0.88419884]\n",
      " [0.88463157]\n",
      " [0.88518959]\n",
      " [0.88589424]\n",
      " [0.88630724]\n",
      " [0.8865788 ]\n",
      " [0.88629723]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.88686883]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[[0.88403845]\n",
      "  [0.88419884]\n",
      "  [0.88463157]\n",
      "  [0.88518959]\n",
      "  [0.88589424]\n",
      "  [0.88630724]\n",
      "  [0.8865788 ]\n",
      "  [0.88629723]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005138151813298464\n",
      "Predicción post entrenamiento : [[0.88666606]]\n",
      "PERDIDAAAA despues: 0.005109122954308987\n",
      "loss en el callback: 0.002842093352228403, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "ejemplar: [[0.88419884]\n",
      " [0.88463157]\n",
      " [0.88518959]\n",
      " [0.88589424]\n",
      " [0.88630724]\n",
      " [0.8865788 ]\n",
      " [0.88629723]\n",
      " [0.88686883]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.8870091]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[[0.88419884]\n",
      "  [0.88463157]\n",
      "  [0.88518959]\n",
      "  [0.88589424]\n",
      "  [0.88630724]\n",
      "  [0.8865788 ]\n",
      "  [0.88629723]\n",
      "  [0.88686883]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00036974737304262817\n",
      "Predicción post entrenamiento : [[0.8872993]]\n",
      "PERDIDAAAA despues: 0.0003586706006899476\n",
      "loss en el callback: 0.006323532667011023, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "ejemplar: [[0.88463157]\n",
      " [0.88518959]\n",
      " [0.88589424]\n",
      " [0.88630724]\n",
      " [0.8865788 ]\n",
      " [0.88629723]\n",
      " [0.88686883]\n",
      " [0.88700908]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.8877053]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[[0.88463157]\n",
      "  [0.88518959]\n",
      "  [0.88589424]\n",
      "  [0.88630724]\n",
      "  [0.8865788 ]\n",
      "  [0.88629723]\n",
      "  [0.88686883]\n",
      "  [0.88700908]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005184029694646597\n",
      "Predicción post entrenamiento : [[0.8885408]]\n",
      "PERDIDAAAA despues: 0.005064418539404869\n",
      "loss en el callback: 0.06441950798034668, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "ejemplar: [[0.88518959]\n",
      " [0.88589424]\n",
      " [0.88630724]\n",
      " [0.8865788 ]\n",
      " [0.88629723]\n",
      " [0.88686883]\n",
      " [0.88700908]\n",
      " [0.88770533]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.8889342]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[[0.88518959]\n",
      "  [0.88589424]\n",
      "  [0.88630724]\n",
      "  [0.8865788 ]\n",
      "  [0.88629723]\n",
      "  [0.88686883]\n",
      "  [0.88700908]\n",
      "  [0.88770533]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005688278470188379\n",
      "Predicción post entrenamiento : [[0.888891]]\n",
      "PERDIDAAAA despues: 0.005694798659533262\n",
      "loss en el callback: 0.00010638571984600276, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "ejemplar: [[0.88589424]\n",
      " [0.88630724]\n",
      " [0.8865788 ]\n",
      " [0.88629723]\n",
      " [0.88686883]\n",
      " [0.88700908]\n",
      " [0.88770533]\n",
      " [0.8889342 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.8892329]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[[0.88589424]\n",
      "  [0.88630724]\n",
      "  [0.8865788 ]\n",
      "  [0.88629723]\n",
      "  [0.88686883]\n",
      "  [0.88700908]\n",
      "  [0.88770533]\n",
      "  [0.8889342 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.4519466731144348e-06\n",
      "Predicción post entrenamiento : [[0.8889395]]\n",
      "PERDIDAAAA despues: 8.310025805258192e-07\n",
      "loss en el callback: 0.005316808354109526, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "ejemplar: [[0.88630724]\n",
      " [0.8865788 ]\n",
      " [0.88629723]\n",
      " [0.88686883]\n",
      " [0.88700908]\n",
      " [0.88770533]\n",
      " [0.8889342 ]\n",
      " [0.88923287]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.88918567]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[[0.88630724]\n",
      "  [0.8865788 ]\n",
      "  [0.88629723]\n",
      "  [0.88686883]\n",
      "  [0.88700908]\n",
      "  [0.88770533]\n",
      "  [0.8889342 ]\n",
      "  [0.88923287]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.2191134374006651e-05\n",
      "Predicción post entrenamiento : [[0.88872385]]\n",
      "PERDIDAAAA despues: 1.5629349945811555e-05\n",
      "loss en el callback: 0.012241998687386513, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "ejemplar: [[0.8865788 ]\n",
      " [0.88629723]\n",
      " [0.88686883]\n",
      " [0.88700908]\n",
      " [0.88770533]\n",
      " [0.8889342 ]\n",
      " [0.88923287]\n",
      " [0.88918567]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.8889531]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[[0.8865788 ]\n",
      "  [0.88629723]\n",
      "  [0.88686883]\n",
      "  [0.88700908]\n",
      "  [0.88770533]\n",
      "  [0.8889342 ]\n",
      "  [0.88923287]\n",
      "  [0.88918567]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00018798922246787697\n",
      "Predicción post entrenamiento : [[0.88846684]]\n",
      "PERDIDAAAA despues: 0.0001748916693031788\n",
      "loss en el callback: 0.013092699460685253, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "ejemplar: [[0.88629723]\n",
      " [0.88686883]\n",
      " [0.88700908]\n",
      " [0.88770533]\n",
      " [0.8889342 ]\n",
      " [0.88923287]\n",
      " [0.88918567]\n",
      " [0.88895309]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.88872325]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[[0.88629723]\n",
      "  [0.88686883]\n",
      "  [0.88700908]\n",
      "  [0.88770533]\n",
      "  [0.8889342 ]\n",
      "  [0.88923287]\n",
      "  [0.88918567]\n",
      "  [0.88895309]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001435671467334032\n",
      "Predicción post entrenamiento : [[0.8890952]]\n",
      "PERDIDAAAA despues: 0.0014639950823038816\n",
      "loss en el callback: 0.01254841685295105, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "ejemplar: [[0.88686883]\n",
      " [0.88700908]\n",
      " [0.88770533]\n",
      " [0.8889342 ]\n",
      " [0.88923287]\n",
      " [0.88918567]\n",
      " [0.88895309]\n",
      " [0.88872325]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.8895376]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[[0.88686883]\n",
      "  [0.88700908]\n",
      "  [0.88770533]\n",
      "  [0.8889342 ]\n",
      "  [0.88923287]\n",
      "  [0.88918567]\n",
      "  [0.88895309]\n",
      "  [0.88872325]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016517546027898788\n",
      "Predicción post entrenamiento : [[0.8893247]]\n",
      "PERDIDAAAA despues: 0.0016344989417120814\n",
      "loss en el callback: 0.003132435493171215, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "ejemplar: [[0.88700908]\n",
      " [0.88770533]\n",
      " [0.8889342 ]\n",
      " [0.88923287]\n",
      " [0.88918567]\n",
      " [0.88895309]\n",
      " [0.88872325]\n",
      " [0.88953757]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.88972443]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[[0.88700908]\n",
      "  [0.88770533]\n",
      "  [0.8889342 ]\n",
      "  [0.88923287]\n",
      "  [0.88918567]\n",
      "  [0.88895309]\n",
      "  [0.88872325]\n",
      "  [0.88953757]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005284305661916733\n",
      "Predicción post entrenamiento : [[0.89001095]]\n",
      "PERDIDAAAA despues: 0.005242731422185898\n",
      "loss en el callback: 0.0057627311907708645, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "ejemplar: [[0.88770533]\n",
      " [0.8889342 ]\n",
      " [0.88923287]\n",
      " [0.88918567]\n",
      " [0.88895309]\n",
      " [0.88872325]\n",
      " [0.88953757]\n",
      " [0.88972443]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.8904715]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[[0.88770533]\n",
      "  [0.8889342 ]\n",
      "  [0.88923287]\n",
      "  [0.88918567]\n",
      "  [0.88895309]\n",
      "  [0.88872325]\n",
      "  [0.88953757]\n",
      "  [0.88972443]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005986179690808058\n",
      "Predicción post entrenamiento : [[0.8909995]]\n",
      "PERDIDAAAA despues: 0.0059047588147223\n",
      "loss en el callback: 0.02307014912366867, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "ejemplar: [[0.8889342 ]\n",
      " [0.88923287]\n",
      " [0.88918567]\n",
      " [0.88895309]\n",
      " [0.88872325]\n",
      " [0.88953757]\n",
      " [0.88972443]\n",
      " [0.89047152]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.89135796]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[[0.8889342 ]\n",
      "  [0.88923287]\n",
      "  [0.88918567]\n",
      "  [0.88895309]\n",
      "  [0.88872325]\n",
      "  [0.88953757]\n",
      "  [0.88972443]\n",
      "  [0.89047152]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002436677925288677\n",
      "Predicción post entrenamiento : [[0.89125776]]\n",
      "PERDIDAAAA despues: 0.0024465799797326326\n",
      "loss en el callback: 0.0006113619892857969, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "ejemplar: [[0.88923287]\n",
      " [0.88918567]\n",
      " [0.88895309]\n",
      " [0.88872325]\n",
      " [0.88953757]\n",
      " [0.88972443]\n",
      " [0.89047152]\n",
      " [0.89135796]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.89134705]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[[0.88923287]\n",
      "  [0.88918567]\n",
      "  [0.88895309]\n",
      "  [0.88872325]\n",
      "  [0.88953757]\n",
      "  [0.88972443]\n",
      "  [0.89047152]\n",
      "  [0.89135796]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006584383547306061\n",
      "Predicción post entrenamiento : [[0.89125925]]\n",
      "PERDIDAAAA despues: 0.006598639767616987\n",
      "loss en el callback: 0.0004810782556887716, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "ejemplar: [[0.88918567]\n",
      " [0.88895309]\n",
      " [0.88872325]\n",
      " [0.88953757]\n",
      " [0.88972443]\n",
      " [0.89047152]\n",
      " [0.89135796]\n",
      " [0.89134705]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.8913203]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[[0.88918567]\n",
      "  [0.88895309]\n",
      "  [0.88872325]\n",
      "  [0.88953757]\n",
      "  [0.88972443]\n",
      "  [0.89047152]\n",
      "  [0.89135796]\n",
      "  [0.89134705]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011147168464958668\n",
      "Predicción post entrenamiento : [[0.8916458]]\n",
      "PERDIDAAAA despues: 0.011078541167080402\n",
      "loss en el callback: 0.007553629577159882, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "ejemplar: [[0.88895309]\n",
      " [0.88872325]\n",
      " [0.88953757]\n",
      " [0.88972443]\n",
      " [0.89047152]\n",
      " [0.89135796]\n",
      " [0.89134705]\n",
      " [0.89132029]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.89178824]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[[0.88895309]\n",
      "  [0.88872325]\n",
      "  [0.88953757]\n",
      "  [0.88972443]\n",
      "  [0.89047152]\n",
      "  [0.89135796]\n",
      "  [0.89134705]\n",
      "  [0.89132029]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0035275837872177362\n",
      "Predicción post entrenamiento : [[0.8921726]]\n",
      "PERDIDAAAA despues: 0.003482077969238162\n",
      "loss en el callback: 0.011709100566804409, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "ejemplar: [[0.88872325]\n",
      " [0.88953757]\n",
      " [0.88972443]\n",
      " [0.89047152]\n",
      " [0.89135796]\n",
      " [0.89134705]\n",
      " [0.89132029]\n",
      " [0.89178824]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.89247066]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[[0.88872325]\n",
      "  [0.88953757]\n",
      "  [0.88972443]\n",
      "  [0.89047152]\n",
      "  [0.89135796]\n",
      "  [0.89134705]\n",
      "  [0.89132029]\n",
      "  [0.89178824]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.0930631106020883e-05\n",
      "Predicción post entrenamiento : [[0.89282036]]\n",
      "PERDIDAAAA despues: 8.740596967982128e-06\n",
      "loss en el callback: 0.010955506935715675, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "ejemplar: [[0.88953757]\n",
      " [0.88972443]\n",
      " [0.89047152]\n",
      " [0.89135796]\n",
      " [0.89134705]\n",
      " [0.89132029]\n",
      " [0.89178824]\n",
      " [0.89247066]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.89329726]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[[0.88953757]\n",
      "  [0.88972443]\n",
      "  [0.89047152]\n",
      "  [0.89135796]\n",
      "  [0.89134705]\n",
      "  [0.89132029]\n",
      "  [0.89178824]\n",
      "  [0.89247066]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00014056378859095275\n",
      "Predicción post entrenamiento : [[0.8930541]]\n",
      "PERDIDAAAA despues: 0.0001348578807665035\n",
      "loss en el callback: 0.004048387985676527, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "ejemplar: [[0.88972443]\n",
      " [0.89047152]\n",
      " [0.89135796]\n",
      " [0.89134705]\n",
      " [0.89132029]\n",
      " [0.89178824]\n",
      " [0.89247066]\n",
      " [0.89329726]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.893434]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[[0.88972443]\n",
      "  [0.89047152]\n",
      "  [0.89135796]\n",
      "  [0.89134705]\n",
      "  [0.89132029]\n",
      "  [0.89178824]\n",
      "  [0.89247066]\n",
      "  [0.89329726]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005594376707449555\n",
      "Predicción post entrenamiento : [[0.8936324]]\n",
      "PERDIDAAAA despues: 0.00055009062634781\n",
      "loss en el callback: 0.003595359856262803, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "ejemplar: [[0.89047152]\n",
      " [0.89135796]\n",
      " [0.89134705]\n",
      " [0.89132029]\n",
      " [0.89178824]\n",
      " [0.89247066]\n",
      " [0.89329726]\n",
      " [0.89343399]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.894079]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[[0.89047152]\n",
      "  [0.89135796]\n",
      "  [0.89134705]\n",
      "  [0.89132029]\n",
      "  [0.89178824]\n",
      "  [0.89247066]\n",
      "  [0.89329726]\n",
      "  [0.89343399]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006614938611164689\n",
      "Predicción post entrenamiento : [[0.89407516]]\n",
      "PERDIDAAAA despues: 0.0006616931641474366\n",
      "loss en el callback: 1.1381978310964769e-06, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "ejemplar: [[0.89135796]\n",
      " [0.89134705]\n",
      " [0.89132029]\n",
      " [0.89178824]\n",
      " [0.89247066]\n",
      " [0.89329726]\n",
      " [0.89343399]\n",
      " [0.89407903]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.89443713]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[[0.89135796]\n",
      "  [0.89134705]\n",
      "  [0.89132029]\n",
      "  [0.89178824]\n",
      "  [0.89247066]\n",
      "  [0.89329726]\n",
      "  [0.89343399]\n",
      "  [0.89407903]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0045166015625\n",
      "Predicción post entrenamiento : [[0.89503306]]\n",
      "PERDIDAAAA despues: 0.004436857532709837\n",
      "loss en el callback: 0.033327553421258926, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "ejemplar: [[0.89134705]\n",
      " [0.89132029]\n",
      " [0.89178824]\n",
      " [0.89247066]\n",
      " [0.89329726]\n",
      " [0.89343399]\n",
      " [0.89407903]\n",
      " [0.89443713]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.8952631]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[[0.89134705]\n",
      "  [0.89132029]\n",
      "  [0.89178824]\n",
      "  [0.89247066]\n",
      "  [0.89329726]\n",
      "  [0.89343399]\n",
      "  [0.89407903]\n",
      "  [0.89443713]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005324077792465687\n",
      "Predicción post entrenamiento : [[0.89570266]]\n",
      "PERDIDAAAA despues: 0.005260121077299118\n",
      "loss en el callback: 0.017185302451252937, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "ejemplar: [[0.89132029]\n",
      " [0.89178824]\n",
      " [0.89247066]\n",
      " [0.89329726]\n",
      " [0.89343399]\n",
      " [0.89407903]\n",
      " [0.89443713]\n",
      " [0.89526308]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.89604956]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[[0.89132029]\n",
      "  [0.89178824]\n",
      "  [0.89247066]\n",
      "  [0.89329726]\n",
      "  [0.89343399]\n",
      "  [0.89407903]\n",
      "  [0.89443713]\n",
      "  [0.89526308]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003809205489233136\n",
      "Predicción post entrenamiento : [[0.89586294]]\n",
      "PERDIDAAAA despues: 0.003832276677712798\n",
      "loss en el callback: 0.0024812074843794107, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "ejemplar: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.2258116]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03229404613375664\n",
      "Predicción post entrenamiento : [[0.19841997]]\n",
      "PERDIDAAAA despues: 0.023199498653411865\n",
      "loss en el callback: 0.03119845874607563, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "ejemplar: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.2258116 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.18267016]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.2258116 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006153930444270372\n",
      "Predicción post entrenamiento : [[0.16439097]]\n",
      "PERDIDAAAA despues: 0.003620163770392537\n",
      "loss en el callback: 0.01100150216370821, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "ejemplar: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.2258116 ]\n",
      " [0.18267016]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.16843641]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.2258116 ]\n",
      "  [0.18267016]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00020256706920918077\n",
      "Predicción post entrenamiento : [[0.1676165]]\n",
      "PERDIDAAAA despues: 0.00017990049673244357\n",
      "loss en el callback: 6.883619062136859e-05, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "ejemplar: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.2258116 ]\n",
      " [0.18267016]\n",
      " [0.16843641]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.17896457]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.2258116 ]\n",
      "  [0.18267016]\n",
      "  [0.16843641]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005387499113567173\n",
      "Predicción post entrenamiento : [[0.17645758]]\n",
      "PERDIDAAAA despues: 0.000428655679570511\n",
      "loss en el callback: 0.0009725684067234397, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "ejemplar: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.2258116 ]\n",
      " [0.18267016]\n",
      " [0.16843641]\n",
      " [0.17896457]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.18877144]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.2258116 ]\n",
      "  [0.18267016]\n",
      "  [0.16843641]\n",
      "  [0.17896457]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003999132663011551\n",
      "Predicción post entrenamiento : [[0.18626289]]\n",
      "PERDIDAAAA despues: 0.0036881505511701107\n",
      "loss en el callback: 0.001989417476579547, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "ejemplar: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.2258116 ]\n",
      " [0.18267016]\n",
      " [0.16843641]\n",
      " [0.17896457]\n",
      " [0.18877144]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.19559327]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.2258116 ]\n",
      "  [0.18267016]\n",
      "  [0.16843641]\n",
      "  [0.17896457]\n",
      "  [0.18877144]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002491337712854147\n",
      "Predicción post entrenamiento : [[0.19433407]]\n",
      "PERDIDAAAA despues: 0.002367222448810935\n",
      "loss en el callback: 0.0007060436764732003, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "ejemplar: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.2258116 ]\n",
      " [0.18267016]\n",
      " [0.16843641]\n",
      " [0.17896457]\n",
      " [0.18877144]\n",
      " [0.19559327]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.2143908]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.2258116 ]\n",
      "  [0.18267016]\n",
      "  [0.16843641]\n",
      "  [0.17896457]\n",
      "  [0.18877144]\n",
      "  [0.19559327]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00461529241874814\n",
      "Predicción post entrenamiento : [[0.21067499]]\n",
      "PERDIDAAAA despues: 0.004124225117266178\n",
      "loss en el callback: 0.006126274820417166, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "ejemplar: [[0.04223169]\n",
      " [0.2258116 ]\n",
      " [0.18267016]\n",
      " [0.16843641]\n",
      " [0.17896457]\n",
      " [0.18877144]\n",
      " [0.19559327]\n",
      " [0.2143908 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.2347351]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[[0.04223169]\n",
      "  [0.2258116 ]\n",
      "  [0.18267016]\n",
      "  [0.16843641]\n",
      "  [0.17896457]\n",
      "  [0.18877144]\n",
      "  [0.19559327]\n",
      "  [0.2143908 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014966890448704362\n",
      "Predicción post entrenamiento : [[0.23314582]]\n",
      "PERDIDAAAA despues: 0.001376245403662324\n",
      "loss en el callback: 0.0014437498757615685, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "ejemplar: [[0.2258116 ]\n",
      " [0.18267016]\n",
      " [0.16843641]\n",
      " [0.17896457]\n",
      " [0.18877144]\n",
      " [0.19559327]\n",
      " [0.2143908 ]\n",
      " [0.2347351 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.2614916]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[[0.2258116 ]\n",
      "  [0.18267016]\n",
      "  [0.16843641]\n",
      "  [0.17896457]\n",
      "  [0.18877144]\n",
      "  [0.19559327]\n",
      "  [0.2143908 ]\n",
      "  [0.2347351 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009585710358805954\n",
      "Predicción post entrenamiento : [[0.25902292]]\n",
      "PERDIDAAAA despues: 0.0008118010591715574\n",
      "loss en el callback: 0.0035535558126866817, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "ejemplar: [[0.18267016]\n",
      " [0.16843641]\n",
      " [0.17896457]\n",
      " [0.18877144]\n",
      " [0.19559327]\n",
      " [0.2143908 ]\n",
      " [0.2347351 ]\n",
      " [0.2614916 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.25226173]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[[0.18267016]\n",
      "  [0.16843641]\n",
      "  [0.17896457]\n",
      "  [0.18877144]\n",
      "  [0.19559327]\n",
      "  [0.2143908 ]\n",
      "  [0.2347351 ]\n",
      "  [0.2614916 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001919788308441639\n",
      "Predicción post entrenamiento : [[0.25113973]]\n",
      "PERDIDAAAA despues: 0.0018227256368845701\n",
      "loss en el callback: 0.0011153508676216006, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "ejemplar: [[0.16843641]\n",
      " [0.17896457]\n",
      " [0.18877144]\n",
      " [0.19559327]\n",
      " [0.2143908 ]\n",
      " [0.2347351 ]\n",
      " [0.2614916 ]\n",
      " [0.25226173]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.25412625]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[[0.16843641]\n",
      "  [0.17896457]\n",
      "  [0.18877144]\n",
      "  [0.19559327]\n",
      "  [0.2143908 ]\n",
      "  [0.2347351 ]\n",
      "  [0.2614916 ]\n",
      "  [0.25226173]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001780240098014474\n",
      "Predicción post entrenamiento : [[0.25070977]]\n",
      "PERDIDAAAA despues: 0.0015036101685836911\n",
      "loss en el callback: 0.009035889059305191, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "ejemplar: [[0.17896457]\n",
      " [0.18877144]\n",
      " [0.19559327]\n",
      " [0.2143908 ]\n",
      " [0.2347351 ]\n",
      " [0.2614916 ]\n",
      " [0.25226173]\n",
      " [0.25412625]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.25881693]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[[0.17896457]\n",
      "  [0.18877144]\n",
      "  [0.19559327]\n",
      "  [0.2143908 ]\n",
      "  [0.2347351 ]\n",
      "  [0.2614916 ]\n",
      "  [0.25226173]\n",
      "  [0.25412625]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0026556423399597406\n",
      "Predicción post entrenamiento : [[0.25718504]]\n",
      "PERDIDAAAA despues: 0.0024901137221604586\n",
      "loss en el callback: 0.0032680139411240816, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "ejemplar: [[0.18877144]\n",
      " [0.19559327]\n",
      " [0.2143908 ]\n",
      " [0.2347351 ]\n",
      " [0.2614916 ]\n",
      " [0.25226173]\n",
      " [0.25412625]\n",
      " [0.25881693]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.2656931]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[[0.18877144]\n",
      "  [0.19559327]\n",
      "  [0.2143908 ]\n",
      "  [0.2347351 ]\n",
      "  [0.2614916 ]\n",
      "  [0.25226173]\n",
      "  [0.25412625]\n",
      "  [0.25881693]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005291779991239309\n",
      "Predicción post entrenamiento : [[0.2648795]]\n",
      "PERDIDAAAA despues: 0.005174071528017521\n",
      "loss en el callback: 0.0010736536933109164, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "ejemplar: [[0.19559327]\n",
      " [0.2143908 ]\n",
      " [0.2347351 ]\n",
      " [0.2614916 ]\n",
      " [0.25226173]\n",
      " [0.25412625]\n",
      " [0.25881693]\n",
      " [0.2656931 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.27383348]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[[0.19559327]\n",
      "  [0.2143908 ]\n",
      "  [0.2347351 ]\n",
      "  [0.2614916 ]\n",
      "  [0.25226173]\n",
      "  [0.25412625]\n",
      "  [0.25881693]\n",
      "  [0.2656931 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005930623505264521\n",
      "Predicción post entrenamiento : [[0.27309078]]\n",
      "PERDIDAAAA despues: 0.005816783290356398\n",
      "loss en el callback: 0.0011902450351044536, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "ejemplar: [[0.2143908 ]\n",
      " [0.2347351 ]\n",
      " [0.2614916 ]\n",
      " [0.25226173]\n",
      " [0.25412625]\n",
      " [0.25881693]\n",
      " [0.2656931 ]\n",
      " [0.27383348]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.2830103]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[[0.2143908 ]\n",
      "  [0.2347351 ]\n",
      "  [0.2614916 ]\n",
      "  [0.25226173]\n",
      "  [0.25412625]\n",
      "  [0.25881693]\n",
      "  [0.2656931 ]\n",
      "  [0.27383348]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004726873245090246\n",
      "Predicción post entrenamiento : [[0.2815355]]\n",
      "PERDIDAAAA despues: 0.004526256583631039\n",
      "loss en el callback: 0.003958248067647219, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "ejemplar: [[0.2347351 ]\n",
      " [0.2614916 ]\n",
      " [0.25226173]\n",
      " [0.25412625]\n",
      " [0.25881693]\n",
      " [0.2656931 ]\n",
      " [0.27383348]\n",
      " [0.2830103 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.28959686]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[[0.2347351 ]\n",
      "  [0.2614916 ]\n",
      "  [0.25226173]\n",
      "  [0.25412625]\n",
      "  [0.25881693]\n",
      "  [0.2656931 ]\n",
      "  [0.27383348]\n",
      "  [0.2830103 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011722780764102936\n",
      "Predicción post entrenamiento : [[0.28572628]]\n",
      "PERDIDAAAA despues: 0.010899613611400127\n",
      "loss en el callback: 0.02418626844882965, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "ejemplar: [[0.2614916 ]\n",
      " [0.25226173]\n",
      " [0.25412625]\n",
      " [0.25881693]\n",
      " [0.2656931 ]\n",
      " [0.27383348]\n",
      " [0.2830103 ]\n",
      " [0.28959686]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.2910752]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[[0.2614916 ]\n",
      "  [0.25226173]\n",
      "  [0.25412625]\n",
      "  [0.25881693]\n",
      "  [0.2656931 ]\n",
      "  [0.27383348]\n",
      "  [0.2830103 ]\n",
      "  [0.28959686]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013444233685731888\n",
      "Predicción post entrenamiento : [[0.28851834]]\n",
      "PERDIDAAAA despues: 0.012857839465141296\n",
      "loss en el callback: 0.014339197427034378, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "ejemplar: [[0.25226173]\n",
      " [0.25412625]\n",
      " [0.25881693]\n",
      " [0.2656931 ]\n",
      " [0.27383348]\n",
      " [0.2830103 ]\n",
      " [0.28959686]\n",
      " [0.2910752 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.2892111]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[[0.25226173]\n",
      "  [0.25412625]\n",
      "  [0.25881693]\n",
      "  [0.2656931 ]\n",
      "  [0.27383348]\n",
      "  [0.2830103 ]\n",
      "  [0.28959686]\n",
      "  [0.2910752 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019939260557293892\n",
      "Predicción post entrenamiento : [[0.28616238]]\n",
      "PERDIDAAAA despues: 0.01908755674958229\n",
      "loss en el callback: 0.022033195942640305, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "ejemplar: [[0.25412625]\n",
      " [0.25881693]\n",
      " [0.2656931 ]\n",
      " [0.27383348]\n",
      " [0.2830103 ]\n",
      " [0.28959686]\n",
      " [0.2910752 ]\n",
      " [0.28921109]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.2897747]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[[0.25412625]\n",
      "  [0.25881693]\n",
      "  [0.2656931 ]\n",
      "  [0.27383348]\n",
      "  [0.2830103 ]\n",
      "  [0.28959686]\n",
      "  [0.2910752 ]\n",
      "  [0.28921109]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017140446230769157\n",
      "Predicción post entrenamiento : [[0.2874177]]\n",
      "PERDIDAAAA despues: 0.016528842970728874\n",
      "loss en el callback: 0.0157456137239933, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "ejemplar: [[0.25881693]\n",
      " [0.2656931 ]\n",
      " [0.27383348]\n",
      " [0.2830103 ]\n",
      " [0.28959686]\n",
      " [0.2910752 ]\n",
      " [0.28921109]\n",
      " [0.28977469]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.29182374]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[[0.25881693]\n",
      "  [0.2656931 ]\n",
      "  [0.27383348]\n",
      "  [0.2830103 ]\n",
      "  [0.28959686]\n",
      "  [0.2910752 ]\n",
      "  [0.28921109]\n",
      "  [0.28977469]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009930157102644444\n",
      "Predicción post entrenamiento : [[0.29013574]]\n",
      "PERDIDAAAA despues: 0.009596587158739567\n",
      "loss en el callback: 0.009226477704942226, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "ejemplar: [[0.2656931 ]\n",
      " [0.27383348]\n",
      " [0.2830103 ]\n",
      " [0.28959686]\n",
      " [0.2910752 ]\n",
      " [0.28921109]\n",
      " [0.28977469]\n",
      " [0.29182374]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.2946903]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[[0.2656931 ]\n",
      "  [0.27383348]\n",
      "  [0.2830103 ]\n",
      "  [0.28959686]\n",
      "  [0.2910752 ]\n",
      "  [0.28921109]\n",
      "  [0.28977469]\n",
      "  [0.29182374]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011819141916930676\n",
      "Predicción post entrenamiento : [[0.29211375]]\n",
      "PERDIDAAAA despues: 0.011265554465353489\n",
      "loss en el callback: 0.019285542890429497, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "ejemplar: [[0.27383348]\n",
      " [0.2830103 ]\n",
      " [0.28959686]\n",
      " [0.2910752 ]\n",
      " [0.28921109]\n",
      " [0.28977469]\n",
      " [0.29182374]\n",
      " [0.29469031]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.29618803]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[[0.27383348]\n",
      "  [0.2830103 ]\n",
      "  [0.28959686]\n",
      "  [0.2910752 ]\n",
      "  [0.28921109]\n",
      "  [0.28977469]\n",
      "  [0.29182374]\n",
      "  [0.29469031]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008548162295483053\n",
      "Predicción post entrenamiento : [[0.296688]]\n",
      "PERDIDAAAA despues: 0.0008843013201840222\n",
      "loss en el callback: 0.0015924491453915834, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "ejemplar: [[0.2830103 ]\n",
      " [0.28959686]\n",
      " [0.2910752 ]\n",
      " [0.28921109]\n",
      " [0.28977469]\n",
      " [0.29182374]\n",
      " [0.29469031]\n",
      " [0.29618803]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.29978737]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[[0.2830103 ]\n",
      "  [0.28959686]\n",
      "  [0.2910752 ]\n",
      "  [0.28921109]\n",
      "  [0.28977469]\n",
      "  [0.29182374]\n",
      "  [0.29469031]\n",
      "  [0.29618803]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.278154640109278e-05\n",
      "Predicción post entrenamiento : [[0.2984138]]\n",
      "PERDIDAAAA despues: 3.471014497336e-05\n",
      "loss en el callback: 0.005500538274645805, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "ejemplar: [[0.28959686]\n",
      " [0.2910752 ]\n",
      " [0.28921109]\n",
      " [0.28977469]\n",
      " [0.29182374]\n",
      " [0.29469031]\n",
      " [0.29618803]\n",
      " [0.29978737]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.30006135]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[[0.28959686]\n",
      "  [0.2910752 ]\n",
      "  [0.28921109]\n",
      "  [0.28977469]\n",
      "  [0.29182374]\n",
      "  [0.29469031]\n",
      "  [0.29618803]\n",
      "  [0.29978737]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00031134503660723567\n",
      "Predicción post entrenamiento : [[0.3000547]]\n",
      "PERDIDAAAA despues: 0.00031157961348071694\n",
      "loss en el callback: 1.773058500020852e-07, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "ejemplar: [[0.2910752 ]\n",
      " [0.28921109]\n",
      " [0.28977469]\n",
      " [0.29182374]\n",
      " [0.29469031]\n",
      " [0.29618803]\n",
      " [0.29978737]\n",
      " [0.30006135]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.30060855]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[[0.2910752 ]\n",
      "  [0.28921109]\n",
      "  [0.28977469]\n",
      "  [0.29182374]\n",
      "  [0.29469031]\n",
      "  [0.29618803]\n",
      "  [0.29978737]\n",
      "  [0.30006135]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00014546699821949005\n",
      "Predicción post entrenamiento : [[0.30128282]]\n",
      "PERDIDAAAA despues: 0.0001296567643294111\n",
      "loss en el callback: 0.0027423747815191746, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "ejemplar: [[0.28921109]\n",
      " [0.28977469]\n",
      " [0.29182374]\n",
      " [0.29469031]\n",
      " [0.29618803]\n",
      " [0.29978737]\n",
      " [0.30006135]\n",
      " [0.30060855]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.30177948]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[[0.28921109]\n",
      "  [0.28977469]\n",
      "  [0.29182374]\n",
      "  [0.29469031]\n",
      "  [0.29618803]\n",
      "  [0.29978737]\n",
      "  [0.30006135]\n",
      "  [0.30060855]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001624150900170207\n",
      "Predicción post entrenamiento : [[0.30143684]]\n",
      "PERDIDAAAA despues: 0.00015379920660052449\n",
      "loss en el callback: 0.0005359223578125238, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "ejemplar: [[0.28977469]\n",
      " [0.29182374]\n",
      " [0.29469031]\n",
      " [0.29618803]\n",
      " [0.29978737]\n",
      " [0.30006135]\n",
      " [0.30060855]\n",
      " [0.30177948]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.30266064]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[[0.28977469]\n",
      "  [0.29182374]\n",
      "  [0.29469031]\n",
      "  [0.29618803]\n",
      "  [0.29978737]\n",
      "  [0.30006135]\n",
      "  [0.30060855]\n",
      "  [0.30177948]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003930121602024883\n",
      "Predicción post entrenamiento : [[0.3005941]]\n",
      "PERDIDAAAA despues: 0.0003153459110762924\n",
      "loss en el callback: 0.014063085429370403, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "ejemplar: [[0.29182374]\n",
      " [0.29469031]\n",
      " [0.29618803]\n",
      " [0.29978737]\n",
      " [0.30006135]\n",
      " [0.30060855]\n",
      " [0.30177948]\n",
      " [0.30266064]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.30208045]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[[0.29182374]\n",
      "  [0.29469031]\n",
      "  [0.29618803]\n",
      "  [0.29978737]\n",
      "  [0.30006135]\n",
      "  [0.30060855]\n",
      "  [0.30177948]\n",
      "  [0.30266064]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.677725650661159e-06\n",
      "Predicción post entrenamiento : [[0.30159286]]\n",
      "PERDIDAAAA despues: 4.395453743200051e-06\n",
      "loss en el callback: 0.0012270199367776513, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "ejemplar: [[0.29469031]\n",
      " [0.29618803]\n",
      " [0.29978737]\n",
      " [0.30006135]\n",
      " [0.30060855]\n",
      " [0.30177948]\n",
      " [0.30266064]\n",
      " [0.30208045]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.30300152]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[[0.29469031]\n",
      "  [0.29618803]\n",
      "  [0.29978737]\n",
      "  [0.30006135]\n",
      "  [0.30060855]\n",
      "  [0.30177948]\n",
      "  [0.30266064]\n",
      "  [0.30208045]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000736550020519644\n",
      "Predicción post entrenamiento : [[0.30297083]]\n",
      "PERDIDAAAA despues: 0.0007348848157562315\n",
      "loss en el callback: 7.040479431452695e-06, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "ejemplar: [[0.29618803]\n",
      " [0.29978737]\n",
      " [0.30006135]\n",
      " [0.30060855]\n",
      " [0.30177948]\n",
      " [0.30266064]\n",
      " [0.30208045]\n",
      " [0.30300152]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.30405942]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[[0.29618803]\n",
      "  [0.29978737]\n",
      "  [0.30006135]\n",
      "  [0.30060855]\n",
      "  [0.30177948]\n",
      "  [0.30266064]\n",
      "  [0.30208045]\n",
      "  [0.30300152]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008619918953627348\n",
      "Predicción post entrenamiento : [[0.30290022]]\n",
      "PERDIDAAAA despues: 0.0007952686282806098\n",
      "loss en el callback: 0.006891667377203703, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "ejemplar: [[0.29978737]\n",
      " [0.30006135]\n",
      " [0.30060855]\n",
      " [0.30177948]\n",
      " [0.30266064]\n",
      " [0.30208045]\n",
      " [0.30300152]\n",
      " [0.30405942]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.30390587]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[[0.29978737]\n",
      "  [0.30006135]\n",
      "  [0.30060855]\n",
      "  [0.30177948]\n",
      "  [0.30266064]\n",
      "  [0.30208045]\n",
      "  [0.30300152]\n",
      "  [0.30405942]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008083368884399533\n",
      "Predicción post entrenamiento : [[0.30337986]]\n",
      "PERDIDAAAA despues: 0.0007787033100612462\n",
      "loss en el callback: 0.0019035928416997194, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "ejemplar: [[0.30006135]\n",
      " [0.30060855]\n",
      " [0.30177948]\n",
      " [0.30266064]\n",
      " [0.30208045]\n",
      " [0.30300152]\n",
      " [0.30405942]\n",
      " [0.30390587]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.30377775]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[[0.30006135]\n",
      "  [0.30060855]\n",
      "  [0.30177948]\n",
      "  [0.30266064]\n",
      "  [0.30208045]\n",
      "  [0.30300152]\n",
      "  [0.30405942]\n",
      "  [0.30390587]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009595253504812717\n",
      "Predicción post entrenamiento : [[0.30364585]]\n",
      "PERDIDAAAA despues: 0.0009677145862951875\n",
      "loss en el callback: 0.00011161445581819862, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "ejemplar: [[0.30060855]\n",
      " [0.30177948]\n",
      " [0.30266064]\n",
      " [0.30208045]\n",
      " [0.30300152]\n",
      " [0.30405942]\n",
      " [0.30390587]\n",
      " [0.30377775]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.30410466]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[[0.30060855]\n",
      "  [0.30177948]\n",
      "  [0.30266064]\n",
      "  [0.30208045]\n",
      "  [0.30300152]\n",
      "  [0.30405942]\n",
      "  [0.30390587]\n",
      "  [0.30377775]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0026596123352646828\n",
      "Predicción post entrenamiento : [[0.30356866]]\n",
      "PERDIDAAAA despues: 0.0027151836548000574\n",
      "loss en el callback: 0.0015555634163320065, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "ejemplar: [[0.30177948]\n",
      " [0.30266064]\n",
      " [0.30208045]\n",
      " [0.30300152]\n",
      " [0.30405942]\n",
      " [0.30390587]\n",
      " [0.30377775]\n",
      " [0.30410466]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.3040234]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[[0.30177948]\n",
      "  [0.30266064]\n",
      "  [0.30208045]\n",
      "  [0.30300152]\n",
      "  [0.30405942]\n",
      "  [0.30390587]\n",
      "  [0.30377775]\n",
      "  [0.30410466]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00106718426104635\n",
      "Predicción post entrenamiento : [[0.30450687]]\n",
      "PERDIDAAAA despues: 0.00103583128657192\n",
      "loss en el callback: 0.002374779898673296, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "ejemplar: [[0.30266064]\n",
      " [0.30208045]\n",
      " [0.30300152]\n",
      " [0.30405942]\n",
      " [0.30390587]\n",
      " [0.30377775]\n",
      " [0.30410466]\n",
      " [0.30402341]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.30479953]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[[0.30266064]\n",
      "  [0.30208045]\n",
      "  [0.30300152]\n",
      "  [0.30405942]\n",
      "  [0.30390587]\n",
      "  [0.30377775]\n",
      "  [0.30410466]\n",
      "  [0.30402341]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008289857651107013\n",
      "Predicción post entrenamiento : [[0.30505395]]\n",
      "PERDIDAAAA despues: 0.0008143997984007001\n",
      "loss en el callback: 0.0005801956285722554, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "ejemplar: [[0.30208045]\n",
      " [0.30300152]\n",
      " [0.30405942]\n",
      " [0.30390587]\n",
      " [0.30377775]\n",
      " [0.30410466]\n",
      " [0.30402341]\n",
      " [0.30479953]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.3052214]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[[0.30208045]\n",
      "  [0.30300152]\n",
      "  [0.30405942]\n",
      "  [0.30390587]\n",
      "  [0.30377775]\n",
      "  [0.30410466]\n",
      "  [0.30402341]\n",
      "  [0.30479953]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006322347559034824\n",
      "Predicción post entrenamiento : [[0.30585703]]\n",
      "PERDIDAAAA despues: 0.0062216706573963165\n",
      "loss en el callback: 0.003424097318202257, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "ejemplar: [[0.30300152]\n",
      " [0.30405942]\n",
      " [0.30390587]\n",
      " [0.30377775]\n",
      " [0.30410466]\n",
      " [0.30402341]\n",
      " [0.30479953]\n",
      " [0.30522141]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.30621907]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[[0.30300152]\n",
      "  [0.30405942]\n",
      "  [0.30390587]\n",
      "  [0.30377775]\n",
      "  [0.30410466]\n",
      "  [0.30402341]\n",
      "  [0.30479953]\n",
      "  [0.30522141]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07016003876924515\n",
      "Predicción post entrenamiento : [[0.30869967]]\n",
      "PERDIDAAAA despues: 0.06885208934545517\n",
      "loss en el callback: 0.062279656529426575, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "ejemplar: [[0.30405942]\n",
      " [0.30390587]\n",
      " [0.30377775]\n",
      " [0.30410466]\n",
      " [0.30402341]\n",
      " [0.30479953]\n",
      " [0.30522141]\n",
      " [0.30621907]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.30893692]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[[0.30405942]\n",
      "  [0.30390587]\n",
      "  [0.30377775]\n",
      "  [0.30410466]\n",
      "  [0.30402341]\n",
      "  [0.30479953]\n",
      "  [0.30522141]\n",
      "  [0.30621907]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08256634324789047\n",
      "Predicción post entrenamiento : [[0.31142476]]\n",
      "PERDIDAAAA despues: 0.08114279806613922\n",
      "loss en el callback: 0.04892754927277565, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "ejemplar: [[0.30390587]\n",
      " [0.30377775]\n",
      " [0.30410466]\n",
      " [0.30402341]\n",
      " [0.30479953]\n",
      " [0.30522141]\n",
      " [0.30621907]\n",
      " [0.30893692]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.31150344]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[[0.30390587]\n",
      "  [0.30377775]\n",
      "  [0.30410466]\n",
      "  [0.30402341]\n",
      "  [0.30479953]\n",
      "  [0.30522141]\n",
      "  [0.30621907]\n",
      "  [0.30893692]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06921110302209854\n",
      "Predicción post entrenamiento : [[0.3138705]]\n",
      "PERDIDAAAA despues: 0.06797125935554504\n",
      "loss en el callback: 0.06411855667829514, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "ejemplar: [[0.30377775]\n",
      " [0.30410466]\n",
      " [0.30402341]\n",
      " [0.30479953]\n",
      " [0.30522141]\n",
      " [0.30621907]\n",
      " [0.30893692]\n",
      " [0.31150344]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.31408703]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[[0.30377775]\n",
      "  [0.30410466]\n",
      "  [0.30402341]\n",
      "  [0.30479953]\n",
      "  [0.30522141]\n",
      "  [0.30621907]\n",
      "  [0.30893692]\n",
      "  [0.31150344]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08542004972696304\n",
      "Predicción post entrenamiento : [[0.31677383]]\n",
      "PERDIDAAAA despues: 0.0838567391037941\n",
      "loss en el callback: 0.0864882618188858, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "ejemplar: [[0.30410466]\n",
      " [0.30402341]\n",
      " [0.30479953]\n",
      " [0.30522141]\n",
      " [0.30621907]\n",
      " [0.30893692]\n",
      " [0.31150344]\n",
      " [0.31408703]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.31719163]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[[0.30410466]\n",
      "  [0.30402341]\n",
      "  [0.30479953]\n",
      "  [0.30522141]\n",
      "  [0.30621907]\n",
      "  [0.30893692]\n",
      "  [0.31150344]\n",
      "  [0.31408703]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0715377926826477\n",
      "Predicción post entrenamiento : [[0.31943497]]\n",
      "PERDIDAAAA despues: 0.07034279406070709\n",
      "loss en el callback: 0.0494832806289196, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "ejemplar: [[0.30402341]\n",
      " [0.30479953]\n",
      " [0.30522141]\n",
      " [0.30621907]\n",
      " [0.30893692]\n",
      " [0.31150344]\n",
      " [0.31408703]\n",
      " [0.31719163]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.32003206]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[[0.30402341]\n",
      "  [0.30479953]\n",
      "  [0.30522141]\n",
      "  [0.30621907]\n",
      "  [0.30893692]\n",
      "  [0.31150344]\n",
      "  [0.31408703]\n",
      "  [0.31719163]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.061871446669101715\n",
      "Predicción post entrenamiento : [[0.32228997]]\n",
      "PERDIDAAAA despues: 0.06075328215956688\n",
      "loss en el callback: 0.06145725026726723, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "ejemplar: [[0.30479953]\n",
      " [0.30522141]\n",
      " [0.30621907]\n",
      " [0.30893692]\n",
      " [0.31150344]\n",
      " [0.31408703]\n",
      " [0.31719163]\n",
      " [0.32003206]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.32324404]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[[0.30479953]\n",
      "  [0.30522141]\n",
      "  [0.30621907]\n",
      "  [0.30893692]\n",
      "  [0.31150344]\n",
      "  [0.31408703]\n",
      "  [0.31719163]\n",
      "  [0.32003206]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1020994633436203\n",
      "Predicción post entrenamiento : [[0.32561502]]\n",
      "PERDIDAAAA despues: 0.10058988630771637\n",
      "loss en el callback: 0.049386657774448395, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "ejemplar: [[0.30522141]\n",
      " [0.30621907]\n",
      " [0.30893692]\n",
      " [0.31150344]\n",
      " [0.31408703]\n",
      " [0.31719163]\n",
      " [0.32003206]\n",
      " [0.32324404]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.32682845]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[[0.30522141]\n",
      "  [0.30621907]\n",
      "  [0.30893692]\n",
      "  [0.31150344]\n",
      "  [0.31408703]\n",
      "  [0.31719163]\n",
      "  [0.32003206]\n",
      "  [0.32324404]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1121784895658493\n",
      "Predicción post entrenamiento : [[0.32958913]]\n",
      "PERDIDAAAA despues: 0.11033683270215988\n",
      "loss en el callback: 0.12842115759849548, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "ejemplar: [[0.30621907]\n",
      " [0.30893692]\n",
      " [0.31150344]\n",
      " [0.31408703]\n",
      " [0.31719163]\n",
      " [0.32003206]\n",
      " [0.32324404]\n",
      " [0.32682845]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.33122864]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[[0.30621907]\n",
      "  [0.30893692]\n",
      "  [0.31150344]\n",
      "  [0.31408703]\n",
      "  [0.31719163]\n",
      "  [0.32003206]\n",
      "  [0.32324404]\n",
      "  [0.32682845]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11680421978235245\n",
      "Predicción post entrenamiento : [[0.3339712]]\n",
      "PERDIDAAAA despues: 0.11493711918592453\n",
      "loss en el callback: 0.10268587619066238, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "ejemplar: [[0.30893692]\n",
      " [0.31150344]\n",
      " [0.31408703]\n",
      " [0.31719163]\n",
      " [0.32003206]\n",
      " [0.32324404]\n",
      " [0.32682845]\n",
      " [0.33122864]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.33600253]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[[0.30893692]\n",
      "  [0.31150344]\n",
      "  [0.31408703]\n",
      "  [0.31719163]\n",
      "  [0.32003206]\n",
      "  [0.32324404]\n",
      "  [0.32682845]\n",
      "  [0.33122864]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1403062641620636\n",
      "Predicción post entrenamiento : [[0.3390855]]\n",
      "PERDIDAAAA despues: 0.13800616562366486\n",
      "loss en el callback: 0.15447701513767242, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "ejemplar: [[0.31150344]\n",
      " [0.31408703]\n",
      " [0.31719163]\n",
      " [0.32003206]\n",
      " [0.32324404]\n",
      " [0.32682845]\n",
      " [0.33122864]\n",
      " [0.33600253]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.3411942]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[[0.31150344]\n",
      "  [0.31408703]\n",
      "  [0.31719163]\n",
      "  [0.32003206]\n",
      "  [0.32324404]\n",
      "  [0.32682845]\n",
      "  [0.33122864]\n",
      "  [0.33600253]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13162128627300262\n",
      "Predicción post entrenamiento : [[0.34409806]]\n",
      "PERDIDAAAA despues: 0.12952271103858948\n",
      "loss en el callback: 0.15387263894081116, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "ejemplar: [[0.31408703]\n",
      " [0.31719163]\n",
      " [0.32003206]\n",
      " [0.32324404]\n",
      " [0.32682845]\n",
      " [0.33122864]\n",
      " [0.33600253]\n",
      " [0.34119421]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.3463719]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[[0.31408703]\n",
      "  [0.31719163]\n",
      "  [0.32003206]\n",
      "  [0.32324404]\n",
      "  [0.32682845]\n",
      "  [0.33122864]\n",
      "  [0.33600253]\n",
      "  [0.34119421]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14505863189697266\n",
      "Predicción post entrenamiento : [[0.34928006]]\n",
      "PERDIDAAAA despues: 0.1428518444299698\n",
      "loss en el callback: 0.1603451371192932, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "ejemplar: [[0.31719163]\n",
      " [0.32003206]\n",
      " [0.32324404]\n",
      " [0.32682845]\n",
      " [0.33122864]\n",
      " [0.33600253]\n",
      " [0.34119421]\n",
      " [0.34637189]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.3517866]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[[0.31719163]\n",
      "  [0.32003206]\n",
      "  [0.32324404]\n",
      "  [0.32682845]\n",
      "  [0.33122864]\n",
      "  [0.33600253]\n",
      "  [0.34119421]\n",
      "  [0.34637189]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13749375939369202\n",
      "Predicción post entrenamiento : [[0.35464108]]\n",
      "PERDIDAAAA despues: 0.13538502156734467\n",
      "loss en el callback: 0.17676763236522675, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "ejemplar: [[0.32003206]\n",
      " [0.32324404]\n",
      " [0.32682845]\n",
      " [0.33122864]\n",
      " [0.33600253]\n",
      " [0.34119421]\n",
      " [0.34637189]\n",
      " [0.35178661]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.3573393]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[[0.32003206]\n",
      "  [0.32324404]\n",
      "  [0.32682845]\n",
      "  [0.33122864]\n",
      "  [0.33600253]\n",
      "  [0.34119421]\n",
      "  [0.34637189]\n",
      "  [0.35178661]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.17177262902259827\n",
      "Predicción post entrenamiento : [[0.3604984]]\n",
      "PERDIDAAAA despues: 0.16916398704051971\n",
      "loss en el callback: 0.2289775162935257, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "ejemplar: [[0.32324404]\n",
      " [0.32682845]\n",
      " [0.33122864]\n",
      " [0.33600253]\n",
      " [0.34119421]\n",
      " [0.34637189]\n",
      " [0.35178661]\n",
      " [0.35733929]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.36352962]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[[0.32324404]\n",
      "  [0.32682845]\n",
      "  [0.33122864]\n",
      "  [0.33600253]\n",
      "  [0.34119421]\n",
      "  [0.34637189]\n",
      "  [0.35178661]\n",
      "  [0.35733929]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13031794130802155\n",
      "Predicción post entrenamiento : [[0.36622384]]\n",
      "PERDIDAAAA despues: 0.12838000059127808\n",
      "loss en el callback: 0.10023004561662674, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "ejemplar: [[0.32682845]\n",
      " [0.33122864]\n",
      " [0.33600253]\n",
      " [0.34119421]\n",
      " [0.34637189]\n",
      " [0.35178661]\n",
      " [0.35733929]\n",
      " [0.36352962]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.3695937]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[[0.32682845]\n",
      "  [0.33122864]\n",
      "  [0.33600253]\n",
      "  [0.34119421]\n",
      "  [0.34637189]\n",
      "  [0.35178661]\n",
      "  [0.35733929]\n",
      "  [0.36352962]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09088053554296494\n",
      "Predicción post entrenamiento : [[0.37180606]]\n",
      "PERDIDAAAA despues: 0.08955154567956924\n",
      "loss en el callback: 0.07707875221967697, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "ejemplar: [[0.33122864]\n",
      " [0.33600253]\n",
      " [0.34119421]\n",
      " [0.34637189]\n",
      " [0.35178661]\n",
      " [0.35733929]\n",
      " [0.36352962]\n",
      " [0.36959371]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.37551343]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[[0.33122864]\n",
      "  [0.33600253]\n",
      "  [0.34119421]\n",
      "  [0.34637189]\n",
      "  [0.35178661]\n",
      "  [0.35733929]\n",
      "  [0.36352962]\n",
      "  [0.36959371]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08895687758922577\n",
      "Predicción post entrenamiento : [[0.37739623]]\n",
      "PERDIDAAAA despues: 0.08783731609582901\n",
      "loss en el callback: 0.050557561218738556, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "ejemplar: [[0.33600253]\n",
      " [0.34119421]\n",
      " [0.34637189]\n",
      " [0.35178661]\n",
      " [0.35733929]\n",
      " [0.36352962]\n",
      " [0.36959371]\n",
      " [0.37551343]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.38132343]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[[0.33600253]\n",
      "  [0.34119421]\n",
      "  [0.34637189]\n",
      "  [0.35178661]\n",
      "  [0.35733929]\n",
      "  [0.36352962]\n",
      "  [0.36959371]\n",
      "  [0.37551343]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1109745055437088\n",
      "Predicción post entrenamiento : [[0.38372886]]\n",
      "PERDIDAAAA despues: 0.1093776524066925\n",
      "loss en el callback: 0.1025710254907608, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "ejemplar: [[0.34119421]\n",
      " [0.34637189]\n",
      " [0.35178661]\n",
      " [0.35733929]\n",
      " [0.36352962]\n",
      " [0.36959371]\n",
      " [0.37551343]\n",
      " [0.38132343]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.38784072]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[[0.34119421]\n",
      "  [0.34637189]\n",
      "  [0.35178661]\n",
      "  [0.35733929]\n",
      "  [0.36352962]\n",
      "  [0.36959371]\n",
      "  [0.37551343]\n",
      "  [0.38132343]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12677660584449768\n",
      "Predicción post entrenamiento : [[0.39045352]]\n",
      "PERDIDAAAA despues: 0.12492281198501587\n",
      "loss en el callback: 0.21065467596054077, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "ejemplar: [[0.34637189]\n",
      " [0.35178661]\n",
      " [0.35733929]\n",
      " [0.36352962]\n",
      " [0.36959371]\n",
      " [0.37551343]\n",
      " [0.38132343]\n",
      " [0.38784072]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.39469418]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[[0.34637189]\n",
      "  [0.35178661]\n",
      "  [0.35733929]\n",
      "  [0.36352962]\n",
      "  [0.36959371]\n",
      "  [0.37551343]\n",
      "  [0.38132343]\n",
      "  [0.38784072]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10751444101333618\n",
      "Predicción post entrenamiento : [[0.39701402]]\n",
      "PERDIDAAAA despues: 0.10599849373102188\n",
      "loss en el callback: 0.10243336111307144, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "ejemplar: [[0.35178661]\n",
      " [0.35733929]\n",
      " [0.36352962]\n",
      " [0.36959371]\n",
      " [0.37551343]\n",
      " [0.38132343]\n",
      " [0.38784072]\n",
      " [0.39469418]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.40142533]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[[0.35178661]\n",
      "  [0.35733929]\n",
      "  [0.36352962]\n",
      "  [0.36959371]\n",
      "  [0.37551343]\n",
      "  [0.38132343]\n",
      "  [0.38784072]\n",
      "  [0.39469418]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08875396102666855\n",
      "Predicción post entrenamiento : [[0.4035501]]\n",
      "PERDIDAAAA despues: 0.08749247342348099\n",
      "loss en el callback: 0.08866646885871887, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "ejemplar: [[0.35733929]\n",
      " [0.36352962]\n",
      " [0.36959371]\n",
      " [0.37551343]\n",
      " [0.38132343]\n",
      " [0.38784072]\n",
      " [0.39469418]\n",
      " [0.40142533]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.40811723]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[[0.35733929]\n",
      "  [0.36352962]\n",
      "  [0.36959371]\n",
      "  [0.37551343]\n",
      "  [0.38132343]\n",
      "  [0.38784072]\n",
      "  [0.39469418]\n",
      "  [0.40142533]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10836862027645111\n",
      "Predicción post entrenamiento : [[0.41029942]]\n",
      "PERDIDAAAA despues: 0.10693665593862534\n",
      "loss en el callback: 0.09854868054389954, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "ejemplar: [[0.36352962]\n",
      " [0.36959371]\n",
      " [0.37551343]\n",
      " [0.38132343]\n",
      " [0.38784072]\n",
      " [0.39469418]\n",
      " [0.40142533]\n",
      " [0.40811723]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.41502905]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[[0.36352962]\n",
      "  [0.36959371]\n",
      "  [0.37551343]\n",
      "  [0.38132343]\n",
      "  [0.38784072]\n",
      "  [0.39469418]\n",
      "  [0.40142533]\n",
      "  [0.40811723]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09387899190187454\n",
      "Predicción post entrenamiento : [[0.41715375]]\n",
      "PERDIDAAAA despues: 0.09258150309324265\n",
      "loss en el callback: 0.09277963638305664, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "ejemplar: [[0.36959371]\n",
      " [0.37551343]\n",
      " [0.38132343]\n",
      " [0.38784072]\n",
      " [0.39469418]\n",
      " [0.40142533]\n",
      " [0.40811723]\n",
      " [0.41502905]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.42192775]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[[0.36959371]\n",
      "  [0.37551343]\n",
      "  [0.38132343]\n",
      "  [0.38784072]\n",
      "  [0.39469418]\n",
      "  [0.40142533]\n",
      "  [0.40811723]\n",
      "  [0.41502905]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08808190375566483\n",
      "Predicción post entrenamiento : [[0.42407468]]\n",
      "PERDIDAAAA despues: 0.08681215345859528\n",
      "loss en el callback: 0.10616125166416168, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "ejemplar: [[0.37551343]\n",
      " [0.38132343]\n",
      " [0.38784072]\n",
      " [0.39469418]\n",
      " [0.40142533]\n",
      " [0.40811723]\n",
      " [0.41502905]\n",
      " [0.42192775]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.42894813]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[[0.37551343]\n",
      "  [0.38132343]\n",
      "  [0.38784072]\n",
      "  [0.39469418]\n",
      "  [0.40142533]\n",
      "  [0.40811723]\n",
      "  [0.41502905]\n",
      "  [0.42192775]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06012754514813423\n",
      "Predicción post entrenamiento : [[0.43065295]]\n",
      "PERDIDAAAA despues: 0.059294380247592926\n",
      "loss en el callback: 0.06842277944087982, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "ejemplar: [[0.38132343]\n",
      " [0.38784072]\n",
      " [0.39469418]\n",
      " [0.40142533]\n",
      " [0.40811723]\n",
      " [0.41502905]\n",
      " [0.42192775]\n",
      " [0.42894813]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.4356931]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[[0.38132343]\n",
      "  [0.38784072]\n",
      "  [0.39469418]\n",
      "  [0.40142533]\n",
      "  [0.40811723]\n",
      "  [0.41502905]\n",
      "  [0.42192775]\n",
      "  [0.42894813]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06910239905118942\n",
      "Predicción post entrenamiento : [[0.4374986]]\n",
      "PERDIDAAAA despues: 0.0681564137339592\n",
      "loss en el callback: 0.0803069919347763, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "ejemplar: [[0.38784072]\n",
      " [0.39469418]\n",
      " [0.40142533]\n",
      " [0.40811723]\n",
      " [0.41502905]\n",
      " [0.42192775]\n",
      " [0.42894813]\n",
      " [0.43569309]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.4427703]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[[0.38784072]\n",
      "  [0.39469418]\n",
      "  [0.40142533]\n",
      "  [0.40811723]\n",
      "  [0.41502905]\n",
      "  [0.42192775]\n",
      "  [0.42894813]\n",
      "  [0.43569309]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07743310183286667\n",
      "Predicción post entrenamiento : [[0.44462848]]\n",
      "PERDIDAAAA despues: 0.07640241086483002\n",
      "loss en el callback: 0.08837411552667618, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "ejemplar: [[0.39469418]\n",
      " [0.40142533]\n",
      " [0.40811723]\n",
      " [0.41502905]\n",
      " [0.42192775]\n",
      " [0.42894813]\n",
      " [0.43569309]\n",
      " [0.4427703 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.4499929]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[[0.39469418]\n",
      "  [0.40142533]\n",
      "  [0.40811723]\n",
      "  [0.41502905]\n",
      "  [0.42192775]\n",
      "  [0.42894813]\n",
      "  [0.43569309]\n",
      "  [0.4427703 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07430815696716309\n",
      "Predicción post entrenamiento : [[0.45183328]]\n",
      "PERDIDAAAA despues: 0.07330818474292755\n",
      "loss en el callback: 0.07883549481630325, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "ejemplar: [[0.40142533]\n",
      " [0.40811723]\n",
      " [0.41502905]\n",
      " [0.42192775]\n",
      " [0.42894813]\n",
      " [0.43569309]\n",
      " [0.4427703 ]\n",
      " [0.4499929 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.45722157]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[[0.40142533]\n",
      "  [0.40811723]\n",
      "  [0.41502905]\n",
      "  [0.42192775]\n",
      "  [0.42894813]\n",
      "  [0.43569309]\n",
      "  [0.4427703 ]\n",
      "  [0.4499929 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08944553881883621\n",
      "Predicción post entrenamiento : [[0.45913795]]\n",
      "PERDIDAAAA despues: 0.08830293267965317\n",
      "loss en el callback: 0.08528683334589005, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "ejemplar: [[0.40811723]\n",
      " [0.41502905]\n",
      " [0.42192775]\n",
      " [0.42894813]\n",
      " [0.43569309]\n",
      " [0.4427703 ]\n",
      " [0.4499929 ]\n",
      " [0.45722157]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.46458945]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[[0.40811723]\n",
      "  [0.41502905]\n",
      "  [0.42192775]\n",
      "  [0.42894813]\n",
      "  [0.43569309]\n",
      "  [0.4427703 ]\n",
      "  [0.4499929 ]\n",
      "  [0.45722157]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1317666620016098\n",
      "Predicción post entrenamiento : [[0.46682212]]\n",
      "PERDIDAAAA despues: 0.13015075027942657\n",
      "loss en el callback: 0.09872196614742279, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "ejemplar: [[0.41502905]\n",
      " [0.42192775]\n",
      " [0.42894813]\n",
      " [0.43569309]\n",
      " [0.4427703 ]\n",
      " [0.4499929 ]\n",
      " [0.45722157]\n",
      " [0.46458945]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.4723632]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[[0.41502905]\n",
      "  [0.42192775]\n",
      "  [0.42894813]\n",
      "  [0.43569309]\n",
      "  [0.4427703 ]\n",
      "  [0.4499929 ]\n",
      "  [0.45722157]\n",
      "  [0.46458945]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13429218530654907\n",
      "Predicción post entrenamiento : [[0.47472715]]\n",
      "PERDIDAAAA despues: 0.1325651854276657\n",
      "loss en el callback: 0.1905791163444519, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "ejemplar: [[0.42192775]\n",
      " [0.42894813]\n",
      " [0.43569309]\n",
      " [0.4427703 ]\n",
      " [0.4499929 ]\n",
      " [0.45722157]\n",
      " [0.46458945]\n",
      " [0.4723632 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.4803238]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[[0.42192775]\n",
      "  [0.42894813]\n",
      "  [0.43569309]\n",
      "  [0.4427703 ]\n",
      "  [0.4499929 ]\n",
      "  [0.45722157]\n",
      "  [0.46458945]\n",
      "  [0.4723632 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09855958819389343\n",
      "Predicción post entrenamiento : [[0.4825239]]\n",
      "PERDIDAAAA despues: 0.09718302637338638\n",
      "loss en el callback: 0.1407899409532547, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "ejemplar: [[0.42894813]\n",
      " [0.43569309]\n",
      " [0.4427703 ]\n",
      " [0.4499929 ]\n",
      " [0.45722157]\n",
      " [0.46458945]\n",
      " [0.4723632 ]\n",
      " [0.48032379]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.48819986]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[[0.42894813]\n",
      "  [0.43569309]\n",
      "  [0.4427703 ]\n",
      "  [0.4499929 ]\n",
      "  [0.45722157]\n",
      "  [0.46458945]\n",
      "  [0.4723632 ]\n",
      "  [0.48032379]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0873822271823883\n",
      "Predicción post entrenamiento : [[0.49009398]]\n",
      "PERDIDAAAA despues: 0.08626599609851837\n",
      "loss en el callback: 0.09766942262649536, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "ejemplar: [[0.43569309]\n",
      " [0.4427703 ]\n",
      " [0.4499929 ]\n",
      " [0.45722157]\n",
      " [0.46458945]\n",
      " [0.4723632 ]\n",
      " [0.48032379]\n",
      " [0.48819986]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.49584597]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[[0.43569309]\n",
      "  [0.4427703 ]\n",
      "  [0.4499929 ]\n",
      "  [0.45722157]\n",
      "  [0.46458945]\n",
      "  [0.4723632 ]\n",
      "  [0.48032379]\n",
      "  [0.48819986]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07402396202087402\n",
      "Predicción post entrenamiento : [[0.49748033]]\n",
      "PERDIDAAAA despues: 0.0731372982263565\n",
      "loss en el callback: 0.0662013366818428, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "ejemplar: [[0.4427703 ]\n",
      " [0.4499929 ]\n",
      " [0.45722157]\n",
      " [0.46458945]\n",
      " [0.4723632 ]\n",
      " [0.48032379]\n",
      " [0.48819986]\n",
      " [0.49584597]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.5034084]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[[0.4427703 ]\n",
      "  [0.4499929 ]\n",
      "  [0.45722157]\n",
      "  [0.46458945]\n",
      "  [0.4723632 ]\n",
      "  [0.48032379]\n",
      "  [0.48819986]\n",
      "  [0.49584597]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07905727624893188\n",
      "Predicción post entrenamiento : [[0.50507987]]\n",
      "PERDIDAAAA despues: 0.07812011986970901\n",
      "loss en el callback: 0.07001658529043198, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "ejemplar: [[0.4499929 ]\n",
      " [0.45722157]\n",
      " [0.46458945]\n",
      " [0.4723632 ]\n",
      " [0.48032379]\n",
      " [0.48819986]\n",
      " [0.49584597]\n",
      " [0.50340837]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.51113635]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[[0.4499929 ]\n",
      "  [0.45722157]\n",
      "  [0.46458945]\n",
      "  [0.4723632 ]\n",
      "  [0.48032379]\n",
      "  [0.48819986]\n",
      "  [0.49584597]\n",
      "  [0.50340837]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13512447476387024\n",
      "Predicción post entrenamiento : [[0.5132742]]\n",
      "PERDIDAAAA despues: 0.13355733454227448\n",
      "loss en el callback: 0.10510090738534927, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "ejemplar: [[0.45722157]\n",
      " [0.46458945]\n",
      " [0.4723632 ]\n",
      " [0.48032379]\n",
      " [0.48819986]\n",
      " [0.49584597]\n",
      " [0.50340837]\n",
      " [0.51113635]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.519449]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[[0.45722157]\n",
      "  [0.46458945]\n",
      "  [0.4723632 ]\n",
      "  [0.48032379]\n",
      "  [0.48819986]\n",
      "  [0.49584597]\n",
      "  [0.50340837]\n",
      "  [0.51113635]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12686462700366974\n",
      "Predicción post entrenamiento : [[0.5216947]]\n",
      "PERDIDAAAA despues: 0.12526990473270416\n",
      "loss en el callback: 0.1365983933210373, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "ejemplar: [[0.46458945]\n",
      " [0.4723632 ]\n",
      " [0.48032379]\n",
      " [0.48819986]\n",
      " [0.49584597]\n",
      " [0.50340837]\n",
      " [0.51113635]\n",
      " [0.519449  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.5280103]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[[0.46458945]\n",
      "  [0.4723632 ]\n",
      "  [0.48032379]\n",
      "  [0.48819986]\n",
      "  [0.49584597]\n",
      "  [0.50340837]\n",
      "  [0.51113635]\n",
      "  [0.519449  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10296749323606491\n",
      "Predicción post entrenamiento : [[0.5298124]]\n",
      "PERDIDAAAA despues: 0.10181421041488647\n",
      "loss en el callback: 0.0798967108130455, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "ejemplar: [[0.4723632 ]\n",
      " [0.48032379]\n",
      " [0.48819986]\n",
      " [0.49584597]\n",
      " [0.50340837]\n",
      " [0.51113635]\n",
      " [0.519449  ]\n",
      " [0.52801031]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.5362583]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[[0.4723632 ]\n",
      "  [0.48032379]\n",
      "  [0.48819986]\n",
      "  [0.49584597]\n",
      "  [0.50340837]\n",
      "  [0.51113635]\n",
      "  [0.519449  ]\n",
      "  [0.52801031]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07954047620296478\n",
      "Predicción post entrenamiento : [[0.53796405]]\n",
      "PERDIDAAAA despues: 0.07858123630285263\n",
      "loss en el callback: 0.08927381038665771, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "ejemplar: [[0.48032379]\n",
      " [0.48819986]\n",
      " [0.49584597]\n",
      " [0.50340837]\n",
      " [0.51113635]\n",
      " [0.519449  ]\n",
      " [0.52801031]\n",
      " [0.53625828]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.54445815]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[[0.48032379]\n",
      "  [0.48819986]\n",
      "  [0.49584597]\n",
      "  [0.50340837]\n",
      "  [0.51113635]\n",
      "  [0.519449  ]\n",
      "  [0.52801031]\n",
      "  [0.53625828]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0797233060002327\n",
      "Predicción post entrenamiento : [[0.54623914]]\n",
      "PERDIDAAAA despues: 0.07872074842453003\n",
      "loss en el callback: 0.09614904969930649, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "ejemplar: [[0.48819986]\n",
      " [0.49584597]\n",
      " [0.50340837]\n",
      " [0.51113635]\n",
      " [0.519449  ]\n",
      " [0.52801031]\n",
      " [0.53625828]\n",
      " [0.54445815]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.55274785]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[[0.48819986]\n",
      "  [0.49584597]\n",
      "  [0.50340837]\n",
      "  [0.51113635]\n",
      "  [0.519449  ]\n",
      "  [0.52801031]\n",
      "  [0.53625828]\n",
      "  [0.54445815]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05410585179924965\n",
      "Predicción post entrenamiento : [[0.5545583]]\n",
      "PERDIDAAAA despues: 0.053266894072294235\n",
      "loss en el callback: 0.16602307558059692, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "ejemplar: [[0.49584597]\n",
      " [0.50340837]\n",
      " [0.51113635]\n",
      " [0.519449  ]\n",
      " [0.52801031]\n",
      " [0.53625828]\n",
      " [0.54445815]\n",
      " [0.55274785]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.5611167]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[[0.49584597]\n",
      "  [0.50340837]\n",
      "  [0.51113635]\n",
      "  [0.519449  ]\n",
      "  [0.52801031]\n",
      "  [0.53625828]\n",
      "  [0.54445815]\n",
      "  [0.55274785]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05203521251678467\n",
      "Predicción post entrenamiento : [[0.5624954]]\n",
      "PERDIDAAAA despues: 0.051408108323812485\n",
      "loss en el callback: 0.05838365480303764, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "ejemplar: [[0.50340837]\n",
      " [0.51113635]\n",
      " [0.519449  ]\n",
      " [0.52801031]\n",
      " [0.53625828]\n",
      " [0.54445815]\n",
      " [0.55274785]\n",
      " [0.5611167 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.5691846]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[[0.50340837]\n",
      "  [0.51113635]\n",
      "  [0.519449  ]\n",
      "  [0.52801031]\n",
      "  [0.53625828]\n",
      "  [0.54445815]\n",
      "  [0.55274785]\n",
      "  [0.5611167 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07021873444318771\n",
      "Predicción post entrenamiento : [[0.5708116]]\n",
      "PERDIDAAAA despues: 0.06935910135507584\n",
      "loss en el callback: 0.07718560099601746, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "ejemplar: [[0.51113635]\n",
      " [0.519449  ]\n",
      " [0.52801031]\n",
      " [0.53625828]\n",
      " [0.54445815]\n",
      " [0.55274785]\n",
      " [0.5611167 ]\n",
      " [0.5691846 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.5776818]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[[0.51113635]\n",
      "  [0.519449  ]\n",
      "  [0.52801031]\n",
      "  [0.53625828]\n",
      "  [0.54445815]\n",
      "  [0.55274785]\n",
      "  [0.5611167 ]\n",
      "  [0.5691846 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05512823164463043\n",
      "Predicción post entrenamiento : [[0.5793045]]\n",
      "PERDIDAAAA despues: 0.054368846118450165\n",
      "loss en el callback: 0.10275530070066452, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "ejemplar: [[0.519449  ]\n",
      " [0.52801031]\n",
      " [0.53625828]\n",
      " [0.54445815]\n",
      " [0.55274785]\n",
      " [0.5611167 ]\n",
      " [0.5691846 ]\n",
      " [0.57768178]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.5863387]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[[0.519449  ]\n",
      "  [0.52801031]\n",
      "  [0.53625828]\n",
      "  [0.54445815]\n",
      "  [0.55274785]\n",
      "  [0.5611167 ]\n",
      "  [0.5691846 ]\n",
      "  [0.57768178]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.046182505786418915\n",
      "Predicción post entrenamiento : [[0.5879512]]\n",
      "PERDIDAAAA despues: 0.04549205303192139\n",
      "loss en el callback: 0.10541833937168121, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "ejemplar: [[0.52801031]\n",
      " [0.53625828]\n",
      " [0.54445815]\n",
      " [0.55274785]\n",
      " [0.5611167 ]\n",
      " [0.5691846 ]\n",
      " [0.57768178]\n",
      " [0.5863387 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.59501225]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[[0.52801031]\n",
      "  [0.53625828]\n",
      "  [0.54445815]\n",
      "  [0.55274785]\n",
      "  [0.5611167 ]\n",
      "  [0.5691846 ]\n",
      "  [0.57768178]\n",
      "  [0.5863387 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04333258792757988\n",
      "Predicción post entrenamiento : [[0.5964243]]\n",
      "PERDIDAAAA despues: 0.042746711522340775\n",
      "loss en el callback: 0.06929352879524231, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "ejemplar: [[0.53625828]\n",
      " [0.54445815]\n",
      " [0.55274785]\n",
      " [0.5611167 ]\n",
      " [0.5691846 ]\n",
      " [0.57768178]\n",
      " [0.5863387 ]\n",
      " [0.59501225]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.60344744]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[[0.53625828]\n",
      "  [0.54445815]\n",
      "  [0.55274785]\n",
      "  [0.5611167 ]\n",
      "  [0.5691846 ]\n",
      "  [0.57768178]\n",
      "  [0.5863387 ]\n",
      "  [0.59501225]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03611651435494423\n",
      "Predicción post entrenamiento : [[0.6043971]]\n",
      "PERDIDAAAA despues: 0.03575645387172699\n",
      "loss en el callback: 0.026287218555808067, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "ejemplar: [[0.54445815]\n",
      " [0.55274785]\n",
      " [0.5611167 ]\n",
      " [0.5691846 ]\n",
      " [0.57768178]\n",
      " [0.5863387 ]\n",
      " [0.59501225]\n",
      " [0.60344744]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.6114646]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[[0.54445815]\n",
      "  [0.55274785]\n",
      "  [0.5611167 ]\n",
      "  [0.5691846 ]\n",
      "  [0.57768178]\n",
      "  [0.5863387 ]\n",
      "  [0.59501225]\n",
      "  [0.60344744]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02211342751979828\n",
      "Predicción post entrenamiento : [[0.61235994]]\n",
      "PERDIDAAAA despues: 0.021847950294613838\n",
      "loss en el callback: 0.02282525971531868, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "ejemplar: [[0.55274785]\n",
      " [0.5611167 ]\n",
      " [0.5691846 ]\n",
      " [0.57768178]\n",
      " [0.5863387 ]\n",
      " [0.59501225]\n",
      " [0.60344744]\n",
      " [0.61146462]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.61949307]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[[0.55274785]\n",
      "  [0.5611167 ]\n",
      "  [0.5691846 ]\n",
      "  [0.57768178]\n",
      "  [0.5863387 ]\n",
      "  [0.59501225]\n",
      "  [0.60344744]\n",
      "  [0.61146462]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013428370468318462\n",
      "Predicción post entrenamiento : [[0.6201801]]\n",
      "PERDIDAAAA despues: 0.013269621878862381\n",
      "loss en el callback: 0.01464042067527771, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "ejemplar: [[0.5611167 ]\n",
      " [0.5691846 ]\n",
      " [0.57768178]\n",
      " [0.5863387 ]\n",
      " [0.59501225]\n",
      " [0.60344744]\n",
      " [0.61146462]\n",
      " [0.61949307]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.6273603]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[[0.5611167 ]\n",
      "  [0.5691846 ]\n",
      "  [0.57768178]\n",
      "  [0.5863387 ]\n",
      "  [0.59501225]\n",
      "  [0.60344744]\n",
      "  [0.61146462]\n",
      "  [0.61949307]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006860732100903988\n",
      "Predicción post entrenamiento : [[0.6275024]]\n",
      "PERDIDAAAA despues: 0.006837212480604649\n",
      "loss en el callback: 0.0005192733951844275, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "ejemplar: [[0.5691846 ]\n",
      " [0.57768178]\n",
      " [0.5863387 ]\n",
      " [0.59501225]\n",
      " [0.60344744]\n",
      " [0.61146462]\n",
      " [0.61949307]\n",
      " [0.62736028]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.63470435]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[[0.5691846 ]\n",
      "  [0.57768178]\n",
      "  [0.5863387 ]\n",
      "  [0.59501225]\n",
      "  [0.60344744]\n",
      "  [0.61146462]\n",
      "  [0.61949307]\n",
      "  [0.62736028]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005994280334562063\n",
      "Predicción post entrenamiento : [[0.6353024]]\n",
      "PERDIDAAAA despues: 0.005902029108256102\n",
      "loss en el callback: 0.011370458640158176, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "ejemplar: [[0.57768178]\n",
      " [0.5863387 ]\n",
      " [0.59501225]\n",
      " [0.60344744]\n",
      " [0.61146462]\n",
      " [0.61949307]\n",
      " [0.62736028]\n",
      " [0.63470435]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.6425961]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[[0.57768178]\n",
      "  [0.5863387 ]\n",
      "  [0.59501225]\n",
      "  [0.60344744]\n",
      "  [0.61146462]\n",
      "  [0.61949307]\n",
      "  [0.62736028]\n",
      "  [0.63470435]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009416703134775162\n",
      "Predicción post entrenamiento : [[0.6431308]]\n",
      "PERDIDAAAA despues: 0.009313223883509636\n",
      "loss en el callback: 0.008160187862813473, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "ejemplar: [[0.5863387 ]\n",
      " [0.59501225]\n",
      " [0.60344744]\n",
      " [0.61146462]\n",
      " [0.61949307]\n",
      " [0.62736028]\n",
      " [0.63470435]\n",
      " [0.64259613]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.6503846]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[[0.5863387 ]\n",
      "  [0.59501225]\n",
      "  [0.60344744]\n",
      "  [0.61146462]\n",
      "  [0.61949307]\n",
      "  [0.62736028]\n",
      "  [0.63470435]\n",
      "  [0.64259613]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007355493027716875\n",
      "Predicción post entrenamiento : [[0.6508926]]\n",
      "PERDIDAAAA despues: 0.007268612738698721\n",
      "loss en el callback: 0.008470484055578709, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "ejemplar: [[0.59501225]\n",
      " [0.60344744]\n",
      " [0.61146462]\n",
      " [0.61949307]\n",
      " [0.62736028]\n",
      " [0.63470435]\n",
      " [0.64259613]\n",
      " [0.6503846 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.65802956]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[[0.59501225]\n",
      "  [0.60344744]\n",
      "  [0.61146462]\n",
      "  [0.61949307]\n",
      "  [0.62736028]\n",
      "  [0.63470435]\n",
      "  [0.64259613]\n",
      "  [0.6503846 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 9.103361662710086e-05\n",
      "Predicción post entrenamiento : [[0.65816283]]\n",
      "PERDIDAAAA despues: 8.850816811900586e-05\n",
      "loss en el callback: 0.0005581977311521769, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "ejemplar: [[0.60344744]\n",
      " [0.61146462]\n",
      " [0.61949307]\n",
      " [0.62736028]\n",
      " [0.63470435]\n",
      " [0.64259613]\n",
      " [0.6503846 ]\n",
      " [0.65802956]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.6651365]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[[0.60344744]\n",
      "  [0.61146462]\n",
      "  [0.61949307]\n",
      "  [0.62736028]\n",
      "  [0.63470435]\n",
      "  [0.64259613]\n",
      "  [0.6503846 ]\n",
      "  [0.65802956]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.2647076548309997e-05\n",
      "Predicción post entrenamiento : [[0.6650839]]\n",
      "PERDIDAAAA despues: 2.3150776542024687e-05\n",
      "loss en el callback: 8.614321995992213e-05, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "ejemplar: [[0.61146462]\n",
      " [0.61949307]\n",
      " [0.62736028]\n",
      " [0.63470435]\n",
      " [0.64259613]\n",
      " [0.6503846 ]\n",
      " [0.65802956]\n",
      " [0.66513652]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.6719164]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[[0.61146462]\n",
      "  [0.61949307]\n",
      "  [0.62736028]\n",
      "  [0.63470435]\n",
      "  [0.64259613]\n",
      "  [0.6503846 ]\n",
      "  [0.65802956]\n",
      "  [0.66513652]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006107225199230015\n",
      "Predicción post entrenamiento : [[0.67258227]]\n",
      "PERDIDAAAA despues: 0.0005782561493106186\n",
      "loss en el callback: 0.018392961472272873, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "ejemplar: [[0.61949307]\n",
      " [0.62736028]\n",
      " [0.63470435]\n",
      " [0.64259613]\n",
      " [0.6503846 ]\n",
      " [0.65802956]\n",
      " [0.66513652]\n",
      " [0.67191643]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.67935246]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[[0.61949307]\n",
      "  [0.62736028]\n",
      "  [0.63470435]\n",
      "  [0.64259613]\n",
      "  [0.6503846 ]\n",
      "  [0.65802956]\n",
      "  [0.66513652]\n",
      "  [0.67191643]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005478003295138478\n",
      "Predicción post entrenamiento : [[0.6790159]]\n",
      "PERDIDAAAA despues: 0.0005321578937582672\n",
      "loss en el callback: 0.0034197878558188677, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "ejemplar: [[0.62736028]\n",
      " [0.63470435]\n",
      " [0.64259613]\n",
      " [0.6503846 ]\n",
      " [0.65802956]\n",
      " [0.66513652]\n",
      " [0.67191643]\n",
      " [0.67935246]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.68568873]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[[0.62736028]\n",
      "  [0.63470435]\n",
      "  [0.64259613]\n",
      "  [0.6503846 ]\n",
      "  [0.65802956]\n",
      "  [0.66513652]\n",
      "  [0.67191643]\n",
      "  [0.67935246]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.736290793516673e-05\n",
      "Predicción post entrenamiento : [[0.6855629]]\n",
      "PERDIDAAAA despues: 4.564686241792515e-05\n",
      "loss en el callback: 0.000540046370588243, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "ejemplar: [[0.63470435]\n",
      " [0.64259613]\n",
      " [0.6503846 ]\n",
      " [0.65802956]\n",
      " [0.66513652]\n",
      " [0.67191643]\n",
      " [0.67935246]\n",
      " [0.68568873]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.6921481]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[[0.63470435]\n",
      "  [0.64259613]\n",
      "  [0.6503846 ]\n",
      "  [0.65802956]\n",
      "  [0.66513652]\n",
      "  [0.67191643]\n",
      "  [0.67935246]\n",
      "  [0.68568873]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00025771671789698303\n",
      "Predicción post entrenamiento : [[0.69262165]]\n",
      "PERDIDAAAA despues: 0.0002731455606408417\n",
      "loss en el callback: 0.009301159530878067, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "ejemplar: [[0.64259613]\n",
      " [0.6503846 ]\n",
      " [0.65802956]\n",
      " [0.66513652]\n",
      " [0.67191643]\n",
      " [0.67935246]\n",
      " [0.68568873]\n",
      " [0.69214809]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.6992275]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[[0.64259613]\n",
      "  [0.6503846 ]\n",
      "  [0.65802956]\n",
      "  [0.66513652]\n",
      "  [0.67191643]\n",
      "  [0.67935246]\n",
      "  [0.68568873]\n",
      "  [0.69214809]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009201910579577088\n",
      "Predicción post entrenamiento : [[0.69918245]]\n",
      "PERDIDAAAA despues: 0.0009229269344359636\n",
      "loss en el callback: 6.381919229170308e-05, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "ejemplar: [[0.6503846 ]\n",
      " [0.65802956]\n",
      " [0.66513652]\n",
      " [0.67191643]\n",
      " [0.67935246]\n",
      " [0.68568873]\n",
      " [0.69214809]\n",
      " [0.69922751]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.7056263]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[[0.6503846 ]\n",
      "  [0.65802956]\n",
      "  [0.66513652]\n",
      "  [0.67191643]\n",
      "  [0.67935246]\n",
      "  [0.68568873]\n",
      "  [0.69214809]\n",
      "  [0.69922751]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.8902857846114784e-05\n",
      "Predicción post entrenamiento : [[0.7055634]]\n",
      "PERDIDAAAA despues: 1.8360013200435787e-05\n",
      "loss en el callback: 0.00012923631584271789, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "ejemplar: [[0.65802956]\n",
      " [0.66513652]\n",
      " [0.67191643]\n",
      " [0.67935246]\n",
      " [0.68568873]\n",
      " [0.69214809]\n",
      " [0.69922751]\n",
      " [0.70562631]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.7118236]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[[0.65802956]\n",
      "  [0.66513652]\n",
      "  [0.67191643]\n",
      "  [0.67935246]\n",
      "  [0.68568873]\n",
      "  [0.69214809]\n",
      "  [0.69922751]\n",
      "  [0.70562631]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003103426657617092\n",
      "Predicción post entrenamiento : [[0.7120802]]\n",
      "PERDIDAAAA despues: 0.0030749032739549875\n",
      "loss en el callback: 0.00212477776221931, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "ejemplar: [[0.66513652]\n",
      " [0.67191643]\n",
      " [0.67935246]\n",
      " [0.68568873]\n",
      " [0.69214809]\n",
      " [0.69922751]\n",
      " [0.70562631]\n",
      " [0.71182358]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.71814823]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[[0.66513652]\n",
      "  [0.67191643]\n",
      "  [0.67935246]\n",
      "  [0.68568873]\n",
      "  [0.69214809]\n",
      "  [0.69922751]\n",
      "  [0.70562631]\n",
      "  [0.71182358]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013679240364581347\n",
      "Predicción post entrenamiento : [[0.7183885]]\n",
      "PERDIDAAAA despues: 0.0013502090005204082\n",
      "loss en el callback: 0.0019763733725994825, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "ejemplar: [[0.67191643]\n",
      " [0.67935246]\n",
      " [0.68568873]\n",
      " [0.69214809]\n",
      " [0.69922751]\n",
      " [0.70562631]\n",
      " [0.71182358]\n",
      " [0.71814823]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.7243702]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[[0.67191643]\n",
      "  [0.67935246]\n",
      "  [0.68568873]\n",
      "  [0.69214809]\n",
      "  [0.69922751]\n",
      "  [0.70562631]\n",
      "  [0.71182358]\n",
      "  [0.71814823]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004280697030480951\n",
      "Predicción post entrenamiento : [[0.7241158]]\n",
      "PERDIDAAAA despues: 0.00043866108171641827\n",
      "loss en el callback: 0.0019786476623266935, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "ejemplar: [[0.67935246]\n",
      " [0.68568873]\n",
      " [0.69214809]\n",
      " [0.69922751]\n",
      " [0.70562631]\n",
      " [0.71182358]\n",
      " [0.71814823]\n",
      " [0.72437018]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.7300721]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[[0.67935246]\n",
      "  [0.68568873]\n",
      "  [0.69214809]\n",
      "  [0.69922751]\n",
      "  [0.70562631]\n",
      "  [0.71182358]\n",
      "  [0.71814823]\n",
      "  [0.72437018]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004823288763873279\n",
      "Predicción post entrenamiento : [[0.729682]]\n",
      "PERDIDAAAA despues: 0.000499613699503243\n",
      "loss en el callback: 0.0046455091796815395, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "ejemplar: [[0.68568873]\n",
      " [0.69214809]\n",
      " [0.69922751]\n",
      " [0.70562631]\n",
      " [0.71182358]\n",
      " [0.71814823]\n",
      " [0.72437018]\n",
      " [0.73007208]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.73540246]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[[0.68568873]\n",
      "  [0.69214809]\n",
      "  [0.69922751]\n",
      "  [0.70562631]\n",
      "  [0.71182358]\n",
      "  [0.71814823]\n",
      "  [0.72437018]\n",
      "  [0.73007208]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006553638959303498\n",
      "Predicción post entrenamiento : [[0.734759]]\n",
      "PERDIDAAAA despues: 0.0006228311103768647\n",
      "loss en el callback: 0.012377182021737099, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "ejemplar: [[0.69214809]\n",
      " [0.69922751]\n",
      " [0.70562631]\n",
      " [0.71182358]\n",
      " [0.71814823]\n",
      " [0.72437018]\n",
      " [0.73007208]\n",
      " [0.73540246]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.74050087]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[[0.69214809]\n",
      "  [0.69922751]\n",
      "  [0.70562631]\n",
      "  [0.71182358]\n",
      "  [0.71814823]\n",
      "  [0.72437018]\n",
      "  [0.73007208]\n",
      "  [0.73540246]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0025070873089134693\n",
      "Predicción post entrenamiento : [[0.7402264]]\n",
      "PERDIDAAAA despues: 0.002479675691574812\n",
      "loss en el callback: 0.0029290199745446444, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "ejemplar: [[0.69922751]\n",
      " [0.70562631]\n",
      " [0.71182358]\n",
      " [0.71814823]\n",
      " [0.72437018]\n",
      " [0.73007208]\n",
      " [0.73540246]\n",
      " [0.74050087]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.7459283]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[[0.69922751]\n",
      "  [0.70562631]\n",
      "  [0.71182358]\n",
      "  [0.71814823]\n",
      "  [0.72437018]\n",
      "  [0.73007208]\n",
      "  [0.73540246]\n",
      "  [0.74050087]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.107300916686654e-05\n",
      "Predicción post entrenamiento : [[0.746049]]\n",
      "PERDIDAAAA despues: 6.905246846145019e-05\n",
      "loss en el callback: 0.0005495930672623217, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "ejemplar: [[0.70562631]\n",
      " [0.71182358]\n",
      " [0.71814823]\n",
      " [0.72437018]\n",
      " [0.73007208]\n",
      " [0.73540246]\n",
      " [0.74050087]\n",
      " [0.74592829]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.75149506]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[[0.70562631]\n",
      "  [0.71182358]\n",
      "  [0.71814823]\n",
      "  [0.72437018]\n",
      "  [0.73007208]\n",
      "  [0.73540246]\n",
      "  [0.74050087]\n",
      "  [0.74592829]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008581602014601231\n",
      "Predicción post entrenamiento : [[0.75119233]]\n",
      "PERDIDAAAA despues: 0.0008405151893384755\n",
      "loss en el callback: 0.0029232550878077745, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "ejemplar: [[0.71182358]\n",
      " [0.71814823]\n",
      " [0.72437018]\n",
      " [0.73007208]\n",
      " [0.73540246]\n",
      " [0.74050087]\n",
      " [0.74592829]\n",
      " [0.75149506]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.75650877]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[[0.71182358]\n",
      "  [0.71814823]\n",
      "  [0.72437018]\n",
      "  [0.73007208]\n",
      "  [0.73540246]\n",
      "  [0.74050087]\n",
      "  [0.74592829]\n",
      "  [0.75149506]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008463924750685692\n",
      "Predicción post entrenamiento : [[0.7576333]]\n",
      "PERDIDAAAA despues: 0.008258271031081676\n",
      "loss en el callback: 0.07070085406303406, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "ejemplar: [[0.71814823]\n",
      " [0.72437018]\n",
      " [0.73007208]\n",
      " [0.73540246]\n",
      " [0.74050087]\n",
      " [0.74592829]\n",
      " [0.75149506]\n",
      " [0.75650877]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.7628342]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[[0.71814823]\n",
      "  [0.72437018]\n",
      "  [0.73007208]\n",
      "  [0.73540246]\n",
      "  [0.74050087]\n",
      "  [0.74592829]\n",
      "  [0.75149506]\n",
      "  [0.75650877]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02034297212958336\n",
      "Predicción post entrenamiento : [[0.7637302]]\n",
      "PERDIDAAAA despues: 0.02008817344903946\n",
      "loss en el callback: 0.031583935022354126, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "ejemplar: [[0.72437018]\n",
      " [0.73007208]\n",
      " [0.73540246]\n",
      " [0.74050087]\n",
      " [0.74592829]\n",
      " [0.75149506]\n",
      " [0.75650877]\n",
      " [0.76283419]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.76874286]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[[0.72437018]\n",
      "  [0.73007208]\n",
      "  [0.73540246]\n",
      "  [0.74050087]\n",
      "  [0.74592829]\n",
      "  [0.75149506]\n",
      "  [0.75650877]\n",
      "  [0.76283419]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01287620235234499\n",
      "Predicción post entrenamiento : [[0.7685101]]\n",
      "PERDIDAAAA despues: 0.012929080054163933\n",
      "loss en el callback: 0.0015043395105749369, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "ejemplar: [[0.73007208]\n",
      " [0.73540246]\n",
      " [0.74050087]\n",
      " [0.74592829]\n",
      " [0.75149506]\n",
      " [0.75650877]\n",
      " [0.76283419]\n",
      " [0.76874286]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.77333015]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[[0.73007208]\n",
      "  [0.73540246]\n",
      "  [0.74050087]\n",
      "  [0.74592829]\n",
      "  [0.75149506]\n",
      "  [0.75650877]\n",
      "  [0.76283419]\n",
      "  [0.76874286]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018078826367855072\n",
      "Predicción post entrenamiento : [[0.7734906]]\n",
      "PERDIDAAAA despues: 0.018035704270005226\n",
      "loss en el callback: 0.0007830621907487512, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "ejemplar: [[0.73540246]\n",
      " [0.74050087]\n",
      " [0.74592829]\n",
      " [0.75149506]\n",
      " [0.75650877]\n",
      " [0.76283419]\n",
      " [0.76874286]\n",
      " [0.77333015]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.77824205]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[[0.73540246]\n",
      "  [0.74050087]\n",
      "  [0.74592829]\n",
      "  [0.75149506]\n",
      "  [0.75650877]\n",
      "  [0.76283419]\n",
      "  [0.76874286]\n",
      "  [0.77333015]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012395624071359634\n",
      "Predicción post entrenamiento : [[0.7784216]]\n",
      "PERDIDAAAA despues: 0.012355679646134377\n",
      "loss en el callback: 0.0011029026936739683, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "ejemplar: [[0.74050087]\n",
      " [0.74592829]\n",
      " [0.75149506]\n",
      " [0.75650877]\n",
      " [0.76283419]\n",
      " [0.76874286]\n",
      " [0.77333015]\n",
      " [0.77824205]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.7832024]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[[0.74050087]\n",
      "  [0.74592829]\n",
      "  [0.75149506]\n",
      "  [0.75650877]\n",
      "  [0.76283419]\n",
      "  [0.76874286]\n",
      "  [0.77333015]\n",
      "  [0.77824205]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008400139398872852\n",
      "Predicción post entrenamiento : [[0.7834811]]\n",
      "PERDIDAAAA despues: 0.008349128067493439\n",
      "loss en el callback: 0.0027115975972265005, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "ejemplar: [[0.74592829]\n",
      " [0.75149506]\n",
      " [0.75650877]\n",
      " [0.76283419]\n",
      " [0.76874286]\n",
      " [0.77333015]\n",
      " [0.77824205]\n",
      " [0.78320241]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.7883574]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[[0.74592829]\n",
      "  [0.75149506]\n",
      "  [0.75650877]\n",
      "  [0.76283419]\n",
      "  [0.76874286]\n",
      "  [0.77333015]\n",
      "  [0.77824205]\n",
      "  [0.78320241]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015588662587106228\n",
      "Predicción post entrenamiento : [[0.7890435]]\n",
      "PERDIDAAAA despues: 0.015417804941534996\n",
      "loss en el callback: 0.019372202455997467, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "ejemplar: [[0.75149506]\n",
      " [0.75650877]\n",
      " [0.76283419]\n",
      " [0.76874286]\n",
      " [0.77333015]\n",
      " [0.77824205]\n",
      " [0.78320241]\n",
      " [0.78835738]]\n",
      "ejemplar: (8, 1)\n",
      "y: 1.0\n",
      "Predicción : [[0.7939216]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[[0.75149506]\n",
      "  [0.75650877]\n",
      "  [0.76283419]\n",
      "  [0.76874286]\n",
      "  [0.77333015]\n",
      "  [0.77824205]\n",
      "  [0.78320241]\n",
      "  [0.78835738]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04246830940246582\n",
      "Predicción post entrenamiento : [[0.7948412]]\n",
      "PERDIDAAAA despues: 0.042090144008398056\n",
      "loss en el callback: 0.03222217038273811, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "ejemplar: [[0.75650877]\n",
      " [0.76283419]\n",
      " [0.76874286]\n",
      " [0.77333015]\n",
      " [0.77824205]\n",
      " [0.78320241]\n",
      " [0.78835738]\n",
      " [0.79392159]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.79966766]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[[0.75650877]\n",
      "  [0.76283419]\n",
      "  [0.76874286]\n",
      "  [0.77333015]\n",
      "  [0.77824205]\n",
      "  [0.78320241]\n",
      "  [0.78835738]\n",
      "  [0.79392159]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.029202161356806755\n",
      "Predicción post entrenamiento : [[0.8003748]]\n",
      "PERDIDAAAA despues: 0.028960976749658585\n",
      "loss en el callback: 0.019481297582387924, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "ejemplar: [[0.76283419]\n",
      " [0.76874286]\n",
      " [0.77333015]\n",
      " [0.77824205]\n",
      " [0.78320241]\n",
      " [0.78835738]\n",
      " [0.79392159]\n",
      " [0.79966766]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.80529]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[[0.76283419]\n",
      "  [0.76874286]\n",
      "  [0.77333015]\n",
      "  [0.77824205]\n",
      "  [0.78320241]\n",
      "  [0.78835738]\n",
      "  [0.79392159]\n",
      "  [0.79966766]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006974385119974613\n",
      "Predicción post entrenamiento : [[0.80583686]]\n",
      "PERDIDAAAA despues: 0.006883342284709215\n",
      "loss en el callback: 0.012046849355101585, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "ejemplar: [[0.76874286]\n",
      " [0.77333015]\n",
      " [0.77824205]\n",
      " [0.78320241]\n",
      " [0.78835738]\n",
      " [0.79392159]\n",
      " [0.79966766]\n",
      " [0.80528998]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.8104687]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[[0.76874286]\n",
      "  [0.77333015]\n",
      "  [0.77824205]\n",
      "  [0.78320241]\n",
      "  [0.78835738]\n",
      "  [0.79392159]\n",
      "  [0.79966766]\n",
      "  [0.80528998]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004554310347884893\n",
      "Predicción post entrenamiento : [[0.8101993]]\n",
      "PERDIDAAAA despues: 0.004590737633407116\n",
      "loss en el callback: 0.0024135189596563578, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "ejemplar: [[0.77333015]\n",
      " [0.77824205]\n",
      " [0.78320241]\n",
      " [0.78835738]\n",
      " [0.79392159]\n",
      " [0.79966766]\n",
      " [0.80528998]\n",
      " [0.81046867]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.8146345]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[[0.77333015]\n",
      "  [0.77824205]\n",
      "  [0.78320241]\n",
      "  [0.78835738]\n",
      "  [0.79392159]\n",
      "  [0.79966766]\n",
      "  [0.80528998]\n",
      "  [0.81046867]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001173835713416338\n",
      "Predicción post entrenamiento : [[0.8138538]]\n",
      "PERDIDAAAA despues: 0.0012279408983886242\n",
      "loss en el callback: 0.0190346110612154, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "ejemplar: [[0.77824205]\n",
      " [0.78320241]\n",
      " [0.78835738]\n",
      " [0.79392159]\n",
      " [0.79966766]\n",
      " [0.80528998]\n",
      " [0.81046867]\n",
      " [0.8146345 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.8184545]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[[0.77824205]\n",
      "  [0.78320241]\n",
      "  [0.78835738]\n",
      "  [0.79392159]\n",
      "  [0.79966766]\n",
      "  [0.80528998]\n",
      "  [0.81046867]\n",
      "  [0.8146345 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000247064366703853\n",
      "Predicción post entrenamiento : [[0.81847614]]\n",
      "PERDIDAAAA despues: 0.000246384646743536\n",
      "loss en el callback: 1.9647051885840483e-05, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "ejemplar: [[0.78320241]\n",
      " [0.78835738]\n",
      " [0.79392159]\n",
      " [0.79966766]\n",
      " [0.80528998]\n",
      " [0.81046867]\n",
      " [0.8146345 ]\n",
      " [0.8184545 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.8231688]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[[0.78320241]\n",
      "  [0.78835738]\n",
      "  [0.79392159]\n",
      "  [0.79966766]\n",
      "  [0.80528998]\n",
      "  [0.81046867]\n",
      "  [0.8146345 ]\n",
      "  [0.8184545 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010192756308242679\n",
      "Predicción post entrenamiento : [[0.8234456]]\n",
      "PERDIDAAAA despues: 0.0010016777087002993\n",
      "loss en el callback: 0.00332316174171865, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "ejemplar: [[0.78835738]\n",
      " [0.79392159]\n",
      " [0.79966766]\n",
      " [0.80528998]\n",
      " [0.81046867]\n",
      " [0.8146345 ]\n",
      " [0.8184545 ]\n",
      " [0.82316881]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.828209]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[[0.78835738]\n",
      "  [0.79392159]\n",
      "  [0.79966766]\n",
      "  [0.80528998]\n",
      "  [0.81046867]\n",
      "  [0.8146345 ]\n",
      "  [0.8184545 ]\n",
      "  [0.82316881]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002212120918557048\n",
      "Predicción post entrenamiento : [[0.8289295]]\n",
      "PERDIDAAAA despues: 0.0021448652260005474\n",
      "loss en el callback: 0.02842751517891884, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "ejemplar: [[0.79392159]\n",
      " [0.79966766]\n",
      " [0.80528998]\n",
      " [0.81046867]\n",
      " [0.8146345 ]\n",
      " [0.8184545 ]\n",
      " [0.82316881]\n",
      " [0.82820898]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.8336894]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[[0.79392159]\n",
      "  [0.79966766]\n",
      "  [0.80528998]\n",
      "  [0.81046867]\n",
      "  [0.8146345 ]\n",
      "  [0.8184545 ]\n",
      "  [0.82316881]\n",
      "  [0.82820898]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005448857555165887\n",
      "Predicción post entrenamiento : [[0.83351314]]\n",
      "PERDIDAAAA despues: 0.0005531451897695661\n",
      "loss en el callback: 0.0011653557885438204, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "ejemplar: [[0.79966766]\n",
      " [0.80528998]\n",
      " [0.81046867]\n",
      " [0.8146345 ]\n",
      " [0.8184545 ]\n",
      " [0.82316881]\n",
      " [0.82820898]\n",
      " [0.83368939]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.83812195]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[[0.79966766]\n",
      "  [0.80528998]\n",
      "  [0.81046867]\n",
      "  [0.8146345 ]\n",
      "  [0.8184545 ]\n",
      "  [0.82316881]\n",
      "  [0.82820898]\n",
      "  [0.83368939]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00014247257786337286\n",
      "Predicción post entrenamiento : [[0.83790994]]\n",
      "PERDIDAAAA despues: 0.0001475788012612611\n",
      "loss en el callback: 0.0017139316769316792, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "ejemplar: [[0.80528998]\n",
      " [0.81046867]\n",
      " [0.8146345 ]\n",
      " [0.8184545 ]\n",
      " [0.82316881]\n",
      " [0.82820898]\n",
      " [0.83368939]\n",
      " [0.83812195]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.84227425]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[[0.80528998]\n",
      "  [0.81046867]\n",
      "  [0.8146345 ]\n",
      "  [0.8184545 ]\n",
      "  [0.82316881]\n",
      "  [0.82820898]\n",
      "  [0.83368939]\n",
      "  [0.83812195]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.7838671340086876e-07\n",
      "Predicción post entrenamiento : [[0.84254664]]\n",
      "PERDIDAAAA despues: 2.2489587081508944e-08\n",
      "loss en el callback: 0.003666061209514737, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "ejemplar: [[0.81046867]\n",
      " [0.8146345 ]\n",
      " [0.8184545 ]\n",
      " [0.82316881]\n",
      " [0.82820898]\n",
      " [0.83368939]\n",
      " [0.83812195]\n",
      " [0.84227425]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.8466584]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[[0.81046867]\n",
      "  [0.8146345 ]\n",
      "  [0.8184545 ]\n",
      "  [0.82316881]\n",
      "  [0.82820898]\n",
      "  [0.83368939]\n",
      "  [0.83812195]\n",
      "  [0.84227425]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005627131322398782\n",
      "Predicción post entrenamiento : [[0.84668535]]\n",
      "PERDIDAAAA despues: 0.0005639920709654689\n",
      "loss en el callback: 3.246069900342263e-05, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "ejemplar: [[0.8146345 ]\n",
      " [0.8184545 ]\n",
      " [0.82316881]\n",
      " [0.82820898]\n",
      " [0.83368939]\n",
      " [0.83812195]\n",
      " [0.84227425]\n",
      " [0.84665841]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.8506391]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[[0.8146345 ]\n",
      "  [0.8184545 ]\n",
      "  [0.82316881]\n",
      "  [0.82820898]\n",
      "  [0.83368939]\n",
      "  [0.83812195]\n",
      "  [0.84227425]\n",
      "  [0.84665841]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0057962448336184025\n",
      "Predicción post entrenamiento : [[0.8503286]]\n",
      "PERDIDAAAA despues: 0.005749065428972244\n",
      "loss en el callback: 0.004457264207303524, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "ejemplar: [[0.8184545 ]\n",
      " [0.82316881]\n",
      " [0.82820898]\n",
      " [0.83368939]\n",
      " [0.83812195]\n",
      " [0.84227425]\n",
      " [0.84665841]\n",
      " [0.8506391 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.854398]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[[0.8184545 ]\n",
      "  [0.82316881]\n",
      "  [0.82820898]\n",
      "  [0.83368939]\n",
      "  [0.83812195]\n",
      "  [0.84227425]\n",
      "  [0.84665841]\n",
      "  [0.8506391 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0049288636073470116\n",
      "Predicción post entrenamiento : [[0.8539023]]\n",
      "PERDIDAAAA despues: 0.0048595028929412365\n",
      "loss en el callback: 0.011569957248866558, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "ejemplar: [[0.82316881]\n",
      " [0.82820898]\n",
      " [0.83368939]\n",
      " [0.83812195]\n",
      " [0.84227425]\n",
      " [0.84665841]\n",
      " [0.8506391 ]\n",
      " [0.85439801]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.8581922]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[[0.82316881]\n",
      "  [0.82820898]\n",
      "  [0.83368939]\n",
      "  [0.83812195]\n",
      "  [0.84227425]\n",
      "  [0.84665841]\n",
      "  [0.8506391 ]\n",
      "  [0.85439801]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.4090297756629298e-06\n",
      "Predicción post entrenamiento : [[0.85842526]]\n",
      "PERDIDAAAA despues: 1.7398949694324983e-06\n",
      "loss en el callback: 0.0027257506735622883, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "ejemplar: [[0.82820898]\n",
      " [0.83368939]\n",
      " [0.83812195]\n",
      " [0.84227425]\n",
      " [0.84665841]\n",
      " [0.8506391 ]\n",
      " [0.85439801]\n",
      " [0.85819221]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.8626813]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[[0.82820898]\n",
      "  [0.83368939]\n",
      "  [0.83812195]\n",
      "  [0.84227425]\n",
      "  [0.84665841]\n",
      "  [0.8506391 ]\n",
      "  [0.85439801]\n",
      "  [0.85819221]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.991100235609338e-05\n",
      "Predicción post entrenamiento : [[0.8620314]]\n",
      "PERDIDAAAA despues: 5.9464931837283075e-05\n",
      "loss en el callback: 0.015802286565303802, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "ejemplar: [[0.83368939]\n",
      " [0.83812195]\n",
      " [0.84227425]\n",
      " [0.84665841]\n",
      " [0.8506391 ]\n",
      " [0.85439801]\n",
      " [0.85819221]\n",
      " [0.86268133]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.8661221]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[[0.83368939]\n",
      "  [0.83812195]\n",
      "  [0.84227425]\n",
      "  [0.84665841]\n",
      "  [0.8506391 ]\n",
      "  [0.85439801]\n",
      "  [0.85819221]\n",
      "  [0.86268133]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008548144833184779\n",
      "Predicción post entrenamiento : [[0.86585677]]\n",
      "PERDIDAAAA despues: 0.0008393681491725147\n",
      "loss en el callback: 0.0032208466436713934, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "ejemplar: [[0.83812195]\n",
      " [0.84227425]\n",
      " [0.84665841]\n",
      " [0.8506391 ]\n",
      " [0.85439801]\n",
      " [0.85819221]\n",
      " [0.86268133]\n",
      " [0.86612213]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.8696065]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[[0.83812195]\n",
      "  [0.84227425]\n",
      "  [0.84665841]\n",
      "  [0.8506391 ]\n",
      "  [0.85439801]\n",
      "  [0.85819221]\n",
      "  [0.86268133]\n",
      "  [0.86612213]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015757422661408782\n",
      "Predicción post entrenamiento : [[0.86857647]]\n",
      "PERDIDAAAA despues: 0.0014950280310586095\n",
      "loss en el callback: 0.0396396778523922, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "ejemplar: [[0.84227425]\n",
      " [0.84665841]\n",
      " [0.8506391 ]\n",
      " [0.85439801]\n",
      " [0.85819221]\n",
      " [0.86268133]\n",
      " [0.86612213]\n",
      " [0.86960649]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.87222296]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[[0.84227425]\n",
      "  [0.84665841]\n",
      "  [0.8506391 ]\n",
      "  [0.85439801]\n",
      "  [0.85819221]\n",
      "  [0.86268133]\n",
      "  [0.86612213]\n",
      "  [0.86960649]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00022590169101022184\n",
      "Predicción post entrenamiento : [[0.8728585]]\n",
      "PERDIDAAAA despues: 0.00020720054453704506\n",
      "loss en el callback: 0.025517182424664497, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "ejemplar: [[0.84665841]\n",
      " [0.8506391 ]\n",
      " [0.85439801]\n",
      " [0.85819221]\n",
      " [0.86268133]\n",
      " [0.86612213]\n",
      " [0.86960649]\n",
      " [0.87222296]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.8764509]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[[0.84665841]\n",
      "  [0.8506391 ]\n",
      "  [0.85439801]\n",
      "  [0.85819221]\n",
      "  [0.86268133]\n",
      "  [0.86612213]\n",
      "  [0.86960649]\n",
      "  [0.87222296]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00027911001234315336\n",
      "Predicción post entrenamiento : [[0.8769307]]\n",
      "PERDIDAAAA despues: 0.0002953724469989538\n",
      "loss en el callback: 0.01541136670857668, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "ejemplar: [[0.8506391 ]\n",
      " [0.85439801]\n",
      " [0.85819221]\n",
      " [0.86268133]\n",
      " [0.86612213]\n",
      " [0.86960649]\n",
      " [0.87222296]\n",
      " [0.8764509 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.88037634]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[[0.8506391 ]\n",
      "  [0.85439801]\n",
      "  [0.85819221]\n",
      "  [0.86268133]\n",
      "  [0.86612213]\n",
      "  [0.86960649]\n",
      "  [0.87222296]\n",
      "  [0.8764509 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016629507299512625\n",
      "Predicción post entrenamiento : [[0.88072497]]\n",
      "PERDIDAAAA despues: 0.001691505778580904\n",
      "loss en el callback: 0.007021963596343994, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "ejemplar: [[0.85439801]\n",
      " [0.85819221]\n",
      " [0.86268133]\n",
      " [0.86612213]\n",
      " [0.86960649]\n",
      " [0.87222296]\n",
      " [0.8764509 ]\n",
      " [0.88037634]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.88410795]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[[0.85439801]\n",
      "  [0.85819221]\n",
      "  [0.86268133]\n",
      "  [0.86612213]\n",
      "  [0.86960649]\n",
      "  [0.87222296]\n",
      "  [0.8764509 ]\n",
      "  [0.88037634]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010060738772153854\n",
      "Predicción post entrenamiento : [[0.8839804]]\n",
      "PERDIDAAAA despues: 0.010035166516900063\n",
      "loss en el callback: 0.0008275671279989183, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "ejemplar: [[0.85819221]\n",
      " [0.86268133]\n",
      " [0.86612213]\n",
      " [0.86960649]\n",
      " [0.87222296]\n",
      " [0.8764509 ]\n",
      " [0.88037634]\n",
      " [0.88410795]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.8873473]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[[0.85819221]\n",
      "  [0.86268133]\n",
      "  [0.86612213]\n",
      "  [0.86960649]\n",
      "  [0.87222296]\n",
      "  [0.8764509 ]\n",
      "  [0.88037634]\n",
      "  [0.88410795]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0047692544758319855\n",
      "Predicción post entrenamiento : [[0.88684845]]\n",
      "PERDIDAAAA despues: 0.004700604826211929\n",
      "loss en el callback: 0.01097418088465929, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "ejemplar: [[0.86268133]\n",
      " [0.86612213]\n",
      " [0.86960649]\n",
      " [0.87222296]\n",
      " [0.8764509 ]\n",
      " [0.88037634]\n",
      " [0.88410795]\n",
      " [0.88734728]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.8901779]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[[0.86268133]\n",
      "  [0.86612213]\n",
      "  [0.86960649]\n",
      "  [0.87222296]\n",
      "  [0.8764509 ]\n",
      "  [0.88037634]\n",
      "  [0.88410795]\n",
      "  [0.88734728]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009803320281207561\n",
      "Predicción post entrenamiento : [[0.8895456]]\n",
      "PERDIDAAAA despues: 0.009678512811660767\n",
      "loss en el callback: 0.01870288886129856, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "ejemplar: [[0.86612213]\n",
      " [0.86960649]\n",
      " [0.87222296]\n",
      " [0.8764509 ]\n",
      " [0.88037634]\n",
      " [0.88410795]\n",
      " [0.88734728]\n",
      " [0.89017791]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.89262265]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[[0.86612213]\n",
      "  [0.86960649]\n",
      "  [0.87222296]\n",
      "  [0.8764509 ]\n",
      "  [0.88037634]\n",
      "  [0.88410795]\n",
      "  [0.88734728]\n",
      "  [0.89017791]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01744108460843563\n",
      "Predicción post entrenamiento : [[0.8919604]]\n",
      "PERDIDAAAA despues: 0.01726659946143627\n",
      "loss en el callback: 0.0222715325653553, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "ejemplar: [[0.86960649]\n",
      " [0.87222296]\n",
      " [0.8764509 ]\n",
      " [0.88037634]\n",
      " [0.88410795]\n",
      " [0.88734728]\n",
      " [0.89017791]\n",
      " [0.89262265]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.8950472]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[[0.86960649]\n",
      "  [0.87222296]\n",
      "  [0.8764509 ]\n",
      "  [0.88037634]\n",
      "  [0.88410795]\n",
      "  [0.88734728]\n",
      "  [0.89017791]\n",
      "  [0.89262265]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01071090716868639\n",
      "Predicción post entrenamiento : [[0.8947767]]\n",
      "PERDIDAAAA despues: 0.0106549933552742\n",
      "loss en el callback: 0.003910244442522526, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "ejemplar: [[0.87222296]\n",
      " [0.8764509 ]\n",
      " [0.88037634]\n",
      " [0.88410795]\n",
      " [0.88734728]\n",
      " [0.89017791]\n",
      " [0.89262265]\n",
      " [0.89504719]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.89784706]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[[0.87222296]\n",
      "  [0.8764509 ]\n",
      "  [0.88037634]\n",
      "  [0.88410795]\n",
      "  [0.88734728]\n",
      "  [0.89017791]\n",
      "  [0.89262265]\n",
      "  [0.89504719]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016680439934134483\n",
      "Predicción post entrenamiento : [[0.89778847]]\n",
      "PERDIDAAAA despues: 0.01666530780494213\n",
      "loss en el callback: 0.00022196289501152933, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "ejemplar: [[0.8764509 ]\n",
      " [0.88037634]\n",
      " [0.88410795]\n",
      " [0.88734728]\n",
      " [0.89017791]\n",
      " [0.89262265]\n",
      " [0.89504719]\n",
      " [0.89784706]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.90106535]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[[0.8764509 ]\n",
      "  [0.88037634]\n",
      "  [0.88410795]\n",
      "  [0.88734728]\n",
      "  [0.89017791]\n",
      "  [0.89262265]\n",
      "  [0.89504719]\n",
      "  [0.89784706]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01752210035920143\n",
      "Predicción post entrenamiento : [[0.9013689]]\n",
      "PERDIDAAAA despues: 0.01760255917906761\n",
      "loss en el callback: 0.007927470840513706, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "ejemplar: [[0.88037634]\n",
      " [0.88410795]\n",
      " [0.88734728]\n",
      " [0.89017791]\n",
      " [0.89262265]\n",
      " [0.89504719]\n",
      " [0.89784706]\n",
      " [0.90106535]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.9043788]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[[0.88037634]\n",
      "  [0.88410795]\n",
      "  [0.88734728]\n",
      "  [0.89017791]\n",
      "  [0.89262265]\n",
      "  [0.89504719]\n",
      "  [0.89784706]\n",
      "  [0.90106535]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011122575961053371\n",
      "Predicción post entrenamiento : [[0.90357643]]\n",
      "PERDIDAAAA despues: 0.010953985154628754\n",
      "loss en el callback: 0.03000551275908947, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "ejemplar: [[0.88410795]\n",
      " [0.88734728]\n",
      " [0.89017791]\n",
      " [0.89262265]\n",
      " [0.89504719]\n",
      " [0.89784706]\n",
      " [0.90106535]\n",
      " [0.90437877]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.9063433]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[[0.88410795]\n",
      "  [0.88734728]\n",
      "  [0.89017791]\n",
      "  [0.89262265]\n",
      "  [0.89504719]\n",
      "  [0.89784706]\n",
      "  [0.90106535]\n",
      "  [0.90437877]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013534852303564548\n",
      "Predicción post entrenamiento : [[0.9056939]]\n",
      "PERDIDAAAA despues: 0.013384174555540085\n",
      "loss en el callback: 0.021669819951057434, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "ejemplar: [[0.88734728]\n",
      " [0.89017791]\n",
      " [0.89262265]\n",
      " [0.89504719]\n",
      " [0.89784706]\n",
      " [0.90106535]\n",
      " [0.90437877]\n",
      " [0.90634328]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.9082251]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[[0.88734728]\n",
      "  [0.89017791]\n",
      "  [0.89262265]\n",
      "  [0.89504719]\n",
      "  [0.89784706]\n",
      "  [0.90106535]\n",
      "  [0.90437877]\n",
      "  [0.90634328]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.021920181810855865\n",
      "Predicción post entrenamiento : [[0.90732646]]\n",
      "PERDIDAAAA despues: 0.0216548889875412\n",
      "loss en el callback: 0.04149908199906349, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "ejemplar: [[0.89017791]\n",
      " [0.89262265]\n",
      " [0.89504719]\n",
      " [0.89784706]\n",
      " [0.90106535]\n",
      " [0.90437877]\n",
      " [0.90634328]\n",
      " [0.90822512]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.9097226]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[[0.89017791]\n",
      "  [0.89262265]\n",
      "  [0.89504719]\n",
      "  [0.89784706]\n",
      "  [0.90106535]\n",
      "  [0.90437877]\n",
      "  [0.90634328]\n",
      "  [0.90822512]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05032365769147873\n",
      "Predicción post entrenamiento : [[0.90866035]]\n",
      "PERDIDAAAA despues: 0.04984818771481514\n",
      "loss en el callback: 0.06054629385471344, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "ejemplar: [[0.89262265]\n",
      " [0.89504719]\n",
      " [0.89784706]\n",
      " [0.90106535]\n",
      " [0.90437877]\n",
      " [0.90634328]\n",
      " [0.90822512]\n",
      " [0.90972263]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.9110097]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[[0.89262265]\n",
      "  [0.89504719]\n",
      "  [0.89784706]\n",
      "  [0.90106535]\n",
      "  [0.90437877]\n",
      "  [0.90634328]\n",
      "  [0.90822512]\n",
      "  [0.90972263]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09352462738752365\n",
      "Predicción post entrenamiento : [[0.9091483]]\n",
      "PERDIDAAAA despues: 0.0923895612359047\n",
      "loss en el callback: 0.15901145339012146, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "ejemplar: [[0.89504719]\n",
      " [0.89784706]\n",
      " [0.90106535]\n",
      " [0.90437877]\n",
      " [0.90634328]\n",
      " [0.90822512]\n",
      " [0.90972263]\n",
      " [0.91100973]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.91153395]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[[0.89504719]\n",
      "  [0.89784706]\n",
      "  [0.90106535]\n",
      "  [0.90437877]\n",
      "  [0.90634328]\n",
      "  [0.90822512]\n",
      "  [0.90972263]\n",
      "  [0.91100973]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06084873899817467\n",
      "Predicción post entrenamiento : [[0.9111007]]\n",
      "PERDIDAAAA despues: 0.06063517555594444\n",
      "loss en el callback: 0.013992328196763992, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "ejemplar: [[0.89784706]\n",
      " [0.90106535]\n",
      " [0.90437877]\n",
      " [0.90634328]\n",
      " [0.90822512]\n",
      " [0.90972263]\n",
      " [0.91100973]\n",
      " [0.91153395]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.9134938]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[[0.89784706]\n",
      "  [0.90106535]\n",
      "  [0.90437877]\n",
      "  [0.90634328]\n",
      "  [0.90822512]\n",
      "  [0.90972263]\n",
      "  [0.91100973]\n",
      "  [0.91153395]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.042283136397600174\n",
      "Predicción post entrenamiento : [[0.9120174]]\n",
      "PERDIDAAAA despues: 0.04167813062667847\n",
      "loss en el callback: 0.10160336643457413, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "ejemplar: [[0.90106535]\n",
      " [0.90437877]\n",
      " [0.90634328]\n",
      " [0.90822512]\n",
      " [0.90972263]\n",
      " [0.91100973]\n",
      " [0.91153395]\n",
      " [0.91349381]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.91425896]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[[0.90106535]\n",
      "  [0.90437877]\n",
      "  [0.90634328]\n",
      "  [0.90822512]\n",
      "  [0.90972263]\n",
      "  [0.91100973]\n",
      "  [0.91153395]\n",
      "  [0.91349381]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.062200549989938736\n",
      "Predicción post entrenamiento : [[0.9131692]]\n",
      "PERDIDAAAA despues: 0.061658166348934174\n",
      "loss en el callback: 0.061418306082487106, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "ejemplar: [[0.90437877]\n",
      " [0.90634328]\n",
      " [0.90822512]\n",
      " [0.90972263]\n",
      " [0.91100973]\n",
      " [0.91153395]\n",
      " [0.91349381]\n",
      " [0.91425896]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.9150639]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[[0.90437877]\n",
      "  [0.90634328]\n",
      "  [0.90822512]\n",
      "  [0.90972263]\n",
      "  [0.91100973]\n",
      "  [0.91153395]\n",
      "  [0.91349381]\n",
      "  [0.91425896]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04149847477674484\n",
      "Predicción post entrenamiento : [[0.914357]]\n",
      "PERDIDAAAA despues: 0.04121096432209015\n",
      "loss en el callback: 0.03012465499341488, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "ejemplar: [[0.90634328]\n",
      " [0.90822512]\n",
      " [0.90972263]\n",
      " [0.91100973]\n",
      " [0.91153395]\n",
      " [0.91349381]\n",
      " [0.91425896]\n",
      " [0.91506392]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.9157869]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[[0.90634328]\n",
      "  [0.90822512]\n",
      "  [0.90972263]\n",
      "  [0.91100973]\n",
      "  [0.91153395]\n",
      "  [0.91349381]\n",
      "  [0.91425896]\n",
      "  [0.91506392]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05689657852053642\n",
      "Predicción post entrenamiento : [[0.9144528]]\n",
      "PERDIDAAAA despues: 0.056261900812387466\n",
      "loss en el callback: 0.09484077990055084, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "ejemplar: [[0.90822512]\n",
      " [0.90972263]\n",
      " [0.91100973]\n",
      " [0.91153395]\n",
      " [0.91349381]\n",
      " [0.91425896]\n",
      " [0.91506392]\n",
      " [0.91578692]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.9157151]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[[0.90822512]\n",
      "  [0.90972263]\n",
      "  [0.91100973]\n",
      "  [0.91153395]\n",
      "  [0.91349381]\n",
      "  [0.91425896]\n",
      "  [0.91506392]\n",
      "  [0.91578692]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02359522320330143\n",
      "Predicción post entrenamiento : [[0.91537404]]\n",
      "PERDIDAAAA despues: 0.023490561172366142\n",
      "loss en el callback: 0.007707065436989069, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "ejemplar: [[0.90972263]\n",
      " [0.91100973]\n",
      " [0.91153395]\n",
      " [0.91349381]\n",
      " [0.91425896]\n",
      " [0.91506392]\n",
      " [0.91578692]\n",
      " [0.9157151 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.9164441]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[[0.90972263]\n",
      "  [0.91100973]\n",
      "  [0.91153395]\n",
      "  [0.91349381]\n",
      "  [0.91425896]\n",
      "  [0.91506392]\n",
      "  [0.91578692]\n",
      "  [0.9157151 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011966736987233162\n",
      "Predicción post entrenamiento : [[0.91635]]\n",
      "PERDIDAAAA despues: 0.01194615475833416\n",
      "loss en el callback: 0.0005945223965682089, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "ejemplar: [[0.91100973]\n",
      " [0.91153395]\n",
      " [0.91349381]\n",
      " [0.91425896]\n",
      " [0.91506392]\n",
      " [0.91578692]\n",
      " [0.9157151 ]\n",
      " [0.91644412]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.91728944]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[[0.91100973]\n",
      "  [0.91153395]\n",
      "  [0.91349381]\n",
      "  [0.91425896]\n",
      "  [0.91506392]\n",
      "  [0.91578692]\n",
      "  [0.9157151 ]\n",
      "  [0.91644412]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010424717329442501\n",
      "Predicción post entrenamiento : [[0.91620535]]\n",
      "PERDIDAAAA despues: 0.010204518213868141\n",
      "loss en el callback: 0.05868585407733917, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "ejemplar: [[0.91153395]\n",
      " [0.91349381]\n",
      " [0.91425896]\n",
      " [0.91506392]\n",
      " [0.91578692]\n",
      " [0.9157151 ]\n",
      " [0.91644412]\n",
      " [0.91728944]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.9170387]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[[0.91153395]\n",
      "  [0.91349381]\n",
      "  [0.91425896]\n",
      "  [0.91506392]\n",
      "  [0.91578692]\n",
      "  [0.9157151 ]\n",
      "  [0.91644412]\n",
      "  [0.91728944]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00011665682541206479\n",
      "Predicción post entrenamiento : [[0.9159949]]\n",
      "PERDIDAAAA despues: 9.519870218355209e-05\n",
      "loss en el callback: 0.04976271092891693, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "ejemplar: [[0.91349381]\n",
      " [0.91425896]\n",
      " [0.91506392]\n",
      " [0.91578692]\n",
      " [0.9157151 ]\n",
      " [0.91644412]\n",
      " [0.91728944]\n",
      " [0.91703868]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.91690594]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[[0.91349381]\n",
      "  [0.91425896]\n",
      "  [0.91506392]\n",
      "  [0.91578692]\n",
      "  [0.9157151 ]\n",
      "  [0.91644412]\n",
      "  [0.91728944]\n",
      "  [0.91703868]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018318051006644964\n",
      "Predicción post entrenamiento : [[0.9164162]]\n",
      "PERDIDAAAA despues: 0.0018739638617262244\n",
      "loss en el callback: 0.012051651254296303, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "ejemplar: [[0.91425896]\n",
      " [0.91506392]\n",
      " [0.91578692]\n",
      " [0.9157151 ]\n",
      " [0.91644412]\n",
      " [0.91728944]\n",
      " [0.91703868]\n",
      " [0.91690594]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.9169731]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[[0.91425896]\n",
      "  [0.91506392]\n",
      "  [0.91578692]\n",
      "  [0.9157151 ]\n",
      "  [0.91644412]\n",
      "  [0.91728944]\n",
      "  [0.91703868]\n",
      "  [0.91690594]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002245031064376235\n",
      "Predicción post entrenamiento : [[0.91720015]]\n",
      "PERDIDAAAA despues: 0.0022235680371522903\n",
      "loss en el callback: 0.002996064256876707, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "ejemplar: [[0.91506392]\n",
      " [0.91578692]\n",
      " [0.9157151 ]\n",
      " [0.91644412]\n",
      " [0.91728944]\n",
      " [0.91703868]\n",
      " [0.91690594]\n",
      " [0.91697311]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.9176795]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[[0.91506392]\n",
      "  [0.91578692]\n",
      "  [0.9157151 ]\n",
      "  [0.91644412]\n",
      "  [0.91728944]\n",
      "  [0.91703868]\n",
      "  [0.91690594]\n",
      "  [0.91697311]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008792163571342826\n",
      "Predicción post entrenamiento : [[0.9173365]]\n",
      "PERDIDAAAA despues: 0.000858995015732944\n",
      "loss en el callback: 0.006739798933267593, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "ejemplar: [[0.91578692]\n",
      " [0.9157151 ]\n",
      " [0.91644412]\n",
      " [0.91728944]\n",
      " [0.91703868]\n",
      " [0.91690594]\n",
      " [0.91697311]\n",
      " [0.91767949]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.9177019]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[[0.91578692]\n",
      "  [0.9157151 ]\n",
      "  [0.91644412]\n",
      "  [0.91728944]\n",
      "  [0.91703868]\n",
      "  [0.91690594]\n",
      "  [0.91697311]\n",
      "  [0.91767949]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000626233231741935\n",
      "Predicción post entrenamiento : [[0.91643]]\n",
      "PERDIDAAAA despues: 0.0005641930620186031\n",
      "loss en el callback: 0.07136879861354828, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "ejemplar: [[0.9157151 ]\n",
      " [0.91644412]\n",
      " [0.91728944]\n",
      " [0.91703868]\n",
      " [0.91690594]\n",
      " [0.91697311]\n",
      " [0.91767949]\n",
      " [0.9177019 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.91668]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[[0.9157151 ]\n",
      "  [0.91644412]\n",
      "  [0.91728944]\n",
      "  [0.91703868]\n",
      "  [0.91690594]\n",
      "  [0.91697311]\n",
      "  [0.91767949]\n",
      "  [0.9177019 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017170916544273496\n",
      "Predicción post entrenamiento : [[0.9170933]]\n",
      "PERDIDAAAA despues: 0.0017515148501843214\n",
      "loss en el callback: 0.017550529912114143, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "ejemplar: [[0.91644412]\n",
      " [0.91728944]\n",
      " [0.91703868]\n",
      " [0.91690594]\n",
      " [0.91697311]\n",
      " [0.91767949]\n",
      " [0.9177019 ]\n",
      " [0.91667998]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.91742754]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[[0.91644412]\n",
      "  [0.91728944]\n",
      "  [0.91703868]\n",
      "  [0.91690594]\n",
      "  [0.91697311]\n",
      "  [0.91767949]\n",
      "  [0.9177019 ]\n",
      "  [0.91667998]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004434832837432623\n",
      "Predicción post entrenamiento : [[0.91697305]]\n",
      "PERDIDAAAA despues: 0.004374506883323193\n",
      "loss en el callback: 0.012589968740940094, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "ejemplar: [[0.91728944]\n",
      " [0.91703868]\n",
      " [0.91690594]\n",
      " [0.91697311]\n",
      " [0.91767949]\n",
      " [0.9177019 ]\n",
      " [0.91667998]\n",
      " [0.91742754]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.91715837]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[[0.91728944]\n",
      "  [0.91703868]\n",
      "  [0.91690594]\n",
      "  [0.91697311]\n",
      "  [0.91767949]\n",
      "  [0.9177019 ]\n",
      "  [0.91667998]\n",
      "  [0.91742754]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004659779369831085\n",
      "Predicción post entrenamiento : [[0.91670334]]\n",
      "PERDIDAAAA despues: 0.004597864579409361\n",
      "loss en el callback: 0.011912185698747635, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "ejemplar: [[0.91703868]\n",
      " [0.91690594]\n",
      " [0.91697311]\n",
      " [0.91767949]\n",
      " [0.9177019 ]\n",
      " [0.91667998]\n",
      " [0.91742754]\n",
      " [0.91715837]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.9166769]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[[0.91703868]\n",
      "  [0.91690594]\n",
      "  [0.91697311]\n",
      "  [0.91767949]\n",
      "  [0.9177019 ]\n",
      "  [0.91667998]\n",
      "  [0.91742754]\n",
      "  [0.91715837]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00209221919067204\n",
      "Predicción post entrenamiento : [[0.9167162]]\n",
      "PERDIDAAAA despues: 0.0020886219572275877\n",
      "loss en el callback: 9.54722345340997e-05, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "ejemplar: [[0.91690594]\n",
      " [0.91697311]\n",
      " [0.91767949]\n",
      " [0.9177019 ]\n",
      " [0.91667998]\n",
      " [0.91742754]\n",
      " [0.91715837]\n",
      " [0.91667688]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.91676146]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[[0.91690594]\n",
      "  [0.91697311]\n",
      "  [0.91767949]\n",
      "  [0.9177019 ]\n",
      "  [0.91667998]\n",
      "  [0.91742754]\n",
      "  [0.91715837]\n",
      "  [0.91667688]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00260921404697001\n",
      "Predicción post entrenamiento : [[0.91604495]]\n",
      "PERDIDAAAA despues: 0.0026829263661056757\n",
      "loss en el callback: 0.025131477043032646, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "ejemplar: [[0.91697311]\n",
      " [0.91767949]\n",
      " [0.9177019 ]\n",
      " [0.91667998]\n",
      " [0.91742754]\n",
      " [0.91715837]\n",
      " [0.91667688]\n",
      " [0.91676146]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.91613007]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[[0.91697311]\n",
      "  [0.91767949]\n",
      "  [0.9177019 ]\n",
      "  [0.91667998]\n",
      "  [0.91742754]\n",
      "  [0.91715837]\n",
      "  [0.91667688]\n",
      "  [0.91676146]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006046981434337795\n",
      "Predicción post entrenamiento : [[0.9163472]]\n",
      "PERDIDAAAA despues: 0.0005940661067143083\n",
      "loss en el callback: 0.0039595081470906734, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "ejemplar: [[0.91767949]\n",
      " [0.9177019 ]\n",
      " [0.91667998]\n",
      " [0.91742754]\n",
      " [0.91715837]\n",
      " [0.91667688]\n",
      " [0.91676146]\n",
      " [0.91613007]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.9164075]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[[0.91767949]\n",
      "  [0.9177019 ]\n",
      "  [0.91667998]\n",
      "  [0.91742754]\n",
      "  [0.91715837]\n",
      "  [0.91667688]\n",
      "  [0.91676146]\n",
      "  [0.91613007]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003145385766401887\n",
      "Predicción post entrenamiento : [[0.91605294]]\n",
      "PERDIDAAAA despues: 0.0031852847896516323\n",
      "loss en el callback: 0.0069885291159152985, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "ejemplar: [[0.9177019 ]\n",
      " [0.91667998]\n",
      " [0.91742754]\n",
      " [0.91715837]\n",
      " [0.91667688]\n",
      " [0.91676146]\n",
      " [0.91613007]\n",
      " [0.91640753]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.9158911]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[[0.9177019 ]\n",
      "  [0.91667998]\n",
      "  [0.91742754]\n",
      "  [0.91715837]\n",
      "  [0.91667688]\n",
      "  [0.91676146]\n",
      "  [0.91613007]\n",
      "  [0.91640753]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006562511436641216\n",
      "Predicción post entrenamiento : [[0.9160571]]\n",
      "PERDIDAAAA despues: 0.006535643711686134\n",
      "loss en el callback: 0.0017450002487748861, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "ejemplar: [[0.91667998]\n",
      " [0.91742754]\n",
      " [0.91715837]\n",
      " [0.91667688]\n",
      " [0.91676146]\n",
      " [0.91613007]\n",
      " [0.91640753]\n",
      " [0.91589111]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.9158382]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[[0.91667998]\n",
      "  [0.91742754]\n",
      "  [0.91715837]\n",
      "  [0.91667688]\n",
      "  [0.91676146]\n",
      "  [0.91613007]\n",
      "  [0.91640753]\n",
      "  [0.91589111]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012491649249568582\n",
      "Predicción post entrenamiento : [[0.9158439]]\n",
      "PERDIDAAAA despues: 0.0012487604981288314\n",
      "loss en el callback: 2.2491374238597928e-06, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "ejemplar: [[0.91742754]\n",
      " [0.91715837]\n",
      " [0.91667688]\n",
      " [0.91676146]\n",
      " [0.91613007]\n",
      " [0.91640753]\n",
      " [0.91589111]\n",
      " [0.91583818]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.9158603]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[[0.91742754]\n",
      "  [0.91715837]\n",
      "  [0.91667688]\n",
      "  [0.91676146]\n",
      "  [0.91613007]\n",
      "  [0.91640753]\n",
      "  [0.91589111]\n",
      "  [0.91583818]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00040334646473638713\n",
      "Predicción post entrenamiento : [[0.9158608]]\n",
      "PERDIDAAAA despues: 0.00040336561505682766\n",
      "loss en el callback: 2.4480417692984702e-08, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "ejemplar: [[0.91715837]\n",
      " [0.91667688]\n",
      " [0.91676146]\n",
      " [0.91613007]\n",
      " [0.91640753]\n",
      " [0.91589111]\n",
      " [0.91583818]\n",
      " [0.9158603 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.9156301]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[[0.91715837]\n",
      "  [0.91667688]\n",
      "  [0.91676146]\n",
      "  [0.91613007]\n",
      "  [0.91640753]\n",
      "  [0.91589111]\n",
      "  [0.91583818]\n",
      "  [0.9158603 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011688745580613613\n",
      "Predicción post entrenamiento : [[0.91583025]]\n",
      "PERDIDAAAA despues: 0.001182600506581366\n",
      "loss en el callback: 0.0033903769217431545, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "ejemplar: [[0.91667688]\n",
      " [0.91676146]\n",
      " [0.91613007]\n",
      " [0.91640753]\n",
      " [0.91589111]\n",
      " [0.91583818]\n",
      " [0.9158603 ]\n",
      " [0.9156301 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.9156141]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[[0.91667688]\n",
      "  [0.91676146]\n",
      "  [0.91613007]\n",
      "  [0.91640753]\n",
      "  [0.91589111]\n",
      "  [0.91583818]\n",
      "  [0.9158603 ]\n",
      "  [0.9156301 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.167650563933421e-06\n",
      "Predicción post entrenamiento : [[0.9159582]]\n",
      "PERDIDAAAA despues: 1.2728278306894936e-06\n",
      "loss en el callback: 0.010427480563521385, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "ejemplar: [[0.91676146]\n",
      " [0.91613007]\n",
      " [0.91640753]\n",
      " [0.91589111]\n",
      " [0.91583818]\n",
      " [0.9158603 ]\n",
      " [0.9156301 ]\n",
      " [0.91561413]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.9158244]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[[0.91676146]\n",
      "  [0.91613007]\n",
      "  [0.91640753]\n",
      "  [0.91589111]\n",
      "  [0.91583818]\n",
      "  [0.9158603 ]\n",
      "  [0.9156301 ]\n",
      "  [0.91561413]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.57937865878921e-05\n",
      "Predicción post entrenamiento : [[0.9154685]]\n",
      "PERDIDAAAA despues: 1.8749238734017126e-05\n",
      "loss en el callback: 0.008544152602553368, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "ejemplar: [[0.91613007]\n",
      " [0.91640753]\n",
      " [0.91589111]\n",
      " [0.91583818]\n",
      " [0.9158603 ]\n",
      " [0.9156301 ]\n",
      " [0.91561413]\n",
      " [0.91582441]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.91527003]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[[0.91613007]\n",
      "  [0.91640753]\n",
      "  [0.91589111]\n",
      "  [0.91583818]\n",
      "  [0.9158603 ]\n",
      "  [0.9156301 ]\n",
      "  [0.91561413]\n",
      "  [0.91582441]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002150433836504817\n",
      "Predicción post entrenamiento : [[0.91598725]]\n",
      "PERDIDAAAA despues: 0.002084429142996669\n",
      "loss en el callback: 0.05717244744300842, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "ejemplar: [[0.91640753]\n",
      " [0.91589111]\n",
      " [0.91583818]\n",
      " [0.9158603 ]\n",
      " [0.9156301 ]\n",
      " [0.91561413]\n",
      " [0.91582441]\n",
      " [0.91527003]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.91592586]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[[0.91640753]\n",
      "  [0.91589111]\n",
      "  [0.91583818]\n",
      "  [0.9158603 ]\n",
      "  [0.9156301 ]\n",
      "  [0.91561413]\n",
      "  [0.91582441]\n",
      "  [0.91527003]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002735655289143324\n",
      "Predicción post entrenamiento : [[0.91530806]]\n",
      "PERDIDAAAA despues: 0.0028006634674966335\n",
      "loss en el callback: 0.021919475868344307, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "ejemplar: [[0.91589111]\n",
      " [0.91583818]\n",
      " [0.9158603 ]\n",
      " [0.9156301 ]\n",
      " [0.91561413]\n",
      " [0.91582441]\n",
      " [0.91527003]\n",
      " [0.91592586]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.9151444]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[[0.91589111]\n",
      "  [0.91583818]\n",
      "  [0.9158603 ]\n",
      "  [0.9156301 ]\n",
      "  [0.91561413]\n",
      "  [0.91582441]\n",
      "  [0.91527003]\n",
      "  [0.91592586]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018167999805882573\n",
      "Predicción post entrenamiento : [[0.9155386]]\n",
      "PERDIDAAAA despues: 0.0017833486199378967\n",
      "loss en el callback: 0.014057480730116367, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "ejemplar: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.21943054]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.030041338875889778\n",
      "Predicción post entrenamiento : [[0.19438599]]\n",
      "PERDIDAAAA despues: 0.021986907348036766\n",
      "loss en el callback: 0.027379320934414864, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "ejemplar: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21943054]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.17848788]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21943054]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005515247583389282\n",
      "Predicción post entrenamiento : [[0.16662835]]\n",
      "PERDIDAAAA despues: 0.0038944061379879713\n",
      "loss en el callback: 0.005656909197568893, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "ejemplar: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21943054]\n",
      " [0.17848788]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.17063923]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21943054]\n",
      "  [0.17848788]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002701233315747231\n",
      "Predicción post entrenamiento : [[0.16858374]]\n",
      "PERDIDAAAA despues: 0.0002067824825644493\n",
      "loss en el callback: 0.00038516902714036405, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "ejemplar: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21943054]\n",
      " [0.17848788]\n",
      " [0.17063923]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.17991406]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21943054]\n",
      "  [0.17848788]\n",
      "  [0.17063923]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005837285425513983\n",
      "Predicción post entrenamiento : [[0.17486297]]\n",
      "PERDIDAAAA despues: 0.00036516852560453117\n",
      "loss en el callback: 0.003242678241804242, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "ejemplar: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21943054]\n",
      " [0.17848788]\n",
      " [0.17063923]\n",
      " [0.17991406]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.18709546]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21943054]\n",
      "  [0.17848788]\n",
      "  [0.17063923]\n",
      "  [0.17991406]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003789968090131879\n",
      "Predicción post entrenamiento : [[0.18169609]]\n",
      "PERDIDAAAA despues: 0.003154320875182748\n",
      "loss en el callback: 0.006464316509664059, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "ejemplar: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.21943054]\n",
      " [0.17848788]\n",
      " [0.17063923]\n",
      " [0.17991406]\n",
      " [0.18709546]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.1908522]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21943054]\n",
      "  [0.17848788]\n",
      "  [0.17063923]\n",
      "  [0.17991406]\n",
      "  [0.18709546]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0020405303221195936\n",
      "Predicción post entrenamiento : [[0.18850218]]\n",
      "PERDIDAAAA despues: 0.0018337417859584093\n",
      "loss en el callback: 0.0019934538286179304, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "ejemplar: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.21943054]\n",
      " [0.17848788]\n",
      " [0.17063923]\n",
      " [0.17991406]\n",
      " [0.18709546]\n",
      " [0.1908522 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.2083929]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21943054]\n",
      "  [0.17848788]\n",
      "  [0.17063923]\n",
      "  [0.17991406]\n",
      "  [0.18709546]\n",
      "  [0.1908522 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003836321644484997\n",
      "Predicción post entrenamiento : [[0.20521425]]\n",
      "PERDIDAAAA despues: 0.0034526661038398743\n",
      "loss en el callback: 0.004421999212354422, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "ejemplar: [[0.04223169]\n",
      " [0.21943054]\n",
      " [0.17848788]\n",
      " [0.17063923]\n",
      " [0.17991406]\n",
      " [0.18709546]\n",
      " [0.1908522 ]\n",
      " [0.2083929 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.22906205]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[[0.04223169]\n",
      "  [0.21943054]\n",
      "  [0.17848788]\n",
      "  [0.17063923]\n",
      "  [0.17991406]\n",
      "  [0.18709546]\n",
      "  [0.1908522 ]\n",
      "  [0.2083929 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001089925179257989\n",
      "Predicción post entrenamiento : [[0.22977331]]\n",
      "PERDIDAAAA despues: 0.0011373942252248526\n",
      "loss en el callback: 0.00046376881073229015, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "ejemplar: [[0.21943054]\n",
      " [0.17848788]\n",
      " [0.17063923]\n",
      " [0.17991406]\n",
      " [0.18709546]\n",
      " [0.1908522 ]\n",
      " [0.2083929 ]\n",
      " [0.22906205]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.25786212]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[[0.21943054]\n",
      "  [0.17848788]\n",
      "  [0.17063923]\n",
      "  [0.17991406]\n",
      "  [0.18709546]\n",
      "  [0.1908522 ]\n",
      "  [0.2083929 ]\n",
      "  [0.22906205]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007470012060366571\n",
      "Predicción post entrenamiento : [[0.25562248]]\n",
      "PERDIDAAAA despues: 0.0006295922794379294\n",
      "loss en el callback: 0.0027825175784528255, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "ejemplar: [[0.17848788]\n",
      " [0.17063923]\n",
      " [0.17991406]\n",
      " [0.18709546]\n",
      " [0.1908522 ]\n",
      " [0.2083929 ]\n",
      " [0.22906205]\n",
      " [0.25786212]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.2496311]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[[0.17848788]\n",
      "  [0.17063923]\n",
      "  [0.17991406]\n",
      "  [0.18709546]\n",
      "  [0.1908522 ]\n",
      "  [0.2083929 ]\n",
      "  [0.22906205]\n",
      "  [0.25786212]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016961850924417377\n",
      "Predicción post entrenamiento : [[0.24756268]]\n",
      "PERDIDAAAA despues: 0.0015300879022106528\n",
      "loss en el callback: 0.0033473281655460596, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "ejemplar: [[0.17063923]\n",
      " [0.17991406]\n",
      " [0.18709546]\n",
      " [0.1908522 ]\n",
      " [0.2083929 ]\n",
      " [0.22906205]\n",
      " [0.25786212]\n",
      " [0.24963111]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.25096384]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[[0.17063923]\n",
      "  [0.17991406]\n",
      "  [0.18709546]\n",
      "  [0.1908522 ]\n",
      "  [0.2083929 ]\n",
      "  [0.22906205]\n",
      "  [0.25786212]\n",
      "  [0.24963111]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015233781887218356\n",
      "Predicción post entrenamiento : [[0.24823056]]\n",
      "PERDIDAAAA despues: 0.0013174868654459715\n",
      "loss en el callback: 0.006064887624233961, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "ejemplar: [[0.17991406]\n",
      " [0.18709546]\n",
      " [0.1908522 ]\n",
      " [0.2083929 ]\n",
      " [0.22906205]\n",
      " [0.25786212]\n",
      " [0.24963111]\n",
      " [0.25096384]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.2553521]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[[0.17991406]\n",
      "  [0.18709546]\n",
      "  [0.1908522 ]\n",
      "  [0.2083929 ]\n",
      "  [0.22906205]\n",
      "  [0.25786212]\n",
      "  [0.24963111]\n",
      "  [0.25096384]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002310542855411768\n",
      "Predicción post entrenamiento : [[0.25303292]]\n",
      "PERDIDAAAA despues: 0.0020929635502398014\n",
      "loss en el callback: 0.005677791312336922, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "ejemplar: [[0.18709546]\n",
      " [0.1908522 ]\n",
      " [0.2083929 ]\n",
      " [0.22906205]\n",
      " [0.25786212]\n",
      " [0.24963111]\n",
      " [0.25096384]\n",
      " [0.25535211]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.26062134]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[[0.18709546]\n",
      "  [0.1908522 ]\n",
      "  [0.2083929 ]\n",
      "  [0.22906205]\n",
      "  [0.25786212]\n",
      "  [0.24963111]\n",
      "  [0.25096384]\n",
      "  [0.25535211]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004579616244882345\n",
      "Predicción post entrenamiento : [[0.25922498]]\n",
      "PERDIDAAAA despues: 0.00439257500693202\n",
      "loss en el callback: 0.0029242057353258133, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "ejemplar: [[0.1908522 ]\n",
      " [0.2083929 ]\n",
      " [0.22906205]\n",
      " [0.25786212]\n",
      " [0.24963111]\n",
      " [0.25096384]\n",
      " [0.25535211]\n",
      " [0.26062134]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.26769015]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[[0.1908522 ]\n",
      "  [0.2083929 ]\n",
      "  [0.22906205]\n",
      "  [0.25786212]\n",
      "  [0.24963111]\n",
      "  [0.25096384]\n",
      "  [0.25535211]\n",
      "  [0.26062134]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005022161640226841\n",
      "Predicción post entrenamiento : [[0.26564032]]\n",
      "PERDIDAAAA despues: 0.004735831171274185\n",
      "loss en el callback: 0.006236423272639513, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "ejemplar: [[0.2083929 ]\n",
      " [0.22906205]\n",
      " [0.25786212]\n",
      " [0.24963111]\n",
      " [0.25096384]\n",
      " [0.25535211]\n",
      " [0.26062134]\n",
      " [0.26769015]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.27569178]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[[0.2083929 ]\n",
      "  [0.22906205]\n",
      "  [0.25786212]\n",
      "  [0.24963111]\n",
      "  [0.25096384]\n",
      "  [0.25535211]\n",
      "  [0.26062134]\n",
      "  [0.26769015]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0037741034757345915\n",
      "Predicción post entrenamiento : [[0.2745928]]\n",
      "PERDIDAAAA despues: 0.0036402810364961624\n",
      "loss en el callback: 0.0023774385917931795, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "ejemplar: [[0.22906205]\n",
      " [0.25786212]\n",
      " [0.24963111]\n",
      " [0.25096384]\n",
      " [0.25535211]\n",
      " [0.26062134]\n",
      " [0.26769015]\n",
      " [0.27569178]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.283074]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[[0.22906205]\n",
      "  [0.25786212]\n",
      "  [0.24963111]\n",
      "  [0.25096384]\n",
      "  [0.25535211]\n",
      "  [0.26062134]\n",
      "  [0.26769015]\n",
      "  [0.27569178]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0103528443723917\n",
      "Predicción post entrenamiento : [[0.28191411]]\n",
      "PERDIDAAAA despues: 0.010118157602846622\n",
      "loss en el callback: 0.0036911845672875643, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "ejemplar: [[0.25786212]\n",
      " [0.24963111]\n",
      " [0.25096384]\n",
      " [0.25535211]\n",
      " [0.26062134]\n",
      " [0.26769015]\n",
      " [0.27569178]\n",
      " [0.28307399]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.28762]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[[0.25786212]\n",
      "  [0.24963111]\n",
      "  [0.25096384]\n",
      "  [0.25535211]\n",
      "  [0.26062134]\n",
      "  [0.26769015]\n",
      "  [0.27569178]\n",
      "  [0.28307399]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012654918245971203\n",
      "Predicción post entrenamiento : [[0.28581285]]\n",
      "PERDIDAAAA despues: 0.012251595966517925\n",
      "loss en el callback: 0.008050664328038692, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "ejemplar: [[0.24963111]\n",
      " [0.25096384]\n",
      " [0.25535211]\n",
      " [0.26062134]\n",
      " [0.26769015]\n",
      " [0.27569178]\n",
      " [0.28307399]\n",
      " [0.28762001]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.28634703]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[[0.24963111]\n",
      "  [0.25096384]\n",
      "  [0.25535211]\n",
      "  [0.26062134]\n",
      "  [0.26769015]\n",
      "  [0.27569178]\n",
      "  [0.28307399]\n",
      "  [0.28762001]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01913861371576786\n",
      "Predicción post entrenamiento : [[0.2832424]]\n",
      "PERDIDAAAA despues: 0.018289249390363693\n",
      "loss en el callback: 0.024315275251865387, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "ejemplar: [[0.25096384]\n",
      " [0.25535211]\n",
      " [0.26062134]\n",
      " [0.26769015]\n",
      " [0.27569178]\n",
      " [0.28307399]\n",
      " [0.28762001]\n",
      " [0.28634703]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.2864256]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[[0.25096384]\n",
      "  [0.25535211]\n",
      "  [0.26062134]\n",
      "  [0.26769015]\n",
      "  [0.27569178]\n",
      "  [0.28307399]\n",
      "  [0.28762001]\n",
      "  [0.28634703]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016274726018309593\n",
      "Predicción post entrenamiento : [[0.28417554]]\n",
      "PERDIDAAAA despues: 0.01570570096373558\n",
      "loss en el callback: 0.014716602861881256, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "ejemplar: [[0.25535211]\n",
      " [0.26062134]\n",
      " [0.26769015]\n",
      " [0.27569178]\n",
      " [0.28307399]\n",
      " [0.28762001]\n",
      " [0.28634703]\n",
      " [0.28642559]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.28820664]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[[0.25535211]\n",
      "  [0.26062134]\n",
      "  [0.26769015]\n",
      "  [0.27569178]\n",
      "  [0.28307399]\n",
      "  [0.28762001]\n",
      "  [0.28634703]\n",
      "  [0.28642559]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00922235008329153\n",
      "Predicción post entrenamiento : [[0.28677663]]\n",
      "PERDIDAAAA despues: 0.008949738927185535\n",
      "loss en el callback: 0.007107401266694069, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "ejemplar: [[0.26062134]\n",
      " [0.26769015]\n",
      " [0.27569178]\n",
      " [0.28307399]\n",
      " [0.28762001]\n",
      " [0.28634703]\n",
      " [0.28642559]\n",
      " [0.28820664]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.2909943]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[[0.26062134]\n",
      "  [0.26769015]\n",
      "  [0.27569178]\n",
      "  [0.28307399]\n",
      "  [0.28762001]\n",
      "  [0.28634703]\n",
      "  [0.28642559]\n",
      "  [0.28820664]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011029168963432312\n",
      "Predicción post entrenamiento : [[0.2888186]]\n",
      "PERDIDAAAA despues: 0.010576922446489334\n",
      "loss en el callback: 0.014772644266486168, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "ejemplar: [[0.26769015]\n",
      " [0.27569178]\n",
      " [0.28307399]\n",
      " [0.28762001]\n",
      " [0.28634703]\n",
      " [0.28642559]\n",
      " [0.28820664]\n",
      " [0.29099429]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.29292426]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[[0.26769015]\n",
      "  [0.27569178]\n",
      "  [0.28307399]\n",
      "  [0.28762001]\n",
      "  [0.28634703]\n",
      "  [0.28642559]\n",
      "  [0.28820664]\n",
      "  [0.29099429]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006746210856363177\n",
      "Predicción post entrenamiento : [[0.2927447]]\n",
      "PERDIDAAAA despues: 0.0006653257878497243\n",
      "loss en el callback: 0.00011421310773584992, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "ejemplar: [[0.27569178]\n",
      " [0.28307399]\n",
      " [0.28762001]\n",
      " [0.28634703]\n",
      " [0.28642559]\n",
      " [0.28820664]\n",
      " [0.29099429]\n",
      " [0.29292426]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.29618105]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[[0.27569178]\n",
      "  [0.28307399]\n",
      "  [0.28762001]\n",
      "  [0.28634703]\n",
      "  [0.28642559]\n",
      "  [0.28820664]\n",
      "  [0.29099429]\n",
      "  [0.29292426]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.3386608770815656e-05\n",
      "Predicción post entrenamiento : [[0.29544544]]\n",
      "PERDIDAAAA despues: 8.544869160687085e-06\n",
      "loss en el callback: 0.001851290580816567, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "ejemplar: [[0.28307399]\n",
      " [0.28762001]\n",
      " [0.28634703]\n",
      " [0.28642559]\n",
      " [0.28820664]\n",
      " [0.29099429]\n",
      " [0.29292426]\n",
      " [0.29618105]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.29779503]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[[0.28307399]\n",
      "  [0.28762001]\n",
      "  [0.28634703]\n",
      "  [0.28642559]\n",
      "  [0.28820664]\n",
      "  [0.29099429]\n",
      "  [0.29292426]\n",
      "  [0.29618105]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003964594507124275\n",
      "Predicción post entrenamiento : [[0.29804415]]\n",
      "PERDIDAAAA despues: 0.00038660099380649626\n",
      "loss en el callback: 0.0002682598715182394, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "ejemplar: [[0.28762001]\n",
      " [0.28634703]\n",
      " [0.28642559]\n",
      " [0.28820664]\n",
      " [0.29099429]\n",
      " [0.29292426]\n",
      " [0.29618105]\n",
      " [0.29779503]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.2992415]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[[0.28762001]\n",
      "  [0.28634703]\n",
      "  [0.28642559]\n",
      "  [0.28820664]\n",
      "  [0.29099429]\n",
      "  [0.29292426]\n",
      "  [0.29618105]\n",
      "  [0.29779503]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00018031125364359468\n",
      "Predicción post entrenamiento : [[0.2992723]]\n",
      "PERDIDAAAA despues: 0.00017948541790246964\n",
      "loss en el callback: 4.607259143085685e-06, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "ejemplar: [[0.28634703]\n",
      " [0.28642559]\n",
      " [0.28820664]\n",
      " [0.29099429]\n",
      " [0.29292426]\n",
      " [0.29618105]\n",
      " [0.29779503]\n",
      " [0.29924151]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.2998104]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[[0.28634703]\n",
      "  [0.28642559]\n",
      "  [0.28820664]\n",
      "  [0.29099429]\n",
      "  [0.29292426]\n",
      "  [0.29618105]\n",
      "  [0.29779503]\n",
      "  [0.29924151]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00011610383080551401\n",
      "Predicción post entrenamiento : [[0.30005658]]\n",
      "PERDIDAAAA despues: 0.00012146940571255982\n",
      "loss en el callback: 0.00036573311081156135, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "ejemplar: [[0.28642559]\n",
      " [0.28820664]\n",
      " [0.29099429]\n",
      " [0.29292426]\n",
      " [0.29618105]\n",
      " [0.29779503]\n",
      " [0.29924151]\n",
      " [0.29981041]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.3012197]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[[0.28642559]\n",
      "  [0.28820664]\n",
      "  [0.29099429]\n",
      "  [0.29292426]\n",
      "  [0.29618105]\n",
      "  [0.29779503]\n",
      "  [0.29924151]\n",
      "  [0.29981041]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003379564732313156\n",
      "Predicción post entrenamiento : [[0.30063847]]\n",
      "PERDIDAAAA despues: 0.00031692394986748695\n",
      "loss en el callback: 0.0017417400376871228, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "ejemplar: [[0.28820664]\n",
      " [0.29099429]\n",
      " [0.29292426]\n",
      " [0.29618105]\n",
      " [0.29779503]\n",
      " [0.29924151]\n",
      " [0.29981041]\n",
      " [0.3012197 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.30220762]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[[0.28820664]\n",
      "  [0.29099429]\n",
      "  [0.29292426]\n",
      "  [0.29618105]\n",
      "  [0.29779503]\n",
      "  [0.29924151]\n",
      "  [0.29981041]\n",
      "  [0.3012197 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.351126441790257e-06\n",
      "Predicción post entrenamiento : [[0.30195725]]\n",
      "PERDIDAAAA despues: 6.056160600564908e-06\n",
      "loss en el callback: 0.0003482537576928735, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "ejemplar: [[0.29099429]\n",
      " [0.29292426]\n",
      " [0.29618105]\n",
      " [0.29779503]\n",
      " [0.29924151]\n",
      " [0.29981041]\n",
      " [0.3012197 ]\n",
      " [0.30220762]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.3035731]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[[0.29099429]\n",
      "  [0.29292426]\n",
      "  [0.29618105]\n",
      "  [0.29779503]\n",
      "  [0.29924151]\n",
      "  [0.29981041]\n",
      "  [0.3012197 ]\n",
      "  [0.30220762]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007679014233872294\n",
      "Predicción post entrenamiento : [[0.30352682]]\n",
      "PERDIDAAAA despues: 0.0007653384236618876\n",
      "loss en el callback: 1.464095385017572e-05, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "ejemplar: [[0.29292426]\n",
      " [0.29618105]\n",
      " [0.29779503]\n",
      " [0.29924151]\n",
      " [0.29981041]\n",
      " [0.3012197 ]\n",
      " [0.30220762]\n",
      " [0.3035731 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.30493066]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[[0.29292426]\n",
      "  [0.29618105]\n",
      "  [0.29779503]\n",
      "  [0.29924151]\n",
      "  [0.29981041]\n",
      "  [0.3012197 ]\n",
      "  [0.30220762]\n",
      "  [0.3035731 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009139096946455538\n",
      "Predicción post entrenamiento : [[0.30461723]]\n",
      "PERDIDAAAA despues: 0.0008950572810135782\n",
      "loss en el callback: 0.0006470847874879837, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "ejemplar: [[0.29618105]\n",
      " [0.29779503]\n",
      " [0.29924151]\n",
      " [0.29981041]\n",
      " [0.3012197 ]\n",
      " [0.30220762]\n",
      " [0.3035731 ]\n",
      " [0.30493066]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.30595246]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[[0.29618105]\n",
      "  [0.29779503]\n",
      "  [0.29924151]\n",
      "  [0.29981041]\n",
      "  [0.3012197 ]\n",
      "  [0.30220762]\n",
      "  [0.3035731 ]\n",
      "  [0.30493066]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009288994478993118\n",
      "Predicción post entrenamiento : [[0.305264]]\n",
      "PERDIDAAAA despues: 0.0008874076302163303\n",
      "loss en el callback: 0.0033297999761998653, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "ejemplar: [[0.29779503]\n",
      " [0.29924151]\n",
      " [0.29981041]\n",
      " [0.3012197 ]\n",
      " [0.30220762]\n",
      " [0.3035731 ]\n",
      " [0.30493066]\n",
      " [0.30595246]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.30618915]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[[0.29779503]\n",
      "  [0.29924151]\n",
      "  [0.29981041]\n",
      "  [0.3012197 ]\n",
      "  [0.30220762]\n",
      "  [0.3035731 ]\n",
      "  [0.30493066]\n",
      "  [0.30595246]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008159484132193029\n",
      "Predicción post entrenamiento : [[0.3066331]]\n",
      "PERDIDAAAA despues: 0.0007907819817773998\n",
      "loss en el callback: 0.0016280014533549547, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "ejemplar: [[0.29924151]\n",
      " [0.29981041]\n",
      " [0.3012197 ]\n",
      " [0.30220762]\n",
      " [0.3035731 ]\n",
      " [0.30493066]\n",
      " [0.30595246]\n",
      " [0.30618915]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.30746216]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[[0.29924151]\n",
      "  [0.29981041]\n",
      "  [0.3012197 ]\n",
      "  [0.30220762]\n",
      "  [0.3035731 ]\n",
      "  [0.30493066]\n",
      "  [0.30595246]\n",
      "  [0.30618915]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0023245830088853836\n",
      "Predicción post entrenamiento : [[0.30754995]]\n",
      "PERDIDAAAA despues: 0.002316124504432082\n",
      "loss en el callback: 4.9429843784309924e-05, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "ejemplar: [[0.29981041]\n",
      " [0.3012197 ]\n",
      " [0.30220762]\n",
      " [0.3035731 ]\n",
      " [0.30493066]\n",
      " [0.30595246]\n",
      " [0.30618915]\n",
      " [0.30746216]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.30830264]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[[0.29981041]\n",
      "  [0.3012197 ]\n",
      "  [0.30220762]\n",
      "  [0.3035731 ]\n",
      "  [0.30493066]\n",
      "  [0.30595246]\n",
      "  [0.30618915]\n",
      "  [0.30746216]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008059103274717927\n",
      "Predicción post entrenamiento : [[0.30848694]]\n",
      "PERDIDAAAA despues: 0.000795480387751013\n",
      "loss en el callback: 0.00028570377617143095, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "ejemplar: [[0.3012197 ]\n",
      " [0.30220762]\n",
      " [0.3035731 ]\n",
      " [0.30493066]\n",
      " [0.30595246]\n",
      " [0.30618915]\n",
      " [0.30746216]\n",
      " [0.30830264]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.30935383]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[[0.3012197 ]\n",
      "  [0.30220762]\n",
      "  [0.3035731 ]\n",
      "  [0.30493066]\n",
      "  [0.30595246]\n",
      "  [0.30618915]\n",
      "  [0.30746216]\n",
      "  [0.30830264]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005874715279787779\n",
      "Predicción post entrenamiento : [[0.30951276]]\n",
      "PERDIDAAAA despues: 0.000579792249482125\n",
      "loss en el callback: 0.00021155597642064095, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "ejemplar: [[0.30220762]\n",
      " [0.3035731 ]\n",
      " [0.30493066]\n",
      " [0.30595246]\n",
      " [0.30618915]\n",
      " [0.30746216]\n",
      " [0.30830264]\n",
      " [0.30935383]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.3103065]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[[0.30220762]\n",
      "  [0.3035731 ]\n",
      "  [0.30493066]\n",
      "  [0.30595246]\n",
      "  [0.30618915]\n",
      "  [0.30746216]\n",
      "  [0.30830264]\n",
      "  [0.30935383]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005539543926715851\n",
      "Predicción post entrenamiento : [[0.31142348]]\n",
      "PERDIDAAAA despues: 0.005374520551413298\n",
      "loss en el callback: 0.016553638502955437, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "ejemplar: [[0.3035731 ]\n",
      " [0.30493066]\n",
      " [0.30595246]\n",
      " [0.30618915]\n",
      " [0.30746216]\n",
      " [0.30830264]\n",
      " [0.30935383]\n",
      " [0.31030649]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.31222677]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[[0.3035731 ]\n",
      "  [0.30493066]\n",
      "  [0.30595246]\n",
      "  [0.30618915]\n",
      "  [0.30746216]\n",
      "  [0.30830264]\n",
      "  [0.30935383]\n",
      "  [0.31030649]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06701352447271347\n",
      "Predicción post entrenamiento : [[0.31480956]]\n",
      "PERDIDAAAA despues: 0.06568298488855362\n",
      "loss en el callback: 0.051754456013441086, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "ejemplar: [[0.30493066]\n",
      " [0.30595246]\n",
      " [0.30618915]\n",
      " [0.30746216]\n",
      " [0.30830264]\n",
      " [0.30935383]\n",
      " [0.31030649]\n",
      " [0.31222677]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.3155354]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[[0.30493066]\n",
      "  [0.30595246]\n",
      "  [0.30618915]\n",
      "  [0.30746216]\n",
      "  [0.30830264]\n",
      "  [0.30935383]\n",
      "  [0.31030649]\n",
      "  [0.31222677]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07881782203912735\n",
      "Predicción post entrenamiento : [[0.31845182]]\n",
      "PERDIDAAAA despues: 0.07718878239393234\n",
      "loss en el callback: 0.09720047563314438, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "ejemplar: [[0.30595246]\n",
      " [0.30618915]\n",
      " [0.30746216]\n",
      " [0.30830264]\n",
      " [0.30935383]\n",
      " [0.31030649]\n",
      " [0.31222677]\n",
      " [0.3155354 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.3191072]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[[0.30595246]\n",
      "  [0.30618915]\n",
      "  [0.30746216]\n",
      "  [0.30830264]\n",
      "  [0.30935383]\n",
      "  [0.31030649]\n",
      "  [0.31222677]\n",
      "  [0.3155354 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0652681216597557\n",
      "Predicción post entrenamiento : [[0.32169253]]\n",
      "PERDIDAAAA despues: 0.06395383179187775\n",
      "loss en el callback: 0.068108469247818, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "ejemplar: [[0.30618915]\n",
      " [0.30746216]\n",
      " [0.30830264]\n",
      " [0.30935383]\n",
      " [0.31030649]\n",
      " [0.31222677]\n",
      " [0.3155354 ]\n",
      " [0.3191072 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.3223833]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[[0.30618915]\n",
      "  [0.30746216]\n",
      "  [0.30830264]\n",
      "  [0.30935383]\n",
      "  [0.31030649]\n",
      "  [0.31222677]\n",
      "  [0.3155354 ]\n",
      "  [0.3191072 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08063941448926926\n",
      "Predicción post entrenamiento : [[0.3250234]]\n",
      "PERDIDAAAA despues: 0.07914696633815765\n",
      "loss en el callback: 0.07806538790464401, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "ejemplar: [[0.30746216]\n",
      " [0.30830264]\n",
      " [0.30935383]\n",
      " [0.31030649]\n",
      " [0.31222677]\n",
      " [0.3155354 ]\n",
      " [0.3191072 ]\n",
      " [0.32238331]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.32599187]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[[0.30746216]\n",
      "  [0.30830264]\n",
      "  [0.30935383]\n",
      "  [0.31030649]\n",
      "  [0.31222677]\n",
      "  [0.3155354 ]\n",
      "  [0.3191072 ]\n",
      "  [0.32238331]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06690771877765656\n",
      "Predicción post entrenamiento : [[0.32807344]]\n",
      "PERDIDAAAA despues: 0.06583519279956818\n",
      "loss en el callback: 0.037285346537828445, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "ejemplar: [[0.30830264]\n",
      " [0.30935383]\n",
      " [0.31030649]\n",
      " [0.31222677]\n",
      " [0.3155354 ]\n",
      " [0.3191072 ]\n",
      " [0.32238331]\n",
      " [0.32599187]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.32917044]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[[0.30830264]\n",
      "  [0.30935383]\n",
      "  [0.31030649]\n",
      "  [0.31222677]\n",
      "  [0.3155354 ]\n",
      "  [0.3191072 ]\n",
      "  [0.32238331]\n",
      "  [0.32599187]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05740880221128464\n",
      "Predicción post entrenamiento : [[0.3313056]]\n",
      "PERDIDAAAA despues: 0.0563901886343956\n",
      "loss en el callback: 0.05437108501791954, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "ejemplar: [[0.30935383]\n",
      " [0.31030649]\n",
      " [0.31222677]\n",
      " [0.3155354 ]\n",
      " [0.3191072 ]\n",
      " [0.32238331]\n",
      " [0.32599187]\n",
      " [0.32917044]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.33270863]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[[0.30935383]\n",
      "  [0.31030649]\n",
      "  [0.31222677]\n",
      "  [0.3155354 ]\n",
      "  [0.3191072 ]\n",
      "  [0.32238331]\n",
      "  [0.32599187]\n",
      "  [0.32917044]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09614060074090958\n",
      "Predicción post entrenamiento : [[0.3353743]]\n",
      "PERDIDAAAA despues: 0.09449464082717896\n",
      "loss en el callback: 0.12721335887908936, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "ejemplar: [[0.31030649]\n",
      " [0.31222677]\n",
      " [0.3155354 ]\n",
      " [0.3191072 ]\n",
      " [0.32238331]\n",
      " [0.32599187]\n",
      " [0.32917044]\n",
      " [0.33270863]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.3371285]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[[0.31030649]\n",
      "  [0.31222677]\n",
      "  [0.3155354 ]\n",
      "  [0.3191072 ]\n",
      "  [0.32238331]\n",
      "  [0.32599187]\n",
      "  [0.32917044]\n",
      "  [0.33270863]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10538498312234879\n",
      "Predicción post entrenamiento : [[0.3398506]]\n",
      "PERDIDAAAA despues: 0.10362502932548523\n",
      "loss en el callback: 0.10181125998497009, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "ejemplar: [[0.31222677]\n",
      " [0.3155354 ]\n",
      " [0.3191072 ]\n",
      " [0.32238331]\n",
      " [0.32599187]\n",
      " [0.32917044]\n",
      " [0.33270863]\n",
      " [0.33712849]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.34207305]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[[0.31222677]\n",
      "  [0.3155354 ]\n",
      "  [0.3191072 ]\n",
      "  [0.32238331]\n",
      "  [0.32599187]\n",
      "  [0.32917044]\n",
      "  [0.33270863]\n",
      "  [0.33712849]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10950931906700134\n",
      "Predicción post entrenamiento : [[0.3448212]]\n",
      "PERDIDAAAA despues: 0.10769801586866379\n",
      "loss en el callback: 0.0997532308101654, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "ejemplar: [[0.3155354 ]\n",
      " [0.3191072 ]\n",
      " [0.32238331]\n",
      " [0.32599187]\n",
      " [0.32917044]\n",
      " [0.33270863]\n",
      " [0.33712849]\n",
      " [0.34207305]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.34738225]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[[0.3155354 ]\n",
      "  [0.3191072 ]\n",
      "  [0.32238331]\n",
      "  [0.32599187]\n",
      "  [0.32917044]\n",
      "  [0.33270863]\n",
      "  [0.33712849]\n",
      "  [0.34207305]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13191065192222595\n",
      "Predicción post entrenamiento : [[0.35031807]]\n",
      "PERDIDAAAA despues: 0.12978671491146088\n",
      "loss en el callback: 0.0987062156200409, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "ejemplar: [[0.3191072 ]\n",
      " [0.32238331]\n",
      " [0.32599187]\n",
      " [0.32917044]\n",
      " [0.33270863]\n",
      " [0.33712849]\n",
      " [0.34207305]\n",
      " [0.34738225]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.35296407]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[[0.3191072 ]\n",
      "  [0.32238331]\n",
      "  [0.32599187]\n",
      "  [0.32917044]\n",
      "  [0.33270863]\n",
      "  [0.33712849]\n",
      "  [0.34207305]\n",
      "  [0.34738225]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12321969121694565\n",
      "Predicción post entrenamiento : [[0.3556863]]\n",
      "PERDIDAAAA despues: 0.12131594866514206\n",
      "loss en el callback: 0.07892872393131256, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "ejemplar: [[0.32238331]\n",
      " [0.32599187]\n",
      " [0.32917044]\n",
      " [0.33270863]\n",
      " [0.33712849]\n",
      " [0.34207305]\n",
      " [0.34738225]\n",
      " [0.35296407]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.35840228]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[[0.32238331]\n",
      "  [0.32599187]\n",
      "  [0.32917044]\n",
      "  [0.33270863]\n",
      "  [0.33712849]\n",
      "  [0.34207305]\n",
      "  [0.34738225]\n",
      "  [0.35296407]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13603943586349487\n",
      "Predicción post entrenamiento : [[0.36137924]]\n",
      "PERDIDAAAA despues: 0.1338522881269455\n",
      "loss en el callback: 0.16399794816970825, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "ejemplar: [[0.32599187]\n",
      " [0.32917044]\n",
      " [0.33270863]\n",
      " [0.33712849]\n",
      " [0.34207305]\n",
      " [0.34738225]\n",
      " [0.35296407]\n",
      " [0.35840228]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.36429226]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[[0.32599187]\n",
      "  [0.32917044]\n",
      "  [0.33270863]\n",
      "  [0.33712849]\n",
      "  [0.34207305]\n",
      "  [0.34738225]\n",
      "  [0.35296407]\n",
      "  [0.35840228]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12837591767311096\n",
      "Predicción post entrenamiento : [[0.36711302]]\n",
      "PERDIDAAAA despues: 0.12636254727840424\n",
      "loss en el callback: 0.13956865668296814, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "ejemplar: [[0.32917044]\n",
      " [0.33270863]\n",
      " [0.33712849]\n",
      " [0.34207305]\n",
      " [0.34738225]\n",
      " [0.35296407]\n",
      " [0.35840228]\n",
      " [0.36429226]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.37021977]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[[0.32917044]\n",
      "  [0.33270863]\n",
      "  [0.33712849]\n",
      "  [0.34207305]\n",
      "  [0.34738225]\n",
      "  [0.35296407]\n",
      "  [0.35840228]\n",
      "  [0.36429226]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.16126178205013275\n",
      "Predicción post entrenamiento : [[0.37319645]]\n",
      "PERDIDAAAA despues: 0.15887992084026337\n",
      "loss en el callback: 0.11097295582294464, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "ejemplar: [[0.33270863]\n",
      " [0.33712849]\n",
      " [0.34207305]\n",
      " [0.34738225]\n",
      " [0.35296407]\n",
      " [0.35840228]\n",
      " [0.36429226]\n",
      " [0.37021977]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.37667924]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[[0.33270863]\n",
      "  [0.33712849]\n",
      "  [0.34207305]\n",
      "  [0.34738225]\n",
      "  [0.35296407]\n",
      "  [0.35840228]\n",
      "  [0.36429226]\n",
      "  [0.37021977]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12099694460630417\n",
      "Predicción post entrenamiento : [[0.37945953]]\n",
      "PERDIDAAAA despues: 0.11907044798135757\n",
      "loss en el callback: 0.16221672296524048, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "ejemplar: [[0.33712849]\n",
      " [0.34207305]\n",
      " [0.34738225]\n",
      " [0.35296407]\n",
      " [0.35840228]\n",
      " [0.36429226]\n",
      " [0.37021977]\n",
      " [0.37667924]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.383328]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[[0.33712849]\n",
      "  [0.34207305]\n",
      "  [0.34738225]\n",
      "  [0.35296407]\n",
      "  [0.35840228]\n",
      "  [0.36429226]\n",
      "  [0.37021977]\n",
      "  [0.37667924]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08278838545084\n",
      "Predicción post entrenamiento : [[0.38567454]]\n",
      "PERDIDAAAA despues: 0.08144354820251465\n",
      "loss en el callback: 0.09342461824417114, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "ejemplar: [[0.34207305]\n",
      " [0.34738225]\n",
      " [0.35296407]\n",
      " [0.35840228]\n",
      " [0.36429226]\n",
      " [0.37021977]\n",
      " [0.37667924]\n",
      " [0.38332799]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.38980272]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[[0.34207305]\n",
      "  [0.34738225]\n",
      "  [0.35296407]\n",
      "  [0.35840228]\n",
      "  [0.36429226]\n",
      "  [0.37021977]\n",
      "  [0.37667924]\n",
      "  [0.38332799]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08063732087612152\n",
      "Predicción post entrenamiento : [[0.39204156]]\n",
      "PERDIDAAAA despues: 0.07937081903219223\n",
      "loss en el callback: 0.10088341683149338, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "ejemplar: [[0.34738225]\n",
      " [0.35296407]\n",
      " [0.35840228]\n",
      " [0.36429226]\n",
      " [0.37021977]\n",
      " [0.37667924]\n",
      " [0.38332799]\n",
      " [0.38980272]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.39636678]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[[0.34738225]\n",
      "  [0.35296407]\n",
      "  [0.35840228]\n",
      "  [0.36429226]\n",
      "  [0.37021977]\n",
      "  [0.37667924]\n",
      "  [0.38332799]\n",
      "  [0.38980272]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10117807984352112\n",
      "Predicción post entrenamiento : [[0.39841884]]\n",
      "PERDIDAAAA despues: 0.09987682104110718\n",
      "loss en el callback: 0.056658871471881866, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "ejemplar: [[0.35296407]\n",
      " [0.35840228]\n",
      " [0.36429226]\n",
      " [0.37021977]\n",
      " [0.37667924]\n",
      " [0.38332799]\n",
      " [0.38980272]\n",
      " [0.39636678]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.40290484]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[[0.35296407]\n",
      "  [0.35840228]\n",
      "  [0.36429226]\n",
      "  [0.37021977]\n",
      "  [0.37667924]\n",
      "  [0.38332799]\n",
      "  [0.38980272]\n",
      "  [0.39636678]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11627615988254547\n",
      "Predicción post entrenamiento : [[0.40499195]]\n",
      "PERDIDAAAA despues: 0.11485712975263596\n",
      "loss en el callback: 0.06443805992603302, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "ejemplar: [[0.35840228]\n",
      " [0.36429226]\n",
      " [0.37021977]\n",
      " [0.37667924]\n",
      " [0.38332799]\n",
      " [0.38980272]\n",
      " [0.39636678]\n",
      " [0.40290484]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.40961638]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[[0.35840228]\n",
      "  [0.36429226]\n",
      "  [0.37021977]\n",
      "  [0.37667924]\n",
      "  [0.38332799]\n",
      "  [0.38980272]\n",
      "  [0.39636678]\n",
      "  [0.40290484]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09795130789279938\n",
      "Predicción post entrenamiento : [[0.41175655]]\n",
      "PERDIDAAAA despues: 0.09661626815795898\n",
      "loss en el callback: 0.0715431198477745, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "ejemplar: [[0.36429226]\n",
      " [0.37021977]\n",
      " [0.37667924]\n",
      " [0.38332799]\n",
      " [0.38980272]\n",
      " [0.39636678]\n",
      " [0.40290484]\n",
      " [0.40961638]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.41659397]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[[0.36429226]\n",
      "  [0.37021977]\n",
      "  [0.37667924]\n",
      "  [0.38332799]\n",
      "  [0.38980272]\n",
      "  [0.39636678]\n",
      "  [0.40290484]\n",
      "  [0.40961638]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07994608581066132\n",
      "Predicción post entrenamiento : [[0.4186876]]\n",
      "PERDIDAAAA despues: 0.07876652479171753\n",
      "loss en el callback: 0.08457308262586594, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "ejemplar: [[0.37021977]\n",
      " [0.37667924]\n",
      " [0.38332799]\n",
      " [0.38980272]\n",
      " [0.39636678]\n",
      " [0.40290484]\n",
      " [0.40961638]\n",
      " [0.41659397]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.42367023]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[[0.37021977]\n",
      "  [0.37667924]\n",
      "  [0.38332799]\n",
      "  [0.38980272]\n",
      "  [0.39636678]\n",
      "  [0.40290484]\n",
      "  [0.40961638]\n",
      "  [0.41659397]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09837061166763306\n",
      "Predicción post entrenamiento : [[0.425987]]\n",
      "PERDIDAAAA despues: 0.09692271053791046\n",
      "loss en el callback: 0.1200675442814827, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "ejemplar: [[0.37667924]\n",
      " [0.38332799]\n",
      " [0.38980272]\n",
      " [0.39636678]\n",
      " [0.40290484]\n",
      " [0.40961638]\n",
      " [0.41659397]\n",
      " [0.42367023]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.43113872]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[[0.37667924]\n",
      "  [0.38332799]\n",
      "  [0.38980272]\n",
      "  [0.39636678]\n",
      "  [0.40290484]\n",
      "  [0.40961638]\n",
      "  [0.41659397]\n",
      "  [0.42367023]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08426660299301147\n",
      "Predicción post entrenamiento : [[0.43305448]]\n",
      "PERDIDAAAA despues: 0.08315803855657578\n",
      "loss en el callback: 0.07024271786212921, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "ejemplar: [[0.38332799]\n",
      " [0.38980272]\n",
      " [0.39636678]\n",
      " [0.40290484]\n",
      " [0.40961638]\n",
      " [0.41659397]\n",
      " [0.42367023]\n",
      " [0.43113872]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.4382761]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[[0.38332799]\n",
      "  [0.38980272]\n",
      "  [0.39636678]\n",
      "  [0.40290484]\n",
      "  [0.40961638]\n",
      "  [0.41659397]\n",
      "  [0.42367023]\n",
      "  [0.43113872]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0786452442407608\n",
      "Predicción post entrenamiento : [[0.44004476]]\n",
      "PERDIDAAAA despues: 0.07765638083219528\n",
      "loss en el callback: 0.05408022180199623, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "ejemplar: [[0.38980272]\n",
      " [0.39636678]\n",
      " [0.40290484]\n",
      " [0.40961638]\n",
      " [0.41659397]\n",
      " [0.42367023]\n",
      " [0.43113872]\n",
      " [0.43827611]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.4453098]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[[0.38980272]\n",
      "  [0.39636678]\n",
      "  [0.40290484]\n",
      "  [0.40961638]\n",
      "  [0.41659397]\n",
      "  [0.42367023]\n",
      "  [0.43113872]\n",
      "  [0.43827611]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05237119272351265\n",
      "Predicción post entrenamiento : [[0.4470906]]\n",
      "PERDIDAAAA despues: 0.05155929923057556\n",
      "loss en el callback: 0.10161229223012924, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "ejemplar: [[0.39636678]\n",
      " [0.40290484]\n",
      " [0.40961638]\n",
      " [0.41659397]\n",
      " [0.42367023]\n",
      " [0.43113872]\n",
      " [0.43827611]\n",
      " [0.44530979]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.4524632]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[[0.39636678]\n",
      "  [0.40290484]\n",
      "  [0.40961638]\n",
      "  [0.41659397]\n",
      "  [0.42367023]\n",
      "  [0.43113872]\n",
      "  [0.43827611]\n",
      "  [0.44530979]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.060566797852516174\n",
      "Predicción post entrenamiento : [[0.45399502]]\n",
      "PERDIDAAAA despues: 0.0598151795566082\n",
      "loss en el callback: 0.04368195682764053, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "ejemplar: [[0.40290484]\n",
      " [0.40961638]\n",
      " [0.41659397]\n",
      " [0.42367023]\n",
      " [0.43113872]\n",
      " [0.43827611]\n",
      " [0.44530979]\n",
      " [0.45246321]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.45947888]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[[0.40290484]\n",
      "  [0.40961638]\n",
      "  [0.41659397]\n",
      "  [0.42367023]\n",
      "  [0.43113872]\n",
      "  [0.43827611]\n",
      "  [0.44530979]\n",
      "  [0.45246321]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06841334700584412\n",
      "Predicción post entrenamiento : [[0.46138284]]\n",
      "PERDIDAAAA despues: 0.06742098182439804\n",
      "loss en el callback: 0.08866804838180542, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "ejemplar: [[0.40961638]\n",
      " [0.41659397]\n",
      " [0.42367023]\n",
      " [0.43113872]\n",
      " [0.43827611]\n",
      " [0.44530979]\n",
      " [0.45246321]\n",
      " [0.45947888]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.46700925]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[[0.40961638]\n",
      "  [0.41659397]\n",
      "  [0.42367023]\n",
      "  [0.43113872]\n",
      "  [0.43827611]\n",
      "  [0.44530979]\n",
      "  [0.45246321]\n",
      "  [0.45947888]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06532055884599686\n",
      "Predicción post entrenamiento : [[0.46885073]]\n",
      "PERDIDAAAA despues: 0.06438266485929489\n",
      "loss en el callback: 0.08562451601028442, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "ejemplar: [[0.41659397]\n",
      " [0.42367023]\n",
      " [0.43113872]\n",
      " [0.43827611]\n",
      " [0.44530979]\n",
      " [0.45246321]\n",
      " [0.45947888]\n",
      " [0.46700925]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.47459948]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[[0.41659397]\n",
      "  [0.42367023]\n",
      "  [0.43113872]\n",
      "  [0.43827611]\n",
      "  [0.44530979]\n",
      "  [0.45246321]\n",
      "  [0.45947888]\n",
      "  [0.46700925]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0793529525399208\n",
      "Predicción post entrenamiento : [[0.47638744]]\n",
      "PERDIDAAAA despues: 0.07834882289171219\n",
      "loss en el callback: 0.06534719467163086, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "ejemplar: [[0.42367023]\n",
      " [0.43113872]\n",
      " [0.43827611]\n",
      " [0.44530979]\n",
      " [0.45246321]\n",
      " [0.45947888]\n",
      " [0.46700925]\n",
      " [0.47459948]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.48220962]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[[0.42367023]\n",
      "  [0.43113872]\n",
      "  [0.43827611]\n",
      "  [0.44530979]\n",
      "  [0.45246321]\n",
      "  [0.45947888]\n",
      "  [0.46700925]\n",
      "  [0.47459948]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11928500235080719\n",
      "Predicción post entrenamiento : [[0.4845081]]\n",
      "PERDIDAAAA despues: 0.11770261079072952\n",
      "loss en el callback: 0.13236916065216064, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "ejemplar: [[0.43113872]\n",
      " [0.43827611]\n",
      " [0.44530979]\n",
      " [0.45246321]\n",
      " [0.45947888]\n",
      " [0.46700925]\n",
      " [0.47459948]\n",
      " [0.48220962]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.49039283]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[[0.43113872]\n",
      "  [0.43827611]\n",
      "  [0.44530979]\n",
      "  [0.45246321]\n",
      "  [0.45947888]\n",
      "  [0.46700925]\n",
      "  [0.47459948]\n",
      "  [0.48220962]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12140301614999771\n",
      "Predicción post entrenamiento : [[0.4926689]]\n",
      "PERDIDAAAA despues: 0.11982209980487823\n",
      "loss en el callback: 0.21263845264911652, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "ejemplar: [[0.43827611]\n",
      " [0.44530979]\n",
      " [0.45246321]\n",
      " [0.45947888]\n",
      " [0.46700925]\n",
      " [0.47459948]\n",
      " [0.48220962]\n",
      " [0.49039283]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.49853113]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[[0.43827611]\n",
      "  [0.44530979]\n",
      "  [0.45246321]\n",
      "  [0.45947888]\n",
      "  [0.46700925]\n",
      "  [0.47459948]\n",
      "  [0.48220962]\n",
      "  [0.49039283]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08745899796485901\n",
      "Predicción post entrenamiento : [[0.5001971]]\n",
      "PERDIDAAAA despues: 0.0864764004945755\n",
      "loss en el callback: 0.054526399821043015, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "ejemplar: [[0.44530979]\n",
      " [0.45246321]\n",
      " [0.45947888]\n",
      " [0.46700925]\n",
      " [0.47459948]\n",
      " [0.48220962]\n",
      " [0.49039283]\n",
      " [0.49853113]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.5061339]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[[0.44530979]\n",
      "  [0.45246321]\n",
      "  [0.45947888]\n",
      "  [0.46700925]\n",
      "  [0.47459948]\n",
      "  [0.48220962]\n",
      "  [0.49039283]\n",
      "  [0.49853113]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07710107415914536\n",
      "Predicción post entrenamiento : [[0.50800884]]\n",
      "PERDIDAAAA despues: 0.0760633647441864\n",
      "loss en el callback: 0.09520133584737778, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "ejemplar: [[0.45246321]\n",
      " [0.45947888]\n",
      " [0.46700925]\n",
      " [0.47459948]\n",
      " [0.48220962]\n",
      " [0.49039283]\n",
      " [0.49853113]\n",
      " [0.50613391]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.514077]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[[0.45246321]\n",
      "  [0.45947888]\n",
      "  [0.46700925]\n",
      "  [0.47459948]\n",
      "  [0.48220962]\n",
      "  [0.49039283]\n",
      "  [0.49853113]\n",
      "  [0.50613391]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06443597376346588\n",
      "Predicción post entrenamiento : [[0.51595145]]\n",
      "PERDIDAAAA despues: 0.06348785758018494\n",
      "loss en el callback: 0.11365075409412384, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "ejemplar: [[0.45947888]\n",
      " [0.46700925]\n",
      " [0.47459948]\n",
      " [0.48220962]\n",
      " [0.49039283]\n",
      " [0.49853113]\n",
      " [0.50613391]\n",
      " [0.51407701]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.5221545]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[[0.45947888]\n",
      "  [0.46700925]\n",
      "  [0.47459948]\n",
      "  [0.48220962]\n",
      "  [0.49039283]\n",
      "  [0.49853113]\n",
      "  [0.50613391]\n",
      "  [0.51407701]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06886694580316544\n",
      "Predicción post entrenamiento : [[0.52408546]]\n",
      "PERDIDAAAA despues: 0.06785721331834793\n",
      "loss en el callback: 0.1123187318444252, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "ejemplar: [[0.46700925]\n",
      " [0.47459948]\n",
      " [0.48220962]\n",
      " [0.49039283]\n",
      " [0.49853113]\n",
      " [0.50613391]\n",
      " [0.51407701]\n",
      " [0.52215451]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.5304922]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[[0.46700925]\n",
      "  [0.47459948]\n",
      "  [0.48220962]\n",
      "  [0.49039283]\n",
      "  [0.49853113]\n",
      "  [0.50613391]\n",
      "  [0.51407701]\n",
      "  [0.52215451]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12126899510622025\n",
      "Predicción post entrenamiento : [[0.53286964]]\n",
      "PERDIDAAAA despues: 0.11961881071329117\n",
      "loss en el callback: 0.1698562502861023, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "ejemplar: [[0.47459948]\n",
      " [0.48220962]\n",
      " [0.49039283]\n",
      " [0.49853113]\n",
      " [0.50613391]\n",
      " [0.51407701]\n",
      " [0.52215451]\n",
      " [0.53049219]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.53938293]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[[0.47459948]\n",
      "  [0.48220962]\n",
      "  [0.49039283]\n",
      "  [0.49853113]\n",
      "  [0.50613391]\n",
      "  [0.51407701]\n",
      "  [0.52215451]\n",
      "  [0.53049219]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11306182295084\n",
      "Predicción post entrenamiento : [[0.5413479]]\n",
      "PERDIDAAAA despues: 0.1117442399263382\n",
      "loss en el callback: 0.09143483638763428, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "ejemplar: [[0.48220962]\n",
      " [0.49039283]\n",
      " [0.49853113]\n",
      " [0.50613391]\n",
      " [0.51407701]\n",
      " [0.52215451]\n",
      " [0.53049219]\n",
      " [0.53938293]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.5479767]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[[0.48220962]\n",
      "  [0.49039283]\n",
      "  [0.49853113]\n",
      "  [0.50613391]\n",
      "  [0.51407701]\n",
      "  [0.52215451]\n",
      "  [0.53049219]\n",
      "  [0.53938293]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09055231511592865\n",
      "Predicción post entrenamiento : [[0.5498023]]\n",
      "PERDIDAAAA despues: 0.08945691585540771\n",
      "loss en el callback: 0.07597984373569489, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "ejemplar: [[0.49039283]\n",
      " [0.49853113]\n",
      " [0.50613391]\n",
      " [0.51407701]\n",
      " [0.52215451]\n",
      " [0.53049219]\n",
      " [0.53938293]\n",
      " [0.54797667]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.55656874]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[[0.49039283]\n",
      "  [0.49853113]\n",
      "  [0.50613391]\n",
      "  [0.51407701]\n",
      "  [0.52215451]\n",
      "  [0.53049219]\n",
      "  [0.53938293]\n",
      "  [0.54797667]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0684967041015625\n",
      "Predicción post entrenamiento : [[0.55845857]]\n",
      "PERDIDAAAA despues: 0.06751106679439545\n",
      "loss en el callback: 0.16658595204353333, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "ejemplar: [[0.49853113]\n",
      " [0.50613391]\n",
      " [0.51407701]\n",
      " [0.52215451]\n",
      " [0.53049219]\n",
      " [0.53938293]\n",
      " [0.54797667]\n",
      " [0.55656874]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.5652408]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[[0.49853113]\n",
      "  [0.50613391]\n",
      "  [0.51407701]\n",
      "  [0.52215451]\n",
      "  [0.53049219]\n",
      "  [0.53938293]\n",
      "  [0.54797667]\n",
      "  [0.55656874]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06841913610696793\n",
      "Predicción post entrenamiento : [[0.5666568]]\n",
      "PERDIDAAAA despues: 0.06768035888671875\n",
      "loss en el callback: 0.0503249429166317, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "ejemplar: [[0.50613391]\n",
      " [0.51407701]\n",
      " [0.52215451]\n",
      " [0.53049219]\n",
      " [0.53938293]\n",
      " [0.54797667]\n",
      " [0.55656874]\n",
      " [0.5652408 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.57348394]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[[0.50613391]\n",
      "  [0.51407701]\n",
      "  [0.52215451]\n",
      "  [0.53049219]\n",
      "  [0.53938293]\n",
      "  [0.54797667]\n",
      "  [0.55656874]\n",
      "  [0.5652408 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04488912969827652\n",
      "Predicción post entrenamiento : [[0.5750374]]\n",
      "PERDIDAAAA despues: 0.04423327371478081\n",
      "loss en el callback: 0.08026394248008728, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "ejemplar: [[0.51407701]\n",
      " [0.52215451]\n",
      " [0.53049219]\n",
      " [0.53938293]\n",
      " [0.54797667]\n",
      " [0.55656874]\n",
      " [0.5652408 ]\n",
      " [0.57348394]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.58207625]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[[0.51407701]\n",
      "  [0.52215451]\n",
      "  [0.53049219]\n",
      "  [0.53938293]\n",
      "  [0.54797667]\n",
      "  [0.55656874]\n",
      "  [0.5652408 ]\n",
      "  [0.57348394]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04291225224733353\n",
      "Predicción post entrenamiento : [[0.583738]]\n",
      "PERDIDAAAA despues: 0.042226530611515045\n",
      "loss en el callback: 0.10611236095428467, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "ejemplar: [[0.52215451]\n",
      " [0.53049219]\n",
      " [0.53938293]\n",
      " [0.54797667]\n",
      " [0.55656874]\n",
      " [0.5652408 ]\n",
      " [0.57348394]\n",
      " [0.58207625]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.5909352]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[[0.52215451]\n",
      "  [0.53049219]\n",
      "  [0.53938293]\n",
      "  [0.54797667]\n",
      "  [0.55656874]\n",
      "  [0.5652408 ]\n",
      "  [0.57348394]\n",
      "  [0.58207625]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.059164538979530334\n",
      "Predicción post entrenamiento : [[0.59213376]]\n",
      "PERDIDAAAA despues: 0.058582890778779984\n",
      "loss en el callback: 0.0318794883787632, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "ejemplar: [[0.53049219]\n",
      " [0.53938293]\n",
      " [0.54797667]\n",
      " [0.55656874]\n",
      " [0.5652408 ]\n",
      " [0.57348394]\n",
      " [0.58207625]\n",
      " [0.59093517]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.59947675]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[[0.53049219]\n",
      "  [0.53938293]\n",
      "  [0.54797667]\n",
      "  [0.55656874]\n",
      "  [0.5652408 ]\n",
      "  [0.57348394]\n",
      "  [0.58207625]\n",
      "  [0.59093517]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04536859318614006\n",
      "Predicción post entrenamiento : [[0.60083765]]\n",
      "PERDIDAAAA despues: 0.044790707528591156\n",
      "loss en el callback: 0.05203733220696449, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "ejemplar: [[0.53938293]\n",
      " [0.54797667]\n",
      " [0.55656874]\n",
      " [0.5652408 ]\n",
      " [0.57348394]\n",
      " [0.58207625]\n",
      " [0.59093517]\n",
      " [0.59947675]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.6082736]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[[0.53938293]\n",
      "  [0.54797667]\n",
      "  [0.55656874]\n",
      "  [0.5652408 ]\n",
      "  [0.57348394]\n",
      "  [0.58207625]\n",
      "  [0.59093517]\n",
      "  [0.59947675]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.037235964089632034\n",
      "Predicción post entrenamiento : [[0.6099388]]\n",
      "PERDIDAAAA despues: 0.036596089601516724\n",
      "loss en el callback: 0.13794568181037903, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "ejemplar: [[0.54797667]\n",
      " [0.55656874]\n",
      " [0.5652408 ]\n",
      " [0.57348394]\n",
      " [0.58207625]\n",
      " [0.59093517]\n",
      " [0.59947675]\n",
      " [0.60827363]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.6173248]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[[0.54797667]\n",
      "  [0.55656874]\n",
      "  [0.5652408 ]\n",
      "  [0.57348394]\n",
      "  [0.58207625]\n",
      "  [0.59093517]\n",
      "  [0.59947675]\n",
      "  [0.60827363]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0345410518348217\n",
      "Predicción post entrenamiento : [[0.61863333]]\n",
      "PERDIDAAAA despues: 0.03405638784170151\n",
      "loss en el callback: 0.04900284856557846, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "ejemplar: [[0.55656874]\n",
      " [0.5652408 ]\n",
      " [0.57348394]\n",
      " [0.58207625]\n",
      " [0.59093517]\n",
      " [0.59947675]\n",
      " [0.60827363]\n",
      " [0.61732483]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.62604374]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[[0.55656874]\n",
      "  [0.5652408 ]\n",
      "  [0.57348394]\n",
      "  [0.58207625]\n",
      "  [0.59093517]\n",
      "  [0.59947675]\n",
      "  [0.60827363]\n",
      "  [0.61732483]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.028038548305630684\n",
      "Predicción post entrenamiento : [[0.62678456]]\n",
      "PERDIDAAAA despues: 0.02779099904000759\n",
      "loss en el callback: 0.013457810506224632, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "ejemplar: [[0.5652408 ]\n",
      " [0.57348394]\n",
      " [0.58207625]\n",
      " [0.59093517]\n",
      " [0.59947675]\n",
      " [0.60827363]\n",
      " [0.61732483]\n",
      " [0.62604374]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.634225]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[[0.5652408 ]\n",
      "  [0.57348394]\n",
      "  [0.58207625]\n",
      "  [0.59093517]\n",
      "  [0.59947675]\n",
      "  [0.60827363]\n",
      "  [0.61732483]\n",
      "  [0.62604374]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015862256288528442\n",
      "Predicción post entrenamiento : [[0.6345521]]\n",
      "PERDIDAAAA despues: 0.015779966488480568\n",
      "loss en el callback: 0.0024917349219322205, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "ejemplar: [[0.57348394]\n",
      " [0.58207625]\n",
      " [0.59093517]\n",
      " [0.59947675]\n",
      " [0.60827363]\n",
      " [0.61732483]\n",
      " [0.62604374]\n",
      " [0.63422501]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.64200485]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[[0.57348394]\n",
      "  [0.58207625]\n",
      "  [0.59093517]\n",
      "  [0.59947675]\n",
      "  [0.60827363]\n",
      "  [0.61732483]\n",
      "  [0.62604374]\n",
      "  [0.63422501]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00871778279542923\n",
      "Predicción post entrenamiento : [[0.6429411]]\n",
      "PERDIDAAAA despues: 0.008543821983039379\n",
      "loss en el callback: 0.03129899874329567, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "ejemplar: [[0.58207625]\n",
      " [0.59093517]\n",
      " [0.59947675]\n",
      " [0.60827363]\n",
      " [0.61732483]\n",
      " [0.62604374]\n",
      " [0.63422501]\n",
      " [0.64200485]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.6505239]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[[0.58207625]\n",
      "  [0.59093517]\n",
      "  [0.59947675]\n",
      "  [0.60827363]\n",
      "  [0.61732483]\n",
      "  [0.62604374]\n",
      "  [0.63422501]\n",
      "  [0.64200485]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0035600217524915934\n",
      "Predicción post entrenamiento : [[0.65088516]]\n",
      "PERDIDAAAA despues: 0.0035170421469956636\n",
      "loss en el callback: 0.0038405167870223522, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "ejemplar: [[0.59093517]\n",
      " [0.59947675]\n",
      " [0.60827363]\n",
      " [0.61732483]\n",
      " [0.62604374]\n",
      " [0.63422501]\n",
      " [0.64200485]\n",
      " [0.6505239 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.658504]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[[0.59093517]\n",
      "  [0.59947675]\n",
      "  [0.60827363]\n",
      "  [0.61732483]\n",
      "  [0.62604374]\n",
      "  [0.63422501]\n",
      "  [0.64200485]\n",
      "  [0.6505239 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0028754347003996372\n",
      "Predicción post entrenamiento : [[0.6586204]]\n",
      "PERDIDAAAA despues: 0.0028629640582948923\n",
      "loss en el callback: 0.0003745606227312237, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "ejemplar: [[0.59947675]\n",
      " [0.60827363]\n",
      " [0.61732483]\n",
      " [0.62604374]\n",
      " [0.63422501]\n",
      " [0.64200485]\n",
      " [0.6505239 ]\n",
      " [0.65850401]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.666185]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[[0.59947675]\n",
      "  [0.60827363]\n",
      "  [0.61732483]\n",
      "  [0.62604374]\n",
      "  [0.63422501]\n",
      "  [0.64200485]\n",
      "  [0.6505239 ]\n",
      "  [0.65850401]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005395020358264446\n",
      "Predicción post entrenamiento : [[0.66652554]]\n",
      "PERDIDAAAA despues: 0.005345113575458527\n",
      "loss en el callback: 0.003293410874903202, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "ejemplar: [[0.60827363]\n",
      " [0.61732483]\n",
      " [0.62604374]\n",
      " [0.63422501]\n",
      " [0.64200485]\n",
      " [0.6505239 ]\n",
      " [0.65850401]\n",
      " [0.66618502]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.6740942]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[[0.60827363]\n",
      "  [0.61732483]\n",
      "  [0.62604374]\n",
      "  [0.63422501]\n",
      "  [0.64200485]\n",
      "  [0.6505239 ]\n",
      "  [0.65850401]\n",
      "  [0.66618502]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0038507701829075813\n",
      "Predicción post entrenamiento : [[0.6739783]]\n",
      "PERDIDAAAA despues: 0.003865164238959551\n",
      "loss en el callback: 0.0003324510180391371, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "ejemplar: [[0.61732483]\n",
      " [0.62604374]\n",
      " [0.63422501]\n",
      " [0.64200485]\n",
      " [0.6505239 ]\n",
      " [0.65850401]\n",
      " [0.66618502]\n",
      " [0.6740942 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.68145055]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[[0.61732483]\n",
      "  [0.62604374]\n",
      "  [0.63422501]\n",
      "  [0.64200485]\n",
      "  [0.6505239 ]\n",
      "  [0.65850401]\n",
      "  [0.66618502]\n",
      "  [0.6740942 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00019264983711764216\n",
      "Predicción post entrenamiento : [[0.6821455]]\n",
      "PERDIDAAAA despues: 0.00021242380898911506\n",
      "loss en el callback: 0.02290201187133789, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "ejemplar: [[0.62604374]\n",
      " [0.63422501]\n",
      " [0.64200485]\n",
      " [0.6505239 ]\n",
      " [0.65850401]\n",
      " [0.66618502]\n",
      " [0.6740942 ]\n",
      " [0.68145055]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.68940926]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[[0.62604374]\n",
      "  [0.63422501]\n",
      "  [0.64200485]\n",
      "  [0.6505239 ]\n",
      "  [0.65850401]\n",
      "  [0.66618502]\n",
      "  [0.6740942 ]\n",
      "  [0.68145055]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00038079015212133527\n",
      "Predicción post entrenamiento : [[0.6893797]]\n",
      "PERDIDAAAA despues: 0.0003796372329816222\n",
      "loss en el callback: 2.8182797905174084e-05, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "ejemplar: [[0.63422501]\n",
      " [0.64200485]\n",
      " [0.6505239 ]\n",
      " [0.65850401]\n",
      " [0.66618502]\n",
      " [0.6740942 ]\n",
      " [0.68145055]\n",
      " [0.68940926]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.69647586]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[[0.63422501]\n",
      "  [0.64200485]\n",
      "  [0.6505239 ]\n",
      "  [0.65850401]\n",
      "  [0.66618502]\n",
      "  [0.6740942 ]\n",
      "  [0.68145055]\n",
      "  [0.68940926]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.352013339645964e-08\n",
      "Predicción post entrenamiento : [[0.69709384]]\n",
      "PERDIDAAAA despues: 2.1587007381640433e-07\n",
      "loss en el callback: 0.016711661592125893, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "ejemplar: [[0.64200485]\n",
      " [0.6505239 ]\n",
      " [0.65850401]\n",
      " [0.66618502]\n",
      " [0.6740942 ]\n",
      " [0.68145055]\n",
      " [0.68940926]\n",
      " [0.69647586]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.7041342]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[[0.64200485]\n",
      "  [0.6505239 ]\n",
      "  [0.65850401]\n",
      "  [0.66618502]\n",
      "  [0.6740942 ]\n",
      "  [0.68145055]\n",
      "  [0.68940926]\n",
      "  [0.69647586]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0023219771683216095\n",
      "Predicción post entrenamiento : [[0.70416546]]\n",
      "PERDIDAAAA despues: 0.0023249881342053413\n",
      "loss en el callback: 3.5470315197017044e-05, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "ejemplar: [[0.6505239 ]\n",
      " [0.65850401]\n",
      " [0.66618502]\n",
      " [0.6740942 ]\n",
      " [0.68145055]\n",
      " [0.68940926]\n",
      " [0.69647586]\n",
      " [0.70413423]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.71123564]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[[0.6505239 ]\n",
      "  [0.65850401]\n",
      "  [0.66618502]\n",
      "  [0.6740942 ]\n",
      "  [0.68145055]\n",
      "  [0.68940926]\n",
      "  [0.69647586]\n",
      "  [0.70413423]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010516387410461903\n",
      "Predicción post entrenamiento : [[0.7114377]]\n",
      "PERDIDAAAA despues: 0.0010647847084328532\n",
      "loss en el callback: 0.0015636420575901866, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "ejemplar: [[0.65850401]\n",
      " [0.66618502]\n",
      " [0.6740942 ]\n",
      " [0.68145055]\n",
      " [0.68940926]\n",
      " [0.69647586]\n",
      " [0.70413423]\n",
      " [0.71123564]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.7183106]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[[0.65850401]\n",
      "  [0.66618502]\n",
      "  [0.6740942 ]\n",
      "  [0.68145055]\n",
      "  [0.68940926]\n",
      "  [0.69647586]\n",
      "  [0.70413423]\n",
      "  [0.71123564]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017821959918364882\n",
      "Predicción post entrenamiento : [[0.71884626]]\n",
      "PERDIDAAAA despues: 0.0018277104245498776\n",
      "loss en el callback: 0.01299437414854765, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "ejemplar: [[0.66618502]\n",
      " [0.6740942 ]\n",
      " [0.68145055]\n",
      " [0.68940926]\n",
      " [0.69647586]\n",
      " [0.70413423]\n",
      " [0.71123564]\n",
      " [0.71831059]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.7256296]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[[0.66618502]\n",
      "  [0.6740942 ]\n",
      "  [0.68145055]\n",
      "  [0.68940926]\n",
      "  [0.69647586]\n",
      "  [0.70413423]\n",
      "  [0.71123564]\n",
      "  [0.71831059]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.546483690617606e-05\n",
      "Predicción post entrenamiento : [[0.72607833]]\n",
      "PERDIDAAAA despues: 1.213708492286969e-05\n",
      "loss en el callback: 0.007832074537873268, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "ejemplar: [[0.6740942 ]\n",
      " [0.68145055]\n",
      " [0.68940926]\n",
      " [0.69647586]\n",
      " [0.70413423]\n",
      " [0.71123564]\n",
      " [0.71831059]\n",
      " [0.72562963]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.7328279]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[[0.6740942 ]\n",
      "  [0.68145055]\n",
      "  [0.68940926]\n",
      "  [0.69647586]\n",
      "  [0.70413423]\n",
      "  [0.71123564]\n",
      "  [0.71831059]\n",
      "  [0.72562963]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009953605476766825\n",
      "Predicción post entrenamiento : [[0.7320228]]\n",
      "PERDIDAAAA despues: 0.0009452091762796044\n",
      "loss en el callback: 0.017437558621168137, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "ejemplar: [[0.68145055]\n",
      " [0.68940926]\n",
      " [0.69647586]\n",
      " [0.70413423]\n",
      " [0.71123564]\n",
      " [0.71831059]\n",
      " [0.72562963]\n",
      " [0.7328279 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.7386494]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[[0.68145055]\n",
      "  [0.68940926]\n",
      "  [0.69647586]\n",
      "  [0.70413423]\n",
      "  [0.71123564]\n",
      "  [0.71831059]\n",
      "  [0.72562963]\n",
      "  [0.7328279 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008342024520970881\n",
      "Predicción post entrenamiento : [[0.7389111]]\n",
      "PERDIDAAAA despues: 0.0008191558299586177\n",
      "loss en el callback: 0.002261390211060643, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "ejemplar: [[0.68940926]\n",
      " [0.69647586]\n",
      " [0.70413423]\n",
      " [0.71123564]\n",
      " [0.71831059]\n",
      " [0.72562963]\n",
      " [0.7328279 ]\n",
      " [0.73864943]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.7455391]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[[0.68940926]\n",
      "  [0.69647586]\n",
      "  [0.70413423]\n",
      "  [0.71123564]\n",
      "  [0.71831059]\n",
      "  [0.72562963]\n",
      "  [0.7328279 ]\n",
      "  [0.73864943]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 9.205557580571622e-05\n",
      "Predicción post entrenamiento : [[0.7457322]]\n",
      "PERDIDAAAA despues: 8.838820940582082e-05\n",
      "loss en el callback: 0.0012654896127060056, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "ejemplar: [[0.69647586]\n",
      " [0.70413423]\n",
      " [0.71123564]\n",
      " [0.71831059]\n",
      " [0.72562963]\n",
      " [0.7328279 ]\n",
      " [0.73864943]\n",
      " [0.74553913]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.75216573]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[[0.69647586]\n",
      "  [0.70413423]\n",
      "  [0.71123564]\n",
      "  [0.71831059]\n",
      "  [0.72562963]\n",
      "  [0.7328279 ]\n",
      "  [0.73864943]\n",
      "  [0.74553913]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.049108949606307e-05\n",
      "Predicción post entrenamiento : [[0.7524611]]\n",
      "PERDIDAAAA despues: 5.4775529861217365e-05\n",
      "loss en el callback: 0.0037407020572572947, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "ejemplar: [[0.70413423]\n",
      " [0.71123564]\n",
      " [0.71831059]\n",
      " [0.72562963]\n",
      " [0.7328279 ]\n",
      " [0.73864943]\n",
      " [0.74553913]\n",
      " [0.75216573]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.7589072]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[[0.70413423]\n",
      "  [0.71123564]\n",
      "  [0.71831059]\n",
      "  [0.72562963]\n",
      "  [0.7328279 ]\n",
      "  [0.73864943]\n",
      "  [0.74553913]\n",
      "  [0.75216573]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.7239926061592996e-05\n",
      "Predicción post entrenamiento : [[0.75878596]]\n",
      "PERDIDAAAA despues: 4.5588087232317775e-05\n",
      "loss en el callback: 0.000477596593555063, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "ejemplar: [[0.71123564]\n",
      " [0.71831059]\n",
      " [0.72562963]\n",
      " [0.7328279 ]\n",
      " [0.73864943]\n",
      " [0.74553913]\n",
      " [0.75216573]\n",
      " [0.7589072 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.7650531]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[[0.71123564]\n",
      "  [0.71831059]\n",
      "  [0.72562963]\n",
      "  [0.7328279 ]\n",
      "  [0.73864943]\n",
      "  [0.74553913]\n",
      "  [0.75216573]\n",
      "  [0.7589072 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003052640240639448\n",
      "Predicción post entrenamiento : [[0.7638261]]\n",
      "PERDIDAAAA despues: 0.0029185584280639887\n",
      "loss en el callback: 0.03617020323872566, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "ejemplar: [[0.71831059]\n",
      " [0.72562963]\n",
      " [0.7328279 ]\n",
      " [0.73864943]\n",
      " [0.74553913]\n",
      " [0.75216573]\n",
      " [0.7589072 ]\n",
      " [0.76505309]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.77002674]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[[0.71831059]\n",
      "  [0.72562963]\n",
      "  [0.7328279 ]\n",
      "  [0.73864943]\n",
      "  [0.74553913]\n",
      "  [0.75216573]\n",
      "  [0.7589072 ]\n",
      "  [0.76505309]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006335634272545576\n",
      "Predicción post entrenamiento : [[0.7691909]]\n",
      "PERDIDAAAA despues: 0.006203273311257362\n",
      "loss en el callback: 0.02116655744612217, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "ejemplar: [[0.72562963]\n",
      " [0.7328279 ]\n",
      " [0.73864943]\n",
      " [0.74553913]\n",
      " [0.75216573]\n",
      " [0.7589072 ]\n",
      " [0.76505309]\n",
      " [0.77002674]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.7752968]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[[0.72562963]\n",
      "  [0.7328279 ]\n",
      "  [0.73864943]\n",
      "  [0.74553913]\n",
      "  [0.75216573]\n",
      "  [0.7589072 ]\n",
      "  [0.76505309]\n",
      "  [0.77002674]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004384014755487442\n",
      "Predicción post entrenamiento : [[0.77614367]]\n",
      "PERDIDAAAA despues: 0.00047458193148486316\n",
      "loss en el callback: 0.04624457284808159, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "ejemplar: [[0.7328279 ]\n",
      " [0.73864943]\n",
      " [0.74553913]\n",
      " [0.75216573]\n",
      " [0.7589072 ]\n",
      " [0.76505309]\n",
      " [0.77002674]\n",
      " [0.77529681]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.78204143]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[[0.7328279 ]\n",
      "  [0.73864943]\n",
      "  [0.74553913]\n",
      "  [0.75216573]\n",
      "  [0.7589072 ]\n",
      "  [0.76505309]\n",
      "  [0.77002674]\n",
      "  [0.77529681]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0035809141118079424\n",
      "Predicción post entrenamiento : [[0.78148234]]\n",
      "PERDIDAAAA despues: 0.003514313604682684\n",
      "loss en el callback: 0.010380423627793789, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "ejemplar: [[0.73864943]\n",
      " [0.74553913]\n",
      " [0.75216573]\n",
      " [0.7589072 ]\n",
      " [0.76505309]\n",
      " [0.77002674]\n",
      " [0.77529681]\n",
      " [0.78204143]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.7871462]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[[0.73864943]\n",
      "  [0.74553913]\n",
      "  [0.75216573]\n",
      "  [0.7589072 ]\n",
      "  [0.76505309]\n",
      "  [0.77002674]\n",
      "  [0.77529681]\n",
      "  [0.78204143]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0037653131876140833\n",
      "Predicción post entrenamiento : [[0.7875625]]\n",
      "PERDIDAAAA despues: 0.0037143989466130733\n",
      "loss en el callback: 0.006291919853538275, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "ejemplar: [[0.74553913]\n",
      " [0.75216573]\n",
      " [0.7589072 ]\n",
      " [0.76505309]\n",
      " [0.77002674]\n",
      " [0.77529681]\n",
      " [0.78204143]\n",
      " [0.78714621]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.79333436]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[[0.74553913]\n",
      "  [0.75216573]\n",
      "  [0.7589072 ]\n",
      "  [0.76505309]\n",
      "  [0.77002674]\n",
      "  [0.77529681]\n",
      "  [0.78204143]\n",
      "  [0.78714621]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012572826817631721\n",
      "Predicción post entrenamiento : [[0.7936038]]\n",
      "PERDIDAAAA despues: 0.012512480840086937\n",
      "loss en el callback: 0.0023312002886086702, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "ejemplar: [[0.75216573]\n",
      " [0.7589072 ]\n",
      " [0.76505309]\n",
      " [0.77002674]\n",
      " [0.77529681]\n",
      " [0.78204143]\n",
      " [0.78714621]\n",
      " [0.79333436]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.7991605]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[[0.75216573]\n",
      "  [0.7589072 ]\n",
      "  [0.76505309]\n",
      "  [0.77002674]\n",
      "  [0.77529681]\n",
      "  [0.78204143]\n",
      "  [0.78714621]\n",
      "  [0.79333436]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0068982550874352455\n",
      "Predicción post entrenamiento : [[0.79950356]]\n",
      "PERDIDAAAA despues: 0.006841382477432489\n",
      "loss en el callback: 0.0037913478445261717, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "ejemplar: [[0.7589072 ]\n",
      " [0.76505309]\n",
      " [0.77002674]\n",
      " [0.77529681]\n",
      " [0.78204143]\n",
      " [0.78714621]\n",
      " [0.79333436]\n",
      " [0.79916048]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.80487114]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[[0.7589072 ]\n",
      "  [0.76505309]\n",
      "  [0.77002674]\n",
      "  [0.77529681]\n",
      "  [0.78204143]\n",
      "  [0.78714621]\n",
      "  [0.79333436]\n",
      "  [0.79916048]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010591814294457436\n",
      "Predicción post entrenamiento : [[0.8045614]]\n",
      "PERDIDAAAA despues: 0.010655669495463371\n",
      "loss en el callback: 0.002622474916279316, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "ejemplar: [[0.76505309]\n",
      " [0.77002674]\n",
      " [0.77529681]\n",
      " [0.78204143]\n",
      " [0.78714621]\n",
      " [0.79333436]\n",
      " [0.79916048]\n",
      " [0.80487114]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.80966985]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[[0.76505309]\n",
      "  [0.77002674]\n",
      "  [0.77529681]\n",
      "  [0.78204143]\n",
      "  [0.78714621]\n",
      "  [0.79333436]\n",
      "  [0.79916048]\n",
      "  [0.80487114]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006385262124240398\n",
      "Predicción post entrenamiento : [[0.8105115]]\n",
      "PERDIDAAAA despues: 0.006251457147300243\n",
      "loss en el callback: 0.03028559312224388, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "ejemplar: [[0.77002674]\n",
      " [0.77529681]\n",
      " [0.78204143]\n",
      " [0.78714621]\n",
      " [0.79333436]\n",
      " [0.79916048]\n",
      " [0.80487114]\n",
      " [0.80966985]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.8154981]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[[0.77002674]\n",
      "  [0.77529681]\n",
      "  [0.78204143]\n",
      "  [0.78714621]\n",
      "  [0.79333436]\n",
      "  [0.79916048]\n",
      "  [0.80487114]\n",
      "  [0.80966985]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0035232023801654577\n",
      "Predicción post entrenamiento : [[0.8152319]]\n",
      "PERDIDAAAA despues: 0.00355487409979105\n",
      "loss en el callback: 0.0020926392171531916, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "ejemplar: [[0.77529681]\n",
      " [0.78204143]\n",
      " [0.78714621]\n",
      " [0.79333436]\n",
      " [0.79916048]\n",
      " [0.80487114]\n",
      " [0.80966985]\n",
      " [0.81549811]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.82041854]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[[0.77529681]\n",
      "  [0.78204143]\n",
      "  [0.78714621]\n",
      "  [0.79333436]\n",
      "  [0.79916048]\n",
      "  [0.80487114]\n",
      "  [0.80966985]\n",
      "  [0.81549811]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008610616438090801\n",
      "Predicción post entrenamiento : [[0.8211986]]\n",
      "PERDIDAAAA despues: 0.008466457948088646\n",
      "loss en el callback: 0.02543158084154129, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "ejemplar: [[0.78204143]\n",
      " [0.78714621]\n",
      " [0.79333436]\n",
      " [0.79916048]\n",
      " [0.80487114]\n",
      " [0.80966985]\n",
      " [0.81549811]\n",
      " [0.82041854]]\n",
      "ejemplar: (8, 1)\n",
      "y: 1.0\n",
      "Predicción : [[0.8265171]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[[0.78204143]\n",
      "  [0.78714621]\n",
      "  [0.79333436]\n",
      "  [0.79916048]\n",
      "  [0.80487114]\n",
      "  [0.80966985]\n",
      "  [0.81549811]\n",
      "  [0.82041854]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03009631484746933\n",
      "Predicción post entrenamiento : [[0.82794243]]\n",
      "PERDIDAAAA despues: 0.029603807255625725\n",
      "loss en el callback: 0.0956043004989624, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "ejemplar: [[0.78714621]\n",
      " [0.79333436]\n",
      " [0.79916048]\n",
      " [0.80487114]\n",
      " [0.80966985]\n",
      " [0.81549811]\n",
      " [0.82041854]\n",
      " [0.82651711]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.83296776]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[[0.78714621]\n",
      "  [0.79333436]\n",
      "  [0.79916048]\n",
      "  [0.80487114]\n",
      "  [0.80966985]\n",
      "  [0.81549811]\n",
      "  [0.82041854]\n",
      "  [0.82651711]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018929988145828247\n",
      "Predicción post entrenamiento : [[0.83328307]]\n",
      "PERDIDAAAA despues: 0.01884332299232483\n",
      "loss en el callback: 0.003243129700422287, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "ejemplar: [[0.79333436]\n",
      " [0.79916048]\n",
      " [0.80487114]\n",
      " [0.80966985]\n",
      " [0.81549811]\n",
      " [0.82041854]\n",
      " [0.82651711]\n",
      " [0.83296776]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.8384457]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[[0.79333436]\n",
      "  [0.79916048]\n",
      "  [0.80487114]\n",
      "  [0.80966985]\n",
      "  [0.81549811]\n",
      "  [0.82041854]\n",
      "  [0.82651711]\n",
      "  [0.83296776]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002535831881687045\n",
      "Predicción post entrenamiento : [[0.8387969]]\n",
      "PERDIDAAAA despues: 0.0025005852803587914\n",
      "loss en el callback: 0.005318216513842344, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "ejemplar: [[0.79916048]\n",
      " [0.80487114]\n",
      " [0.80966985]\n",
      " [0.81549811]\n",
      " [0.82041854]\n",
      " [0.82651711]\n",
      " [0.83296776]\n",
      " [0.83844572]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.8437996]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[[0.79916048]\n",
      "  [0.80487114]\n",
      "  [0.80966985]\n",
      "  [0.81549811]\n",
      "  [0.82041854]\n",
      "  [0.82651711]\n",
      "  [0.83296776]\n",
      "  [0.83844572]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011665443889796734\n",
      "Predicción post entrenamiento : [[0.84364516]]\n",
      "PERDIDAAAA despues: 0.001177117694169283\n",
      "loss en el callback: 0.0008296259911730886, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "ejemplar: [[0.80487114]\n",
      " [0.80966985]\n",
      " [0.81549811]\n",
      " [0.82041854]\n",
      " [0.82651711]\n",
      " [0.83296776]\n",
      " [0.83844572]\n",
      " [0.84379959]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.8485749]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[[0.80487114]\n",
      "  [0.80966985]\n",
      "  [0.81549811]\n",
      "  [0.82041854]\n",
      "  [0.82651711]\n",
      "  [0.83296776]\n",
      "  [0.83844572]\n",
      "  [0.84379959]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.0298413144482765e-07\n",
      "Predicción post entrenamiento : [[0.8482744]]\n",
      "PERDIDAAAA despues: 3.86111139505374e-07\n",
      "loss en el callback: 0.003043873468413949, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "ejemplar: [[0.80966985]\n",
      " [0.81549811]\n",
      " [0.82041854]\n",
      " [0.82651711]\n",
      " [0.83296776]\n",
      " [0.83844572]\n",
      " [0.84379959]\n",
      " [0.84857488]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.8531597]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[[0.80966985]\n",
      "  [0.81549811]\n",
      "  [0.82041854]\n",
      "  [0.82651711]\n",
      "  [0.83296776]\n",
      "  [0.83844572]\n",
      "  [0.84379959]\n",
      "  [0.84857488]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003605039091780782\n",
      "Predicción post entrenamiento : [[0.8520595]]\n",
      "PERDIDAAAA despues: 0.0003199339844286442\n",
      "loss en el callback: 0.03513455018401146, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "ejemplar: [[0.81549811]\n",
      " [0.82041854]\n",
      " [0.82651711]\n",
      " [0.83296776]\n",
      " [0.83844572]\n",
      " [0.84379959]\n",
      " [0.84857488]\n",
      " [0.85315973]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.8571558]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[[0.81549811]\n",
      "  [0.82041854]\n",
      "  [0.82651711]\n",
      "  [0.83296776]\n",
      "  [0.83844572]\n",
      "  [0.84379959]\n",
      "  [0.84857488]\n",
      "  [0.85315973]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.247268407198135e-06\n",
      "Predicción post entrenamiento : [[0.85700345]]\n",
      "PERDIDAAAA despues: 3.6425276448426303e-06\n",
      "loss en el callback: 0.0009446301846764982, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "ejemplar: [[0.82041854]\n",
      " [0.82651711]\n",
      " [0.83296776]\n",
      " [0.83844572]\n",
      " [0.84379959]\n",
      " [0.84857488]\n",
      " [0.85315973]\n",
      " [0.8571558 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.86201847]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[[0.82041854]\n",
      "  [0.82651711]\n",
      "  [0.83296776]\n",
      "  [0.83844572]\n",
      "  [0.84379959]\n",
      "  [0.84857488]\n",
      "  [0.85315973]\n",
      "  [0.8571558 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00017486645083408803\n",
      "Predicción post entrenamiento : [[0.86226964]]\n",
      "PERDIDAAAA despues: 0.00016828662774059922\n",
      "loss en el callback: 0.0026886595878750086, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "ejemplar: [[0.82651711]\n",
      " [0.83296776]\n",
      " [0.83844572]\n",
      " [0.84379959]\n",
      " [0.84857488]\n",
      " [0.85315973]\n",
      " [0.8571558 ]\n",
      " [0.86201847]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.86742365]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[[0.82651711]\n",
      "  [0.83296776]\n",
      "  [0.83844572]\n",
      "  [0.84379959]\n",
      "  [0.84857488]\n",
      "  [0.85315973]\n",
      "  [0.8571558 ]\n",
      "  [0.86201847]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00010798272705869749\n",
      "Predicción post entrenamiento : [[0.8669712]]\n",
      "PERDIDAAAA despues: 9.878401760943234e-05\n",
      "loss en el callback: 0.007058902643620968, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "ejemplar: [[0.83296776]\n",
      " [0.83844572]\n",
      " [0.84379959]\n",
      " [0.84857488]\n",
      " [0.85315973]\n",
      " [0.8571558 ]\n",
      " [0.86201847]\n",
      " [0.86742365]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.8718973]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[[0.83296776]\n",
      "  [0.83844572]\n",
      "  [0.84379959]\n",
      "  [0.84857488]\n",
      "  [0.85315973]\n",
      "  [0.8571558 ]\n",
      "  [0.86201847]\n",
      "  [0.86742365]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00047694810200482607\n",
      "Predicción post entrenamiento : [[0.8704678]]\n",
      "PERDIDAAAA despues: 0.00041655355016700923\n",
      "loss en el callback: 0.05854908004403114, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "ejemplar: [[0.83844572]\n",
      " [0.84379959]\n",
      " [0.84857488]\n",
      " [0.85315973]\n",
      " [0.8571558 ]\n",
      " [0.86201847]\n",
      " [0.86742365]\n",
      " [0.87189728]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.87499654]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[[0.83844572]\n",
      "  [0.84379959]\n",
      "  [0.84857488]\n",
      "  [0.85315973]\n",
      "  [0.8571558 ]\n",
      "  [0.86201847]\n",
      "  [0.86742365]\n",
      "  [0.87189728]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010432858252897859\n",
      "Predicción post entrenamiento : [[0.8738527]]\n",
      "PERDIDAAAA despues: 0.0009707039571367204\n",
      "loss en el callback: 0.03932943940162659, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "ejemplar: [[0.84379959]\n",
      " [0.84857488]\n",
      " [0.85315973]\n",
      " [0.8571558 ]\n",
      " [0.86201847]\n",
      " [0.86742365]\n",
      " [0.87189728]\n",
      " [0.87499654]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.8781885]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[[0.84379959]\n",
      "  [0.84857488]\n",
      "  [0.85315973]\n",
      "  [0.8571558 ]\n",
      "  [0.86201847]\n",
      "  [0.86742365]\n",
      "  [0.87189728]\n",
      "  [0.87499654]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0030527457129210234\n",
      "Predicción post entrenamiento : [[0.87805]]\n",
      "PERDIDAAAA despues: 0.003037464339286089\n",
      "loss en el callback: 0.0008959366241469979, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "ejemplar: [[0.84857488]\n",
      " [0.85315973]\n",
      " [0.8571558 ]\n",
      " [0.86201847]\n",
      " [0.86742365]\n",
      " [0.87189728]\n",
      " [0.87499654]\n",
      " [0.87818849]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.8821778]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[[0.84857488]\n",
      "  [0.85315973]\n",
      "  [0.8571558 ]\n",
      "  [0.86201847]\n",
      "  [0.86742365]\n",
      "  [0.87189728]\n",
      "  [0.87499654]\n",
      "  [0.87818849]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011593216098845005\n",
      "Predicción post entrenamiento : [[0.88150436]]\n",
      "PERDIDAAAA despues: 0.011448641307651997\n",
      "loss en el callback: 0.02100270241498947, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "ejemplar: [[0.85315973]\n",
      " [0.8571558 ]\n",
      " [0.86201847]\n",
      " [0.86742365]\n",
      " [0.87189728]\n",
      " [0.87499654]\n",
      " [0.87818849]\n",
      " [0.88217783]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.8855395]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[[0.85315973]\n",
      "  [0.8571558 ]\n",
      "  [0.86201847]\n",
      "  [0.86742365]\n",
      "  [0.87189728]\n",
      "  [0.87499654]\n",
      "  [0.87818849]\n",
      "  [0.88217783]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010271281003952026\n",
      "Predicción post entrenamiento : [[0.885309]]\n",
      "PERDIDAAAA despues: 0.010224614292383194\n",
      "loss en el callback: 0.0027132241521030664, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "ejemplar: [[0.8571558 ]\n",
      " [0.86201847]\n",
      " [0.86742365]\n",
      " [0.87189728]\n",
      " [0.87499654]\n",
      " [0.87818849]\n",
      " [0.88217783]\n",
      " [0.88553947]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.889266]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[[0.8571558 ]\n",
      "  [0.86201847]\n",
      "  [0.86742365]\n",
      "  [0.87189728]\n",
      "  [0.87499654]\n",
      "  [0.87818849]\n",
      "  [0.88217783]\n",
      "  [0.88553947]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008715309668332338\n",
      "Predicción post entrenamiento : [[0.889454]]\n",
      "PERDIDAAAA despues: 0.0008826660923659801\n",
      "loss en el callback: 0.001915282104164362, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "ejemplar: [[0.86201847]\n",
      " [0.86742365]\n",
      " [0.87189728]\n",
      " [0.87499654]\n",
      " [0.87818849]\n",
      " [0.88217783]\n",
      " [0.88553947]\n",
      " [0.88926601]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.8934605]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[[0.86201847]\n",
      "  [0.86742365]\n",
      "  [0.87189728]\n",
      "  [0.87499654]\n",
      "  [0.87818849]\n",
      "  [0.88217783]\n",
      "  [0.88553947]\n",
      "  [0.88926601]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015319758094847202\n",
      "Predicción post entrenamiento : [[0.893528]]\n",
      "PERDIDAAAA despues: 0.0015372622292488813\n",
      "loss en el callback: 0.00020220330043230206, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "ejemplar: [[0.86742365]\n",
      " [0.87189728]\n",
      " [0.87499654]\n",
      " [0.87818849]\n",
      " [0.88217783]\n",
      " [0.88553947]\n",
      " [0.88926601]\n",
      " [0.89346051]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.8973022]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[[0.86742365]\n",
      "  [0.87189728]\n",
      "  [0.87499654]\n",
      "  [0.87818849]\n",
      "  [0.88217783]\n",
      "  [0.88553947]\n",
      "  [0.88926601]\n",
      "  [0.89346051]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003650249447673559\n",
      "Predicción post entrenamiento : [[0.8966421]]\n",
      "PERDIDAAAA despues: 0.0035709196235984564\n",
      "loss en el callback: 0.017295056954026222, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "ejemplar: [[0.87189728]\n",
      " [0.87499654]\n",
      " [0.87818849]\n",
      " [0.88217783]\n",
      " [0.88553947]\n",
      " [0.88926601]\n",
      " [0.89346051]\n",
      " [0.89730221]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.89997095]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[[0.87189728]\n",
      "  [0.87499654]\n",
      "  [0.87818849]\n",
      "  [0.88217783]\n",
      "  [0.88553947]\n",
      "  [0.88926601]\n",
      "  [0.89346051]\n",
      "  [0.89730221]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004908414091914892\n",
      "Predicción post entrenamiento : [[0.9001057]]\n",
      "PERDIDAAAA despues: 0.004927315749228001\n",
      "loss en el callback: 0.0010419348254799843, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "ejemplar: [[0.87499654]\n",
      " [0.87818849]\n",
      " [0.88217783]\n",
      " [0.88553947]\n",
      " [0.88926601]\n",
      " [0.89346051]\n",
      " [0.89730221]\n",
      " [0.89997095]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.90319574]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[[0.87499654]\n",
      "  [0.87818849]\n",
      "  [0.88217783]\n",
      "  [0.88553947]\n",
      "  [0.88926601]\n",
      "  [0.89346051]\n",
      "  [0.89730221]\n",
      "  [0.89997095]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00025417134747840464\n",
      "Predicción post entrenamiento : [[0.9022898]]\n",
      "PERDIDAAAA despues: 0.0002261059999000281\n",
      "loss en el callback: 0.027085257694125175, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "ejemplar: [[0.87818849]\n",
      " [0.88217783]\n",
      " [0.88553947]\n",
      " [0.88926601]\n",
      " [0.89346051]\n",
      " [0.89730221]\n",
      " [0.89997095]\n",
      " [0.90319574]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.90551203]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[[0.87818849]\n",
      "  [0.88217783]\n",
      "  [0.88553947]\n",
      "  [0.88926601]\n",
      "  [0.89346051]\n",
      "  [0.89730221]\n",
      "  [0.89997095]\n",
      "  [0.90319574]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002094684634357691\n",
      "Predicción post entrenamiento : [[0.9041277]]\n",
      "PERDIDAAAA despues: 0.0019698867108672857\n",
      "loss en el callback: 0.06553742289543152, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "ejemplar: [[0.88217783]\n",
      " [0.88553947]\n",
      " [0.88926601]\n",
      " [0.89346051]\n",
      " [0.89730221]\n",
      " [0.89997095]\n",
      " [0.90319574]\n",
      " [0.90551203]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.907461]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[[0.88217783]\n",
      "  [0.88553947]\n",
      "  [0.88926601]\n",
      "  [0.89346051]\n",
      "  [0.89730221]\n",
      "  [0.89997095]\n",
      "  [0.90319574]\n",
      "  [0.90551203]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004605514463037252\n",
      "Predicción post entrenamiento : [[0.9066628]]\n",
      "PERDIDAAAA despues: 0.004497818183153868\n",
      "loss en el callback: 0.0259846281260252, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "ejemplar: [[0.88553947]\n",
      " [0.88926601]\n",
      " [0.89346051]\n",
      " [0.89730221]\n",
      " [0.89997095]\n",
      " [0.90319574]\n",
      " [0.90551203]\n",
      " [0.90746099]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.90986156]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[[0.88553947]\n",
      "  [0.88926601]\n",
      "  [0.89346051]\n",
      "  [0.89730221]\n",
      "  [0.89997095]\n",
      "  [0.90319574]\n",
      "  [0.90551203]\n",
      "  [0.90746099]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01589033007621765\n",
      "Predicción post entrenamiento : [[0.909399]]\n",
      "PERDIDAAAA despues: 0.015773918479681015\n",
      "loss en el callback: 0.009446004405617714, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "ejemplar: [[0.88926601]\n",
      " [0.89346051]\n",
      " [0.89730221]\n",
      " [0.89997095]\n",
      " [0.90319574]\n",
      " [0.90551203]\n",
      " [0.90746099]\n",
      " [0.90986156]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.91259015]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[[0.88926601]\n",
      "  [0.89346051]\n",
      "  [0.89730221]\n",
      "  [0.89997095]\n",
      "  [0.90319574]\n",
      "  [0.90551203]\n",
      "  [0.90746099]\n",
      "  [0.90986156]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00889299064874649\n",
      "Predicción post entrenamiento : [[0.9128465]]\n",
      "PERDIDAAAA despues: 0.008941407315433025\n",
      "loss en el callback: 0.004290096461772919, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "ejemplar: [[0.89346051]\n",
      " [0.89730221]\n",
      " [0.89997095]\n",
      " [0.90319574]\n",
      " [0.90551203]\n",
      " [0.90746099]\n",
      " [0.90986156]\n",
      " [0.91259015]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.9158788]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[[0.89346051]\n",
      "  [0.89730221]\n",
      "  [0.89997095]\n",
      "  [0.90319574]\n",
      "  [0.90551203]\n",
      "  [0.90746099]\n",
      "  [0.90986156]\n",
      "  [0.91259015]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015553229488432407\n",
      "Predicción post entrenamiento : [[0.91400194]]\n",
      "PERDIDAAAA despues: 0.015088622458279133\n",
      "loss en el callback: 0.11849482357501984, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "ejemplar: [[0.89730221]\n",
      " [0.89997095]\n",
      " [0.90319574]\n",
      " [0.90551203]\n",
      " [0.90746099]\n",
      " [0.90986156]\n",
      " [0.91259015]\n",
      " [0.91587877]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.91667837]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[[0.89730221]\n",
      "  [0.89997095]\n",
      "  [0.90319574]\n",
      "  [0.90551203]\n",
      "  [0.90746099]\n",
      "  [0.90986156]\n",
      "  [0.91259015]\n",
      "  [0.91587877]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.024373585358262062\n",
      "Predicción post entrenamiento : [[0.9163767]]\n",
      "PERDIDAAAA despues: 0.024279486387968063\n",
      "loss en el callback: 0.00495851831510663, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "ejemplar: [[0.89997095]\n",
      " [0.90319574]\n",
      " [0.90551203]\n",
      " [0.90746099]\n",
      " [0.90986156]\n",
      " [0.91259015]\n",
      " [0.91587877]\n",
      " [0.91667837]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.9187244]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[[0.89997095]\n",
      "  [0.90319574]\n",
      "  [0.90551203]\n",
      "  [0.90746099]\n",
      "  [0.90986156]\n",
      "  [0.91259015]\n",
      "  [0.91587877]\n",
      "  [0.91667837]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016172397881746292\n",
      "Predicción post entrenamiento : [[0.9181607]]\n",
      "PERDIDAAAA despues: 0.01602933183312416\n",
      "loss en el callback: 0.01524706557393074, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "ejemplar: [[0.90319574]\n",
      " [0.90551203]\n",
      " [0.90746099]\n",
      " [0.90986156]\n",
      " [0.91259015]\n",
      " [0.91587877]\n",
      " [0.91667837]\n",
      " [0.91872442]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9204574]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[[0.90319574]\n",
      "  [0.90551203]\n",
      "  [0.90746099]\n",
      "  [0.90986156]\n",
      "  [0.91259015]\n",
      "  [0.91587877]\n",
      "  [0.91667837]\n",
      "  [0.91872442]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0230320505797863\n",
      "Predicción post entrenamiento : [[0.9194346]]\n",
      "PERDIDAAAA despues: 0.022722646594047546\n",
      "loss en el callback: 0.044704895466566086, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "ejemplar: [[0.90551203]\n",
      " [0.90746099]\n",
      " [0.90986156]\n",
      " [0.91259015]\n",
      " [0.91587877]\n",
      " [0.91667837]\n",
      " [0.91872442]\n",
      " [0.92045742]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9214926]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[[0.90551203]\n",
      "  [0.90746099]\n",
      "  [0.90986156]\n",
      "  [0.91259015]\n",
      "  [0.91587877]\n",
      "  [0.91667837]\n",
      "  [0.91872442]\n",
      "  [0.92045742]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.023347318172454834\n",
      "Predicción post entrenamiento : [[0.92126983]]\n",
      "PERDIDAAAA despues: 0.023279299959540367\n",
      "loss en el callback: 0.003048143582418561, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "ejemplar: [[0.90746099]\n",
      " [0.90986156]\n",
      " [0.91259015]\n",
      " [0.91587877]\n",
      " [0.91667837]\n",
      " [0.91872442]\n",
      " [0.92045742]\n",
      " [0.92149258]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.9233028]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[[0.90746099]\n",
      "  [0.90986156]\n",
      "  [0.91259015]\n",
      "  [0.91587877]\n",
      "  [0.91667837]\n",
      "  [0.91872442]\n",
      "  [0.92045742]\n",
      "  [0.92149258]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015472295694053173\n",
      "Predicción post entrenamiento : [[0.922714]]\n",
      "PERDIDAAAA despues: 0.015326154418289661\n",
      "loss en el callback: 0.017800448462367058, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "ejemplar: [[0.90986156]\n",
      " [0.91259015]\n",
      " [0.91587877]\n",
      " [0.91667837]\n",
      " [0.91872442]\n",
      " [0.92045742]\n",
      " [0.92149258]\n",
      " [0.92330283]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.92480105]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[[0.90986156]\n",
      "  [0.91259015]\n",
      "  [0.91587877]\n",
      "  [0.91667837]\n",
      "  [0.91872442]\n",
      "  [0.92045742]\n",
      "  [0.92149258]\n",
      "  [0.92330283]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018170272931456566\n",
      "Predicción post entrenamiento : [[0.92330796]]\n",
      "PERDIDAAAA despues: 0.01776997186243534\n",
      "loss en el callback: 0.08107610791921616, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "ejemplar: [[0.91259015]\n",
      " [0.91587877]\n",
      " [0.91667837]\n",
      " [0.91872442]\n",
      " [0.92045742]\n",
      " [0.92149258]\n",
      " [0.92330283]\n",
      " [0.92480105]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.92529213]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[[0.91259015]\n",
      "  [0.91587877]\n",
      "  [0.91667837]\n",
      "  [0.91872442]\n",
      "  [0.92045742]\n",
      "  [0.92149258]\n",
      "  [0.92330283]\n",
      "  [0.92480105]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.027265166863799095\n",
      "Predicción post entrenamiento : [[0.9251509]]\n",
      "PERDIDAAAA despues: 0.027218535542488098\n",
      "loss en el callback: 0.0012998103629797697, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "ejemplar: [[0.91587877]\n",
      " [0.91667837]\n",
      " [0.91872442]\n",
      " [0.92045742]\n",
      " [0.92149258]\n",
      " [0.92330283]\n",
      " [0.92480105]\n",
      " [0.92529213]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.9268871]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[[0.91587877]\n",
      "  [0.91667837]\n",
      "  [0.91872442]\n",
      "  [0.92045742]\n",
      "  [0.92149258]\n",
      "  [0.92330283]\n",
      "  [0.92480105]\n",
      "  [0.92529213]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05831926688551903\n",
      "Predicción post entrenamiento : [[0.9259645]]\n",
      "PERDIDAAAA despues: 0.05787450447678566\n",
      "loss en el callback: 0.051006682217121124, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "ejemplar: [[0.91667837]\n",
      " [0.91872442]\n",
      " [0.92045742]\n",
      " [0.92149258]\n",
      " [0.92330283]\n",
      " [0.92480105]\n",
      " [0.92529213]\n",
      " [0.92688709]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.92722994]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[[0.91667837]\n",
      "  [0.91872442]\n",
      "  [0.92045742]\n",
      "  [0.92149258]\n",
      "  [0.92330283]\n",
      "  [0.92480105]\n",
      "  [0.92529213]\n",
      "  [0.92688709]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10370858758687973\n",
      "Predicción post entrenamiento : [[0.926215]]\n",
      "PERDIDAAAA despues: 0.1030559092760086\n",
      "loss en el callback: 0.06197471171617508, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "ejemplar: [[0.91872442]\n",
      " [0.92045742]\n",
      " [0.92149258]\n",
      " [0.92330283]\n",
      " [0.92480105]\n",
      " [0.92529213]\n",
      " [0.92688709]\n",
      " [0.92722994]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9276541]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[[0.91872442]\n",
      "  [0.92045742]\n",
      "  [0.92149258]\n",
      "  [0.92330283]\n",
      "  [0.92480105]\n",
      "  [0.92529213]\n",
      "  [0.92688709]\n",
      "  [0.92722994]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06906148046255112\n",
      "Predicción post entrenamiento : [[0.92588204]]\n",
      "PERDIDAAAA despues: 0.06813324987888336\n",
      "loss en el callback: 0.13102734088897705, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "ejemplar: [[0.92045742]\n",
      " [0.92149258]\n",
      " [0.92330283]\n",
      " [0.92480105]\n",
      " [0.92529213]\n",
      " [0.92688709]\n",
      " [0.92722994]\n",
      " [0.92765409]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.9271305]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[[0.92045742]\n",
      "  [0.92149258]\n",
      "  [0.92330283]\n",
      "  [0.92480105]\n",
      "  [0.92529213]\n",
      "  [0.92688709]\n",
      "  [0.92722994]\n",
      "  [0.92765409]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0480772890150547\n",
      "Predicción post entrenamiento : [[0.92614996]]\n",
      "PERDIDAAAA despues: 0.047648247331380844\n",
      "loss en el callback: 0.05217638611793518, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "ejemplar: [[0.92149258]\n",
      " [0.92330283]\n",
      " [0.92480105]\n",
      " [0.92529213]\n",
      " [0.92688709]\n",
      " [0.92722994]\n",
      " [0.92765409]\n",
      " [0.92713052]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9272414]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[[0.92149258]\n",
      "  [0.92330283]\n",
      "  [0.92480105]\n",
      "  [0.92529213]\n",
      "  [0.92688709]\n",
      "  [0.92722994]\n",
      "  [0.92765409]\n",
      "  [0.92713052]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.068844735622406\n",
      "Predicción post entrenamiento : [[0.925504]]\n",
      "PERDIDAAAA despues: 0.06793604791164398\n",
      "loss en el callback: 0.13632342219352722, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "ejemplar: [[0.92330283]\n",
      " [0.92480105]\n",
      " [0.92529213]\n",
      " [0.92688709]\n",
      " [0.92722994]\n",
      " [0.92765409]\n",
      " [0.92713052]\n",
      " [0.92724138]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.9265832]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[[0.92330283]\n",
      "  [0.92480105]\n",
      "  [0.92529213]\n",
      "  [0.92688709]\n",
      "  [0.92722994]\n",
      "  [0.92765409]\n",
      "  [0.92713052]\n",
      "  [0.92724138]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04632438346743584\n",
      "Predicción post entrenamiento : [[0.926664]]\n",
      "PERDIDAAAA despues: 0.04635918140411377\n",
      "loss en el callback: 0.0005895073991268873, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "ejemplar: [[0.92480105]\n",
      " [0.92529213]\n",
      " [0.92688709]\n",
      " [0.92722994]\n",
      " [0.92765409]\n",
      " [0.92713052]\n",
      " [0.92724138]\n",
      " [0.92658317]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.9274586]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[[0.92480105]\n",
      "  [0.92529213]\n",
      "  [0.92688709]\n",
      "  [0.92722994]\n",
      "  [0.92765409]\n",
      "  [0.92713052]\n",
      "  [0.92724138]\n",
      "  [0.92658317]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06260088831186295\n",
      "Predicción post entrenamiento : [[0.9260657]]\n",
      "PERDIDAAAA despues: 0.06190581992268562\n",
      "loss en el callback: 0.10632001608610153, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "ejemplar: [[0.92529213]\n",
      " [0.92688709]\n",
      " [0.92722994]\n",
      " [0.92765409]\n",
      " [0.92713052]\n",
      " [0.92724138]\n",
      " [0.92658317]\n",
      " [0.92745858]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.92659]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[[0.92529213]\n",
      "  [0.92688709]\n",
      "  [0.92722994]\n",
      "  [0.92765409]\n",
      "  [0.92713052]\n",
      "  [0.92724138]\n",
      "  [0.92658317]\n",
      "  [0.92745858]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.027054425328969955\n",
      "Predicción post entrenamiento : [[0.92575496]]\n",
      "PERDIDAAAA despues: 0.026780417189002037\n",
      "loss en el callback: 0.040585197508335114, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "ejemplar: [[0.92688709]\n",
      " [0.92722994]\n",
      " [0.92765409]\n",
      " [0.92713052]\n",
      " [0.92724138]\n",
      " [0.92658317]\n",
      " [0.92745858]\n",
      " [0.92659003]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.9262316]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[[0.92688709]\n",
      "  [0.92722994]\n",
      "  [0.92765409]\n",
      "  [0.92713052]\n",
      "  [0.92724138]\n",
      "  [0.92658317]\n",
      "  [0.92745858]\n",
      "  [0.92659003]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014203892089426517\n",
      "Predicción post entrenamiento : [[0.9263005]]\n",
      "PERDIDAAAA despues: 0.014220320619642735\n",
      "loss en el callback: 0.0003459972213022411, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "ejemplar: [[0.92722994]\n",
      " [0.92765409]\n",
      " [0.92713052]\n",
      " [0.92724138]\n",
      " [0.92658317]\n",
      " [0.92745858]\n",
      " [0.92659003]\n",
      " [0.92623162]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.9263725]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[[0.92722994]\n",
      "  [0.92765409]\n",
      "  [0.92713052]\n",
      "  [0.92724138]\n",
      "  [0.92658317]\n",
      "  [0.92745858]\n",
      "  [0.92659003]\n",
      "  [0.92623162]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012362014502286911\n",
      "Predicción post entrenamiento : [[0.92548954]]\n",
      "PERDIDAAAA despues: 0.012166446074843407\n",
      "loss en el callback: 0.04080680385231972, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "ejemplar: [[0.92765409]\n",
      " [0.92713052]\n",
      " [0.92724138]\n",
      " [0.92658317]\n",
      " [0.92745858]\n",
      " [0.92659003]\n",
      " [0.92623162]\n",
      " [0.92637253]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.92545056]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[[0.92765409]\n",
      "  [0.92713052]\n",
      "  [0.92724138]\n",
      "  [0.92658317]\n",
      "  [0.92745858]\n",
      "  [0.92659003]\n",
      "  [0.92623162]\n",
      "  [0.92637253]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003691264137160033\n",
      "Predicción post entrenamiento : [[0.9245239]]\n",
      "PERDIDAAAA despues: 0.0003343774296808988\n",
      "loss en el callback: 0.03667421638965607, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "ejemplar: [[0.92713052]\n",
      " [0.92724138]\n",
      " [0.92658317]\n",
      " [0.92745858]\n",
      " [0.92659003]\n",
      " [0.92623162]\n",
      " [0.92637253]\n",
      " [0.92545056]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.9243258]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[[0.92713052]\n",
      "  [0.92724138]\n",
      "  [0.92658317]\n",
      "  [0.92745858]\n",
      "  [0.92659003]\n",
      "  [0.92623162]\n",
      "  [0.92637253]\n",
      "  [0.92545056]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012517237337306142\n",
      "Predicción post entrenamiento : [[0.92413205]]\n",
      "PERDIDAAAA despues: 0.0012654726160690188\n",
      "loss en el callback: 0.0018559610471129417, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "ejemplar: [[0.92724138]\n",
      " [0.92658317]\n",
      " [0.92745858]\n",
      " [0.92659003]\n",
      " [0.92623162]\n",
      " [0.92637253]\n",
      " [0.92545056]\n",
      " [0.92432582]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.92401737]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[[0.92724138]\n",
      "  [0.92658317]\n",
      "  [0.92745858]\n",
      "  [0.92659003]\n",
      "  [0.92623162]\n",
      "  [0.92637253]\n",
      "  [0.92545056]\n",
      "  [0.92432582]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016271141357719898\n",
      "Predicción post entrenamiento : [[0.92442626]]\n",
      "PERDIDAAAA despues: 0.0015942943282425404\n",
      "loss en el callback: 0.011185248382389545, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "ejemplar: [[0.92658317]\n",
      " [0.92745858]\n",
      " [0.92659003]\n",
      " [0.92623162]\n",
      " [0.92637253]\n",
      " [0.92545056]\n",
      " [0.92432582]\n",
      " [0.92401737]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.92420727]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[[0.92658317]\n",
      "  [0.92745858]\n",
      "  [0.92659003]\n",
      "  [0.92623162]\n",
      "  [0.92637253]\n",
      "  [0.92545056]\n",
      "  [0.92432582]\n",
      "  [0.92401737]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001308946404606104\n",
      "Predicción post entrenamiento : [[0.92464197]]\n",
      "PERDIDAAAA despues: 0.0013405893696472049\n",
      "loss en el callback: 0.015520703047513962, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "ejemplar: [[0.92745858]\n",
      " [0.92659003]\n",
      " [0.92623162]\n",
      " [0.92637253]\n",
      " [0.92545056]\n",
      " [0.92432582]\n",
      " [0.92401737]\n",
      " [0.92420727]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.92451465]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[[0.92745858]\n",
      "  [0.92659003]\n",
      "  [0.92623162]\n",
      "  [0.92637253]\n",
      "  [0.92545056]\n",
      "  [0.92432582]\n",
      "  [0.92401737]\n",
      "  [0.92420727]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010136202909052372\n",
      "Predicción post entrenamiento : [[0.9251167]]\n",
      "PERDIDAAAA despues: 0.0010523191886022687\n",
      "loss en el callback: 0.03820652887225151, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "ejemplar: [[0.92659003]\n",
      " [0.92623162]\n",
      " [0.92637253]\n",
      " [0.92545056]\n",
      " [0.92432582]\n",
      " [0.92401737]\n",
      " [0.92420727]\n",
      " [0.92451465]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.9246419]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[[0.92659003]\n",
      "  [0.92623162]\n",
      "  [0.92637253]\n",
      "  [0.92545056]\n",
      "  [0.92432582]\n",
      "  [0.92401737]\n",
      "  [0.92420727]\n",
      "  [0.92451465]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0024403335992246866\n",
      "Predicción post entrenamiento : [[0.9241547]]\n",
      "PERDIDAAAA despues: 0.0023924352135509253\n",
      "loss en el callback: 0.013516551814973354, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "ejemplar: [[0.92623162]\n",
      " [0.92637253]\n",
      " [0.92545056]\n",
      " [0.92432582]\n",
      " [0.92401737]\n",
      " [0.92420727]\n",
      " [0.92451465]\n",
      " [0.92464191]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.9238009]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[[0.92623162]\n",
      "  [0.92637253]\n",
      "  [0.92545056]\n",
      "  [0.92432582]\n",
      "  [0.92401737]\n",
      "  [0.92420727]\n",
      "  [0.92451465]\n",
      "  [0.92464191]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00532431248575449\n",
      "Predicción post entrenamiento : [[0.92340785]]\n",
      "PERDIDAAAA despues: 0.005267109256237745\n",
      "loss en el callback: 0.00935335922986269, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "ejemplar: [[0.92637253]\n",
      " [0.92545056]\n",
      " [0.92432582]\n",
      " [0.92401737]\n",
      " [0.92420727]\n",
      " [0.92451465]\n",
      " [0.92464191]\n",
      " [0.92380089]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.9230537]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[[0.92637253]\n",
      "  [0.92545056]\n",
      "  [0.92432582]\n",
      "  [0.92401737]\n",
      "  [0.92420727]\n",
      "  [0.92451465]\n",
      "  [0.92464191]\n",
      "  [0.92380089]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005499393213540316\n",
      "Predicción post entrenamiento : [[0.92221624]]\n",
      "PERDIDAAAA despues: 0.0053758881986141205\n",
      "loss en el callback: 0.03910255432128906, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "ejemplar: [[0.92545056]\n",
      " [0.92432582]\n",
      " [0.92401737]\n",
      " [0.92420727]\n",
      " [0.92451465]\n",
      " [0.92464191]\n",
      " [0.92380089]\n",
      " [0.92305368]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.9217259]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[[0.92545056]\n",
      "  [0.92432582]\n",
      "  [0.92401737]\n",
      "  [0.92420727]\n",
      "  [0.92451465]\n",
      "  [0.92464191]\n",
      "  [0.92380089]\n",
      "  [0.92305368]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016558171482756734\n",
      "Predicción post entrenamiento : [[0.9216243]]\n",
      "PERDIDAAAA despues: 0.0016640981193631887\n",
      "loss en el callback: 0.0006689683650620282, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "ejemplar: [[0.92432582]\n",
      " [0.92401737]\n",
      " [0.92420727]\n",
      " [0.92451465]\n",
      " [0.92464191]\n",
      " [0.92380089]\n",
      " [0.92305368]\n",
      " [0.92172593]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.9212937]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[[0.92432582]\n",
      "  [0.92401737]\n",
      "  [0.92420727]\n",
      "  [0.92451465]\n",
      "  [0.92464191]\n",
      "  [0.92380089]\n",
      "  [0.92305368]\n",
      "  [0.92172593]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002166739432141185\n",
      "Predicción post entrenamiento : [[0.92122614]]\n",
      "PERDIDAAAA despues: 0.0021730309817939997\n",
      "loss en el callback: 0.0002734254230745137, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "ejemplar: [[0.92401737]\n",
      " [0.92420727]\n",
      " [0.92451465]\n",
      " [0.92464191]\n",
      " [0.92380089]\n",
      " [0.92305368]\n",
      " [0.92172593]\n",
      " [0.92129368]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.92112905]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[[0.92401737]\n",
      "  [0.92420727]\n",
      "  [0.92451465]\n",
      "  [0.92464191]\n",
      "  [0.92380089]\n",
      "  [0.92305368]\n",
      "  [0.92172593]\n",
      "  [0.92129368]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003838319389615208\n",
      "Predicción post entrenamiento : [[0.9213118]]\n",
      "PERDIDAAAA despues: 0.0003767047019209713\n",
      "loss en el callback: 0.0024440863635390997, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "ejemplar: [[0.92420727]\n",
      " [0.92451465]\n",
      " [0.92464191]\n",
      " [0.92380089]\n",
      " [0.92305368]\n",
      " [0.92172593]\n",
      " [0.92129368]\n",
      " [0.92112905]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.9212231]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[[0.92420727]\n",
      "  [0.92451465]\n",
      "  [0.92464191]\n",
      "  [0.92380089]\n",
      "  [0.92305368]\n",
      "  [0.92172593]\n",
      "  [0.92129368]\n",
      "  [0.92112905]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0026284242048859596\n",
      "Predicción post entrenamiento : [[0.92095375]]\n",
      "PERDIDAAAA despues: 0.0026561152189970016\n",
      "loss en el callback: 0.004505488555878401, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "ejemplar: [[0.92451465]\n",
      " [0.92464191]\n",
      " [0.92380089]\n",
      " [0.92305368]\n",
      " [0.92172593]\n",
      " [0.92129368]\n",
      " [0.92112905]\n",
      " [0.9212231 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.92070967]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[[0.92451465]\n",
      "  [0.92464191]\n",
      "  [0.92380089]\n",
      "  [0.92305368]\n",
      "  [0.92172593]\n",
      "  [0.92129368]\n",
      "  [0.92112905]\n",
      "  [0.9212231 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0058050332590937614\n",
      "Predicción post entrenamiento : [[0.92160505]]\n",
      "PERDIDAAAA despues: 0.005669395439326763\n",
      "loss en el callback: 0.0866147130727768, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "ejemplar: [[0.92464191]\n",
      " [0.92380089]\n",
      " [0.92305368]\n",
      " [0.92172593]\n",
      " [0.92129368]\n",
      " [0.92112905]\n",
      " [0.9212231 ]\n",
      " [0.92070967]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.9211396]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[[0.92464191]\n",
      "  [0.92380089]\n",
      "  [0.92305368]\n",
      "  [0.92172593]\n",
      "  [0.92129368]\n",
      "  [0.92112905]\n",
      "  [0.9212231 ]\n",
      "  [0.92070967]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009025284671224654\n",
      "Predicción post entrenamiento : [[0.9211538]]\n",
      "PERDIDAAAA despues: 0.0009016763651743531\n",
      "loss en el callback: 1.3998396752867848e-05, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "ejemplar: [[0.92380089]\n",
      " [0.92305368]\n",
      " [0.92172593]\n",
      " [0.92129368]\n",
      " [0.92112905]\n",
      " [0.9212231 ]\n",
      " [0.92070967]\n",
      " [0.9211396 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.92049825]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[[0.92380089]\n",
      "  [0.92305368]\n",
      "  [0.92172593]\n",
      "  [0.92129368]\n",
      "  [0.92112905]\n",
      "  [0.9212231 ]\n",
      "  [0.92070967]\n",
      "  [0.9211396 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006111497641541064\n",
      "Predicción post entrenamiento : [[0.9198973]]\n",
      "PERDIDAAAA despues: 0.0005817989585921168\n",
      "loss en el callback: 0.020833443850278854, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "ejemplar: [[0.92305368]\n",
      " [0.92172593]\n",
      " [0.92129368]\n",
      " [0.92112905]\n",
      " [0.9212231 ]\n",
      " [0.92070967]\n",
      " [0.9211396 ]\n",
      " [0.92049825]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.9193279]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[[0.92305368]\n",
      "  [0.92172593]\n",
      "  [0.92129368]\n",
      "  [0.92112905]\n",
      "  [0.9212231 ]\n",
      "  [0.92070967]\n",
      "  [0.9211396 ]\n",
      "  [0.92049825]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014353959122672677\n",
      "Predicción post entrenamiento : [[0.9184913]]\n",
      "PERDIDAAAA despues: 0.001372703118249774\n",
      "loss en el callback: 0.03772683069109917, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "ejemplar: [[0.92172593]\n",
      " [0.92129368]\n",
      " [0.92112905]\n",
      " [0.9212231 ]\n",
      " [0.92070967]\n",
      " [0.9211396 ]\n",
      " [0.92049825]\n",
      " [0.91932791]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.91800857]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[[0.92172593]\n",
      "  [0.92129368]\n",
      "  [0.92112905]\n",
      "  [0.9212231 ]\n",
      "  [0.92070967]\n",
      "  [0.9211396 ]\n",
      "  [0.92049825]\n",
      "  [0.91932791]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.503485560140689e-07\n",
      "Predicción post entrenamiento : [[0.91794175]]\n",
      "PERDIDAAAA despues: 7.315836683119414e-07\n",
      "loss en el callback: 0.00032086859573610127, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "ejemplar: [[0.92129368]\n",
      " [0.92112905]\n",
      " [0.9212231 ]\n",
      " [0.92070967]\n",
      " [0.9211396 ]\n",
      " [0.92049825]\n",
      " [0.91932791]\n",
      " [0.91800857]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.9177281]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[[0.92129368]\n",
      "  [0.92112905]\n",
      "  [0.9212231 ]\n",
      "  [0.92070967]\n",
      "  [0.9211396 ]\n",
      "  [0.92049825]\n",
      "  [0.91932791]\n",
      "  [0.91800857]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.286667717678938e-06\n",
      "Predicción post entrenamiento : [[0.9180202]]\n",
      "PERDIDAAAA despues: 3.16257910526474e-06\n",
      "loss en el callback: 0.00745121156796813, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "ejemplar: [[0.92112905]\n",
      " [0.9212231 ]\n",
      " [0.92070967]\n",
      " [0.9211396 ]\n",
      " [0.92049825]\n",
      " [0.91932791]\n",
      " [0.91800857]\n",
      " [0.91772813]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.9178385]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[[0.92112905]\n",
      "  [0.9212231 ]\n",
      "  [0.92070967]\n",
      "  [0.9211396 ]\n",
      "  [0.92049825]\n",
      "  [0.91932791]\n",
      "  [0.91800857]\n",
      "  [0.91772813]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001918815658427775\n",
      "Predicción post entrenamiento : [[0.91840154]]\n",
      "PERDIDAAAA despues: 0.0018698067869991064\n",
      "loss en el callback: 0.033017031848430634, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "ejemplar: [[0.9212231 ]\n",
      " [0.92070967]\n",
      " [0.9211396 ]\n",
      " [0.92049825]\n",
      " [0.91932791]\n",
      " [0.91800857]\n",
      " [0.91772813]\n",
      " [0.91783851]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.9181608]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[[0.9212231 ]\n",
      "  [0.92070967]\n",
      "  [0.9211396 ]\n",
      "  [0.92049825]\n",
      "  [0.91932791]\n",
      "  [0.91800857]\n",
      "  [0.91772813]\n",
      "  [0.91783851]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0025068605318665504\n",
      "Predicción post entrenamiento : [[0.9186451]]\n",
      "PERDIDAAAA despues: 0.0024585998617112637\n",
      "loss en el callback: 0.02399340458214283, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "ejemplar: [[0.92070967]\n",
      " [0.9211396 ]\n",
      " [0.92049825]\n",
      " [0.91932791]\n",
      " [0.91800857]\n",
      " [0.91772813]\n",
      " [0.91783851]\n",
      " [0.9181608 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.91825336]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[[0.92070967]\n",
      "  [0.9211396 ]\n",
      "  [0.92049825]\n",
      "  [0.91932791]\n",
      "  [0.91800857]\n",
      "  [0.91772813]\n",
      "  [0.91783851]\n",
      "  [0.9181608 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001561432029120624\n",
      "Predicción post entrenamiento : [[0.9187453]]\n",
      "PERDIDAAAA despues: 0.0015227977419272065\n",
      "loss en el callback: 0.02148483507335186, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "ejemplar: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.2143067]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02829142101109028\n",
      "Predicción post entrenamiento : [[0.18977325]]\n",
      "PERDIDAAAA despues: 0.020640231668949127\n",
      "loss en el callback: 0.026025839149951935, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "ejemplar: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.2143067 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.17376144]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.2143067 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004835571628063917\n",
      "Predicción post entrenamiento : [[0.1649656]]\n",
      "PERDIDAAAA despues: 0.0036896427627652884\n",
      "loss en el callback: 0.003549988381564617, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "ejemplar: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.2143067 ]\n",
      " [0.17376144]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.16893043]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.2143067 ]\n",
      "  [0.17376144]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002168734499718994\n",
      "Predicción post entrenamiento : [[0.1669178]]\n",
      "PERDIDAAAA despues: 0.0001616457593627274\n",
      "loss en el callback: 0.0003564300131984055, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "ejemplar: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.2143067 ]\n",
      " [0.17376144]\n",
      " [0.16893043]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.17818041]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.2143067 ]\n",
      "  [0.17376144]\n",
      "  [0.16893043]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005029626190662384\n",
      "Predicción post entrenamiento : [[0.17328195]]\n",
      "PERDIDAAAA despues: 0.0003072437539231032\n",
      "loss en el callback: 0.003007072489708662, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "ejemplar: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.2143067 ]\n",
      " [0.17376144]\n",
      " [0.16893043]\n",
      " [0.17818041]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.18536839]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.2143067 ]\n",
      "  [0.17376144]\n",
      "  [0.16893043]\n",
      "  [0.17818041]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0035803040955215693\n",
      "Predicción post entrenamiento : [[0.1829613]]\n",
      "PERDIDAAAA despues: 0.00329803884960711\n",
      "loss en el callback: 0.00174421607516706, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "ejemplar: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.2143067 ]\n",
      " [0.17376144]\n",
      " [0.16893043]\n",
      " [0.17818041]\n",
      " [0.18536839]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.19187723]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.2143067 ]\n",
      "  [0.17376144]\n",
      "  [0.16893043]\n",
      "  [0.17818041]\n",
      "  [0.18536839]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0021341873798519373\n",
      "Predicción post entrenamiento : [[0.19012977]]\n",
      "PERDIDAAAA despues: 0.001975785242393613\n",
      "loss en el callback: 0.0011495620710775256, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "ejemplar: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.2143067 ]\n",
      " [0.17376144]\n",
      " [0.16893043]\n",
      " [0.17818041]\n",
      " [0.18536839]\n",
      " [0.19187723]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.20980154]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.2143067 ]\n",
      "  [0.17376144]\n",
      "  [0.16893043]\n",
      "  [0.17818041]\n",
      "  [0.18536839]\n",
      "  [0.19187723]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00401280215010047\n",
      "Predicción post entrenamiento : [[0.20649986]]\n",
      "PERDIDAAAA despues: 0.0036054025404155254\n",
      "loss en el callback: 0.005035351030528545, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "ejemplar: [[0.04223169]\n",
      " [0.2143067 ]\n",
      " [0.17376144]\n",
      " [0.16893043]\n",
      " [0.17818041]\n",
      " [0.18536839]\n",
      " [0.19187723]\n",
      " [0.20980154]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.23010734]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[[0.04223169]\n",
      "  [0.2143067 ]\n",
      "  [0.17376144]\n",
      "  [0.16893043]\n",
      "  [0.17818041]\n",
      "  [0.18536839]\n",
      "  [0.19187723]\n",
      "  [0.20980154]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001160035957582295\n",
      "Predicción post entrenamiento : [[0.22820112]]\n",
      "PERDIDAAAA despues: 0.0010338209103792906\n",
      "loss en el callback: 0.001884482684545219, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "ejemplar: [[0.2143067 ]\n",
      " [0.17376144]\n",
      " [0.16893043]\n",
      " [0.17818041]\n",
      " [0.18536839]\n",
      " [0.19187723]\n",
      " [0.20980154]\n",
      " [0.23010734]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.2560214]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[[0.2143067 ]\n",
      "  [0.17376144]\n",
      "  [0.16893043]\n",
      "  [0.17818041]\n",
      "  [0.18536839]\n",
      "  [0.19187723]\n",
      "  [0.20980154]\n",
      "  [0.23010734]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006497713038697839\n",
      "Predicción post entrenamiento : [[0.25634158]]\n",
      "PERDIDAAAA despues: 0.0006661962834186852\n",
      "loss en el callback: 8.157372212735936e-05, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "ejemplar: [[0.17376144]\n",
      " [0.16893043]\n",
      " [0.17818041]\n",
      " [0.18536839]\n",
      " [0.19187723]\n",
      " [0.20980154]\n",
      " [0.23010734]\n",
      " [0.25602141]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.25101978]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[[0.17376144]\n",
      "  [0.16893043]\n",
      "  [0.17818041]\n",
      "  [0.18536839]\n",
      "  [0.19187723]\n",
      "  [0.20980154]\n",
      "  [0.23010734]\n",
      "  [0.25602141]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018124975031241775\n",
      "Predicción post entrenamiento : [[0.24751696]]\n",
      "PERDIDAAAA despues: 0.0015265134861692786\n",
      "loss en el callback: 0.00790119357407093, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "ejemplar: [[0.16893043]\n",
      " [0.17818041]\n",
      " [0.18536839]\n",
      " [0.19187723]\n",
      " [0.20980154]\n",
      " [0.23010734]\n",
      " [0.25602141]\n",
      " [0.25101978]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.25175282]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[[0.16893043]\n",
      "  [0.17818041]\n",
      "  [0.18536839]\n",
      "  [0.19187723]\n",
      "  [0.20980154]\n",
      "  [0.23010734]\n",
      "  [0.25602141]\n",
      "  [0.25101978]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015855897217988968\n",
      "Predicción post entrenamiento : [[0.25093108]]\n",
      "PERDIDAAAA despues: 0.001520822523161769\n",
      "loss en el callback: 0.0007508491398766637, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "ejemplar: [[0.17818041]\n",
      " [0.18536839]\n",
      " [0.19187723]\n",
      " [0.20980154]\n",
      " [0.23010734]\n",
      " [0.25602141]\n",
      " [0.25101978]\n",
      " [0.25175282]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.25842327]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[[0.17818041]\n",
      "  [0.18536839]\n",
      "  [0.19187723]\n",
      "  [0.20980154]\n",
      "  [0.23010734]\n",
      "  [0.25602141]\n",
      "  [0.25101978]\n",
      "  [0.25175282]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0026152245700359344\n",
      "Predicción post entrenamiento : [[0.2581622]]\n",
      "PERDIDAAAA despues: 0.0025885908398777246\n",
      "loss en el callback: 0.0001201777413371019, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "ejemplar: [[0.18536839]\n",
      " [0.19187723]\n",
      " [0.20980154]\n",
      " [0.23010734]\n",
      " [0.25602141]\n",
      " [0.25101978]\n",
      " [0.25175282]\n",
      " [0.25842327]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.2662344]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[[0.18536839]\n",
      "  [0.19187723]\n",
      "  [0.20980154]\n",
      "  [0.23010734]\n",
      "  [0.25602141]\n",
      "  [0.25101978]\n",
      "  [0.25175282]\n",
      "  [0.25842327]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005370826460421085\n",
      "Predicción post entrenamiento : [[0.26504835]]\n",
      "PERDIDAAAA despues: 0.005198392551392317\n",
      "loss en el callback: 0.0023443850222975016, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "ejemplar: [[0.19187723]\n",
      " [0.20980154]\n",
      " [0.23010734]\n",
      " [0.25602141]\n",
      " [0.25101978]\n",
      " [0.25175282]\n",
      " [0.25842327]\n",
      " [0.2662344 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.27412945]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[[0.19187723]\n",
      "  [0.20980154]\n",
      "  [0.23010734]\n",
      "  [0.25602141]\n",
      "  [0.25101978]\n",
      "  [0.25175282]\n",
      "  [0.25842327]\n",
      "  [0.2662344 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005976296495646238\n",
      "Predicción post entrenamiento : [[0.27449042]]\n",
      "PERDIDAAAA despues: 0.006032236851751804\n",
      "loss en el callback: 0.00038846605457365513, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "ejemplar: [[0.20980154]\n",
      " [0.23010734]\n",
      " [0.25602141]\n",
      " [0.25101978]\n",
      " [0.25175282]\n",
      " [0.25842327]\n",
      " [0.2662344 ]\n",
      " [0.27412945]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.28471693]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[[0.20980154]\n",
      "  [0.23010734]\n",
      "  [0.25602141]\n",
      "  [0.25101978]\n",
      "  [0.25175282]\n",
      "  [0.25842327]\n",
      "  [0.2662344 ]\n",
      "  [0.27412945]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004964455030858517\n",
      "Predicción post entrenamiento : [[0.28294238]]\n",
      "PERDIDAAAA despues: 0.004717538598924875\n",
      "loss en el callback: 0.0053338417783379555, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "ejemplar: [[0.23010734]\n",
      " [0.25602141]\n",
      " [0.25101978]\n",
      " [0.25175282]\n",
      " [0.25842327]\n",
      " [0.2662344 ]\n",
      " [0.27412945]\n",
      " [0.28471693]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.29160944]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[[0.23010734]\n",
      "  [0.25602141]\n",
      "  [0.25101978]\n",
      "  [0.25175282]\n",
      "  [0.25842327]\n",
      "  [0.2662344 ]\n",
      "  [0.27412945]\n",
      "  [0.28471693]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012162642553448677\n",
      "Predicción post entrenamiento : [[0.2887042]]\n",
      "PERDIDAAAA despues: 0.011530276387929916\n",
      "loss en el callback: 0.014695380814373493, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "ejemplar: [[0.25602141]\n",
      " [0.25101978]\n",
      " [0.25175282]\n",
      " [0.25842327]\n",
      " [0.2662344 ]\n",
      " [0.27412945]\n",
      " [0.28471693]\n",
      " [0.29160944]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.29481098]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[[0.25602141]\n",
      "  [0.25101978]\n",
      "  [0.25175282]\n",
      "  [0.25842327]\n",
      "  [0.2662344 ]\n",
      "  [0.27412945]\n",
      "  [0.28471693]\n",
      "  [0.29160944]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014324512332677841\n",
      "Predicción post entrenamiento : [[0.29248807]]\n",
      "PERDIDAAAA despues: 0.013773872517049313\n",
      "loss en el callback: 0.012081973254680634, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "ejemplar: [[0.25101978]\n",
      " [0.25175282]\n",
      " [0.25842327]\n",
      " [0.2662344 ]\n",
      " [0.27412945]\n",
      " [0.28471693]\n",
      " [0.29160944]\n",
      " [0.29481098]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.29425517]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[[0.25101978]\n",
      "  [0.25175282]\n",
      "  [0.25842327]\n",
      "  [0.2662344 ]\n",
      "  [0.27412945]\n",
      "  [0.28471693]\n",
      "  [0.29160944]\n",
      "  [0.29481098]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02138921432197094\n",
      "Predicción post entrenamiento : [[0.28992227]]\n",
      "PERDIDAAAA despues: 0.02014061063528061\n",
      "loss en el callback: 0.03722140192985535, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "ejemplar: [[0.25175282]\n",
      " [0.25842327]\n",
      " [0.2662344 ]\n",
      " [0.27412945]\n",
      " [0.28471693]\n",
      " [0.29160944]\n",
      " [0.29481098]\n",
      " [0.29425517]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.29394707]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[[0.25175282]\n",
      "  [0.25842327]\n",
      "  [0.2662344 ]\n",
      "  [0.27412945]\n",
      "  [0.28471693]\n",
      "  [0.29160944]\n",
      "  [0.29481098]\n",
      "  [0.29425517]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018250364810228348\n",
      "Predicción post entrenamiento : [[0.292213]]\n",
      "PERDIDAAAA despues: 0.01778484508395195\n",
      "loss en el callback: 0.009761379100382328, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "ejemplar: [[0.25842327]\n",
      " [0.2662344 ]\n",
      " [0.27412945]\n",
      " [0.28471693]\n",
      " [0.29160944]\n",
      " [0.29481098]\n",
      " [0.29425517]\n",
      " [0.29394707]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.29747418]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[[0.25842327]\n",
      "  [0.2662344 ]\n",
      "  [0.27412945]\n",
      "  [0.28471693]\n",
      "  [0.29160944]\n",
      "  [0.29481098]\n",
      "  [0.29425517]\n",
      "  [0.29394707]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011088217608630657\n",
      "Predicción post entrenamiento : [[0.2958509]]\n",
      "PERDIDAAAA despues: 0.010748988948762417\n",
      "loss en el callback: 0.008148432709276676, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "ejemplar: [[0.2662344 ]\n",
      " [0.27412945]\n",
      " [0.28471693]\n",
      " [0.29160944]\n",
      " [0.29481098]\n",
      " [0.29425517]\n",
      " [0.29394707]\n",
      " [0.29747418]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.30102167]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[[0.2662344 ]\n",
      "  [0.27412945]\n",
      "  [0.28471693]\n",
      "  [0.29160944]\n",
      "  [0.29481098]\n",
      "  [0.29425517]\n",
      "  [0.29394707]\n",
      "  [0.29747418]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013235865160822868\n",
      "Predicción post entrenamiento : [[0.29837218]]\n",
      "PERDIDAAAA despues: 0.012633252888917923\n",
      "loss en el callback: 0.0200047567486763, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "ejemplar: [[0.27412945]\n",
      " [0.28471693]\n",
      " [0.29160944]\n",
      " [0.29481098]\n",
      " [0.29425517]\n",
      " [0.29394707]\n",
      " [0.29747418]\n",
      " [0.30102167]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.3030142]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[[0.27412945]\n",
      "  [0.28471693]\n",
      "  [0.29160944]\n",
      "  [0.29481098]\n",
      "  [0.29425517]\n",
      "  [0.29394707]\n",
      "  [0.29747418]\n",
      "  [0.30102167]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013005690416321158\n",
      "Predicción post entrenamiento : [[0.30205485]]\n",
      "PERDIDAAAA despues: 0.0012322954135015607\n",
      "loss en el callback: 0.0031439217273145914, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "ejemplar: [[0.28471693]\n",
      " [0.29160944]\n",
      " [0.29481098]\n",
      " [0.29425517]\n",
      " [0.29394707]\n",
      " [0.29747418]\n",
      " [0.30102167]\n",
      " [0.30301419]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.3059311]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[[0.28471693]\n",
      "  [0.29160944]\n",
      "  [0.29481098]\n",
      "  [0.29425517]\n",
      "  [0.29394707]\n",
      "  [0.29747418]\n",
      "  [0.30102167]\n",
      "  [0.30301419]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00017979618860408664\n",
      "Predicción post entrenamiento : [[0.30625576]]\n",
      "PERDIDAAAA despues: 0.00018860837735701352\n",
      "loss en el callback: 0.00047129730228334665, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "ejemplar: [[0.29160944]\n",
      " [0.29481098]\n",
      " [0.29425517]\n",
      " [0.29394707]\n",
      " [0.29747418]\n",
      " [0.30102167]\n",
      " [0.30301419]\n",
      " [0.30593109]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.30851287]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[[0.29160944]\n",
      "  [0.29481098]\n",
      "  [0.29425517]\n",
      "  [0.29394707]\n",
      "  [0.29747418]\n",
      "  [0.30102167]\n",
      "  [0.30301419]\n",
      "  [0.30593109]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.451952453469858e-05\n",
      "Predicción post entrenamiento : [[0.3094878]]\n",
      "PERDIDAAAA despues: 6.754418427590281e-05\n",
      "loss en el callback: 0.00587420491501689, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "ejemplar: [[0.29481098]\n",
      " [0.29425517]\n",
      " [0.29394707]\n",
      " [0.29747418]\n",
      " [0.30102167]\n",
      " [0.30301419]\n",
      " [0.30593109]\n",
      " [0.30851287]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.3107207]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[[0.29481098]\n",
      "  [0.29425517]\n",
      "  [0.29394707]\n",
      "  [0.29747418]\n",
      "  [0.30102167]\n",
      "  [0.30301419]\n",
      "  [0.30593109]\n",
      "  [0.30851287]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.797835688601481e-06\n",
      "Predicción post entrenamiento : [[0.31071135]]\n",
      "PERDIDAAAA despues: 3.834396920865402e-06\n",
      "loss en el callback: 3.9116460470722814e-07, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "ejemplar: [[0.29425517]\n",
      " [0.29394707]\n",
      " [0.29747418]\n",
      " [0.30102167]\n",
      " [0.30301419]\n",
      " [0.30593109]\n",
      " [0.30851287]\n",
      " [0.31072071]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.3116591]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[[0.29425517]\n",
      "  [0.29394707]\n",
      "  [0.29747418]\n",
      "  [0.30102167]\n",
      "  [0.30301419]\n",
      "  [0.30593109]\n",
      "  [0.30851287]\n",
      "  [0.31072071]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005118380067870021\n",
      "Predicción post entrenamiento : [[0.3108213]]\n",
      "PERDIDAAAA despues: 0.0004746312915813178\n",
      "loss en el callback: 0.0030035630334168673, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "ejemplar: [[0.29394707]\n",
      " [0.29747418]\n",
      " [0.30102167]\n",
      " [0.30301419]\n",
      " [0.30593109]\n",
      " [0.30851287]\n",
      " [0.31072071]\n",
      " [0.3116591 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.31235832]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[[0.29394707]\n",
      "  [0.29747418]\n",
      "  [0.30102167]\n",
      "  [0.30301419]\n",
      "  [0.30593109]\n",
      "  [0.30851287]\n",
      "  [0.31072071]\n",
      "  [0.3116591 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008715608855709434\n",
      "Predicción post entrenamiento : [[0.31186247]]\n",
      "PERDIDAAAA despues: 0.0008425295236520469\n",
      "loss en el callback: 0.0011964684817939997, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "ejemplar: [[0.29747418]\n",
      " [0.30102167]\n",
      " [0.30301419]\n",
      " [0.30593109]\n",
      " [0.30851287]\n",
      " [0.31072071]\n",
      " [0.3116591 ]\n",
      " [0.31235832]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.31401455]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[[0.29747418]\n",
      "  [0.30102167]\n",
      "  [0.30301419]\n",
      "  [0.30593109]\n",
      "  [0.30851287]\n",
      "  [0.31072071]\n",
      "  [0.3116591 ]\n",
      "  [0.31235832]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002107790351146832\n",
      "Predicción post entrenamiento : [[0.31349206]]\n",
      "PERDIDAAAA despues: 0.00019588065333664417\n",
      "loss en el callback: 0.0013348233187571168, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "ejemplar: [[0.30102167]\n",
      " [0.30301419]\n",
      " [0.30593109]\n",
      " [0.30851287]\n",
      " [0.31072071]\n",
      " [0.3116591 ]\n",
      " [0.31235832]\n",
      " [0.31401455]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.31540534]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[[0.30102167]\n",
      "  [0.30301419]\n",
      "  [0.30593109]\n",
      "  [0.30851287]\n",
      "  [0.31072071]\n",
      "  [0.3116591 ]\n",
      "  [0.31235832]\n",
      "  [0.31401455]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015636702300980687\n",
      "Predicción post entrenamiento : [[0.31540775]]\n",
      "PERDIDAAAA despues: 0.0015638611512258649\n",
      "loss en el callback: 4.26423696353595e-08, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "ejemplar: [[0.30301419]\n",
      " [0.30593109]\n",
      " [0.30851287]\n",
      " [0.31072071]\n",
      " [0.3116591 ]\n",
      " [0.31235832]\n",
      " [0.31401455]\n",
      " [0.31540534]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.31700367]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[[0.30301419]\n",
      "  [0.30593109]\n",
      "  [0.30851287]\n",
      "  [0.31072071]\n",
      "  [0.3116591 ]\n",
      "  [0.31235832]\n",
      "  [0.31401455]\n",
      "  [0.31540534]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017896241042762995\n",
      "Predicción post entrenamiento : [[0.31687117]]\n",
      "PERDIDAAAA despues: 0.0017784311203286052\n",
      "loss en el callback: 0.00012845014862250537, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "ejemplar: [[0.30593109]\n",
      " [0.30851287]\n",
      " [0.31072071]\n",
      " [0.3116591 ]\n",
      " [0.31235832]\n",
      " [0.31401455]\n",
      " [0.31540534]\n",
      " [0.31700367]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.31844378]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[[0.30593109]\n",
      "  [0.30851287]\n",
      "  [0.31072071]\n",
      "  [0.3116591 ]\n",
      "  [0.31235832]\n",
      "  [0.31401455]\n",
      "  [0.31540534]\n",
      "  [0.31700367]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018463493324816227\n",
      "Predicción post entrenamiento : [[0.31703]]\n",
      "PERDIDAAAA despues: 0.0017268516821786761\n",
      "loss en el callback: 0.010187269188463688, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "ejemplar: [[0.30851287]\n",
      " [0.31072071]\n",
      " [0.3116591 ]\n",
      " [0.31235832]\n",
      " [0.31401455]\n",
      " [0.31540534]\n",
      " [0.31700367]\n",
      " [0.31844378]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.3183312]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[[0.30851287]\n",
      "  [0.31072071]\n",
      "  [0.3116591 ]\n",
      "  [0.31235832]\n",
      "  [0.31401455]\n",
      "  [0.31540534]\n",
      "  [0.31700367]\n",
      "  [0.31844378]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002697066811379045\n",
      "Predicción post entrenamiento : [[0.31865248]]\n",
      "PERDIDAAAA despues: 0.00025925764930434525\n",
      "loss en el callback: 0.0008985326276160777, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "ejemplar: [[0.31072071]\n",
      " [0.3116591 ]\n",
      " [0.31235832]\n",
      " [0.31401455]\n",
      " [0.31540534]\n",
      " [0.31700367]\n",
      " [0.31844378]\n",
      " [0.31833121]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.31970245]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[[0.31072071]\n",
      "  [0.3116591 ]\n",
      "  [0.31235832]\n",
      "  [0.31401455]\n",
      "  [0.31540534]\n",
      "  [0.31700367]\n",
      "  [0.31844378]\n",
      "  [0.31833121]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001294102636165917\n",
      "Predicción post entrenamiento : [[0.32044962]]\n",
      "PERDIDAAAA despues: 0.0012409037444740534\n",
      "loss en el callback: 0.005071114283055067, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "ejemplar: [[0.3116591 ]\n",
      " [0.31235832]\n",
      " [0.31401455]\n",
      " [0.31540534]\n",
      " [0.31700367]\n",
      " [0.31844378]\n",
      " [0.31833121]\n",
      " [0.31970245]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.32128865]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[[0.3116591 ]\n",
      "  [0.31235832]\n",
      "  [0.31401455]\n",
      "  [0.31540534]\n",
      "  [0.31700367]\n",
      "  [0.31844378]\n",
      "  [0.31833121]\n",
      "  [0.31970245]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00023723870981484652\n",
      "Predicción post entrenamiento : [[0.32165098]]\n",
      "PERDIDAAAA despues: 0.0002262081834487617\n",
      "loss en el callback: 0.001217255718074739, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "ejemplar: [[0.31235832]\n",
      " [0.31401455]\n",
      " [0.31540534]\n",
      " [0.31700367]\n",
      " [0.31844378]\n",
      " [0.31833121]\n",
      " [0.31970245]\n",
      " [0.32128865]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.32254818]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[[0.31235832]\n",
      "  [0.31401455]\n",
      "  [0.31540534]\n",
      "  [0.31700367]\n",
      "  [0.31844378]\n",
      "  [0.31833121]\n",
      "  [0.31970245]\n",
      "  [0.32128865]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00012195799354230985\n",
      "Predicción post entrenamiento : [[0.3222229]]\n",
      "PERDIDAAAA despues: 0.00012924851034767926\n",
      "loss en el callback: 0.0007787315407767892, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "ejemplar: [[0.31401455]\n",
      " [0.31540534]\n",
      " [0.31700367]\n",
      " [0.31844378]\n",
      " [0.31833121]\n",
      " [0.31970245]\n",
      " [0.32128865]\n",
      " [0.32254818]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.3232417]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[[0.31401455]\n",
      "  [0.31540534]\n",
      "  [0.31700367]\n",
      "  [0.31844378]\n",
      "  [0.31833121]\n",
      "  [0.31970245]\n",
      "  [0.32128865]\n",
      "  [0.32254818]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003781375475227833\n",
      "Predicción post entrenamiento : [[0.32345015]]\n",
      "PERDIDAAAA despues: 0.0037557841278612614\n",
      "loss en el callback: 0.00032830165582709014, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "ejemplar: [[0.31540534]\n",
      " [0.31700367]\n",
      " [0.31844378]\n",
      " [0.31833121]\n",
      " [0.31970245]\n",
      " [0.32128865]\n",
      " [0.32254818]\n",
      " [0.32324171]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.32437283]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[[0.31540534]\n",
      "  [0.31700367]\n",
      "  [0.31844378]\n",
      "  [0.31833121]\n",
      "  [0.31970245]\n",
      "  [0.32128865]\n",
      "  [0.32254818]\n",
      "  [0.32324171]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06087256222963333\n",
      "Predicción post entrenamiento : [[0.3268426]]\n",
      "PERDIDAAAA despues: 0.05965995416045189\n",
      "loss en el callback: 0.05650974065065384, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "ejemplar: [[0.31700367]\n",
      " [0.31844378]\n",
      " [0.31833121]\n",
      " [0.31970245]\n",
      " [0.32128865]\n",
      " [0.32254818]\n",
      " [0.32324171]\n",
      " [0.32437283]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.32771376]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[[0.31700367]\n",
      "  [0.31844378]\n",
      "  [0.31833121]\n",
      "  [0.31970245]\n",
      "  [0.32128865]\n",
      "  [0.32254818]\n",
      "  [0.32324171]\n",
      "  [0.32437283]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07212810218334198\n",
      "Predicción post entrenamiento : [[0.33039558]]\n",
      "PERDIDAAAA despues: 0.07069479674100876\n",
      "loss en el callback: 0.10083003342151642, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "ejemplar: [[0.31844378]\n",
      " [0.31833121]\n",
      " [0.31970245]\n",
      " [0.32128865]\n",
      " [0.32254818]\n",
      " [0.32324171]\n",
      " [0.32437283]\n",
      " [0.32771376]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.33116606]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[[0.31844378]\n",
      "  [0.31833121]\n",
      "  [0.31970245]\n",
      "  [0.32128865]\n",
      "  [0.32254818]\n",
      "  [0.32324171]\n",
      "  [0.32437283]\n",
      "  [0.32771376]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05925203487277031\n",
      "Predicción post entrenamiento : [[0.3336144]]\n",
      "PERDIDAAAA despues: 0.05806608870625496\n",
      "loss en el callback: 0.07876637578010559, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "ejemplar: [[0.31833121]\n",
      " [0.31970245]\n",
      " [0.32128865]\n",
      " [0.32254818]\n",
      " [0.32324171]\n",
      " [0.32437283]\n",
      " [0.32771376]\n",
      " [0.33116606]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.33433595]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[[0.31833121]\n",
      "  [0.31970245]\n",
      "  [0.32128865]\n",
      "  [0.32254818]\n",
      "  [0.32324171]\n",
      "  [0.32437283]\n",
      "  [0.32771376]\n",
      "  [0.33116606]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07399388402700424\n",
      "Predicción post entrenamiento : [[0.33697274]]\n",
      "PERDIDAAAA despues: 0.07256632298231125\n",
      "loss en el callback: 0.10135754942893982, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "ejemplar: [[0.31970245]\n",
      " [0.32128865]\n",
      " [0.32254818]\n",
      " [0.32324171]\n",
      " [0.32437283]\n",
      " [0.32771376]\n",
      " [0.33116606]\n",
      " [0.33433595]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.33805612]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[[0.31970245]\n",
      "  [0.32128865]\n",
      "  [0.32254818]\n",
      "  [0.32324171]\n",
      "  [0.32437283]\n",
      "  [0.32771376]\n",
      "  [0.33116606]\n",
      "  [0.33433595]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06081205978989601\n",
      "Predicción post entrenamiento : [[0.34019217]]\n",
      "PERDIDAAAA despues: 0.059763118624687195\n",
      "loss en el callback: 0.04110207408666611, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "ejemplar: [[0.32128865]\n",
      " [0.32254818]\n",
      " [0.32324171]\n",
      " [0.32437283]\n",
      " [0.32771376]\n",
      " [0.33116606]\n",
      " [0.33433595]\n",
      " [0.33805612]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.34138164]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[[0.32128865]\n",
      "  [0.32254818]\n",
      "  [0.32324171]\n",
      "  [0.32437283]\n",
      "  [0.32771376]\n",
      "  [0.33116606]\n",
      "  [0.33433595]\n",
      "  [0.33805612]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05170627683401108\n",
      "Predicción post entrenamiento : [[0.3431795]]\n",
      "PERDIDAAAA despues: 0.05089187994599342\n",
      "loss en el callback: 0.035272955894470215, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "ejemplar: [[0.32254818]\n",
      " [0.32324171]\n",
      " [0.32437283]\n",
      " [0.32771376]\n",
      " [0.33116606]\n",
      " [0.33433595]\n",
      " [0.33805612]\n",
      " [0.34138164]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.3444903]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[[0.32254818]\n",
      "  [0.32324171]\n",
      "  [0.32437283]\n",
      "  [0.32771376]\n",
      "  [0.33116606]\n",
      "  [0.33433595]\n",
      "  [0.33805612]\n",
      "  [0.34138164]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08897323161363602\n",
      "Predicción post entrenamiento : [[0.34717742]]\n",
      "PERDIDAAAA despues: 0.0873773992061615\n",
      "loss en el callback: 0.13417954742908478, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "ejemplar: [[0.32324171]\n",
      " [0.32437283]\n",
      " [0.32771376]\n",
      " [0.33116606]\n",
      " [0.33433595]\n",
      " [0.33805612]\n",
      " [0.34138164]\n",
      " [0.34449029]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.34875837]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[[0.32324171]\n",
      "  [0.32437283]\n",
      "  [0.32771376]\n",
      "  [0.33116606]\n",
      "  [0.33433595]\n",
      "  [0.33805612]\n",
      "  [0.34138164]\n",
      "  [0.34449029]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0979694053530693\n",
      "Predicción post entrenamiento : [[0.3515457]]\n",
      "PERDIDAAAA despues: 0.09623230993747711\n",
      "loss en el callback: 0.11564667522907257, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "ejemplar: [[0.32437283]\n",
      " [0.32771376]\n",
      " [0.33116606]\n",
      " [0.33433595]\n",
      " [0.33805612]\n",
      " [0.34138164]\n",
      " [0.34449029]\n",
      " [0.34875837]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.3536214]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[[0.32437283]\n",
      "  [0.32771376]\n",
      "  [0.33116606]\n",
      "  [0.33433595]\n",
      "  [0.33805612]\n",
      "  [0.34138164]\n",
      "  [0.34449029]\n",
      "  [0.34875837]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10199948400259018\n",
      "Predicción post entrenamiento : [[0.35648185]]\n",
      "PERDIDAAAA despues: 0.10018055886030197\n",
      "loss en el callback: 0.12380240857601166, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "ejemplar: [[0.32771376]\n",
      " [0.33116606]\n",
      " [0.33433595]\n",
      " [0.33805612]\n",
      " [0.34138164]\n",
      " [0.34449029]\n",
      " [0.34875837]\n",
      " [0.35362139]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.35905674]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[[0.32771376]\n",
      "  [0.33116606]\n",
      "  [0.33433595]\n",
      "  [0.33805612]\n",
      "  [0.34138164]\n",
      "  [0.34449029]\n",
      "  [0.34875837]\n",
      "  [0.35362139]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12356670945882797\n",
      "Predicción post entrenamiento : [[0.3619455]]\n",
      "PERDIDAAAA despues: 0.12154413014650345\n",
      "loss en el callback: 0.09400610625743866, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "ejemplar: [[0.33116606]\n",
      " [0.33433595]\n",
      " [0.33805612]\n",
      " [0.34138164]\n",
      " [0.34449029]\n",
      " [0.34875837]\n",
      " [0.35362139]\n",
      " [0.35905674]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.36458442]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[[0.33116606]\n",
      "  [0.33433595]\n",
      "  [0.33805612]\n",
      "  [0.34138164]\n",
      "  [0.34449029]\n",
      "  [0.34875837]\n",
      "  [0.35362139]\n",
      "  [0.35905674]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11519662290811539\n",
      "Predicción post entrenamiento : [[0.3673704]]\n",
      "PERDIDAAAA despues: 0.113313227891922\n",
      "loss en el callback: 0.11610579490661621, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "ejemplar: [[0.33433595]\n",
      " [0.33805612]\n",
      " [0.34138164]\n",
      " [0.34449029]\n",
      " [0.34875837]\n",
      " [0.35362139]\n",
      " [0.35905674]\n",
      " [0.36458442]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.3700921]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[[0.33433595]\n",
      "  [0.33805612]\n",
      "  [0.34138164]\n",
      "  [0.34449029]\n",
      "  [0.34875837]\n",
      "  [0.35362139]\n",
      "  [0.35905674]\n",
      "  [0.36458442]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1275528520345688\n",
      "Predicción post entrenamiento : [[0.3730612]]\n",
      "PERDIDAAAA despues: 0.12544086575508118\n",
      "loss en el callback: 0.14392505586147308, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "ejemplar: [[0.33805612]\n",
      " [0.34138164]\n",
      " [0.34449029]\n",
      " [0.34875837]\n",
      " [0.35362139]\n",
      " [0.35905674]\n",
      " [0.36458442]\n",
      " [0.37009209]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.37599358]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[[0.33805612]\n",
      "  [0.34138164]\n",
      "  [0.34449029]\n",
      "  [0.34875837]\n",
      "  [0.35362139]\n",
      "  [0.35905674]\n",
      "  [0.36458442]\n",
      "  [0.37009209]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12012777477502823\n",
      "Predicción post entrenamiento : [[0.3786418]]\n",
      "PERDIDAAAA despues: 0.11829905956983566\n",
      "loss en el callback: 0.09190008044242859, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "ejemplar: [[0.34138164]\n",
      " [0.34449029]\n",
      " [0.34875837]\n",
      " [0.35362139]\n",
      " [0.35905674]\n",
      " [0.36458442]\n",
      " [0.37009209]\n",
      " [0.37599358]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.38173026]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[[0.34138164]\n",
      "  [0.34449029]\n",
      "  [0.34875837]\n",
      "  [0.35362139]\n",
      "  [0.35905674]\n",
      "  [0.36458442]\n",
      "  [0.37009209]\n",
      "  [0.37599358]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.15214964747428894\n",
      "Predicción post entrenamiento : [[0.38484883]]\n",
      "PERDIDAAAA despues: 0.1497264802455902\n",
      "loss en el callback: 0.12763544917106628, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "ejemplar: [[0.34449029]\n",
      " [0.34875837]\n",
      " [0.35362139]\n",
      " [0.35905674]\n",
      " [0.36458442]\n",
      " [0.37009209]\n",
      " [0.37599358]\n",
      " [0.38173026]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.3882661]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[[0.34449029]\n",
      "  [0.34875837]\n",
      "  [0.35362139]\n",
      "  [0.35905674]\n",
      "  [0.36458442]\n",
      "  [0.37009209]\n",
      "  [0.37599358]\n",
      "  [0.38173026]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11307032406330109\n",
      "Predicción post entrenamiento : [[0.3906881]]\n",
      "PERDIDAAAA despues: 0.11144734174013138\n",
      "loss en el callback: 0.0735393539071083, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "ejemplar: [[0.34875837]\n",
      " [0.35362139]\n",
      " [0.35905674]\n",
      " [0.36458442]\n",
      " [0.37009209]\n",
      " [0.37599358]\n",
      " [0.38173026]\n",
      " [0.38826609]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.39458278]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[[0.34875837]\n",
      "  [0.35362139]\n",
      "  [0.35905674]\n",
      "  [0.36458442]\n",
      "  [0.37009209]\n",
      "  [0.37599358]\n",
      "  [0.38173026]\n",
      "  [0.38826609]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07643838226795197\n",
      "Predicción post entrenamiento : [[0.39688477]]\n",
      "PERDIDAAAA despues: 0.07517080008983612\n",
      "loss en el callback: 0.11773185431957245, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "ejemplar: [[0.35362139]\n",
      " [0.35905674]\n",
      " [0.36458442]\n",
      " [0.37009209]\n",
      " [0.37599358]\n",
      " [0.38173026]\n",
      " [0.38826609]\n",
      " [0.39458278]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.4010731]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[[0.35362139]\n",
      "  [0.35905674]\n",
      "  [0.36458442]\n",
      "  [0.37009209]\n",
      "  [0.37599358]\n",
      "  [0.38173026]\n",
      "  [0.38826609]\n",
      "  [0.39458278]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07436350733041763\n",
      "Predicción post entrenamiento : [[0.40320203]]\n",
      "PERDIDAAAA despues: 0.07320693880319595\n",
      "loss en el callback: 0.10281170904636383, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "ejemplar: [[0.35905674]\n",
      " [0.36458442]\n",
      " [0.37009209]\n",
      " [0.37599358]\n",
      " [0.38173026]\n",
      " [0.38826609]\n",
      " [0.39458278]\n",
      " [0.4010731 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.40760517]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[[0.35905674]\n",
      "  [0.36458442]\n",
      "  [0.37009209]\n",
      "  [0.37599358]\n",
      "  [0.38173026]\n",
      "  [0.38826609]\n",
      "  [0.39458278]\n",
      "  [0.4010731 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09415484964847565\n",
      "Predicción post entrenamiento : [[0.4099317]]\n",
      "PERDIDAAAA despues: 0.0927324891090393\n",
      "loss en el callback: 0.10632824152708054, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "ejemplar: [[0.36458442]\n",
      " [0.37009209]\n",
      " [0.37599358]\n",
      " [0.38173026]\n",
      " [0.38826609]\n",
      " [0.39458278]\n",
      " [0.4010731 ]\n",
      " [0.40760517]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.41446006]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[[0.36458442]\n",
      "  [0.37009209]\n",
      "  [0.37599358]\n",
      "  [0.38173026]\n",
      "  [0.38826609]\n",
      "  [0.39458278]\n",
      "  [0.4010731 ]\n",
      "  [0.40760517]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10852918028831482\n",
      "Predicción post entrenamiento : [[0.41698414]]\n",
      "PERDIDAAAA despues: 0.10687249898910522\n",
      "loss en el callback: 0.12123918533325195, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "ejemplar: [[0.37009209]\n",
      " [0.37599358]\n",
      " [0.38173026]\n",
      " [0.38826609]\n",
      " [0.39458278]\n",
      " [0.4010731 ]\n",
      " [0.40760517]\n",
      " [0.41446006]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.42165518]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[[0.37009209]\n",
      "  [0.37599358]\n",
      "  [0.38173026]\n",
      "  [0.38826609]\n",
      "  [0.39458278]\n",
      "  [0.4010731 ]\n",
      "  [0.40760517]\n",
      "  [0.41446006]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09056063741445541\n",
      "Predicción post entrenamiento : [[0.42395243]]\n",
      "PERDIDAAAA despues: 0.0891832783818245\n",
      "loss en el callback: 0.09982059895992279, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "ejemplar: [[0.37599358]\n",
      " [0.38173026]\n",
      " [0.38826609]\n",
      " [0.39458278]\n",
      " [0.4010731 ]\n",
      " [0.40760517]\n",
      " [0.41446006]\n",
      " [0.42165518]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.4288149]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[[0.37599358]\n",
      "  [0.38173026]\n",
      "  [0.38826609]\n",
      "  [0.39458278]\n",
      "  [0.4010731 ]\n",
      "  [0.40760517]\n",
      "  [0.41446006]\n",
      "  [0.42165518]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07318457216024399\n",
      "Predicción post entrenamiento : [[0.4308994]]\n",
      "PERDIDAAAA despues: 0.07206107676029205\n",
      "loss en el callback: 0.09672126919031143, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "ejemplar: [[0.38173026]\n",
      " [0.38826609]\n",
      " [0.39458278]\n",
      " [0.4010731 ]\n",
      " [0.40760517]\n",
      " [0.41446006]\n",
      " [0.42165518]\n",
      " [0.42881489]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.43590304]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[[0.38173026]\n",
      "  [0.38826609]\n",
      "  [0.39458278]\n",
      "  [0.4010731 ]\n",
      "  [0.40760517]\n",
      "  [0.41446006]\n",
      "  [0.42165518]\n",
      "  [0.42881489]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09084682911634445\n",
      "Predicción post entrenamiento : [[0.43798816]]\n",
      "PERDIDAAAA despues: 0.08959423750638962\n",
      "loss en el callback: 0.07560303807258606, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "ejemplar: [[0.38826609]\n",
      " [0.39458278]\n",
      " [0.4010731 ]\n",
      " [0.40760517]\n",
      " [0.41446006]\n",
      " [0.42165518]\n",
      " [0.42881489]\n",
      " [0.43590304]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.44321677]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[[0.38826609]\n",
      "  [0.39458278]\n",
      "  [0.4010731 ]\n",
      "  [0.40760517]\n",
      "  [0.41446006]\n",
      "  [0.42165518]\n",
      "  [0.42881489]\n",
      "  [0.43590304]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07740028202533722\n",
      "Predicción post entrenamiento : [[0.44522092]]\n",
      "PERDIDAAAA despues: 0.07628915458917618\n",
      "loss en el callback: 0.08224426954984665, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "ejemplar: [[0.39458278]\n",
      " [0.4010731 ]\n",
      " [0.40760517]\n",
      " [0.41446006]\n",
      " [0.42165518]\n",
      " [0.42881489]\n",
      " [0.43590304]\n",
      " [0.44321677]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.45051914]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[[0.39458278]\n",
      "  [0.4010731 ]\n",
      "  [0.40760517]\n",
      "  [0.41446006]\n",
      "  [0.42165518]\n",
      "  [0.42881489]\n",
      "  [0.43590304]\n",
      "  [0.44321677]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07192832231521606\n",
      "Predicción post entrenamiento : [[0.45187995]]\n",
      "PERDIDAAAA despues: 0.07120025157928467\n",
      "loss en el callback: 0.02653645910322666, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "ejemplar: [[0.4010731 ]\n",
      " [0.40760517]\n",
      " [0.41446006]\n",
      " [0.42165518]\n",
      " [0.42881489]\n",
      " [0.43590304]\n",
      " [0.44321677]\n",
      " [0.45051914]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.45732936]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[[0.4010731 ]\n",
      "  [0.40760517]\n",
      "  [0.41446006]\n",
      "  [0.42165518]\n",
      "  [0.42881489]\n",
      "  [0.43590304]\n",
      "  [0.44321677]\n",
      "  [0.45051914]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04701436311006546\n",
      "Predicción post entrenamiento : [[0.4585603]]\n",
      "PERDIDAAAA despues: 0.04648208245635033\n",
      "loss en el callback: 0.02409299835562706, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "ejemplar: [[0.40760517]\n",
      " [0.41446006]\n",
      " [0.42165518]\n",
      " [0.42881489]\n",
      " [0.43590304]\n",
      " [0.44321677]\n",
      " [0.45051914]\n",
      " [0.45732936]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.46414924]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[[0.40760517]\n",
      "  [0.41446006]\n",
      "  [0.42165518]\n",
      "  [0.42881489]\n",
      "  [0.43590304]\n",
      "  [0.44321677]\n",
      "  [0.45051914]\n",
      "  [0.45732936]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05495142191648483\n",
      "Predicción post entrenamiento : [[0.46597394]]\n",
      "PERDIDAAAA despues: 0.05409926921129227\n",
      "loss en el callback: 0.08665773272514343, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "ejemplar: [[0.41446006]\n",
      " [0.42165518]\n",
      " [0.42881489]\n",
      " [0.43590304]\n",
      " [0.44321677]\n",
      " [0.45051914]\n",
      " [0.45732936]\n",
      " [0.46414924]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.4717172]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[[0.41446006]\n",
      "  [0.42165518]\n",
      "  [0.42881489]\n",
      "  [0.43590304]\n",
      "  [0.44321677]\n",
      "  [0.45051914]\n",
      "  [0.45732936]\n",
      "  [0.46414924]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.062161028385162354\n",
      "Predicción post entrenamiento : [[0.47341925]]\n",
      "PERDIDAAAA despues: 0.06131521612405777\n",
      "loss en el callback: 0.06126988306641579, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "ejemplar: [[0.42165518]\n",
      " [0.42881489]\n",
      " [0.43590304]\n",
      " [0.44321677]\n",
      " [0.45051914]\n",
      " [0.45732936]\n",
      " [0.46414924]\n",
      " [0.47171721]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.47925422]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[[0.42165518]\n",
      "  [0.42881489]\n",
      "  [0.43590304]\n",
      "  [0.44321677]\n",
      "  [0.45051914]\n",
      "  [0.45732936]\n",
      "  [0.46414924]\n",
      "  [0.47171721]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05921138823032379\n",
      "Predicción post entrenamiento : [[0.48080543]]\n",
      "PERDIDAAAA despues: 0.05845887213945389\n",
      "loss en el callback: 0.05174977704882622, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "ejemplar: [[0.42881489]\n",
      " [0.43590304]\n",
      " [0.44321677]\n",
      " [0.45051914]\n",
      " [0.45732936]\n",
      " [0.46414924]\n",
      " [0.47171721]\n",
      " [0.47925422]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.48665416]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[[0.42881489]\n",
      "  [0.43590304]\n",
      "  [0.44321677]\n",
      "  [0.45051914]\n",
      "  [0.45732936]\n",
      "  [0.46414924]\n",
      "  [0.47171721]\n",
      "  [0.47925422]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07270674407482147\n",
      "Predicción post entrenamiento : [[0.48841354]]\n",
      "PERDIDAAAA despues: 0.07176103442907333\n",
      "loss en el callback: 0.06942971050739288, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "ejemplar: [[0.43590304]\n",
      " [0.44321677]\n",
      " [0.45051914]\n",
      " [0.45732936]\n",
      " [0.46414924]\n",
      " [0.47171721]\n",
      " [0.47925422]\n",
      " [0.48665416]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.49428833]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[[0.43590304]\n",
      "  [0.44321677]\n",
      "  [0.45051914]\n",
      "  [0.45732936]\n",
      "  [0.46414924]\n",
      "  [0.47171721]\n",
      "  [0.47925422]\n",
      "  [0.48665416]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11108749359846115\n",
      "Predicción post entrenamiento : [[0.49647224]]\n",
      "PERDIDAAAA despues: 0.10963647812604904\n",
      "loss en el callback: 0.11068251729011536, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "ejemplar: [[0.44321677]\n",
      " [0.45051914]\n",
      " [0.45732936]\n",
      " [0.46414924]\n",
      " [0.47171721]\n",
      " [0.47925422]\n",
      " [0.48665416]\n",
      " [0.49428833]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.5024007]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[[0.44321677]\n",
      "  [0.45051914]\n",
      "  [0.45732936]\n",
      "  [0.46414924]\n",
      "  [0.47171721]\n",
      "  [0.47925422]\n",
      "  [0.48665416]\n",
      "  [0.49428833]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11317941546440125\n",
      "Predicción post entrenamiento : [[0.50460243]]\n",
      "PERDIDAAAA despues: 0.11170284450054169\n",
      "loss en el callback: 0.10162939131259918, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "ejemplar: [[0.45051914]\n",
      " [0.45732936]\n",
      " [0.46414924]\n",
      " [0.47171721]\n",
      " [0.47925422]\n",
      " [0.48665416]\n",
      " [0.49428833]\n",
      " [0.5024007 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.5105426]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[[0.45051914]\n",
      "  [0.45732936]\n",
      "  [0.46414924]\n",
      "  [0.47171721]\n",
      "  [0.47925422]\n",
      "  [0.48665416]\n",
      "  [0.49428833]\n",
      "  [0.5024007 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08049887418746948\n",
      "Predicción post entrenamiento : [[0.5118166]]\n",
      "PERDIDAAAA despues: 0.0797775462269783\n",
      "loss en el callback: 0.026839813217520714, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "ejemplar: [[0.45732936]\n",
      " [0.46414924]\n",
      " [0.47171721]\n",
      " [0.47925422]\n",
      " [0.48665416]\n",
      " [0.49428833]\n",
      " [0.5024007 ]\n",
      " [0.51054257]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.51778644]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[[0.45732936]\n",
      "  [0.46414924]\n",
      "  [0.47171721]\n",
      "  [0.47925422]\n",
      "  [0.48665416]\n",
      "  [0.49428833]\n",
      "  [0.5024007 ]\n",
      "  [0.51054257]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07076571881771088\n",
      "Predicción post entrenamiento : [[0.5197632]]\n",
      "PERDIDAAAA despues: 0.06971793621778488\n",
      "loss en el callback: 0.09935547411441803, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "ejemplar: [[0.46414924]\n",
      " [0.47171721]\n",
      " [0.47925422]\n",
      " [0.48665416]\n",
      " [0.49428833]\n",
      " [0.5024007 ]\n",
      " [0.51054257]\n",
      " [0.51778644]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.52591777]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[[0.46414924]\n",
      "  [0.47171721]\n",
      "  [0.47925422]\n",
      "  [0.48665416]\n",
      "  [0.49428833]\n",
      "  [0.5024007 ]\n",
      "  [0.51054257]\n",
      "  [0.51778644]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05856480076909065\n",
      "Predicción post entrenamiento : [[0.5274578]]\n",
      "PERDIDAAAA despues: 0.05782180279493332\n",
      "loss en el callback: 0.05325440317392349, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "ejemplar: [[0.47171721]\n",
      " [0.47925422]\n",
      " [0.48665416]\n",
      " [0.49428833]\n",
      " [0.5024007 ]\n",
      " [0.51054257]\n",
      " [0.51778644]\n",
      " [0.52591777]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.53383356]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[[0.47171721]\n",
      "  [0.47925422]\n",
      "  [0.48665416]\n",
      "  [0.49428833]\n",
      "  [0.5024007 ]\n",
      "  [0.51054257]\n",
      "  [0.51778644]\n",
      "  [0.52591777]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06287359446287155\n",
      "Predicción post entrenamiento : [[0.5350185]]\n",
      "PERDIDAAAA despues: 0.06228075921535492\n",
      "loss en el callback: 0.026152098551392555, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "ejemplar: [[0.47925422]\n",
      " [0.48665416]\n",
      " [0.49428833]\n",
      " [0.5024007 ]\n",
      " [0.51054257]\n",
      " [0.51778644]\n",
      " [0.52591777]\n",
      " [0.53383356]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.5414531]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[[0.47925422]\n",
      "  [0.48665416]\n",
      "  [0.49428833]\n",
      "  [0.5024007 ]\n",
      "  [0.51054257]\n",
      "  [0.51778644]\n",
      "  [0.52591777]\n",
      "  [0.53383356]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11375512927770615\n",
      "Predicción post entrenamiento : [[0.5436291]]\n",
      "PERDIDAAAA despues: 0.11229204386472702\n",
      "loss en el callback: 0.1209033727645874, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "ejemplar: [[0.48665416]\n",
      " [0.49428833]\n",
      " [0.5024007 ]\n",
      " [0.51054257]\n",
      " [0.51778644]\n",
      " [0.52591777]\n",
      " [0.53383356]\n",
      " [0.54145312]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.55014586]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[[0.48665416]\n",
      "  [0.49428833]\n",
      "  [0.5024007 ]\n",
      "  [0.51054257]\n",
      "  [0.51778644]\n",
      "  [0.52591777]\n",
      "  [0.53383356]\n",
      "  [0.54145312]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10593966394662857\n",
      "Predicción post entrenamiento : [[0.5521498]]\n",
      "PERDIDAAAA despues: 0.1046392023563385\n",
      "loss en el callback: 0.09640534222126007, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "ejemplar: [[0.49428833]\n",
      " [0.5024007 ]\n",
      " [0.51054257]\n",
      " [0.51778644]\n",
      " [0.52591777]\n",
      " [0.53383356]\n",
      " [0.54145312]\n",
      " [0.55014586]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.55880225]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[[0.49428833]\n",
      "  [0.5024007 ]\n",
      "  [0.51054257]\n",
      "  [0.51778644]\n",
      "  [0.52591777]\n",
      "  [0.53383356]\n",
      "  [0.54145312]\n",
      "  [0.55014586]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08415426313877106\n",
      "Predicción post entrenamiento : [[0.5606942]]\n",
      "PERDIDAAAA despues: 0.08306014537811279\n",
      "loss en el callback: 0.09766586124897003, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "ejemplar: [[0.5024007 ]\n",
      " [0.51054257]\n",
      " [0.51778644]\n",
      " [0.52591777]\n",
      " [0.53383356]\n",
      " [0.54145312]\n",
      " [0.55014586]\n",
      " [0.55880225]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.56744444]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[[0.5024007 ]\n",
      "  [0.51054257]\n",
      "  [0.51778644]\n",
      "  [0.52591777]\n",
      "  [0.53383356]\n",
      "  [0.54145312]\n",
      "  [0.55014586]\n",
      "  [0.55880225]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06292223185300827\n",
      "Predicción post entrenamiento : [[0.5692321]]\n",
      "PERDIDAAAA despues: 0.062028586864471436\n",
      "loss en el callback: 0.1004810482263565, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "ejemplar: [[0.51054257]\n",
      " [0.51778644]\n",
      " [0.52591777]\n",
      " [0.53383356]\n",
      " [0.54145312]\n",
      " [0.55014586]\n",
      " [0.55880225]\n",
      " [0.56744444]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.5759737]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[[0.51054257]\n",
      "  [0.51778644]\n",
      "  [0.52591777]\n",
      "  [0.53383356]\n",
      "  [0.54145312]\n",
      "  [0.55014586]\n",
      "  [0.55880225]\n",
      "  [0.56744444]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0629195123910904\n",
      "Predicción post entrenamiento : [[0.5777162]]\n",
      "PERDIDAAAA despues: 0.06204839050769806\n",
      "loss en el callback: 0.0951366126537323, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "ejemplar: [[0.51778644]\n",
      " [0.52591777]\n",
      " [0.53383356]\n",
      " [0.54145312]\n",
      " [0.55014586]\n",
      " [0.55880225]\n",
      " [0.56744444]\n",
      " [0.57597369]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.58445543]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[[0.51778644]\n",
      "  [0.52591777]\n",
      "  [0.53383356]\n",
      "  [0.54145312]\n",
      "  [0.55014586]\n",
      "  [0.55880225]\n",
      "  [0.56744444]\n",
      "  [0.57597369]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04036043584346771\n",
      "Predicción post entrenamiento : [[0.5855607]]\n",
      "PERDIDAAAA despues: 0.03991756960749626\n",
      "loss en el callback: 0.03094113990664482, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "ejemplar: [[0.52591777]\n",
      " [0.53383356]\n",
      " [0.54145312]\n",
      " [0.55014586]\n",
      " [0.55880225]\n",
      " [0.56744444]\n",
      " [0.57597369]\n",
      " [0.58445543]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.5925622]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[[0.52591777]\n",
      "  [0.53383356]\n",
      "  [0.54145312]\n",
      "  [0.55014586]\n",
      "  [0.55880225]\n",
      "  [0.56744444]\n",
      "  [0.57597369]\n",
      "  [0.58445543]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.038677822798490524\n",
      "Predicción post entrenamiento : [[0.59407854]]\n",
      "PERDIDAAAA despues: 0.03808369114995003\n",
      "loss en el callback: 0.07329177111387253, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "ejemplar: [[0.53383356]\n",
      " [0.54145312]\n",
      " [0.55014586]\n",
      " [0.55880225]\n",
      " [0.56744444]\n",
      " [0.57597369]\n",
      " [0.58445543]\n",
      " [0.5925622 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.6011484]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[[0.53383356]\n",
      "  [0.54145312]\n",
      "  [0.55014586]\n",
      "  [0.55880225]\n",
      "  [0.56744444]\n",
      "  [0.57597369]\n",
      "  [0.58445543]\n",
      "  [0.5925622 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.054300352931022644\n",
      "Predicción post entrenamiento : [[0.6025107]]\n",
      "PERDIDAAAA despues: 0.053667325526475906\n",
      "loss en el callback: 0.044115714728832245, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "ejemplar: [[0.54145312]\n",
      " [0.55014586]\n",
      " [0.55880225]\n",
      " [0.56744444]\n",
      " [0.57597369]\n",
      " [0.58445543]\n",
      " [0.5925622 ]\n",
      " [0.60114843]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.60972565]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[[0.54145312]\n",
      "  [0.55014586]\n",
      "  [0.55880225]\n",
      "  [0.56744444]\n",
      "  [0.57597369]\n",
      "  [0.58445543]\n",
      "  [0.5925622 ]\n",
      "  [0.60114843]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04110762104392052\n",
      "Predicción post entrenamiento : [[0.6109011]]\n",
      "PERDIDAAAA despues: 0.040632352232933044\n",
      "loss en el callback: 0.0368056483566761, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "ejemplar: [[0.55014586]\n",
      " [0.55880225]\n",
      " [0.56744444]\n",
      " [0.57597369]\n",
      " [0.58445543]\n",
      " [0.5925622 ]\n",
      " [0.60114843]\n",
      " [0.60972565]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.6183651]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[[0.55014586]\n",
      "  [0.55880225]\n",
      "  [0.56744444]\n",
      "  [0.57597369]\n",
      "  [0.58445543]\n",
      "  [0.5925622 ]\n",
      "  [0.60114843]\n",
      "  [0.60972565]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03344317153096199\n",
      "Predicción post entrenamiento : [[0.619937]]\n",
      "PERDIDAAAA despues: 0.03287072107195854\n",
      "loss en el callback: 0.10112529993057251, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "ejemplar: [[0.55880225]\n",
      " [0.56744444]\n",
      " [0.57597369]\n",
      " [0.58445543]\n",
      " [0.5925622 ]\n",
      " [0.60114843]\n",
      " [0.60972565]\n",
      " [0.61836511]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.6273827]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[[0.55880225]\n",
      "  [0.56744444]\n",
      "  [0.57597369]\n",
      "  [0.58445543]\n",
      "  [0.5925622 ]\n",
      "  [0.60114843]\n",
      "  [0.60972565]\n",
      "  [0.61836511]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.030903657898306847\n",
      "Predicción post entrenamiento : [[0.6286393]]\n",
      "PERDIDAAAA despues: 0.030463436618447304\n",
      "loss en el callback: 0.04398118332028389, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "ejemplar: [[0.56744444]\n",
      " [0.57597369]\n",
      " [0.58445543]\n",
      " [0.5925622 ]\n",
      " [0.60114843]\n",
      " [0.60972565]\n",
      " [0.61836511]\n",
      " [0.6273827 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.63606954]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[[0.56744444]\n",
      "  [0.57597369]\n",
      "  [0.58445543]\n",
      "  [0.5925622 ]\n",
      "  [0.60114843]\n",
      "  [0.60972565]\n",
      "  [0.61836511]\n",
      "  [0.6273827 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02478148229420185\n",
      "Predicción post entrenamiento : [[0.63762915]]\n",
      "PERDIDAAAA despues: 0.024292880669236183\n",
      "loss en el callback: 0.12482409179210663, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "ejemplar: [[0.57597369]\n",
      " [0.58445543]\n",
      " [0.5925622 ]\n",
      " [0.60114843]\n",
      " [0.60972565]\n",
      " [0.61836511]\n",
      " [0.6273827 ]\n",
      " [0.63606954]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.6450484]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[[0.57597369]\n",
      "  [0.58445543]\n",
      "  [0.5925622 ]\n",
      "  [0.60114843]\n",
      "  [0.60972565]\n",
      "  [0.61836511]\n",
      "  [0.6273827 ]\n",
      "  [0.63606954]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01325309369713068\n",
      "Predicción post entrenamiento : [[0.64532095]]\n",
      "PERDIDAAAA despues: 0.013190409168601036\n",
      "loss en el callback: 0.0016448772512376308, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "ejemplar: [[0.58445543]\n",
      " [0.5925622 ]\n",
      " [0.60114843]\n",
      " [0.60972565]\n",
      " [0.61836511]\n",
      " [0.6273827 ]\n",
      " [0.63606954]\n",
      " [0.64504838]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.652762]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[[0.58445543]\n",
      "  [0.5925622 ]\n",
      "  [0.60114843]\n",
      "  [0.60972565]\n",
      "  [0.61836511]\n",
      "  [0.6273827 ]\n",
      "  [0.63606954]\n",
      "  [0.64504838]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006824729032814503\n",
      "Predicción post entrenamiento : [[0.65361303]]\n",
      "PERDIDAAAA despues: 0.006684842053800821\n",
      "loss en el callback: 0.02853132225573063, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "ejemplar: [[0.5925622 ]\n",
      " [0.60114843]\n",
      " [0.60972565]\n",
      " [0.61836511]\n",
      " [0.6273827 ]\n",
      " [0.63606954]\n",
      " [0.64504838]\n",
      " [0.652762  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.66109836]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[[0.5925622 ]\n",
      "  [0.60114843]\n",
      "  [0.60972565]\n",
      "  [0.61836511]\n",
      "  [0.6273827 ]\n",
      "  [0.63606954]\n",
      "  [0.64504838]\n",
      "  [0.652762  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0024099713191390038\n",
      "Predicción post entrenamiento : [[0.6616704]]\n",
      "PERDIDAAAA despues: 0.0023541352711617947\n",
      "loss en el callback: 0.010507133789360523, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "ejemplar: [[0.60114843]\n",
      " [0.60972565]\n",
      " [0.61836511]\n",
      " [0.6273827 ]\n",
      " [0.63606954]\n",
      " [0.64504838]\n",
      " [0.652762  ]\n",
      " [0.66109836]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.66930944]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[[0.60114843]\n",
      "  [0.60972565]\n",
      "  [0.61836511]\n",
      "  [0.6273827 ]\n",
      "  [0.63606954]\n",
      "  [0.64504838]\n",
      "  [0.652762  ]\n",
      "  [0.66109836]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018333513289690018\n",
      "Predicción post entrenamiento : [[0.6699309]]\n",
      "PERDIDAAAA despues: 0.001780520542524755\n",
      "loss en el callback: 0.01404948253184557, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "ejemplar: [[0.60972565]\n",
      " [0.61836511]\n",
      " [0.6273827 ]\n",
      " [0.63606954]\n",
      " [0.64504838]\n",
      " [0.652762  ]\n",
      " [0.66109836]\n",
      " [0.66930944]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.6775985]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[[0.60972565]\n",
      "  [0.61836511]\n",
      "  [0.6273827 ]\n",
      "  [0.63606954]\n",
      "  [0.64504838]\n",
      "  [0.652762  ]\n",
      "  [0.66109836]\n",
      "  [0.66930944]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003848632564768195\n",
      "Predicción post entrenamiento : [[0.6778025]]\n",
      "PERDIDAAAA despues: 0.0038233597297221422\n",
      "loss en el callback: 0.0010951529256999493, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "ejemplar: [[0.61836511]\n",
      " [0.6273827 ]\n",
      " [0.63606954]\n",
      " [0.64504838]\n",
      " [0.652762  ]\n",
      " [0.66109836]\n",
      " [0.66930944]\n",
      " [0.67759848]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.68548733]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[[0.61836511]\n",
      "  [0.6273827 ]\n",
      "  [0.63606954]\n",
      "  [0.64504838]\n",
      "  [0.652762  ]\n",
      "  [0.66109836]\n",
      "  [0.66930944]\n",
      "  [0.67759848]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0025665820576250553\n",
      "Predicción post entrenamiento : [[0.68593746]]\n",
      "PERDIDAAAA despues: 0.0025211756583303213\n",
      "loss en el callback: 0.00536065548658371, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "ejemplar: [[0.6273827 ]\n",
      " [0.63606954]\n",
      " [0.64504838]\n",
      " [0.652762  ]\n",
      " [0.66109836]\n",
      " [0.66930944]\n",
      " [0.67759848]\n",
      " [0.68548733]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.69360304]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[[0.6273827 ]\n",
      "  [0.63606954]\n",
      "  [0.64504838]\n",
      "  [0.652762  ]\n",
      "  [0.66109836]\n",
      "  [0.66930944]\n",
      "  [0.67759848]\n",
      "  [0.68548733]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006776821101084352\n",
      "Predicción post entrenamiento : [[0.69299746]]\n",
      "PERDIDAAAA despues: 0.0006465193582698703\n",
      "loss en el callback: 0.00847439095377922, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "ejemplar: [[0.63606954]\n",
      " [0.64504838]\n",
      " [0.652762  ]\n",
      " [0.66109836]\n",
      " [0.66930944]\n",
      " [0.67759848]\n",
      " [0.68548733]\n",
      " [0.69360304]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.7005072]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[[0.63606954]\n",
      "  [0.64504838]\n",
      "  [0.652762  ]\n",
      "  [0.66109836]\n",
      "  [0.66930944]\n",
      "  [0.67759848]\n",
      "  [0.68548733]\n",
      "  [0.69360304]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009370830957777798\n",
      "Predicción post entrenamiento : [[0.7000583]]\n",
      "PERDIDAAAA despues: 0.0009097987785935402\n",
      "loss en el callback: 0.005050904583185911, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "ejemplar: [[0.64504838]\n",
      " [0.652762  ]\n",
      " [0.66109836]\n",
      " [0.66930944]\n",
      " [0.67759848]\n",
      " [0.68548733]\n",
      " [0.69360304]\n",
      " [0.70050722]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.7074608]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[[0.64504838]\n",
      "  [0.652762  ]\n",
      "  [0.66109836]\n",
      "  [0.66930944]\n",
      "  [0.67759848]\n",
      "  [0.68548733]\n",
      "  [0.69360304]\n",
      "  [0.70050722]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00011732344137271866\n",
      "Predicción post entrenamiento : [[0.7073639]]\n",
      "PERDIDAAAA despues: 0.00011523329885676503\n",
      "loss en el callback: 0.00026998278917744756, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "ejemplar: [[0.652762  ]\n",
      " [0.66109836]\n",
      " [0.66930944]\n",
      " [0.67759848]\n",
      " [0.68548733]\n",
      " [0.69360304]\n",
      " [0.70050722]\n",
      " [0.70746082]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.71453434]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[[0.652762  ]\n",
      "  [0.66109836]\n",
      "  [0.66930944]\n",
      "  [0.67759848]\n",
      "  [0.68548733]\n",
      "  [0.69360304]\n",
      "  [0.70050722]\n",
      "  [0.70746082]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0034324382431805134\n",
      "Predicción post entrenamiento : [[0.7141213]]\n",
      "PERDIDAAAA despues: 0.00338420900516212\n",
      "loss en el callback: 0.004919486586004496, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "ejemplar: [[0.66109836]\n",
      " [0.66930944]\n",
      " [0.67759848]\n",
      " [0.68548733]\n",
      " [0.69360304]\n",
      " [0.70050722]\n",
      " [0.70746082]\n",
      " [0.71453434]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.7213607]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[[0.66109836]\n",
      "  [0.66930944]\n",
      "  [0.67759848]\n",
      "  [0.68548733]\n",
      "  [0.69360304]\n",
      "  [0.70050722]\n",
      "  [0.70746082]\n",
      "  [0.71453434]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018108446383848786\n",
      "Predicción post entrenamiento : [[0.7206991]]\n",
      "PERDIDAAAA despues: 0.001754974015057087\n",
      "loss en el callback: 0.011715693399310112, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "ejemplar: [[0.66930944]\n",
      " [0.67759848]\n",
      " [0.68548733]\n",
      " [0.69360304]\n",
      " [0.70050722]\n",
      " [0.70746082]\n",
      " [0.71453434]\n",
      " [0.72136068]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.72780067]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[[0.66930944]\n",
      "  [0.67759848]\n",
      "  [0.68548733]\n",
      "  [0.69360304]\n",
      "  [0.70050722]\n",
      "  [0.70746082]\n",
      "  [0.71453434]\n",
      "  [0.72136068]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002673524431884289\n",
      "Predicción post entrenamiento : [[0.7279293]]\n",
      "PERDIDAAAA despues: 0.002686842577531934\n",
      "loss en el callback: 0.0005791767034679651, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "ejemplar: [[0.67759848]\n",
      " [0.68548733]\n",
      " [0.69360304]\n",
      " [0.70050722]\n",
      " [0.70746082]\n",
      " [0.71453434]\n",
      " [0.72136068]\n",
      " [0.72780067]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.73487073]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[[0.67759848]\n",
      "  [0.68548733]\n",
      "  [0.69360304]\n",
      "  [0.70050722]\n",
      "  [0.70746082]\n",
      "  [0.71453434]\n",
      "  [0.72136068]\n",
      "  [0.72780067]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.8180898880236782e-05\n",
      "Predicción post entrenamiento : [[0.7355818]]\n",
      "PERDIDAAAA despues: 3.623620796133764e-05\n",
      "loss en el callback: 0.024668114259839058, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "ejemplar: [[0.68548733]\n",
      " [0.69360304]\n",
      " [0.70050722]\n",
      " [0.70746082]\n",
      " [0.71453434]\n",
      " [0.72136068]\n",
      " [0.72780067]\n",
      " [0.73487073]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.7422809]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[[0.68548733]\n",
      "  [0.69360304]\n",
      "  [0.70050722]\n",
      "  [0.70746082]\n",
      "  [0.71453434]\n",
      "  [0.72136068]\n",
      "  [0.72780067]\n",
      "  [0.73487073]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016811913810670376\n",
      "Predicción post entrenamiento : [[0.74230313]]\n",
      "PERDIDAAAA despues: 0.0016830150270834565\n",
      "loss en el callback: 1.7386419131071307e-05, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "ejemplar: [[0.69360304]\n",
      " [0.70050722]\n",
      " [0.70746082]\n",
      " [0.71453434]\n",
      " [0.72136068]\n",
      " [0.72780067]\n",
      " [0.73487073]\n",
      " [0.7422809 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.7488123]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[[0.69360304]\n",
      "  [0.70050722]\n",
      "  [0.70746082]\n",
      "  [0.71453434]\n",
      "  [0.72136068]\n",
      "  [0.72780067]\n",
      "  [0.73487073]\n",
      "  [0.7422809 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00035042615490965545\n",
      "Predicción post entrenamiento : [[0.74911886]]\n",
      "PERDIDAAAA despues: 0.0003390432393644005\n",
      "loss en el callback: 0.0033517072442919016, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "ejemplar: [[0.70050722]\n",
      " [0.70746082]\n",
      " [0.71453434]\n",
      " [0.72136068]\n",
      " [0.72780067]\n",
      " [0.73487073]\n",
      " [0.7422809 ]\n",
      " [0.74881232]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.75532967]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[[0.70050722]\n",
      "  [0.70746082]\n",
      "  [0.71453434]\n",
      "  [0.72136068]\n",
      "  [0.72780067]\n",
      "  [0.73487073]\n",
      "  [0.7422809 ]\n",
      "  [0.74881232]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.84081886295462e-08\n",
      "Predicción post entrenamiento : [[0.7554907]]\n",
      "PERDIDAAAA despues: 1.2747172206672985e-07\n",
      "loss en el callback: 0.0009352776105515659, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "ejemplar: [[0.70746082]\n",
      " [0.71453434]\n",
      " [0.72136068]\n",
      " [0.72780067]\n",
      " [0.73487073]\n",
      " [0.7422809 ]\n",
      " [0.74881232]\n",
      " [0.75532967]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.761705]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[[0.70746082]\n",
      "  [0.71453434]\n",
      "  [0.72136068]\n",
      "  [0.72780067]\n",
      "  [0.73487073]\n",
      "  [0.7422809 ]\n",
      "  [0.74881232]\n",
      "  [0.75532967]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002770545252133161\n",
      "Predicción post entrenamiento : [[0.76129806]]\n",
      "PERDIDAAAA despues: 0.0002636737481225282\n",
      "loss en el callback: 0.004763411357998848, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "ejemplar: [[0.71453434]\n",
      " [0.72136068]\n",
      " [0.72780067]\n",
      " [0.73487073]\n",
      " [0.7422809 ]\n",
      " [0.74881232]\n",
      " [0.75532967]\n",
      " [0.76170498]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.7674926]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[[0.71453434]\n",
      "  [0.72136068]\n",
      "  [0.72780067]\n",
      "  [0.73487073]\n",
      "  [0.7422809 ]\n",
      "  [0.74881232]\n",
      "  [0.75532967]\n",
      "  [0.76170498]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00023896597849670798\n",
      "Predicción post entrenamiento : [[0.76797974]]\n",
      "PERDIDAAAA despues: 0.0002542644797358662\n",
      "loss en el callback: 0.011864821426570415, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "ejemplar: [[0.72136068]\n",
      " [0.72780067]\n",
      " [0.73487073]\n",
      " [0.7422809 ]\n",
      " [0.74881232]\n",
      " [0.75532967]\n",
      " [0.76170498]\n",
      " [0.76749259]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.7741049]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[[0.72136068]\n",
      "  [0.72780067]\n",
      "  [0.73487073]\n",
      "  [0.7422809 ]\n",
      "  [0.74881232]\n",
      "  [0.75532967]\n",
      "  [0.76170498]\n",
      "  [0.76749259]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00413481192663312\n",
      "Predicción post entrenamiento : [[0.773935]]\n",
      "PERDIDAAAA despues: 0.00411299429833889\n",
      "loss en el callback: 0.0009827413596212864, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "ejemplar: [[0.72780067]\n",
      " [0.73487073]\n",
      " [0.7422809 ]\n",
      " [0.74881232]\n",
      " [0.75532967]\n",
      " [0.76170498]\n",
      " [0.76749259]\n",
      " [0.77410489]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.7800358]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[[0.72780067]\n",
      "  [0.73487073]\n",
      "  [0.7422809 ]\n",
      "  [0.74881232]\n",
      "  [0.75532967]\n",
      "  [0.76170498]\n",
      "  [0.76749259]\n",
      "  [0.77410489]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008029189892113209\n",
      "Predicción post entrenamiento : [[0.78018415]]\n",
      "PERDIDAAAA despues: 0.008055799640715122\n",
      "loss en el callback: 0.0009508947841823101, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "ejemplar: [[0.73487073]\n",
      " [0.7422809 ]\n",
      " [0.74881232]\n",
      " [0.75532967]\n",
      " [0.76170498]\n",
      " [0.76749259]\n",
      " [0.77410489]\n",
      " [0.78003579]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.78634894]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[[0.73487073]\n",
      "  [0.7422809 ]\n",
      "  [0.74881232]\n",
      "  [0.75532967]\n",
      "  [0.76170498]\n",
      "  [0.76749259]\n",
      "  [0.77410489]\n",
      "  [0.78003579]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010233710054308176\n",
      "Predicción post entrenamiento : [[0.7857806]]\n",
      "PERDIDAAAA despues: 0.0009873320814222097\n",
      "loss en el callback: 0.008904910646378994, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "ejemplar: [[0.7422809 ]\n",
      " [0.74881232]\n",
      " [0.75532967]\n",
      " [0.76170498]\n",
      " [0.76749259]\n",
      " [0.77410489]\n",
      " [0.78003579]\n",
      " [0.78634894]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.7918077]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[[0.7422809 ]\n",
      "  [0.74881232]\n",
      "  [0.75532967]\n",
      "  [0.76170498]\n",
      "  [0.76749259]\n",
      "  [0.77410489]\n",
      "  [0.78003579]\n",
      "  [0.78634894]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004845137242227793\n",
      "Predicción post entrenamiento : [[0.7913145]]\n",
      "PERDIDAAAA despues: 0.004776716232299805\n",
      "loss en el callback: 0.008283878676593304, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "ejemplar: [[0.74881232]\n",
      " [0.75532967]\n",
      " [0.76170498]\n",
      " [0.76749259]\n",
      " [0.77410489]\n",
      " [0.78003579]\n",
      " [0.78634894]\n",
      " [0.79180771]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.79706067]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[[0.74881232]\n",
      "  [0.75532967]\n",
      "  [0.76170498]\n",
      "  [0.76749259]\n",
      "  [0.77410489]\n",
      "  [0.78003579]\n",
      "  [0.78634894]\n",
      "  [0.79180771]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0026468648575246334\n",
      "Predicción post entrenamiento : [[0.7973935]]\n",
      "PERDIDAAAA despues: 0.002612728625535965\n",
      "loss en el callback: 0.003892300184816122, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "ejemplar: [[0.75532967]\n",
      " [0.76170498]\n",
      " [0.76749259]\n",
      " [0.77410489]\n",
      " [0.78003579]\n",
      " [0.78634894]\n",
      " [0.79180771]\n",
      " [0.79706067]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.80305606]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[[0.75532967]\n",
      "  [0.76170498]\n",
      "  [0.76749259]\n",
      "  [0.77410489]\n",
      "  [0.78003579]\n",
      "  [0.78634894]\n",
      "  [0.79180771]\n",
      "  [0.79706067]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010487177409231663\n",
      "Predicción post entrenamiento : [[0.80386996]]\n",
      "PERDIDAAAA despues: 0.010321141220629215\n",
      "loss en el callback: 0.025542685762047768, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "ejemplar: [[0.76170498]\n",
      " [0.76749259]\n",
      " [0.77410489]\n",
      " [0.78003579]\n",
      " [0.78634894]\n",
      " [0.79180771]\n",
      " [0.79706067]\n",
      " [0.80305606]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.80942285]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[[0.76170498]\n",
      "  [0.76749259]\n",
      "  [0.77410489]\n",
      "  [0.78003579]\n",
      "  [0.78634894]\n",
      "  [0.79180771]\n",
      "  [0.79706067]\n",
      "  [0.80305606]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005298873875290155\n",
      "Predicción post entrenamiento : [[0.8092248]]\n",
      "PERDIDAAAA despues: 0.005327749066054821\n",
      "loss en el callback: 0.0010671939235180616, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "ejemplar: [[0.76749259]\n",
      " [0.77410489]\n",
      " [0.78003579]\n",
      " [0.78634894]\n",
      " [0.79180771]\n",
      " [0.79706067]\n",
      " [0.80305606]\n",
      " [0.80942285]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.81467843]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[[0.76749259]\n",
      "  [0.77410489]\n",
      "  [0.78003579]\n",
      "  [0.78634894]\n",
      "  [0.79180771]\n",
      "  [0.79706067]\n",
      "  [0.80305606]\n",
      "  [0.80942285]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008669332601130009\n",
      "Predicción post entrenamiento : [[0.8154238]]\n",
      "PERDIDAAAA despues: 0.008531088940799236\n",
      "loss en el callback: 0.026688067242503166, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "ejemplar: [[0.77410489]\n",
      " [0.78003579]\n",
      " [0.78634894]\n",
      " [0.79180771]\n",
      " [0.79706067]\n",
      " [0.80305606]\n",
      " [0.80942285]\n",
      " [0.81467843]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.8209248]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[[0.77410489]\n",
      "  [0.78003579]\n",
      "  [0.78634894]\n",
      "  [0.79180771]\n",
      "  [0.79706067]\n",
      "  [0.80305606]\n",
      "  [0.80942285]\n",
      "  [0.81467843]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004713216330856085\n",
      "Predicción post entrenamiento : [[0.8189442]]\n",
      "PERDIDAAAA despues: 0.004989087115973234\n",
      "loss en el callback: 0.0791572630405426, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "ejemplar: [[0.78003579]\n",
      " [0.78634894]\n",
      " [0.79180771]\n",
      " [0.79706067]\n",
      " [0.80305606]\n",
      " [0.80942285]\n",
      " [0.81467843]\n",
      " [0.82092482]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.82424164]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[[0.78003579]\n",
      "  [0.78634894]\n",
      "  [0.79180771]\n",
      "  [0.79706067]\n",
      "  [0.80305606]\n",
      "  [0.80942285]\n",
      "  [0.81467843]\n",
      "  [0.82092482]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002561680506914854\n",
      "Predicción post entrenamiento : [[0.8245702]]\n",
      "PERDIDAAAA despues: 0.002528531476855278\n",
      "loss en el callback: 0.004485147539526224, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "ejemplar: [[0.78634894]\n",
      " [0.79180771]\n",
      " [0.79706067]\n",
      " [0.80305606]\n",
      " [0.80942285]\n",
      " [0.81467843]\n",
      " [0.82092482]\n",
      " [0.82424164]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.8298231]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[[0.78634894]\n",
      "  [0.79180771]\n",
      "  [0.79706067]\n",
      "  [0.80305606]\n",
      "  [0.80942285]\n",
      "  [0.81467843]\n",
      "  [0.82092482]\n",
      "  [0.82424164]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00695370277389884\n",
      "Predicción post entrenamiento : [[0.83008206]]\n",
      "PERDIDAAAA despues: 0.006910577416419983\n",
      "loss en el callback: 0.0023257124703377485, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "ejemplar: [[0.79180771]\n",
      " [0.79706067]\n",
      " [0.80305606]\n",
      " [0.80942285]\n",
      " [0.81467843]\n",
      " [0.82092482]\n",
      " [0.82424164]\n",
      " [0.82982308]]\n",
      "ejemplar: (8, 1)\n",
      "y: 1.0\n",
      "Predicción : [[0.8351537]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[[0.79180771]\n",
      "  [0.79706067]\n",
      "  [0.80305606]\n",
      "  [0.80942285]\n",
      "  [0.81467843]\n",
      "  [0.82092482]\n",
      "  [0.82424164]\n",
      "  [0.82982308]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02717430330812931\n",
      "Predicción post entrenamiento : [[0.8362095]]\n",
      "PERDIDAAAA despues: 0.026827335357666016\n",
      "loss en el callback: 0.04164479672908783, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "ejemplar: [[0.79706067]\n",
      " [0.80305606]\n",
      " [0.80942285]\n",
      " [0.81467843]\n",
      " [0.82092482]\n",
      " [0.82424164]\n",
      " [0.82982308]\n",
      " [0.8351537 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.8413092]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[[0.79706067]\n",
      "  [0.80305606]\n",
      "  [0.80942285]\n",
      "  [0.81467843]\n",
      "  [0.82092482]\n",
      "  [0.82424164]\n",
      "  [0.82982308]\n",
      "  [0.8351537 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01670423522591591\n",
      "Predicción post entrenamiento : [[0.8417542]]\n",
      "PERDIDAAAA despues: 0.01658940315246582\n",
      "loss en el callback: 0.006577072665095329, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "ejemplar: [[0.80305606]\n",
      " [0.80942285]\n",
      " [0.81467843]\n",
      " [0.82092482]\n",
      " [0.82424164]\n",
      " [0.82982308]\n",
      " [0.8351537 ]\n",
      " [0.84130919]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.8469289]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[[0.80305606]\n",
      "  [0.80942285]\n",
      "  [0.81467843]\n",
      "  [0.82092482]\n",
      "  [0.82424164]\n",
      "  [0.82982308]\n",
      "  [0.8351537 ]\n",
      "  [0.84130919]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017534211510792375\n",
      "Predicción post entrenamiento : [[0.84688264]]\n",
      "PERDIDAAAA despues: 0.0017572969663888216\n",
      "loss en el callback: 7.117756467778236e-05, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "ejemplar: [[0.80942285]\n",
      " [0.81467843]\n",
      " [0.82092482]\n",
      " [0.82424164]\n",
      " [0.82982308]\n",
      " [0.8351537 ]\n",
      " [0.84130919]\n",
      " [0.84692889]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.8519088]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[[0.80942285]\n",
      "  [0.81467843]\n",
      "  [0.82092482]\n",
      "  [0.82424164]\n",
      "  [0.82982308]\n",
      "  [0.8351537 ]\n",
      "  [0.84130919]\n",
      "  [0.84692889]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006783681455999613\n",
      "Predicción post entrenamiento : [[0.85264385]]\n",
      "PERDIDAAAA despues: 0.0006406191969290376\n",
      "loss en el callback: 0.024451088160276413, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "ejemplar: [[0.81467843]\n",
      " [0.82092482]\n",
      " [0.82424164]\n",
      " [0.82982308]\n",
      " [0.8351537 ]\n",
      " [0.84130919]\n",
      " [0.84692889]\n",
      " [0.8519088 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.8573853]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[[0.81467843]\n",
      "  [0.82092482]\n",
      "  [0.82424164]\n",
      "  [0.82982308]\n",
      "  [0.8351537 ]\n",
      "  [0.84130919]\n",
      "  [0.84692889]\n",
      "  [0.8519088 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.207143062260002e-05\n",
      "Predicción post entrenamiento : [[0.8579801]]\n",
      "PERDIDAAAA despues: 8.252422412624583e-05\n",
      "loss en el callback: 0.018594713881611824, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "ejemplar: [[0.82092482]\n",
      " [0.82424164]\n",
      " [0.82982308]\n",
      " [0.8351537 ]\n",
      " [0.84130919]\n",
      " [0.84692889]\n",
      " [0.8519088 ]\n",
      " [0.85738528]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.86272895]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[[0.82092482]\n",
      "  [0.82424164]\n",
      "  [0.82982308]\n",
      "  [0.8351537 ]\n",
      "  [0.84130919]\n",
      "  [0.84692889]\n",
      "  [0.8519088 ]\n",
      "  [0.85738528]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008154547540470958\n",
      "Predicción post entrenamiento : [[0.86243975]]\n",
      "PERDIDAAAA despues: 0.0007990213925950229\n",
      "loss en el callback: 0.002922752406448126, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "ejemplar: [[0.82424164]\n",
      " [0.82982308]\n",
      " [0.8351537 ]\n",
      " [0.84130919]\n",
      " [0.84692889]\n",
      " [0.8519088 ]\n",
      " [0.85738528]\n",
      " [0.86272895]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.8669172]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[[0.82424164]\n",
      "  [0.82982308]\n",
      "  [0.8351537 ]\n",
      "  [0.84130919]\n",
      "  [0.84692889]\n",
      "  [0.8519088 ]\n",
      "  [0.85738528]\n",
      "  [0.86272895]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00013976638729218394\n",
      "Predicción post entrenamiento : [[0.8672955]]\n",
      "PERDIDAAAA despues: 0.00014885449490975589\n",
      "loss en el callback: 0.0061865816824138165, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "ejemplar: [[0.82982308]\n",
      " [0.8351537 ]\n",
      " [0.84130919]\n",
      " [0.84692889]\n",
      " [0.8519088 ]\n",
      " [0.85738528]\n",
      " [0.86272895]\n",
      " [0.86691719]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.8723364]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[[0.82982308]\n",
      "  [0.8351537 ]\n",
      "  [0.84130919]\n",
      "  [0.84692889]\n",
      "  [0.8519088 ]\n",
      "  [0.85738528]\n",
      "  [0.86272895]\n",
      "  [0.86691719]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.44359237817116e-06\n",
      "Predicción post entrenamiento : [[0.8722335]]\n",
      "PERDIDAAAA despues: 9.052057066583075e-06\n",
      "loss en el callback: 0.0003982915950473398, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "ejemplar: [[0.8351537 ]\n",
      " [0.84130919]\n",
      " [0.84692889]\n",
      " [0.8519088 ]\n",
      " [0.85738528]\n",
      " [0.86272895]\n",
      " [0.86691719]\n",
      " [0.87233639]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.8772365]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[[0.8351537 ]\n",
      "  [0.84130919]\n",
      "  [0.84692889]\n",
      "  [0.8519088 ]\n",
      "  [0.85738528]\n",
      "  [0.86272895]\n",
      "  [0.86691719]\n",
      "  [0.87233639]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000408213963964954\n",
      "Predicción post entrenamiento : [[0.87725294]]\n",
      "PERDIDAAAA despues: 0.0004088789864908904\n",
      "loss en el callback: 1.2038030035910197e-05, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "ejemplar: [[0.84130919]\n",
      " [0.84692889]\n",
      " [0.8519088 ]\n",
      " [0.85738528]\n",
      " [0.86272895]\n",
      " [0.86691719]\n",
      " [0.87233639]\n",
      " [0.87723649]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.882266]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[[0.84130919]\n",
      "  [0.84692889]\n",
      "  [0.8519088 ]\n",
      "  [0.85738528]\n",
      "  [0.86272895]\n",
      "  [0.86691719]\n",
      "  [0.87233639]\n",
      "  [0.87723649]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001037345384247601\n",
      "Predicción post entrenamiento : [[0.8812533]]\n",
      "PERDIDAAAA despues: 0.0009731382597237825\n",
      "loss en el callback: 0.032479315996170044, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "ejemplar: [[0.84692889]\n",
      " [0.8519088 ]\n",
      " [0.85738528]\n",
      " [0.86272895]\n",
      " [0.86691719]\n",
      " [0.87233639]\n",
      " [0.87723649]\n",
      " [0.88226599]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.8860109]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[[0.84692889]\n",
      "  [0.8519088 ]\n",
      "  [0.85738528]\n",
      "  [0.86272895]\n",
      "  [0.86691719]\n",
      "  [0.87233639]\n",
      "  [0.87723649]\n",
      "  [0.88226599]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001876126741990447\n",
      "Predicción post entrenamiento : [[0.88521147]]\n",
      "PERDIDAAAA despues: 0.001807513413950801\n",
      "loss en el callback: 0.02080540731549263, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "ejemplar: [[0.8519088 ]\n",
      " [0.85738528]\n",
      " [0.86272895]\n",
      " [0.86691719]\n",
      " [0.87233639]\n",
      " [0.87723649]\n",
      " [0.88226599]\n",
      " [0.88601089]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.8898171]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[[0.8519088 ]\n",
      "  [0.85738528]\n",
      "  [0.86272895]\n",
      "  [0.86691719]\n",
      "  [0.87233639]\n",
      "  [0.87723649]\n",
      "  [0.88226599]\n",
      "  [0.88601089]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004472972825169563\n",
      "Predicción post entrenamiento : [[0.8888962]]\n",
      "PERDIDAAAA despues: 0.004350641742348671\n",
      "loss en el callback: 0.02869073860347271, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "ejemplar: [[0.85738528]\n",
      " [0.86272895]\n",
      " [0.86691719]\n",
      " [0.87233639]\n",
      " [0.87723649]\n",
      " [0.88226599]\n",
      " [0.88601089]\n",
      " [0.88981712]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.89349407]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[[0.85738528]\n",
      "  [0.86272895]\n",
      "  [0.86691719]\n",
      "  [0.87233639]\n",
      "  [0.87723649]\n",
      "  [0.88226599]\n",
      "  [0.88601089]\n",
      "  [0.88981712]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014158152975142002\n",
      "Predicción post entrenamiento : [[0.8935671]]\n",
      "PERDIDAAAA despues: 0.01417553424835205\n",
      "loss en el callback: 0.0003149618278257549, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "ejemplar: [[0.86272895]\n",
      " [0.86691719]\n",
      " [0.87233639]\n",
      " [0.87723649]\n",
      " [0.88226599]\n",
      " [0.88601089]\n",
      " [0.88981712]\n",
      " [0.89349407]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.89798015]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[[0.86272895]\n",
      "  [0.86691719]\n",
      "  [0.87233639]\n",
      "  [0.87723649]\n",
      "  [0.88226599]\n",
      "  [0.88601089]\n",
      "  [0.88981712]\n",
      "  [0.89349407]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012947711162269115\n",
      "Predicción post entrenamiento : [[0.8980386]]\n",
      "PERDIDAAAA despues: 0.01296102162450552\n",
      "loss en el callback: 0.00018028324120678008, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "ejemplar: [[0.86691719]\n",
      " [0.87233639]\n",
      " [0.87723649]\n",
      " [0.88226599]\n",
      " [0.88601089]\n",
      " [0.88981712]\n",
      " [0.89349407]\n",
      " [0.89798015]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.9022513]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[[0.86691719]\n",
      "  [0.87233639]\n",
      "  [0.87723649]\n",
      "  [0.88226599]\n",
      "  [0.88601089]\n",
      "  [0.88981712]\n",
      "  [0.89349407]\n",
      "  [0.89798015]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018068444915115833\n",
      "Predicción post entrenamiento : [[0.90101504]]\n",
      "PERDIDAAAA despues: 0.001703273388557136\n",
      "loss en el callback: 0.04831376671791077, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "ejemplar: [[0.87233639]\n",
      " [0.87723649]\n",
      " [0.88226599]\n",
      " [0.88601089]\n",
      " [0.88981712]\n",
      " [0.89349407]\n",
      " [0.89798015]\n",
      " [0.9022513 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.9053116]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[[0.87233639]\n",
      "  [0.87723649]\n",
      "  [0.88226599]\n",
      "  [0.88601089]\n",
      "  [0.88981712]\n",
      "  [0.89349407]\n",
      "  [0.89798015]\n",
      "  [0.9022513 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0026001366786658764\n",
      "Predicción post entrenamiento : [[0.90460795]]\n",
      "PERDIDAAAA despues: 0.0025288730394095182\n",
      "loss en el callback: 0.01899060793220997, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "ejemplar: [[0.87723649]\n",
      " [0.88226599]\n",
      " [0.88601089]\n",
      " [0.88981712]\n",
      " [0.89349407]\n",
      " [0.89798015]\n",
      " [0.9022513 ]\n",
      " [0.90531158]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.9086051]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[[0.87723649]\n",
      "  [0.88226599]\n",
      "  [0.88601089]\n",
      "  [0.88981712]\n",
      "  [0.89349407]\n",
      "  [0.89798015]\n",
      "  [0.9022513 ]\n",
      "  [0.90531158]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005143784452229738\n",
      "Predicción post entrenamiento : [[0.9082969]]\n",
      "PERDIDAAAA despues: 0.005099669098854065\n",
      "loss en el callback: 0.0043665156699717045, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "ejemplar: [[0.88226599]\n",
      " [0.88601089]\n",
      " [0.88981712]\n",
      " [0.89349407]\n",
      " [0.89798015]\n",
      " [0.9022513 ]\n",
      " [0.90531158]\n",
      " [0.9086051 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.91207695]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[[0.88226599]\n",
      "  [0.88601089]\n",
      "  [0.88981712]\n",
      "  [0.89349407]\n",
      "  [0.89798015]\n",
      "  [0.9022513 ]\n",
      "  [0.90531158]\n",
      "  [0.9086051 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006751263979822397\n",
      "Predicción post entrenamiento : [[0.91202736]]\n",
      "PERDIDAAAA despues: 0.006743117235600948\n",
      "loss en el callback: 0.00012392942153383046, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "ejemplar: [[0.88601089]\n",
      " [0.88981712]\n",
      " [0.89349407]\n",
      " [0.89798015]\n",
      " [0.9022513 ]\n",
      " [0.90531158]\n",
      " [0.9086051 ]\n",
      " [0.91207695]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.91550136]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[[0.88601089]\n",
      "  [0.88981712]\n",
      "  [0.89349407]\n",
      "  [0.89798015]\n",
      "  [0.9022513 ]\n",
      "  [0.90531158]\n",
      "  [0.9086051 ]\n",
      "  [0.91207695]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007979703950695693\n",
      "Predicción post entrenamiento : [[0.9151635]]\n",
      "PERDIDAAAA despues: 0.0007789977244101465\n",
      "loss en el callback: 0.004609811119735241, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "ejemplar: [[0.88981712]\n",
      " [0.89349407]\n",
      " [0.89798015]\n",
      " [0.9022513 ]\n",
      " [0.90531158]\n",
      " [0.9086051 ]\n",
      " [0.91207695]\n",
      " [0.91550136]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.91865313]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[[0.88981712]\n",
      "  [0.89349407]\n",
      "  [0.89798015]\n",
      "  [0.9022513 ]\n",
      "  [0.90531158]\n",
      "  [0.9086051 ]\n",
      "  [0.91207695]\n",
      "  [0.91550136]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003470249008387327\n",
      "Predicción post entrenamiento : [[0.91890574]]\n",
      "PERDIDAAAA despues: 0.0035000741481781006\n",
      "loss en el callback: 0.0036741208750754595, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "ejemplar: [[0.89349407]\n",
      " [0.89798015]\n",
      " [0.9022513 ]\n",
      " [0.90531158]\n",
      " [0.9086051 ]\n",
      " [0.91207695]\n",
      " [0.91550136]\n",
      " [0.91865313]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.92237717]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[[0.89349407]\n",
      "  [0.89798015]\n",
      "  [0.9022513 ]\n",
      "  [0.90531158]\n",
      "  [0.9086051 ]\n",
      "  [0.91207695]\n",
      "  [0.91550136]\n",
      "  [0.91865313]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006852548569440842\n",
      "Predicción post entrenamiento : [[0.9214318]]\n",
      "PERDIDAAAA despues: 0.006696923635900021\n",
      "loss en el callback: 0.03513580188155174, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "ejemplar: [[0.89798015]\n",
      " [0.9022513 ]\n",
      " [0.90531158]\n",
      " [0.9086051 ]\n",
      " [0.91207695]\n",
      " [0.91550136]\n",
      " [0.91865313]\n",
      " [0.92237717]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.9248993]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[[0.89798015]\n",
      "  [0.9022513 ]\n",
      "  [0.90531158]\n",
      "  [0.9086051 ]\n",
      "  [0.91207695]\n",
      "  [0.91550136]\n",
      "  [0.91865313]\n",
      "  [0.92237717]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019907675683498383\n",
      "Predicción post entrenamiento : [[0.92448866]]\n",
      "PERDIDAAAA despues: 0.019791973754763603\n",
      "loss en el callback: 0.008669409900903702, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "ejemplar: [[0.9022513 ]\n",
      " [0.90531158]\n",
      " [0.9086051 ]\n",
      " [0.91207695]\n",
      " [0.91550136]\n",
      " [0.91865313]\n",
      " [0.92237717]\n",
      " [0.92489928]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.92769027]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[[0.9022513 ]\n",
      "  [0.90531158]\n",
      "  [0.9086051 ]\n",
      "  [0.91207695]\n",
      "  [0.91550136]\n",
      "  [0.91865313]\n",
      "  [0.92237717]\n",
      "  [0.92489928]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011968967504799366\n",
      "Predicción post entrenamiento : [[0.92660475]]\n",
      "PERDIDAAAA despues: 0.011732627637684345\n",
      "loss en el callback: 0.04602214694023132, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "ejemplar: [[0.90531158]\n",
      " [0.9086051 ]\n",
      " [0.91207695]\n",
      " [0.91550136]\n",
      " [0.91865313]\n",
      " [0.92237717]\n",
      " [0.92489928]\n",
      " [0.92769027]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.9295494]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[[0.90531158]\n",
      "  [0.9086051 ]\n",
      "  [0.91207695]\n",
      "  [0.91550136]\n",
      "  [0.91865313]\n",
      "  [0.92237717]\n",
      "  [0.92489928]\n",
      "  [0.92769027]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019149912521243095\n",
      "Predicción post entrenamiento : [[0.92920715]]\n",
      "PERDIDAAAA despues: 0.019055306911468506\n",
      "loss en el callback: 0.005486529320478439, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "ejemplar: [[0.9086051 ]\n",
      " [0.91207695]\n",
      " [0.91550136]\n",
      " [0.91865313]\n",
      " [0.92237717]\n",
      " [0.92489928]\n",
      " [0.92769027]\n",
      " [0.9295494 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.93220043]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[[0.9086051 ]\n",
      "  [0.91207695]\n",
      "  [0.91550136]\n",
      "  [0.91865313]\n",
      "  [0.92237717]\n",
      "  [0.92489928]\n",
      "  [0.92769027]\n",
      "  [0.9295494 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.029461141675710678\n",
      "Predicción post entrenamiento : [[0.93088555]]\n",
      "PERDIDAAAA despues: 0.029011493548750877\n",
      "loss en el callback: 0.06554069370031357, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "ejemplar: [[0.91207695]\n",
      " [0.91550136]\n",
      " [0.91865313]\n",
      " [0.92237717]\n",
      " [0.92489928]\n",
      " [0.92769027]\n",
      " [0.9295494 ]\n",
      " [0.93220043]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.93384045]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[[0.91207695]\n",
      "  [0.91550136]\n",
      "  [0.91865313]\n",
      "  [0.92237717]\n",
      "  [0.92489928]\n",
      "  [0.92769027]\n",
      "  [0.9295494 ]\n",
      "  [0.93220043]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02024552784860134\n",
      "Predicción post entrenamiento : [[0.9328958]]\n",
      "PERDIDAAAA despues: 0.019977590069174767\n",
      "loss en el callback: 0.036624692380428314, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "ejemplar: [[0.91550136]\n",
      " [0.91865313]\n",
      " [0.92237717]\n",
      " [0.92489928]\n",
      " [0.92769027]\n",
      " [0.9295494 ]\n",
      " [0.93220043]\n",
      " [0.93384045]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.93572074]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[[0.91550136]\n",
      "  [0.91865313]\n",
      "  [0.92237717]\n",
      "  [0.92489928]\n",
      "  [0.92769027]\n",
      "  [0.9295494 ]\n",
      "  [0.93220043]\n",
      "  [0.93384045]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02789783850312233\n",
      "Predicción post entrenamiento : [[0.93544245]]\n",
      "PERDIDAAAA despues: 0.02780495025217533\n",
      "loss en el callback: 0.004399734083563089, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "ejemplar: [[0.91865313]\n",
      " [0.92237717]\n",
      " [0.92489928]\n",
      " [0.92769027]\n",
      " [0.9295494 ]\n",
      " [0.93220043]\n",
      " [0.93384045]\n",
      " [0.93572074]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9380958]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[[0.91865313]\n",
      "  [0.92237717]\n",
      "  [0.92489928]\n",
      "  [0.92769027]\n",
      "  [0.9295494 ]\n",
      "  [0.93220043]\n",
      "  [0.93384045]\n",
      "  [0.93572074]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.028696877881884575\n",
      "Predicción post entrenamiento : [[0.9369214]]\n",
      "PERDIDAAAA despues: 0.028300369158387184\n",
      "loss en el callback: 0.060042526572942734, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "ejemplar: [[0.92237717]\n",
      " [0.92489928]\n",
      " [0.92769027]\n",
      " [0.9295494 ]\n",
      " [0.93220043]\n",
      " [0.93384045]\n",
      " [0.93572074]\n",
      " [0.93809581]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.93942165]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[[0.92237717]\n",
      "  [0.92489928]\n",
      "  [0.92769027]\n",
      "  [0.9295494 ]\n",
      "  [0.93220043]\n",
      "  [0.93384045]\n",
      "  [0.93572074]\n",
      "  [0.93809581]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019742079079151154\n",
      "Predicción post entrenamiento : [[0.93853384]]\n",
      "PERDIDAAAA despues: 0.019493380561470985\n",
      "loss en el callback: 0.03504915535449982, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "ejemplar: [[0.92489928]\n",
      " [0.92769027]\n",
      " [0.9295494 ]\n",
      " [0.93220043]\n",
      " [0.93384045]\n",
      " [0.93572074]\n",
      " [0.93809581]\n",
      " [0.93942165]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.9406588]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[[0.92489928]\n",
      "  [0.92769027]\n",
      "  [0.9295494 ]\n",
      "  [0.93220043]\n",
      "  [0.93384045]\n",
      "  [0.93572074]\n",
      "  [0.93809581]\n",
      "  [0.93942165]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022696902975440025\n",
      "Predicción post entrenamiento : [[0.94009995]]\n",
      "PERDIDAAAA despues: 0.02252882719039917\n",
      "loss en el callback: 0.016829699277877808, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "ejemplar: [[0.92769027]\n",
      " [0.9295494 ]\n",
      " [0.93220043]\n",
      " [0.93384045]\n",
      " [0.93572074]\n",
      " [0.93809581]\n",
      " [0.93942165]\n",
      " [0.94065881]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.9421245]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[[0.92769027]\n",
      "  [0.9295494 ]\n",
      "  [0.93220043]\n",
      "  [0.93384045]\n",
      "  [0.93572074]\n",
      "  [0.93809581]\n",
      "  [0.93942165]\n",
      "  [0.94065881]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03310726583003998\n",
      "Predicción post entrenamiento : [[0.94171506]]\n",
      "PERDIDAAAA despues: 0.03295844420790672\n",
      "loss en el callback: 0.010275255888700485, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "ejemplar: [[0.9295494 ]\n",
      " [0.93220043]\n",
      " [0.93384045]\n",
      " [0.93572074]\n",
      " [0.93809581]\n",
      " [0.93942165]\n",
      " [0.94065881]\n",
      " [0.94212449]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.94352245]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[[0.9295494 ]\n",
      "  [0.93220043]\n",
      "  [0.93384045]\n",
      "  [0.93572074]\n",
      "  [0.93809581]\n",
      "  [0.93942165]\n",
      "  [0.94065881]\n",
      "  [0.94212449]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06663067638874054\n",
      "Predicción post entrenamiento : [[0.94253844]]\n",
      "PERDIDAAAA despues: 0.06612363457679749\n",
      "loss en el callback: 0.05517131835222244, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "ejemplar: [[0.93220043]\n",
      " [0.93384045]\n",
      " [0.93572074]\n",
      " [0.93809581]\n",
      " [0.93942165]\n",
      " [0.94065881]\n",
      " [0.94212449]\n",
      " [0.94352245]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.94435036]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[[0.93220043]\n",
      "  [0.93384045]\n",
      "  [0.93572074]\n",
      "  [0.93809581]\n",
      "  [0.93942165]\n",
      "  [0.94065881]\n",
      "  [0.94212449]\n",
      "  [0.94352245]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11502855271100998\n",
      "Predicción post entrenamiento : [[0.9428337]]\n",
      "PERDIDAAAA despues: 0.11400208622217178\n",
      "loss en el callback: 0.12126965820789337, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "ejemplar: [[0.93384045]\n",
      " [0.93572074]\n",
      " [0.93809581]\n",
      " [0.93942165]\n",
      " [0.94065881]\n",
      " [0.94212449]\n",
      " [0.94352245]\n",
      " [0.94435036]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9443931]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[[0.93384045]\n",
      "  [0.93572074]\n",
      "  [0.93809581]\n",
      "  [0.93942165]\n",
      "  [0.94065881]\n",
      "  [0.94212449]\n",
      "  [0.94352245]\n",
      "  [0.94435036]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0781395435333252\n",
      "Predicción post entrenamiento : [[0.943923]]\n",
      "PERDIDAAAA despues: 0.07787694782018661\n",
      "loss en el callback: 0.015429027378559113, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "ejemplar: [[0.93572074]\n",
      " [0.93809581]\n",
      " [0.93942165]\n",
      " [0.94065881]\n",
      " [0.94212449]\n",
      " [0.94352245]\n",
      " [0.94435036]\n",
      " [0.9443931 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.94546396]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[[0.93572074]\n",
      "  [0.93809581]\n",
      "  [0.93942165]\n",
      "  [0.94065881]\n",
      "  [0.94212449]\n",
      "  [0.94352245]\n",
      "  [0.94435036]\n",
      "  [0.9443931 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05645317956805229\n",
      "Predicción post entrenamiento : [[0.9444169]]\n",
      "PERDIDAAAA despues: 0.055956706404685974\n",
      "loss en el callback: 0.05702657252550125, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "ejemplar: [[0.93809581]\n",
      " [0.93942165]\n",
      " [0.94065881]\n",
      " [0.94212449]\n",
      " [0.94352245]\n",
      " [0.94435036]\n",
      " [0.9443931 ]\n",
      " [0.94546396]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9458337]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[[0.93809581]\n",
      "  [0.93942165]\n",
      "  [0.94065881]\n",
      "  [0.94212449]\n",
      "  [0.94352245]\n",
      "  [0.94435036]\n",
      "  [0.9443931 ]\n",
      "  [0.94546396]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07894700765609741\n",
      "Predicción post entrenamiento : [[0.9450395]]\n",
      "PERDIDAAAA despues: 0.07850135117769241\n",
      "loss en el callback: 0.040146373212337494, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "ejemplar: [[0.93942165]\n",
      " [0.94065881]\n",
      " [0.94212449]\n",
      " [0.94352245]\n",
      " [0.94435036]\n",
      " [0.9443931 ]\n",
      " [0.94546396]\n",
      " [0.94583368]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.946137]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[[0.93942165]\n",
      "  [0.94065881]\n",
      "  [0.94212449]\n",
      "  [0.94352245]\n",
      "  [0.94435036]\n",
      "  [0.9443931 ]\n",
      "  [0.94546396]\n",
      "  [0.94583368]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05512392148375511\n",
      "Predicción post entrenamiento : [[0.94476736]]\n",
      "PERDIDAAAA despues: 0.05448265001177788\n",
      "loss en el callback: 0.09110983461141586, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "ejemplar: [[0.94065881]\n",
      " [0.94212449]\n",
      " [0.94352245]\n",
      " [0.94435036]\n",
      " [0.9443931 ]\n",
      " [0.94546396]\n",
      " [0.94583368]\n",
      " [0.94613701]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.94578195]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[[0.94065881]\n",
      "  [0.94212449]\n",
      "  [0.94352245]\n",
      "  [0.94435036]\n",
      "  [0.9443931 ]\n",
      "  [0.94546396]\n",
      "  [0.94583368]\n",
      "  [0.94613701]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07210571318864822\n",
      "Predicción post entrenamiento : [[0.9440578]]\n",
      "PERDIDAAAA despues: 0.0711827427148819\n",
      "loss en el callback: 0.13657402992248535, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "ejemplar: [[0.94212449]\n",
      " [0.94352245]\n",
      " [0.94435036]\n",
      " [0.9443931 ]\n",
      " [0.94546396]\n",
      " [0.94583368]\n",
      " [0.94613701]\n",
      " [0.94578195]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.94497234]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[[0.94212449]\n",
      "  [0.94352245]\n",
      "  [0.94435036]\n",
      "  [0.9443931 ]\n",
      "  [0.94546396]\n",
      "  [0.94583368]\n",
      "  [0.94613701]\n",
      "  [0.94578195]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03343946486711502\n",
      "Predicción post entrenamiento : [[0.9441229]]\n",
      "PERDIDAAAA despues: 0.03312952443957329\n",
      "loss en el callback: 0.040582865476608276, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "ejemplar: [[0.94352245]\n",
      " [0.94435036]\n",
      " [0.9443931 ]\n",
      " [0.94546396]\n",
      " [0.94583368]\n",
      " [0.94613701]\n",
      " [0.94578195]\n",
      " [0.94497234]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.9448193]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[[0.94352245]\n",
      "  [0.94435036]\n",
      "  [0.9443931 ]\n",
      "  [0.94546396]\n",
      "  [0.94583368]\n",
      "  [0.94613701]\n",
      "  [0.94578195]\n",
      "  [0.94497234]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01897994801402092\n",
      "Predicción post entrenamiento : [[0.9445267]]\n",
      "PERDIDAAAA despues: 0.01889941282570362\n",
      "loss en el callback: 0.005045585799962282, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "ejemplar: [[0.94435036]\n",
      " [0.9443931 ]\n",
      " [0.94546396]\n",
      " [0.94583368]\n",
      " [0.94613701]\n",
      " [0.94578195]\n",
      " [0.94497234]\n",
      " [0.94481927]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.94495916]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[[0.94435036]\n",
      "  [0.9443931 ]\n",
      "  [0.94546396]\n",
      "  [0.94583368]\n",
      "  [0.94613701]\n",
      "  [0.94578195]\n",
      "  [0.94497234]\n",
      "  [0.94481927]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016840573400259018\n",
      "Predicción post entrenamiento : [[0.9445407]]\n",
      "PERDIDAAAA despues: 0.01673213392496109\n",
      "loss en el callback: 0.010419301688671112, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "ejemplar: [[0.9443931 ]\n",
      " [0.94546396]\n",
      " [0.94583368]\n",
      " [0.94613701]\n",
      " [0.94578195]\n",
      " [0.94497234]\n",
      " [0.94481927]\n",
      " [0.94495916]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.94481206]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[[0.9443931 ]\n",
      "  [0.94546396]\n",
      "  [0.94583368]\n",
      "  [0.94613701]\n",
      "  [0.94578195]\n",
      "  [0.94497234]\n",
      "  [0.94481927]\n",
      "  [0.94495916]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014879658119753003\n",
      "Predicción post entrenamiento : [[0.9442798]]\n",
      "PERDIDAAAA despues: 0.0014471854083240032\n",
      "loss en el callback: 0.014055742882192135, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "ejemplar: [[0.94546396]\n",
      " [0.94583368]\n",
      " [0.94613701]\n",
      " [0.94578195]\n",
      " [0.94497234]\n",
      " [0.94481927]\n",
      " [0.94495916]\n",
      " [0.94481206]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.94457287]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[[0.94546396]\n",
      "  [0.94583368]\n",
      "  [0.94613701]\n",
      "  [0.94578195]\n",
      "  [0.94497234]\n",
      "  [0.94481927]\n",
      "  [0.94495916]\n",
      "  [0.94481206]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002289975673193112\n",
      "Predicción post entrenamiento : [[0.94527304]]\n",
      "PERDIDAAAA despues: 0.0002082967694150284\n",
      "loss en el callback: 0.042346082627773285, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "ejemplar: [[0.94583368]\n",
      " [0.94613701]\n",
      " [0.94578195]\n",
      " [0.94497234]\n",
      " [0.94481927]\n",
      " [0.94495916]\n",
      " [0.94481206]\n",
      " [0.94457287]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.9452676]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[[0.94583368]\n",
      "  [0.94613701]\n",
      "  [0.94578195]\n",
      "  [0.94497234]\n",
      "  [0.94481927]\n",
      "  [0.94495916]\n",
      "  [0.94481206]\n",
      "  [0.94457287]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003643232921604067\n",
      "Predicción post entrenamiento : [[0.94577867]]\n",
      "PERDIDAAAA despues: 0.0003450753865763545\n",
      "loss en el callback: 0.019625889137387276, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "ejemplar: [[0.94613701]\n",
      " [0.94578195]\n",
      " [0.94497234]\n",
      " [0.94481927]\n",
      " [0.94495916]\n",
      " [0.94481206]\n",
      " [0.94457287]\n",
      " [0.94526762]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.9456324]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[[0.94613701]\n",
      "  [0.94578195]\n",
      "  [0.94497234]\n",
      "  [0.94481927]\n",
      "  [0.94495916]\n",
      "  [0.94481206]\n",
      "  [0.94457287]\n",
      "  [0.94526762]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003318277420476079\n",
      "Predicción post entrenamiento : [[0.9460897]]\n",
      "PERDIDAAAA despues: 0.003371170023456216\n",
      "loss en el callback: 0.017919566482305527, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "ejemplar: [[0.94578195]\n",
      " [0.94497234]\n",
      " [0.94481927]\n",
      " [0.94495916]\n",
      " [0.94481206]\n",
      " [0.94457287]\n",
      " [0.94526762]\n",
      " [0.9456324 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.9458122]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[[0.94578195]\n",
      "  [0.94497234]\n",
      "  [0.94481927]\n",
      "  [0.94495916]\n",
      "  [0.94481206]\n",
      "  [0.94457287]\n",
      "  [0.94526762]\n",
      "  [0.9456324 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0028233258053660393\n",
      "Predicción post entrenamiento : [[0.94511]]\n",
      "PERDIDAAAA despues: 0.002749196020886302\n",
      "loss en el callback: 0.025308066979050636, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "ejemplar: [[0.94497234]\n",
      " [0.94481927]\n",
      " [0.94495916]\n",
      " [0.94481206]\n",
      " [0.94457287]\n",
      " [0.94526762]\n",
      " [0.9456324 ]\n",
      " [0.94581223]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.944896]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[[0.94497234]\n",
      "  [0.94481927]\n",
      "  [0.94495916]\n",
      "  [0.94481206]\n",
      "  [0.94457287]\n",
      "  [0.94526762]\n",
      "  [0.9456324 ]\n",
      "  [0.94581223]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00485165324062109\n",
      "Predicción post entrenamiento : [[0.9443251]]\n",
      "PERDIDAAAA despues: 0.004772449377924204\n",
      "loss en el callback: 0.019046388566493988, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "ejemplar: [[0.94481927]\n",
      " [0.94495916]\n",
      " [0.94481206]\n",
      " [0.94457287]\n",
      " [0.94526762]\n",
      " [0.9456324 ]\n",
      " [0.94581223]\n",
      " [0.94489598]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.9443304]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[[0.94481927]\n",
      "  [0.94495916]\n",
      "  [0.94481206]\n",
      "  [0.94457287]\n",
      "  [0.94526762]\n",
      "  [0.9456324 ]\n",
      "  [0.94581223]\n",
      "  [0.94489598]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008741763420403004\n",
      "Predicción post entrenamiento : [[0.944083]]\n",
      "PERDIDAAAA despues: 0.008695557713508606\n",
      "loss en el callback: 0.0038452388253062963, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "ejemplar: [[0.94495916]\n",
      " [0.94481206]\n",
      " [0.94457287]\n",
      " [0.94526762]\n",
      " [0.9456324 ]\n",
      " [0.94581223]\n",
      " [0.94489598]\n",
      " [0.94433039]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.94414496]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[[0.94495916]\n",
      "  [0.94481206]\n",
      "  [0.94457287]\n",
      "  [0.94526762]\n",
      "  [0.9456324 ]\n",
      "  [0.94581223]\n",
      "  [0.94489598]\n",
      "  [0.94433039]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00907240528613329\n",
      "Predicción post entrenamiento : [[0.94377714]]\n",
      "PERDIDAAAA despues: 0.009002471342682838\n",
      "loss en el callback: 0.009354662150144577, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "ejemplar: [[0.94481206]\n",
      " [0.94457287]\n",
      " [0.94526762]\n",
      " [0.9456324 ]\n",
      " [0.94581223]\n",
      " [0.94489598]\n",
      " [0.94433039]\n",
      " [0.94414496]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.94380933]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[[0.94481206]\n",
      "  [0.94457287]\n",
      "  [0.94526762]\n",
      "  [0.9456324 ]\n",
      "  [0.94581223]\n",
      "  [0.94489598]\n",
      "  [0.94433039]\n",
      "  [0.94414496]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00034627001150511205\n",
      "Predicción post entrenamiento : [[0.94302046]]\n",
      "PERDIDAAAA despues: 0.0003762513224501163\n",
      "loss en el callback: 0.03204832598567009, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "ejemplar: [[0.94457287]\n",
      " [0.94526762]\n",
      " [0.9456324 ]\n",
      " [0.94581223]\n",
      " [0.94489598]\n",
      " [0.94433039]\n",
      " [0.94414496]\n",
      " [0.94380933]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.9430884]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[[0.94457287]\n",
      "  [0.94526762]\n",
      "  [0.9456324 ]\n",
      "  [0.94581223]\n",
      "  [0.94489598]\n",
      "  [0.94433039]\n",
      "  [0.94414496]\n",
      "  [0.94380933]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006127363303676248\n",
      "Predicción post entrenamiento : [[0.94360876]]\n",
      "PERDIDAAAA despues: 0.0005872461479157209\n",
      "loss en el callback: 0.02031288854777813, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "ejemplar: [[0.94526762]\n",
      " [0.9456324 ]\n",
      " [0.94581223]\n",
      " [0.94489598]\n",
      " [0.94433039]\n",
      " [0.94414496]\n",
      " [0.94380933]\n",
      " [0.94308841]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.943723]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[[0.94526762]\n",
      "  [0.9456324 ]\n",
      "  [0.94581223]\n",
      "  [0.94489598]\n",
      "  [0.94433039]\n",
      "  [0.94414496]\n",
      "  [0.94380933]\n",
      "  [0.94308841]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 9.014079296321142e-06\n",
      "Predicción post entrenamiento : [[0.943844]]\n",
      "PERDIDAAAA despues: 9.755271094036289e-06\n",
      "loss en el callback: 0.0009351572953164577, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "ejemplar: [[0.9456324 ]\n",
      " [0.94581223]\n",
      " [0.94489598]\n",
      " [0.94433039]\n",
      " [0.94414496]\n",
      " [0.94380933]\n",
      " [0.94308841]\n",
      " [0.94372302]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.9437183]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[[0.9456324 ]\n",
      "  [0.94581223]\n",
      "  [0.94489598]\n",
      "  [0.94433039]\n",
      "  [0.94414496]\n",
      "  [0.94380933]\n",
      "  [0.94308841]\n",
      "  [0.94372302]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008278826717287302\n",
      "Predicción post entrenamiento : [[0.9433514]]\n",
      "PERDIDAAAA despues: 0.000849132367875427\n",
      "loss en el callback: 0.007494513411074877, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "ejemplar: [[0.94581223]\n",
      " [0.94489598]\n",
      " [0.94433039]\n",
      " [0.94414496]\n",
      " [0.94380933]\n",
      " [0.94308841]\n",
      " [0.94372302]\n",
      " [0.94371831]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.9430433]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[[0.94581223]\n",
      "  [0.94489598]\n",
      "  [0.94433039]\n",
      "  [0.94414496]\n",
      "  [0.94380933]\n",
      "  [0.94308841]\n",
      "  [0.94372302]\n",
      "  [0.94371831]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029005922842770815\n",
      "Predicción post entrenamiento : [[0.94245356]]\n",
      "PERDIDAAAA despues: 0.002964462386444211\n",
      "loss en el callback: 0.017563341185450554, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "ejemplar: [[0.94489598]\n",
      " [0.94433039]\n",
      " [0.94414496]\n",
      " [0.94380933]\n",
      " [0.94308841]\n",
      " [0.94372302]\n",
      " [0.94371831]\n",
      " [0.94304329]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.94199795]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[[0.94489598]\n",
      "  [0.94433039]\n",
      "  [0.94414496]\n",
      "  [0.94380933]\n",
      "  [0.94308841]\n",
      "  [0.94372302]\n",
      "  [0.94371831]\n",
      "  [0.94304329]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.43415327835828e-05\n",
      "Predicción post entrenamiento : [[0.9417981]]\n",
      "PERDIDAAAA despues: 8.805230027064681e-05\n",
      "loss en el callback: 0.002551897196099162, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "ejemplar: [[0.94433039]\n",
      " [0.94414496]\n",
      " [0.94380933]\n",
      " [0.94308841]\n",
      " [0.94372302]\n",
      " [0.94371831]\n",
      " [0.94304329]\n",
      " [0.94199795]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.94150347]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[[0.94433039]\n",
      "  [0.94414496]\n",
      "  [0.94380933]\n",
      "  [0.94308841]\n",
      "  [0.94372302]\n",
      "  [0.94371831]\n",
      "  [0.94304329]\n",
      "  [0.94199795]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0020909272134304047\n",
      "Predicción post entrenamiento : [[0.9413475]]\n",
      "PERDIDAAAA despues: 0.0020766861271113157\n",
      "loss en el callback: 0.0016057766042649746, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "ejemplar: [[0.94414496]\n",
      " [0.94380933]\n",
      " [0.94308841]\n",
      " [0.94372302]\n",
      " [0.94371831]\n",
      " [0.94304329]\n",
      " [0.94199795]\n",
      " [0.94150347]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.9411329]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[[0.94414496]\n",
      "  [0.94380933]\n",
      "  [0.94308841]\n",
      "  [0.94372302]\n",
      "  [0.94371831]\n",
      "  [0.94304329]\n",
      "  [0.94199795]\n",
      "  [0.94150347]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003563088132068515\n",
      "Predicción post entrenamiento : [[0.94099164]]\n",
      "PERDIDAAAA despues: 0.0035462435334920883\n",
      "loss en el callback: 0.001420808956027031, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "ejemplar: [[0.94380933]\n",
      " [0.94308841]\n",
      " [0.94372302]\n",
      " [0.94371831]\n",
      " [0.94304329]\n",
      " [0.94199795]\n",
      " [0.94150347]\n",
      " [0.9411329 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.9407492]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[[0.94380933]\n",
      "  [0.94308841]\n",
      "  [0.94372302]\n",
      "  [0.94371831]\n",
      "  [0.94304329]\n",
      "  [0.94199795]\n",
      "  [0.94150347]\n",
      "  [0.9411329 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005599283613264561\n",
      "Predicción post entrenamiento : [[0.94087684]]\n",
      "PERDIDAAAA despues: 0.0005659840535372496\n",
      "loss en el callback: 0.0013033929280936718, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "ejemplar: [[0.94308841]\n",
      " [0.94372302]\n",
      " [0.94371831]\n",
      " [0.94304329]\n",
      " [0.94199795]\n",
      " [0.94150347]\n",
      " [0.9411329 ]\n",
      " [0.94074923]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.9406367]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[[0.94308841]\n",
      "  [0.94372302]\n",
      "  [0.94371831]\n",
      "  [0.94304329]\n",
      "  [0.94199795]\n",
      "  [0.94150347]\n",
      "  [0.9411329 ]\n",
      "  [0.94074923]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00043422813178040087\n",
      "Predicción post entrenamiento : [[0.9400769]]\n",
      "PERDIDAAAA despues: 0.0004112108435947448\n",
      "loss en el callback: 0.01844913698732853, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "ejemplar: [[0.94372302]\n",
      " [0.94371831]\n",
      " [0.94304329]\n",
      " [0.94199795]\n",
      " [0.94150347]\n",
      " [0.9411329 ]\n",
      " [0.94074923]\n",
      " [0.94063669]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.93994087]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[[0.94372302]\n",
      "  [0.94371831]\n",
      "  [0.94304329]\n",
      "  [0.94199795]\n",
      "  [0.94150347]\n",
      "  [0.9411329 ]\n",
      "  [0.94074923]\n",
      "  [0.94063669]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004709738423116505\n",
      "Predicción post entrenamiento : [[0.9383411]]\n",
      "PERDIDAAAA despues: 0.0005429701996035874\n",
      "loss en el callback: 0.11858122050762177, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "ejemplar: [[0.94371831]\n",
      " [0.94304329]\n",
      " [0.94199795]\n",
      " [0.94150347]\n",
      " [0.9411329 ]\n",
      " [0.94074923]\n",
      " [0.94063669]\n",
      " [0.93994087]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.93791544]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[[0.94371831]\n",
      "  [0.94304329]\n",
      "  [0.94199795]\n",
      "  [0.94150347]\n",
      "  [0.9411329 ]\n",
      "  [0.94074923]\n",
      "  [0.94063669]\n",
      "  [0.93994087]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000918933073990047\n",
      "Predicción post entrenamiento : [[0.93759364]]\n",
      "PERDIDAAAA despues: 0.0009385470184497535\n",
      "loss en el callback: 0.006452824920415878, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "ejemplar: [[0.94304329]\n",
      " [0.94199795]\n",
      " [0.94150347]\n",
      " [0.9411329 ]\n",
      " [0.94074923]\n",
      " [0.94063669]\n",
      " [0.93994087]\n",
      " [0.93791544]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.93701625]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[[0.94304329]\n",
      "  [0.94199795]\n",
      "  [0.94150347]\n",
      "  [0.9411329 ]\n",
      "  [0.94074923]\n",
      "  [0.94063669]\n",
      "  [0.93994087]\n",
      "  [0.93791544]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004306485061533749\n",
      "Predicción post entrenamiento : [[0.93723583]]\n",
      "PERDIDAAAA despues: 0.0004215830995235592\n",
      "loss en el callback: 0.003569167573004961, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "ejemplar: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.20972343]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.026770610362291336\n",
      "Predicción post entrenamiento : [[0.18183717]]\n",
      "PERDIDAAAA despues: 0.01842290721833706\n",
      "loss en el callback: 0.02905191294848919, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "ejemplar: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20972343]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.16577289]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.20972343]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003788367612287402\n",
      "Predicción post entrenamiento : [[0.15754329]]\n",
      "PERDIDAAAA despues: 0.0028430349193513393\n",
      "loss en el callback: 0.0029874956235289574, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "ejemplar: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20972343]\n",
      " [0.16577289]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.16143392]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.20972343]\n",
      "  [0.16577289]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.2274604968260974e-05\n",
      "Predicción post entrenamiento : [[0.15705955]]\n",
      "PERDIDAAAA despues: 8.15529620012967e-06\n",
      "loss en el callback: 0.0013235548976808786, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "ejemplar: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20972343]\n",
      " [0.16577289]\n",
      " [0.16143392]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.16813327]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.20972343]\n",
      "  [0.16577289]\n",
      "  [0.16143392]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00015325675485655665\n",
      "Predicción post entrenamiento : [[0.1668014]]\n",
      "PERDIDAAAA despues: 0.00012205411621835083\n",
      "loss en el callback: 0.00026666317717172205, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "ejemplar: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20972343]\n",
      " [0.16577289]\n",
      " [0.16143392]\n",
      " [0.16813327]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.17854708]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.20972343]\n",
      "  [0.16577289]\n",
      "  [0.16143392]\n",
      "  [0.16813327]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0028105201199650764\n",
      "Predicción post entrenamiento : [[0.17453343]]\n",
      "PERDIDAAAA despues: 0.0024010667111724615\n",
      "loss en el callback: 0.003638339461758733, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "ejemplar: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20972343]\n",
      " [0.16577289]\n",
      " [0.16143392]\n",
      " [0.16813327]\n",
      " [0.17854708]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.18286322]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.20972343]\n",
      "  [0.16577289]\n",
      "  [0.16143392]\n",
      "  [0.16813327]\n",
      "  [0.17854708]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013825944624841213\n",
      "Predicción post entrenamiento : [[0.18127103]]\n",
      "PERDIDAAAA despues: 0.0012667239643633366\n",
      "loss en el callback: 0.0010293555678799748, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "ejemplar: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.20972343]\n",
      " [0.16577289]\n",
      " [0.16143392]\n",
      " [0.16813327]\n",
      " [0.17854708]\n",
      " [0.18286322]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.20009623]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.20972343]\n",
      "  [0.16577289]\n",
      "  [0.16143392]\n",
      "  [0.16813327]\n",
      "  [0.17854708]\n",
      "  [0.18286322]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0028773974627256393\n",
      "Predicción post entrenamiento : [[0.19639152]]\n",
      "PERDIDAAAA despues: 0.0024936706759035587\n",
      "loss en el callback: 0.005427670665085316, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "ejemplar: [[0.04223169]\n",
      " [0.20972343]\n",
      " [0.16577289]\n",
      " [0.16143392]\n",
      " [0.16813327]\n",
      " [0.17854708]\n",
      " [0.18286322]\n",
      " [0.20009623]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.21883245]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[[0.04223169]\n",
      "  [0.20972343]\n",
      "  [0.16577289]\n",
      "  [0.16143392]\n",
      "  [0.16813327]\n",
      "  [0.17854708]\n",
      "  [0.18286322]\n",
      "  [0.20009623]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005191294476389885\n",
      "Predicción post entrenamiento : [[0.21754315]]\n",
      "PERDIDAAAA despues: 0.00046204013051465154\n",
      "loss en el callback: 0.0009168446413241327, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "ejemplar: [[0.20972343]\n",
      " [0.16577289]\n",
      " [0.16143392]\n",
      " [0.16813327]\n",
      " [0.17854708]\n",
      " [0.18286322]\n",
      " [0.20009623]\n",
      " [0.21883245]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.24384844]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[[0.20972343]\n",
      "  [0.16577289]\n",
      "  [0.16143392]\n",
      "  [0.16813327]\n",
      "  [0.17854708]\n",
      "  [0.18286322]\n",
      "  [0.20009623]\n",
      "  [0.21883245]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00017735965957399458\n",
      "Predicción post entrenamiento : [[0.24309184]]\n",
      "PERDIDAAAA despues: 0.00015777967928443104\n",
      "loss en el callback: 0.0003690079029183835, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "ejemplar: [[0.16577289]\n",
      " [0.16143392]\n",
      " [0.16813327]\n",
      " [0.17854708]\n",
      " [0.18286322]\n",
      " [0.20009623]\n",
      " [0.21883245]\n",
      " [0.24384844]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.23699051]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[[0.16577289]\n",
      "  [0.16143392]\n",
      "  [0.16813327]\n",
      "  [0.17854708]\n",
      "  [0.18286322]\n",
      "  [0.20009623]\n",
      "  [0.21883245]\n",
      "  [0.24384844]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008147697662934661\n",
      "Predicción post entrenamiento : [[0.2350146]]\n",
      "PERDIDAAAA despues: 0.0007058726623654366\n",
      "loss en el callback: 0.0028829362709075212, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "ejemplar: [[0.16143392]\n",
      " [0.16813327]\n",
      " [0.17854708]\n",
      " [0.18286322]\n",
      " [0.20009623]\n",
      " [0.21883245]\n",
      " [0.24384844]\n",
      " [0.23699051]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.239006]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[[0.16143392]\n",
      "  [0.16813327]\n",
      "  [0.17854708]\n",
      "  [0.18286322]\n",
      "  [0.20009623]\n",
      "  [0.21883245]\n",
      "  [0.24384844]\n",
      "  [0.23699051]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007329277577809989\n",
      "Predicción post entrenamiento : [[0.23878857]]\n",
      "PERDIDAAAA despues: 0.0007212025811895728\n",
      "loss en el callback: 5.649222293868661e-05, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "ejemplar: [[0.16813327]\n",
      " [0.17854708]\n",
      " [0.18286322]\n",
      " [0.20009623]\n",
      " [0.21883245]\n",
      " [0.24384844]\n",
      " [0.23699051]\n",
      " [0.239006  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.24579053]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[[0.16813327]\n",
      "  [0.17854708]\n",
      "  [0.18286322]\n",
      "  [0.20009623]\n",
      "  [0.21883245]\n",
      "  [0.24384844]\n",
      "  [0.23699051]\n",
      "  [0.239006  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014827522682026029\n",
      "Predicción post entrenamiento : [[0.2450474]]\n",
      "PERDIDAAAA despues: 0.001426074537448585\n",
      "loss en el callback: 0.0007172622717916965, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "ejemplar: [[0.17854708]\n",
      " [0.18286322]\n",
      " [0.20009623]\n",
      " [0.21883245]\n",
      " [0.24384844]\n",
      " [0.23699051]\n",
      " [0.239006  ]\n",
      " [0.24579053]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.25303417]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[[0.17854708]\n",
      "  [0.18286322]\n",
      "  [0.20009623]\n",
      "  [0.21883245]\n",
      "  [0.24384844]\n",
      "  [0.23699051]\n",
      "  [0.239006  ]\n",
      "  [0.24579053]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0036102912854403257\n",
      "Predicción post entrenamiento : [[0.25093433]]\n",
      "PERDIDAAAA despues: 0.0033623597119003534\n",
      "loss en el callback: 0.005458254832774401, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "ejemplar: [[0.18286322]\n",
      " [0.20009623]\n",
      " [0.21883245]\n",
      " [0.24384844]\n",
      " [0.23699051]\n",
      " [0.239006  ]\n",
      " [0.24579053]\n",
      " [0.25303417]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.25908175]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[[0.18286322]\n",
      "  [0.20009623]\n",
      "  [0.21883245]\n",
      "  [0.24384844]\n",
      "  [0.23699051]\n",
      "  [0.239006  ]\n",
      "  [0.24579053]\n",
      "  [0.25303417]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003876159433275461\n",
      "Predicción post entrenamiento : [[0.25775814]]\n",
      "PERDIDAAAA despues: 0.0037130985874682665\n",
      "loss en el callback: 0.00297594559378922, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "ejemplar: [[0.20009623]\n",
      " [0.21883245]\n",
      " [0.24384844]\n",
      " [0.23699051]\n",
      " [0.239006  ]\n",
      " [0.24579053]\n",
      " [0.25303417]\n",
      " [0.25908175]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.26731178]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[[0.20009623]\n",
      "  [0.21883245]\n",
      "  [0.24384844]\n",
      "  [0.23699051]\n",
      "  [0.239006  ]\n",
      "  [0.24579053]\n",
      "  [0.25303417]\n",
      "  [0.25908175]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002814698964357376\n",
      "Predicción post entrenamiento : [[0.26679695]]\n",
      "PERDIDAAAA despues: 0.0027603362686932087\n",
      "loss en el callback: 0.0005695068975910544, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "ejemplar: [[0.21883245]\n",
      " [0.24384844]\n",
      " [0.23699051]\n",
      " [0.239006  ]\n",
      " [0.24579053]\n",
      " [0.25303417]\n",
      " [0.25908175]\n",
      " [0.26731178]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.27478573]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[[0.21883245]\n",
      "  [0.24384844]\n",
      "  [0.23699051]\n",
      "  [0.239006  ]\n",
      "  [0.24579053]\n",
      "  [0.25303417]\n",
      "  [0.25908175]\n",
      "  [0.26731178]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00873489584773779\n",
      "Predicción post entrenamiento : [[0.27052084]]\n",
      "PERDIDAAAA despues: 0.007955885492265224\n",
      "loss en el callback: 0.025543643161654472, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "ejemplar: [[0.24384844]\n",
      " [0.23699051]\n",
      " [0.239006  ]\n",
      " [0.24579053]\n",
      " [0.25303417]\n",
      " [0.25908175]\n",
      " [0.26731178]\n",
      " [0.27478573]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.27614006]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[[0.24384844]\n",
      "  [0.23699051]\n",
      "  [0.239006  ]\n",
      "  [0.24579053]\n",
      "  [0.25303417]\n",
      "  [0.25908175]\n",
      "  [0.26731178]\n",
      "  [0.27478573]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01020385604351759\n",
      "Predicción post entrenamiento : [[0.27348295]]\n",
      "PERDIDAAAA despues: 0.009674103930592537\n",
      "loss en el callback: 0.014731137081980705, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "ejemplar: [[0.23699051]\n",
      " [0.239006  ]\n",
      " [0.24579053]\n",
      " [0.25303417]\n",
      " [0.25908175]\n",
      " [0.26731178]\n",
      " [0.27478573]\n",
      " [0.27614006]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.2748343]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[[0.23699051]\n",
      "  [0.239006  ]\n",
      "  [0.24579053]\n",
      "  [0.25303417]\n",
      "  [0.25908175]\n",
      "  [0.26731178]\n",
      "  [0.27478573]\n",
      "  [0.27614006]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016085760667920113\n",
      "Predicción post entrenamiento : [[0.27122256]]\n",
      "PERDIDAAAA despues: 0.015182653442025185\n",
      "loss en el callback: 0.027470996603369713, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "ejemplar: [[0.239006  ]\n",
      " [0.24579053]\n",
      " [0.25303417]\n",
      " [0.25908175]\n",
      " [0.26731178]\n",
      " [0.27478573]\n",
      " [0.27614006]\n",
      " [0.27483431]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.2750798]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[[0.239006  ]\n",
      "  [0.24579053]\n",
      "  [0.25303417]\n",
      "  [0.25908175]\n",
      "  [0.26731178]\n",
      "  [0.27478573]\n",
      "  [0.27614006]\n",
      "  [0.27483431]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0135086290538311\n",
      "Predicción post entrenamiento : [[0.27301222]]\n",
      "PERDIDAAAA despues: 0.013032292015850544\n",
      "loss en el callback: 0.012912415899336338, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "ejemplar: [[0.24579053]\n",
      " [0.25303417]\n",
      " [0.25908175]\n",
      " [0.26731178]\n",
      " [0.27478573]\n",
      " [0.27614006]\n",
      " [0.27483431]\n",
      " [0.27507979]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.27765438]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[[0.24579053]\n",
      "  [0.25303417]\n",
      "  [0.25908175]\n",
      "  [0.26731178]\n",
      "  [0.27478573]\n",
      "  [0.27614006]\n",
      "  [0.27483431]\n",
      "  [0.27507979]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007306968793272972\n",
      "Predicción post entrenamiento : [[0.2758335]]\n",
      "PERDIDAAAA despues: 0.006998981814831495\n",
      "loss en el callback: 0.009287983179092407, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "ejemplar: [[0.25303417]\n",
      " [0.25908175]\n",
      " [0.26731178]\n",
      " [0.27478573]\n",
      " [0.27614006]\n",
      " [0.27483431]\n",
      " [0.27507979]\n",
      " [0.27765438]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.2801461]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[[0.25303417]\n",
      "  [0.25908175]\n",
      "  [0.26731178]\n",
      "  [0.27478573]\n",
      "  [0.27614006]\n",
      "  [0.27483431]\n",
      "  [0.27507979]\n",
      "  [0.27765438]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008868301287293434\n",
      "Predicción post entrenamiento : [[0.27817702]]\n",
      "PERDIDAAAA despues: 0.008501317352056503\n",
      "loss en el callback: 0.01211067009717226, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "ejemplar: [[0.25908175]\n",
      " [0.26731178]\n",
      " [0.27478573]\n",
      " [0.27614006]\n",
      " [0.27483431]\n",
      " [0.27507979]\n",
      " [0.27765438]\n",
      " [0.28014609]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.2818643]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[[0.25908175]\n",
      "  [0.26731178]\n",
      "  [0.27478573]\n",
      "  [0.27614006]\n",
      "  [0.27483431]\n",
      "  [0.27507979]\n",
      "  [0.27765438]\n",
      "  [0.28014609]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002224124618805945\n",
      "Predicción post entrenamiento : [[0.28175676]]\n",
      "PERDIDAAAA despues: 0.00021921681764069945\n",
      "loss en el callback: 4.307620110921562e-05, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "ejemplar: [[0.26731178]\n",
      " [0.27478573]\n",
      " [0.27614006]\n",
      " [0.27483431]\n",
      " [0.27507979]\n",
      " [0.27765438]\n",
      " [0.28014609]\n",
      " [0.28186429]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.28488788]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[[0.26731178]\n",
      "  [0.27478573]\n",
      "  [0.27614006]\n",
      "  [0.27483431]\n",
      "  [0.27507979]\n",
      "  [0.27765438]\n",
      "  [0.28014609]\n",
      "  [0.28186429]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.828408393426798e-05\n",
      "Predicción post entrenamiento : [[0.28505084]]\n",
      "PERDIDAAAA despues: 5.582244921242818e-05\n",
      "loss en el callback: 0.00011692736734403297, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "ejemplar: [[0.27478573]\n",
      " [0.27614006]\n",
      " [0.27483431]\n",
      " [0.27507979]\n",
      " [0.27765438]\n",
      " [0.28014609]\n",
      " [0.28186429]\n",
      " [0.28488788]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.28694558]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[[0.27478573]\n",
      "  [0.27614006]\n",
      "  [0.27483431]\n",
      "  [0.27507979]\n",
      "  [0.27765438]\n",
      "  [0.28014609]\n",
      "  [0.28186429]\n",
      "  [0.28488788]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009462228626944125\n",
      "Predicción post entrenamiento : [[0.28757858]]\n",
      "PERDIDAAAA despues: 0.0009076803689822555\n",
      "loss en el callback: 0.0019420734606683254, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "ejemplar: [[0.27614006]\n",
      " [0.27483431]\n",
      " [0.27507979]\n",
      " [0.27765438]\n",
      " [0.28014609]\n",
      " [0.28186429]\n",
      " [0.28488788]\n",
      " [0.28694558]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.28820094]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[[0.27614006]\n",
      "  [0.27483431]\n",
      "  [0.27507979]\n",
      "  [0.27765438]\n",
      "  [0.28014609]\n",
      "  [0.28186429]\n",
      "  [0.28488788]\n",
      "  [0.28694558]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005987109616398811\n",
      "Predicción post entrenamiento : [[0.28796223]]\n",
      "PERDIDAAAA despues: 0.0006104500498622656\n",
      "loss en el callback: 0.0002261741174152121, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "ejemplar: [[0.27483431]\n",
      " [0.27507979]\n",
      " [0.27765438]\n",
      " [0.28014609]\n",
      " [0.28186429]\n",
      " [0.28488788]\n",
      " [0.28694558]\n",
      " [0.28820094]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.28858483]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[[0.27483431]\n",
      "  [0.27507979]\n",
      "  [0.27765438]\n",
      "  [0.28014609]\n",
      "  [0.28186429]\n",
      "  [0.28488788]\n",
      "  [0.28694558]\n",
      "  [0.28820094]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.0288925384193135e-07\n",
      "Predicción post entrenamiento : [[0.28783596]]\n",
      "PERDIDAAAA despues: 1.4383326742972713e-06\n",
      "loss en el callback: 0.0020926909055560827, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "ejemplar: [[0.27507979]\n",
      " [0.27765438]\n",
      " [0.28014609]\n",
      " [0.28186429]\n",
      " [0.28488788]\n",
      " [0.28694558]\n",
      " [0.28820094]\n",
      " [0.28858483]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.28911018]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[[0.27507979]\n",
      "  [0.27765438]\n",
      "  [0.28014609]\n",
      "  [0.28186429]\n",
      "  [0.28488788]\n",
      "  [0.28694558]\n",
      "  [0.28820094]\n",
      "  [0.28858483]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.936400753445923e-05\n",
      "Predicción post entrenamiento : [[0.28944445]]\n",
      "PERDIDAAAA despues: 4.3670119339367375e-05\n",
      "loss en el callback: 0.0007202608976513147, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "ejemplar: [[0.27765438]\n",
      " [0.28014609]\n",
      " [0.28186429]\n",
      " [0.28488788]\n",
      " [0.28694558]\n",
      " [0.28820094]\n",
      " [0.28858483]\n",
      " [0.28911018]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.29109743]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[[0.27765438]\n",
      "  [0.28014609]\n",
      "  [0.28186429]\n",
      "  [0.28488788]\n",
      "  [0.28694558]\n",
      "  [0.28820094]\n",
      "  [0.28858483]\n",
      "  [0.28911018]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.054136221995577e-05\n",
      "Predicción post entrenamiento : [[0.29127032]]\n",
      "PERDIDAAAA despues: 6.766719161532819e-05\n",
      "loss en el callback: 0.0001735950354486704, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "ejemplar: [[0.28014609]\n",
      " [0.28186429]\n",
      " [0.28488788]\n",
      " [0.28694558]\n",
      " [0.28820094]\n",
      " [0.28858483]\n",
      " [0.28911018]\n",
      " [0.29109743]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.2927831]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[[0.28014609]\n",
      "  [0.28186429]\n",
      "  [0.28488788]\n",
      "  [0.28694558]\n",
      "  [0.28820094]\n",
      "  [0.28858483]\n",
      "  [0.28911018]\n",
      "  [0.29109743]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002863217086996883\n",
      "Predicción post entrenamiento : [[0.292158]]\n",
      "PERDIDAAAA despues: 0.00026555763906799257\n",
      "loss en el callback: 0.002144765807315707, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "ejemplar: [[0.28186429]\n",
      " [0.28488788]\n",
      " [0.28694558]\n",
      " [0.28820094]\n",
      " [0.28858483]\n",
      " [0.28911018]\n",
      " [0.29109743]\n",
      " [0.29278311]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.2935018]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[[0.28186429]\n",
      "  [0.28488788]\n",
      "  [0.28694558]\n",
      "  [0.28820094]\n",
      "  [0.28858483]\n",
      "  [0.28911018]\n",
      "  [0.29109743]\n",
      "  [0.29278311]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003535180876497179\n",
      "Predicción post entrenamiento : [[0.2931155]]\n",
      "PERDIDAAAA despues: 0.0003391409118194133\n",
      "loss en el callback: 0.0009005849133245647, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "ejemplar: [[0.28488788]\n",
      " [0.28694558]\n",
      " [0.28820094]\n",
      " [0.28858483]\n",
      " [0.28911018]\n",
      " [0.29109743]\n",
      " [0.29278311]\n",
      " [0.29350179]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.29442555]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[[0.28488788]\n",
      "  [0.28694558]\n",
      "  [0.28820094]\n",
      "  [0.28858483]\n",
      "  [0.28911018]\n",
      "  [0.29109743]\n",
      "  [0.29278311]\n",
      "  [0.29350179]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003591380955185741\n",
      "Predicción post entrenamiento : [[0.29434586]]\n",
      "PERDIDAAAA despues: 0.00035612398642115295\n",
      "loss en el callback: 4.8750804126029834e-05, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "ejemplar: [[0.28694558]\n",
      " [0.28820094]\n",
      " [0.28858483]\n",
      " [0.28911018]\n",
      " [0.29109743]\n",
      " [0.29278311]\n",
      " [0.29350179]\n",
      " [0.29442555]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.29528943]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[[0.28694558]\n",
      "  [0.28820094]\n",
      "  [0.28858483]\n",
      "  [0.28911018]\n",
      "  [0.29109743]\n",
      "  [0.29278311]\n",
      "  [0.29350179]\n",
      "  [0.29442555]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015574493445456028\n",
      "Predicción post entrenamiento : [[0.29521525]]\n",
      "PERDIDAAAA despues: 0.0015633096918463707\n",
      "loss en el callback: 3.547067171894014e-05, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "ejemplar: [[0.28820094]\n",
      " [0.28858483]\n",
      " [0.28911018]\n",
      " [0.29109743]\n",
      " [0.29278311]\n",
      " [0.29350179]\n",
      " [0.29442555]\n",
      " [0.29528943]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.29595676]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[[0.28820094]\n",
      "  [0.28858483]\n",
      "  [0.28911018]\n",
      "  [0.29109743]\n",
      "  [0.29278311]\n",
      "  [0.29350179]\n",
      "  [0.29442555]\n",
      "  [0.29528943]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003566397586837411\n",
      "Predicción post entrenamiento : [[0.29649204]]\n",
      "PERDIDAAAA despues: 0.0035027512349188328\n",
      "loss en el callback: 0.002126412931829691, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "ejemplar: [[0.28858483]\n",
      " [0.28911018]\n",
      " [0.29109743]\n",
      " [0.29278311]\n",
      " [0.29350179]\n",
      " [0.29442555]\n",
      " [0.29528943]\n",
      " [0.29595676]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.29718858]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[[0.28858483]\n",
      "  [0.28911018]\n",
      "  [0.29109743]\n",
      "  [0.29278311]\n",
      "  [0.29350179]\n",
      "  [0.29442555]\n",
      "  [0.29528943]\n",
      "  [0.29595676]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015604570508003235\n",
      "Predicción post entrenamiento : [[0.29710385]]\n",
      "PERDIDAAAA despues: 0.0015671581495553255\n",
      "loss en el callback: 4.7532474127365276e-05, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "ejemplar: [[0.28911018]\n",
      " [0.29109743]\n",
      " [0.29278311]\n",
      " [0.29350179]\n",
      " [0.29442555]\n",
      " [0.29528943]\n",
      " [0.29595676]\n",
      " [0.29718858]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.297954]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[[0.28911018]\n",
      "  [0.29109743]\n",
      "  [0.29278311]\n",
      "  [0.29350179]\n",
      "  [0.29442555]\n",
      "  [0.29528943]\n",
      "  [0.29595676]\n",
      "  [0.29718858]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001270041917450726\n",
      "Predicción post entrenamiento : [[0.29850265]]\n",
      "PERDIDAAAA despues: 0.0012312369653955102\n",
      "loss en el callback: 0.002856487175449729, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "ejemplar: [[0.29109743]\n",
      " [0.29278311]\n",
      " [0.29350179]\n",
      " [0.29442555]\n",
      " [0.29528943]\n",
      " [0.29595676]\n",
      " [0.29718858]\n",
      " [0.29795399]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.29948866]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[[0.29109743]\n",
      "  [0.29278311]\n",
      "  [0.29350179]\n",
      "  [0.29442555]\n",
      "  [0.29528943]\n",
      "  [0.29595676]\n",
      "  [0.29718858]\n",
      "  [0.29795399]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007266869768500328\n",
      "Predicción post entrenamiento : [[0.30061463]]\n",
      "PERDIDAAAA despues: 0.0070761702954769135\n",
      "loss en el callback: 0.014897435903549194, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "ejemplar: [[0.29278311]\n",
      " [0.29350179]\n",
      " [0.29442555]\n",
      " [0.29528943]\n",
      " [0.29595676]\n",
      " [0.29718858]\n",
      " [0.29795399]\n",
      " [0.29948866]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.3014013]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[[0.29278311]\n",
      "  [0.29350179]\n",
      "  [0.29442555]\n",
      "  [0.29528943]\n",
      "  [0.29595676]\n",
      "  [0.29718858]\n",
      "  [0.29795399]\n",
      "  [0.29948866]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.072735495865345\n",
      "Predicción post entrenamiento : [[0.3040196]]\n",
      "PERDIDAAAA despues: 0.07133006304502487\n",
      "loss en el callback: 0.05521521717309952, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "ejemplar: [[0.29350179]\n",
      " [0.29442555]\n",
      " [0.29528943]\n",
      " [0.29595676]\n",
      " [0.29718858]\n",
      " [0.29795399]\n",
      " [0.29948866]\n",
      " [0.30140129]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.30465162]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[[0.29350179]\n",
      "  [0.29442555]\n",
      "  [0.29528943]\n",
      "  [0.29595676]\n",
      "  [0.29718858]\n",
      "  [0.29795399]\n",
      "  [0.29948866]\n",
      "  [0.30140129]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0850474163889885\n",
      "Predicción post entrenamiento : [[0.3074776]]\n",
      "PERDIDAAAA despues: 0.08340712636709213\n",
      "loss en el callback: 0.08099978417158127, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "ejemplar: [[0.29442555]\n",
      " [0.29528943]\n",
      " [0.29595676]\n",
      " [0.29718858]\n",
      " [0.29795399]\n",
      " [0.29948866]\n",
      " [0.30140129]\n",
      " [0.30465162]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.3081841]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[[0.29442555]\n",
      "  [0.29528943]\n",
      "  [0.29595676]\n",
      "  [0.29718858]\n",
      "  [0.29795399]\n",
      "  [0.29948866]\n",
      "  [0.30140129]\n",
      "  [0.30465162]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0709686279296875\n",
      "Predicción post entrenamiento : [[0.31063208]]\n",
      "PERDIDAAAA despues: 0.06967033445835114\n",
      "loss en el callback: 0.055661920458078384, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "ejemplar: [[0.29528943]\n",
      " [0.29595676]\n",
      " [0.29718858]\n",
      " [0.29795399]\n",
      " [0.29948866]\n",
      " [0.30140129]\n",
      " [0.30465162]\n",
      " [0.30818409]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.3114137]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[[0.29528943]\n",
      "  [0.29595676]\n",
      "  [0.29718858]\n",
      "  [0.29795399]\n",
      "  [0.29948866]\n",
      "  [0.30140129]\n",
      "  [0.30465162]\n",
      "  [0.30818409]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08698984980583191\n",
      "Predicción post entrenamiento : [[0.31424046]]\n",
      "PERDIDAAAA despues: 0.08533038944005966\n",
      "loss en el callback: 0.09787406027317047, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "ejemplar: [[0.29595676]\n",
      " [0.29718858]\n",
      " [0.29795399]\n",
      " [0.29948866]\n",
      " [0.30140129]\n",
      " [0.30465162]\n",
      " [0.30818409]\n",
      " [0.31141371]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.3151723]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[[0.29595676]\n",
      "  [0.29718858]\n",
      "  [0.29795399]\n",
      "  [0.29948866]\n",
      "  [0.30140129]\n",
      "  [0.30465162]\n",
      "  [0.30818409]\n",
      "  [0.31141371]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07262206822633743\n",
      "Predicción post entrenamiento : [[0.31766587]]\n",
      "PERDIDAAAA despues: 0.07128433138132095\n",
      "loss en el callback: 0.08630621433258057, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "ejemplar: [[0.29718858]\n",
      " [0.29795399]\n",
      " [0.29948866]\n",
      " [0.30140129]\n",
      " [0.30465162]\n",
      " [0.30818409]\n",
      " [0.31141371]\n",
      " [0.31517231]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.3188744]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[[0.29718858]\n",
      "  [0.29795399]\n",
      "  [0.29948866]\n",
      "  [0.30140129]\n",
      "  [0.30465162]\n",
      "  [0.30818409]\n",
      "  [0.31141371]\n",
      "  [0.31517231]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06244870647788048\n",
      "Predicción post entrenamiento : [[0.32116058]]\n",
      "PERDIDAAAA despues: 0.061311304569244385\n",
      "loss en el callback: 0.1054457426071167, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "ejemplar: [[0.29795399]\n",
      " [0.29948866]\n",
      " [0.30140129]\n",
      " [0.30465162]\n",
      " [0.30818409]\n",
      " [0.31141371]\n",
      " [0.31517231]\n",
      " [0.31887439]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.322608]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[[0.29795399]\n",
      "  [0.29948866]\n",
      "  [0.30140129]\n",
      "  [0.30465162]\n",
      "  [0.30818409]\n",
      "  [0.31141371]\n",
      "  [0.31517231]\n",
      "  [0.31887439]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10250633955001831\n",
      "Predicción post entrenamiento : [[0.325375]]\n",
      "PERDIDAAAA despues: 0.10074219852685928\n",
      "loss en el callback: 0.11483785510063171, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "ejemplar: [[0.29948866]\n",
      " [0.30140129]\n",
      " [0.30465162]\n",
      " [0.30818409]\n",
      " [0.31141371]\n",
      " [0.31517231]\n",
      " [0.31887439]\n",
      " [0.32260799]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.32726187]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[[0.29948866]\n",
      "  [0.30140129]\n",
      "  [0.30465162]\n",
      "  [0.30818409]\n",
      "  [0.31141371]\n",
      "  [0.31517231]\n",
      "  [0.31887439]\n",
      "  [0.32260799]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1118883490562439\n",
      "Predicción post entrenamiento : [[0.32981658]]\n",
      "PERDIDAAAA despues: 0.11018577963113785\n",
      "loss en el callback: 0.06390891969203949, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "ejemplar: [[0.30140129]\n",
      " [0.30465162]\n",
      " [0.30818409]\n",
      " [0.31141371]\n",
      " [0.31517231]\n",
      " [0.31887439]\n",
      " [0.32260799]\n",
      " [0.32726187]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.3320675]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[[0.30140129]\n",
      "  [0.30465162]\n",
      "  [0.30818409]\n",
      "  [0.31141371]\n",
      "  [0.31517231]\n",
      "  [0.31887439]\n",
      "  [0.32260799]\n",
      "  [0.32726187]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11623154580593109\n",
      "Predicción post entrenamiento : [[0.33495444]]\n",
      "PERDIDAAAA despues: 0.11427140235900879\n",
      "loss en el callback: 0.12799029052257538, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "ejemplar: [[0.30465162]\n",
      " [0.30818409]\n",
      " [0.31141371]\n",
      " [0.31517231]\n",
      " [0.31887439]\n",
      " [0.32260799]\n",
      " [0.32726187]\n",
      " [0.33206749]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.3375693]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[[0.30465162]\n",
      "  [0.30818409]\n",
      "  [0.31141371]\n",
      "  [0.31517231]\n",
      "  [0.31887439]\n",
      "  [0.32260799]\n",
      "  [0.32726187]\n",
      "  [0.33206749]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1391349732875824\n",
      "Predicción post entrenamiento : [[0.34051645]]\n",
      "PERDIDAAAA despues: 0.13694503903388977\n",
      "loss en el callback: 0.0917305126786232, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "ejemplar: [[0.30818409]\n",
      " [0.31141371]\n",
      " [0.31517231]\n",
      " [0.31887439]\n",
      " [0.32260799]\n",
      " [0.32726187]\n",
      " [0.33206749]\n",
      " [0.3375693 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.34325922]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[[0.30818409]\n",
      "  [0.31141371]\n",
      "  [0.31517231]\n",
      "  [0.31887439]\n",
      "  [0.32260799]\n",
      "  [0.32726187]\n",
      "  [0.33206749]\n",
      "  [0.3375693 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1301272064447403\n",
      "Predicción post entrenamiento : [[0.34621653]]\n",
      "PERDIDAAAA despues: 0.1280023604631424\n",
      "loss en el callback: 0.15639451146125793, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "ejemplar: [[0.31141371]\n",
      " [0.31517231]\n",
      " [0.31887439]\n",
      " [0.32260799]\n",
      " [0.32726187]\n",
      " [0.33206749]\n",
      " [0.3375693 ]\n",
      " [0.34325922]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.34907568]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[[0.31141371]\n",
      "  [0.31517231]\n",
      "  [0.31887439]\n",
      "  [0.32260799]\n",
      "  [0.32726187]\n",
      "  [0.33206749]\n",
      "  [0.3375693 ]\n",
      "  [0.34325922]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14300638437271118\n",
      "Predicción post entrenamiento : [[0.35224423]]\n",
      "PERDIDAAAA despues: 0.14061997830867767\n",
      "loss en el callback: 0.12159386277198792, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "ejemplar: [[0.31517231]\n",
      " [0.31887439]\n",
      " [0.32260799]\n",
      " [0.32726187]\n",
      " [0.33206749]\n",
      " [0.3375693 ]\n",
      " [0.34325922]\n",
      " [0.34907568]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.35535672]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[[0.31517231]\n",
      "  [0.31887439]\n",
      "  [0.32260799]\n",
      "  [0.32726187]\n",
      "  [0.33206749]\n",
      "  [0.3375693 ]\n",
      "  [0.34325922]\n",
      "  [0.34907568]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1348589062690735\n",
      "Predicción post entrenamiento : [[0.35836247]]\n",
      "PERDIDAAAA despues: 0.13266032934188843\n",
      "loss en el callback: 0.1299973726272583, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "ejemplar: [[0.31887439]\n",
      " [0.32260799]\n",
      " [0.32726187]\n",
      " [0.33206749]\n",
      " [0.3375693 ]\n",
      " [0.34325922]\n",
      " [0.34907568]\n",
      " [0.35535672]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.36168456]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[[0.31887439]\n",
      "  [0.32260799]\n",
      "  [0.32726187]\n",
      "  [0.33206749]\n",
      "  [0.3375693 ]\n",
      "  [0.34325922]\n",
      "  [0.34907568]\n",
      "  [0.35535672]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.16818967461585999\n",
      "Predicción post entrenamiento : [[0.36480576]]\n",
      "PERDIDAAAA despues: 0.16563935577869415\n",
      "loss en el callback: 0.17964144051074982, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "ejemplar: [[0.32260799]\n",
      " [0.32726187]\n",
      " [0.33206749]\n",
      " [0.3375693 ]\n",
      " [0.34325922]\n",
      " [0.34907568]\n",
      " [0.35535672]\n",
      " [0.36168456]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.36843204]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[[0.32260799]\n",
      "  [0.32726187]\n",
      "  [0.33206749]\n",
      "  [0.3375693 ]\n",
      "  [0.34325922]\n",
      "  [0.34907568]\n",
      "  [0.35535672]\n",
      "  [0.36168456]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1268024742603302\n",
      "Predicción post entrenamiento : [[0.37115213]]\n",
      "PERDIDAAAA despues: 0.12487266212701797\n",
      "loss en el callback: 0.14108428359031677, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "ejemplar: [[0.32726187]\n",
      " [0.33206749]\n",
      " [0.3375693 ]\n",
      " [0.34325922]\n",
      " [0.34907568]\n",
      " [0.35535672]\n",
      " [0.36168456]\n",
      " [0.36843204]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.37516677]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[[0.32726187]\n",
      "  [0.33206749]\n",
      "  [0.3375693 ]\n",
      "  [0.34325922]\n",
      "  [0.34907568]\n",
      "  [0.35535672]\n",
      "  [0.36168456]\n",
      "  [0.36843204]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08755143731832504\n",
      "Predicción post entrenamiento : [[0.3774867]]\n",
      "PERDIDAAAA despues: 0.08618392795324326\n",
      "loss en el callback: 0.14364391565322876, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "ejemplar: [[0.33206749]\n",
      " [0.3375693 ]\n",
      " [0.34325922]\n",
      " [0.34907568]\n",
      " [0.35535672]\n",
      " [0.36168456]\n",
      " [0.36843204]\n",
      " [0.37516677]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.38175735]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[[0.33206749]\n",
      "  [0.3375693 ]\n",
      "  [0.34325922]\n",
      "  [0.34907568]\n",
      "  [0.35535672]\n",
      "  [0.36168456]\n",
      "  [0.36843204]\n",
      "  [0.37516677]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08527129143476486\n",
      "Predicción post entrenamiento : [[0.3839725]]\n",
      "PERDIDAAAA despues: 0.08398249745368958\n",
      "loss en el callback: 0.09377550333738327, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "ejemplar: [[0.3375693 ]\n",
      " [0.34325922]\n",
      " [0.34907568]\n",
      " [0.35535672]\n",
      " [0.36168456]\n",
      " [0.36843204]\n",
      " [0.37516677]\n",
      " [0.38175735]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.38853213]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[[0.3375693 ]\n",
      "  [0.34325922]\n",
      "  [0.34907568]\n",
      "  [0.35535672]\n",
      "  [0.36168456]\n",
      "  [0.36843204]\n",
      "  [0.37516677]\n",
      "  [0.38175735]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10622362047433853\n",
      "Predicción post entrenamiento : [[0.39102805]]\n",
      "PERDIDAAAA despues: 0.10460291802883148\n",
      "loss en el callback: 0.10542664676904678, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "ejemplar: [[0.34325922]\n",
      " [0.34907568]\n",
      " [0.35535672]\n",
      " [0.36168456]\n",
      " [0.36843204]\n",
      " [0.37516677]\n",
      " [0.38175735]\n",
      " [0.38853213]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.39577106]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[[0.34325922]\n",
      "  [0.34907568]\n",
      "  [0.35535672]\n",
      "  [0.36168456]\n",
      "  [0.36843204]\n",
      "  [0.37516677]\n",
      "  [0.38175735]\n",
      "  [0.38853213]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12119218707084656\n",
      "Predicción post entrenamiento : [[0.39799398]]\n",
      "PERDIDAAAA despues: 0.11964941024780273\n",
      "loss en el callback: 0.07848505675792694, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "ejemplar: [[0.34907568]\n",
      " [0.35535672]\n",
      " [0.36168456]\n",
      " [0.36843204]\n",
      " [0.37516677]\n",
      " [0.38175735]\n",
      " [0.38853213]\n",
      " [0.39577106]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.40292162]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[[0.34907568]\n",
      "  [0.35535672]\n",
      "  [0.36168456]\n",
      "  [0.36843204]\n",
      "  [0.37516677]\n",
      "  [0.38175735]\n",
      "  [0.38853213]\n",
      "  [0.39577106]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1021866723895073\n",
      "Predicción post entrenamiento : [[0.4052748]]\n",
      "PERDIDAAAA despues: 0.10068774223327637\n",
      "loss en el callback: 0.09582015872001648, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "ejemplar: [[0.35535672]\n",
      " [0.36168456]\n",
      " [0.36843204]\n",
      " [0.37516677]\n",
      " [0.38175735]\n",
      " [0.38853213]\n",
      " [0.39577106]\n",
      " [0.40292162]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.41040105]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[[0.35535672]\n",
      "  [0.36168456]\n",
      "  [0.36843204]\n",
      "  [0.37516677]\n",
      "  [0.38175735]\n",
      "  [0.38853213]\n",
      "  [0.39577106]\n",
      "  [0.40292162]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08348650485277176\n",
      "Predicción post entrenamiento : [[0.41248196]]\n",
      "PERDIDAAAA despues: 0.08228830993175507\n",
      "loss en el callback: 0.08307985216379166, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "ejemplar: [[0.36168456]\n",
      " [0.36843204]\n",
      " [0.37516677]\n",
      " [0.38175735]\n",
      " [0.38853213]\n",
      " [0.39577106]\n",
      " [0.40292162]\n",
      " [0.41040105]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.4177347]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[[0.36168456]\n",
      "  [0.36843204]\n",
      "  [0.37516677]\n",
      "  [0.38175735]\n",
      "  [0.38853213]\n",
      "  [0.39577106]\n",
      "  [0.40292162]\n",
      "  [0.41040105]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10212908685207367\n",
      "Predicción post entrenamiento : [[0.4200925]]\n",
      "PERDIDAAAA despues: 0.10062766075134277\n",
      "loss en el callback: 0.16706426441669464, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "ejemplar: [[0.36843204]\n",
      " [0.37516677]\n",
      " [0.38175735]\n",
      " [0.38853213]\n",
      " [0.39577106]\n",
      " [0.40292162]\n",
      " [0.41040105]\n",
      " [0.41773471]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.4254943]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[[0.36843204]\n",
      "  [0.37516677]\n",
      "  [0.38175735]\n",
      "  [0.38853213]\n",
      "  [0.39577106]\n",
      "  [0.40292162]\n",
      "  [0.41040105]\n",
      "  [0.41773471]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08757546544075012\n",
      "Predicción post entrenamiento : [[0.4274208]]\n",
      "PERDIDAAAA despues: 0.08643896132707596\n",
      "loss en el callback: 0.07072588056325912, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "ejemplar: [[0.37516677]\n",
      " [0.38175735]\n",
      " [0.38853213]\n",
      " [0.39577106]\n",
      " [0.40292162]\n",
      " [0.41040105]\n",
      " [0.41773471]\n",
      " [0.42549431]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.43290126]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[[0.37516677]\n",
      "  [0.38175735]\n",
      "  [0.38853213]\n",
      "  [0.39577106]\n",
      "  [0.40292162]\n",
      "  [0.41040105]\n",
      "  [0.41773471]\n",
      "  [0.42549431]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08168874680995941\n",
      "Predicción post entrenamiento : [[0.43483767]]\n",
      "PERDIDAAAA despues: 0.08058559894561768\n",
      "loss en el callback: 0.07345736026763916, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "ejemplar: [[0.38175735]\n",
      " [0.38853213]\n",
      " [0.39577106]\n",
      " [0.40292162]\n",
      " [0.41040105]\n",
      " [0.41773471]\n",
      " [0.42549431]\n",
      " [0.43290126]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.44042775]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[[0.38175735]\n",
      "  [0.38853213]\n",
      "  [0.39577106]\n",
      "  [0.40292162]\n",
      "  [0.41040105]\n",
      "  [0.41773471]\n",
      "  [0.42549431]\n",
      "  [0.43290126]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05462951213121414\n",
      "Predicción post entrenamiento : [[0.44207606]]\n",
      "PERDIDAAAA despues: 0.05386171489953995\n",
      "loss en el callback: 0.055590368807315826, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "ejemplar: [[0.38853213]\n",
      " [0.39577106]\n",
      " [0.40292162]\n",
      " [0.41040105]\n",
      " [0.41773471]\n",
      " [0.42549431]\n",
      " [0.43290126]\n",
      " [0.44042775]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.44784272]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[[0.38853213]\n",
      "  [0.39577106]\n",
      "  [0.40292162]\n",
      "  [0.41040105]\n",
      "  [0.41773471]\n",
      "  [0.42549431]\n",
      "  [0.43290126]\n",
      "  [0.44042775]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06286238133907318\n",
      "Predicción post entrenamiento : [[0.44951594]]\n",
      "PERDIDAAAA despues: 0.06202615052461624\n",
      "loss en el callback: 0.055773112922906876, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "ejemplar: [[0.39577106]\n",
      " [0.40292162]\n",
      " [0.41040105]\n",
      " [0.41773471]\n",
      " [0.42549431]\n",
      " [0.43290126]\n",
      " [0.44042775]\n",
      " [0.44784272]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.45544693]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[[0.39577106]\n",
      "  [0.40292162]\n",
      "  [0.41040105]\n",
      "  [0.41773471]\n",
      "  [0.42549431]\n",
      "  [0.43290126]\n",
      "  [0.44042775]\n",
      "  [0.44784272]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07053879648447037\n",
      "Predicción post entrenamiento : [[0.45664904]]\n",
      "PERDIDAAAA despues: 0.06990170478820801\n",
      "loss en el callback: 0.022059356793761253, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "ejemplar: [[0.40292162]\n",
      " [0.41040105]\n",
      " [0.41773471]\n",
      " [0.42549431]\n",
      " [0.43290126]\n",
      " [0.44042775]\n",
      " [0.44784272]\n",
      " [0.45544693]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.46265063]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[[0.40292162]\n",
      "  [0.41040105]\n",
      "  [0.41773471]\n",
      "  [0.42549431]\n",
      "  [0.43290126]\n",
      "  [0.44042775]\n",
      "  [0.44784272]\n",
      "  [0.45544693]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06756750494241714\n",
      "Predicción post entrenamiento : [[0.46405068]]\n",
      "PERDIDAAAA despues: 0.06684160977602005\n",
      "loss en el callback: 0.03403274342417717, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "ejemplar: [[0.41040105]\n",
      " [0.41773471]\n",
      " [0.42549431]\n",
      " [0.43290126]\n",
      " [0.44042775]\n",
      " [0.44784272]\n",
      " [0.45544693]\n",
      " [0.46265063]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.4701557]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[[0.41040105]\n",
      "  [0.41773471]\n",
      "  [0.42549431]\n",
      "  [0.43290126]\n",
      "  [0.44042775]\n",
      "  [0.44784272]\n",
      "  [0.45544693]\n",
      "  [0.46265063]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08187630027532578\n",
      "Predicción post entrenamiento : [[0.4721656]]\n",
      "PERDIDAAAA despues: 0.08073009550571442\n",
      "loss en el callback: 0.14466430246829987, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "ejemplar: [[0.41773471]\n",
      " [0.42549431]\n",
      " [0.43290126]\n",
      " [0.44042775]\n",
      " [0.44784272]\n",
      " [0.45544693]\n",
      " [0.46265063]\n",
      " [0.47015569]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.47830018]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[[0.41773471]\n",
      "  [0.42549431]\n",
      "  [0.43290126]\n",
      "  [0.44042775]\n",
      "  [0.44784272]\n",
      "  [0.45544693]\n",
      "  [0.46265063]\n",
      "  [0.47015569]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12200074642896652\n",
      "Predicción post entrenamiento : [[0.48070657]]\n",
      "PERDIDAAAA despues: 0.1203254982829094\n",
      "loss en el callback: 0.17549873888492584, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "ejemplar: [[0.42549431]\n",
      " [0.43290126]\n",
      " [0.44042775]\n",
      " [0.44784272]\n",
      " [0.45544693]\n",
      " [0.46265063]\n",
      " [0.47015569]\n",
      " [0.47830018]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.48691228]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[[0.42549431]\n",
      "  [0.43290126]\n",
      "  [0.44042775]\n",
      "  [0.44784272]\n",
      "  [0.45544693]\n",
      "  [0.46265063]\n",
      "  [0.47015569]\n",
      "  [0.47830018]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1238405853509903\n",
      "Predicción post entrenamiento : [[0.48910657]]\n",
      "PERDIDAAAA despues: 0.12230101227760315\n",
      "loss en el callback: 0.0937410444021225, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "ejemplar: [[0.43290126]\n",
      " [0.44042775]\n",
      " [0.44784272]\n",
      " [0.45544693]\n",
      " [0.46265063]\n",
      " [0.47015569]\n",
      " [0.47830018]\n",
      " [0.48691228]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.49528468]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[[0.43290126]\n",
      "  [0.44042775]\n",
      "  [0.44784272]\n",
      "  [0.45544693]\n",
      "  [0.46265063]\n",
      "  [0.47015569]\n",
      "  [0.47830018]\n",
      "  [0.48691228]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08938971906900406\n",
      "Predicción post entrenamiento : [[0.4973143]]\n",
      "PERDIDAAAA despues: 0.08818019181489944\n",
      "loss en el callback: 0.09802581369876862, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "ejemplar: [[0.44042775]\n",
      " [0.44784272]\n",
      " [0.45544693]\n",
      " [0.46265063]\n",
      " [0.47015569]\n",
      " [0.47830018]\n",
      " [0.48691228]\n",
      " [0.49528468]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.5035671]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[[0.44042775]\n",
      "  [0.44784272]\n",
      "  [0.45544693]\n",
      "  [0.46265063]\n",
      "  [0.47015569]\n",
      "  [0.47830018]\n",
      "  [0.48691228]\n",
      "  [0.49528468]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0785331204533577\n",
      "Predicción post entrenamiento : [[0.5055661]]\n",
      "PERDIDAAAA despues: 0.07741671800613403\n",
      "loss en el callback: 0.10361827164888382, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "ejemplar: [[0.44784272]\n",
      " [0.45544693]\n",
      " [0.46265063]\n",
      " [0.47015569]\n",
      " [0.47830018]\n",
      " [0.48691228]\n",
      " [0.49528468]\n",
      " [0.5035671 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.51189065]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[[0.44784272]\n",
      "  [0.45544693]\n",
      "  [0.46265063]\n",
      "  [0.47015569]\n",
      "  [0.47830018]\n",
      "  [0.48691228]\n",
      "  [0.49528468]\n",
      "  [0.5035671 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06555072963237762\n",
      "Predicción post entrenamiento : [[0.51334864]]\n",
      "PERDIDAAAA despues: 0.06480628252029419\n",
      "loss en el callback: 0.04269930347800255, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "ejemplar: [[0.45544693]\n",
      " [0.46265063]\n",
      " [0.47015569]\n",
      " [0.47830018]\n",
      " [0.48691228]\n",
      " [0.49528468]\n",
      " [0.5035671 ]\n",
      " [0.51189065]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.51980543]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[[0.45544693]\n",
      "  [0.46265063]\n",
      "  [0.47015569]\n",
      "  [0.47830018]\n",
      "  [0.48691228]\n",
      "  [0.49528468]\n",
      "  [0.5035671 ]\n",
      "  [0.51189065]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07010538130998611\n",
      "Predicción post entrenamiento : [[0.5214572]]\n",
      "PERDIDAAAA despues: 0.06923341751098633\n",
      "loss en el callback: 0.06929519027471542, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "ejemplar: [[0.46265063]\n",
      " [0.47015569]\n",
      " [0.47830018]\n",
      " [0.48691228]\n",
      " [0.49528468]\n",
      " [0.5035671 ]\n",
      " [0.51189065]\n",
      " [0.51980543]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.528033]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[[0.46265063]\n",
      "  [0.47015569]\n",
      "  [0.47830018]\n",
      "  [0.48691228]\n",
      "  [0.49528468]\n",
      "  [0.5035671 ]\n",
      "  [0.51189065]\n",
      "  [0.51980543]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1229877844452858\n",
      "Predicción post entrenamiento : [[0.5304259]]\n",
      "PERDIDAAAA despues: 0.12131515890359879\n",
      "loss en el callback: 0.14340905845165253, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "ejemplar: [[0.47015569]\n",
      " [0.47830018]\n",
      " [0.48691228]\n",
      " [0.49528468]\n",
      " [0.5035671 ]\n",
      " [0.51189065]\n",
      " [0.51980543]\n",
      " [0.52803302]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.5372609]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[[0.47015569]\n",
      "  [0.47830018]\n",
      "  [0.48691228]\n",
      "  [0.49528468]\n",
      "  [0.5035671 ]\n",
      "  [0.51189065]\n",
      "  [0.51980543]\n",
      "  [0.52803302]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11449338495731354\n",
      "Predicción post entrenamiento : [[0.5395879]]\n",
      "PERDIDAAAA despues: 0.1129240170121193\n",
      "loss en el callback: 0.1850784868001938, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "ejemplar: [[0.47830018]\n",
      " [0.48691228]\n",
      " [0.49528468]\n",
      " [0.5035671 ]\n",
      " [0.51189065]\n",
      " [0.51980543]\n",
      " [0.52803302]\n",
      " [0.53726089]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.54664576]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[[0.47830018]\n",
      "  [0.48691228]\n",
      "  [0.49528468]\n",
      "  [0.5035671 ]\n",
      "  [0.51189065]\n",
      "  [0.51980543]\n",
      "  [0.52803302]\n",
      "  [0.53726089]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09135507792234421\n",
      "Predicción post entrenamiento : [[0.54829174]]\n",
      "PERDIDAAAA despues: 0.0903627946972847\n",
      "loss en el callback: 0.060460641980171204, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "ejemplar: [[0.48691228]\n",
      " [0.49528468]\n",
      " [0.5035671 ]\n",
      " [0.51189065]\n",
      " [0.51980543]\n",
      " [0.52803302]\n",
      " [0.53726089]\n",
      " [0.54664576]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.55543596]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[[0.48691228]\n",
      "  [0.49528468]\n",
      "  [0.5035671 ]\n",
      "  [0.51189065]\n",
      "  [0.51980543]\n",
      "  [0.52803302]\n",
      "  [0.53726089]\n",
      "  [0.54664576]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06909093260765076\n",
      "Predicción post entrenamiento : [[0.5567761]]\n",
      "PERDIDAAAA despues: 0.0683882012963295\n",
      "loss en el callback: 0.03935081511735916, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "ejemplar: [[0.49528468]\n",
      " [0.5035671 ]\n",
      " [0.51189065]\n",
      " [0.51980543]\n",
      " [0.52803302]\n",
      " [0.53726089]\n",
      " [0.54664576]\n",
      " [0.55543596]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.56389916]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[[0.49528468]\n",
      "  [0.5035671 ]\n",
      "  [0.51189065]\n",
      "  [0.51980543]\n",
      "  [0.52803302]\n",
      "  [0.53726089]\n",
      "  [0.54664576]\n",
      "  [0.55543596]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0691227987408638\n",
      "Predicción post entrenamiento : [[0.5655765]]\n",
      "PERDIDAAAA despues: 0.06824363023042679\n",
      "loss en el callback: 0.07487844675779343, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "ejemplar: [[0.5035671 ]\n",
      " [0.51189065]\n",
      " [0.51980543]\n",
      " [0.52803302]\n",
      " [0.53726089]\n",
      " [0.54664576]\n",
      " [0.55543596]\n",
      " [0.56389916]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.5727541]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[[0.5035671 ]\n",
      "  [0.51189065]\n",
      "  [0.51980543]\n",
      "  [0.52803302]\n",
      "  [0.53726089]\n",
      "  [0.54664576]\n",
      "  [0.55543596]\n",
      "  [0.56389916]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04519893601536751\n",
      "Predicción post entrenamiento : [[0.5741644]]\n",
      "PERDIDAAAA despues: 0.044601261615753174\n",
      "loss en el callback: 0.05036201328039169, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "ejemplar: [[0.51189065]\n",
      " [0.51980543]\n",
      " [0.52803302]\n",
      " [0.53726089]\n",
      " [0.54664576]\n",
      " [0.55543596]\n",
      " [0.56389916]\n",
      " [0.57275409]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.58144224]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[[0.51189065]\n",
      "  [0.51980543]\n",
      "  [0.52803302]\n",
      "  [0.53726089]\n",
      "  [0.54664576]\n",
      "  [0.55543596]\n",
      "  [0.56389916]\n",
      "  [0.57275409]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04317532852292061\n",
      "Predicción post entrenamiento : [[0.5823286]]\n",
      "PERDIDAAAA despues: 0.04280775785446167\n",
      "loss en el callback: 0.015962405130267143, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "ejemplar: [[0.51980543]\n",
      " [0.52803302]\n",
      " [0.53726089]\n",
      " [0.54664576]\n",
      " [0.55543596]\n",
      " [0.56389916]\n",
      " [0.57275409]\n",
      " [0.58144224]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.58971876]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[[0.51980543]\n",
      "  [0.52803302]\n",
      "  [0.53726089]\n",
      "  [0.54664576]\n",
      "  [0.55543596]\n",
      "  [0.56389916]\n",
      "  [0.57275409]\n",
      "  [0.58144224]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.059757769107818604\n",
      "Predicción post entrenamiento : [[0.59117484]]\n",
      "PERDIDAAAA despues: 0.05904800072312355\n",
      "loss en el callback: 0.061056964099407196, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "ejemplar: [[0.52803302]\n",
      " [0.53726089]\n",
      " [0.54664576]\n",
      " [0.55543596]\n",
      " [0.56389916]\n",
      " [0.57275409]\n",
      " [0.58144224]\n",
      " [0.58971876]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.5988112]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[[0.52803302]\n",
      "  [0.53726089]\n",
      "  [0.54664576]\n",
      "  [0.55543596]\n",
      "  [0.56389916]\n",
      "  [0.57275409]\n",
      "  [0.58144224]\n",
      "  [0.58971876]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04565255716443062\n",
      "Predicción post entrenamiento : [[0.600305]]\n",
      "PERDIDAAAA despues: 0.045016441494226456\n",
      "loss en el callback: 0.0693795382976532, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "ejemplar: [[0.53726089]\n",
      " [0.54664576]\n",
      " [0.55543596]\n",
      " [0.56389916]\n",
      " [0.57275409]\n",
      " [0.58144224]\n",
      " [0.58971876]\n",
      " [0.59881121]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.6081291]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[[0.53726089]\n",
      "  [0.54664576]\n",
      "  [0.55543596]\n",
      "  [0.56389916]\n",
      "  [0.57275409]\n",
      "  [0.58144224]\n",
      "  [0.58971876]\n",
      "  [0.59881121]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.037291768938302994\n",
      "Predicción post entrenamiento : [[0.60939723]]\n",
      "PERDIDAAAA despues: 0.03680358827114105\n",
      "loss en el callback: 0.04334177076816559, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "ejemplar: [[0.54664576]\n",
      " [0.55543596]\n",
      " [0.56389916]\n",
      " [0.57275409]\n",
      " [0.58144224]\n",
      " [0.58971876]\n",
      " [0.59881121]\n",
      " [0.60812908]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.61714506]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[[0.54664576]\n",
      "  [0.55543596]\n",
      "  [0.56389916]\n",
      "  [0.57275409]\n",
      "  [0.58144224]\n",
      "  [0.58971876]\n",
      "  [0.59881121]\n",
      "  [0.60812908]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0346079021692276\n",
      "Predicción post entrenamiento : [[0.618253]]\n",
      "PERDIDAAAA despues: 0.03419690951704979\n",
      "loss en el callback: 0.03233926370739937, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "ejemplar: [[0.55543596]\n",
      " [0.56389916]\n",
      " [0.57275409]\n",
      " [0.58144224]\n",
      " [0.58971876]\n",
      " [0.59881121]\n",
      " [0.60812908]\n",
      " [0.61714506]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.6258636]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[[0.55543596]\n",
      "  [0.56389916]\n",
      "  [0.57275409]\n",
      "  [0.58144224]\n",
      "  [0.58971876]\n",
      "  [0.59881121]\n",
      "  [0.60812908]\n",
      "  [0.61714506]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.028098903596401215\n",
      "Predicción post entrenamiento : [[0.6272132]]\n",
      "PERDIDAAAA despues: 0.02764827571809292\n",
      "loss en el callback: 0.05941213294863701, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "ejemplar: [[0.56389916]\n",
      " [0.57275409]\n",
      " [0.58144224]\n",
      " [0.58971876]\n",
      " [0.59881121]\n",
      " [0.60812908]\n",
      " [0.61714506]\n",
      " [0.62586361]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.63483775]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[[0.56389916]\n",
      "  [0.57275409]\n",
      "  [0.58144224]\n",
      "  [0.58971876]\n",
      "  [0.59881121]\n",
      "  [0.60812908]\n",
      "  [0.61714506]\n",
      "  [0.62586361]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015708288177847862\n",
      "Predicción post entrenamiento : [[0.63567203]]\n",
      "PERDIDAAAA despues: 0.015499858185648918\n",
      "loss en el callback: 0.020383475348353386, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "ejemplar: [[0.57275409]\n",
      " [0.58144224]\n",
      " [0.58971876]\n",
      " [0.59881121]\n",
      " [0.60812908]\n",
      " [0.61714506]\n",
      " [0.62586361]\n",
      " [0.63483775]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.6434089]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[[0.57275409]\n",
      "  [0.58144224]\n",
      "  [0.58971876]\n",
      "  [0.59881121]\n",
      "  [0.60812908]\n",
      "  [0.61714506]\n",
      "  [0.62586361]\n",
      "  [0.63483775]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008457564748823643\n",
      "Predicción post entrenamiento : [[0.6438212]]\n",
      "PERDIDAAAA despues: 0.008381903171539307\n",
      "loss en el callback: 0.0045549459755420685, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "ejemplar: [[0.58144224]\n",
      " [0.58971876]\n",
      " [0.59881121]\n",
      " [0.60812908]\n",
      " [0.61714506]\n",
      " [0.62586361]\n",
      " [0.63483775]\n",
      " [0.64340889]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.6515763]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[[0.58144224]\n",
      "  [0.58971876]\n",
      "  [0.59881121]\n",
      "  [0.60812908]\n",
      "  [0.61714506]\n",
      "  [0.62586361]\n",
      "  [0.63483775]\n",
      "  [0.64340889]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00343554699793458\n",
      "Predicción post entrenamiento : [[0.6521792]]\n",
      "PERDIDAAAA despues: 0.0033652340061962605\n",
      "loss en el callback: 0.011677556671202183, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "ejemplar: [[0.58971876]\n",
      " [0.59881121]\n",
      " [0.60812908]\n",
      " [0.61714506]\n",
      " [0.62586361]\n",
      " [0.63483775]\n",
      " [0.64340889]\n",
      " [0.65157628]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.65999913]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[[0.58971876]\n",
      "  [0.59881121]\n",
      "  [0.60812908]\n",
      "  [0.61714506]\n",
      "  [0.62586361]\n",
      "  [0.63483775]\n",
      "  [0.64340889]\n",
      "  [0.65157628]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0027173238340765238\n",
      "Predicción post entrenamiento : [[0.6599212]]\n",
      "PERDIDAAAA despues: 0.0027254519518464804\n",
      "loss en el callback: 0.00015737826470285654, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "ejemplar: [[0.59881121]\n",
      " [0.60812908]\n",
      " [0.61714506]\n",
      " [0.62586361]\n",
      " [0.63483775]\n",
      " [0.64340889]\n",
      " [0.65157628]\n",
      " [0.65999913]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.6679177]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[[0.59881121]\n",
      "  [0.60812908]\n",
      "  [0.61714506]\n",
      "  [0.62586361]\n",
      "  [0.63483775]\n",
      "  [0.64340889]\n",
      "  [0.65157628]\n",
      "  [0.65999913]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005143485497683287\n",
      "Predicción post entrenamiento : [[0.6674629]]\n",
      "PERDIDAAAA despues: 0.005208933260291815\n",
      "loss en el callback: 0.004215768538415432, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "ejemplar: [[0.60812908]\n",
      " [0.61714506]\n",
      " [0.62586361]\n",
      " [0.63483775]\n",
      " [0.64340889]\n",
      " [0.65157628]\n",
      " [0.65999913]\n",
      " [0.66791773]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.6754022]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[[0.60812908]\n",
      "  [0.61714506]\n",
      "  [0.62586361]\n",
      "  [0.63483775]\n",
      "  [0.64340889]\n",
      "  [0.65157628]\n",
      "  [0.65999913]\n",
      "  [0.66791773]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003690143348649144\n",
      "Predicción post entrenamiento : [[0.67612445]]\n",
      "PERDIDAAAA despues: 0.0036029191687703133\n",
      "loss en el callback: 0.02073054015636444, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "ejemplar: [[0.61714506]\n",
      " [0.62586361]\n",
      " [0.63483775]\n",
      " [0.64340889]\n",
      " [0.65157628]\n",
      " [0.65999913]\n",
      " [0.66791773]\n",
      " [0.67540222]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.6839058]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[[0.61714506]\n",
      "  [0.62586361]\n",
      "  [0.63483775]\n",
      "  [0.64340889]\n",
      "  [0.65157628]\n",
      "  [0.65999913]\n",
      "  [0.66791773]\n",
      "  [0.67540222]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00026683451142162085\n",
      "Predicción post entrenamiento : [[0.6838817]]\n",
      "PERDIDAAAA despues: 0.000266048387857154\n",
      "loss en el callback: 1.743466782500036e-05, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "ejemplar: [[0.62586361]\n",
      " [0.63483775]\n",
      " [0.64340889]\n",
      " [0.65157628]\n",
      " [0.65999913]\n",
      " [0.66791773]\n",
      " [0.67540222]\n",
      " [0.68390578]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.6915371]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[[0.62586361]\n",
      "  [0.63483775]\n",
      "  [0.64340889]\n",
      "  [0.65157628]\n",
      "  [0.65999913]\n",
      "  [0.66791773]\n",
      "  [0.67540222]\n",
      "  [0.68390578]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004683619481511414\n",
      "Predicción post entrenamiento : [[0.6920405]]\n",
      "PERDIDAAAA despues: 0.0004904051311314106\n",
      "loss en el callback: 0.010168627835810184, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "ejemplar: [[0.63483775]\n",
      " [0.64340889]\n",
      " [0.65157628]\n",
      " [0.65999913]\n",
      " [0.66791773]\n",
      " [0.67540222]\n",
      " [0.68390578]\n",
      " [0.69153708]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.69961137]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[[0.63483775]\n",
      "  [0.64340889]\n",
      "  [0.65157628]\n",
      "  [0.65999913]\n",
      "  [0.66791773]\n",
      "  [0.67540222]\n",
      "  [0.68390578]\n",
      "  [0.69153708]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.893156518752221e-06\n",
      "Predicción post entrenamiento : [[0.70009327]]\n",
      "PERDIDAAAA despues: 1.1999594789813273e-05\n",
      "loss en el callback: 0.00867257360368967, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "ejemplar: [[0.64340889]\n",
      " [0.65157628]\n",
      " [0.65999913]\n",
      " [0.66791773]\n",
      " [0.67540222]\n",
      " [0.68390578]\n",
      " [0.69153708]\n",
      " [0.69961137]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.7074706]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[[0.64340889]\n",
      "  [0.65157628]\n",
      "  [0.65999913]\n",
      "  [0.66791773]\n",
      "  [0.67540222]\n",
      "  [0.68390578]\n",
      "  [0.69153708]\n",
      "  [0.69961137]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002654647221788764\n",
      "Predicción post entrenamiento : [[0.70750314]]\n",
      "PERDIDAAAA despues: 0.002658001845702529\n",
      "loss en el callback: 3.5936875065090135e-05, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "ejemplar: [[0.65157628]\n",
      " [0.65999913]\n",
      " [0.66791773]\n",
      " [0.67540222]\n",
      " [0.68390578]\n",
      " [0.69153708]\n",
      " [0.69961137]\n",
      " [0.7074706 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.71475786]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[[0.65157628]\n",
      "  [0.65999913]\n",
      "  [0.66791773]\n",
      "  [0.67540222]\n",
      "  [0.68390578]\n",
      "  [0.69153708]\n",
      "  [0.69961137]\n",
      "  [0.7074706 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012924885377287865\n",
      "Predicción post entrenamiento : [[0.7151223]]\n",
      "PERDIDAAAA despues: 0.0013188242446631193\n",
      "loss en el callback: 0.005584543105214834, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "ejemplar: [[0.65999913]\n",
      " [0.66791773]\n",
      " [0.67540222]\n",
      " [0.68390578]\n",
      " [0.69153708]\n",
      " [0.69961137]\n",
      " [0.7074706 ]\n",
      " [0.71475786]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.7223409]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[[0.65999913]\n",
      "  [0.66791773]\n",
      "  [0.67540222]\n",
      "  [0.68390578]\n",
      "  [0.69153708]\n",
      "  [0.69961137]\n",
      "  [0.7074706 ]\n",
      "  [0.71475786]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002138724783435464\n",
      "Predicción post entrenamiento : [[0.72242534]]\n",
      "PERDIDAAAA despues: 0.002146543934941292\n",
      "loss en el callback: 0.00025549583369866014, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "ejemplar: [[0.66791773]\n",
      " [0.67540222]\n",
      " [0.68390578]\n",
      " [0.69153708]\n",
      " [0.69961137]\n",
      " [0.7074706 ]\n",
      " [0.71475786]\n",
      " [0.72234088]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.7295137]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[[0.66791773]\n",
      "  [0.67540222]\n",
      "  [0.68390578]\n",
      "  [0.69153708]\n",
      "  [0.69961137]\n",
      "  [0.7074706 ]\n",
      "  [0.71475786]\n",
      "  [0.72234088]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.3482336075630883e-09\n",
      "Predicción post entrenamiento : [[0.7298676]]\n",
      "PERDIDAAAA despues: 9.327783345725038e-08\n",
      "loss en el callback: 0.004446693230420351, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "ejemplar: [[0.67540222]\n",
      " [0.68390578]\n",
      " [0.69153708]\n",
      " [0.69961137]\n",
      " [0.7074706 ]\n",
      " [0.71475786]\n",
      " [0.72234088]\n",
      " [0.7295137 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.7369411]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[[0.67540222]\n",
      "  [0.68390578]\n",
      "  [0.69153708]\n",
      "  [0.69961137]\n",
      "  [0.7074706 ]\n",
      "  [0.71475786]\n",
      "  [0.72234088]\n",
      "  [0.7295137 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012718162033706903\n",
      "Predicción post entrenamiento : [[0.7361701]]\n",
      "PERDIDAAAA despues: 0.0012174199800938368\n",
      "loss en el callback: 0.015065803192555904, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "ejemplar: [[0.68390578]\n",
      " [0.69153708]\n",
      " [0.69961137]\n",
      " [0.7074706 ]\n",
      " [0.71475786]\n",
      " [0.72234088]\n",
      " [0.7295137 ]\n",
      " [0.7369411 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.74333197]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[[0.68390578]\n",
      "  [0.69153708]\n",
      "  [0.69961137]\n",
      "  [0.7074706 ]\n",
      "  [0.71475786]\n",
      "  [0.72234088]\n",
      "  [0.7295137 ]\n",
      "  [0.7369411 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005856410716660321\n",
      "Predicción post entrenamiento : [[0.74400043]]\n",
      "PERDIDAAAA despues: 0.0005537341348826885\n",
      "loss en el callback: 0.017993096262216568, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "ejemplar: [[0.69153708]\n",
      " [0.69961137]\n",
      " [0.7074706 ]\n",
      " [0.71475786]\n",
      " [0.72234088]\n",
      " [0.7295137 ]\n",
      " [0.7369411 ]\n",
      " [0.74333197]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.7509442]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[[0.69153708]\n",
      "  [0.69961137]\n",
      "  [0.7074706 ]\n",
      "  [0.71475786]\n",
      "  [0.72234088]\n",
      "  [0.7295137 ]\n",
      "  [0.7369411 ]\n",
      "  [0.74333197]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.7551836208440363e-05\n",
      "Predicción post entrenamiento : [[0.7504275]]\n",
      "PERDIDAAAA despues: 2.214835512859281e-05\n",
      "loss en el callback: 0.006975898053497076, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "ejemplar: [[0.69961137]\n",
      " [0.7074706 ]\n",
      " [0.71475786]\n",
      " [0.72234088]\n",
      " [0.7295137 ]\n",
      " [0.7369411 ]\n",
      " [0.74333197]\n",
      " [0.7509442 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.75734943]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[[0.69961137]\n",
      "  [0.7074706 ]\n",
      "  [0.71475786]\n",
      "  [0.72234088]\n",
      "  [0.7295137 ]\n",
      "  [0.7369411 ]\n",
      "  [0.74333197]\n",
      "  [0.7509442 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00015102946781553328\n",
      "Predicción post entrenamiento : [[0.75788367]]\n",
      "PERDIDAAAA despues: 0.00016444578068330884\n",
      "loss en el callback: 0.0125587685033679, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "ejemplar: [[0.7074706 ]\n",
      " [0.71475786]\n",
      " [0.72234088]\n",
      " [0.7295137 ]\n",
      " [0.7369411 ]\n",
      " [0.74333197]\n",
      " [0.7509442 ]\n",
      " [0.75734943]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.7646285]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[[0.7074706 ]\n",
      "  [0.71475786]\n",
      "  [0.72234088]\n",
      "  [0.7295137 ]\n",
      "  [0.7369411 ]\n",
      "  [0.74333197]\n",
      "  [0.7509442 ]\n",
      "  [0.75734943]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00015862045984249562\n",
      "Predicción post entrenamiento : [[0.76466715]]\n",
      "PERDIDAAAA despues: 0.00015959484153427184\n",
      "loss en el callback: 5.229163070907816e-05, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "ejemplar: [[0.71475786]\n",
      " [0.72234088]\n",
      " [0.7295137 ]\n",
      " [0.7369411 ]\n",
      " [0.74333197]\n",
      " [0.7509442 ]\n",
      " [0.75734943]\n",
      " [0.76462853]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.7712515]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[[0.71475786]\n",
      "  [0.72234088]\n",
      "  [0.7295137 ]\n",
      "  [0.7369411 ]\n",
      "  [0.74333197]\n",
      "  [0.7509442 ]\n",
      "  [0.75734943]\n",
      "  [0.76462853]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0037759931292384863\n",
      "Predicción post entrenamiento : [[0.77068955]]\n",
      "PERDIDAAAA despues: 0.003707245923578739\n",
      "loss en el callback: 0.009994867257773876, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "ejemplar: [[0.72234088]\n",
      " [0.7295137 ]\n",
      " [0.7369411 ]\n",
      " [0.74333197]\n",
      " [0.7509442 ]\n",
      " [0.75734943]\n",
      " [0.76462853]\n",
      " [0.7712515 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.7772393]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[[0.72234088]\n",
      "  [0.7295137 ]\n",
      "  [0.7369411 ]\n",
      "  [0.74333197]\n",
      "  [0.7509442 ]\n",
      "  [0.75734943]\n",
      "  [0.76462853]\n",
      "  [0.7712515 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007535850629210472\n",
      "Predicción post entrenamiento : [[0.7760877]]\n",
      "PERDIDAAAA despues: 0.007337233982980251\n",
      "loss en el callback: 0.03416067734360695, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "ejemplar: [[0.7295137 ]\n",
      " [0.7369411 ]\n",
      " [0.74333197]\n",
      " [0.7509442 ]\n",
      " [0.75734943]\n",
      " [0.76462853]\n",
      " [0.7712515 ]\n",
      " [0.77723932]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.7824905]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[[0.7295137 ]\n",
      "  [0.7369411 ]\n",
      "  [0.74333197]\n",
      "  [0.7509442 ]\n",
      "  [0.75734943]\n",
      "  [0.76462853]\n",
      "  [0.7712515 ]\n",
      "  [0.77723932]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007913938607089221\n",
      "Predicción post entrenamiento : [[0.78121394]]\n",
      "PERDIDAAAA despues: 0.0007212001946754754\n",
      "loss en el callback: 0.03940039500594139, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "ejemplar: [[0.7369411 ]\n",
      " [0.74333197]\n",
      " [0.7509442 ]\n",
      " [0.75734943]\n",
      " [0.76462853]\n",
      " [0.7712515 ]\n",
      " [0.77723932]\n",
      " [0.78249049]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.7875419]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[[0.7369411 ]\n",
      "  [0.74333197]\n",
      "  [0.7509442 ]\n",
      "  [0.75734943]\n",
      "  [0.76462853]\n",
      "  [0.7712515 ]\n",
      "  [0.77723932]\n",
      "  [0.78249049]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004269476979970932\n",
      "Predicción post entrenamiento : [[0.787672]]\n",
      "PERDIDAAAA despues: 0.00428648991510272\n",
      "loss en el callback: 0.0007757172570563853, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "ejemplar: [[0.74333197]\n",
      " [0.7509442 ]\n",
      " [0.75734943]\n",
      " [0.76462853]\n",
      " [0.7712515 ]\n",
      " [0.77723932]\n",
      " [0.78249049]\n",
      " [0.78754193]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.79380757]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[[0.74333197]\n",
      "  [0.7509442 ]\n",
      "  [0.75734943]\n",
      "  [0.76462853]\n",
      "  [0.7712515 ]\n",
      "  [0.77723932]\n",
      "  [0.78249049]\n",
      "  [0.78754193]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029921766836196184\n",
      "Predicción post entrenamiento : [[0.79474694]]\n",
      "PERDIDAAAA despues: 0.0028902904596179724\n",
      "loss en el callback: 0.04192500561475754, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "ejemplar: [[0.7509442 ]\n",
      " [0.75734943]\n",
      " [0.76462853]\n",
      " [0.7712515 ]\n",
      " [0.77723932]\n",
      " [0.78249049]\n",
      " [0.78754193]\n",
      " [0.79380757]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.8009288]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[[0.7509442 ]\n",
      "  [0.75734943]\n",
      "  [0.76462853]\n",
      "  [0.7712515 ]\n",
      "  [0.77723932]\n",
      "  [0.78249049]\n",
      "  [0.78754193]\n",
      "  [0.79380757]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010927400551736355\n",
      "Predicción post entrenamiento : [[0.80096954]]\n",
      "PERDIDAAAA despues: 0.010918878950178623\n",
      "loss en el callback: 4.677895049098879e-05, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "ejemplar: [[0.75734943]\n",
      " [0.76462853]\n",
      " [0.7712515 ]\n",
      " [0.77723932]\n",
      " [0.78249049]\n",
      " [0.78754193]\n",
      " [0.79380757]\n",
      " [0.80092877]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.8068085]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[[0.75734943]\n",
      "  [0.76462853]\n",
      "  [0.7712515 ]\n",
      "  [0.77723932]\n",
      "  [0.78249049]\n",
      "  [0.78754193]\n",
      "  [0.79380757]\n",
      "  [0.80092877]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005686327815055847\n",
      "Predicción post entrenamiento : [[0.80737877]]\n",
      "PERDIDAAAA despues: 0.005600643344223499\n",
      "loss en el callback: 0.012654844671487808, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "ejemplar: [[0.76462853]\n",
      " [0.7712515 ]\n",
      " [0.77723932]\n",
      " [0.78249049]\n",
      " [0.78754193]\n",
      " [0.79380757]\n",
      " [0.80092877]\n",
      " [0.80680847]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.81315887]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[[0.76462853]\n",
      "  [0.7712515 ]\n",
      "  [0.77723932]\n",
      "  [0.78249049]\n",
      "  [0.78754193]\n",
      "  [0.79380757]\n",
      "  [0.80092877]\n",
      "  [0.80680847]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008954611606895924\n",
      "Predicción post entrenamiento : [[0.81368303]]\n",
      "PERDIDAAAA despues: 0.008855684660375118\n",
      "loss en el callback: 0.00965043343603611, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "ejemplar: [[0.7712515 ]\n",
      " [0.77723932]\n",
      " [0.78249049]\n",
      " [0.78754193]\n",
      " [0.79380757]\n",
      " [0.80092877]\n",
      " [0.80680847]\n",
      " [0.81315887]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.81912684]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[[0.7712515 ]\n",
      "  [0.77723932]\n",
      "  [0.78249049]\n",
      "  [0.78754193]\n",
      "  [0.79380757]\n",
      "  [0.80092877]\n",
      "  [0.80680847]\n",
      "  [0.81315887]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004963321145623922\n",
      "Predicción post entrenamiento : [[0.819197]]\n",
      "PERDIDAAAA despues: 0.004953441210091114\n",
      "loss en el callback: 0.00014325625670608133, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "ejemplar: [[0.77723932]\n",
      " [0.78249049]\n",
      " [0.78754193]\n",
      " [0.79380757]\n",
      " [0.80092877]\n",
      " [0.80680847]\n",
      " [0.81315887]\n",
      " [0.81912684]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.8244545]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[[0.77723932]\n",
      "  [0.78249049]\n",
      "  [0.78754193]\n",
      "  [0.79380757]\n",
      "  [0.80092877]\n",
      "  [0.80680847]\n",
      "  [0.81315887]\n",
      "  [0.81912684]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002540179993957281\n",
      "Predicción post entrenamiento : [[0.8241559]]\n",
      "PERDIDAAAA despues: 0.002570363925769925\n",
      "loss en el callback: 0.0026714846026152372, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "ejemplar: [[0.78249049]\n",
      " [0.78754193]\n",
      " [0.79380757]\n",
      " [0.80092877]\n",
      " [0.80680847]\n",
      " [0.81315887]\n",
      " [0.81912684]\n",
      " [0.82445449]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.8294009]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[[0.78249049]\n",
      "  [0.78754193]\n",
      "  [0.79380757]\n",
      "  [0.80092877]\n",
      "  [0.80680847]\n",
      "  [0.81315887]\n",
      "  [0.81912684]\n",
      "  [0.82445449]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0070242914371192455\n",
      "Predicción post entrenamiento : [[0.8293234]]\n",
      "PERDIDAAAA despues: 0.007037285715341568\n",
      "loss en el callback: 0.00018407078459858894, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "ejemplar: [[0.78754193]\n",
      " [0.79380757]\n",
      " [0.80092877]\n",
      " [0.80680847]\n",
      " [0.81315887]\n",
      " [0.81912684]\n",
      " [0.82445449]\n",
      " [0.8294009 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 1.0\n",
      "Predicción : [[0.83477557]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[[0.78754193]\n",
      "  [0.79380757]\n",
      "  [0.80092877]\n",
      "  [0.80680847]\n",
      "  [0.81315887]\n",
      "  [0.81912684]\n",
      "  [0.82445449]\n",
      "  [0.8294009 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02729911357164383\n",
      "Predicción post entrenamiento : [[0.8354797]]\n",
      "PERDIDAAAA despues: 0.02706693671643734\n",
      "loss en el callback: 0.01634545437991619, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "ejemplar: [[0.79380757]\n",
      " [0.80092877]\n",
      " [0.80680847]\n",
      " [0.81315887]\n",
      " [0.81912684]\n",
      " [0.82445449]\n",
      " [0.8294009 ]\n",
      " [0.83477557]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.8412147]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[[0.79380757]\n",
      "  [0.80092877]\n",
      "  [0.80680847]\n",
      "  [0.81315887]\n",
      "  [0.81912684]\n",
      "  [0.82445449]\n",
      "  [0.8294009 ]\n",
      "  [0.83477557]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016728663817048073\n",
      "Predicción post entrenamiento : [[0.84127617]]\n",
      "PERDIDAAAA despues: 0.016712771728634834\n",
      "loss en el callback: 0.00011121620627818629, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "ejemplar: [[0.80092877]\n",
      " [0.80680847]\n",
      " [0.81315887]\n",
      " [0.81912684]\n",
      " [0.82445449]\n",
      " [0.8294009 ]\n",
      " [0.83477557]\n",
      " [0.84121472]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.846946]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[[0.80092877]\n",
      "  [0.80680847]\n",
      "  [0.81315887]\n",
      "  [0.81912684]\n",
      "  [0.82445449]\n",
      "  [0.8294009 ]\n",
      "  [0.83477557]\n",
      "  [0.84121472]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017519888933748007\n",
      "Predicción post entrenamiento : [[0.8474922]]\n",
      "PERDIDAAAA despues: 0.001706561422906816\n",
      "loss en el callback: 0.012691629119217396, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "ejemplar: [[0.80680847]\n",
      " [0.81315887]\n",
      " [0.81912684]\n",
      " [0.82445449]\n",
      " [0.8294009 ]\n",
      " [0.83477557]\n",
      " [0.84121472]\n",
      " [0.846946  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.8528105]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[[0.80680847]\n",
      "  [0.81315887]\n",
      "  [0.81912684]\n",
      "  [0.82445449]\n",
      "  [0.8294009 ]\n",
      "  [0.83477557]\n",
      "  [0.84121472]\n",
      "  [0.846946  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006322108092717826\n",
      "Predicción post entrenamiento : [[0.8530835]]\n",
      "PERDIDAAAA despues: 0.0006185573292896152\n",
      "loss en el callback: 0.003076853696256876, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "ejemplar: [[0.81315887]\n",
      " [0.81912684]\n",
      " [0.82445449]\n",
      " [0.8294009 ]\n",
      " [0.83477557]\n",
      " [0.84121472]\n",
      " [0.846946  ]\n",
      " [0.8528105 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.8583562]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[[0.81315887]\n",
      "  [0.81912684]\n",
      "  [0.82445449]\n",
      "  [0.8294009 ]\n",
      "  [0.83477557]\n",
      "  [0.84121472]\n",
      "  [0.846946  ]\n",
      "  [0.8528105 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.949897164711729e-05\n",
      "Predicción post entrenamiento : [[0.85797995]]\n",
      "PERDIDAAAA despues: 8.25220558908768e-05\n",
      "loss en el callback: 0.004978491924703121, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "ejemplar: [[0.81912684]\n",
      " [0.82445449]\n",
      " [0.8294009 ]\n",
      " [0.83477557]\n",
      " [0.84121472]\n",
      " [0.846946  ]\n",
      " [0.8528105 ]\n",
      " [0.85835618]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.8630567]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[[0.81912684]\n",
      "  [0.82445449]\n",
      "  [0.8294009 ]\n",
      "  [0.83477557]\n",
      "  [0.84121472]\n",
      "  [0.846946  ]\n",
      "  [0.8528105 ]\n",
      "  [0.85835618]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008342816727235913\n",
      "Predicción post entrenamiento : [[0.86324954]]\n",
      "PERDIDAAAA despues: 0.0008454576600342989\n",
      "loss en el callback: 0.0016734530217945576, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "ejemplar: [[0.82445449]\n",
      " [0.8294009 ]\n",
      " [0.83477557]\n",
      " [0.84121472]\n",
      " [0.846946  ]\n",
      " [0.8528105 ]\n",
      " [0.85835618]\n",
      " [0.86305672]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.8682194]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[[0.82445449]\n",
      "  [0.8294009 ]\n",
      "  [0.83477557]\n",
      "  [0.84121472]\n",
      "  [0.846946  ]\n",
      "  [0.8528105 ]\n",
      "  [0.85835618]\n",
      "  [0.86305672]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00017225160263478756\n",
      "Predicción post entrenamiento : [[0.8682196]]\n",
      "PERDIDAAAA despues: 0.00017225785995833576\n",
      "loss en el callback: 5.875463671145553e-09, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "ejemplar: [[0.8294009 ]\n",
      " [0.83477557]\n",
      " [0.84121472]\n",
      " [0.846946  ]\n",
      " [0.8528105 ]\n",
      " [0.85835618]\n",
      " [0.86305672]\n",
      " [0.86821938]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.87325746]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[[0.8294009 ]\n",
      "  [0.83477557]\n",
      "  [0.84121472]\n",
      "  [0.846946  ]\n",
      "  [0.8528105 ]\n",
      "  [0.85835618]\n",
      "  [0.86305672]\n",
      "  [0.86821938]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.939095677196747e-06\n",
      "Predicción post entrenamiento : [[0.8730925]]\n",
      "PERDIDAAAA despues: 4.621214884537039e-06\n",
      "loss en el callback: 0.0009335029753856361, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "ejemplar: [[0.83477557]\n",
      " [0.84121472]\n",
      " [0.846946  ]\n",
      " [0.8528105 ]\n",
      " [0.85835618]\n",
      " [0.86305672]\n",
      " [0.86821938]\n",
      " [0.87325746]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.87831235]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[[0.83477557]\n",
      "  [0.84121472]\n",
      "  [0.846946  ]\n",
      "  [0.8528105 ]\n",
      "  [0.85835618]\n",
      "  [0.86305672]\n",
      "  [0.86821938]\n",
      "  [0.87325746]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00045284561929292977\n",
      "Predicción post entrenamiento : [[0.8783168]]\n",
      "PERDIDAAAA despues: 0.0004530359001364559\n",
      "loss en el callback: 8.728103466637549e-07, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "ejemplar: [[0.84121472]\n",
      " [0.846946  ]\n",
      " [0.8528105 ]\n",
      " [0.85835618]\n",
      " [0.86305672]\n",
      " [0.86821938]\n",
      " [0.87325746]\n",
      " [0.87831235]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.88359445]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[[0.84121472]\n",
      "  [0.846946  ]\n",
      "  [0.8528105 ]\n",
      "  [0.85835618]\n",
      "  [0.86305672]\n",
      "  [0.86821938]\n",
      "  [0.87325746]\n",
      "  [0.87831235]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011246844660490751\n",
      "Predicción post entrenamiento : [[0.88378656]]\n",
      "PERDIDAAAA despues: 0.0011376063339412212\n",
      "loss en el callback: 0.0016352074453607202, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "ejemplar: [[0.846946  ]\n",
      " [0.8528105 ]\n",
      " [0.85835618]\n",
      " [0.86305672]\n",
      " [0.86821938]\n",
      " [0.87325746]\n",
      " [0.87831235]\n",
      " [0.88359445]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.8887869]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[[0.846946  ]\n",
      "  [0.8528105 ]\n",
      "  [0.85835618]\n",
      "  [0.86305672]\n",
      "  [0.86821938]\n",
      "  [0.87325746]\n",
      "  [0.87831235]\n",
      "  [0.88359445]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002124316291883588\n",
      "Predicción post entrenamiento : [[0.8880895]]\n",
      "PERDIDAAAA despues: 0.0020605127792805433\n",
      "loss en el callback: 0.017008481547236443, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "ejemplar: [[0.8528105 ]\n",
      " [0.85835618]\n",
      " [0.86305672]\n",
      " [0.86821938]\n",
      " [0.87325746]\n",
      " [0.87831235]\n",
      " [0.88359445]\n",
      " [0.88878691]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.89296275]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[[0.8528105 ]\n",
      "  [0.85835618]\n",
      "  [0.86305672]\n",
      "  [0.86821938]\n",
      "  [0.87325746]\n",
      "  [0.87831235]\n",
      "  [0.88359445]\n",
      "  [0.88878691]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004903629422187805\n",
      "Predicción post entrenamiento : [[0.89248556]]\n",
      "PERDIDAAAA despues: 0.004837025422602892\n",
      "loss en el callback: 0.00885618943721056, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "ejemplar: [[0.85835618]\n",
      " [0.86305672]\n",
      " [0.86821938]\n",
      " [0.87325746]\n",
      " [0.87831235]\n",
      " [0.88359445]\n",
      " [0.88878691]\n",
      " [0.89296275]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.89715964]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[[0.85835618]\n",
      "  [0.86305672]\n",
      "  [0.86821938]\n",
      "  [0.87325746]\n",
      "  [0.87831235]\n",
      "  [0.88359445]\n",
      "  [0.88878691]\n",
      "  [0.89296275]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01504390686750412\n",
      "Predicción post entrenamiento : [[0.8965094]]\n",
      "PERDIDAAAA despues: 0.014884823933243752\n",
      "loss en el callback: 0.016369741410017014, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "ejemplar: [[0.86305672]\n",
      " [0.86821938]\n",
      " [0.87325746]\n",
      " [0.87831235]\n",
      " [0.88359445]\n",
      " [0.88878691]\n",
      " [0.89296275]\n",
      " [0.89715964]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.9010376]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[[0.86305672]\n",
      "  [0.86821938]\n",
      "  [0.87325746]\n",
      "  [0.87831235]\n",
      "  [0.88359445]\n",
      "  [0.88878691]\n",
      "  [0.89296275]\n",
      "  [0.89715964]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013652854599058628\n",
      "Predicción post entrenamiento : [[0.89983577]]\n",
      "PERDIDAAAA despues: 0.01337344665080309\n",
      "loss en el callback: 0.05389108508825302, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "ejemplar: [[0.86821938]\n",
      " [0.87325746]\n",
      " [0.87831235]\n",
      " [0.88359445]\n",
      " [0.88878691]\n",
      " [0.89296275]\n",
      " [0.89715964]\n",
      " [0.90103757]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.9044303]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[[0.86821938]\n",
      "  [0.87325746]\n",
      "  [0.87831235]\n",
      "  [0.88359445]\n",
      "  [0.88878691]\n",
      "  [0.89296275]\n",
      "  [0.89715964]\n",
      "  [0.90103757]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001996840350329876\n",
      "Predicción post entrenamiento : [[0.90411144]]\n",
      "PERDIDAAAA despues: 0.0019684426952153444\n",
      "loss en el callback: 0.004061391577124596, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "ejemplar: [[0.87325746]\n",
      " [0.87831235]\n",
      " [0.88359445]\n",
      " [0.88878691]\n",
      " [0.89296275]\n",
      " [0.89715964]\n",
      " [0.90103757]\n",
      " [0.90443033]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.9086159]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[[0.87325746]\n",
      "  [0.87831235]\n",
      "  [0.88359445]\n",
      "  [0.88878691]\n",
      "  [0.89296275]\n",
      "  [0.89715964]\n",
      "  [0.90103757]\n",
      "  [0.90443033]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029480380471795797\n",
      "Predicción post entrenamiento : [[0.9087206]]\n",
      "PERDIDAAAA despues: 0.002959421370178461\n",
      "loss en el callback: 0.0005205835914239287, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "ejemplar: [[0.87831235]\n",
      " [0.88359445]\n",
      " [0.88878691]\n",
      " [0.89296275]\n",
      " [0.89715964]\n",
      " [0.90103757]\n",
      " [0.90443033]\n",
      " [0.90861589]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.91312265]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[[0.87831235]\n",
      "  [0.88359445]\n",
      "  [0.88878691]\n",
      "  [0.89296275]\n",
      "  [0.89715964]\n",
      "  [0.90103757]\n",
      "  [0.90443033]\n",
      "  [0.90861589]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005812192801386118\n",
      "Predicción post entrenamiento : [[0.9124233]]\n",
      "PERDIDAAAA despues: 0.0057060495018959045\n",
      "loss en el callback: 0.01926187239587307, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "ejemplar: [[0.88359445]\n",
      " [0.88878691]\n",
      " [0.89296275]\n",
      " [0.89715964]\n",
      " [0.90103757]\n",
      " [0.90443033]\n",
      " [0.90861589]\n",
      " [0.91312265]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.91666615]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[[0.88359445]\n",
      "  [0.88878691]\n",
      "  [0.89296275]\n",
      "  [0.89715964]\n",
      "  [0.90103757]\n",
      "  [0.90443033]\n",
      "  [0.90861589]\n",
      "  [0.91312265]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007526477798819542\n",
      "Predicción post entrenamiento : [[0.9160252]]\n",
      "PERDIDAAAA despues: 0.007415680680423975\n",
      "loss en el callback: 0.017082270234823227, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "ejemplar: [[0.88878691]\n",
      " [0.89296275]\n",
      " [0.89715964]\n",
      " [0.90103757]\n",
      " [0.90443033]\n",
      " [0.90861589]\n",
      " [0.91312265]\n",
      " [0.91666615]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.919988]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[[0.88878691]\n",
      "  [0.89296275]\n",
      "  [0.89715964]\n",
      "  [0.90103757]\n",
      "  [0.90443033]\n",
      "  [0.90861589]\n",
      "  [0.91312265]\n",
      "  [0.91666615]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001071579521521926\n",
      "Predicción post entrenamiento : [[0.91992545]]\n",
      "PERDIDAAAA despues: 0.0010674899676814675\n",
      "loss en el callback: 0.00019253072969149798, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "ejemplar: [[0.89296275]\n",
      " [0.89715964]\n",
      " [0.90103757]\n",
      " [0.90443033]\n",
      " [0.90861589]\n",
      " [0.91312265]\n",
      " [0.91666615]\n",
      " [0.91998798]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.92357314]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[[0.89296275]\n",
      "  [0.89715964]\n",
      "  [0.90103757]\n",
      "  [0.90443033]\n",
      "  [0.90861589]\n",
      "  [0.91312265]\n",
      "  [0.91666615]\n",
      "  [0.91998798]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004074119031429291\n",
      "Predicción post entrenamiento : [[0.9233092]]\n",
      "PERDIDAAAA despues: 0.0040404959581792355\n",
      "loss en el callback: 0.0028568694833666086, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "ejemplar: [[0.89715964]\n",
      " [0.90103757]\n",
      " [0.90443033]\n",
      " [0.90861589]\n",
      " [0.91312265]\n",
      " [0.91666615]\n",
      " [0.91998798]\n",
      " [0.92357314]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.9268867]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[[0.89715964]\n",
      "  [0.90103757]\n",
      "  [0.90443033]\n",
      "  [0.90861589]\n",
      "  [0.91312265]\n",
      "  [0.91666615]\n",
      "  [0.91998798]\n",
      "  [0.92357314]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007619479671120644\n",
      "Predicción post entrenamiento : [[0.92670494]]\n",
      "PERDIDAAAA despues: 0.007587785832583904\n",
      "loss en el callback: 0.0017760966438800097, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "ejemplar: [[0.90103757]\n",
      " [0.90443033]\n",
      " [0.90861589]\n",
      " [0.91312265]\n",
      " [0.91666615]\n",
      " [0.91998798]\n",
      " [0.92357314]\n",
      " [0.92688668]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.9301851]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[[0.90103757]\n",
      "  [0.90443033]\n",
      "  [0.90861589]\n",
      "  [0.91312265]\n",
      "  [0.91666615]\n",
      "  [0.91998798]\n",
      "  [0.92357314]\n",
      "  [0.92688668]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.021427210420370102\n",
      "Predicción post entrenamiento : [[0.93012995]]\n",
      "PERDIDAAAA despues: 0.021411072462797165\n",
      "loss en el callback: 0.00018365535652264953, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "ejemplar: [[0.90443033]\n",
      " [0.90861589]\n",
      " [0.91312265]\n",
      " [0.91666615]\n",
      " [0.91998798]\n",
      " [0.92357314]\n",
      " [0.92688668]\n",
      " [0.93018508]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.9335808]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[[0.90443033]\n",
      "  [0.90861589]\n",
      "  [0.91312265]\n",
      "  [0.91666615]\n",
      "  [0.91998798]\n",
      "  [0.92357314]\n",
      "  [0.92688668]\n",
      "  [0.93018508]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01329255010932684\n",
      "Predicción post entrenamiento : [[0.9326761]]\n",
      "PERDIDAAAA despues: 0.01308474875986576\n",
      "loss en el callback: 0.031971290707588196, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "ejemplar: [[0.90861589]\n",
      " [0.91312265]\n",
      " [0.91666615]\n",
      " [0.91998798]\n",
      " [0.92357314]\n",
      " [0.92688668]\n",
      " [0.93018508]\n",
      " [0.93358082]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.93622005]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[[0.90861589]\n",
      "  [0.91312265]\n",
      "  [0.91666615]\n",
      "  [0.91998798]\n",
      "  [0.92357314]\n",
      "  [0.92688668]\n",
      "  [0.93018508]\n",
      "  [0.93358082]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.021040624007582664\n",
      "Predicción post entrenamiento : [[0.9360449]]\n",
      "PERDIDAAAA despues: 0.020989833399653435\n",
      "loss en el callback: 0.0016914959996938705, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "ejemplar: [[0.91312265]\n",
      " [0.91666615]\n",
      " [0.91998798]\n",
      " [0.92357314]\n",
      " [0.92688668]\n",
      " [0.93018508]\n",
      " [0.93358082]\n",
      " [0.93622005]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.93943405]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[[0.91312265]\n",
      "  [0.91666615]\n",
      "  [0.91998798]\n",
      "  [0.92357314]\n",
      "  [0.92688668]\n",
      "  [0.93018508]\n",
      "  [0.93358082]\n",
      "  [0.93622005]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03199665993452072\n",
      "Predicción post entrenamiento : [[0.9376494]]\n",
      "PERDIDAAAA despues: 0.03136139363050461\n",
      "loss en el callback: 0.11699479073286057, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "ejemplar: [[0.91666615]\n",
      " [0.91998798]\n",
      " [0.92357314]\n",
      " [0.92688668]\n",
      " [0.93018508]\n",
      " [0.93358082]\n",
      " [0.93622005]\n",
      " [0.93943405]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.94074273]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[[0.91666615]\n",
      "  [0.91998798]\n",
      "  [0.92357314]\n",
      "  [0.92688668]\n",
      "  [0.93018508]\n",
      "  [0.93358082]\n",
      "  [0.93622005]\n",
      "  [0.93943405]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022257374599575996\n",
      "Predicción post entrenamiento : [[0.9396599]]\n",
      "PERDIDAAAA despues: 0.02193545177578926\n",
      "loss en el callback: 0.04866849258542061, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "ejemplar: [[0.91998798]\n",
      " [0.92357314]\n",
      " [0.92688668]\n",
      " [0.93018508]\n",
      " [0.93358082]\n",
      " [0.93622005]\n",
      " [0.93943405]\n",
      " [0.94074273]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.942679]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[[0.91998798]\n",
      "  [0.92357314]\n",
      "  [0.92688668]\n",
      "  [0.93018508]\n",
      "  [0.93358082]\n",
      "  [0.93622005]\n",
      "  [0.93943405]\n",
      "  [0.94074273]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03027067892253399\n",
      "Predicción post entrenamiento : [[0.94250727]]\n",
      "PERDIDAAAA despues: 0.0302109532058239\n",
      "loss en el callback: 0.0018466566689312458, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "ejemplar: [[0.92357314]\n",
      " [0.92688668]\n",
      " [0.93018508]\n",
      " [0.93358082]\n",
      " [0.93622005]\n",
      " [0.93943405]\n",
      " [0.94074273]\n",
      " [0.94267899]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.94547695]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[[0.92357314]\n",
      "  [0.92688668]\n",
      "  [0.93018508]\n",
      "  [0.93358082]\n",
      "  [0.93622005]\n",
      "  [0.93943405]\n",
      "  [0.94074273]\n",
      "  [0.94267899]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03125211223959923\n",
      "Predicción post entrenamiento : [[0.9447448]]\n",
      "PERDIDAAAA despues: 0.030993793159723282\n",
      "loss en el callback: 0.02968214824795723, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "ejemplar: [[0.92688668]\n",
      " [0.93018508]\n",
      " [0.93358082]\n",
      " [0.93622005]\n",
      " [0.93943405]\n",
      " [0.94074273]\n",
      " [0.94267899]\n",
      " [0.94547695]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.94754434]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[[0.92688668]\n",
      "  [0.93018508]\n",
      "  [0.93358082]\n",
      "  [0.93622005]\n",
      "  [0.93943405]\n",
      "  [0.94074273]\n",
      "  [0.94267899]\n",
      "  [0.94547695]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02209063619375229\n",
      "Predicción post entrenamiento : [[0.9471905]]\n",
      "PERDIDAAAA despues: 0.02198558673262596\n",
      "loss en el callback: 0.006907020229846239, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "ejemplar: [[0.93018508]\n",
      " [0.93358082]\n",
      " [0.93622005]\n",
      " [0.93943405]\n",
      " [0.94074273]\n",
      " [0.94267899]\n",
      " [0.94547695]\n",
      " [0.94754434]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.94984156]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[[0.93018508]\n",
      "  [0.93358082]\n",
      "  [0.93622005]\n",
      "  [0.93943405]\n",
      "  [0.94074273]\n",
      "  [0.94267899]\n",
      "  [0.94547695]\n",
      "  [0.94754434]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02554807811975479\n",
      "Predicción post entrenamiento : [[0.9498963]]\n",
      "PERDIDAAAA despues: 0.025565573945641518\n",
      "loss en el callback: 0.00019412857363931835, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "ejemplar: [[0.93358082]\n",
      " [0.93622005]\n",
      " [0.93943405]\n",
      " [0.94074273]\n",
      " [0.94267899]\n",
      " [0.94547695]\n",
      " [0.94754434]\n",
      " [0.94984156]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.9523509]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[[0.93358082]\n",
      "  [0.93622005]\n",
      "  [0.93943405]\n",
      "  [0.94074273]\n",
      "  [0.94267899]\n",
      "  [0.94547695]\n",
      "  [0.94754434]\n",
      "  [0.94984156]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.036933328956365585\n",
      "Predicción post entrenamiento : [[0.952116]]\n",
      "PERDIDAAAA despues: 0.03684309497475624\n",
      "loss en el callback: 0.003399990266188979, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "ejemplar: [[0.93622005]\n",
      " [0.93943405]\n",
      " [0.94074273]\n",
      " [0.94267899]\n",
      " [0.94547695]\n",
      " [0.94754434]\n",
      " [0.94984156]\n",
      " [0.95235091]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.9542964]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[[0.93622005]\n",
      "  [0.93943405]\n",
      "  [0.94074273]\n",
      "  [0.94267899]\n",
      "  [0.94547695]\n",
      "  [0.94754434]\n",
      "  [0.94984156]\n",
      "  [0.95235091]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07230889797210693\n",
      "Predicción post entrenamiento : [[0.9535062]]\n",
      "PERDIDAAAA despues: 0.07188452780246735\n",
      "loss en el callback: 0.03800196573138237, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "ejemplar: [[0.93943405]\n",
      " [0.94074273]\n",
      " [0.94267899]\n",
      " [0.94547695]\n",
      " [0.94754434]\n",
      " [0.94984156]\n",
      " [0.95235091]\n",
      " [0.95429641]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.95558727]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[[0.93943405]\n",
      "  [0.94074273]\n",
      "  [0.94267899]\n",
      "  [0.94547695]\n",
      "  [0.94754434]\n",
      "  [0.94984156]\n",
      "  [0.95235091]\n",
      "  [0.95429641]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12277700752019882\n",
      "Predicción post entrenamiento : [[0.95399094]]\n",
      "PERDIDAAAA despues: 0.12166085839271545\n",
      "loss en el callback: 0.1235780417919159, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "ejemplar: [[0.94074273]\n",
      " [0.94267899]\n",
      " [0.94547695]\n",
      " [0.94754434]\n",
      " [0.94984156]\n",
      " [0.95235091]\n",
      " [0.95429641]\n",
      " [0.95558727]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.95578307]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[[0.94074273]\n",
      "  [0.94267899]\n",
      "  [0.94547695]\n",
      "  [0.94754434]\n",
      "  [0.94984156]\n",
      "  [0.95235091]\n",
      "  [0.95429641]\n",
      "  [0.95558727]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08463706076145172\n",
      "Predicción post entrenamiento : [[0.95493096]]\n",
      "PERDIDAAAA despues: 0.08414198458194733\n",
      "loss en el callback: 0.04626297950744629, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "ejemplar: [[0.94267899]\n",
      " [0.94547695]\n",
      " [0.94754434]\n",
      " [0.94984156]\n",
      " [0.95235091]\n",
      " [0.95429641]\n",
      " [0.95558727]\n",
      " [0.95578307]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.95694727]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[[0.94267899]\n",
      "  [0.94547695]\n",
      "  [0.94754434]\n",
      "  [0.94984156]\n",
      "  [0.95235091]\n",
      "  [0.95429641]\n",
      "  [0.95558727]\n",
      "  [0.95578307]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.062041886150836945\n",
      "Predicción post entrenamiento : [[0.9552454]]\n",
      "PERDIDAAAA despues: 0.061196960508823395\n",
      "loss en el callback: 0.12405271083116531, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "ejemplar: [[0.94547695]\n",
      " [0.94754434]\n",
      " [0.94984156]\n",
      " [0.95235091]\n",
      " [0.95429641]\n",
      " [0.95558727]\n",
      " [0.95578307]\n",
      " [0.95694727]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9573015]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[[0.94547695]\n",
      "  [0.94754434]\n",
      "  [0.94984156]\n",
      "  [0.95235091]\n",
      "  [0.95429641]\n",
      "  [0.95558727]\n",
      "  [0.95578307]\n",
      "  [0.95694727]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08552286028862\n",
      "Predicción post entrenamiento : [[0.9567332]]\n",
      "PERDIDAAAA despues: 0.08519081026315689\n",
      "loss en el callback: 0.021162133663892746, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "ejemplar: [[0.94754434]\n",
      " [0.94984156]\n",
      " [0.95235091]\n",
      " [0.95429641]\n",
      " [0.95558727]\n",
      " [0.95578307]\n",
      " [0.95694727]\n",
      " [0.9573015 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.95853525]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[[0.94754434]\n",
      "  [0.94984156]\n",
      "  [0.95235091]\n",
      "  [0.95429641]\n",
      "  [0.95558727]\n",
      "  [0.95578307]\n",
      "  [0.95694727]\n",
      "  [0.9573015 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06109947711229324\n",
      "Predicción post entrenamiento : [[0.9578698]]\n",
      "PERDIDAAAA despues: 0.06077095493674278\n",
      "loss en el callback: 0.02762920968234539, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "ejemplar: [[0.94984156]\n",
      " [0.95235091]\n",
      " [0.95429641]\n",
      " [0.95558727]\n",
      " [0.95578307]\n",
      " [0.95694727]\n",
      " [0.9573015 ]\n",
      " [0.95853525]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.959551]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[[0.94984156]\n",
      "  [0.95235091]\n",
      "  [0.95429641]\n",
      "  [0.95558727]\n",
      "  [0.95578307]\n",
      "  [0.95694727]\n",
      "  [0.9573015 ]\n",
      "  [0.95853525]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07968995720148087\n",
      "Predicción post entrenamiento : [[0.95856655]]\n",
      "PERDIDAAAA despues: 0.07913512736558914\n",
      "loss en el callback: 0.058470070362091064, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "ejemplar: [[0.95235091]\n",
      " [0.95429641]\n",
      " [0.95558727]\n",
      " [0.95578307]\n",
      " [0.95694727]\n",
      " [0.9573015 ]\n",
      " [0.95853525]\n",
      " [0.95955098]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.959998]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[[0.95235091]\n",
      "  [0.95429641]\n",
      "  [0.95558727]\n",
      "  [0.95578307]\n",
      "  [0.95694727]\n",
      "  [0.9573015 ]\n",
      "  [0.95853525]\n",
      "  [0.95955098]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03916056454181671\n",
      "Predicción post entrenamiento : [[0.9595438]]\n",
      "PERDIDAAAA despues: 0.038981013000011444\n",
      "loss en el callback: 0.012502802535891533, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "ejemplar: [[0.95429641]\n",
      " [0.95558727]\n",
      " [0.95578307]\n",
      " [0.95694727]\n",
      " [0.9573015 ]\n",
      " [0.95853525]\n",
      " [0.95955098]\n",
      " [0.95999801]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.9605917]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[[0.95429641]\n",
      "  [0.95558727]\n",
      "  [0.95578307]\n",
      "  [0.95694727]\n",
      "  [0.9573015 ]\n",
      "  [0.95853525]\n",
      "  [0.95955098]\n",
      "  [0.95999801]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.023574572056531906\n",
      "Predicción post entrenamiento : [[0.960238]]\n",
      "PERDIDAAAA despues: 0.023466086015105247\n",
      "loss en el callback: 0.007056559436023235, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "ejemplar: [[0.95558727]\n",
      " [0.95578307]\n",
      " [0.95694727]\n",
      " [0.9573015 ]\n",
      " [0.95853525]\n",
      " [0.95955098]\n",
      " [0.95999801]\n",
      " [0.96059167]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.96099645]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[[0.95558727]\n",
      "  [0.95578307]\n",
      "  [0.95694727]\n",
      "  [0.9573015 ]\n",
      "  [0.95853525]\n",
      "  [0.95955098]\n",
      "  [0.95999801]\n",
      "  [0.96059167]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.021260123699903488\n",
      "Predicción post entrenamiento : [[0.9600227]]\n",
      "PERDIDAAAA despues: 0.02097710594534874\n",
      "loss en el callback: 0.0473768413066864, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "ejemplar: [[0.95578307]\n",
      " [0.95694727]\n",
      " [0.9573015 ]\n",
      " [0.95853525]\n",
      " [0.95955098]\n",
      " [0.95999801]\n",
      " [0.96059167]\n",
      " [0.96099645]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.96063685]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[[0.95578307]\n",
      "  [0.95694727]\n",
      "  [0.9573015 ]\n",
      "  [0.95853525]\n",
      "  [0.95955098]\n",
      "  [0.95999801]\n",
      "  [0.96059167]\n",
      "  [0.96099645]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029592462815344334\n",
      "Predicción post entrenamiento : [[0.9599541]]\n",
      "PERDIDAAAA despues: 0.0028854282572865486\n",
      "loss en el callback: 0.023589126765727997, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "ejemplar: [[0.95694727]\n",
      " [0.9573015 ]\n",
      " [0.95853525]\n",
      " [0.95955098]\n",
      " [0.95999801]\n",
      " [0.96059167]\n",
      " [0.96099645]\n",
      " [0.96063685]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.9607186]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[[0.95694727]\n",
      "  [0.9573015 ]\n",
      "  [0.95853525]\n",
      "  [0.95955098]\n",
      "  [0.95999801]\n",
      "  [0.96059167]\n",
      "  [0.96099645]\n",
      "  [0.96063685]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.026251084113028e-06\n",
      "Predicción post entrenamiento : [[0.96080697]]\n",
      "PERDIDAAAA despues: 1.2131573612350621e-06\n",
      "loss en el callback: 0.0004784384509548545, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "ejemplar: [[0.9573015 ]\n",
      " [0.95853525]\n",
      " [0.95955098]\n",
      " [0.95999801]\n",
      " [0.96059167]\n",
      " [0.96099645]\n",
      " [0.96063685]\n",
      " [0.96071857]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.9614389]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[[0.9573015 ]\n",
      "  [0.95853525]\n",
      "  [0.95955098]\n",
      "  [0.95999801]\n",
      "  [0.96059167]\n",
      "  [0.96099645]\n",
      "  [0.96063685]\n",
      "  [0.96071857]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.502930540998932e-06\n",
      "Predicción post entrenamiento : [[0.96109825]]\n",
      "PERDIDAAAA despues: 1.0605566785670817e-05\n",
      "loss en el callback: 0.006100778002291918, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "ejemplar: [[0.95853525]\n",
      " [0.95955098]\n",
      " [0.95999801]\n",
      " [0.96059167]\n",
      " [0.96099645]\n",
      " [0.96063685]\n",
      " [0.96071857]\n",
      " [0.96143889]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.9617969]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[[0.95853525]\n",
      "  [0.95955098]\n",
      "  [0.95999801]\n",
      "  [0.96059167]\n",
      "  [0.96099645]\n",
      "  [0.96063685]\n",
      "  [0.96071857]\n",
      "  [0.96143889]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005441861227154732\n",
      "Predicción post entrenamiento : [[0.9612088]]\n",
      "PERDIDAAAA despues: 0.005355446133762598\n",
      "loss en el callback: 0.01834031008183956, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "ejemplar: [[0.95955098]\n",
      " [0.95999801]\n",
      " [0.96059167]\n",
      " [0.96099645]\n",
      " [0.96063685]\n",
      " [0.96071857]\n",
      " [0.96143889]\n",
      " [0.96179688]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.96170294]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[[0.95955098]\n",
      "  [0.95999801]\n",
      "  [0.96059167]\n",
      "  [0.96099645]\n",
      "  [0.96063685]\n",
      "  [0.96071857]\n",
      "  [0.96143889]\n",
      "  [0.96179688]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004764546640217304\n",
      "Predicción post entrenamiento : [[0.96145153]]\n",
      "PERDIDAAAA despues: 0.004729901906102896\n",
      "loss en el callback: 0.003836521180346608, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "ejemplar: [[0.95999801]\n",
      " [0.96059167]\n",
      " [0.96099645]\n",
      " [0.96063685]\n",
      " [0.96071857]\n",
      " [0.96143889]\n",
      " [0.96179688]\n",
      " [0.96170294]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.9617609]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[[0.95999801]\n",
      "  [0.96059167]\n",
      "  [0.96099645]\n",
      "  [0.96063685]\n",
      "  [0.96071857]\n",
      "  [0.96143889]\n",
      "  [0.96179688]\n",
      "  [0.96170294]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007485486101359129\n",
      "Predicción post entrenamiento : [[0.9619375]]\n",
      "PERDIDAAAA despues: 0.007516077253967524\n",
      "loss en el callback: 0.0025532222352921963, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "ejemplar: [[0.96059167]\n",
      " [0.96099645]\n",
      " [0.96063685]\n",
      " [0.96071857]\n",
      " [0.96143889]\n",
      " [0.96179688]\n",
      " [0.96170294]\n",
      " [0.96176088]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.9621952]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[[0.96059167]\n",
      "  [0.96099645]\n",
      "  [0.96063685]\n",
      "  [0.96071857]\n",
      "  [0.96143889]\n",
      "  [0.96179688]\n",
      "  [0.96170294]\n",
      "  [0.96176088]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01240154355764389\n",
      "Predicción post entrenamiento : [[0.9621137]]\n",
      "PERDIDAAAA despues: 0.01238338928669691\n",
      "loss en el callback: 0.0004502643132582307, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "ejemplar: [[0.96099645]\n",
      " [0.96063685]\n",
      " [0.96071857]\n",
      " [0.96143889]\n",
      " [0.96179688]\n",
      " [0.96170294]\n",
      " [0.96176088]\n",
      " [0.96219522]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.96226645]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[[0.96099645]\n",
      "  [0.96063685]\n",
      "  [0.96071857]\n",
      "  [0.96143889]\n",
      "  [0.96179688]\n",
      "  [0.96170294]\n",
      "  [0.96176088]\n",
      "  [0.96219522]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012852906249463558\n",
      "Predicción post entrenamiento : [[0.96191615]]\n",
      "PERDIDAAAA despues: 0.012773602269589901\n",
      "loss en el callback: 0.00845795962959528, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "ejemplar: [[0.96063685]\n",
      " [0.96071857]\n",
      " [0.96143889]\n",
      " [0.96179688]\n",
      " [0.96170294]\n",
      " [0.96176088]\n",
      " [0.96219522]\n",
      " [0.96226645]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.96200705]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[[0.96063685]\n",
      "  [0.96071857]\n",
      "  [0.96143889]\n",
      "  [0.96179688]\n",
      "  [0.96170294]\n",
      "  [0.96176088]\n",
      "  [0.96219522]\n",
      "  [0.96226645]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.686058226368914e-07\n",
      "Predicción post entrenamiento : [[0.96193165]]\n",
      "PERDIDAAAA despues: 2.3621181810540293e-07\n",
      "loss en el callback: 0.0003358613757882267, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "ejemplar: [[0.96071857]\n",
      " [0.96143889]\n",
      " [0.96179688]\n",
      " [0.96170294]\n",
      " [0.96176088]\n",
      " [0.96219522]\n",
      " [0.96226645]\n",
      " [0.96200705]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.9621773]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[[0.96071857]\n",
      "  [0.96143889]\n",
      "  [0.96179688]\n",
      "  [0.96170294]\n",
      "  [0.96176088]\n",
      "  [0.96219522]\n",
      "  [0.96226645]\n",
      "  [0.96200705]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.208822090527974e-05\n",
      "Predicción post entrenamiento : [[0.9627539]]\n",
      "PERDIDAAAA despues: 2.588806273706723e-05\n",
      "loss en el callback: 0.027053209021687508, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "ejemplar: [[0.96143889]\n",
      " [0.96179688]\n",
      " [0.96170294]\n",
      " [0.96176088]\n",
      " [0.96219522]\n",
      " [0.96226645]\n",
      " [0.96200705]\n",
      " [0.96217728]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.9630387]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[[0.96143889]\n",
      "  [0.96179688]\n",
      "  [0.96170294]\n",
      "  [0.96176088]\n",
      "  [0.96219522]\n",
      "  [0.96226645]\n",
      "  [0.96200705]\n",
      "  [0.96217728]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004980933736078441\n",
      "Predicción post entrenamiento : [[0.963306]]\n",
      "PERDIDAAAA despues: 0.0005100972484797239\n",
      "loss en el callback: 0.005544713232666254, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "ejemplar: [[0.96179688]\n",
      " [0.96170294]\n",
      " [0.96176088]\n",
      " [0.96219522]\n",
      " [0.96226645]\n",
      " [0.96200705]\n",
      " [0.96217728]\n",
      " [0.96303868]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.96344113]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[[0.96179688]\n",
      "  [0.96170294]\n",
      "  [0.96176088]\n",
      "  [0.96219522]\n",
      "  [0.96226645]\n",
      "  [0.96200705]\n",
      "  [0.96217728]\n",
      "  [0.96303868]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.190486551029608e-05\n",
      "Predicción post entrenamiento : [[0.96274734]]\n",
      "PERDIDAAAA despues: 9.494415280641988e-05\n",
      "loss en el callback: 0.02238309383392334, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "ejemplar: [[0.96170294]\n",
      " [0.96176088]\n",
      " [0.96219522]\n",
      " [0.96226645]\n",
      " [0.96200705]\n",
      " [0.96217728]\n",
      " [0.96303868]\n",
      " [0.96344113]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.9628221]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[[0.96170294]\n",
      "  [0.96176088]\n",
      "  [0.96219522]\n",
      "  [0.96226645]\n",
      "  [0.96200705]\n",
      "  [0.96217728]\n",
      "  [0.96303868]\n",
      "  [0.96344113]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011613345704972744\n",
      "Predicción post entrenamiento : [[0.96339446]]\n",
      "PERDIDAAAA despues: 0.001122650457546115\n",
      "loss en el callback: 0.02621343918144703, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "ejemplar: [[0.96176088]\n",
      " [0.96219522]\n",
      " [0.96226645]\n",
      " [0.96200705]\n",
      " [0.96217728]\n",
      " [0.96303868]\n",
      " [0.96344113]\n",
      " [0.96282208]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.9635376]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[[0.96176088]\n",
      "  [0.96219522]\n",
      "  [0.96226645]\n",
      "  [0.96200705]\n",
      "  [0.96217728]\n",
      "  [0.96303868]\n",
      "  [0.96344113]\n",
      "  [0.96282208]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00015266737318597734\n",
      "Predicción post entrenamiento : [[0.96354353]]\n",
      "PERDIDAAAA despues: 0.00015281471132766455\n",
      "loss en el callback: 2.601259666334954e-06, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "ejemplar: [[0.96219522]\n",
      " [0.96226645]\n",
      " [0.96200705]\n",
      " [0.96217728]\n",
      " [0.96303868]\n",
      " [0.96344113]\n",
      " [0.96282208]\n",
      " [0.96353757]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.9637227]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[[0.96219522]\n",
      "  [0.96226645]\n",
      "  [0.96200705]\n",
      "  [0.96217728]\n",
      "  [0.96303868]\n",
      "  [0.96344113]\n",
      "  [0.96282208]\n",
      "  [0.96353757]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004616645164787769\n",
      "Predicción post entrenamiento : [[0.96374]]\n",
      "PERDIDAAAA despues: 0.004618994425982237\n",
      "loss en el callback: 2.2594915208173916e-05, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "ejemplar: [[0.96226645]\n",
      " [0.96200705]\n",
      " [0.96217728]\n",
      " [0.96303868]\n",
      " [0.96344113]\n",
      " [0.96282208]\n",
      " [0.96353757]\n",
      " [0.96372271]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.9638523]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[[0.96226645]\n",
      "  [0.96200705]\n",
      "  [0.96217728]\n",
      "  [0.96303868]\n",
      "  [0.96344113]\n",
      "  [0.96282208]\n",
      "  [0.96353757]\n",
      "  [0.96372271]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006791571620851755\n",
      "Predicción post entrenamiento : [[0.9631128]]\n",
      "PERDIDAAAA despues: 0.006670230068266392\n",
      "loss en el callback: 0.031696151942014694, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "ejemplar: [[0.96200705]\n",
      " [0.96217728]\n",
      " [0.96303868]\n",
      " [0.96344113]\n",
      " [0.96282208]\n",
      " [0.96353757]\n",
      " [0.96372271]\n",
      " [0.96385229]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.9632603]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[[0.96200705]\n",
      "  [0.96217728]\n",
      "  [0.96303868]\n",
      "  [0.96344113]\n",
      "  [0.96282208]\n",
      "  [0.96353757]\n",
      "  [0.96372271]\n",
      "  [0.96385229]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002132026245817542\n",
      "Predicción post entrenamiento : [[0.9618463]]\n",
      "PERDIDAAAA despues: 0.00200344598852098\n",
      "loss en el callback: 0.09693766385316849, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "ejemplar: [[0.96217728]\n",
      " [0.96303868]\n",
      " [0.96344113]\n",
      " [0.96282208]\n",
      " [0.96353757]\n",
      " [0.96372271]\n",
      " [0.96385229]\n",
      " [0.96326029]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.9621286]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[[0.96217728]\n",
      "  [0.96303868]\n",
      "  [0.96344113]\n",
      "  [0.96282208]\n",
      "  [0.96353757]\n",
      "  [0.96372271]\n",
      "  [0.96385229]\n",
      "  [0.96326029]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017918311059474945\n",
      "Predicción post entrenamiento : [[0.96012825]]\n",
      "PERDIDAAAA despues: 0.001626484328880906\n",
      "loss en el callback: 0.16300491988658905, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "ejemplar: [[0.96303868]\n",
      " [0.96344113]\n",
      " [0.96282208]\n",
      " [0.96353757]\n",
      " [0.96372271]\n",
      " [0.96385229]\n",
      " [0.96326029]\n",
      " [0.96212858]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.9604191]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[[0.96303868]\n",
      "  [0.96344113]\n",
      "  [0.96282208]\n",
      "  [0.96353757]\n",
      "  [0.96372271]\n",
      "  [0.96385229]\n",
      "  [0.96326029]\n",
      "  [0.96212858]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.4974009445722913e-06\n",
      "Predicción post entrenamiento : [[0.9605747]]\n",
      "PERDIDAAAA despues: 1.1408701539039612e-06\n",
      "loss en el callback: 0.002087380038574338, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "ejemplar: [[0.96344113]\n",
      " [0.96282208]\n",
      " [0.96353757]\n",
      " [0.96372271]\n",
      " [0.96385229]\n",
      " [0.96326029]\n",
      " [0.96212858]\n",
      " [0.96041912]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.9606396]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[[0.96344113]\n",
      "  [0.96282208]\n",
      "  [0.96353757]\n",
      "  [0.96372271]\n",
      "  [0.96385229]\n",
      "  [0.96326029]\n",
      "  [0.96212858]\n",
      "  [0.96041912]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.7604418543633074e-05\n",
      "Predicción post entrenamiento : [[0.96121085]]\n",
      "PERDIDAAAA despues: 4.9259433581028134e-05\n",
      "loss en el callback: 0.032580237835645676, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "ejemplar: [[0.96282208]\n",
      " [0.96353757]\n",
      " [0.96372271]\n",
      " [0.96385229]\n",
      " [0.96326029]\n",
      " [0.96212858]\n",
      " [0.96041912]\n",
      " [0.9606396 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.961125]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[[0.96282208]\n",
      "  [0.96353757]\n",
      "  [0.96372271]\n",
      "  [0.96385229]\n",
      "  [0.96326029]\n",
      "  [0.96212858]\n",
      "  [0.96041912]\n",
      "  [0.9606396 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.126740244217217e-05\n",
      "Predicción post entrenamiento : [[0.9614115]]\n",
      "PERDIDAAAA despues: 1.3272579053591471e-05\n",
      "loss en el callback: 0.0068082730285823345, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "ejemplar: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.20942028]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.026671500876545906\n",
      "Predicción post entrenamiento : [[0.1842344]]\n",
      "PERDIDAAAA despues: 0.019079409539699554\n",
      "loss en el callback: 0.025797057896852493, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "ejemplar: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20942028]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.16801706]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.20942028]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004069660324603319\n",
      "Predicción post entrenamiento : [[0.15686676]]\n",
      "PERDIDAAAA despues: 0.002771347528323531\n",
      "loss en el callback: 0.004797419533133507, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "ejemplar: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20942028]\n",
      " [0.16801706]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.16079196]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.20942028]\n",
      "  [0.16801706]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.3403866584412754e-05\n",
      "Predicción post entrenamiento : [[0.15935549]]\n",
      "PERDIDAAAA despues: 2.653989940881729e-05\n",
      "loss en el callback: 0.0001794918061932549, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "ejemplar: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20942028]\n",
      " [0.16801706]\n",
      " [0.16079196]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.17054881]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.20942028]\n",
      "  [0.16801706]\n",
      "  [0.16079196]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00021889880008529872\n",
      "Predicción post entrenamiento : [[0.1690879]]\n",
      "PERDIDAAAA despues: 0.00017780406051315367\n",
      "loss en el callback: 0.00034503941424191, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "ejemplar: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20942028]\n",
      " [0.16801706]\n",
      " [0.16079196]\n",
      " [0.17054881]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.18097933]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.20942028]\n",
      "  [0.16801706]\n",
      "  [0.16079196]\n",
      "  [0.17054881]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0030743232928216457\n",
      "Predicción post entrenamiento : [[0.17800903]]\n",
      "PERDIDAAAA despues: 0.002753760665655136\n",
      "loss en el callback: 0.0023016396444290876, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "ejemplar: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20942028]\n",
      " [0.16801706]\n",
      " [0.16079196]\n",
      " [0.17054881]\n",
      " [0.18097933]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.18649308]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.20942028]\n",
      "  [0.16801706]\n",
      "  [0.16079196]\n",
      "  [0.17054881]\n",
      "  [0.18097933]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016657105879858136\n",
      "Predicción post entrenamiento : [[0.18548554]]\n",
      "PERDIDAAAA despues: 0.0015844838926568627\n",
      "loss en el callback: 0.00042075864621438086, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "ejemplar: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.20942028]\n",
      " [0.16801706]\n",
      " [0.16079196]\n",
      " [0.17054881]\n",
      " [0.18097933]\n",
      " [0.18649308]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.20463659]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.20942028]\n",
      "  [0.16801706]\n",
      "  [0.16079196]\n",
      "  [0.17054881]\n",
      "  [0.18097933]\n",
      "  [0.18649308]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0033851140178740025\n",
      "Predicción post entrenamiento : [[0.20267646]]\n",
      "PERDIDAAAA despues: 0.0031608687713742256\n",
      "loss en el callback: 0.0021375990472733974, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "ejemplar: [[0.04223169]\n",
      " [0.20942028]\n",
      " [0.16801706]\n",
      " [0.16079196]\n",
      " [0.17054881]\n",
      " [0.18097933]\n",
      " [0.18649308]\n",
      " [0.20463659]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.22559339]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[[0.04223169]\n",
      "  [0.20942028]\n",
      "  [0.16801706]\n",
      "  [0.16079196]\n",
      "  [0.17054881]\n",
      "  [0.18097933]\n",
      "  [0.18649308]\n",
      "  [0.20463659]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008729278342798352\n",
      "Predicción post entrenamiento : [[0.22421385]]\n",
      "PERDIDAAAA despues: 0.0007933132583275437\n",
      "loss en el callback: 0.0010757445124909282, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "ejemplar: [[0.20942028]\n",
      " [0.16801706]\n",
      " [0.16079196]\n",
      " [0.17054881]\n",
      " [0.18097933]\n",
      " [0.18649308]\n",
      " [0.20463659]\n",
      " [0.22559339]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.2511676]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[[0.20942028]\n",
      "  [0.16801706]\n",
      "  [0.16079196]\n",
      "  [0.17054881]\n",
      "  [0.18097933]\n",
      "  [0.18649308]\n",
      "  [0.20463659]\n",
      "  [0.22559339]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00042587739881128073\n",
      "Predicción post entrenamiento : [[0.25135234]]\n",
      "PERDIDAAAA despues: 0.0004335365956649184\n",
      "loss en el callback: 2.6990881451638415e-05, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "ejemplar: [[0.16801706]\n",
      " [0.16079196]\n",
      " [0.17054881]\n",
      " [0.18097933]\n",
      " [0.18649308]\n",
      " [0.20463659]\n",
      " [0.22559339]\n",
      " [0.2511676 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.24573807]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[[0.16801706]\n",
      "  [0.16079196]\n",
      "  [0.17054881]\n",
      "  [0.18097933]\n",
      "  [0.18649308]\n",
      "  [0.20463659]\n",
      "  [0.22559339]\n",
      "  [0.2511676 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013906735694035888\n",
      "Predicción post entrenamiento : [[0.24479122]]\n",
      "PERDIDAAAA despues: 0.00132095068693161\n",
      "loss en el callback: 0.0008246076758950949, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "ejemplar: [[0.16079196]\n",
      " [0.17054881]\n",
      " [0.18097933]\n",
      " [0.18649308]\n",
      " [0.20463659]\n",
      " [0.22559339]\n",
      " [0.2511676 ]\n",
      " [0.24573807]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.24903353]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[[0.16079196]\n",
      "  [0.17054881]\n",
      "  [0.18097933]\n",
      "  [0.18649308]\n",
      "  [0.20463659]\n",
      "  [0.22559339]\n",
      "  [0.2511676 ]\n",
      "  [0.24573807]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001376422354951501\n",
      "Predicción post entrenamiento : [[0.24886334]]\n",
      "PERDIDAAAA despues: 0.0013638234231621027\n",
      "loss en el callback: 3.587793980841525e-05, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "ejemplar: [[0.17054881]\n",
      " [0.18097933]\n",
      " [0.18649308]\n",
      " [0.20463659]\n",
      " [0.22559339]\n",
      " [0.2511676 ]\n",
      " [0.24573807]\n",
      " [0.24903353]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.25699618]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[[0.17054881]\n",
      "  [0.18097933]\n",
      "  [0.18649308]\n",
      "  [0.20463659]\n",
      "  [0.22559339]\n",
      "  [0.2511676 ]\n",
      "  [0.24573807]\n",
      "  [0.24903353]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002471301006153226\n",
      "Predicción post entrenamiento : [[0.25401458]]\n",
      "PERDIDAAAA despues: 0.002183747012168169\n",
      "loss en el callback: 0.008277890272438526, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "ejemplar: [[0.18097933]\n",
      " [0.18649308]\n",
      " [0.20463659]\n",
      " [0.22559339]\n",
      " [0.2511676 ]\n",
      " [0.24573807]\n",
      " [0.24903353]\n",
      " [0.25699618]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.26275167]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[[0.18097933]\n",
      "  [0.18649308]\n",
      "  [0.20463659]\n",
      "  [0.22559339]\n",
      "  [0.2511676 ]\n",
      "  [0.24573807]\n",
      "  [0.24903353]\n",
      "  [0.25699618]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004872485995292664\n",
      "Predicción post entrenamiento : [[0.2609562]]\n",
      "PERDIDAAAA despues: 0.004625050351023674\n",
      "loss en el callback: 0.004265760071575642, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "ejemplar: [[0.18649308]\n",
      " [0.20463659]\n",
      " [0.22559339]\n",
      " [0.2511676 ]\n",
      " [0.24573807]\n",
      " [0.24903353]\n",
      " [0.25699618]\n",
      " [0.26275167]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.27010313]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[[0.18649308]\n",
      "  [0.20463659]\n",
      "  [0.22559339]\n",
      "  [0.2511676 ]\n",
      "  [0.24573807]\n",
      "  [0.24903353]\n",
      "  [0.25699618]\n",
      "  [0.26275167]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005369985476136208\n",
      "Predicción post entrenamiento : [[0.26821208]]\n",
      "PERDIDAAAA despues: 0.0050964090041816235\n",
      "loss en el callback: 0.00560873793438077, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "ejemplar: [[0.20463659]\n",
      " [0.22559339]\n",
      " [0.2511676 ]\n",
      " [0.24573807]\n",
      " [0.24903353]\n",
      " [0.25699618]\n",
      " [0.26275167]\n",
      " [0.27010313]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.27877805]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[[0.20463659]\n",
      "  [0.22559339]\n",
      "  [0.2511676 ]\n",
      "  [0.24573807]\n",
      "  [0.24903353]\n",
      "  [0.25699618]\n",
      "  [0.26275167]\n",
      "  [0.27010313]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004162830766290426\n",
      "Predicción post entrenamiento : [[0.27465177]]\n",
      "PERDIDAAAA despues: 0.003647401463240385\n",
      "loss en el callback: 0.01969134248793125, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "ejemplar: [[0.22559339]\n",
      " [0.2511676 ]\n",
      " [0.24573807]\n",
      " [0.24903353]\n",
      " [0.25699618]\n",
      " [0.26275167]\n",
      " [0.27010313]\n",
      " [0.27877805]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.2836462]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[[0.22559339]\n",
      "  [0.2511676 ]\n",
      "  [0.24573807]\n",
      "  [0.24903353]\n",
      "  [0.25699618]\n",
      "  [0.26275167]\n",
      "  [0.27010313]\n",
      "  [0.27877805]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010469614528119564\n",
      "Predicción post entrenamiento : [[0.28071994]]\n",
      "PERDIDAAAA despues: 0.009879340417683125\n",
      "loss en el callback: 0.014942054636776447, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "ejemplar: [[0.2511676 ]\n",
      " [0.24573807]\n",
      " [0.24903353]\n",
      " [0.25699618]\n",
      " [0.26275167]\n",
      " [0.27010313]\n",
      " [0.27877805]\n",
      " [0.2836462 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.28700787]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[[0.2511676 ]\n",
      "  [0.24573807]\n",
      "  [0.24903353]\n",
      "  [0.25699618]\n",
      "  [0.26275167]\n",
      "  [0.27010313]\n",
      "  [0.27877805]\n",
      "  [0.2836462 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012517568655312061\n",
      "Predicción post entrenamiento : [[0.28543139]]\n",
      "PERDIDAAAA despues: 0.012167294509708881\n",
      "loss en el callback: 0.006323219742625952, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "ejemplar: [[0.24573807]\n",
      " [0.24903353]\n",
      " [0.25699618]\n",
      " [0.26275167]\n",
      " [0.27010313]\n",
      " [0.27877805]\n",
      " [0.2836462 ]\n",
      " [0.28700787]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.2873901]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[[0.24573807]\n",
      "  [0.24903353]\n",
      "  [0.25699618]\n",
      "  [0.26275167]\n",
      "  [0.27010313]\n",
      "  [0.27877805]\n",
      "  [0.2836462 ]\n",
      "  [0.28700787]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019428307190537453\n",
      "Predicción post entrenamiento : [[0.28495005]]\n",
      "PERDIDAAAA despues: 0.01875404082238674\n",
      "loss en el callback: 0.01651424542069435, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "ejemplar: [[0.24903353]\n",
      " [0.25699618]\n",
      " [0.26275167]\n",
      " [0.27010313]\n",
      " [0.27877805]\n",
      " [0.2836462 ]\n",
      " [0.28700787]\n",
      " [0.28739011]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.28923967]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[[0.24903353]\n",
      "  [0.25699618]\n",
      "  [0.26275167]\n",
      "  [0.27010313]\n",
      "  [0.27877805]\n",
      "  [0.2836462 ]\n",
      "  [0.28700787]\n",
      "  [0.28739011]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01700064353644848\n",
      "Predicción post entrenamiento : [[0.28604585]]\n",
      "PERDIDAAAA despues: 0.016177980229258537\n",
      "loss en el callback: 0.02461414225399494, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "ejemplar: [[0.25699618]\n",
      " [0.26275167]\n",
      " [0.27010313]\n",
      " [0.27877805]\n",
      " [0.2836462 ]\n",
      " [0.28700787]\n",
      " [0.28739011]\n",
      " [0.28923967]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.29091746]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[[0.25699618]\n",
      "  [0.26275167]\n",
      "  [0.27010313]\n",
      "  [0.27877805]\n",
      "  [0.2836462 ]\n",
      "  [0.28700787]\n",
      "  [0.28739011]\n",
      "  [0.28923967]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009750355035066605\n",
      "Predicción post entrenamiento : [[0.29086936]]\n",
      "PERDIDAAAA despues: 0.00974085833877325\n",
      "loss en el callback: 1.2591873201017734e-05, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "ejemplar: [[0.26275167]\n",
      " [0.27010313]\n",
      " [0.27877805]\n",
      " [0.2836462 ]\n",
      " [0.28700787]\n",
      " [0.28739011]\n",
      " [0.28923967]\n",
      " [0.29091746]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.2952004]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[[0.26275167]\n",
      "  [0.27010313]\n",
      "  [0.27877805]\n",
      "  [0.2836462 ]\n",
      "  [0.28700787]\n",
      "  [0.28739011]\n",
      "  [0.28923967]\n",
      "  [0.29091746]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01193031296133995\n",
      "Predicción post entrenamiento : [[0.29440773]]\n",
      "PERDIDAAAA despues: 0.01175777893513441\n",
      "loss en el callback: 0.002688389038667083, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "ejemplar: [[0.27010313]\n",
      " [0.27877805]\n",
      " [0.2836462 ]\n",
      " [0.28700787]\n",
      " [0.28739011]\n",
      " [0.28923967]\n",
      " [0.29091746]\n",
      " [0.29520041]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.29852062]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[[0.27010313]\n",
      "  [0.27877805]\n",
      "  [0.2836462 ]\n",
      "  [0.28700787]\n",
      "  [0.28739011]\n",
      "  [0.28923967]\n",
      "  [0.29091746]\n",
      "  [0.29520041]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009966547368094325\n",
      "Predicción post entrenamiento : [[0.29871842]]\n",
      "PERDIDAAAA despues: 0.001009182771667838\n",
      "loss en el callback: 0.0001835745933931321, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "ejemplar: [[0.27877805]\n",
      " [0.2836462 ]\n",
      " [0.28700787]\n",
      " [0.28739011]\n",
      " [0.28923967]\n",
      " [0.29091746]\n",
      " [0.29520041]\n",
      " [0.29852062]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.3021018]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[[0.27877805]\n",
      "  [0.2836462 ]\n",
      "  [0.28700787]\n",
      "  [0.28739011]\n",
      "  [0.28923967]\n",
      "  [0.29091746]\n",
      "  [0.29520041]\n",
      "  [0.29852062]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 9.176700405078009e-05\n",
      "Predicción post entrenamiento : [[0.3008267]]\n",
      "PERDIDAAAA despues: 6.896334525663406e-05\n",
      "loss en el callback: 0.004774013999849558, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "ejemplar: [[0.2836462 ]\n",
      " [0.28700787]\n",
      " [0.28739011]\n",
      " [0.28923967]\n",
      " [0.29091746]\n",
      " [0.29520041]\n",
      " [0.29852062]\n",
      " [0.30210179]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.30298796]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[[0.2836462 ]\n",
      "  [0.28700787]\n",
      "  [0.28739011]\n",
      "  [0.28923967]\n",
      "  [0.29091746]\n",
      "  [0.29520041]\n",
      "  [0.29852062]\n",
      "  [0.30210179]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002166299382224679\n",
      "Predicción post entrenamiento : [[0.30363873]]\n",
      "PERDIDAAAA despues: 0.00019789709767792374\n",
      "loss en el callback: 0.0020084246061742306, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "ejemplar: [[0.28700787]\n",
      " [0.28739011]\n",
      " [0.28923967]\n",
      " [0.29091746]\n",
      " [0.29520041]\n",
      " [0.29852062]\n",
      " [0.30210179]\n",
      " [0.30298796]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.30528763]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[[0.28700787]\n",
      "  [0.28739011]\n",
      "  [0.28923967]\n",
      "  [0.29091746]\n",
      "  [0.29520041]\n",
      "  [0.29852062]\n",
      "  [0.30210179]\n",
      "  [0.30298796]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.449224408948794e-05\n",
      "Predicción post entrenamiento : [[0.30530205]]\n",
      "PERDIDAAAA despues: 5.427949508884922e-05\n",
      "loss en el callback: 8.68972335865692e-07, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "ejemplar: [[0.28739011]\n",
      " [0.28923967]\n",
      " [0.29091746]\n",
      " [0.29520041]\n",
      " [0.29852062]\n",
      " [0.30210179]\n",
      " [0.30298796]\n",
      " [0.30528763]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.30672964]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[[0.28739011]\n",
      "  [0.28923967]\n",
      "  [0.29091746]\n",
      "  [0.29520041]\n",
      "  [0.29852062]\n",
      "  [0.30210179]\n",
      "  [0.30298796]\n",
      "  [0.30528763]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003130912082269788\n",
      "Predicción post entrenamiento : [[0.30651864]]\n",
      "PERDIDAAAA despues: 0.00030566868372261524\n",
      "loss en el callback: 0.00021134882990736514, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "ejemplar: [[0.28923967]\n",
      " [0.29091746]\n",
      " [0.29520041]\n",
      " [0.29852062]\n",
      " [0.30210179]\n",
      " [0.30298796]\n",
      " [0.30528763]\n",
      " [0.30672964]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.30841464]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[[0.28923967]\n",
      "  [0.29091746]\n",
      "  [0.29520041]\n",
      "  [0.29852062]\n",
      "  [0.30210179]\n",
      "  [0.30298796]\n",
      "  [0.30528763]\n",
      "  [0.30672964]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006542611517943442\n",
      "Predicción post entrenamiento : [[0.3078902]]\n",
      "PERDIDAAAA despues: 0.0006277078064158559\n",
      "loss en el callback: 0.001361723174341023, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "ejemplar: [[0.29091746]\n",
      " [0.29520041]\n",
      " [0.29852062]\n",
      " [0.30210179]\n",
      " [0.30298796]\n",
      " [0.30528763]\n",
      " [0.30672964]\n",
      " [0.30841464]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.30996016]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[[0.29091746]\n",
      "  [0.29520041]\n",
      "  [0.29852062]\n",
      "  [0.30210179]\n",
      "  [0.30298796]\n",
      "  [0.30528763]\n",
      "  [0.30672964]\n",
      "  [0.30841464]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00010949181887554005\n",
      "Predicción post entrenamiento : [[0.3096821]]\n",
      "PERDIDAAAA despues: 0.00010375007695984095\n",
      "loss en el callback: 0.00041646353201940656, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "ejemplar: [[0.29520041]\n",
      " [0.29852062]\n",
      " [0.30210179]\n",
      " [0.30298796]\n",
      " [0.30528763]\n",
      " [0.30672964]\n",
      " [0.30841464]\n",
      " [0.30996016]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.31196257]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[[0.29520041]\n",
      "  [0.29852062]\n",
      "  [0.30210179]\n",
      "  [0.30298796]\n",
      "  [0.30528763]\n",
      "  [0.30672964]\n",
      "  [0.30841464]\n",
      "  [0.30996016]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013032465940341353\n",
      "Predicción post entrenamiento : [[0.31097162]]\n",
      "PERDIDAAAA despues: 0.0012326805153861642\n",
      "loss en el callback: 0.004878377076238394, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "ejemplar: [[0.29852062]\n",
      " [0.30210179]\n",
      " [0.30298796]\n",
      " [0.30528763]\n",
      " [0.30672964]\n",
      " [0.30841464]\n",
      " [0.30996016]\n",
      " [0.31196257]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.31282657]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[[0.29852062]\n",
      "  [0.30210179]\n",
      "  [0.30298796]\n",
      "  [0.30528763]\n",
      "  [0.30672964]\n",
      "  [0.30841464]\n",
      "  [0.30996016]\n",
      "  [0.31196257]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014536571688950062\n",
      "Predicción post entrenamiento : [[0.31264877]]\n",
      "PERDIDAAAA despues: 0.0014401307562366128\n",
      "loss en el callback: 0.00023195380344986916, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "ejemplar: [[0.30210179]\n",
      " [0.30298796]\n",
      " [0.30528763]\n",
      " [0.30672964]\n",
      " [0.30841464]\n",
      " [0.30996016]\n",
      " [0.31196257]\n",
      " [0.31282657]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.3142141]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[[0.30210179]\n",
      "  [0.30298796]\n",
      "  [0.30528763]\n",
      "  [0.30672964]\n",
      "  [0.30841464]\n",
      "  [0.30996016]\n",
      "  [0.31196257]\n",
      "  [0.31282657]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015007490292191505\n",
      "Predicción post entrenamiento : [[0.31396124]]\n",
      "PERDIDAAAA despues: 0.0014812207082286477\n",
      "loss en el callback: 0.00047130894381552935, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "ejemplar: [[0.30298796]\n",
      " [0.30528763]\n",
      " [0.30672964]\n",
      " [0.30841464]\n",
      " [0.30996016]\n",
      " [0.31196257]\n",
      " [0.31282657]\n",
      " [0.31421411]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.31510955]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[[0.30298796]\n",
      "  [0.30528763]\n",
      "  [0.30672964]\n",
      "  [0.30841464]\n",
      "  [0.30996016]\n",
      "  [0.31196257]\n",
      "  [0.31282657]\n",
      "  [0.31421411]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003859028220176697\n",
      "Predicción post entrenamiento : [[0.31507173]]\n",
      "PERDIDAAAA despues: 0.00038739011506550014\n",
      "loss en el callback: 8.664460438012611e-06, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "ejemplar: [[0.30528763]\n",
      " [0.30672964]\n",
      " [0.30841464]\n",
      " [0.30996016]\n",
      " [0.31196257]\n",
      " [0.31282657]\n",
      " [0.31421411]\n",
      " [0.31510955]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.31637996]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[[0.30528763]\n",
      "  [0.30672964]\n",
      "  [0.30841464]\n",
      "  [0.30996016]\n",
      "  [0.31196257]\n",
      "  [0.31282657]\n",
      "  [0.31421411]\n",
      "  [0.31510955]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015441850991919637\n",
      "Predicción post entrenamiento : [[0.3172566]]\n",
      "PERDIDAAAA despues: 0.0014760568737983704\n",
      "loss en el callback: 0.006882323417812586, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "ejemplar: [[0.30672964]\n",
      " [0.30841464]\n",
      " [0.30996016]\n",
      " [0.31196257]\n",
      " [0.31282657]\n",
      " [0.31421411]\n",
      " [0.31510955]\n",
      " [0.31637996]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.31839427]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[[0.30672964]\n",
      "  [0.30841464]\n",
      "  [0.30996016]\n",
      "  [0.31196257]\n",
      "  [0.31282657]\n",
      "  [0.31421411]\n",
      "  [0.31510955]\n",
      "  [0.31637996]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00033477754914201796\n",
      "Predicción post entrenamiento : [[0.3183261]]\n",
      "PERDIDAAAA despues: 0.00033727745176292956\n",
      "loss en el callback: 3.100790854659863e-05, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "ejemplar: [[0.30841464]\n",
      " [0.30996016]\n",
      " [0.31196257]\n",
      " [0.31282657]\n",
      " [0.31421411]\n",
      " [0.31510955]\n",
      " [0.31637996]\n",
      " [0.31839427]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.31946626]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[[0.30841464]\n",
      "  [0.30996016]\n",
      "  [0.31196257]\n",
      "  [0.31282657]\n",
      "  [0.31421411]\n",
      "  [0.31510955]\n",
      "  [0.31637996]\n",
      "  [0.31839427]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00019952627189923078\n",
      "Predicción post entrenamiento : [[0.3199581]]\n",
      "PERDIDAAAA despues: 0.000185873665031977\n",
      "loss en el callback: 0.0025130717549473047, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "ejemplar: [[0.30996016]\n",
      " [0.31196257]\n",
      " [0.31282657]\n",
      " [0.31421411]\n",
      " [0.31510955]\n",
      " [0.31637996]\n",
      " [0.31839427]\n",
      " [0.31946626]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.32103673]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[[0.30996016]\n",
      "  [0.31196257]\n",
      "  [0.31282657]\n",
      "  [0.31421411]\n",
      "  [0.31510955]\n",
      "  [0.31637996]\n",
      "  [0.31839427]\n",
      "  [0.31946626]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004057419020682573\n",
      "Predicción post entrenamiento : [[0.32127038]]\n",
      "PERDIDAAAA despues: 0.00402770796790719\n",
      "loss en el callback: 0.00036424139398150146, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "ejemplar: [[0.31196257]\n",
      " [0.31282657]\n",
      " [0.31421411]\n",
      " [0.31510955]\n",
      " [0.31637996]\n",
      " [0.31839427]\n",
      " [0.31946626]\n",
      " [0.32103673]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.3223093]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[[0.31196257]\n",
      "  [0.31282657]\n",
      "  [0.31421411]\n",
      "  [0.31510955]\n",
      "  [0.31637996]\n",
      "  [0.31839427]\n",
      "  [0.31946626]\n",
      "  [0.32103673]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06189506873488426\n",
      "Predicción post entrenamiento : [[0.32464927]]\n",
      "PERDIDAAAA despues: 0.06073622405529022\n",
      "loss en el callback: 0.04801584407687187, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "ejemplar: [[0.31282657]\n",
      " [0.31421411]\n",
      " [0.31510955]\n",
      " [0.31637996]\n",
      " [0.31839427]\n",
      " [0.31946626]\n",
      " [0.32103673]\n",
      " [0.32230929]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.32553372]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[[0.31282657]\n",
      "  [0.31421411]\n",
      "  [0.31510955]\n",
      "  [0.31637996]\n",
      "  [0.31839427]\n",
      "  [0.31946626]\n",
      "  [0.32103673]\n",
      "  [0.32230929]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07330382615327835\n",
      "Predicción post entrenamiento : [[0.3280814]]\n",
      "PERDIDAAAA despues: 0.07193076610565186\n",
      "loss en el callback: 0.05324586108326912, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "ejemplar: [[0.31421411]\n",
      " [0.31510955]\n",
      " [0.31637996]\n",
      " [0.31839427]\n",
      " [0.31946626]\n",
      " [0.32103673]\n",
      " [0.32230929]\n",
      " [0.32553372]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.32907915]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[[0.31421411]\n",
      "  [0.31510955]\n",
      "  [0.31637996]\n",
      "  [0.31839427]\n",
      "  [0.31946626]\n",
      "  [0.32103673]\n",
      "  [0.32230929]\n",
      "  [0.32553372]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06027236953377724\n",
      "Predicción post entrenamiento : [[0.33090425]]\n",
      "PERDIDAAAA despues: 0.059379566460847855\n",
      "loss en el callback: 0.025508899241685867, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "ejemplar: [[0.31510955]\n",
      " [0.31637996]\n",
      " [0.31839427]\n",
      " [0.31946626]\n",
      " [0.32103673]\n",
      " [0.32230929]\n",
      " [0.32553372]\n",
      " [0.32907915]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.331932]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[[0.31510955]\n",
      "  [0.31637996]\n",
      "  [0.31839427]\n",
      "  [0.31946626]\n",
      "  [0.32103673]\n",
      "  [0.32230929]\n",
      "  [0.32553372]\n",
      "  [0.32907915]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07530749589204788\n",
      "Predicción post entrenamiento : [[0.3346132]]\n",
      "PERDIDAAAA despues: 0.07384312152862549\n",
      "loss en el callback: 0.10097943991422653, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "ejemplar: [[0.31637996]\n",
      " [0.31839427]\n",
      " [0.31946626]\n",
      " [0.32103673]\n",
      " [0.32230929]\n",
      " [0.32553372]\n",
      " [0.32907915]\n",
      " [0.33193201]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.33583176]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[[0.31637996]\n",
      "  [0.31839427]\n",
      "  [0.31946626]\n",
      "  [0.32103673]\n",
      "  [0.32230929]\n",
      "  [0.32553372]\n",
      "  [0.32907915]\n",
      "  [0.33193201]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06191406399011612\n",
      "Predicción post entrenamiento : [[0.33831137]]\n",
      "PERDIDAAAA despues: 0.06068623438477516\n",
      "loss en el callback: 0.08224211633205414, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "ejemplar: [[0.31839427]\n",
      " [0.31946626]\n",
      " [0.32103673]\n",
      " [0.32230929]\n",
      " [0.32553372]\n",
      " [0.32907915]\n",
      " [0.33193201]\n",
      " [0.33583176]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.3397004]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[[0.31839427]\n",
      "  [0.31946626]\n",
      "  [0.32103673]\n",
      "  [0.32230929]\n",
      "  [0.32553372]\n",
      "  [0.32907915]\n",
      "  [0.33193201]\n",
      "  [0.33583176]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05247369781136513\n",
      "Predicción post entrenamiento : [[0.3416152]]\n",
      "PERDIDAAAA despues: 0.05160010978579521\n",
      "loss en el callback: 0.042591895908117294, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "ejemplar: [[0.31946626]\n",
      " [0.32103673]\n",
      " [0.32230929]\n",
      " [0.32553372]\n",
      " [0.32907915]\n",
      " [0.33193201]\n",
      " [0.33583176]\n",
      " [0.3397004 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.34306556]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[[0.31946626]\n",
      "  [0.32103673]\n",
      "  [0.32230929]\n",
      "  [0.32553372]\n",
      "  [0.32907915]\n",
      "  [0.33193201]\n",
      "  [0.33583176]\n",
      "  [0.3397004 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08982521295547485\n",
      "Predicción post entrenamiento : [[0.34573233]]\n",
      "PERDIDAAAA despues: 0.0882338136434555\n",
      "loss en el callback: 0.08431493490934372, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "ejemplar: [[0.32103673]\n",
      " [0.32230929]\n",
      " [0.32553372]\n",
      " [0.32907915]\n",
      " [0.33193201]\n",
      " [0.33583176]\n",
      " [0.3397004 ]\n",
      " [0.34306556]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.3475356]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[[0.32103673]\n",
      "  [0.32230929]\n",
      "  [0.32553372]\n",
      "  [0.32907915]\n",
      "  [0.33193201]\n",
      "  [0.33583176]\n",
      "  [0.3397004 ]\n",
      "  [0.34306556]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09873635321855545\n",
      "Predicción post entrenamiento : [[0.35022494]]\n",
      "PERDIDAAAA despues: 0.09705348312854767\n",
      "loss en el callback: 0.08143813908100128, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "ejemplar: [[0.32230929]\n",
      " [0.32553372]\n",
      " [0.32907915]\n",
      " [0.33193201]\n",
      " [0.33583176]\n",
      " [0.3397004 ]\n",
      " [0.34306556]\n",
      " [0.34753561]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.35235736]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[[0.32230929]\n",
      "  [0.32553372]\n",
      "  [0.32907915]\n",
      "  [0.33193201]\n",
      "  [0.33583176]\n",
      "  [0.3397004 ]\n",
      "  [0.34306556]\n",
      "  [0.34753561]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10280847549438477\n",
      "Predicción post entrenamiento : [[0.35506746]]\n",
      "PERDIDAAAA despues: 0.10107789933681488\n",
      "loss en el callback: 0.0782490000128746, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "ejemplar: [[0.32553372]\n",
      " [0.32907915]\n",
      " [0.33193201]\n",
      " [0.33583176]\n",
      " [0.3397004 ]\n",
      " [0.34306556]\n",
      " [0.34753561]\n",
      " [0.35235736]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.35769275]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[[0.32553372]\n",
      "  [0.32907915]\n",
      "  [0.33193201]\n",
      "  [0.33583176]\n",
      "  [0.3397004 ]\n",
      "  [0.34306556]\n",
      "  [0.34753561]\n",
      "  [0.35235736]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12452751398086548\n",
      "Predicción post entrenamiento : [[0.36070666]]\n",
      "PERDIDAAAA despues: 0.12240947037935257\n",
      "loss en el callback: 0.1139490082859993, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "ejemplar: [[0.32907915]\n",
      " [0.33193201]\n",
      " [0.33583176]\n",
      " [0.3397004 ]\n",
      " [0.34306556]\n",
      " [0.34753561]\n",
      " [0.35235736]\n",
      " [0.35769275]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.36344945]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[[0.32907915]\n",
      "  [0.33193201]\n",
      "  [0.33583176]\n",
      "  [0.3397004 ]\n",
      "  [0.34306556]\n",
      "  [0.34753561]\n",
      "  [0.35235736]\n",
      "  [0.35769275]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11596833914518356\n",
      "Predicción post entrenamiento : [[0.36632234]]\n",
      "PERDIDAAAA despues: 0.11401992291212082\n",
      "loss en el callback: 0.126548171043396, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "ejemplar: [[0.33193201]\n",
      " [0.33583176]\n",
      " [0.3397004 ]\n",
      " [0.34306556]\n",
      " [0.34753561]\n",
      " [0.35235736]\n",
      " [0.35769275]\n",
      " [0.36344945]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.369159]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[[0.33193201]\n",
      "  [0.33583176]\n",
      "  [0.3397004 ]\n",
      "  [0.34306556]\n",
      "  [0.34753561]\n",
      "  [0.35235736]\n",
      "  [0.35769275]\n",
      "  [0.36344945]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12822021543979645\n",
      "Predicción post entrenamiento : [[0.37213677]]\n",
      "PERDIDAAAA despues: 0.12609654664993286\n",
      "loss en el callback: 0.1596960425376892, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "ejemplar: [[0.33583176]\n",
      " [0.3397004 ]\n",
      " [0.34306556]\n",
      " [0.34753561]\n",
      " [0.35235736]\n",
      " [0.35769275]\n",
      " [0.36344945]\n",
      " [0.36915901]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.37530097]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[[0.33583176]\n",
      "  [0.3397004 ]\n",
      "  [0.34306556]\n",
      "  [0.34753561]\n",
      "  [0.35235736]\n",
      "  [0.35769275]\n",
      "  [0.36344945]\n",
      "  [0.36915901]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1206083670258522\n",
      "Predicción post entrenamiento : [[0.37806]]\n",
      "PERDIDAAAA despues: 0.11869961768388748\n",
      "loss en el callback: 0.10683495551347733, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "ejemplar: [[0.3397004 ]\n",
      " [0.34306556]\n",
      " [0.34753561]\n",
      " [0.35235736]\n",
      " [0.35769275]\n",
      " [0.36344945]\n",
      " [0.36915901]\n",
      " [0.37530097]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.38138682]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[[0.3397004 ]\n",
      "  [0.34306556]\n",
      "  [0.34753561]\n",
      "  [0.35235736]\n",
      "  [0.35769275]\n",
      "  [0.36344945]\n",
      "  [0.36915901]\n",
      "  [0.37530097]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.15241768956184387\n",
      "Predicción post entrenamiento : [[0.38453457]]\n",
      "PERDIDAAAA despues: 0.14996978640556335\n",
      "loss en el callback: 0.21293039619922638, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "ejemplar: [[0.34306556]\n",
      " [0.34753561]\n",
      " [0.35235736]\n",
      " [0.35769275]\n",
      " [0.36344945]\n",
      " [0.36915901]\n",
      " [0.37530097]\n",
      " [0.38138682]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.3881054]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[[0.34306556]\n",
      "  [0.34753561]\n",
      "  [0.35235736]\n",
      "  [0.35769275]\n",
      "  [0.36344945]\n",
      "  [0.36915901]\n",
      "  [0.37530097]\n",
      "  [0.38138682]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11317841708660126\n",
      "Predicción post entrenamiento : [[0.39072412]]\n",
      "PERDIDAAAA despues: 0.11142328381538391\n",
      "loss en el callback: 0.08931602537631989, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "ejemplar: [[0.34753561]\n",
      " [0.35235736]\n",
      " [0.35769275]\n",
      " [0.36344945]\n",
      " [0.36915901]\n",
      " [0.37530097]\n",
      " [0.38138682]\n",
      " [0.38810539]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.39475054]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[[0.34753561]\n",
      "  [0.35235736]\n",
      "  [0.35769275]\n",
      "  [0.36344945]\n",
      "  [0.36915901]\n",
      "  [0.37530097]\n",
      "  [0.38138682]\n",
      "  [0.38810539]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07634565234184265\n",
      "Predicción post entrenamiento : [[0.39700684]]\n",
      "PERDIDAAAA despues: 0.07510387152433395\n",
      "loss en el callback: 0.08362960815429688, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "ejemplar: [[0.35235736]\n",
      " [0.35769275]\n",
      " [0.36344945]\n",
      " [0.36915901]\n",
      " [0.37530097]\n",
      " [0.38138682]\n",
      " [0.38810539]\n",
      " [0.39475054]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.40131673]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[[0.35235736]\n",
      "  [0.35769275]\n",
      "  [0.36344945]\n",
      "  [0.36915901]\n",
      "  [0.37530097]\n",
      "  [0.38138682]\n",
      "  [0.38810539]\n",
      "  [0.39475054]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07423069328069687\n",
      "Predicción post entrenamiento : [[0.40345606]]\n",
      "PERDIDAAAA despues: 0.07306953519582748\n",
      "loss en el callback: 0.08528110384941101, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "ejemplar: [[0.35769275]\n",
      " [0.36344945]\n",
      " [0.36915901]\n",
      " [0.37530097]\n",
      " [0.38138682]\n",
      " [0.38810539]\n",
      " [0.39475054]\n",
      " [0.40131673]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.40803447]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[[0.35769275]\n",
      "  [0.36344945]\n",
      "  [0.36915901]\n",
      "  [0.37530097]\n",
      "  [0.38138682]\n",
      "  [0.38810539]\n",
      "  [0.39475054]\n",
      "  [0.40131673]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09389156848192215\n",
      "Predicción post entrenamiento : [[0.4105674]]\n",
      "PERDIDAAAA despues: 0.0923457220196724\n",
      "loss en el callback: 0.12909981608390808, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "ejemplar: [[0.36344945]\n",
      " [0.36915901]\n",
      " [0.37530097]\n",
      " [0.38138682]\n",
      " [0.38810539]\n",
      " [0.39475054]\n",
      " [0.40131673]\n",
      " [0.40803447]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.41534904]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[[0.36344945]\n",
      "  [0.36915901]\n",
      "  [0.37530097]\n",
      "  [0.38138682]\n",
      "  [0.38810539]\n",
      "  [0.39475054]\n",
      "  [0.40131673]\n",
      "  [0.40803447]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10794425010681152\n",
      "Predicción post entrenamiento : [[0.41767508]]\n",
      "PERDIDAAAA despues: 0.10642122477293015\n",
      "loss en el callback: 0.08573519438505173, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "ejemplar: [[0.36915901]\n",
      " [0.37530097]\n",
      " [0.38138682]\n",
      " [0.38810539]\n",
      " [0.39475054]\n",
      " [0.40131673]\n",
      " [0.40803447]\n",
      " [0.41534904]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.42260534]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[[0.36915901]\n",
      "  [0.37530097]\n",
      "  [0.38138682]\n",
      "  [0.38810539]\n",
      "  [0.39475054]\n",
      "  [0.40131673]\n",
      "  [0.40803447]\n",
      "  [0.41534904]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08998966962099075\n",
      "Predicción post entrenamiento : [[0.42504442]]\n",
      "PERDIDAAAA despues: 0.08853225409984589\n",
      "loss en el callback: 0.1509494185447693, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "ejemplar: [[0.37530097]\n",
      " [0.38138682]\n",
      " [0.38810539]\n",
      " [0.39475054]\n",
      " [0.40131673]\n",
      " [0.40803447]\n",
      " [0.41534904]\n",
      " [0.42260534]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.43017992]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[[0.37530097]\n",
      "  [0.38138682]\n",
      "  [0.38810539]\n",
      "  [0.39475054]\n",
      "  [0.40131673]\n",
      "  [0.40803447]\n",
      "  [0.41534904]\n",
      "  [0.42260534]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07244787365198135\n",
      "Predicción post entrenamiento : [[0.43208334]]\n",
      "PERDIDAAAA despues: 0.07142684608697891\n",
      "loss en el callback: 0.07146701216697693, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "ejemplar: [[0.38138682]\n",
      " [0.38810539]\n",
      " [0.39475054]\n",
      " [0.40131673]\n",
      " [0.40803447]\n",
      " [0.41534904]\n",
      " [0.42260534]\n",
      " [0.43017992]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.43736428]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[[0.38138682]\n",
      "  [0.38810539]\n",
      "  [0.39475054]\n",
      "  [0.40131673]\n",
      "  [0.40803447]\n",
      "  [0.41534904]\n",
      "  [0.42260534]\n",
      "  [0.43017992]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08996810764074326\n",
      "Predicción post entrenamiento : [[0.43953344]]\n",
      "PERDIDAAAA despues: 0.08867155015468597\n",
      "loss en el callback: 0.08600125461816788, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "ejemplar: [[0.38810539]\n",
      " [0.39475054]\n",
      " [0.40131673]\n",
      " [0.40803447]\n",
      " [0.41534904]\n",
      " [0.42260534]\n",
      " [0.43017992]\n",
      " [0.43736428]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.44501644]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[[0.38810539]\n",
      "  [0.39475054]\n",
      "  [0.40131673]\n",
      "  [0.40803447]\n",
      "  [0.41534904]\n",
      "  [0.42260534]\n",
      "  [0.43017992]\n",
      "  [0.43736428]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07640215009450912\n",
      "Predicción post entrenamiento : [[0.44708946]]\n",
      "PERDIDAAAA despues: 0.07526044547557831\n",
      "loss en el callback: 0.10362318158149719, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "ejemplar: [[0.39475054]\n",
      " [0.40131673]\n",
      " [0.40803447]\n",
      " [0.41534904]\n",
      " [0.42260534]\n",
      " [0.43017992]\n",
      " [0.43736428]\n",
      " [0.44501644]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.4526573]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[[0.39475054]\n",
      "  [0.40131673]\n",
      "  [0.40803447]\n",
      "  [0.41534904]\n",
      "  [0.42260534]\n",
      "  [0.43017992]\n",
      "  [0.43736428]\n",
      "  [0.44501644]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0707859992980957\n",
      "Predicción post entrenamiento : [[0.45466116]]\n",
      "PERDIDAAAA despues: 0.06972374022006989\n",
      "loss en el callback: 0.0965479165315628, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "ejemplar: [[0.40131673]\n",
      " [0.40803447]\n",
      " [0.41534904]\n",
      " [0.42260534]\n",
      " [0.43017992]\n",
      " [0.43736428]\n",
      " [0.44501644]\n",
      " [0.45265731]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.46036306]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[[0.40131673]\n",
      "  [0.40803447]\n",
      "  [0.41534904]\n",
      "  [0.42260534]\n",
      "  [0.43017992]\n",
      "  [0.43736428]\n",
      "  [0.44501644]\n",
      "  [0.45265731]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04570798575878143\n",
      "Predicción post entrenamiento : [[0.4616715]]\n",
      "PERDIDAAAA despues: 0.04515022411942482\n",
      "loss en el callback: 0.03334501013159752, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "ejemplar: [[0.40803447]\n",
      " [0.41534904]\n",
      " [0.42260534]\n",
      " [0.43017992]\n",
      " [0.43736428]\n",
      " [0.44501644]\n",
      " [0.45265731]\n",
      " [0.46036306]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.46756294]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[[0.40803447]\n",
      "  [0.41534904]\n",
      "  [0.42260534]\n",
      "  [0.43017992]\n",
      "  [0.43736428]\n",
      "  [0.44501644]\n",
      "  [0.45265731]\n",
      "  [0.46036306]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.053362615406513214\n",
      "Predicción post entrenamiento : [[0.4693302]]\n",
      "PERDIDAAAA despues: 0.05254925787448883\n",
      "loss en el callback: 0.07806777209043503, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "ejemplar: [[0.41534904]\n",
      " [0.42260534]\n",
      " [0.43017992]\n",
      " [0.43736428]\n",
      " [0.44501644]\n",
      " [0.45265731]\n",
      " [0.46036306]\n",
      " [0.46756294]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.4754103]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[[0.41534904]\n",
      "  [0.42260534]\n",
      "  [0.43017992]\n",
      "  [0.43736428]\n",
      "  [0.44501644]\n",
      "  [0.45265731]\n",
      "  [0.46036306]\n",
      "  [0.46756294]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06033312901854515\n",
      "Predicción post entrenamiento : [[0.47716504]]\n",
      "PERDIDAAAA despues: 0.05947418510913849\n",
      "loss en el callback: 0.06413891166448593, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "ejemplar: [[0.42260534]\n",
      " [0.43017992]\n",
      " [0.43736428]\n",
      " [0.44501644]\n",
      " [0.45265731]\n",
      " [0.46036306]\n",
      " [0.46756294]\n",
      " [0.47541031]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.48330775]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[[0.42260534]\n",
      "  [0.43017992]\n",
      "  [0.43736428]\n",
      "  [0.44501644]\n",
      "  [0.45265731]\n",
      "  [0.46036306]\n",
      "  [0.46756294]\n",
      "  [0.47541031]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0572550967335701\n",
      "Predicción post entrenamiento : [[0.48452333]]\n",
      "PERDIDAAAA despues: 0.05667484551668167\n",
      "loss en el callback: 0.024510961025953293, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "ejemplar: [[0.43017992]\n",
      " [0.43736428]\n",
      " [0.44501644]\n",
      " [0.45265731]\n",
      " [0.46036306]\n",
      " [0.46756294]\n",
      " [0.47541031]\n",
      " [0.48330775]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.49075535]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[[0.43017992]\n",
      "  [0.43736428]\n",
      "  [0.44501644]\n",
      "  [0.45265731]\n",
      "  [0.46036306]\n",
      "  [0.46756294]\n",
      "  [0.47541031]\n",
      "  [0.48330775]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07051185518503189\n",
      "Predicción post entrenamiento : [[0.49267676]]\n",
      "PERDIDAAAA despues: 0.06949511915445328\n",
      "loss en el callback: 0.08671876788139343, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "ejemplar: [[0.43736428]\n",
      " [0.44501644]\n",
      " [0.45265731]\n",
      " [0.46036306]\n",
      " [0.46756294]\n",
      " [0.47541031]\n",
      " [0.48330775]\n",
      " [0.49075535]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.49893013]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[[0.43736428]\n",
      "  [0.44501644]\n",
      "  [0.45265731]\n",
      "  [0.46036306]\n",
      "  [0.46756294]\n",
      "  [0.47541031]\n",
      "  [0.48330775]\n",
      "  [0.49075535]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10801483690738678\n",
      "Predicción post entrenamiento : [[0.50112414]]\n",
      "PERDIDAAAA despues: 0.10657749325037003\n",
      "loss en el callback: 0.10742104053497314, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "ejemplar: [[0.44501644]\n",
      " [0.45265731]\n",
      " [0.46036306]\n",
      " [0.46756294]\n",
      " [0.47541031]\n",
      " [0.48330775]\n",
      " [0.49075535]\n",
      " [0.49893013]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.5075111]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[[0.44501644]\n",
      "  [0.45265731]\n",
      "  [0.46036306]\n",
      "  [0.46756294]\n",
      "  [0.47541031]\n",
      "  [0.48330775]\n",
      "  [0.49075535]\n",
      "  [0.49893013]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10976704955101013\n",
      "Predicción post entrenamiento : [[0.5098719]]\n",
      "PERDIDAAAA despues: 0.10820829123258591\n",
      "loss en el callback: 0.15147949755191803, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "ejemplar: [[0.45265731]\n",
      " [0.46036306]\n",
      " [0.46756294]\n",
      " [0.47541031]\n",
      " [0.48330775]\n",
      " [0.49075535]\n",
      " [0.49893013]\n",
      " [0.50751108]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.51629317]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[[0.45265731]\n",
      "  [0.46036306]\n",
      "  [0.46756294]\n",
      "  [0.47541031]\n",
      "  [0.48330775]\n",
      "  [0.49075535]\n",
      "  [0.49893013]\n",
      "  [0.50751108]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07726878672838211\n",
      "Predicción post entrenamiento : [[0.5180339]]\n",
      "PERDIDAAAA despues: 0.07630405575037003\n",
      "loss en el callback: 0.06510213762521744, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "ejemplar: [[0.46036306]\n",
      " [0.46756294]\n",
      " [0.47541031]\n",
      " [0.48330775]\n",
      " [0.49075535]\n",
      " [0.49893013]\n",
      " [0.50751108]\n",
      " [0.51629317]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.52450997]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[[0.46036306]\n",
      "  [0.46756294]\n",
      "  [0.47541031]\n",
      "  [0.48330775]\n",
      "  [0.49075535]\n",
      "  [0.49893013]\n",
      "  [0.50751108]\n",
      "  [0.51629317]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06723376363515854\n",
      "Predicción post entrenamiento : [[0.52619505]]\n",
      "PERDIDAAAA despues: 0.06636273860931396\n",
      "loss en el callback: 0.06782445311546326, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "ejemplar: [[0.46756294]\n",
      " [0.47541031]\n",
      " [0.48330775]\n",
      " [0.49075535]\n",
      " [0.49893013]\n",
      " [0.50751108]\n",
      " [0.51629317]\n",
      " [0.52450997]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.53273505]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[[0.46756294]\n",
      "  [0.47541031]\n",
      "  [0.48330775]\n",
      "  [0.49075535]\n",
      "  [0.49893013]\n",
      "  [0.50751108]\n",
      "  [0.51629317]\n",
      "  [0.52450997]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05531168729066849\n",
      "Predicción post entrenamiento : [[0.5339419]]\n",
      "PERDIDAAAA despues: 0.054745469242334366\n",
      "loss en el callback: 0.028542760759592056, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "ejemplar: [[0.47541031]\n",
      " [0.48330775]\n",
      " [0.49075535]\n",
      " [0.49893013]\n",
      " [0.50751108]\n",
      " [0.51629317]\n",
      " [0.52450997]\n",
      " [0.53273505]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.54071075]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[[0.47541031]\n",
      "  [0.48330775]\n",
      "  [0.49075535]\n",
      "  [0.49893013]\n",
      "  [0.50751108]\n",
      "  [0.51629317]\n",
      "  [0.52450997]\n",
      "  [0.53273505]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.059472035616636276\n",
      "Predicción post entrenamiento : [[0.54252225]]\n",
      "PERDIDAAAA despues: 0.058591775596141815\n",
      "loss en el callback: 0.09895601868629456, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "ejemplar: [[0.48330775]\n",
      " [0.49075535]\n",
      " [0.49893013]\n",
      " [0.50751108]\n",
      " [0.51629317]\n",
      " [0.52450997]\n",
      " [0.53273505]\n",
      " [0.54071075]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.5493899]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[[0.48330775]\n",
      "  [0.49075535]\n",
      "  [0.49893013]\n",
      "  [0.50751108]\n",
      "  [0.51629317]\n",
      "  [0.52450997]\n",
      "  [0.53273505]\n",
      "  [0.54071075]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10846435278654099\n",
      "Predicción post entrenamiento : [[0.5517564]]\n",
      "PERDIDAAAA despues: 0.10691119730472565\n",
      "loss en el callback: 0.16951388120651245, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "ejemplar: [[0.49075535]\n",
      " [0.49893013]\n",
      " [0.50751108]\n",
      " [0.51629317]\n",
      " [0.52450997]\n",
      " [0.53273505]\n",
      " [0.54071075]\n",
      " [0.5493899 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.5587338]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[[0.49075535]\n",
      "  [0.49893013]\n",
      "  [0.50751108]\n",
      "  [0.51629317]\n",
      "  [0.52450997]\n",
      "  [0.53273505]\n",
      "  [0.54071075]\n",
      "  [0.5493899 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1004229336977005\n",
      "Predicción post entrenamiento : [[0.5608226]]\n",
      "PERDIDAAAA despues: 0.09910344332456589\n",
      "loss en el callback: 0.10368743538856506, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "ejemplar: [[0.49893013]\n",
      " [0.50751108]\n",
      " [0.51629317]\n",
      " [0.52450997]\n",
      " [0.53273505]\n",
      " [0.54071075]\n",
      " [0.5493899 ]\n",
      " [0.55873382]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.5680586]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[[0.49893013]\n",
      "  [0.50751108]\n",
      "  [0.51629317]\n",
      "  [0.52450997]\n",
      "  [0.53273505]\n",
      "  [0.54071075]\n",
      "  [0.5493899 ]\n",
      "  [0.55873382]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0788695216178894\n",
      "Predicción post entrenamiento : [[0.5699544]]\n",
      "PERDIDAAAA despues: 0.07780829817056656\n",
      "loss en el callback: 0.10519712418317795, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "ejemplar: [[0.50751108]\n",
      " [0.51629317]\n",
      " [0.52450997]\n",
      " [0.53273505]\n",
      " [0.54071075]\n",
      " [0.5493899 ]\n",
      " [0.55873382]\n",
      " [0.56805861]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.577294]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[[0.50751108]\n",
      "  [0.51629317]\n",
      "  [0.52450997]\n",
      "  [0.53273505]\n",
      "  [0.54071075]\n",
      "  [0.5493899 ]\n",
      "  [0.55873382]\n",
      "  [0.56805861]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.058077868074178696\n",
      "Predicción post entrenamiento : [[0.5789614]]\n",
      "PERDIDAAAA despues: 0.05727699026465416\n",
      "loss en el callback: 0.07399963587522507, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "ejemplar: [[0.51629317]\n",
      " [0.52450997]\n",
      " [0.53273505]\n",
      " [0.54071075]\n",
      " [0.5493899 ]\n",
      " [0.55873382]\n",
      " [0.56805861]\n",
      " [0.57729399]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.5863174]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[[0.51629317]\n",
      "  [0.52450997]\n",
      "  [0.53273505]\n",
      "  [0.54071075]\n",
      "  [0.5493899 ]\n",
      "  [0.55873382]\n",
      "  [0.56805861]\n",
      "  [0.57729399]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.057837311178445816\n",
      "Predicción post entrenamiento : [[0.5880555]]\n",
      "PERDIDAAAA despues: 0.05700434371829033\n",
      "loss en el callback: 0.09574637562036514, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "ejemplar: [[0.52450997]\n",
      " [0.53273505]\n",
      " [0.54071075]\n",
      " [0.5493899 ]\n",
      " [0.55873382]\n",
      " [0.56805861]\n",
      " [0.57729399]\n",
      " [0.58631742]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.5953922]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[[0.52450997]\n",
      "  [0.53273505]\n",
      "  [0.54071075]\n",
      "  [0.5493899 ]\n",
      "  [0.55873382]\n",
      "  [0.56805861]\n",
      "  [0.57729399]\n",
      "  [0.58631742]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03608566150069237\n",
      "Predicción post entrenamiento : [[0.59661186]]\n",
      "PERDIDAAAA despues: 0.035623785108327866\n",
      "loss en el callback: 0.039274800568819046, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "ejemplar: [[0.53273505]\n",
      " [0.54071075]\n",
      " [0.5493899 ]\n",
      " [0.55873382]\n",
      " [0.56805861]\n",
      " [0.57729399]\n",
      " [0.58631742]\n",
      " [0.59539223]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.6041051]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[[0.53273505]\n",
      "  [0.54071075]\n",
      "  [0.5493899 ]\n",
      "  [0.55873382]\n",
      "  [0.56805861]\n",
      "  [0.57729399]\n",
      "  [0.58631742]\n",
      "  [0.59539223]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03427084535360336\n",
      "Predicción post entrenamiento : [[0.6052803]]\n",
      "PERDIDAAAA despues: 0.03383712098002434\n",
      "loss en el callback: 0.03195773437619209, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "ejemplar: [[0.54071075]\n",
      " [0.5493899 ]\n",
      " [0.55873382]\n",
      " [0.56805861]\n",
      " [0.57729399]\n",
      " [0.58631742]\n",
      " [0.59539223]\n",
      " [0.60410511]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.6129679]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[[0.54071075]\n",
      "  [0.5493899 ]\n",
      "  [0.55873382]\n",
      "  [0.56805861]\n",
      "  [0.57729399]\n",
      "  [0.58631742]\n",
      "  [0.59539223]\n",
      "  [0.60410511]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04893159866333008\n",
      "Predicción post entrenamiento : [[0.6145996]]\n",
      "PERDIDAAAA despues: 0.04821239039301872\n",
      "loss en el callback: 0.0793646052479744, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "ejemplar: [[0.5493899 ]\n",
      " [0.55873382]\n",
      " [0.56805861]\n",
      " [0.57729399]\n",
      " [0.58631742]\n",
      " [0.59539223]\n",
      " [0.60410511]\n",
      " [0.61296791]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.62258834]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[[0.5493899 ]\n",
      "  [0.55873382]\n",
      "  [0.56805861]\n",
      "  [0.57729399]\n",
      "  [0.58631742]\n",
      "  [0.59539223]\n",
      "  [0.60410511]\n",
      "  [0.61296791]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.036057248711586\n",
      "Predicción post entrenamiento : [[0.62388337]]\n",
      "PERDIDAAAA despues: 0.03556710481643677\n",
      "loss en el callback: 0.04978632554411888, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "ejemplar: [[0.55873382]\n",
      " [0.56805861]\n",
      " [0.57729399]\n",
      " [0.58631742]\n",
      " [0.59539223]\n",
      " [0.60410511]\n",
      " [0.61296791]\n",
      " [0.62258834]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.63201416]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[[0.55873382]\n",
      "  [0.56805861]\n",
      "  [0.57729399]\n",
      "  [0.58631742]\n",
      "  [0.59539223]\n",
      "  [0.60410511]\n",
      "  [0.61296791]\n",
      "  [0.62258834]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02863733470439911\n",
      "Predicción post entrenamiento : [[0.63273513]]\n",
      "PERDIDAAAA despues: 0.028393838554620743\n",
      "loss en el callback: 0.01305434387177229, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "ejemplar: [[0.56805861]\n",
      " [0.57729399]\n",
      " [0.58631742]\n",
      " [0.59539223]\n",
      " [0.60410511]\n",
      " [0.61296791]\n",
      " [0.62258834]\n",
      " [0.63201416]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.64083093]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[[0.56805861]\n",
      "  [0.57729399]\n",
      "  [0.58631742]\n",
      "  [0.59539223]\n",
      "  [0.60410511]\n",
      "  [0.61296791]\n",
      "  [0.62258834]\n",
      "  [0.63201416]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02635626494884491\n",
      "Predicción post entrenamiento : [[0.64194405]]\n",
      "PERDIDAAAA despues: 0.02599608339369297\n",
      "loss en el callback: 0.03509257733821869, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "ejemplar: [[0.57729399]\n",
      " [0.58631742]\n",
      " [0.59539223]\n",
      " [0.60410511]\n",
      " [0.61296791]\n",
      " [0.62258834]\n",
      " [0.63201416]\n",
      " [0.64083093]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.65000135]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[[0.57729399]\n",
      "  [0.58631742]\n",
      "  [0.59539223]\n",
      "  [0.60410511]\n",
      "  [0.61296791]\n",
      "  [0.62258834]\n",
      "  [0.63201416]\n",
      "  [0.64083093]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.020589247345924377\n",
      "Predicción post entrenamiento : [[0.6512978]]\n",
      "PERDIDAAAA despues: 0.020218871533870697\n",
      "loss en el callback: 0.0578036904335022, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "ejemplar: [[0.58631742]\n",
      " [0.59539223]\n",
      " [0.60410511]\n",
      " [0.61296791]\n",
      " [0.62258834]\n",
      " [0.63201416]\n",
      " [0.64083093]\n",
      " [0.65000135]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.6593354]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[[0.58631742]\n",
      "  [0.59539223]\n",
      "  [0.60410511]\n",
      "  [0.61296791]\n",
      "  [0.62258834]\n",
      "  [0.63201416]\n",
      "  [0.64083093]\n",
      "  [0.65000135]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010167714208364487\n",
      "Predicción post entrenamiento : [[0.6598909]]\n",
      "PERDIDAAAA despues: 0.01005599182099104\n",
      "loss en el callback: 0.008590197190642357, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "ejemplar: [[0.59539223]\n",
      " [0.60410511]\n",
      " [0.61296791]\n",
      " [0.62258834]\n",
      " [0.63201416]\n",
      " [0.64083093]\n",
      " [0.65000135]\n",
      " [0.65933537]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.66796607]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[[0.59539223]\n",
      "  [0.60410511]\n",
      "  [0.61296791]\n",
      "  [0.62258834]\n",
      "  [0.63201416]\n",
      "  [0.64083093]\n",
      "  [0.65000135]\n",
      "  [0.65933537]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004543817602097988\n",
      "Predicción post entrenamiento : [[0.66858107]]\n",
      "PERDIDAAAA despues: 0.004461284261196852\n",
      "loss en el callback: 0.010457277297973633, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "ejemplar: [[0.60410511]\n",
      " [0.61296791]\n",
      " [0.62258834]\n",
      " [0.63201416]\n",
      " [0.64083093]\n",
      " [0.65000135]\n",
      " [0.65933537]\n",
      " [0.66796607]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.6766846]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[[0.60410511]\n",
      "  [0.61296791]\n",
      "  [0.62258834]\n",
      "  [0.63201416]\n",
      "  [0.64083093]\n",
      "  [0.65000135]\n",
      "  [0.65933537]\n",
      "  [0.66796607]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011225985363125801\n",
      "Predicción post entrenamiento : [[0.67685205]]\n",
      "PERDIDAAAA despues: 0.0011114070657640696\n",
      "loss en el callback: 0.0007089560967870057, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "ejemplar: [[0.61296791]\n",
      " [0.62258834]\n",
      " [0.63201416]\n",
      " [0.64083093]\n",
      " [0.65000135]\n",
      " [0.65933537]\n",
      " [0.66796607]\n",
      " [0.67668462]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.68508554]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[[0.61296791]\n",
      "  [0.62258834]\n",
      "  [0.63201416]\n",
      "  [0.64083093]\n",
      "  [0.65000135]\n",
      "  [0.65933537]\n",
      "  [0.66796607]\n",
      "  [0.67668462]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007312456727959216\n",
      "Predicción post entrenamiento : [[0.68513983]]\n",
      "PERDIDAAAA despues: 0.000728311890270561\n",
      "loss en el callback: 7.949116843519732e-05, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "ejemplar: [[0.62258834]\n",
      " [0.63201416]\n",
      " [0.64083093]\n",
      " [0.65000135]\n",
      " [0.65933537]\n",
      " [0.66796607]\n",
      " [0.67668462]\n",
      " [0.68508554]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.6934624]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[[0.62258834]\n",
      "  [0.63201416]\n",
      "  [0.64083093]\n",
      "  [0.65000135]\n",
      "  [0.65933537]\n",
      "  [0.66796607]\n",
      "  [0.67668462]\n",
      "  [0.68508554]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002131987828761339\n",
      "Predicción post entrenamiento : [[0.6936244]]\n",
      "PERDIDAAAA despues: 0.002117053372785449\n",
      "loss en el callback: 0.0006865366594865918, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "ejemplar: [[0.63201416]\n",
      " [0.64083093]\n",
      " [0.65000135]\n",
      " [0.65933537]\n",
      " [0.66796607]\n",
      " [0.67668462]\n",
      " [0.68508554]\n",
      " [0.69346237]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.70180565]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[[0.63201416]\n",
      "  [0.64083093]\n",
      "  [0.65000135]\n",
      "  [0.65933537]\n",
      "  [0.66796607]\n",
      "  [0.67668462]\n",
      "  [0.68508554]\n",
      "  [0.69346237]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011794500751420856\n",
      "Predicción post entrenamiento : [[0.70206827]]\n",
      "PERDIDAAAA despues: 0.001161480788141489\n",
      "loss en el callback: 0.00202356418594718, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "ejemplar: [[0.64083093]\n",
      " [0.65000135]\n",
      " [0.65933537]\n",
      " [0.66796607]\n",
      " [0.67668462]\n",
      " [0.68508554]\n",
      " [0.69346237]\n",
      " [0.70180565]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.71011996]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[[0.64083093]\n",
      "  [0.65000135]\n",
      "  [0.65933537]\n",
      "  [0.66796607]\n",
      "  [0.67668462]\n",
      "  [0.68508554]\n",
      "  [0.69346237]\n",
      "  [0.70180565]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018104389309883118\n",
      "Predicción post entrenamiento : [[0.7098437]]\n",
      "PERDIDAAAA despues: 0.0017870052251964808\n",
      "loss en el callback: 0.0021749206352978945, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "ejemplar: [[0.65000135]\n",
      " [0.65933537]\n",
      " [0.66796607]\n",
      " [0.67668462]\n",
      " [0.68508554]\n",
      " [0.69346237]\n",
      " [0.70180565]\n",
      " [0.71011996]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.71789825]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[[0.65000135]\n",
      "  [0.65933537]\n",
      "  [0.66796607]\n",
      "  [0.67668462]\n",
      "  [0.68508554]\n",
      "  [0.69346237]\n",
      "  [0.70180565]\n",
      "  [0.71011996]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0023042724933475256\n",
      "Predicción post entrenamiento : [[0.71770716]]\n",
      "PERDIDAAAA despues: 0.0022859631571918726\n",
      "loss en el callback: 0.0011159860296174884, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "ejemplar: [[0.65933537]\n",
      " [0.66796607]\n",
      " [0.67668462]\n",
      " [0.68508554]\n",
      " [0.69346237]\n",
      " [0.70180565]\n",
      " [0.71011996]\n",
      " [0.71789825]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.72563547]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[[0.65933537]\n",
      "  [0.66796607]\n",
      "  [0.67668462]\n",
      "  [0.68508554]\n",
      "  [0.69346237]\n",
      "  [0.70180565]\n",
      "  [0.71011996]\n",
      "  [0.71789825]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008413621108047664\n",
      "Predicción post entrenamiento : [[0.7252693]]\n",
      "PERDIDAAAA despues: 0.0008202548488043249\n",
      "loss en el callback: 0.0036394756752997637, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "ejemplar: [[0.66796607]\n",
      " [0.67668462]\n",
      " [0.68508554]\n",
      " [0.69346237]\n",
      " [0.70180565]\n",
      " [0.71011996]\n",
      " [0.71789825]\n",
      " [0.72563547]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.7329762]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[[0.66796607]\n",
      "  [0.67668462]\n",
      "  [0.68508554]\n",
      "  [0.69346237]\n",
      "  [0.70180565]\n",
      "  [0.71011996]\n",
      "  [0.71789825]\n",
      "  [0.72563547]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0059334468096494675\n",
      "Predicción post entrenamiento : [[0.7327247]]\n",
      "PERDIDAAAA despues: 0.005894768983125687\n",
      "loss en el callback: 0.001974561484530568, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "ejemplar: [[0.67668462]\n",
      " [0.68508554]\n",
      " [0.69346237]\n",
      " [0.70180565]\n",
      " [0.71011996]\n",
      " [0.71789825]\n",
      " [0.72563547]\n",
      " [0.7329762 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.7403581]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[[0.67668462]\n",
      "  [0.68508554]\n",
      "  [0.69346237]\n",
      "  [0.70180565]\n",
      "  [0.71011996]\n",
      "  [0.71789825]\n",
      "  [0.72563547]\n",
      "  [0.7329762 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0037885811179876328\n",
      "Predicción post entrenamiento : [[0.74024343]]\n",
      "PERDIDAAAA despues: 0.0037744769360870123\n",
      "loss en el callback: 0.0004136172356083989, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "ejemplar: [[0.68508554]\n",
      " [0.69346237]\n",
      " [0.70180565]\n",
      " [0.71011996]\n",
      " [0.71789825]\n",
      " [0.72563547]\n",
      " [0.7329762 ]\n",
      " [0.74035811]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.7477381]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[[0.68508554]\n",
      "  [0.69346237]\n",
      "  [0.70180565]\n",
      "  [0.71011996]\n",
      "  [0.71789825]\n",
      "  [0.72563547]\n",
      "  [0.7329762 ]\n",
      "  [0.74035811]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005132804159075022\n",
      "Predicción post entrenamiento : [[0.7475559]]\n",
      "PERDIDAAAA despues: 0.005106728989630938\n",
      "loss en el callback: 0.0010597881628200412, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "ejemplar: [[0.69346237]\n",
      " [0.70180565]\n",
      " [0.71011996]\n",
      " [0.71789825]\n",
      " [0.72563547]\n",
      " [0.7329762 ]\n",
      " [0.74035811]\n",
      " [0.74773812]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.7549551]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[[0.69346237]\n",
      "  [0.70180565]\n",
      "  [0.71011996]\n",
      "  [0.71789825]\n",
      "  [0.72563547]\n",
      "  [0.7329762 ]\n",
      "  [0.74035811]\n",
      "  [0.74773812]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006448018830269575\n",
      "Predicción post entrenamiento : [[0.75518036]]\n",
      "PERDIDAAAA despues: 0.0006562919588759542\n",
      "loss en el callback: 0.001786294742487371, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "ejemplar: [[0.70180565]\n",
      " [0.71011996]\n",
      " [0.71789825]\n",
      " [0.72563547]\n",
      " [0.7329762 ]\n",
      " [0.74035811]\n",
      " [0.74773812]\n",
      " [0.75495511]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.76244795]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[[0.70180565]\n",
      "  [0.71011996]\n",
      "  [0.71789825]\n",
      "  [0.72563547]\n",
      "  [0.7329762 ]\n",
      "  [0.74035811]\n",
      "  [0.74773812]\n",
      "  [0.75495511]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0037416936829686165\n",
      "Predicción post entrenamiento : [[0.76119876]]\n",
      "PERDIDAAAA despues: 0.0035904294345527887\n",
      "loss en el callback: 0.03584083169698715, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "ejemplar: [[0.71011996]\n",
      " [0.71789825]\n",
      " [0.72563547]\n",
      " [0.7329762 ]\n",
      " [0.74035811]\n",
      " [0.74773812]\n",
      " [0.75495511]\n",
      " [0.76244795]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.7682938]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[[0.71011996]\n",
      "  [0.71789825]\n",
      "  [0.72563547]\n",
      "  [0.7329762 ]\n",
      "  [0.74035811]\n",
      "  [0.74773812]\n",
      "  [0.75495511]\n",
      "  [0.76244795]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.803498765999393e-07\n",
      "Predicción post entrenamiento : [[0.7688961]]\n",
      "PERDIDAAAA despues: 1.8608012624099501e-06\n",
      "loss en el callback: 0.015054084360599518, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "ejemplar: [[0.71789825]\n",
      " [0.72563547]\n",
      " [0.7329762 ]\n",
      " [0.74035811]\n",
      " [0.74773812]\n",
      " [0.75495511]\n",
      " [0.76244795]\n",
      " [0.7682938 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.7757801]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[[0.71789825]\n",
      "  [0.72563547]\n",
      "  [0.7329762 ]\n",
      "  [0.74035811]\n",
      "  [0.74773812]\n",
      "  [0.75495511]\n",
      "  [0.76244795]\n",
      "  [0.7682938 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004262735601514578\n",
      "Predicción post entrenamiento : [[0.7752404]]\n",
      "PERDIDAAAA despues: 0.0004042806976940483\n",
      "loss en el callback: 0.008002198301255703, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "ejemplar: [[0.72563547]\n",
      " [0.7329762 ]\n",
      " [0.74035811]\n",
      " [0.74773812]\n",
      " [0.75495511]\n",
      " [0.76244795]\n",
      " [0.7682938 ]\n",
      " [0.77578008]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.7820147]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[[0.72563547]\n",
      "  [0.7329762 ]\n",
      "  [0.74035811]\n",
      "  [0.74773812]\n",
      "  [0.75495511]\n",
      "  [0.76244795]\n",
      "  [0.7682938 ]\n",
      "  [0.77578008]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013656499795615673\n",
      "Predicción post entrenamiento : [[0.7806815]]\n",
      "PERDIDAAAA despues: 0.0012688887072727084\n",
      "loss en el callback: 0.042571134865283966, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "ejemplar: [[0.7329762 ]\n",
      " [0.74035811]\n",
      " [0.74773812]\n",
      " [0.75495511]\n",
      " [0.76244795]\n",
      " [0.7682938 ]\n",
      " [0.77578008]\n",
      " [0.78201473]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.78731745]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[[0.7329762 ]\n",
      "  [0.74035811]\n",
      "  [0.74773812]\n",
      "  [0.75495511]\n",
      "  [0.76244795]\n",
      "  [0.7682938 ]\n",
      "  [0.77578008]\n",
      "  [0.78201473]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012449173955246806\n",
      "Predicción post entrenamiento : [[0.78704566]]\n",
      "PERDIDAAAA despues: 0.001225811429321766\n",
      "loss en el callback: 0.00217684474773705, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "ejemplar: [[0.74035811]\n",
      " [0.74773812]\n",
      " [0.75495511]\n",
      " [0.76244795]\n",
      " [0.7682938 ]\n",
      " [0.77578008]\n",
      " [0.78201473]\n",
      " [0.78731745]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.7936135]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[[0.74035811]\n",
      "  [0.74773812]\n",
      "  [0.75495511]\n",
      "  [0.76244795]\n",
      "  [0.7682938 ]\n",
      "  [0.77578008]\n",
      "  [0.78201473]\n",
      "  [0.78731745]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007024301216006279\n",
      "Predicción post entrenamiento : [[0.7928647]]\n",
      "PERDIDAAAA despues: 0.006899344269186258\n",
      "loss en el callback: 0.01569889299571514, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "ejemplar: [[0.74773812]\n",
      " [0.75495511]\n",
      " [0.76244795]\n",
      " [0.7682938 ]\n",
      " [0.77578008]\n",
      " [0.78201473]\n",
      " [0.78731745]\n",
      " [0.79361349]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.79930586]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[[0.74773812]\n",
      "  [0.75495511]\n",
      "  [0.76244795]\n",
      "  [0.7682938 ]\n",
      "  [0.77578008]\n",
      "  [0.78201473]\n",
      "  [0.78731745]\n",
      "  [0.79361349]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011853942647576332\n",
      "Predicción post entrenamiento : [[0.7975907]]\n",
      "PERDIDAAAA despues: 0.011483400128781796\n",
      "loss en el callback: 0.07037180662155151, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "ejemplar: [[0.75495511]\n",
      " [0.76244795]\n",
      " [0.7682938 ]\n",
      " [0.77578008]\n",
      " [0.78201473]\n",
      " [0.78731745]\n",
      " [0.79361349]\n",
      " [0.79930586]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.80384636]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[[0.75495511]\n",
      "  [0.76244795]\n",
      "  [0.7682938 ]\n",
      "  [0.77578008]\n",
      "  [0.78201473]\n",
      "  [0.78731745]\n",
      "  [0.79361349]\n",
      "  [0.79930586]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0024490216746926308\n",
      "Predicción post entrenamiento : [[0.80277777]]\n",
      "PERDIDAAAA despues: 0.002344399457797408\n",
      "loss en el callback: 0.0292186439037323, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "ejemplar: [[0.76244795]\n",
      " [0.7682938 ]\n",
      " [0.77578008]\n",
      " [0.78201473]\n",
      " [0.78731745]\n",
      " [0.79361349]\n",
      " [0.79930586]\n",
      " [0.80384636]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.8088262]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[[0.76244795]\n",
      "  [0.7682938 ]\n",
      "  [0.77578008]\n",
      "  [0.78201473]\n",
      "  [0.78731745]\n",
      "  [0.79361349]\n",
      "  [0.79930586]\n",
      "  [0.80384636]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007503980305045843\n",
      "Predicción post entrenamiento : [[0.808425]]\n",
      "PERDIDAAAA despues: 0.0074346330948174\n",
      "loss en el callback: 0.005394013598561287, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "ejemplar: [[0.7682938 ]\n",
      " [0.77578008]\n",
      " [0.78201473]\n",
      " [0.78731745]\n",
      " [0.79361349]\n",
      " [0.79930586]\n",
      " [0.80384636]\n",
      " [0.80882621]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.81411093]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[[0.7682938 ]\n",
      "  [0.77578008]\n",
      "  [0.78201473]\n",
      "  [0.78731745]\n",
      "  [0.79361349]\n",
      "  [0.79930586]\n",
      "  [0.80384636]\n",
      "  [0.80882621]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011831826996058226\n",
      "Predicción post entrenamiento : [[0.8146927]]\n",
      "PERDIDAAAA despues: 0.0011435003252699971\n",
      "loss en el callback: 0.013181922025978565, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "ejemplar: [[0.77578008]\n",
      " [0.78201473]\n",
      " [0.78731745]\n",
      " [0.79361349]\n",
      " [0.79930586]\n",
      " [0.80384636]\n",
      " [0.80882621]\n",
      " [0.81411093]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.8204102]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[[0.77578008]\n",
      "  [0.78201473]\n",
      "  [0.78731745]\n",
      "  [0.79361349]\n",
      "  [0.79930586]\n",
      "  [0.80384636]\n",
      "  [0.80882621]\n",
      "  [0.81411093]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007233976852148771\n",
      "Predicción post entrenamiento : [[0.8211515]]\n",
      "PERDIDAAAA despues: 0.0071084266528487206\n",
      "loss en el callback: 0.022172141820192337, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "ejemplar: [[0.78201473]\n",
      " [0.78731745]\n",
      " [0.79361349]\n",
      " [0.79930586]\n",
      " [0.80384636]\n",
      " [0.80882621]\n",
      " [0.81411093]\n",
      " [0.82041019]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.82638353]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[[0.78201473]\n",
      "  [0.78731745]\n",
      "  [0.79361349]\n",
      "  [0.79930586]\n",
      "  [0.80384636]\n",
      "  [0.80882621]\n",
      "  [0.81411093]\n",
      "  [0.82041019]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0031172886956483126\n",
      "Predicción post entrenamiento : [[0.82732856]]\n",
      "PERDIDAAAA despues: 0.00301265437155962\n",
      "loss en el callback: 0.04433261230587959, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "ejemplar: [[0.78731745]\n",
      " [0.79361349]\n",
      " [0.79930586]\n",
      " [0.80384636]\n",
      " [0.80882621]\n",
      " [0.81411093]\n",
      " [0.82041019]\n",
      " [0.82638353]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.8323625]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[[0.78731745]\n",
      "  [0.79361349]\n",
      "  [0.79930586]\n",
      "  [0.80384636]\n",
      "  [0.80882621]\n",
      "  [0.81411093]\n",
      "  [0.82041019]\n",
      "  [0.82638353]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005688962060958147\n",
      "Predicción post entrenamiento : [[0.83256274]]\n",
      "PERDIDAAAA despues: 0.005658790934830904\n",
      "loss en el callback: 0.0012966534122824669, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "ejemplar: [[0.79361349]\n",
      " [0.79930586]\n",
      " [0.80384636]\n",
      " [0.80882621]\n",
      " [0.81411093]\n",
      " [0.82041019]\n",
      " [0.82638353]\n",
      " [0.83236247]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.8376472]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[[0.79361349]\n",
      "  [0.79930586]\n",
      "  [0.80384636]\n",
      "  [0.80882621]\n",
      "  [0.81411093]\n",
      "  [0.82041019]\n",
      "  [0.82638353]\n",
      "  [0.83236247]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002696775598451495\n",
      "Predicción post entrenamiento : [[0.83865947]]\n",
      "PERDIDAAAA despues: 0.0025926653761416674\n",
      "loss en el callback: 0.04565029218792915, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "ejemplar: [[0.79930586]\n",
      " [0.80384636]\n",
      " [0.80882621]\n",
      " [0.81411093]\n",
      " [0.82041019]\n",
      " [0.82638353]\n",
      " [0.83236247]\n",
      " [0.8376472 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.8435151]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[[0.79930586]\n",
      "  [0.80384636]\n",
      "  [0.80882621]\n",
      "  [0.81411093]\n",
      "  [0.82041019]\n",
      "  [0.82638353]\n",
      "  [0.83236247]\n",
      "  [0.8376472 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009821696439757943\n",
      "Predicción post entrenamiento : [[0.84290504]]\n",
      "PERDIDAAAA despues: 0.0010207794839516282\n",
      "loss en el callback: 0.009849265217781067, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "ejemplar: [[0.80384636]\n",
      " [0.80882621]\n",
      " [0.81411093]\n",
      " [0.82041019]\n",
      " [0.82638353]\n",
      " [0.83236247]\n",
      " [0.8376472 ]\n",
      " [0.8435151 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.8476953]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[[0.80384636]\n",
      "  [0.80882621]\n",
      "  [0.81411093]\n",
      "  [0.82041019]\n",
      "  [0.82638353]\n",
      "  [0.83236247]\n",
      "  [0.8376472 ]\n",
      "  [0.8435151 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00429243128746748\n",
      "Predicción post entrenamiento : [[0.8478934]]\n",
      "PERDIDAAAA despues: 0.004266509786248207\n",
      "loss en el callback: 0.0012757304357364774, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "ejemplar: [[0.80882621]\n",
      " [0.81411093]\n",
      " [0.82041019]\n",
      " [0.82638353]\n",
      " [0.83236247]\n",
      " [0.8376472 ]\n",
      " [0.8435151 ]\n",
      " [0.84769529]]\n",
      "ejemplar: (8, 1)\n",
      "y: 1.0\n",
      "Predicción : [[0.85296607]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[[0.80882621]\n",
      "  [0.81411093]\n",
      "  [0.82041019]\n",
      "  [0.82638353]\n",
      "  [0.83236247]\n",
      "  [0.8376472 ]\n",
      "  [0.8435151 ]\n",
      "  [0.84769529]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.021618977189064026\n",
      "Predicción post entrenamiento : [[0.8539135]]\n",
      "PERDIDAAAA despues: 0.021341269835829735\n",
      "loss en el callback: 0.03265044465661049, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "ejemplar: [[0.81411093]\n",
      " [0.82041019]\n",
      " [0.82638353]\n",
      " [0.83236247]\n",
      " [0.8376472 ]\n",
      " [0.8435151 ]\n",
      " [0.84769529]\n",
      " [0.85296607]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.8591751]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[[0.81411093]\n",
      "  [0.82041019]\n",
      "  [0.82638353]\n",
      "  [0.83236247]\n",
      "  [0.8376472 ]\n",
      "  [0.8435151 ]\n",
      "  [0.84769529]\n",
      "  [0.85296607]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0124052744358778\n",
      "Predicción post entrenamiento : [[0.8593431]]\n",
      "PERDIDAAAA despues: 0.012367873452603817\n",
      "loss en el callback: 0.0008942282875068486, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "ejemplar: [[0.82041019]\n",
      " [0.82638353]\n",
      " [0.83236247]\n",
      " [0.8376472 ]\n",
      " [0.8435151 ]\n",
      " [0.84769529]\n",
      " [0.85296607]\n",
      " [0.85917509]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.86471194]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[[0.82041019]\n",
      "  [0.82638353]\n",
      "  [0.83236247]\n",
      "  [0.8376472 ]\n",
      "  [0.8435151 ]\n",
      "  [0.84769529]\n",
      "  [0.85296607]\n",
      "  [0.85917509]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005803679232485592\n",
      "Predicción post entrenamiento : [[0.86522204]]\n",
      "PERDIDAAAA despues: 0.0005560507997870445\n",
      "loss en el callback: 0.01146203838288784, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "ejemplar: [[0.82638353]\n",
      " [0.83236247]\n",
      " [0.8376472 ]\n",
      " [0.8435151 ]\n",
      " [0.84769529]\n",
      " [0.85296607]\n",
      " [0.85917509]\n",
      " [0.86471194]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.8703931]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[[0.82638353]\n",
      "  [0.83236247]\n",
      "  [0.8376472 ]\n",
      "  [0.8435151 ]\n",
      "  [0.84769529]\n",
      "  [0.85296607]\n",
      "  [0.85917509]\n",
      "  [0.86471194]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.717184831155464e-05\n",
      "Predicción post entrenamiento : [[0.87051004]]\n",
      "PERDIDAAAA despues: 5.54170437681023e-05\n",
      "loss en el callback: 0.0005146358744241297, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "ejemplar: [[0.83236247]\n",
      " [0.8376472 ]\n",
      " [0.8435151 ]\n",
      " [0.84769529]\n",
      " [0.85296607]\n",
      " [0.85917509]\n",
      " [0.86471194]\n",
      " [0.8703931 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.8755411]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[[0.83236247]\n",
      "  [0.8376472 ]\n",
      "  [0.8435151 ]\n",
      "  [0.84769529]\n",
      "  [0.85296607]\n",
      "  [0.85917509]\n",
      "  [0.86471194]\n",
      "  [0.8703931 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007099721697159111\n",
      "Predicción post entrenamiento : [[0.8757046]]\n",
      "PERDIDAAAA despues: 0.0007187116425484419\n",
      "loss en el callback: 0.0010624248534440994, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "ejemplar: [[0.8376472 ]\n",
      " [0.8435151 ]\n",
      " [0.84769529]\n",
      " [0.85296607]\n",
      " [0.85917509]\n",
      " [0.86471194]\n",
      " [0.8703931 ]\n",
      " [0.87554109]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.8805734]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[[0.8376472 ]\n",
      "  [0.8435151 ]\n",
      "  [0.84769529]\n",
      "  [0.85296607]\n",
      "  [0.85917509]\n",
      "  [0.86471194]\n",
      "  [0.8703931 ]\n",
      "  [0.87554109]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0021530163940042257\n",
      "Predicción post entrenamiento : [[0.8804066]]\n",
      "PERDIDAAAA despues: 0.0021375673823058605\n",
      "loss en el callback: 0.0011155440006405115, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "ejemplar: [[0.8435151 ]\n",
      " [0.84769529]\n",
      " [0.85296607]\n",
      " [0.85917509]\n",
      " [0.86471194]\n",
      " [0.8703931 ]\n",
      " [0.87554109]\n",
      " [0.88057339]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.8853007]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[[0.8435151 ]\n",
      "  [0.84769529]\n",
      "  [0.85296607]\n",
      "  [0.85917509]\n",
      "  [0.86471194]\n",
      "  [0.8703931 ]\n",
      "  [0.87554109]\n",
      "  [0.88057339]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009123895433731377\n",
      "Predicción post entrenamiento : [[0.8851355]]\n",
      "PERDIDAAAA despues: 0.0009024353930726647\n",
      "loss en el callback: 0.0009703697287477553, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "ejemplar: [[0.84769529]\n",
      " [0.85296607]\n",
      " [0.85917509]\n",
      " [0.86471194]\n",
      " [0.8703931 ]\n",
      " [0.87554109]\n",
      " [0.88057339]\n",
      " [0.8853007 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.88988626]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[[0.84769529]\n",
      "  [0.85296607]\n",
      "  [0.85917509]\n",
      "  [0.86471194]\n",
      "  [0.8703931 ]\n",
      "  [0.87554109]\n",
      "  [0.88057339]\n",
      "  [0.8853007 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00021444926096592098\n",
      "Predicción post entrenamiento : [[0.89063686]]\n",
      "PERDIDAAAA despues: 0.00023699640587437898\n",
      "loss en el callback: 0.034748513251543045, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "ejemplar: [[0.85296607]\n",
      " [0.85917509]\n",
      " [0.86471194]\n",
      " [0.8703931 ]\n",
      " [0.87554109]\n",
      " [0.88057339]\n",
      " [0.8853007 ]\n",
      " [0.88988626]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.89572453]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[[0.85296607]\n",
      "  [0.85917509]\n",
      "  [0.86471194]\n",
      "  [0.8703931 ]\n",
      "  [0.87554109]\n",
      "  [0.88057339]\n",
      "  [0.8853007 ]\n",
      "  [0.88988626]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014970983611419797\n",
      "Predicción post entrenamiento : [[0.8955533]]\n",
      "PERDIDAAAA despues: 0.0014838760253041983\n",
      "loss en el callback: 0.0010702493600547314, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "ejemplar: [[0.85917509]\n",
      " [0.86471194]\n",
      " [0.8703931 ]\n",
      " [0.87554109]\n",
      " [0.88057339]\n",
      " [0.8853007 ]\n",
      " [0.88988626]\n",
      " [0.89572453]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.90067923]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[[0.85917509]\n",
      "  [0.86471194]\n",
      "  [0.8703931 ]\n",
      "  [0.87554109]\n",
      "  [0.88057339]\n",
      "  [0.8853007 ]\n",
      "  [0.88988626]\n",
      "  [0.89572453]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0025624949485063553\n",
      "Predicción post entrenamiento : [[0.90026045]]\n",
      "PERDIDAAAA despues: 0.0025202720426023006\n",
      "loss en el callback: 0.006194985471665859, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "ejemplar: [[0.86471194]\n",
      " [0.8703931 ]\n",
      " [0.87554109]\n",
      " [0.88057339]\n",
      " [0.8853007 ]\n",
      " [0.88988626]\n",
      " [0.89572453]\n",
      " [0.90067923]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.90512687]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[[0.86471194]\n",
      "  [0.8703931 ]\n",
      "  [0.87554109]\n",
      "  [0.88057339]\n",
      "  [0.8853007 ]\n",
      "  [0.88988626]\n",
      "  [0.89572453]\n",
      "  [0.90067923]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003897537710145116\n",
      "Predicción post entrenamiento : [[0.90472513]]\n",
      "PERDIDAAAA despues: 0.003847538260743022\n",
      "loss en el callback: 0.006486624479293823, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "ejemplar: [[0.8703931 ]\n",
      " [0.87554109]\n",
      " [0.88057339]\n",
      " [0.8853007 ]\n",
      " [0.88988626]\n",
      " [0.89572453]\n",
      " [0.90067923]\n",
      " [0.90512687]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.9094793]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[[0.8703931 ]\n",
      "  [0.87554109]\n",
      "  [0.88057339]\n",
      "  [0.8853007 ]\n",
      "  [0.88988626]\n",
      "  [0.89572453]\n",
      "  [0.90067923]\n",
      "  [0.90512687]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007489602081477642\n",
      "Predicción post entrenamiento : [[0.9091286]]\n",
      "PERDIDAAAA despues: 0.007429021876305342\n",
      "loss en el callback: 0.004811109509319067, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "ejemplar: [[0.87554109]\n",
      " [0.88057339]\n",
      " [0.8853007 ]\n",
      " [0.88988626]\n",
      " [0.89572453]\n",
      " [0.90067923]\n",
      " [0.90512687]\n",
      " [0.90947932]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.9136975]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[[0.87554109]\n",
      "  [0.88057339]\n",
      "  [0.8853007 ]\n",
      "  [0.88988626]\n",
      "  [0.89572453]\n",
      "  [0.90067923]\n",
      "  [0.90512687]\n",
      "  [0.90947932]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019374258816242218\n",
      "Predicción post entrenamiento : [[0.91311556]]\n",
      "PERDIDAAAA despues: 0.019212601706385612\n",
      "loss en el callback: 0.013164368458092213, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "ejemplar: [[0.88057339]\n",
      " [0.8853007 ]\n",
      " [0.88988626]\n",
      " [0.89572453]\n",
      " [0.90067923]\n",
      " [0.90512687]\n",
      " [0.90947932]\n",
      " [0.91369748]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.91761965]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[[0.88057339]\n",
      "  [0.8853007 ]\n",
      "  [0.88988626]\n",
      "  [0.89572453]\n",
      "  [0.90067923]\n",
      "  [0.90512687]\n",
      "  [0.90947932]\n",
      "  [0.91369748]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017802897840738297\n",
      "Predicción post entrenamiento : [[0.9172027]]\n",
      "PERDIDAAAA despues: 0.01769181154668331\n",
      "loss en el callback: 0.006482852157205343, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "ejemplar: [[0.8853007 ]\n",
      " [0.88988626]\n",
      " [0.89572453]\n",
      " [0.90067923]\n",
      " [0.90512687]\n",
      " [0.90947932]\n",
      " [0.91369748]\n",
      " [0.91761965]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.9216507]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[[0.8853007 ]\n",
      "  [0.88988626]\n",
      "  [0.89572453]\n",
      "  [0.90067923]\n",
      "  [0.90512687]\n",
      "  [0.90947932]\n",
      "  [0.91369748]\n",
      "  [0.91761965]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003832401940599084\n",
      "Predicción post entrenamiento : [[0.9202435]]\n",
      "PERDIDAAAA despues: 0.0036601522006094456\n",
      "loss en el callback: 0.05921592935919762, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "ejemplar: [[0.88988626]\n",
      " [0.89572453]\n",
      " [0.90067923]\n",
      " [0.90512687]\n",
      " [0.90947932]\n",
      " [0.91369748]\n",
      " [0.91761965]\n",
      " [0.92165071]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.92469376]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[[0.88988626]\n",
      "  [0.89572453]\n",
      "  [0.90067923]\n",
      "  [0.90512687]\n",
      "  [0.90947932]\n",
      "  [0.91369748]\n",
      "  [0.91761965]\n",
      "  [0.92165071]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004952459596097469\n",
      "Predicción post entrenamiento : [[0.9244657]]\n",
      "PERDIDAAAA despues: 0.0049204146489501\n",
      "loss en el callback: 0.0021400977857410908, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "ejemplar: [[0.89572453]\n",
      " [0.90067923]\n",
      " [0.90512687]\n",
      " [0.90947932]\n",
      " [0.91369748]\n",
      " [0.91761965]\n",
      " [0.92165071]\n",
      " [0.92469376]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.92892516]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[[0.89572453]\n",
      "  [0.90067923]\n",
      "  [0.90512687]\n",
      "  [0.90947932]\n",
      "  [0.91369748]\n",
      "  [0.91761965]\n",
      "  [0.92165071]\n",
      "  [0.92469376]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008471406064927578\n",
      "Predicción post entrenamiento : [[0.92880815]]\n",
      "PERDIDAAAA despues: 0.008449881337583065\n",
      "loss en el callback: 0.0006110024405643344, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "ejemplar: [[0.90067923]\n",
      " [0.90512687]\n",
      " [0.90947932]\n",
      " [0.91369748]\n",
      " [0.91761965]\n",
      " [0.92165071]\n",
      " [0.92469376]\n",
      " [0.92892516]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.9328635]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[[0.90067923]\n",
      "  [0.90512687]\n",
      "  [0.90947932]\n",
      "  [0.91369748]\n",
      "  [0.91761965]\n",
      "  [0.92165071]\n",
      "  [0.92469376]\n",
      "  [0.92892516]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010599237866699696\n",
      "Predicción post entrenamiento : [[0.9330065]]\n",
      "PERDIDAAAA despues: 0.0106287132948637\n",
      "loss en el callback: 0.00096803909400478, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "ejemplar: [[0.90512687]\n",
      " [0.90947932]\n",
      " [0.91369748]\n",
      " [0.91761965]\n",
      " [0.92165071]\n",
      " [0.92469376]\n",
      " [0.92892516]\n",
      " [0.93286347]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.9368375]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[[0.90512687]\n",
      "  [0.90947932]\n",
      "  [0.91369748]\n",
      "  [0.91761965]\n",
      "  [0.92165071]\n",
      "  [0.92469376]\n",
      "  [0.92892516]\n",
      "  [0.93286347]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0024586233776062727\n",
      "Predicción post entrenamiento : [[0.9358753]]\n",
      "PERDIDAAAA despues: 0.0023641290608793497\n",
      "loss en el callback: 0.033821336925029755, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "ejemplar: [[0.90947932]\n",
      " [0.91369748]\n",
      " [0.91761965]\n",
      " [0.92165071]\n",
      " [0.92469376]\n",
      " [0.92892516]\n",
      " [0.93286347]\n",
      " [0.93683749]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.9395832]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[[0.90947932]\n",
      "  [0.91369748]\n",
      "  [0.91761965]\n",
      "  [0.92165071]\n",
      "  [0.92469376]\n",
      "  [0.92892516]\n",
      "  [0.93286347]\n",
      "  [0.93683749]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006374245509505272\n",
      "Predicción post entrenamiento : [[0.9393989]]\n",
      "PERDIDAAAA despues: 0.006344851106405258\n",
      "loss en el callback: 0.0018026005709543824, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "ejemplar: [[0.91369748]\n",
      " [0.91761965]\n",
      " [0.92165071]\n",
      " [0.92469376]\n",
      " [0.92892516]\n",
      " [0.93286347]\n",
      " [0.93683749]\n",
      " [0.93958318]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.942979]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[[0.91369748]\n",
      "  [0.91761965]\n",
      "  [0.92165071]\n",
      "  [0.92469376]\n",
      "  [0.92892516]\n",
      "  [0.93286347]\n",
      "  [0.93683749]\n",
      "  [0.93958318]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01068782340735197\n",
      "Predicción post entrenamiento : [[0.9429215]]\n",
      "PERDIDAAAA despues: 0.0106759462505579\n",
      "loss en el callback: 0.00017699786985758692, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "ejemplar: [[0.91761965]\n",
      " [0.92165071]\n",
      " [0.92469376]\n",
      " [0.92892516]\n",
      " [0.93286347]\n",
      " [0.93683749]\n",
      " [0.93958318]\n",
      " [0.94297898]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.9463828]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[[0.91761965]\n",
      "  [0.92165071]\n",
      "  [0.92469376]\n",
      "  [0.92892516]\n",
      "  [0.93286347]\n",
      "  [0.93683749]\n",
      "  [0.93958318]\n",
      "  [0.94297898]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02643164061009884\n",
      "Predicción post entrenamiento : [[0.9464259]]\n",
      "PERDIDAAAA despues: 0.026445655152201653\n",
      "loss en el callback: 0.00010942945664282888, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "ejemplar: [[0.92165071]\n",
      " [0.92469376]\n",
      " [0.92892516]\n",
      " [0.93286347]\n",
      " [0.93683749]\n",
      " [0.93958318]\n",
      " [0.94297898]\n",
      " [0.94638282]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.9498269]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[[0.92165071]\n",
      "  [0.92469376]\n",
      "  [0.92892516]\n",
      "  [0.93286347]\n",
      "  [0.93683749]\n",
      "  [0.93958318]\n",
      "  [0.94297898]\n",
      "  [0.94638282]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0173026155680418\n",
      "Predicción post entrenamiento : [[0.94860643]]\n",
      "PERDIDAAAA despues: 0.016983026638627052\n",
      "loss en el callback: 0.05479314550757408, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "ejemplar: [[0.92469376]\n",
      " [0.92892516]\n",
      " [0.93286347]\n",
      " [0.93683749]\n",
      " [0.93958318]\n",
      " [0.94297898]\n",
      " [0.94638282]\n",
      " [0.9498269 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.95189357]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[[0.92469376]\n",
      "  [0.92892516]\n",
      "  [0.93286347]\n",
      "  [0.93683749]\n",
      "  [0.93958318]\n",
      "  [0.94297898]\n",
      "  [0.94638282]\n",
      "  [0.9498269 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.025833291932940483\n",
      "Predicción post entrenamiento : [[0.95037943]]\n",
      "PERDIDAAAA despues: 0.025348857045173645\n",
      "loss en el callback: 0.08325973898172379, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "ejemplar: [[0.92892516]\n",
      " [0.93286347]\n",
      " [0.93683749]\n",
      " [0.93958318]\n",
      " [0.94297898]\n",
      " [0.94638282]\n",
      " [0.9498269 ]\n",
      " [0.95189357]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.9538112]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[[0.92892516]\n",
      "  [0.93286347]\n",
      "  [0.93683749]\n",
      "  [0.93958318]\n",
      "  [0.94297898]\n",
      "  [0.94638282]\n",
      "  [0.9498269 ]\n",
      "  [0.95189357]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03734682872891426\n",
      "Predicción post entrenamiento : [[0.9519511]]\n",
      "PERDIDAAAA despues: 0.03663133457303047\n",
      "loss en el callback: 0.12286808341741562, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "ejemplar: [[0.93286347]\n",
      " [0.93683749]\n",
      " [0.93958318]\n",
      " [0.94297898]\n",
      " [0.94638282]\n",
      " [0.9498269 ]\n",
      " [0.95189357]\n",
      " [0.95381123]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.95515865]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[[0.93286347]\n",
      "  [0.93683749]\n",
      "  [0.93958318]\n",
      "  [0.94297898]\n",
      "  [0.94638282]\n",
      "  [0.9498269 ]\n",
      "  [0.95189357]\n",
      "  [0.95381123]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.026766587048768997\n",
      "Predicción post entrenamiento : [[0.953421]]\n",
      "PERDIDAAAA despues: 0.026201030239462852\n",
      "loss en el callback: 0.1015477403998375, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "ejemplar: [[0.93683749]\n",
      " [0.93958318]\n",
      " [0.94297898]\n",
      " [0.94638282]\n",
      " [0.9498269 ]\n",
      " [0.95189357]\n",
      " [0.95381123]\n",
      " [0.95515865]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9564175]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[[0.93683749]\n",
      "  [0.93958318]\n",
      "  [0.94297898]\n",
      "  [0.94638282]\n",
      "  [0.9498269 ]\n",
      "  [0.95189357]\n",
      "  [0.95381123]\n",
      "  [0.95515865]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03524000570178032\n",
      "Predicción post entrenamiento : [[0.9557035]]\n",
      "PERDIDAAAA despues: 0.03497244790196419\n",
      "loss en el callback: 0.024659277871251106, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "ejemplar: [[0.93958318]\n",
      " [0.94297898]\n",
      " [0.94638282]\n",
      " [0.9498269 ]\n",
      " [0.95189357]\n",
      " [0.95381123]\n",
      " [0.95515865]\n",
      " [0.9564175 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.958402]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[[0.93958318]\n",
      "  [0.94297898]\n",
      "  [0.94638282]\n",
      "  [0.9498269 ]\n",
      "  [0.95189357]\n",
      "  [0.95381123]\n",
      "  [0.95515865]\n",
      "  [0.9564175 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03598900884389877\n",
      "Predicción post entrenamiento : [[0.95774895]]\n",
      "PERDIDAAAA despues: 0.035741668194532394\n",
      "loss en el callback: 0.02240387536585331, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "ejemplar: [[0.94297898]\n",
      " [0.94638282]\n",
      " [0.9498269 ]\n",
      " [0.95189357]\n",
      " [0.95381123]\n",
      " [0.95515865]\n",
      " [0.9564175 ]\n",
      " [0.95840198]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.9604246]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[[0.94297898]\n",
      "  [0.94638282]\n",
      "  [0.9498269 ]\n",
      "  [0.95189357]\n",
      "  [0.95381123]\n",
      "  [0.95515865]\n",
      "  [0.9564175 ]\n",
      "  [0.95840198]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.026085304096341133\n",
      "Predicción post entrenamiento : [[0.95989406]]\n",
      "PERDIDAAAA despues: 0.025914210826158524\n",
      "loss en el callback: 0.015125780366361141, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "ejemplar: [[0.94638282]\n",
      " [0.9498269 ]\n",
      " [0.95189357]\n",
      " [0.95381123]\n",
      " [0.95515865]\n",
      " [0.9564175 ]\n",
      " [0.95840198]\n",
      " [0.9604246 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.9622977]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[[0.94638282]\n",
      "  [0.9498269 ]\n",
      "  [0.95189357]\n",
      "  [0.95381123]\n",
      "  [0.95515865]\n",
      "  [0.9564175 ]\n",
      "  [0.95840198]\n",
      "  [0.9604246 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02968514710664749\n",
      "Predicción post entrenamiento : [[0.96123636]]\n",
      "PERDIDAAAA despues: 0.029320556670427322\n",
      "loss en el callback: 0.04979337379336357, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "ejemplar: [[0.9498269 ]\n",
      " [0.95189357]\n",
      " [0.95381123]\n",
      " [0.95515865]\n",
      " [0.9564175 ]\n",
      " [0.95840198]\n",
      " [0.9604246 ]\n",
      " [0.96229768]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.96328455]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[[0.9498269 ]\n",
      "  [0.95189357]\n",
      "  [0.95381123]\n",
      "  [0.95515865]\n",
      "  [0.9564175 ]\n",
      "  [0.95840198]\n",
      "  [0.9604246 ]\n",
      "  [0.96229768]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04125533625483513\n",
      "Predicción post entrenamiento : [[0.96250534]]\n",
      "PERDIDAAAA despues: 0.04093940556049347\n",
      "loss en el callback: 0.030304141342639923, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "ejemplar: [[0.95189357]\n",
      " [0.95381123]\n",
      " [0.95515865]\n",
      " [0.9564175 ]\n",
      " [0.95840198]\n",
      " [0.9604246 ]\n",
      " [0.96229768]\n",
      " [0.96328455]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.9641091]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[[0.95189357]\n",
      "  [0.95381123]\n",
      "  [0.95515865]\n",
      "  [0.9564175 ]\n",
      "  [0.95840198]\n",
      "  [0.9604246 ]\n",
      "  [0.96229768]\n",
      "  [0.96328455]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07768252491950989\n",
      "Predicción post entrenamiento : [[0.9631324]]\n",
      "PERDIDAAAA despues: 0.07713901251554489\n",
      "loss en el callback: 0.0476372167468071, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "ejemplar: [[0.95381123]\n",
      " [0.95515865]\n",
      " [0.9564175 ]\n",
      " [0.95840198]\n",
      " [0.9604246 ]\n",
      " [0.96229768]\n",
      " [0.96328455]\n",
      " [0.96410912]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.96462435]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[[0.95381123]\n",
      "  [0.95515865]\n",
      "  [0.9564175 ]\n",
      "  [0.95840198]\n",
      "  [0.9604246 ]\n",
      "  [0.96229768]\n",
      "  [0.96328455]\n",
      "  [0.96410912]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12919177114963531\n",
      "Predicción post entrenamiento : [[0.96207607]]\n",
      "PERDIDAAAA despues: 0.12736640870571136\n",
      "loss en el callback: 0.26529234647750854, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "ejemplar: [[0.95515865]\n",
      " [0.9564175 ]\n",
      " [0.95840198]\n",
      " [0.9604246 ]\n",
      " [0.96229768]\n",
      " [0.96328455]\n",
      " [0.96410912]\n",
      " [0.96462435]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.96347106]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[[0.95515865]\n",
      "  [0.9564175 ]\n",
      "  [0.95840198]\n",
      "  [0.9604246 ]\n",
      "  [0.96229768]\n",
      "  [0.96328455]\n",
      "  [0.96410912]\n",
      "  [0.96462435]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08916941285133362\n",
      "Predicción post entrenamiento : [[0.9612836]]\n",
      "PERDIDAAAA despues: 0.08786780387163162\n",
      "loss en el callback: 0.18990415334701538, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "ejemplar: [[0.9564175 ]\n",
      " [0.95840198]\n",
      " [0.9604246 ]\n",
      " [0.96229768]\n",
      " [0.96328455]\n",
      " [0.96410912]\n",
      " [0.96462435]\n",
      " [0.96347106]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.96270865]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[[0.9564175 ]\n",
      "  [0.95840198]\n",
      "  [0.9604246 ]\n",
      "  [0.96229768]\n",
      "  [0.96328455]\n",
      "  [0.96410912]\n",
      "  [0.96462435]\n",
      "  [0.96347106]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06494519859552383\n",
      "Predicción post entrenamiento : [[0.9599106]]\n",
      "PERDIDAAAA despues: 0.06352688372135162\n",
      "loss en el callback: 0.2791031301021576, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "ejemplar: [[0.95840198]\n",
      " [0.9604246 ]\n",
      " [0.96229768]\n",
      " [0.96328455]\n",
      " [0.96410912]\n",
      " [0.96462435]\n",
      " [0.96347106]\n",
      " [0.96270865]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.96134317]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[[0.95840198]\n",
      "  [0.9604246 ]\n",
      "  [0.96229768]\n",
      "  [0.96328455]\n",
      "  [0.96410912]\n",
      "  [0.96462435]\n",
      "  [0.96347106]\n",
      "  [0.96270865]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08790311217308044\n",
      "Predicción post entrenamiento : [[0.96094507]]\n",
      "PERDIDAAAA despues: 0.08766721189022064\n",
      "loss en el callback: 0.011383606120944023, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "ejemplar: [[0.9604246 ]\n",
      " [0.96229768]\n",
      " [0.96328455]\n",
      " [0.96410912]\n",
      " [0.96462435]\n",
      " [0.96347106]\n",
      " [0.96270865]\n",
      " [0.96134317]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.96209764]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[[0.9604246 ]\n",
      "  [0.96229768]\n",
      "  [0.96328455]\n",
      "  [0.96410912]\n",
      "  [0.96462435]\n",
      "  [0.96347106]\n",
      "  [0.96270865]\n",
      "  [0.96134317]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06287329643964767\n",
      "Predicción post entrenamiento : [[0.96155286]]\n",
      "PERDIDAAAA despues: 0.06260038167238235\n",
      "loss en el callback: 0.01871446520090103, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "ejemplar: [[0.96229768]\n",
      " [0.96328455]\n",
      " [0.96410912]\n",
      " [0.96462435]\n",
      " [0.96347106]\n",
      " [0.96270865]\n",
      " [0.96134317]\n",
      " [0.96209764]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.9623015]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[[0.96229768]\n",
      "  [0.96328455]\n",
      "  [0.96410912]\n",
      "  [0.96462435]\n",
      "  [0.96347106]\n",
      "  [0.96270865]\n",
      "  [0.96134317]\n",
      "  [0.96209764]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08125042915344238\n",
      "Predicción post entrenamiento : [[0.96081406]]\n",
      "PERDIDAAAA despues: 0.08040466904640198\n",
      "loss en el callback: 0.11048153042793274, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "ejemplar: [[0.96328455]\n",
      " [0.96410912]\n",
      " [0.96462435]\n",
      " [0.96347106]\n",
      " [0.96270865]\n",
      " [0.96134317]\n",
      " [0.96209764]\n",
      " [0.96230149]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.96109146]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[[0.96328455]\n",
      "  [0.96410912]\n",
      "  [0.96462435]\n",
      "  [0.96347106]\n",
      "  [0.96270865]\n",
      "  [0.96134317]\n",
      "  [0.96209764]\n",
      "  [0.96230149]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03959452360868454\n",
      "Predicción post entrenamiento : [[0.9609993]]\n",
      "PERDIDAAAA despues: 0.03955785930156708\n",
      "loss en el callback: 0.0006329783354885876, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "ejemplar: [[0.96410912]\n",
      " [0.96462435]\n",
      " [0.96347106]\n",
      " [0.96270865]\n",
      " [0.96134317]\n",
      " [0.96209764]\n",
      " [0.96230149]\n",
      " [0.96109146]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.9609646]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[[0.96410912]\n",
      "  [0.96462435]\n",
      "  [0.96347106]\n",
      "  [0.96270865]\n",
      "  [0.96134317]\n",
      "  [0.96209764]\n",
      "  [0.96230149]\n",
      "  [0.96109146]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.023689236491918564\n",
      "Predicción post entrenamiento : [[0.9601987]]\n",
      "PERDIDAAAA despues: 0.023454053327441216\n",
      "loss en el callback: 0.03412014991044998, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "ejemplar: [[0.96462435]\n",
      " [0.96347106]\n",
      " [0.96270865]\n",
      " [0.96134317]\n",
      " [0.96209764]\n",
      " [0.96230149]\n",
      " [0.96109146]\n",
      " [0.96096462]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.9598384]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[[0.96462435]\n",
      "  [0.96347106]\n",
      "  [0.96270865]\n",
      "  [0.96134317]\n",
      "  [0.96209764]\n",
      "  [0.96230149]\n",
      "  [0.96109146]\n",
      "  [0.96096462]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.020923756062984467\n",
      "Predicción post entrenamiento : [[0.958876]]\n",
      "PERDIDAAAA despues: 0.020646264776587486\n",
      "loss en el callback: 0.04614400863647461, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "ejemplar: [[0.96347106]\n",
      " [0.96270865]\n",
      " [0.96134317]\n",
      " [0.96209764]\n",
      " [0.96230149]\n",
      " [0.96109146]\n",
      " [0.96096462]\n",
      " [0.95983839]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.9582339]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[[0.96347106]\n",
      "  [0.96270865]\n",
      "  [0.96134317]\n",
      "  [0.96209764]\n",
      "  [0.96230149]\n",
      "  [0.96109146]\n",
      "  [0.96096462]\n",
      "  [0.95983839]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0027035833336412907\n",
      "Predicción post entrenamiento : [[0.95838135]]\n",
      "PERDIDAAAA despues: 0.0027189399115741253\n",
      "loss en el callback: 0.001533002476207912, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "ejemplar: [[0.96270865]\n",
      " [0.96134317]\n",
      " [0.96209764]\n",
      " [0.96230149]\n",
      " [0.96109146]\n",
      " [0.96096462]\n",
      " [0.95983839]\n",
      " [0.95823389]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.9579139]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[[0.96270865]\n",
      "  [0.96134317]\n",
      "  [0.96209764]\n",
      "  [0.96230149]\n",
      "  [0.96109146]\n",
      "  [0.96096462]\n",
      "  [0.95983839]\n",
      "  [0.95823389]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.2100313092087163e-06\n",
      "Predicción post entrenamiento : [[0.95818126]]\n",
      "PERDIDAAAA despues: 2.3233976662595524e-06\n",
      "loss en el callback: 0.004450613167136908, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "ejemplar: [[0.96134317]\n",
      " [0.96209764]\n",
      " [0.96230149]\n",
      " [0.96109146]\n",
      " [0.96096462]\n",
      " [0.95983839]\n",
      " [0.95823389]\n",
      " [0.95791388]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.9577904]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[[0.96134317]\n",
      "  [0.96209764]\n",
      "  [0.96230149]\n",
      "  [0.96109146]\n",
      "  [0.96096462]\n",
      "  [0.95983839]\n",
      "  [0.95823389]\n",
      "  [0.95791388]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.309263385948725e-05\n",
      "Predicción post entrenamiento : [[0.9573517]]\n",
      "PERDIDAAAA despues: 4.904464367427863e-05\n",
      "loss en el callback: 0.009500758722424507, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "ejemplar: [[0.96209764]\n",
      " [0.96230149]\n",
      " [0.96109146]\n",
      " [0.96096462]\n",
      " [0.95983839]\n",
      " [0.95823389]\n",
      " [0.95791388]\n",
      " [0.95779037]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.95721126]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[[0.96209764]\n",
      "  [0.96230149]\n",
      "  [0.96109146]\n",
      "  [0.96096462]\n",
      "  [0.95983839]\n",
      "  [0.95823389]\n",
      "  [0.95791388]\n",
      "  [0.95779037]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004786335863173008\n",
      "Predicción post entrenamiento : [[0.9568316]]\n",
      "PERDIDAAAA despues: 0.0047339447773993015\n",
      "loss en el callback: 0.007573493756353855, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "ejemplar: [[0.96230149]\n",
      " [0.96109146]\n",
      " [0.96096462]\n",
      " [0.95983839]\n",
      " [0.95823389]\n",
      " [0.95791388]\n",
      " [0.95779037]\n",
      " [0.95721126]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.95632786]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[[0.96230149]\n",
      "  [0.96109146]\n",
      "  [0.96096462]\n",
      "  [0.95983839]\n",
      "  [0.95823389]\n",
      "  [0.95791388]\n",
      "  [0.95779037]\n",
      "  [0.95721126]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0040513998828828335\n",
      "Predicción post entrenamiento : [[0.9562892]]\n",
      "PERDIDAAAA despues: 0.004046476911753416\n",
      "loss en el callback: 0.000109761422208976, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "ejemplar: [[0.96109146]\n",
      " [0.96096462]\n",
      " [0.95983839]\n",
      " [0.95823389]\n",
      " [0.95791388]\n",
      " [0.95779037]\n",
      " [0.95721126]\n",
      " [0.95632786]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.955527]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[[0.96109146]\n",
      "  [0.96096462]\n",
      "  [0.95983839]\n",
      "  [0.95823389]\n",
      "  [0.95791388]\n",
      "  [0.95779037]\n",
      "  [0.95721126]\n",
      "  [0.95632786]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006445654667913914\n",
      "Predicción post entrenamiento : [[0.95607734]]\n",
      "PERDIDAAAA despues: 0.006534323561936617\n",
      "loss en el callback: 0.030167747288942337, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "ejemplar: [[0.96096462]\n",
      " [0.95983839]\n",
      " [0.95823389]\n",
      " [0.95791388]\n",
      " [0.95779037]\n",
      " [0.95721126]\n",
      " [0.95632786]\n",
      " [0.95552701]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.95544297]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[[0.96096462]\n",
      "  [0.95983839]\n",
      "  [0.95823389]\n",
      "  [0.95791388]\n",
      "  [0.95779037]\n",
      "  [0.95721126]\n",
      "  [0.95632786]\n",
      "  [0.95552701]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010943245142698288\n",
      "Predicción post entrenamiento : [[0.95553637]]\n",
      "PERDIDAAAA despues: 0.010962795466184616\n",
      "loss en el callback: 0.000692697474732995, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "ejemplar: [[0.95983839]\n",
      " [0.95823389]\n",
      " [0.95791388]\n",
      " [0.95779037]\n",
      " [0.95721126]\n",
      " [0.95632786]\n",
      " [0.95552701]\n",
      " [0.95544297]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.95473677]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[[0.95983839]\n",
      "  [0.95823389]\n",
      "  [0.95791388]\n",
      "  [0.95779037]\n",
      "  [0.95721126]\n",
      "  [0.95632786]\n",
      "  [0.95552701]\n",
      "  [0.95544297]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011202313005924225\n",
      "Predicción post entrenamiento : [[0.95414037]]\n",
      "PERDIDAAAA despues: 0.011076420545578003\n",
      "loss en el callback: 0.019532645121216774, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "ejemplar: [[0.95823389]\n",
      " [0.95791388]\n",
      " [0.95779037]\n",
      " [0.95721126]\n",
      " [0.95632786]\n",
      " [0.95552701]\n",
      " [0.95544297]\n",
      " [0.95473677]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.9534619]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[[0.95823389]\n",
      "  [0.95791388]\n",
      "  [0.95779037]\n",
      "  [0.95721126]\n",
      "  [0.95632786]\n",
      "  [0.95552701]\n",
      "  [0.95544297]\n",
      "  [0.95473677]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.020593668334186e-05\n",
      "Predicción post entrenamiento : [[0.95326024]]\n",
      "PERDIDAAAA despues: 8.385832916246727e-05\n",
      "loss en el callback: 0.0022982051596045494, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "ejemplar: [[0.95791388]\n",
      " [0.95779037]\n",
      " [0.95721126]\n",
      " [0.95632786]\n",
      " [0.95552701]\n",
      " [0.95544297]\n",
      " [0.95473677]\n",
      " [0.95346189]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.95286435]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[[0.95791388]\n",
      "  [0.95779037]\n",
      "  [0.95721126]\n",
      "  [0.95632786]\n",
      "  [0.95552701]\n",
      "  [0.95544297]\n",
      "  [0.95473677]\n",
      "  [0.95346189]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00022432772675529122\n",
      "Predicción post entrenamiento : [[0.95247024]]\n",
      "PERDIDAAAA despues: 0.00023628855706192553\n",
      "loss en el callback: 0.007882012985646725, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "ejemplar: [[0.95779037]\n",
      " [0.95721126]\n",
      " [0.95632786]\n",
      " [0.95552701]\n",
      " [0.95544297]\n",
      " [0.95473677]\n",
      " [0.95346189]\n",
      " [0.95286435]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.95200783]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[[0.95779037]\n",
      "  [0.95721126]\n",
      "  [0.95632786]\n",
      "  [0.95552701]\n",
      "  [0.95544297]\n",
      "  [0.95473677]\n",
      "  [0.95346189]\n",
      "  [0.95286435]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001273998204851523\n",
      "Predicción post entrenamiento : [[0.9522313]]\n",
      "PERDIDAAAA despues: 0.00013249415496829897\n",
      "loss en el callback: 0.0036617317236959934, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "ejemplar: [[0.95721126]\n",
      " [0.95632786]\n",
      " [0.95552701]\n",
      " [0.95544297]\n",
      " [0.95473677]\n",
      " [0.95346189]\n",
      " [0.95286435]\n",
      " [0.95200783]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.9516248]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[[0.95721126]\n",
      "  [0.95632786]\n",
      "  [0.95552701]\n",
      "  [0.95544297]\n",
      "  [0.95473677]\n",
      "  [0.95346189]\n",
      "  [0.95286435]\n",
      "  [0.95200783]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00043540887418203056\n",
      "Predicción post entrenamiento : [[0.95116633]]\n",
      "PERDIDAAAA despues: 0.0004547527350950986\n",
      "loss en el callback: 0.011781875975430012, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "ejemplar: [[0.95632786]\n",
      " [0.95552701]\n",
      " [0.95544297]\n",
      " [0.95473677]\n",
      " [0.95346189]\n",
      " [0.95286435]\n",
      " [0.95200783]\n",
      " [0.95162481]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.9505273]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[[0.95632786]\n",
      "  [0.95552701]\n",
      "  [0.95544297]\n",
      "  [0.95473677]\n",
      "  [0.95346189]\n",
      "  [0.95286435]\n",
      "  [0.95200783]\n",
      "  [0.95162481]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0021504671312868595\n",
      "Predicción post entrenamiento : [[0.9509695]]\n",
      "PERDIDAAAA despues: 0.0021096495911478996\n",
      "loss en el callback: 0.015037868171930313, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "ejemplar: [[0.95552701]\n",
      " [0.95544297]\n",
      " [0.95473677]\n",
      " [0.95346189]\n",
      " [0.95286435]\n",
      " [0.95200783]\n",
      " [0.95162481]\n",
      " [0.95052731]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.9503801]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[[0.95552701]\n",
      "  [0.95544297]\n",
      "  [0.95473677]\n",
      "  [0.95346189]\n",
      "  [0.95286435]\n",
      "  [0.95200783]\n",
      "  [0.95162481]\n",
      "  [0.95052731]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.425992182812479e-07\n",
      "Predicción post entrenamiento : [[0.95105785]]\n",
      "PERDIDAAAA despues: 1.5340916093009582e-08\n",
      "loss en el callback: 0.045187074691057205, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "ejemplar: [[0.95544297]\n",
      " [0.95473677]\n",
      " [0.95346189]\n",
      " [0.95286435]\n",
      " [0.95200783]\n",
      " [0.95162481]\n",
      " [0.95052731]\n",
      " [0.95038009]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.9504978]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[[0.95544297]\n",
      "  [0.95473677]\n",
      "  [0.95346189]\n",
      "  [0.95286435]\n",
      "  [0.95200783]\n",
      "  [0.95162481]\n",
      "  [0.95052731]\n",
      "  [0.95038009]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029943876434117556\n",
      "Predicción post entrenamiento : [[0.9502956]]\n",
      "PERDIDAAAA despues: 0.002972301561385393\n",
      "loss en el callback: 0.0025268234312534332, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "ejemplar: [[0.95473677]\n",
      " [0.95346189]\n",
      " [0.95286435]\n",
      " [0.95200783]\n",
      " [0.95162481]\n",
      " [0.95052731]\n",
      " [0.95038009]\n",
      " [0.95049781]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.94956094]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[[0.95473677]\n",
      "  [0.95346189]\n",
      "  [0.95286435]\n",
      "  [0.95200783]\n",
      "  [0.95162481]\n",
      "  [0.95052731]\n",
      "  [0.95038009]\n",
      "  [0.95049781]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004640285857021809\n",
      "Predicción post entrenamiento : [[0.94997734]]\n",
      "PERDIDAAAA despues: 0.004697189200669527\n",
      "loss en el callback: 0.017776472494006157, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "ejemplar: [[0.95346189]\n",
      " [0.95286435]\n",
      " [0.95200783]\n",
      " [0.95162481]\n",
      " [0.95052731]\n",
      " [0.95038009]\n",
      " [0.95049781]\n",
      " [0.94956094]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.9492397]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[[0.95346189]\n",
      "  [0.95286435]\n",
      "  [0.95200783]\n",
      "  [0.95162481]\n",
      "  [0.95052731]\n",
      "  [0.95038009]\n",
      "  [0.95049781]\n",
      "  [0.94956094]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001033831387758255\n",
      "Predicción post entrenamiento : [[0.94867355]]\n",
      "PERDIDAAAA despues: 0.0009977463632822037\n",
      "loss en el callback: 0.020336799323558807, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "ejemplar: [[0.95286435]\n",
      " [0.95200783]\n",
      " [0.95162481]\n",
      " [0.95052731]\n",
      " [0.95038009]\n",
      " [0.95049781]\n",
      " [0.94956094]\n",
      " [0.94923967]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.94811594]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[[0.95286435]\n",
      "  [0.95200783]\n",
      "  [0.95162481]\n",
      "  [0.95052731]\n",
      "  [0.95038009]\n",
      "  [0.95049781]\n",
      "  [0.94956094]\n",
      "  [0.94923967]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008018746739253402\n",
      "Predicción post entrenamiento : [[0.947106]]\n",
      "PERDIDAAAA despues: 0.0007456968887709081\n",
      "loss en el callback: 0.05207225680351257, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "ejemplar: [[0.95200783]\n",
      " [0.95162481]\n",
      " [0.95052731]\n",
      " [0.95038009]\n",
      " [0.95049781]\n",
      " [0.94956094]\n",
      " [0.94923967]\n",
      " [0.94811594]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.94655997]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[[0.95200783]\n",
      "  [0.95162481]\n",
      "  [0.95052731]\n",
      "  [0.95038009]\n",
      "  [0.95049781]\n",
      "  [0.94956094]\n",
      "  [0.94923967]\n",
      "  [0.94811594]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00022749195341020823\n",
      "Predicción post entrenamiento : [[0.9462256]]\n",
      "PERDIDAAAA despues: 0.00023769061954226345\n",
      "loss en el callback: 0.006832619663327932, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "ejemplar: [[0.95162481]\n",
      " [0.95052731]\n",
      " [0.95038009]\n",
      " [0.95049781]\n",
      " [0.94956094]\n",
      " [0.94923967]\n",
      " [0.94811594]\n",
      " [0.94655997]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.9457655]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[[0.95162481]\n",
      "  [0.95052731]\n",
      "  [0.95038009]\n",
      "  [0.95049781]\n",
      "  [0.94956094]\n",
      "  [0.94923967]\n",
      "  [0.94811594]\n",
      "  [0.94655997]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005046249134466052\n",
      "Predicción post entrenamiento : [[0.9465148]]\n",
      "PERDIDAAAA despues: 0.0004715224786195904\n",
      "loss en el callback: 0.06066705659031868, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "ejemplar: [[0.95052731]\n",
      " [0.95038009]\n",
      " [0.95049781]\n",
      " [0.94956094]\n",
      " [0.94923967]\n",
      " [0.94811594]\n",
      " [0.94655997]\n",
      " [0.9457655 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.9460011]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[[0.95052731]\n",
      "  [0.95038009]\n",
      "  [0.95049781]\n",
      "  [0.94956094]\n",
      "  [0.94923967]\n",
      "  [0.94811594]\n",
      "  [0.94655997]\n",
      "  [0.9457655 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00013846719230059534\n",
      "Predicción post entrenamiento : [[0.94615936]]\n",
      "PERDIDAAAA despues: 0.00013476790627464652\n",
      "loss en el callback: 0.0019798355642706156, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "ejemplar: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.20378469]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.024862518534064293\n",
      "Predicción post entrenamiento : [[0.17756434]]\n",
      "PERDIDAAAA despues: 0.01728125289082527\n",
      "loss en el callback: 0.025923466309905052, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "ejemplar: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20378469]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.16130236]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.20378469]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0032580336555838585\n",
      "Predicción post entrenamiento : [[0.1535207]]\n",
      "PERDIDAAAA despues: 0.0024302469100803137\n",
      "loss en el callback: 0.0026273922994732857, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "ejemplar: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20378469]\n",
      " [0.16130236]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.15736985]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.20378469]\n",
      "  [0.16130236]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.0023871254816186e-05\n",
      "Predicción post entrenamiento : [[0.15789862]]\n",
      "PERDIDAAAA despues: 1.3651675544679165e-05\n",
      "loss en el callback: 2.908443275373429e-05, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "ejemplar: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20378469]\n",
      " [0.16130236]\n",
      " [0.15736985]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.16895366]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.20378469]\n",
      "  [0.16130236]\n",
      "  [0.15736985]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001742419699439779\n",
      "Predicción post entrenamiento : [[0.16751947]]\n",
      "PERDIDAAAA despues: 0.00013843599299434572\n",
      "loss en el callback: 0.00032081734389066696, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "ejemplar: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20378469]\n",
      " [0.16130236]\n",
      " [0.15736985]\n",
      " [0.16895366]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.17915939]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.20378469]\n",
      "  [0.16130236]\n",
      "  [0.15736985]\n",
      "  [0.16895366]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0028758167754858732\n",
      "Predicción post entrenamiento : [[0.17842527]]\n",
      "PERDIDAAAA despues: 0.002797618741169572\n",
      "loss en el callback: 0.00021601626940537244, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "ejemplar: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20378469]\n",
      " [0.16130236]\n",
      " [0.15736985]\n",
      " [0.16895366]\n",
      " [0.17915939]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.18653695]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.20378469]\n",
      "  [0.16130236]\n",
      "  [0.15736985]\n",
      "  [0.16895366]\n",
      "  [0.17915939]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016692933859303594\n",
      "Predicción post entrenamiento : [[0.1841486]]\n",
      "PERDIDAAAA despues: 0.001479835482314229\n",
      "loss en el callback: 0.0020235185511410236, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "ejemplar: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.20378469]\n",
      " [0.16130236]\n",
      " [0.15736985]\n",
      " [0.16895366]\n",
      " [0.17915939]\n",
      " [0.18653695]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.2028523]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.20378469]\n",
      "  [0.16130236]\n",
      "  [0.15736985]\n",
      "  [0.16895366]\n",
      "  [0.17915939]\n",
      "  [0.18653695]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0031806710176169872\n",
      "Predicción post entrenamiento : [[0.2007122]]\n",
      "PERDIDAAAA despues: 0.002943859901279211\n",
      "loss en el callback: 0.0022275384981185198, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "ejemplar: [[0.04223169]\n",
      " [0.20378469]\n",
      " [0.16130236]\n",
      " [0.15736985]\n",
      " [0.16895366]\n",
      " [0.17915939]\n",
      " [0.18653695]\n",
      " [0.20285229]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.22309622]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[[0.04223169]\n",
      "  [0.20378469]\n",
      "  [0.16130236]\n",
      "  [0.15736985]\n",
      "  [0.16895366]\n",
      "  [0.17915939]\n",
      "  [0.18653695]\n",
      "  [0.20285229]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007316043484024704\n",
      "Predicción post entrenamiento : [[0.22229977]]\n",
      "PERDIDAAAA despues: 0.0006891535012982786\n",
      "loss en el callback: 0.0003777795936912298, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "ejemplar: [[0.20378469]\n",
      " [0.16130236]\n",
      " [0.15736985]\n",
      " [0.16895366]\n",
      " [0.17915939]\n",
      " [0.18653695]\n",
      " [0.20285229]\n",
      " [0.22309622]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.24865794]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[[0.20378469]\n",
      "  [0.16130236]\n",
      "  [0.15736985]\n",
      "  [0.16895366]\n",
      "  [0.17915939]\n",
      "  [0.18653695]\n",
      "  [0.20285229]\n",
      "  [0.22309622]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00032859333441592753\n",
      "Predicción post entrenamiento : [[0.24717928]]\n",
      "PERDIDAAAA despues: 0.0002771721046883613\n",
      "loss en el callback: 0.0013546105474233627, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "ejemplar: [[0.16130236]\n",
      " [0.15736985]\n",
      " [0.16895366]\n",
      " [0.17915939]\n",
      " [0.18653695]\n",
      " [0.20285229]\n",
      " [0.22309622]\n",
      " [0.24865794]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.24212383]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[[0.16130236]\n",
      "  [0.15736985]\n",
      "  [0.16895366]\n",
      "  [0.17915939]\n",
      "  [0.18653695]\n",
      "  [0.20285229]\n",
      "  [0.22309622]\n",
      "  [0.24865794]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001134173246100545\n",
      "Predicción post entrenamiento : [[0.24196568]]\n",
      "PERDIDAAAA despues: 0.0011235462734475732\n",
      "loss en el callback: 2.6399296984891407e-05, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "ejemplar: [[0.15736985]\n",
      " [0.16895366]\n",
      " [0.17915939]\n",
      " [0.18653695]\n",
      " [0.20285229]\n",
      " [0.22309622]\n",
      " [0.24865794]\n",
      " [0.24212383]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.24715982]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[[0.15736985]\n",
      "  [0.16895366]\n",
      "  [0.17915939]\n",
      "  [0.18653695]\n",
      "  [0.20285229]\n",
      "  [0.22309622]\n",
      "  [0.24865794]\n",
      "  [0.24212383]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012409037444740534\n",
      "Predicción post entrenamiento : [[0.24641764]]\n",
      "PERDIDAAAA despues: 0.001189165748655796\n",
      "loss en el callback: 0.0005892635672353208, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "ejemplar: [[0.16895366]\n",
      " [0.17915939]\n",
      " [0.18653695]\n",
      " [0.20285229]\n",
      " [0.22309622]\n",
      " [0.24865794]\n",
      " [0.24212383]\n",
      " [0.24715982]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.25491104]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[[0.16895366]\n",
      "  [0.17915939]\n",
      "  [0.18653695]\n",
      "  [0.20285229]\n",
      "  [0.22309622]\n",
      "  [0.24865794]\n",
      "  [0.24212383]\n",
      "  [0.24715982]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002268334152176976\n",
      "Predicción post entrenamiento : [[0.25252825]]\n",
      "PERDIDAAAA despues: 0.0020470418967306614\n",
      "loss en el callback: 0.005512303207069635, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "ejemplar: [[0.17915939]\n",
      " [0.18653695]\n",
      " [0.20285229]\n",
      " [0.22309622]\n",
      " [0.24865794]\n",
      " [0.24212383]\n",
      " [0.24715982]\n",
      " [0.25491104]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.26124325]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[[0.17915939]\n",
      "  [0.18653695]\n",
      "  [0.20285229]\n",
      "  [0.22309622]\n",
      "  [0.24865794]\n",
      "  [0.24212383]\n",
      "  [0.24715982]\n",
      "  [0.25491104]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004664176609367132\n",
      "Predicción post entrenamiento : [[0.25992683]]\n",
      "PERDIDAAAA despues: 0.004486099351197481\n",
      "loss en el callback: 0.0027703114319592714, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "ejemplar: [[0.18653695]\n",
      " [0.20285229]\n",
      " [0.22309622]\n",
      " [0.24865794]\n",
      " [0.24212383]\n",
      " [0.24715982]\n",
      " [0.25491104]\n",
      " [0.26124325]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.26907852]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[[0.18653695]\n",
      "  [0.20285229]\n",
      "  [0.22309622]\n",
      "  [0.24865794]\n",
      "  [0.24212383]\n",
      "  [0.24715982]\n",
      "  [0.25491104]\n",
      "  [0.26124325]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005220869090408087\n",
      "Predicción post entrenamiento : [[0.26706076]]\n",
      "PERDIDAAAA despues: 0.004933350719511509\n",
      "loss en el callback: 0.006196777801960707, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "ejemplar: [[0.20285229]\n",
      " [0.22309622]\n",
      " [0.24865794]\n",
      " [0.24212383]\n",
      " [0.24715982]\n",
      " [0.25491104]\n",
      " [0.26124325]\n",
      " [0.26907852]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.27718616]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[[0.20285229]\n",
      "  [0.22309622]\n",
      "  [0.24865794]\n",
      "  [0.24212383]\n",
      "  [0.24715982]\n",
      "  [0.25491104]\n",
      "  [0.26124325]\n",
      "  [0.26907852]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003959947265684605\n",
      "Predicción post entrenamiento : [[0.27297527]]\n",
      "PERDIDAAAA despues: 0.0034477119334042072\n",
      "loss en el callback: 0.02081143483519554, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "ejemplar: [[0.22309622]\n",
      " [0.24865794]\n",
      " [0.24212383]\n",
      " [0.24715982]\n",
      " [0.25491104]\n",
      " [0.26124325]\n",
      " [0.26907852]\n",
      " [0.27718616]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.28188908]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[[0.22309622]\n",
      "  [0.24865794]\n",
      "  [0.24212383]\n",
      "  [0.24715982]\n",
      "  [0.25491104]\n",
      "  [0.26124325]\n",
      "  [0.26907852]\n",
      "  [0.27718616]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010113121941685677\n",
      "Predicción post entrenamiento : [[0.27999732]]\n",
      "PERDIDAAAA despues: 0.009736213833093643\n",
      "loss en el callback: 0.007732970640063286, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "ejemplar: [[0.24865794]\n",
      " [0.24212383]\n",
      " [0.24715982]\n",
      " [0.25491104]\n",
      " [0.26124325]\n",
      " [0.26907852]\n",
      " [0.27718616]\n",
      " [0.28188908]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.28637597]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[[0.24865794]\n",
      "  [0.24212383]\n",
      "  [0.24715982]\n",
      "  [0.25491104]\n",
      "  [0.26124325]\n",
      "  [0.26907852]\n",
      "  [0.27718616]\n",
      "  [0.28188908]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012376572005450726\n",
      "Predicción post entrenamiento : [[0.28491762]]\n",
      "PERDIDAAAA despues: 0.012054216116666794\n",
      "loss en el callback: 0.0059449258260428905, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "ejemplar: [[0.24212383]\n",
      " [0.24715982]\n",
      " [0.25491104]\n",
      " [0.26124325]\n",
      " [0.26907852]\n",
      " [0.27718616]\n",
      " [0.28188908]\n",
      " [0.28637597]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.28699398]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[[0.24212383]\n",
      "  [0.24715982]\n",
      "  [0.25491104]\n",
      "  [0.26124325]\n",
      "  [0.26907852]\n",
      "  [0.27718616]\n",
      "  [0.28188908]\n",
      "  [0.28637597]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019318033009767532\n",
      "Predicción post entrenamiento : [[0.2831111]]\n",
      "PERDIDAAAA despues: 0.01825375109910965\n",
      "loss en el callback: 0.03126804530620575, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "ejemplar: [[0.24715982]\n",
      " [0.25491104]\n",
      " [0.26124325]\n",
      " [0.26907852]\n",
      " [0.27718616]\n",
      " [0.28188908]\n",
      " [0.28637597]\n",
      " [0.28699398]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.28783646]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[[0.24715982]\n",
      "  [0.25491104]\n",
      "  [0.26124325]\n",
      "  [0.26907852]\n",
      "  [0.27718616]\n",
      "  [0.28188908]\n",
      "  [0.28637597]\n",
      "  [0.28699398]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016636691987514496\n",
      "Predicción post entrenamiento : [[0.28487957]]\n",
      "PERDIDAAAA despues: 0.01588265597820282\n",
      "loss en el callback: 0.02135583572089672, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "ejemplar: [[0.25491104]\n",
      " [0.26124325]\n",
      " [0.26907852]\n",
      " [0.27718616]\n",
      " [0.28188908]\n",
      " [0.28637597]\n",
      " [0.28699398]\n",
      " [0.28783646]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.2898644]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[[0.25491104]\n",
      "  [0.26124325]\n",
      "  [0.26907852]\n",
      "  [0.27718616]\n",
      "  [0.28188908]\n",
      "  [0.28637597]\n",
      "  [0.28699398]\n",
      "  [0.28783646]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009543496184051037\n",
      "Predicción post entrenamiento : [[0.2876982]]\n",
      "PERDIDAAAA despues: 0.009124957025051117\n",
      "loss en el callback: 0.013365293852984905, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "ejemplar: [[0.26124325]\n",
      " [0.26907852]\n",
      " [0.27718616]\n",
      " [0.28188908]\n",
      " [0.28637597]\n",
      " [0.28699398]\n",
      " [0.28783646]\n",
      " [0.28986439]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.29221618]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[[0.26124325]\n",
      "  [0.26907852]\n",
      "  [0.27718616]\n",
      "  [0.28188908]\n",
      "  [0.28637597]\n",
      "  [0.28699398]\n",
      "  [0.28783646]\n",
      "  [0.28986439]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011287309229373932\n",
      "Predicción post entrenamiento : [[0.2900386]]\n",
      "PERDIDAAAA despues: 0.010829348117113113\n",
      "loss en el callback: 0.013720148243010044, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "ejemplar: [[0.26907852]\n",
      " [0.27718616]\n",
      " [0.28188908]\n",
      " [0.28637597]\n",
      " [0.28699398]\n",
      " [0.28783646]\n",
      " [0.28986439]\n",
      " [0.29221618]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.29422465]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[[0.26907852]\n",
      "  [0.27718616]\n",
      "  [0.28188908]\n",
      "  [0.28637597]\n",
      "  [0.28699398]\n",
      "  [0.28783646]\n",
      "  [0.28986439]\n",
      "  [0.29221618]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007438636384904385\n",
      "Predicción post entrenamiento : [[0.29469946]]\n",
      "PERDIDAAAA despues: 0.0007699889247305691\n",
      "loss en el callback: 0.001025642268359661, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "ejemplar: [[0.27718616]\n",
      " [0.28188908]\n",
      " [0.28637597]\n",
      " [0.28699398]\n",
      " [0.28783646]\n",
      " [0.28986439]\n",
      " [0.29221618]\n",
      " [0.29422465]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.29802656]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[[0.27718616]\n",
      "  [0.28188908]\n",
      "  [0.28637597]\n",
      "  [0.28699398]\n",
      "  [0.28783646]\n",
      "  [0.28986439]\n",
      "  [0.29221618]\n",
      "  [0.29422465]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.0297102057375014e-05\n",
      "Predicción post entrenamiento : [[0.2977665]]\n",
      "PERDIDAAAA despues: 2.750189923972357e-05\n",
      "loss en el callback: 0.0002564666501712054, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "ejemplar: [[0.28188908]\n",
      " [0.28637597]\n",
      " [0.28699398]\n",
      " [0.28783646]\n",
      " [0.28986439]\n",
      " [0.29221618]\n",
      " [0.29422465]\n",
      " [0.29802656]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.2999531]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[[0.28188908]\n",
      "  [0.28637597]\n",
      "  [0.28699398]\n",
      "  [0.28783646]\n",
      "  [0.28986439]\n",
      "  [0.29221618]\n",
      "  [0.29422465]\n",
      "  [0.29802656]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003151765849906951\n",
      "Predicción post entrenamiento : [[0.3002507]]\n",
      "PERDIDAAAA despues: 0.0003046982455998659\n",
      "loss en el callback: 0.0003646942786872387, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "ejemplar: [[0.28637597]\n",
      " [0.28699398]\n",
      " [0.28783646]\n",
      " [0.28986439]\n",
      " [0.29221618]\n",
      " [0.29422465]\n",
      " [0.29802656]\n",
      " [0.2999531 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.3019085]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[[0.28637597]\n",
      "  [0.28699398]\n",
      "  [0.28783646]\n",
      "  [0.28986439]\n",
      "  [0.29221618]\n",
      "  [0.29422465]\n",
      "  [0.29802656]\n",
      "  [0.2999531 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00011579960846574977\n",
      "Predicción post entrenamiento : [[0.3017754]]\n",
      "PERDIDAAAA despues: 0.00011868184810737148\n",
      "loss en el callback: 7.445594383170828e-05, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "ejemplar: [[0.28699398]\n",
      " [0.28783646]\n",
      " [0.28986439]\n",
      " [0.29221618]\n",
      " [0.29422465]\n",
      " [0.29802656]\n",
      " [0.2999531 ]\n",
      " [0.30190849]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.30287662]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[[0.28699398]\n",
      "  [0.28783646]\n",
      "  [0.28986439]\n",
      "  [0.29221618]\n",
      "  [0.29422465]\n",
      "  [0.29802656]\n",
      "  [0.2999531 ]\n",
      "  [0.30190849]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00019158326904289424\n",
      "Predicción post entrenamiento : [[0.3023769]]\n",
      "PERDIDAAAA despues: 0.00017799923080019653\n",
      "loss en el callback: 0.0011019844096153975, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "ejemplar: [[0.28783646]\n",
      " [0.28986439]\n",
      " [0.29221618]\n",
      " [0.29422465]\n",
      " [0.29802656]\n",
      " [0.2999531 ]\n",
      " [0.30190849]\n",
      " [0.30287662]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.30378184]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[[0.28783646]\n",
      "  [0.28986439]\n",
      "  [0.29221618]\n",
      "  [0.29422465]\n",
      "  [0.29802656]\n",
      "  [0.2999531 ]\n",
      "  [0.30190849]\n",
      "  [0.30287662]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00043872350943274796\n",
      "Predicción post entrenamiento : [[0.3042119]]\n",
      "PERDIDAAAA despues: 0.0004569250450003892\n",
      "loss en el callback: 0.0012884855968877673, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "ejemplar: [[0.28986439]\n",
      " [0.29221618]\n",
      " [0.29422465]\n",
      " [0.29802656]\n",
      " [0.2999531 ]\n",
      " [0.30190849]\n",
      " [0.30287662]\n",
      " [0.30378184]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.30591252]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[[0.28986439]\n",
      "  [0.29221618]\n",
      "  [0.29422465]\n",
      "  [0.29802656]\n",
      "  [0.2999531 ]\n",
      "  [0.30190849]\n",
      "  [0.30287662]\n",
      "  [0.30378184]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.116764466743916e-05\n",
      "Predicción post entrenamiento : [[0.30532464]]\n",
      "PERDIDAAAA despues: 3.396932515897788e-05\n",
      "loss en el callback: 0.001670177560299635, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "ejemplar: [[0.29221618]\n",
      " [0.29422465]\n",
      " [0.29802656]\n",
      " [0.2999531 ]\n",
      " [0.30190849]\n",
      " [0.30287662]\n",
      " [0.30378184]\n",
      " [0.30591252]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.30706167]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[[0.29221618]\n",
      "  [0.29422465]\n",
      "  [0.29802656]\n",
      "  [0.2999531 ]\n",
      "  [0.30190849]\n",
      "  [0.30287662]\n",
      "  [0.30378184]\n",
      "  [0.30591252]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009734153281897306\n",
      "Predicción post entrenamiento : [[0.30564973]]\n",
      "PERDIDAAAA despues: 0.0008873046608641744\n",
      "loss en el callback: 0.00908034946769476, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "ejemplar: [[0.29422465]\n",
      " [0.29802656]\n",
      " [0.2999531 ]\n",
      " [0.30190849]\n",
      " [0.30287662]\n",
      " [0.30378184]\n",
      " [0.30591252]\n",
      " [0.30706167]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.30732355]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[[0.29422465]\n",
      "  [0.29802656]\n",
      "  [0.2999531 ]\n",
      "  [0.30190849]\n",
      "  [0.30287662]\n",
      "  [0.30378184]\n",
      "  [0.30591252]\n",
      "  [0.30706167]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010643141577020288\n",
      "Predicción post entrenamiento : [[0.3067858]]\n",
      "PERDIDAAAA despues: 0.001029516221024096\n",
      "loss en el callback: 0.0017723332857713103, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "ejemplar: [[0.29802656]\n",
      " [0.2999531 ]\n",
      " [0.30190849]\n",
      " [0.30287662]\n",
      " [0.30378184]\n",
      " [0.30591252]\n",
      " [0.30706167]\n",
      " [0.30732355]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.3084369]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[[0.29802656]\n",
      "  [0.2999531 ]\n",
      "  [0.30190849]\n",
      "  [0.30287662]\n",
      "  [0.30378184]\n",
      "  [0.30591252]\n",
      "  [0.30706167]\n",
      "  [0.30732355]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001086512696929276\n",
      "Predicción post entrenamiento : [[0.30889076]]\n",
      "PERDIDAAAA despues: 0.0011166392359882593\n",
      "loss en el callback: 0.0022538043558597565, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "ejemplar: [[0.2999531 ]\n",
      " [0.30190849]\n",
      " [0.30287662]\n",
      " [0.30378184]\n",
      " [0.30591252]\n",
      " [0.30706167]\n",
      " [0.30732355]\n",
      " [0.3084369 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.31004944]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[[0.2999531 ]\n",
      "  [0.30190849]\n",
      "  [0.30287662]\n",
      "  [0.30378184]\n",
      "  [0.30591252]\n",
      "  [0.30706167]\n",
      "  [0.30732355]\n",
      "  [0.3084369 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006103130872361362\n",
      "Predicción post entrenamiento : [[0.30997384]]\n",
      "PERDIDAAAA despues: 0.0006140545592643321\n",
      "loss en el callback: 3.732205732376315e-05, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "ejemplar: [[0.30190849]\n",
      " [0.30287662]\n",
      " [0.30378184]\n",
      " [0.30591252]\n",
      " [0.30706167]\n",
      " [0.30732355]\n",
      " [0.3084369 ]\n",
      " [0.31004944]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.31100038]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[[0.30190849]\n",
      "  [0.30287662]\n",
      "  [0.30378184]\n",
      "  [0.30591252]\n",
      "  [0.30706167]\n",
      "  [0.30732355]\n",
      "  [0.3084369 ]\n",
      "  [0.31004944]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001995918806642294\n",
      "Predicción post entrenamiento : [[0.31089675]]\n",
      "PERDIDAAAA despues: 0.0020051884930580854\n",
      "loss en el callback: 5.684152711182833e-05, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "ejemplar: [[0.30287662]\n",
      " [0.30378184]\n",
      " [0.30591252]\n",
      " [0.30706167]\n",
      " [0.30732355]\n",
      " [0.3084369 ]\n",
      " [0.31004944]\n",
      " [0.31100038]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.3117553]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[[0.30287662]\n",
      "  [0.30378184]\n",
      "  [0.30591252]\n",
      "  [0.30706167]\n",
      "  [0.30732355]\n",
      "  [0.3084369 ]\n",
      "  [0.31004944]\n",
      "  [0.31100038]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006217991467565298\n",
      "Predicción post entrenamiento : [[0.31232116]]\n",
      "PERDIDAAAA despues: 0.0005938990507274866\n",
      "loss en el callback: 0.0030501610599458218, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "ejemplar: [[0.30378184]\n",
      " [0.30591252]\n",
      " [0.30706167]\n",
      " [0.30732355]\n",
      " [0.3084369 ]\n",
      " [0.31004944]\n",
      " [0.31100038]\n",
      " [0.3117553 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.31322086]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[[0.30378184]\n",
      "  [0.30591252]\n",
      "  [0.30706167]\n",
      "  [0.30732355]\n",
      "  [0.3084369 ]\n",
      "  [0.31004944]\n",
      "  [0.31100038]\n",
      "  [0.3117553 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00041496873018331826\n",
      "Predicción post entrenamiento : [[0.31253102]]\n",
      "PERDIDAAAA despues: 0.000443549535702914\n",
      "loss en el callback: 0.002845624927431345, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "ejemplar: [[0.30591252]\n",
      " [0.30706167]\n",
      " [0.30732355]\n",
      " [0.3084369 ]\n",
      " [0.31004944]\n",
      " [0.31100038]\n",
      " [0.3117553 ]\n",
      " [0.31322086]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.31348842]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[[0.30591252]\n",
      "  [0.30706167]\n",
      "  [0.30732355]\n",
      "  [0.3084369 ]\n",
      "  [0.31004944]\n",
      "  [0.31100038]\n",
      "  [0.3117553 ]\n",
      "  [0.31322086]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0050760176964104176\n",
      "Predicción post entrenamiento : [[0.31435153]]\n",
      "PERDIDAAAA despues: 0.004953776951879263\n",
      "loss en el callback: 0.008082136511802673, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "ejemplar: [[0.30706167]\n",
      " [0.30732355]\n",
      " [0.3084369 ]\n",
      " [0.31004944]\n",
      " [0.31100038]\n",
      " [0.3117553 ]\n",
      " [0.31322086]\n",
      " [0.31348842]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.3150714]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[[0.30706167]\n",
      "  [0.30732355]\n",
      "  [0.3084369 ]\n",
      "  [0.31004944]\n",
      "  [0.31100038]\n",
      "  [0.3117553 ]\n",
      "  [0.31322086]\n",
      "  [0.31348842]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.065548837184906\n",
      "Predicción post entrenamiento : [[0.31777248]]\n",
      "PERDIDAAAA despues: 0.06417305022478104\n",
      "loss en el callback: 0.07571849226951599, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "ejemplar: [[0.30732355]\n",
      " [0.3084369 ]\n",
      " [0.31004944]\n",
      " [0.31100038]\n",
      " [0.3117553 ]\n",
      " [0.31322086]\n",
      " [0.31348842]\n",
      " [0.3150714 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.31845796]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[[0.30732355]\n",
      "  [0.3084369 ]\n",
      "  [0.31004944]\n",
      "  [0.31100038]\n",
      "  [0.3117553 ]\n",
      "  [0.31322086]\n",
      "  [0.31348842]\n",
      "  [0.3150714 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07718537002801895\n",
      "Predicción post entrenamiento : [[0.32135677]]\n",
      "PERDIDAAAA despues: 0.0755830630660057\n",
      "loss en el callback: 0.08828819543123245, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "ejemplar: [[0.3084369 ]\n",
      " [0.31004944]\n",
      " [0.31100038]\n",
      " [0.3117553 ]\n",
      " [0.31322086]\n",
      " [0.31348842]\n",
      " [0.3150714 ]\n",
      " [0.31845796]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.3222337]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[[0.3084369 ]\n",
      "  [0.31004944]\n",
      "  [0.31100038]\n",
      "  [0.3117553 ]\n",
      "  [0.31322086]\n",
      "  [0.31348842]\n",
      "  [0.3150714 ]\n",
      "  [0.31845796]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06368040293455124\n",
      "Predicción post entrenamiento : [[0.32411456]]\n",
      "PERDIDAAAA despues: 0.0627346783876419\n",
      "loss en el callback: 0.02743852324783802, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "ejemplar: [[0.31004944]\n",
      " [0.31100038]\n",
      " [0.3117553 ]\n",
      " [0.31322086]\n",
      " [0.31348842]\n",
      " [0.3150714 ]\n",
      " [0.31845796]\n",
      " [0.32223371]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.32503211]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[[0.31004944]\n",
      "  [0.31100038]\n",
      "  [0.3117553 ]\n",
      "  [0.31322086]\n",
      "  [0.31348842]\n",
      "  [0.3150714 ]\n",
      "  [0.31845796]\n",
      "  [0.32223371]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07914207130670547\n",
      "Predicción post entrenamiento : [[0.32768694]]\n",
      "PERDIDAAAA despues: 0.07765539735555649\n",
      "loss en el callback: 0.08547214418649673, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "ejemplar: [[0.31100038]\n",
      " [0.3117553 ]\n",
      " [0.31322086]\n",
      " [0.31348842]\n",
      " [0.3150714 ]\n",
      " [0.31845796]\n",
      " [0.32223371]\n",
      " [0.32503211]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.3285699]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[[0.31100038]\n",
      "  [0.3117553 ]\n",
      "  [0.31322086]\n",
      "  [0.31348842]\n",
      "  [0.3150714 ]\n",
      "  [0.31845796]\n",
      "  [0.32223371]\n",
      "  [0.32503211]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06558067351579666\n",
      "Predicción post entrenamiento : [[0.33074707]]\n",
      "PERDIDAAAA despues: 0.0644703209400177\n",
      "loss en el callback: 0.043198615312576294, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "ejemplar: [[0.3117553 ]\n",
      " [0.31322086]\n",
      " [0.31348842]\n",
      " [0.3150714 ]\n",
      " [0.31845796]\n",
      " [0.32223371]\n",
      " [0.32503211]\n",
      " [0.32856989]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.33180568]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[[0.3117553 ]\n",
      "  [0.31322086]\n",
      "  [0.31348842]\n",
      "  [0.3150714 ]\n",
      "  [0.31845796]\n",
      "  [0.32223371]\n",
      "  [0.32503211]\n",
      "  [0.32856989]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05615293234586716\n",
      "Predicción post entrenamiento : [[0.33378297]]\n",
      "PERDIDAAAA despues: 0.05521973967552185\n",
      "loss en el callback: 0.04228535294532776, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "ejemplar: [[0.31322086]\n",
      " [0.31348842]\n",
      " [0.3150714 ]\n",
      " [0.31845796]\n",
      " [0.32223371]\n",
      " [0.32503211]\n",
      " [0.32856989]\n",
      " [0.33180568]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.3351484]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[[0.31322086]\n",
      "  [0.31348842]\n",
      "  [0.3150714 ]\n",
      "  [0.31845796]\n",
      "  [0.32223371]\n",
      "  [0.32503211]\n",
      "  [0.32856989]\n",
      "  [0.33180568]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09463357925415039\n",
      "Predicción post entrenamiento : [[0.3377192]]\n",
      "PERDIDAAAA despues: 0.0930584967136383\n",
      "loss en el callback: 0.07681017369031906, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "ejemplar: [[0.31348842]\n",
      " [0.3150714 ]\n",
      " [0.31845796]\n",
      " [0.32223371]\n",
      " [0.32503211]\n",
      " [0.32856989]\n",
      " [0.33180568]\n",
      " [0.33514839]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.33931458]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[[0.31348842]\n",
      "  [0.3150714 ]\n",
      "  [0.31845796]\n",
      "  [0.32223371]\n",
      "  [0.32503211]\n",
      "  [0.32856989]\n",
      "  [0.33180568]\n",
      "  [0.33514839]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10397041589021683\n",
      "Predicción post entrenamiento : [[0.342106]]\n",
      "PERDIDAAAA despues: 0.10217804461717606\n",
      "loss en el callback: 0.08579203486442566, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "ejemplar: [[0.3150714 ]\n",
      " [0.31845796]\n",
      " [0.32223371]\n",
      " [0.32503211]\n",
      " [0.32856989]\n",
      " [0.33180568]\n",
      " [0.33514839]\n",
      " [0.33931458]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.34430602]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[[0.3150714 ]\n",
      "  [0.31845796]\n",
      "  [0.32223371]\n",
      "  [0.32503211]\n",
      "  [0.32856989]\n",
      "  [0.33180568]\n",
      "  [0.33514839]\n",
      "  [0.33931458]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10803642868995667\n",
      "Predicción post entrenamiento : [[0.34716508]]\n",
      "PERDIDAAAA despues: 0.10616511851549149\n",
      "loss en el callback: 0.11038095504045486, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "ejemplar: [[0.31845796]\n",
      " [0.32223371]\n",
      " [0.32503211]\n",
      " [0.32856989]\n",
      " [0.33180568]\n",
      " [0.33514839]\n",
      " [0.33931458]\n",
      " [0.34430602]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.34976998]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[[0.31845796]\n",
      "  [0.32223371]\n",
      "  [0.32503211]\n",
      "  [0.32856989]\n",
      "  [0.33180568]\n",
      "  [0.33514839]\n",
      "  [0.33931458]\n",
      "  [0.34430602]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1301819235086441\n",
      "Predicción post entrenamiento : [[0.3529031]]\n",
      "PERDIDAAAA despues: 0.12793083488941193\n",
      "loss en el callback: 0.1823314130306244, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "ejemplar: [[0.32223371]\n",
      " [0.32503211]\n",
      " [0.32856989]\n",
      " [0.33180568]\n",
      " [0.33514839]\n",
      " [0.33931458]\n",
      " [0.34430602]\n",
      " [0.34976998]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.3555568]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[[0.32223371]\n",
      "  [0.32503211]\n",
      "  [0.32856989]\n",
      "  [0.33180568]\n",
      "  [0.33514839]\n",
      "  [0.33931458]\n",
      "  [0.34430602]\n",
      "  [0.34976998]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.121406190097332\n",
      "Predicción post entrenamiento : [[0.35859004]]\n",
      "PERDIDAAAA despues: 0.11930161714553833\n",
      "loss en el callback: 0.13230106234550476, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "ejemplar: [[0.32503211]\n",
      " [0.32856989]\n",
      " [0.33180568]\n",
      " [0.33514839]\n",
      " [0.33931458]\n",
      " [0.34430602]\n",
      " [0.34976998]\n",
      " [0.35555679]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.36124352]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[[0.32503211]\n",
      "  [0.32856989]\n",
      "  [0.33180568]\n",
      "  [0.33514839]\n",
      "  [0.33931458]\n",
      "  [0.34430602]\n",
      "  [0.34976998]\n",
      "  [0.35555679]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13395161926746368\n",
      "Predicción post entrenamiento : [[0.36423418]]\n",
      "PERDIDAAAA despues: 0.13177143037319183\n",
      "loss en el callback: 0.11523399502038956, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "ejemplar: [[0.32856989]\n",
      " [0.33180568]\n",
      " [0.33514839]\n",
      " [0.33931458]\n",
      " [0.34430602]\n",
      " [0.34976998]\n",
      " [0.35555679]\n",
      " [0.36124352]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.3671851]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[[0.32856989]\n",
      "  [0.33180568]\n",
      "  [0.33514839]\n",
      "  [0.33931458]\n",
      "  [0.34430602]\n",
      "  [0.34976998]\n",
      "  [0.35555679]\n",
      "  [0.36124352]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1263113170862198\n",
      "Predicción post entrenamiento : [[0.37013537]]\n",
      "PERDIDAAAA despues: 0.12422294169664383\n",
      "loss en el callback: 0.14326226711273193, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "ejemplar: [[0.33180568]\n",
      " [0.33514839]\n",
      " [0.33931458]\n",
      " [0.34430602]\n",
      " [0.34976998]\n",
      " [0.35555679]\n",
      " [0.36124352]\n",
      " [0.36718509]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.3732995]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[[0.33180568]\n",
      "  [0.33514839]\n",
      "  [0.33931458]\n",
      "  [0.34430602]\n",
      "  [0.34976998]\n",
      "  [0.35555679]\n",
      "  [0.36124352]\n",
      "  [0.36718509]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.15879778563976288\n",
      "Predicción post entrenamiento : [[0.3765244]]\n",
      "PERDIDAAAA despues: 0.15623798966407776\n",
      "loss en el callback: 0.1407167762517929, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "ejemplar: [[0.33514839]\n",
      " [0.33931458]\n",
      " [0.34430602]\n",
      " [0.34976998]\n",
      " [0.35555679]\n",
      " [0.36124352]\n",
      " [0.36718509]\n",
      " [0.37329951]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.38006607]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[[0.33514839]\n",
      "  [0.33931458]\n",
      "  [0.34430602]\n",
      "  [0.34976998]\n",
      "  [0.35555679]\n",
      "  [0.36124352]\n",
      "  [0.36718509]\n",
      "  [0.37329951]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11865222454071045\n",
      "Predicción post entrenamiento : [[0.38278928]]\n",
      "PERDIDAAAA despues: 0.11678356677293777\n",
      "loss en el callback: 0.12540331482887268, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "ejemplar: [[0.33931458]\n",
      " [0.34430602]\n",
      " [0.34976998]\n",
      " [0.35555679]\n",
      " [0.36124352]\n",
      " [0.36718509]\n",
      " [0.37329951]\n",
      " [0.38006607]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.3867884]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[[0.33931458]\n",
      "  [0.34430602]\n",
      "  [0.34976998]\n",
      "  [0.35555679]\n",
      "  [0.36124352]\n",
      "  [0.36718509]\n",
      "  [0.37329951]\n",
      "  [0.38006607]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08080903440713882\n",
      "Predicción post entrenamiento : [[0.38892293]]\n",
      "PERDIDAAAA despues: 0.079600028693676\n",
      "loss en el callback: 0.06679563224315643, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "ejemplar: [[0.34430602]\n",
      " [0.34976998]\n",
      " [0.35555679]\n",
      " [0.36124352]\n",
      " [0.36718509]\n",
      " [0.37329951]\n",
      " [0.38006607]\n",
      " [0.3867884 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.39327958]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[[0.34430602]\n",
      "  [0.34976998]\n",
      "  [0.35555679]\n",
      "  [0.36124352]\n",
      "  [0.36718509]\n",
      "  [0.37329951]\n",
      "  [0.38006607]\n",
      "  [0.3867884 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07867477834224701\n",
      "Predicción post entrenamiento : [[0.39544806]]\n",
      "PERDIDAAAA despues: 0.07746300846338272\n",
      "loss en el callback: 0.08861199021339417, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "ejemplar: [[0.34976998]\n",
      " [0.35555679]\n",
      " [0.36124352]\n",
      " [0.36718509]\n",
      " [0.37329951]\n",
      " [0.38006607]\n",
      " [0.3867884 ]\n",
      " [0.39327958]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.4000364]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[[0.34976998]\n",
      "  [0.35555679]\n",
      "  [0.36124352]\n",
      "  [0.36718509]\n",
      "  [0.37329951]\n",
      "  [0.38006607]\n",
      "  [0.3867884 ]\n",
      "  [0.39327958]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09885703772306442\n",
      "Predicción post entrenamiento : [[0.40218282]]\n",
      "PERDIDAAAA despues: 0.0975119099020958\n",
      "loss en el callback: 0.07033643871545792, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "ejemplar: [[0.35555679]\n",
      " [0.36124352]\n",
      " [0.36718509]\n",
      " [0.37329951]\n",
      " [0.38006607]\n",
      " [0.3867884 ]\n",
      " [0.39327958]\n",
      " [0.40003639]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.4069415]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[[0.35555679]\n",
      "  [0.36124352]\n",
      "  [0.36718509]\n",
      "  [0.37329951]\n",
      "  [0.38006607]\n",
      "  [0.3867884 ]\n",
      "  [0.39327958]\n",
      "  [0.40003639]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11353950202465057\n",
      "Predicción post entrenamiento : [[0.40948722]]\n",
      "PERDIDAAAA despues: 0.11183039844036102\n",
      "loss en el callback: 0.11245033144950867, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "ejemplar: [[0.36124352]\n",
      " [0.36718509]\n",
      " [0.37329951]\n",
      " [0.38006607]\n",
      " [0.3867884 ]\n",
      " [0.39327958]\n",
      " [0.40003639]\n",
      " [0.4069415 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.41438124]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[[0.36124352]\n",
      "  [0.36718509]\n",
      "  [0.37329951]\n",
      "  [0.38006607]\n",
      "  [0.3867884 ]\n",
      "  [0.39327958]\n",
      "  [0.40003639]\n",
      "  [0.4069415 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09499148279428482\n",
      "Predicción post entrenamiento : [[0.41666424]]\n",
      "PERDIDAAAA despues: 0.0935894176363945\n",
      "loss en el callback: 0.10767653584480286, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "ejemplar: [[0.36718509]\n",
      " [0.37329951]\n",
      " [0.38006607]\n",
      " [0.3867884 ]\n",
      " [0.39327958]\n",
      " [0.40003639]\n",
      " [0.4069415 ]\n",
      " [0.41438124]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.42176098]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[[0.36718509]\n",
      "  [0.37329951]\n",
      "  [0.38006607]\n",
      "  [0.3867884 ]\n",
      "  [0.39327958]\n",
      "  [0.40003639]\n",
      "  [0.4069415 ]\n",
      "  [0.41438124]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07705086469650269\n",
      "Predicción post entrenamiento : [[0.42389944]]\n",
      "PERDIDAAAA despues: 0.07586824893951416\n",
      "loss en el callback: 0.11407638341188431, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "ejemplar: [[0.37329951]\n",
      " [0.38006607]\n",
      " [0.3867884 ]\n",
      " [0.39327958]\n",
      " [0.40003639]\n",
      " [0.4069415 ]\n",
      " [0.41438124]\n",
      " [0.42176098]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.42918393]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[[0.37329951]\n",
      "  [0.38006607]\n",
      "  [0.3867884 ]\n",
      "  [0.39327958]\n",
      "  [0.40003639]\n",
      "  [0.4069415 ]\n",
      "  [0.41438124]\n",
      "  [0.42176098]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0949423685669899\n",
      "Predicción post entrenamiento : [[0.43161753]]\n",
      "PERDIDAAAA despues: 0.09344857186079025\n",
      "loss en el callback: 0.15277715027332306, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "ejemplar: [[0.38006607]\n",
      " [0.3867884 ]\n",
      " [0.39327958]\n",
      " [0.40003639]\n",
      " [0.4069415 ]\n",
      " [0.41438124]\n",
      " [0.42176098]\n",
      " [0.42918393]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.4370921]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[[0.38006607]\n",
      "  [0.3867884 ]\n",
      "  [0.39327958]\n",
      "  [0.40003639]\n",
      "  [0.4069415 ]\n",
      "  [0.41438124]\n",
      "  [0.42176098]\n",
      "  [0.42918393]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0808456763625145\n",
      "Predicción post entrenamiento : [[0.43873692]]\n",
      "PERDIDAAAA despues: 0.07991302013397217\n",
      "loss en el callback: 0.03807015344500542, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "ejemplar: [[0.3867884 ]\n",
      " [0.39327958]\n",
      " [0.40003639]\n",
      " [0.4069415 ]\n",
      " [0.41438124]\n",
      " [0.42176098]\n",
      " [0.42918393]\n",
      " [0.4370921 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.44427693]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[[0.3867884 ]\n",
      "  [0.39327958]\n",
      "  [0.40003639]\n",
      "  [0.4069415 ]\n",
      "  [0.41438124]\n",
      "  [0.42176098]\n",
      "  [0.42918393]\n",
      "  [0.4370921 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07531554251909256\n",
      "Predicción post entrenamiento : [[0.44617078]]\n",
      "PERDIDAAAA despues: 0.07427964359521866\n",
      "loss en el callback: 0.06234707310795784, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "ejemplar: [[0.39327958]\n",
      " [0.40003639]\n",
      " [0.4069415 ]\n",
      " [0.41438124]\n",
      " [0.42176098]\n",
      " [0.42918393]\n",
      " [0.4370921 ]\n",
      " [0.44427693]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.45181656]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[[0.39327958]\n",
      "  [0.40003639]\n",
      "  [0.4069415 ]\n",
      "  [0.41438124]\n",
      "  [0.42176098]\n",
      "  [0.42918393]\n",
      "  [0.4370921 ]\n",
      "  [0.44427693]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.049435414373874664\n",
      "Predicción post entrenamiento : [[0.4530371]]\n",
      "PERDIDAAAA despues: 0.04889414831995964\n",
      "loss en el callback: 0.022791270166635513, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "ejemplar: [[0.40003639]\n",
      " [0.4069415 ]\n",
      " [0.41438124]\n",
      " [0.42176098]\n",
      " [0.42918393]\n",
      " [0.4370921 ]\n",
      " [0.44427693]\n",
      " [0.45181656]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.45888016]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[[0.40003639]\n",
      "  [0.4069415 ]\n",
      "  [0.41438124]\n",
      "  [0.42176098]\n",
      "  [0.42918393]\n",
      "  [0.4370921 ]\n",
      "  [0.44427693]\n",
      "  [0.45181656]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05744951218366623\n",
      "Predicción post entrenamiento : [[0.46052524]]\n",
      "PERDIDAAAA despues: 0.05666361004114151\n",
      "loss en el callback: 0.05939207226037979, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "ejemplar: [[0.4069415 ]\n",
      " [0.41438124]\n",
      " [0.42176098]\n",
      " [0.42918393]\n",
      " [0.4370921 ]\n",
      " [0.44427693]\n",
      " [0.45181656]\n",
      " [0.45888016]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.46653518]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[[0.4069415 ]\n",
      "  [0.41438124]\n",
      "  [0.42176098]\n",
      "  [0.42918393]\n",
      "  [0.4370921 ]\n",
      "  [0.44427693]\n",
      "  [0.45181656]\n",
      "  [0.45888016]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0647718608379364\n",
      "Predicción post entrenamiento : [[0.46854663]]\n",
      "PERDIDAAAA despues: 0.06375206261873245\n",
      "loss en el callback: 0.11205043643712997, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "ejemplar: [[0.41438124]\n",
      " [0.42176098]\n",
      " [0.42918393]\n",
      " [0.4370921 ]\n",
      " [0.44427693]\n",
      " [0.45181656]\n",
      " [0.45888016]\n",
      " [0.46653518]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.47471157]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[[0.41438124]\n",
      "  [0.42176098]\n",
      "  [0.42918393]\n",
      "  [0.4370921 ]\n",
      "  [0.44427693]\n",
      "  [0.45181656]\n",
      "  [0.45888016]\n",
      "  [0.46653518]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0614427849650383\n",
      "Predicción post entrenamiento : [[0.4763432]]\n",
      "PERDIDAAAA despues: 0.060636553913354874\n",
      "loss en el callback: 0.05887361615896225, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "ejemplar: [[0.42176098]\n",
      " [0.42918393]\n",
      " [0.4370921 ]\n",
      " [0.44427693]\n",
      " [0.45181656]\n",
      " [0.45888016]\n",
      " [0.46653518]\n",
      " [0.47471157]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.48254308]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[[0.42176098]\n",
      "  [0.42918393]\n",
      "  [0.4370921 ]\n",
      "  [0.44427693]\n",
      "  [0.45181656]\n",
      "  [0.45888016]\n",
      "  [0.46653518]\n",
      "  [0.47471157]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07494068145751953\n",
      "Predicción post entrenamiento : [[0.48456115]]\n",
      "PERDIDAAAA despues: 0.07383985072374344\n",
      "loss en el callback: 0.08707857877016068, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "ejemplar: [[0.42918393]\n",
      " [0.4370921 ]\n",
      " [0.44427693]\n",
      " [0.45181656]\n",
      " [0.45888016]\n",
      " [0.46653518]\n",
      " [0.47471157]\n",
      " [0.48254308]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.4908201]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[[0.42918393]\n",
      "  [0.4370921 ]\n",
      "  [0.44427693]\n",
      "  [0.45181656]\n",
      "  [0.45888016]\n",
      "  [0.46653518]\n",
      "  [0.47471157]\n",
      "  [0.48254308]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11341141909360886\n",
      "Predicción post entrenamiento : [[0.4928435]]\n",
      "PERDIDAAAA despues: 0.11205269396305084\n",
      "loss en el callback: 0.07085336744785309, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "ejemplar: [[0.4370921 ]\n",
      " [0.44427693]\n",
      " [0.45181656]\n",
      " [0.45888016]\n",
      " [0.46653518]\n",
      " [0.47471157]\n",
      " [0.48254308]\n",
      " [0.49082011]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.4991656]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[[0.4370921 ]\n",
      "  [0.44427693]\n",
      "  [0.45181656]\n",
      "  [0.45888016]\n",
      "  [0.46653518]\n",
      "  [0.47471157]\n",
      "  [0.48254308]\n",
      "  [0.49082011]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11536660045385361\n",
      "Predicción post entrenamiento : [[0.5009827]]\n",
      "PERDIDAAAA despues: 0.11413551867008209\n",
      "loss en el callback: 0.05086567625403404, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "ejemplar: [[0.44427693]\n",
      " [0.45181656]\n",
      " [0.45888016]\n",
      " [0.46653518]\n",
      " [0.47471157]\n",
      " [0.48254308]\n",
      " [0.49082011]\n",
      " [0.49916559]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.50725806]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[[0.44427693]\n",
      "  [0.45181656]\n",
      "  [0.45888016]\n",
      "  [0.46653518]\n",
      "  [0.47471157]\n",
      "  [0.48254308]\n",
      "  [0.49082011]\n",
      "  [0.49916559]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08237344771623611\n",
      "Predicción post entrenamiento : [[0.5089632]]\n",
      "PERDIDAAAA despues: 0.08139756321907043\n",
      "loss en el callback: 0.05242973938584328, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "ejemplar: [[0.45181656]\n",
      " [0.45888016]\n",
      " [0.46653518]\n",
      " [0.47471157]\n",
      " [0.48254308]\n",
      " [0.49082011]\n",
      " [0.49916559]\n",
      " [0.50725806]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.51539785]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[[0.45181656]\n",
      "  [0.45888016]\n",
      "  [0.46653518]\n",
      "  [0.47471157]\n",
      "  [0.48254308]\n",
      "  [0.49082011]\n",
      "  [0.49916559]\n",
      "  [0.50725806]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07204224914312363\n",
      "Predicción post entrenamiento : [[0.51678467]]\n",
      "PERDIDAAAA despues: 0.07129970192909241\n",
      "loss en el callback: 0.035229869186878204, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "ejemplar: [[0.45888016]\n",
      " [0.46653518]\n",
      " [0.47471157]\n",
      " [0.48254308]\n",
      " [0.49082011]\n",
      " [0.49916559]\n",
      " [0.50725806]\n",
      " [0.51539785]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.5233224]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[[0.45888016]\n",
      "  [0.46653518]\n",
      "  [0.47471157]\n",
      "  [0.48254308]\n",
      "  [0.49082011]\n",
      "  [0.49916559]\n",
      "  [0.50725806]\n",
      "  [0.51539785]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05982770025730133\n",
      "Predicción post entrenamiento : [[0.52486134]]\n",
      "PERDIDAAAA despues: 0.05907723307609558\n",
      "loss en el callback: 0.05368301272392273, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "ejemplar: [[0.46653518]\n",
      " [0.47471157]\n",
      " [0.48254308]\n",
      " [0.49082011]\n",
      " [0.49916559]\n",
      " [0.50725806]\n",
      " [0.51539785]\n",
      " [0.5233224 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.53165936]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[[0.46653518]\n",
      "  [0.47471157]\n",
      "  [0.48254308]\n",
      "  [0.49082011]\n",
      "  [0.49916559]\n",
      "  [0.50725806]\n",
      "  [0.51539785]\n",
      "  [0.5233224 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06396866589784622\n",
      "Predicción post entrenamiento : [[0.5333043]]\n",
      "PERDIDAAAA despues: 0.06313930451869965\n",
      "loss en el callback: 0.05828222259879112, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "ejemplar: [[0.47471157]\n",
      " [0.48254308]\n",
      " [0.49082011]\n",
      " [0.49916559]\n",
      " [0.50725806]\n",
      " [0.51539785]\n",
      " [0.5233224 ]\n",
      " [0.53165936]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.54024374]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[[0.47471157]\n",
      "  [0.48254308]\n",
      "  [0.49082011]\n",
      "  [0.49916559]\n",
      "  [0.50725806]\n",
      "  [0.51539785]\n",
      "  [0.5233224 ]\n",
      "  [0.53165936]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11457237601280212\n",
      "Predicción post entrenamiento : [[0.54211986]]\n",
      "PERDIDAAAA despues: 0.11330582201480865\n",
      "loss en el callback: 0.06644970923662186, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "ejemplar: [[0.48254308]\n",
      " [0.49082011]\n",
      " [0.49916559]\n",
      " [0.50725806]\n",
      " [0.51539785]\n",
      " [0.5233224 ]\n",
      " [0.53165936]\n",
      " [0.54024374]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.54907984]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[[0.48254308]\n",
      "  [0.49082011]\n",
      "  [0.49916559]\n",
      "  [0.50725806]\n",
      "  [0.51539785]\n",
      "  [0.5233224 ]\n",
      "  [0.53165936]\n",
      "  [0.54024374]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10663475096225739\n",
      "Predicción post entrenamiento : [[0.5509502]]\n",
      "PERDIDAAAA despues: 0.1054166927933693\n",
      "loss en el callback: 0.06725800037384033, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "ejemplar: [[0.49082011]\n",
      " [0.49916559]\n",
      " [0.50725806]\n",
      " [0.51539785]\n",
      " [0.5233224 ]\n",
      " [0.53165936]\n",
      " [0.54024374]\n",
      " [0.54907984]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.5580326]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[[0.49082011]\n",
      "  [0.49916559]\n",
      "  [0.50725806]\n",
      "  [0.51539785]\n",
      "  [0.5233224 ]\n",
      "  [0.53165936]\n",
      "  [0.54024374]\n",
      "  [0.54907984]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08460140973329544\n",
      "Predicción post entrenamiento : [[0.56002545]]\n",
      "PERDIDAAAA despues: 0.08344607055187225\n",
      "loss en el callback: 0.10820240527391434, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "ejemplar: [[0.49916559]\n",
      " [0.50725806]\n",
      " [0.51539785]\n",
      " [0.5233224 ]\n",
      " [0.53165936]\n",
      " [0.54024374]\n",
      " [0.54907984]\n",
      " [0.55803257]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.5671324]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[[0.49916559]\n",
      "  [0.50725806]\n",
      "  [0.51539785]\n",
      "  [0.5233224 ]\n",
      "  [0.53165936]\n",
      "  [0.54024374]\n",
      "  [0.54907984]\n",
      "  [0.55803257]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.063078872859478\n",
      "Predicción post entrenamiento : [[0.56820685]]\n",
      "PERDIDAAAA despues: 0.06254032999277115\n",
      "loss en el callback: 0.02147679775953293, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "ejemplar: [[0.50725806]\n",
      " [0.51539785]\n",
      " [0.5233224 ]\n",
      " [0.53165936]\n",
      " [0.54024374]\n",
      " [0.54907984]\n",
      " [0.55803257]\n",
      " [0.56713241]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.57533383]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[[0.50725806]\n",
      "  [0.51539785]\n",
      "  [0.5233224 ]\n",
      "  [0.53165936]\n",
      "  [0.54024374]\n",
      "  [0.54907984]\n",
      "  [0.55803257]\n",
      "  [0.56713241]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06324092298746109\n",
      "Predicción post entrenamiento : [[0.5770517]]\n",
      "PERDIDAAAA despues: 0.0623798668384552\n",
      "loss en el callback: 0.07975339889526367, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "ejemplar: [[0.51539785]\n",
      " [0.5233224 ]\n",
      " [0.53165936]\n",
      " [0.54024374]\n",
      " [0.54907984]\n",
      " [0.55803257]\n",
      " [0.56713241]\n",
      " [0.57533383]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.5842897]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[[0.51539785]\n",
      "  [0.5233224 ]\n",
      "  [0.53165936]\n",
      "  [0.54024374]\n",
      "  [0.54907984]\n",
      "  [0.55803257]\n",
      "  [0.56713241]\n",
      "  [0.57533383]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04042704030871391\n",
      "Predicción post entrenamiento : [[0.5850638]]\n",
      "PERDIDAAAA despues: 0.04011635482311249\n",
      "loss en el callback: 0.011465586721897125, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "ejemplar: [[0.5233224 ]\n",
      " [0.53165936]\n",
      " [0.54024374]\n",
      " [0.54907984]\n",
      " [0.55803257]\n",
      " [0.56713241]\n",
      " [0.57533383]\n",
      " [0.58428973]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.592427]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[[0.5233224 ]\n",
      "  [0.53165936]\n",
      "  [0.54024374]\n",
      "  [0.54907984]\n",
      "  [0.55803257]\n",
      "  [0.56713241]\n",
      "  [0.57533383]\n",
      "  [0.58428973]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.038731012493371964\n",
      "Predicción post entrenamiento : [[0.59343994]]\n",
      "PERDIDAAAA despues: 0.03833334892988205\n",
      "loss en el callback: 0.022435201331973076, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "ejemplar: [[0.53165936]\n",
      " [0.54024374]\n",
      " [0.54907984]\n",
      " [0.55803257]\n",
      " [0.56713241]\n",
      " [0.57533383]\n",
      " [0.58428973]\n",
      " [0.59242702]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.60101473]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[[0.53165936]\n",
      "  [0.54024374]\n",
      "  [0.54907984]\n",
      "  [0.55803257]\n",
      "  [0.56713241]\n",
      "  [0.57533383]\n",
      "  [0.58428973]\n",
      "  [0.59242702]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05436267703771591\n",
      "Predicción post entrenamiento : [[0.6019438]]\n",
      "PERDIDAAAA despues: 0.05393030494451523\n",
      "loss en el callback: 0.01848352886736393, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "ejemplar: [[0.54024374]\n",
      " [0.54907984]\n",
      " [0.55803257]\n",
      " [0.56713241]\n",
      " [0.57533383]\n",
      " [0.58428973]\n",
      " [0.59242702]\n",
      " [0.60101473]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.60964084]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[[0.54024374]\n",
      "  [0.54907984]\n",
      "  [0.55803257]\n",
      "  [0.56713241]\n",
      "  [0.57533383]\n",
      "  [0.58428973]\n",
      "  [0.59242702]\n",
      "  [0.60101473]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04114202409982681\n",
      "Predicción post entrenamiento : [[0.61086243]]\n",
      "PERDIDAAAA despues: 0.040647950023412704\n",
      "loss en el callback: 0.03491862863302231, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "ejemplar: [[0.54907984]\n",
      " [0.55803257]\n",
      " [0.56713241]\n",
      " [0.57533383]\n",
      " [0.58428973]\n",
      " [0.59242702]\n",
      " [0.60101473]\n",
      " [0.60964084]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.6186198]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[[0.54907984]\n",
      "  [0.55803257]\n",
      "  [0.56713241]\n",
      "  [0.57533383]\n",
      "  [0.58428973]\n",
      "  [0.59242702]\n",
      "  [0.60101473]\n",
      "  [0.60964084]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.033350083976984024\n",
      "Predicción post entrenamiento : [[0.6201114]]\n",
      "PERDIDAAAA despues: 0.03280751407146454\n",
      "loss en el callback: 0.07335978746414185, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "ejemplar: [[0.55803257]\n",
      " [0.56713241]\n",
      " [0.57533383]\n",
      " [0.58428973]\n",
      " [0.59242702]\n",
      " [0.60101473]\n",
      " [0.60964084]\n",
      " [0.6186198 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.62785554]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[[0.55803257]\n",
      "  [0.56713241]\n",
      "  [0.57533383]\n",
      "  [0.58428973]\n",
      "  [0.59242702]\n",
      "  [0.60101473]\n",
      "  [0.60964084]\n",
      "  [0.6186198 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.030737634748220444\n",
      "Predicción post entrenamiento : [[0.6285898]]\n",
      "PERDIDAAAA despues: 0.030480707064270973\n",
      "loss en el callback: 0.012250415049493313, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "ejemplar: [[0.56713241]\n",
      " [0.57533383]\n",
      " [0.58428973]\n",
      " [0.59242702]\n",
      " [0.60101473]\n",
      " [0.60964084]\n",
      " [0.6186198 ]\n",
      " [0.62785554]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.63627756]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[[0.56713241]\n",
      "  [0.57533383]\n",
      "  [0.58428973]\n",
      "  [0.59242702]\n",
      "  [0.60101473]\n",
      "  [0.60964084]\n",
      "  [0.6186198 ]\n",
      "  [0.62785554]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.024716030806303024\n",
      "Predicción post entrenamiento : [[0.6376583]]\n",
      "PERDIDAAAA despues: 0.024283796548843384\n",
      "loss en el callback: 0.07009253650903702, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "ejemplar: [[0.57533383]\n",
      " [0.58428973]\n",
      " [0.59242702]\n",
      " [0.60101473]\n",
      " [0.60964084]\n",
      " [0.6186198 ]\n",
      " [0.62785554]\n",
      " [0.63627756]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.6452412]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[[0.57533383]\n",
      "  [0.58428973]\n",
      "  [0.59242702]\n",
      "  [0.60101473]\n",
      "  [0.60964084]\n",
      "  [0.6186198 ]\n",
      "  [0.62785554]\n",
      "  [0.63627756]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013208734802901745\n",
      "Predicción post entrenamiento : [[0.64615244]]\n",
      "PERDIDAAAA despues: 0.013000109232962132\n",
      "loss en el callback: 0.023355843499302864, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "ejemplar: [[0.58428973]\n",
      " [0.59242702]\n",
      " [0.60101473]\n",
      " [0.60964084]\n",
      " [0.6186198 ]\n",
      " [0.62785554]\n",
      " [0.63627756]\n",
      " [0.6452412 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.65387726]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[[0.58428973]\n",
      "  [0.59242702]\n",
      "  [0.60101473]\n",
      "  [0.60964084]\n",
      "  [0.6186198 ]\n",
      "  [0.62785554]\n",
      "  [0.63627756]\n",
      "  [0.6452412 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006641705054789782\n",
      "Predicción post entrenamiento : [[0.6546305]]\n",
      "PERDIDAAAA despues: 0.006519502028822899\n",
      "loss en el callback: 0.019562629982829094, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "ejemplar: [[0.59242702]\n",
      " [0.60101473]\n",
      " [0.60964084]\n",
      " [0.6186198 ]\n",
      " [0.62785554]\n",
      " [0.63627756]\n",
      " [0.6452412 ]\n",
      " [0.65387726]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.6623052]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[[0.59242702]\n",
      "  [0.60101473]\n",
      "  [0.60964084]\n",
      "  [0.6186198 ]\n",
      "  [0.62785554]\n",
      "  [0.63627756]\n",
      "  [0.6452412 ]\n",
      "  [0.65387726]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002292938996106386\n",
      "Predicción post entrenamiento : [[0.66279715]]\n",
      "PERDIDAAAA despues: 0.002246064832434058\n",
      "loss en el callback: 0.0075973523780703545, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "ejemplar: [[0.60101473]\n",
      " [0.60964084]\n",
      " [0.6186198 ]\n",
      " [0.62785554]\n",
      " [0.63627756]\n",
      " [0.6452412 ]\n",
      " [0.65387726]\n",
      " [0.66230518]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.67065144]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[[0.60101473]\n",
      "  [0.60964084]\n",
      "  [0.6186198 ]\n",
      "  [0.62785554]\n",
      "  [0.63627756]\n",
      "  [0.6452412 ]\n",
      "  [0.65387726]\n",
      "  [0.66230518]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017202298622578382\n",
      "Predicción post entrenamiento : [[0.6702436]]\n",
      "PERDIDAAAA despues: 0.0017542249988764524\n",
      "loss en el callback: 0.0035330234095454216, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "ejemplar: [[0.60964084]\n",
      " [0.6186198 ]\n",
      " [0.62785554]\n",
      " [0.63627756]\n",
      " [0.6452412 ]\n",
      " [0.65387726]\n",
      " [0.66230518]\n",
      " [0.67065144]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.67816424]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[[0.60964084]\n",
      "  [0.6186198 ]\n",
      "  [0.62785554]\n",
      "  [0.63627756]\n",
      "  [0.6452412 ]\n",
      "  [0.65387726]\n",
      "  [0.66230518]\n",
      "  [0.67065144]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003778755431994796\n",
      "Predicción post entrenamiento : [[0.67809093]]\n",
      "PERDIDAAAA despues: 0.0037877741269767284\n",
      "loss en el callback: 0.00012789410538971424, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "ejemplar: [[0.6186198 ]\n",
      " [0.62785554]\n",
      " [0.63627756]\n",
      " [0.6452412 ]\n",
      " [0.65387726]\n",
      " [0.66230518]\n",
      " [0.67065144]\n",
      " [0.67816424]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.6860583]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[[0.6186198 ]\n",
      "  [0.62785554]\n",
      "  [0.63627756]\n",
      "  [0.6452412 ]\n",
      "  [0.65387726]\n",
      "  [0.66230518]\n",
      "  [0.67065144]\n",
      "  [0.67816424]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0025090572889894247\n",
      "Predicción post entrenamiento : [[0.68677884]]\n",
      "PERDIDAAAA despues: 0.0024373901542276144\n",
      "loss en el callback: 0.018858937546610832, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "ejemplar: [[0.62785554]\n",
      " [0.63627756]\n",
      " [0.6452412 ]\n",
      " [0.65387726]\n",
      " [0.66230518]\n",
      " [0.67065144]\n",
      " [0.67816424]\n",
      " [0.68605828]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.69467145]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[[0.62785554]\n",
      "  [0.63627756]\n",
      "  [0.6452412 ]\n",
      "  [0.65387726]\n",
      "  [0.66230518]\n",
      "  [0.67065144]\n",
      "  [0.67816424]\n",
      "  [0.68605828]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007344502373598516\n",
      "Predicción post entrenamiento : [[0.69478065]]\n",
      "PERDIDAAAA despues: 0.0007403807248920202\n",
      "loss en el callback: 0.00034570458228699863, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "ejemplar: [[0.63627756]\n",
      " [0.6452412 ]\n",
      " [0.65387726]\n",
      " [0.66230518]\n",
      " [0.67065144]\n",
      " [0.67816424]\n",
      " [0.68605828]\n",
      " [0.69467145]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.7024844]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[[0.63627756]\n",
      "  [0.6452412 ]\n",
      "  [0.65387726]\n",
      "  [0.66230518]\n",
      "  [0.67065144]\n",
      "  [0.67816424]\n",
      "  [0.68605828]\n",
      "  [0.69467145]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010620440589264035\n",
      "Predicción post entrenamiento : [[0.70234895]]\n",
      "PERDIDAAAA despues: 0.0010532321175560355\n",
      "loss en el callback: 0.0005377301131375134, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "ejemplar: [[0.6452412 ]\n",
      " [0.65387726]\n",
      " [0.66230518]\n",
      " [0.67065144]\n",
      " [0.67816424]\n",
      " [0.68605828]\n",
      " [0.69467145]\n",
      " [0.70248443]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.7100494]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[[0.6452412 ]\n",
      "  [0.65387726]\n",
      "  [0.66230518]\n",
      "  [0.67065144]\n",
      "  [0.67816424]\n",
      "  [0.68605828]\n",
      "  [0.69467145]\n",
      "  [0.70248443]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00018010081839747727\n",
      "Predicción post entrenamiento : [[0.7100678]]\n",
      "PERDIDAAAA despues: 0.00018059549620375037\n",
      "loss en el callback: 9.591394700692035e-06, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "ejemplar: [[0.65387726]\n",
      " [0.66230518]\n",
      " [0.67065144]\n",
      " [0.67816424]\n",
      " [0.68605828]\n",
      " [0.69467145]\n",
      " [0.70248443]\n",
      " [0.71004939]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.71758306]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[[0.65387726]\n",
      "  [0.66230518]\n",
      "  [0.67065144]\n",
      "  [0.67816424]\n",
      "  [0.68605828]\n",
      "  [0.69467145]\n",
      "  [0.70248443]\n",
      "  [0.71004939]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003798963502049446\n",
      "Predicción post entrenamiento : [[0.716853]]\n",
      "PERDIDAAAA despues: 0.0037095036823302507\n",
      "loss en el callback: 0.014755157753825188, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "ejemplar: [[0.66230518]\n",
      " [0.67065144]\n",
      " [0.67816424]\n",
      " [0.68605828]\n",
      " [0.69467145]\n",
      " [0.70248443]\n",
      " [0.71004939]\n",
      " [0.71758306]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.72422934]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[[0.66230518]\n",
      "  [0.67065144]\n",
      "  [0.67816424]\n",
      "  [0.68605828]\n",
      "  [0.69467145]\n",
      "  [0.70248443]\n",
      "  [0.71004939]\n",
      "  [0.71758306]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002063219202682376\n",
      "Predicción post entrenamiento : [[0.72416127]]\n",
      "PERDIDAAAA despues: 0.002057040110230446\n",
      "loss en el callback: 0.0001522243401268497, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "ejemplar: [[0.67065144]\n",
      " [0.67816424]\n",
      " [0.68605828]\n",
      " [0.69467145]\n",
      " [0.70248443]\n",
      " [0.71004939]\n",
      " [0.71758306]\n",
      " [0.72422934]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.73141855]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[[0.67065144]\n",
      "  [0.67816424]\n",
      "  [0.68605828]\n",
      "  [0.69467145]\n",
      "  [0.70248443]\n",
      "  [0.71004939]\n",
      "  [0.71758306]\n",
      "  [0.72422934]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0030607469379901886\n",
      "Predicción post entrenamiento : [[0.731649]]\n",
      "PERDIDAAAA despues: 0.0030862968415021896\n",
      "loss en el callback: 0.0021637105382978916, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "ejemplar: [[0.67816424]\n",
      " [0.68605828]\n",
      " [0.69467145]\n",
      " [0.70248443]\n",
      " [0.71004939]\n",
      " [0.71758306]\n",
      " [0.72422934]\n",
      " [0.73141855]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.738771]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[[0.67816424]\n",
      "  [0.68605828]\n",
      "  [0.69467145]\n",
      "  [0.70248443]\n",
      "  [0.71004939]\n",
      "  [0.71758306]\n",
      "  [0.72422934]\n",
      "  [0.73141855]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.48030686029233e-05\n",
      "Predicción post entrenamiento : [[0.73925734]]\n",
      "PERDIDAAAA despues: 9.39963647397235e-05\n",
      "loss en el callback: 0.009477939456701279, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "ejemplar: [[0.68605828]\n",
      " [0.69467145]\n",
      " [0.70248443]\n",
      " [0.71004939]\n",
      " [0.71758306]\n",
      " [0.72422934]\n",
      " [0.73141855]\n",
      " [0.73877102]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.7464452]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[[0.68605828]\n",
      "  [0.69467145]\n",
      "  [0.70248443]\n",
      "  [0.71004939]\n",
      "  [0.71758306]\n",
      "  [0.72422934]\n",
      "  [0.73141855]\n",
      "  [0.73877102]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002040022751316428\n",
      "Predicción post entrenamiento : [[0.74534434]]\n",
      "PERDIDAAAA despues: 0.0019417924340814352\n",
      "loss en el callback: 0.02977708913385868, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "ejemplar: [[0.69467145]\n",
      " [0.70248443]\n",
      " [0.71004939]\n",
      " [0.71758306]\n",
      " [0.72422934]\n",
      " [0.73141855]\n",
      " [0.73877102]\n",
      " [0.74644518]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.75246346]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[[0.69467145]\n",
      "  [0.70248443]\n",
      "  [0.71004939]\n",
      "  [0.71758306]\n",
      "  [0.72422934]\n",
      "  [0.73141855]\n",
      "  [0.73877102]\n",
      "  [0.74644518]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00022706063464283943\n",
      "Predicción post entrenamiento : [[0.7521836]]\n",
      "PERDIDAAAA despues: 0.0002355726173846051\n",
      "loss en el callback: 0.0021310686133801937, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "ejemplar: [[0.70248443]\n",
      " [0.71004939]\n",
      " [0.71758306]\n",
      " [0.72422934]\n",
      " [0.73141855]\n",
      " [0.73877102]\n",
      " [0.74644518]\n",
      " [0.75246346]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.7589853]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[[0.70248443]\n",
      "  [0.71004939]\n",
      "  [0.71758306]\n",
      "  [0.72422934]\n",
      "  [0.73141855]\n",
      "  [0.73877102]\n",
      "  [0.74644518]\n",
      "  [0.75246346]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.4834765352134127e-05\n",
      "Predicción post entrenamiento : [[0.7576727]]\n",
      "PERDIDAAAA despues: 6.446717179642292e-06\n",
      "loss en el callback: 0.039456069469451904, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "ejemplar: [[0.71004939]\n",
      " [0.71758306]\n",
      " [0.72422934]\n",
      " [0.73141855]\n",
      " [0.73877102]\n",
      " [0.74644518]\n",
      " [0.75246346]\n",
      " [0.75898528]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.76432014]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[[0.71004939]\n",
      "  [0.71758306]\n",
      "  [0.72422934]\n",
      "  [0.73141855]\n",
      "  [0.73877102]\n",
      "  [0.74644518]\n",
      "  [0.75246346]\n",
      "  [0.75898528]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003709517768584192\n",
      "Predicción post entrenamiento : [[0.76440173]]\n",
      "PERDIDAAAA despues: 0.00037410162622109056\n",
      "loss en el callback: 0.0002268415264552459, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "ejemplar: [[0.71758306]\n",
      " [0.72422934]\n",
      " [0.73141855]\n",
      " [0.73877102]\n",
      " [0.74644518]\n",
      " [0.75246346]\n",
      " [0.75898528]\n",
      " [0.76432014]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.7709213]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[[0.71758306]\n",
      "  [0.72422934]\n",
      "  [0.73141855]\n",
      "  [0.73877102]\n",
      "  [0.74644518]\n",
      "  [0.75246346]\n",
      "  [0.75898528]\n",
      "  [0.76432014]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003567271342035383\n",
      "Predicción post entrenamiento : [[0.770825]]\n",
      "PERDIDAAAA despues: 0.0003531001857481897\n",
      "loss en el callback: 0.00026412884471938014, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "ejemplar: [[0.72422934]\n",
      " [0.73141855]\n",
      " [0.73877102]\n",
      " [0.74644518]\n",
      " [0.75246346]\n",
      " [0.75898528]\n",
      " [0.76432014]\n",
      " [0.77092129]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.77717805]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[[0.72422934]\n",
      "  [0.73141855]\n",
      "  [0.73877102]\n",
      "  [0.74644518]\n",
      "  [0.75246346]\n",
      "  [0.75898528]\n",
      "  [0.76432014]\n",
      "  [0.77092129]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004539479501545429\n",
      "Predicción post entrenamiento : [[0.77710915]]\n",
      "PERDIDAAAA despues: 0.004530199337750673\n",
      "loss en el callback: 0.000162470547365956, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "ejemplar: [[0.73141855]\n",
      " [0.73877102]\n",
      " [0.74644518]\n",
      " [0.75246346]\n",
      " [0.75898528]\n",
      " [0.76432014]\n",
      " [0.77092129]\n",
      " [0.77717805]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.7835038]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[[0.73141855]\n",
      "  [0.73877102]\n",
      "  [0.74644518]\n",
      "  [0.75246346]\n",
      "  [0.75898528]\n",
      "  [0.76432014]\n",
      "  [0.77092129]\n",
      "  [0.77717805]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00866271834820509\n",
      "Predicción post entrenamiento : [[0.7829554]]\n",
      "PERDIDAAAA despues: 0.008560942485928535\n",
      "loss en el callback: 0.009327322244644165, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "ejemplar: [[0.73877102]\n",
      " [0.74644518]\n",
      " [0.75246346]\n",
      " [0.75898528]\n",
      " [0.76432014]\n",
      " [0.77092129]\n",
      " [0.77717805]\n",
      " [0.78350377]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.78920263]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[[0.73877102]\n",
      "  [0.74644518]\n",
      "  [0.75246346]\n",
      "  [0.75898528]\n",
      "  [0.76432014]\n",
      "  [0.77092129]\n",
      "  [0.77717805]\n",
      "  [0.78350377]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012140946928411722\n",
      "Predicción post entrenamiento : [[0.78869253]]\n",
      "PERDIDAAAA despues: 0.0011788074625656009\n",
      "loss en el callback: 0.007353632245212793, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "ejemplar: [[0.74644518]\n",
      " [0.75246346]\n",
      " [0.75898528]\n",
      " [0.76432014]\n",
      " [0.77092129]\n",
      " [0.77717805]\n",
      " [0.78350377]\n",
      " [0.78920263]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.7946921]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[[0.74644518]\n",
      "  [0.75246346]\n",
      "  [0.75898528]\n",
      "  [0.76432014]\n",
      "  [0.77092129]\n",
      "  [0.77717805]\n",
      "  [0.78350377]\n",
      "  [0.78920263]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005255003925412893\n",
      "Predicción post entrenamiento : [[0.79538023]]\n",
      "PERDIDAAAA despues: 0.005355245433747768\n",
      "loss en el callback: 0.029971346259117126, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "ejemplar: [[0.75246346]\n",
      " [0.75898528]\n",
      " [0.76432014]\n",
      " [0.77092129]\n",
      " [0.77717805]\n",
      " [0.78350377]\n",
      " [0.78920263]\n",
      " [0.7946921 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.80098164]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[[0.75246346]\n",
      "  [0.75898528]\n",
      "  [0.76432014]\n",
      "  [0.77092129]\n",
      "  [0.77717805]\n",
      "  [0.78350377]\n",
      "  [0.78920263]\n",
      "  [0.7946921 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0022587887942790985\n",
      "Predicción post entrenamiento : [[0.79941154]]\n",
      "PERDIDAAAA despues: 0.002410497982054949\n",
      "loss en el callback: 0.05101166293025017, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "ejemplar: [[0.75898528]\n",
      " [0.76432014]\n",
      " [0.77092129]\n",
      " [0.77717805]\n",
      " [0.78350377]\n",
      " [0.78920263]\n",
      " [0.7946921 ]\n",
      " [0.80098164]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.80503505]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[[0.75898528]\n",
      "  [0.76432014]\n",
      "  [0.77092129]\n",
      "  [0.77717805]\n",
      "  [0.78350377]\n",
      "  [0.78920263]\n",
      "  [0.7946921 ]\n",
      "  [0.80098164]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010085768066346645\n",
      "Predicción post entrenamiento : [[0.80607194]]\n",
      "PERDIDAAAA despues: 0.009878579527139664\n",
      "loss en el callback: 0.04105840250849724, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "ejemplar: [[0.76432014]\n",
      " [0.77092129]\n",
      " [0.77717805]\n",
      " [0.78350377]\n",
      " [0.78920263]\n",
      " [0.7946921 ]\n",
      " [0.80098164]\n",
      " [0.80503505]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.8115599]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[[0.76432014]\n",
      "  [0.77092129]\n",
      "  [0.77717805]\n",
      "  [0.78350377]\n",
      "  [0.78920263]\n",
      "  [0.7946921 ]\n",
      "  [0.80098164]\n",
      "  [0.80503505]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004992312751710415\n",
      "Predicción post entrenamiento : [[0.81256145]]\n",
      "PERDIDAAAA despues: 0.004851785954087973\n",
      "loss en el callback: 0.044268906116485596, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "ejemplar: [[0.77092129]\n",
      " [0.77717805]\n",
      " [0.78350377]\n",
      " [0.78920263]\n",
      " [0.7946921 ]\n",
      " [0.80098164]\n",
      " [0.80503505]\n",
      " [0.81155992]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.81822985]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[[0.77092129]\n",
      "  [0.77717805]\n",
      "  [0.78350377]\n",
      "  [0.78920263]\n",
      "  [0.7946921 ]\n",
      "  [0.80098164]\n",
      "  [0.80503505]\n",
      "  [0.81155992]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008020604029297829\n",
      "Predicción post entrenamiento : [[0.81903285]]\n",
      "PERDIDAAAA despues: 0.007877420634031296\n",
      "loss en el callback: 0.02327149733901024, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "ejemplar: [[0.77717805]\n",
      " [0.78350377]\n",
      " [0.78920263]\n",
      " [0.7946921 ]\n",
      " [0.80098164]\n",
      " [0.80503505]\n",
      " [0.81155992]\n",
      " [0.81822985]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.82451296]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[[0.77717805]\n",
      "  [0.78350377]\n",
      "  [0.78920263]\n",
      "  [0.7946921 ]\n",
      "  [0.80098164]\n",
      "  [0.80503505]\n",
      "  [0.81155992]\n",
      "  [0.81822985]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0042334189638495445\n",
      "Predicción post entrenamiento : [[0.82530004]]\n",
      "PERDIDAAAA despues: 0.004131616093218327\n",
      "loss en el callback: 0.024391399696469307, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "ejemplar: [[0.78350377]\n",
      " [0.78920263]\n",
      " [0.7946921 ]\n",
      " [0.80098164]\n",
      " [0.80503505]\n",
      " [0.81155992]\n",
      " [0.81822985]\n",
      " [0.82451296]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.83066183]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[[0.78350377]\n",
      "  [0.78920263]\n",
      "  [0.7946921 ]\n",
      "  [0.80098164]\n",
      "  [0.80503505]\n",
      "  [0.81155992]\n",
      "  [0.81822985]\n",
      "  [0.82451296]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001953008002601564\n",
      "Predicción post entrenamiento : [[0.8299102]]\n",
      "PERDIDAAAA despues: 0.002020004903897643\n",
      "loss en el callback: 0.014477969147264957, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "ejemplar: [[0.78920263]\n",
      " [0.7946921 ]\n",
      " [0.80098164]\n",
      " [0.80503505]\n",
      " [0.81155992]\n",
      " [0.81822985]\n",
      " [0.82451296]\n",
      " [0.83066183]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.83512074]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[[0.78920263]\n",
      "  [0.7946921 ]\n",
      "  [0.80098164]\n",
      "  [0.80503505]\n",
      "  [0.81155992]\n",
      "  [0.81822985]\n",
      "  [0.82451296]\n",
      "  [0.83066183]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006098235957324505\n",
      "Predicción post entrenamiento : [[0.835303]]\n",
      "PERDIDAAAA despues: 0.00606980174779892\n",
      "loss en el callback: 0.001088248216547072, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "ejemplar: [[0.7946921 ]\n",
      " [0.80098164]\n",
      " [0.80503505]\n",
      " [0.81155992]\n",
      " [0.81822985]\n",
      " [0.82451296]\n",
      " [0.83066183]\n",
      " [0.83512074]]\n",
      "ejemplar: (8, 1)\n",
      "y: 1.0\n",
      "Predicción : [[0.8405385]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[[0.7946921 ]\n",
      "  [0.80098164]\n",
      "  [0.80503505]\n",
      "  [0.81155992]\n",
      "  [0.81822985]\n",
      "  [0.82451296]\n",
      "  [0.83066183]\n",
      "  [0.83512074]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02542796917259693\n",
      "Predicción post entrenamiento : [[0.8411309]]\n",
      "PERDIDAAAA despues: 0.025239387527108192\n",
      "loss en el callback: 0.011808753944933414, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "ejemplar: [[0.80098164]\n",
      " [0.80503505]\n",
      " [0.81155992]\n",
      " [0.81822985]\n",
      " [0.82451296]\n",
      " [0.83066183]\n",
      " [0.83512074]\n",
      " [0.8405385 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.84646165]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[[0.80098164]\n",
      "  [0.80503505]\n",
      "  [0.81155992]\n",
      "  [0.81822985]\n",
      "  [0.82451296]\n",
      "  [0.83066183]\n",
      "  [0.83512074]\n",
      "  [0.8405385 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015398923307657242\n",
      "Predicción post entrenamiento : [[0.8475625]]\n",
      "PERDIDAAAA despues: 0.015126924030482769\n",
      "loss en el callback: 0.05513413995504379, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "ejemplar: [[0.80503505]\n",
      " [0.81155992]\n",
      " [0.81822985]\n",
      " [0.82451296]\n",
      " [0.83066183]\n",
      " [0.83512074]\n",
      " [0.8405385 ]\n",
      " [0.84646165]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.85276294]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[[0.80503505]\n",
      "  [0.81155992]\n",
      "  [0.81822985]\n",
      "  [0.82451296]\n",
      "  [0.83066183]\n",
      "  [0.83512074]\n",
      "  [0.8405385 ]\n",
      "  [0.84646165]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012988692615181208\n",
      "Predicción post entrenamiento : [[0.8533615]]\n",
      "PERDIDAAAA despues: 0.0012560843024402857\n",
      "loss en el callback: 0.017634885385632515, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "ejemplar: [[0.81155992]\n",
      " [0.81822985]\n",
      " [0.82451296]\n",
      " [0.83066183]\n",
      " [0.83512074]\n",
      " [0.8405385 ]\n",
      " [0.84646165]\n",
      " [0.85276294]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.8590764]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[[0.81155992]\n",
      "  [0.81822985]\n",
      "  [0.82451296]\n",
      "  [0.83066183]\n",
      "  [0.83512074]\n",
      "  [0.8405385 ]\n",
      "  [0.84646165]\n",
      "  [0.85276294]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003563759964890778\n",
      "Predicción post entrenamiento : [[0.8582093]]\n",
      "PERDIDAAAA despues: 0.00038986472645774484\n",
      "loss en el callback: 0.022763598710298538, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "ejemplar: [[0.81822985]\n",
      " [0.82451296]\n",
      " [0.83066183]\n",
      " [0.83512074]\n",
      " [0.8405385 ]\n",
      " [0.84646165]\n",
      " [0.85276294]\n",
      " [0.85907638]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.86375475]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[[0.81822985]\n",
      "  [0.82451296]\n",
      "  [0.83066183]\n",
      "  [0.83512074]\n",
      "  [0.8405385 ]\n",
      "  [0.84646165]\n",
      "  [0.85276294]\n",
      "  [0.85907638]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00022078873007558286\n",
      "Predicción post entrenamiento : [[0.8636087]]\n",
      "PERDIDAAAA despues: 0.00021647030371241271\n",
      "loss en el callback: 0.0007401049952022731, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "ejemplar: [[0.82451296]\n",
      " [0.83066183]\n",
      " [0.83512074]\n",
      " [0.8405385 ]\n",
      " [0.84646165]\n",
      " [0.85276294]\n",
      " [0.85907638]\n",
      " [0.86375475]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.8689031]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[[0.82451296]\n",
      "  [0.83066183]\n",
      "  [0.83512074]\n",
      "  [0.8405385 ]\n",
      "  [0.84646165]\n",
      "  [0.85276294]\n",
      "  [0.85907638]\n",
      "  [0.86375475]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012061947491019964\n",
      "Predicción post entrenamiento : [[0.8675233]]\n",
      "PERDIDAAAA despues: 0.001112257712520659\n",
      "loss en el callback: 0.05095968395471573, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "ejemplar: [[0.83066183]\n",
      " [0.83512074]\n",
      " [0.8405385 ]\n",
      " [0.84646165]\n",
      " [0.85276294]\n",
      " [0.85907638]\n",
      " [0.86375475]\n",
      " [0.8689031 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.87263733]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[[0.83066183]\n",
      "  [0.83512074]\n",
      "  [0.8405385 ]\n",
      "  [0.84646165]\n",
      "  [0.85276294]\n",
      "  [0.85907638]\n",
      "  [0.86375475]\n",
      "  [0.8689031 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003077365690842271\n",
      "Predicción post entrenamiento : [[0.87242967]]\n",
      "PERDIDAAAA despues: 0.0003004938771482557\n",
      "loss en el callback: 0.0015131464460864663, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "ejemplar: [[0.83512074]\n",
      " [0.8405385 ]\n",
      " [0.84646165]\n",
      " [0.85276294]\n",
      " [0.85907638]\n",
      " [0.86375475]\n",
      " [0.8689031 ]\n",
      " [0.87263733]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.87737167]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[[0.83512074]\n",
      "  [0.8405385 ]\n",
      "  [0.84646165]\n",
      "  [0.85276294]\n",
      "  [0.85907638]\n",
      "  [0.86375475]\n",
      "  [0.8689031 ]\n",
      "  [0.87263733]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.534749677986838e-06\n",
      "Predicción post entrenamiento : [[0.87746376]]\n",
      "PERDIDAAAA despues: 4.935436663799919e-06\n",
      "loss en el callback: 0.0003271449531894177, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "ejemplar: [[0.8405385 ]\n",
      " [0.84646165]\n",
      " [0.85276294]\n",
      " [0.85907638]\n",
      " [0.86375475]\n",
      " [0.8689031 ]\n",
      " [0.87263733]\n",
      " [0.87737167]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.88269883]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[[0.8405385 ]\n",
      "  [0.84646165]\n",
      "  [0.85276294]\n",
      "  [0.85907638]\n",
      "  [0.86375475]\n",
      "  [0.8689031 ]\n",
      "  [0.87263733]\n",
      "  [0.87737167]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006587771349586546\n",
      "Predicción post entrenamiento : [[0.88283205]]\n",
      "PERDIDAAAA despues: 0.0006656332989223301\n",
      "loss en el callback: 0.0007228594622574747, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "ejemplar: [[0.84646165]\n",
      " [0.85276294]\n",
      " [0.85907638]\n",
      " [0.86375475]\n",
      " [0.8689031 ]\n",
      " [0.87263733]\n",
      " [0.87737167]\n",
      " [0.88269883]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.88808095]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[[0.84646165]\n",
      "  [0.85276294]\n",
      "  [0.85907638]\n",
      "  [0.86375475]\n",
      "  [0.8689031 ]\n",
      "  [0.87263733]\n",
      "  [0.87737167]\n",
      "  [0.88269883]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014457345241680741\n",
      "Predicción post entrenamiento : [[0.8874547]]\n",
      "PERDIDAAAA despues: 0.001398501917719841\n",
      "loss en el callback: 0.012579229660332203, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "ejemplar: [[0.85276294]\n",
      " [0.85907638]\n",
      " [0.86375475]\n",
      " [0.8689031 ]\n",
      " [0.87263733]\n",
      " [0.87737167]\n",
      " [0.88269883]\n",
      " [0.88808095]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.8925286]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[[0.85276294]\n",
      "  [0.85907638]\n",
      "  [0.86375475]\n",
      "  [0.8689031 ]\n",
      "  [0.87263733]\n",
      "  [0.87737167]\n",
      "  [0.88269883]\n",
      "  [0.88808095]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0024832268245518208\n",
      "Predicción post entrenamiento : [[0.89238]]\n",
      "PERDIDAAAA despues: 0.00246843951754272\n",
      "loss en el callback: 0.0008521050331182778, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "ejemplar: [[0.85907638]\n",
      " [0.86375475]\n",
      " [0.8689031 ]\n",
      " [0.87263733]\n",
      " [0.87737167]\n",
      " [0.88269883]\n",
      " [0.88808095]\n",
      " [0.89252859]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.8971102]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[[0.85907638]\n",
      "  [0.86375475]\n",
      "  [0.8689031 ]\n",
      "  [0.87263733]\n",
      "  [0.87737167]\n",
      "  [0.88269883]\n",
      "  [0.88808095]\n",
      "  [0.89252859]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005501691717654467\n",
      "Predicción post entrenamiento : [[0.8961072]]\n",
      "PERDIDAAAA despues: 0.005353902000933886\n",
      "loss en el callback: 0.033554837107658386, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "ejemplar: [[0.86375475]\n",
      " [0.8689031 ]\n",
      " [0.87263733]\n",
      " [0.87737167]\n",
      " [0.88269883]\n",
      " [0.88808095]\n",
      " [0.89252859]\n",
      " [0.89711022]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.90042484]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[[0.86375475]\n",
      "  [0.8689031 ]\n",
      "  [0.87263733]\n",
      "  [0.87737167]\n",
      "  [0.88269883]\n",
      "  [0.88808095]\n",
      "  [0.89252859]\n",
      "  [0.89711022]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015855545178055763\n",
      "Predicción post entrenamiento : [[0.9003717]]\n",
      "PERDIDAAAA despues: 0.01584215834736824\n",
      "loss en el callback: 0.00014059770910535008, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "ejemplar: [[0.8689031 ]\n",
      " [0.87263733]\n",
      " [0.87737167]\n",
      " [0.88269883]\n",
      " [0.88808095]\n",
      " [0.89252859]\n",
      " [0.89711022]\n",
      " [0.90042484]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.9047032]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[[0.8689031 ]\n",
      "  [0.87263733]\n",
      "  [0.87737167]\n",
      "  [0.88269883]\n",
      "  [0.88808095]\n",
      "  [0.89252859]\n",
      "  [0.89711022]\n",
      "  [0.90042484]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0145229147747159\n",
      "Predicción post entrenamiento : [[0.90491116]]\n",
      "PERDIDAAAA despues: 0.014573080465197563\n",
      "loss en el callback: 0.0024860494304448366, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "ejemplar: [[0.87263733]\n",
      " [0.87737167]\n",
      " [0.88269883]\n",
      " [0.88808095]\n",
      " [0.89252859]\n",
      " [0.89711022]\n",
      " [0.90042484]\n",
      " [0.9047032 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.9091096]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[[0.87263733]\n",
      "  [0.87737167]\n",
      "  [0.88269883]\n",
      "  [0.88808095]\n",
      "  [0.89252859]\n",
      "  [0.89711022]\n",
      "  [0.90042484]\n",
      "  [0.9047032 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002436931012198329\n",
      "Predicción post entrenamiento : [[0.90772253]]\n",
      "PERDIDAAAA despues: 0.002301909727975726\n",
      "loss en el callback: 0.05931007117033005, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "ejemplar: [[0.87737167]\n",
      " [0.88269883]\n",
      " [0.88808095]\n",
      " [0.89252859]\n",
      " [0.89711022]\n",
      " [0.90042484]\n",
      " [0.9047032 ]\n",
      " [0.90910959]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.9121772]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[[0.87737167]\n",
      "  [0.88269883]\n",
      "  [0.88808095]\n",
      "  [0.89252859]\n",
      "  [0.89711022]\n",
      "  [0.90042484]\n",
      "  [0.9047032 ]\n",
      "  [0.90910959]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003347450401633978\n",
      "Predicción post entrenamiento : [[0.91200554]]\n",
      "PERDIDAAAA despues: 0.0033276162575930357\n",
      "loss en el callback: 0.0012080585584044456, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "ejemplar: [[0.88269883]\n",
      " [0.88808095]\n",
      " [0.89252859]\n",
      " [0.89711022]\n",
      " [0.90042484]\n",
      " [0.9047032 ]\n",
      " [0.90910959]\n",
      " [0.91217721]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.9164217]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[[0.88269883]\n",
      "  [0.88808095]\n",
      "  [0.89252859]\n",
      "  [0.89711022]\n",
      "  [0.90042484]\n",
      "  [0.9047032 ]\n",
      "  [0.90910959]\n",
      "  [0.91217721]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006326101720333099\n",
      "Predicción post entrenamiento : [[0.91591567]]\n",
      "PERDIDAAAA despues: 0.006245859898626804\n",
      "loss en el callback: 0.009911390952765942, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "ejemplar: [[0.88808095]\n",
      " [0.89252859]\n",
      " [0.89711022]\n",
      " [0.90042484]\n",
      " [0.9047032 ]\n",
      " [0.90910959]\n",
      " [0.91217721]\n",
      " [0.91642171]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.92007244]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[[0.88808095]\n",
      "  [0.89252859]\n",
      "  [0.89711022]\n",
      "  [0.90042484]\n",
      "  [0.9047032 ]\n",
      "  [0.90910959]\n",
      "  [0.91217721]\n",
      "  [0.91642171]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00812910683453083\n",
      "Predicción post entrenamiento : [[0.9196775]]\n",
      "PERDIDAAAA despues: 0.008058045990765095\n",
      "loss en el callback: 0.006495979614555836, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "ejemplar: [[0.89252859]\n",
      " [0.89711022]\n",
      " [0.90042484]\n",
      " [0.9047032 ]\n",
      " [0.90910959]\n",
      " [0.91217721]\n",
      " [0.91642171]\n",
      " [0.92007244]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.92349255]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[[0.89252859]\n",
      "  [0.89711022]\n",
      "  [0.90042484]\n",
      "  [0.9047032 ]\n",
      "  [0.90910959]\n",
      "  [0.91217721]\n",
      "  [0.91642171]\n",
      "  [0.92007244]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013133060419932008\n",
      "Predicción post entrenamiento : [[0.9237469]]\n",
      "PERDIDAAAA despues: 0.0013318045530468225\n",
      "loss en el callback: 0.0034734660293906927, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "ejemplar: [[0.89711022]\n",
      " [0.90042484]\n",
      " [0.9047032 ]\n",
      " [0.90910959]\n",
      " [0.91217721]\n",
      " [0.91642171]\n",
      " [0.92007244]\n",
      " [0.92349255]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.92743325]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[[0.89711022]\n",
      "  [0.90042484]\n",
      "  [0.9047032 ]\n",
      "  [0.90910959]\n",
      "  [0.91217721]\n",
      "  [0.91642171]\n",
      "  [0.92007244]\n",
      "  [0.92349255]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004581792745739222\n",
      "Predicción post entrenamiento : [[0.92745]]\n",
      "PERDIDAAAA despues: 0.00458406051620841\n",
      "loss en el callback: 1.562746547278948e-05, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "ejemplar: [[0.90042484]\n",
      " [0.9047032 ]\n",
      " [0.90910959]\n",
      " [0.91217721]\n",
      " [0.91642171]\n",
      " [0.92007244]\n",
      " [0.92349255]\n",
      " [0.92743325]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.93093836]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[[0.90042484]\n",
      "  [0.9047032 ]\n",
      "  [0.90910959]\n",
      "  [0.91217721]\n",
      "  [0.91642171]\n",
      "  [0.92007244]\n",
      "  [0.92349255]\n",
      "  [0.92743325]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008343236520886421\n",
      "Predicción post entrenamiento : [[0.93078613]]\n",
      "PERDIDAAAA despues: 0.008315449580550194\n",
      "loss en el callback: 0.0010469431290403008, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "ejemplar: [[0.9047032 ]\n",
      " [0.90910959]\n",
      " [0.91217721]\n",
      " [0.91642171]\n",
      " [0.92007244]\n",
      " [0.92349255]\n",
      " [0.92743325]\n",
      " [0.93093836]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.93441963]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[[0.9047032 ]\n",
      "  [0.90910959]\n",
      "  [0.91217721]\n",
      "  [0.91642171]\n",
      "  [0.92007244]\n",
      "  [0.92349255]\n",
      "  [0.92743325]\n",
      "  [0.93093836]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02268485352396965\n",
      "Predicción post entrenamiento : [[0.93382627]]\n",
      "PERDIDAAAA despues: 0.022506466135382652\n",
      "loss en el callback: 0.017554746940732002, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "ejemplar: [[0.90910959]\n",
      " [0.91217721]\n",
      " [0.91642171]\n",
      " [0.92007244]\n",
      " [0.92349255]\n",
      " [0.92743325]\n",
      " [0.93093836]\n",
      " [0.93441963]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.93732375]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[[0.90910959]\n",
      "  [0.91217721]\n",
      "  [0.91642171]\n",
      "  [0.92007244]\n",
      "  [0.92349255]\n",
      "  [0.92743325]\n",
      "  [0.93093836]\n",
      "  [0.93441963]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014169630594551563\n",
      "Predicción post entrenamiento : [[0.93728375]]\n",
      "PERDIDAAAA despues: 0.014160110615193844\n",
      "loss en el callback: 8.852611063048244e-05, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "ejemplar: [[0.91217721]\n",
      " [0.91642171]\n",
      " [0.92007244]\n",
      " [0.92349255]\n",
      " [0.92743325]\n",
      " [0.93093836]\n",
      " [0.93441963]\n",
      " [0.93732375]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.9405767]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[[0.91217721]\n",
      "  [0.91642171]\n",
      "  [0.92007244]\n",
      "  [0.92349255]\n",
      "  [0.92743325]\n",
      "  [0.93093836]\n",
      "  [0.93441963]\n",
      "  [0.93732375]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022323492914438248\n",
      "Predicción post entrenamiento : [[0.94007605]]\n",
      "PERDIDAAAA despues: 0.02217414788901806\n",
      "loss en el callback: 0.012022237293422222, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "ejemplar: [[0.91642171]\n",
      " [0.92007244]\n",
      " [0.92349255]\n",
      " [0.92743325]\n",
      " [0.93093836]\n",
      " [0.93441963]\n",
      " [0.93732375]\n",
      " [0.94057667]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.94352454]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[[0.91642171]\n",
      "  [0.92007244]\n",
      "  [0.92349255]\n",
      "  [0.92743325]\n",
      "  [0.93093836]\n",
      "  [0.93441963]\n",
      "  [0.93732375]\n",
      "  [0.94057667]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03347677364945412\n",
      "Predicción post entrenamiento : [[0.9422183]]\n",
      "PERDIDAAAA despues: 0.033000484108924866\n",
      "loss en el callback: 0.07276265323162079, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "ejemplar: [[0.92007244]\n",
      " [0.92349255]\n",
      " [0.92743325]\n",
      " [0.93093836]\n",
      " [0.93441963]\n",
      " [0.93732375]\n",
      " [0.94057667]\n",
      " [0.94352454]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.94547325]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[[0.92007244]\n",
      "  [0.92349255]\n",
      "  [0.92743325]\n",
      "  [0.93093836]\n",
      "  [0.93441963]\n",
      "  [0.93732375]\n",
      "  [0.94057667]\n",
      "  [0.94352454]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.023691236972808838\n",
      "Predicción post entrenamiento : [[0.94481236]]\n",
      "PERDIDAAAA despues: 0.023488223552703857\n",
      "loss en el callback: 0.020967474207282066, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "ejemplar: [[0.92349255]\n",
      " [0.92743325]\n",
      " [0.93093836]\n",
      " [0.93441963]\n",
      " [0.93732375]\n",
      " [0.94057667]\n",
      " [0.94352454]\n",
      " [0.94547325]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.94800067]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[[0.92349255]\n",
      "  [0.92743325]\n",
      "  [0.93093836]\n",
      "  [0.93441963]\n",
      "  [0.93732375]\n",
      "  [0.94057667]\n",
      "  [0.94352454]\n",
      "  [0.94547325]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03215077891945839\n",
      "Predicción post entrenamiento : [[0.947337]]\n",
      "PERDIDAAAA despues: 0.031913209706544876\n",
      "loss en el callback: 0.020362596958875656, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "ejemplar: [[0.92743325]\n",
      " [0.93093836]\n",
      " [0.93441963]\n",
      " [0.93732375]\n",
      " [0.94057667]\n",
      " [0.94352454]\n",
      " [0.94547325]\n",
      " [0.94800067]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.95048904]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[[0.92743325]\n",
      "  [0.93093836]\n",
      "  [0.93441963]\n",
      "  [0.93732375]\n",
      "  [0.94057667]\n",
      "  [0.94352454]\n",
      "  [0.94547325]\n",
      "  [0.94800067]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.033049337565898895\n",
      "Predicción post entrenamiento : [[0.9494786]]\n",
      "PERDIDAAAA despues: 0.03268297761678696\n",
      "loss en el callback: 0.046853095293045044, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "ejemplar: [[0.93093836]\n",
      " [0.93441963]\n",
      " [0.93732375]\n",
      " [0.94057667]\n",
      " [0.94352454]\n",
      " [0.94547325]\n",
      " [0.94800067]\n",
      " [0.95048904]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.9523989]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[[0.93093836]\n",
      "  [0.93441963]\n",
      "  [0.93732375]\n",
      "  [0.94057667]\n",
      "  [0.94352454]\n",
      "  [0.94547325]\n",
      "  [0.94800067]\n",
      "  [0.95048904]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.023557260632514954\n",
      "Predicción post entrenamiento : [[0.95029736]]\n",
      "PERDIDAAAA despues: 0.02291657216846943\n",
      "loss en el callback: 0.15185154974460602, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "ejemplar: [[0.93441963]\n",
      " [0.93732375]\n",
      " [0.94057667]\n",
      " [0.94352454]\n",
      " [0.94547325]\n",
      " [0.94800067]\n",
      " [0.95048904]\n",
      " [0.9523989 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.95304954]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[[0.93441963]\n",
      "  [0.93732375]\n",
      "  [0.94057667]\n",
      "  [0.94352454]\n",
      "  [0.94547325]\n",
      "  [0.94800067]\n",
      "  [0.95048904]\n",
      "  [0.9523989 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.026583882048726082\n",
      "Predicción post entrenamiento : [[0.9517607]]\n",
      "PERDIDAAAA despues: 0.026165267452597618\n",
      "loss en el callback: 0.06714779883623123, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "ejemplar: [[0.93732375]\n",
      " [0.94057667]\n",
      " [0.94352454]\n",
      " [0.94547325]\n",
      " [0.94800067]\n",
      " [0.95048904]\n",
      " [0.9523989 ]\n",
      " [0.95304954]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.9542905]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[[0.93732375]\n",
      "  [0.94057667]\n",
      "  [0.94352454]\n",
      "  [0.94547325]\n",
      "  [0.94800067]\n",
      "  [0.95048904]\n",
      "  [0.9523989 ]\n",
      "  [0.95304954]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03768259286880493\n",
      "Predicción post entrenamiento : [[0.9543424]]\n",
      "PERDIDAAAA despues: 0.03770275041460991\n",
      "loss en el callback: 0.00018612892017699778, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "ejemplar: [[0.94057667]\n",
      " [0.94352454]\n",
      " [0.94547325]\n",
      " [0.94800067]\n",
      " [0.95048904]\n",
      " [0.9523989 ]\n",
      " [0.95304954]\n",
      " [0.95429051]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.95674896]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[[0.94057667]\n",
      "  [0.94352454]\n",
      "  [0.94547325]\n",
      "  [0.94800067]\n",
      "  [0.95048904]\n",
      "  [0.9523989 ]\n",
      "  [0.95304954]\n",
      "  [0.95429051]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07363390922546387\n",
      "Predicción post entrenamiento : [[0.95550555]]\n",
      "PERDIDAAAA despues: 0.07296064496040344\n",
      "loss en el callback: 0.07756239175796509, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "ejemplar: [[0.94352454]\n",
      " [0.94547325]\n",
      " [0.94800067]\n",
      " [0.95048904]\n",
      " [0.9523989 ]\n",
      " [0.95304954]\n",
      " [0.95429051]\n",
      " [0.95674896]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.9576267]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[[0.94352454]\n",
      "  [0.94547325]\n",
      "  [0.94800067]\n",
      "  [0.95048904]\n",
      "  [0.9523989 ]\n",
      "  [0.95304954]\n",
      "  [0.95429051]\n",
      "  [0.95674896]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12421038001775742\n",
      "Predicción post entrenamiento : [[0.9558707]]\n",
      "PERDIDAAAA despues: 0.12297570705413818\n",
      "loss en el callback: 0.14351819455623627, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "ejemplar: [[0.94547325]\n",
      " [0.94800067]\n",
      " [0.95048904]\n",
      " [0.9523989 ]\n",
      " [0.95304954]\n",
      " [0.95429051]\n",
      " [0.95674896]\n",
      " [0.9576267 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9577234]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[[0.94547325]\n",
      "  [0.94800067]\n",
      "  [0.95048904]\n",
      "  [0.9523989 ]\n",
      "  [0.95304954]\n",
      "  [0.95429051]\n",
      "  [0.95674896]\n",
      "  [0.9576267 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08576978743076324\n",
      "Predicción post entrenamiento : [[0.9569527]]\n",
      "PERDIDAAAA despues: 0.08531896770000458\n",
      "loss en el callback: 0.03585044667124748, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "ejemplar: [[0.94800067]\n",
      " [0.95048904]\n",
      " [0.9523989 ]\n",
      " [0.95304954]\n",
      " [0.95429051]\n",
      " [0.95674896]\n",
      " [0.9576267 ]\n",
      " [0.95772338]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.9587621]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[[0.94800067]\n",
      "  [0.95048904]\n",
      "  [0.9523989 ]\n",
      "  [0.95304954]\n",
      "  [0.95429051]\n",
      "  [0.95674896]\n",
      "  [0.9576267 ]\n",
      "  [0.95772338]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0629492700099945\n",
      "Predicción post entrenamiento : [[0.9578809]]\n",
      "PERDIDAAAA despues: 0.06250786781311035\n",
      "loss en el callback: 0.042336247861385345, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "ejemplar: [[0.95048904]\n",
      " [0.9523989 ]\n",
      " [0.95304954]\n",
      " [0.95429051]\n",
      " [0.95674896]\n",
      " [0.9576267 ]\n",
      " [0.95772338]\n",
      " [0.95876211]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9594306]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[[0.95048904]\n",
      "  [0.9523989 ]\n",
      "  [0.95304954]\n",
      "  [0.95429051]\n",
      "  [0.95674896]\n",
      "  [0.9576267 ]\n",
      "  [0.95772338]\n",
      "  [0.95876211]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08677265793085098\n",
      "Predicción post entrenamiento : [[0.95850354]]\n",
      "PERDIDAAAA despues: 0.08622736483812332\n",
      "loss en el callback: 0.0500139556825161, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "ejemplar: [[0.9523989 ]\n",
      " [0.95304954]\n",
      " [0.95429051]\n",
      " [0.95674896]\n",
      " [0.9576267 ]\n",
      " [0.95772338]\n",
      " [0.95876211]\n",
      " [0.95943058]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.95973605]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[[0.9523989 ]\n",
      "  [0.95304954]\n",
      "  [0.95429051]\n",
      "  [0.95674896]\n",
      "  [0.9576267 ]\n",
      "  [0.95772338]\n",
      "  [0.95876211]\n",
      "  [0.95943058]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06169455125927925\n",
      "Predicción post entrenamiento : [[0.95923525]]\n",
      "PERDIDAAAA despues: 0.06144602224230766\n",
      "loss en el callback: 0.01742381975054741, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "ejemplar: [[0.95304954]\n",
      " [0.95429051]\n",
      " [0.95674896]\n",
      " [0.9576267 ]\n",
      " [0.95772338]\n",
      " [0.95876211]\n",
      " [0.95943058]\n",
      " [0.95973605]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.960254]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[[0.95304954]\n",
      "  [0.95429051]\n",
      "  [0.95674896]\n",
      "  [0.9576267 ]\n",
      "  [0.95772338]\n",
      "  [0.95876211]\n",
      "  [0.95943058]\n",
      "  [0.95973605]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08008737862110138\n",
      "Predicción post entrenamiento : [[0.9587414]]\n",
      "PERDIDAAAA despues: 0.0792335495352745\n",
      "loss en el callback: 0.11455656588077545, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "ejemplar: [[0.95429051]\n",
      " [0.95674896]\n",
      " [0.9576267 ]\n",
      " [0.95772338]\n",
      " [0.95876211]\n",
      " [0.95943058]\n",
      " [0.95973605]\n",
      " [0.96025401]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.959868]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[[0.95429051]\n",
      "  [0.95674896]\n",
      "  [0.9576267 ]\n",
      "  [0.95772338]\n",
      "  [0.95876211]\n",
      "  [0.95943058]\n",
      "  [0.95973605]\n",
      "  [0.96025401]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03910912945866585\n",
      "Predicción post entrenamiento : [[0.95869535]]\n",
      "PERDIDAAAA despues: 0.03864669427275658\n",
      "loss en el callback: 0.06870239973068237, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "ejemplar: [[0.95674896]\n",
      " [0.9576267 ]\n",
      " [0.95772338]\n",
      " [0.95876211]\n",
      " [0.95943058]\n",
      " [0.95973605]\n",
      " [0.96025401]\n",
      " [0.95986801]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.95973337]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[[0.95674896]\n",
      "  [0.9576267 ]\n",
      "  [0.95772338]\n",
      "  [0.95876211]\n",
      "  [0.95943058]\n",
      "  [0.95973605]\n",
      "  [0.96025401]\n",
      "  [0.95986801]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.023311739787459373\n",
      "Predicción post entrenamiento : [[0.9586204]]\n",
      "PERDIDAAAA despues: 0.02297312766313553\n",
      "loss en el callback: 0.06088420748710632, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "ejemplar: [[0.9576267 ]\n",
      " [0.95772338]\n",
      " [0.95876211]\n",
      " [0.95943058]\n",
      " [0.95973605]\n",
      " [0.96025401]\n",
      " [0.95986801]\n",
      " [0.95973337]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.9591591]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[[0.9576267 ]\n",
      "  [0.95772338]\n",
      "  [0.95876211]\n",
      "  [0.95943058]\n",
      "  [0.95973605]\n",
      "  [0.96025401]\n",
      "  [0.95986801]\n",
      "  [0.95973337]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.020727690309286118\n",
      "Predicción post entrenamiento : [[0.9586767]]\n",
      "PERDIDAAAA despues: 0.02058902569115162\n",
      "loss en el callback: 0.013555468991398811, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "ejemplar: [[0.95772338]\n",
      " [0.95876211]\n",
      " [0.95943058]\n",
      " [0.95973605]\n",
      " [0.96025401]\n",
      " [0.95986801]\n",
      " [0.95973337]\n",
      " [0.95915908]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.9590907]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[[0.95772338]\n",
      "  [0.95876211]\n",
      "  [0.95943058]\n",
      "  [0.95973605]\n",
      "  [0.96025401]\n",
      "  [0.95986801]\n",
      "  [0.95973337]\n",
      "  [0.95915908]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0027934194076806307\n",
      "Predicción post entrenamiento : [[0.95986646]]\n",
      "PERDIDAAAA despues: 0.002876022830605507\n",
      "loss en el callback: 0.06290103495121002, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "ejemplar: [[0.95876211]\n",
      " [0.95943058]\n",
      " [0.95973605]\n",
      " [0.96025401]\n",
      " [0.95986801]\n",
      " [0.95973337]\n",
      " [0.95915908]\n",
      " [0.95909071]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.9603449]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[[0.95876211]\n",
      "  [0.95943058]\n",
      "  [0.95973605]\n",
      "  [0.96025401]\n",
      "  [0.95986801]\n",
      "  [0.95973337]\n",
      "  [0.95915908]\n",
      "  [0.95909071]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.0880553342503845e-07\n",
      "Predicción post entrenamiento : [[0.9591883]]\n",
      "PERDIDAAAA despues: 2.675466248547309e-07\n",
      "loss en el callback: 0.05615755170583725, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "ejemplar: [[0.95943058]\n",
      " [0.95973605]\n",
      " [0.96025401]\n",
      " [0.95986801]\n",
      " [0.95973337]\n",
      " [0.95915908]\n",
      " [0.95909071]\n",
      " [0.96034491]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.95943755]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[[0.95943058]\n",
      "  [0.95973605]\n",
      "  [0.96025401]\n",
      "  [0.95986801]\n",
      "  [0.95973337]\n",
      "  [0.95915908]\n",
      "  [0.95909071]\n",
      "  [0.96034491]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.418007170490455e-05\n",
      "Predicción post entrenamiento : [[0.959615]]\n",
      "PERDIDAAAA despues: 2.2466467271442525e-05\n",
      "loss en el callback: 0.0021140321623533964, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "ejemplar: [[0.95973605]\n",
      " [0.96025401]\n",
      " [0.95986801]\n",
      " [0.95973337]\n",
      " [0.95915908]\n",
      " [0.95909071]\n",
      " [0.96034491]\n",
      " [0.95943755]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.959697]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[[0.95973605]\n",
      "  [0.96025401]\n",
      "  [0.95986801]\n",
      "  [0.95973337]\n",
      "  [0.95915908]\n",
      "  [0.95909071]\n",
      "  [0.96034491]\n",
      "  [0.95943755]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005136460065841675\n",
      "Predicción post entrenamiento : [[0.96020865]]\n",
      "PERDIDAAAA despues: 0.0052100601606070995\n",
      "loss en el callback: 0.025883132591843605, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "ejemplar: [[0.96025401]\n",
      " [0.95986801]\n",
      " [0.95973337]\n",
      " [0.95915908]\n",
      " [0.95909071]\n",
      " [0.96034491]\n",
      " [0.95943755]\n",
      " [0.95969701]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.96020144]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[[0.96025401]\n",
      "  [0.95986801]\n",
      "  [0.95973337]\n",
      "  [0.95915908]\n",
      "  [0.95909071]\n",
      "  [0.96034491]\n",
      "  [0.95943755]\n",
      "  [0.95969701]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004559516906738281\n",
      "Predicción post entrenamiento : [[0.95990926]]\n",
      "PERDIDAAAA despues: 0.004520143382251263\n",
      "loss en el callback: 0.005201519466936588, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "ejemplar: [[0.95986801]\n",
      " [0.95973337]\n",
      " [0.95915908]\n",
      " [0.95909071]\n",
      " [0.96034491]\n",
      " [0.95943755]\n",
      " [0.95969701]\n",
      " [0.96020144]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.9597418]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[[0.95986801]\n",
      "  [0.95973337]\n",
      "  [0.95915908]\n",
      "  [0.95909071]\n",
      "  [0.96034491]\n",
      "  [0.95943755]\n",
      "  [0.95969701]\n",
      "  [0.96020144]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0071401819586753845\n",
      "Predicción post entrenamiento : [[0.9600131]]\n",
      "PERDIDAAAA despues: 0.007186108734458685\n",
      "loss en el callback: 0.0058367932215332985, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "ejemplar: [[0.95973337]\n",
      " [0.95915908]\n",
      " [0.95909071]\n",
      " [0.96034491]\n",
      " [0.95943755]\n",
      " [0.95969701]\n",
      " [0.96020144]\n",
      " [0.95974177]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.95994157]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[[0.95973337]\n",
      "  [0.95915908]\n",
      "  [0.95909071]\n",
      "  [0.96034491]\n",
      "  [0.95943755]\n",
      "  [0.95969701]\n",
      "  [0.96020144]\n",
      "  [0.95974177]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011904679238796234\n",
      "Predicción post entrenamiento : [[0.959546]]\n",
      "PERDIDAAAA despues: 0.01181852351874113\n",
      "loss en el callback: 0.009834221564233303, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "ejemplar: [[0.95915908]\n",
      " [0.95909071]\n",
      " [0.96034491]\n",
      " [0.95943755]\n",
      " [0.95969701]\n",
      " [0.96020144]\n",
      " [0.95974177]\n",
      " [0.95994157]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.95951796]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[[0.95915908]\n",
      "  [0.95909071]\n",
      "  [0.96034491]\n",
      "  [0.95943755]\n",
      "  [0.95969701]\n",
      "  [0.96020144]\n",
      "  [0.95974177]\n",
      "  [0.95994157]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012237263843417168\n",
      "Predicción post entrenamiento : [[0.9582505]]\n",
      "PERDIDAAAA despues: 0.01195845752954483\n",
      "loss en el callback: 0.07592235505580902, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "ejemplar: [[0.95909071]\n",
      " [0.96034491]\n",
      " [0.95943755]\n",
      " [0.95969701]\n",
      " [0.96020144]\n",
      " [0.95974177]\n",
      " [0.95994157]\n",
      " [0.95951796]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.95840234]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[[0.95909071]\n",
      "  [0.96034491]\n",
      "  [0.95943755]\n",
      "  [0.95969701]\n",
      "  [0.96020144]\n",
      "  [0.95974177]\n",
      "  [0.95994157]\n",
      "  [0.95951796]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.6122847227961756e-05\n",
      "Predicción post entrenamiento : [[0.9589113]]\n",
      "PERDIDAAAA despues: 1.2294577572902199e-05\n",
      "loss en el callback: 0.021576212719082832, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "ejemplar: [[0.96034491]\n",
      " [0.95943755]\n",
      " [0.95969701]\n",
      " [0.96020144]\n",
      " [0.95974177]\n",
      " [0.95994157]\n",
      " [0.95951796]\n",
      " [0.95840234]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.959103]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[[0.96034491]\n",
      "  [0.95943755]\n",
      "  [0.95969701]\n",
      "  [0.96020144]\n",
      "  [0.95974177]\n",
      "  [0.95994157]\n",
      "  [0.95951796]\n",
      "  [0.95840234]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.636898226337507e-05\n",
      "Predicción post entrenamiento : [[0.95888704]]\n",
      "PERDIDAAAA despues: 8.018992230063304e-05\n",
      "loss en el callback: 0.0026474781334400177, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "ejemplar: [[0.95943755]\n",
      " [0.95969701]\n",
      " [0.96020144]\n",
      " [0.95974177]\n",
      " [0.95994157]\n",
      " [0.95951796]\n",
      " [0.95840234]\n",
      " [0.95910299]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.958717]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[[0.95943755]\n",
      "  [0.95969701]\n",
      "  [0.96020144]\n",
      "  [0.95974177]\n",
      "  [0.95994157]\n",
      "  [0.95951796]\n",
      "  [0.95840234]\n",
      "  [0.95910299]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00032386722159571946\n",
      "Predicción post entrenamiento : [[0.9587119]]\n",
      "PERDIDAAAA despues: 0.000323684886097908\n",
      "loss en el callback: 1.6303476968460018e-06, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "ejemplar: [[0.95969701]\n",
      " [0.96020144]\n",
      " [0.95974177]\n",
      " [0.95994157]\n",
      " [0.95951796]\n",
      " [0.95840234]\n",
      " [0.95910299]\n",
      " [0.95871699]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.95876527]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[[0.95969701]\n",
      "  [0.96020144]\n",
      "  [0.95974177]\n",
      "  [0.95994157]\n",
      "  [0.95951796]\n",
      "  [0.95840234]\n",
      "  [0.95910299]\n",
      "  [0.95871699]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001884029625216499\n",
      "Predicción post entrenamiento : [[0.9588799]]\n",
      "PERDIDAAAA despues: 0.0001852695713751018\n",
      "loss en el callback: 0.0009831225033849478, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "ejemplar: [[0.96020144]\n",
      " [0.95974177]\n",
      " [0.95994157]\n",
      " [0.95951796]\n",
      " [0.95840234]\n",
      " [0.95910299]\n",
      " [0.95871699]\n",
      " [0.95876527]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.95883155]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[[0.96020144]\n",
      "  [0.95974177]\n",
      "  [0.95994157]\n",
      "  [0.95951796]\n",
      "  [0.95840234]\n",
      "  [0.95910299]\n",
      "  [0.95871699]\n",
      "  [0.95876527]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014492403715848923\n",
      "Predicción post entrenamiento : [[0.9587818]]\n",
      "PERDIDAAAA despues: 0.0014530322514474392\n",
      "loss en el callback: 0.00016448399401269853, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "ejemplar: [[0.95974177]\n",
      " [0.95994157]\n",
      " [0.95951796]\n",
      " [0.95840234]\n",
      " [0.95910299]\n",
      " [0.95871699]\n",
      " [0.95876527]\n",
      " [0.95883155]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.9585407]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[[0.95974177]\n",
      "  [0.95994157]\n",
      "  [0.95951796]\n",
      "  [0.95840234]\n",
      "  [0.95910299]\n",
      "  [0.95871699]\n",
      "  [0.95876527]\n",
      "  [0.95883155]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.415441410150379e-05\n",
      "Predicción post entrenamiento : [[0.9589241]]\n",
      "PERDIDAAAA despues: 5.994483581162058e-05\n",
      "loss en el callback: 0.011704199016094208, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "ejemplar: [[0.95994157]\n",
      " [0.95951796]\n",
      " [0.95840234]\n",
      " [0.95910299]\n",
      " [0.95871699]\n",
      " [0.95876527]\n",
      " [0.95883155]\n",
      " [0.95854068]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.9587544]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[[0.95994157]\n",
      "  [0.95951796]\n",
      "  [0.95840234]\n",
      "  [0.95910299]\n",
      "  [0.95871699]\n",
      "  [0.95876527]\n",
      "  [0.95883155]\n",
      "  [0.95854068]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003966179676353931\n",
      "Predicción post entrenamiento : [[0.95848763]]\n",
      "PERDIDAAAA despues: 0.003932646941393614\n",
      "loss en el callback: 0.004944317042827606, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "ejemplar: [[0.95951796]\n",
      " [0.95840234]\n",
      " [0.95910299]\n",
      " [0.95871699]\n",
      " [0.95876527]\n",
      " [0.95883155]\n",
      " [0.95854068]\n",
      " [0.95875442]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.9582112]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[[0.95951796]\n",
      "  [0.95840234]\n",
      "  [0.95910299]\n",
      "  [0.95871699]\n",
      "  [0.95876527]\n",
      "  [0.95883155]\n",
      "  [0.95854068]\n",
      "  [0.95875442]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005893615540117025\n",
      "Predicción post entrenamiento : [[0.9569219]]\n",
      "PERDIDAAAA despues: 0.005697317887097597\n",
      "loss en el callback: 0.08608103543519974, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "ejemplar: [[0.95840234]\n",
      " [0.95910299]\n",
      " [0.95871699]\n",
      " [0.95876527]\n",
      " [0.95883155]\n",
      " [0.95854068]\n",
      " [0.95875442]\n",
      " [0.95821118]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.95671916]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[[0.95840234]\n",
      "  [0.95910299]\n",
      "  [0.95871699]\n",
      "  [0.95876527]\n",
      "  [0.95883155]\n",
      "  [0.95854068]\n",
      "  [0.95875442]\n",
      "  [0.95821118]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001570753869600594\n",
      "Predicción post entrenamiento : [[0.95632315]]\n",
      "PERDIDAAAA despues: 0.001539520570077002\n",
      "loss en el callback: 0.00947466678917408, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "ejemplar: [[0.95910299]\n",
      " [0.95871699]\n",
      " [0.95876527]\n",
      " [0.95883155]\n",
      " [0.95854068]\n",
      " [0.95875442]\n",
      " [0.95821118]\n",
      " [0.95671916]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.9564052]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[[0.95910299]\n",
      "  [0.95871699]\n",
      "  [0.95876527]\n",
      "  [0.95883155]\n",
      "  [0.95854068]\n",
      "  [0.95875442]\n",
      "  [0.95821118]\n",
      "  [0.95671916]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013400482712313533\n",
      "Predicción post entrenamiento : [[0.95656157]]\n",
      "PERDIDAAAA despues: 0.0013515191385522485\n",
      "loss en el callback: 0.0019954342860728502, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "ejemplar: [[0.95871699]\n",
      " [0.95876527]\n",
      " [0.95883155]\n",
      " [0.95854068]\n",
      " [0.95875442]\n",
      " [0.95821118]\n",
      " [0.95671916]\n",
      " [0.95640522]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.956411]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[[0.95871699]\n",
      "  [0.95876527]\n",
      "  [0.95883155]\n",
      "  [0.95854068]\n",
      "  [0.95875442]\n",
      "  [0.95821118]\n",
      "  [0.95671916]\n",
      "  [0.95640522]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.737170689215418e-05\n",
      "Predicción post entrenamiento : [[0.9563056]]\n",
      "PERDIDAAAA despues: 2.848547592293471e-05\n",
      "loss en el callback: 0.0007422274793498218, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "ejemplar: [[0.95876527]\n",
      " [0.95883155]\n",
      " [0.95854068]\n",
      " [0.95875442]\n",
      " [0.95821118]\n",
      " [0.95671916]\n",
      " [0.95640522]\n",
      " [0.956411  ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.95619684]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[[0.95876527]\n",
      "  [0.95883155]\n",
      "  [0.95854068]\n",
      "  [0.95875442]\n",
      "  [0.95821118]\n",
      "  [0.95671916]\n",
      "  [0.95640522]\n",
      "  [0.956411  ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00014478126831818372\n",
      "Predicción post entrenamiento : [[0.9566378]]\n",
      "PERDIDAAAA despues: 0.0001343641197308898\n",
      "loss en el callback: 0.019188137724995613, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "ejemplar: [[0.95883155]\n",
      " [0.95854068]\n",
      " [0.95875442]\n",
      " [0.95821118]\n",
      " [0.95671916]\n",
      " [0.95640522]\n",
      " [0.956411  ]\n",
      " [0.95619684]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.95643365]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[[0.95883155]\n",
      "  [0.95854068]\n",
      "  [0.95875442]\n",
      "  [0.95821118]\n",
      "  [0.95671916]\n",
      "  [0.95640522]\n",
      "  [0.956411  ]\n",
      "  [0.95619684]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.7813365502661327e-06\n",
      "Predicción post entrenamiento : [[0.95634973]]\n",
      "PERDIDAAAA despues: 2.0123991362197557e-06\n",
      "loss en el callback: 0.0005299601471051574, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "ejemplar: [[0.12010849]\n",
      " [0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.20287497]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.024576460942626\n",
      "Predicción post entrenamiento : [[0.1774937]]\n",
      "PERDIDAAAA despues: 0.017262687906622887\n",
      "loss en el callback: 0.024671006947755814, batch 1, lote_designado 1\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "ejemplar: [[0.01975978]\n",
      " [0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20287497]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.16114257]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.20287497]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0032398183830082417\n",
      "Predicción post entrenamiento : [[0.15184273]]\n",
      "PERDIDAAAA despues: 0.0022676223888993263\n",
      "loss en el callback: 0.003426541807129979, batch 2, lote_designado 1\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "ejemplar: [[0.        ]\n",
      " [0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20287497]\n",
      " [0.16114257]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.15569831]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.20287497]\n",
      "  [0.16114257]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.2335659650707385e-06\n",
      "Predicción post entrenamiento : [[0.15456101]]\n",
      "PERDIDAAAA despues: 1.2759943501805537e-07\n",
      "loss en el callback: 0.00011272043047938496, batch 3, lote_designado 1\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "ejemplar: [[0.01859744]\n",
      " [0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20287497]\n",
      " [0.16114257]\n",
      " [0.15569831]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.1656296]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.20287497]\n",
      "  [0.16114257]\n",
      "  [0.15569831]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 9.753563062986359e-05\n",
      "Predicción post entrenamiento : [[0.16585998]]\n",
      "PERDIDAAAA despues: 0.0001021393109112978\n",
      "loss en el callback: 9.026161933434196e-06, batch 4, lote_designado 1\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "ejemplar: [[0.05656722]\n",
      " [0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20287497]\n",
      " [0.16114257]\n",
      " [0.15569831]\n",
      " [0.1656296 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.17749456]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.20287497]\n",
      "  [0.16114257]\n",
      "  [0.15569831]\n",
      "  [0.1656296 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0027000296395272017\n",
      "Predicción post entrenamiento : [[0.17678054]]\n",
      "PERDIDAAAA despues: 0.002626335946843028\n",
      "loss en el callback: 0.00019296930986456573, batch 5, lote_designado 1\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "ejemplar: [[0.02595893]\n",
      " [0.03448276]\n",
      " [0.04223169]\n",
      " [0.20287497]\n",
      " [0.16114257]\n",
      " [0.15569831]\n",
      " [0.1656296 ]\n",
      " [0.17749456]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.18482278]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.20287497]\n",
      "  [0.16114257]\n",
      "  [0.15569831]\n",
      "  [0.1656296 ]\n",
      "  [0.17749456]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015321600949391723\n",
      "Predicción post entrenamiento : [[0.18136463]]\n",
      "PERDIDAAAA despues: 0.0012733949115499854\n",
      "loss en el callback: 0.003506043227389455, batch 6, lote_designado 1\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "ejemplar: [[0.03448276]\n",
      " [0.04223169]\n",
      " [0.20287497]\n",
      " [0.16114257]\n",
      " [0.15569831]\n",
      " [0.1656296 ]\n",
      " [0.17749456]\n",
      " [0.18482278]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.19997482]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.20287497]\n",
      "  [0.16114257]\n",
      "  [0.15569831]\n",
      "  [0.1656296 ]\n",
      "  [0.17749456]\n",
      "  [0.18482278]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0028643866535276175\n",
      "Predicción post entrenamiento : [[0.19769056]]\n",
      "PERDIDAAAA despues: 0.002625097520649433\n",
      "loss en el callback: 0.0025196406058967113, batch 7, lote_designado 1\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "ejemplar: [[0.04223169]\n",
      " [0.20287497]\n",
      " [0.16114257]\n",
      " [0.15569831]\n",
      " [0.1656296 ]\n",
      " [0.17749456]\n",
      " [0.18482278]\n",
      " [0.19997482]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.21991979]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[[0.04223169]\n",
      "  [0.20287497]\n",
      "  [0.16114257]\n",
      "  [0.15569831]\n",
      "  [0.1656296 ]\n",
      "  [0.17749456]\n",
      "  [0.18482278]\n",
      "  [0.19997482]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005698604509234428\n",
      "Predicción post entrenamiento : [[0.21763363]]\n",
      "PERDIDAAAA despues: 0.0004659380647353828\n",
      "loss en el callback: 0.0024651444982737303, batch 8, lote_designado 1\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "ejemplar: [[0.20287497]\n",
      " [0.16114257]\n",
      " [0.15569831]\n",
      " [0.1656296 ]\n",
      " [0.17749456]\n",
      " [0.18482278]\n",
      " [0.19997482]\n",
      " [0.21991979]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.24374045]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[[0.20287497]\n",
      "  [0.16114257]\n",
      "  [0.15569831]\n",
      "  [0.1656296 ]\n",
      "  [0.17749456]\n",
      "  [0.18482278]\n",
      "  [0.19997482]\n",
      "  [0.21991979]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00017449501319788396\n",
      "Predicción post entrenamiento : [[0.24342395]]\n",
      "PERDIDAAAA despues: 0.00016623345436528325\n",
      "loss en el callback: 6.636343459831551e-05, batch 9, lote_designado 1\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "ejemplar: [[0.16114257]\n",
      " [0.15569831]\n",
      " [0.1656296 ]\n",
      " [0.17749456]\n",
      " [0.18482278]\n",
      " [0.19997482]\n",
      " [0.21991979]\n",
      " [0.24374045]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.2381396]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[[0.16114257]\n",
      "  [0.15569831]\n",
      "  [0.1656296 ]\n",
      "  [0.17749456]\n",
      "  [0.18482278]\n",
      "  [0.19997482]\n",
      "  [0.21991979]\n",
      "  [0.24374045]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008816897170618176\n",
      "Predicción post entrenamiento : [[0.23580875]]\n",
      "PERDIDAAAA despues: 0.0007487012771889567\n",
      "loss en el callback: 0.003867971943691373, batch 10, lote_designado 1\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "ejemplar: [[0.15569831]\n",
      " [0.1656296 ]\n",
      " [0.17749456]\n",
      " [0.18482278]\n",
      " [0.19997482]\n",
      " [0.21991979]\n",
      " [0.24374045]\n",
      " [0.2381396 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.24054292]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[[0.15569831]\n",
      "  [0.1656296 ]\n",
      "  [0.17749456]\n",
      "  [0.18482278]\n",
      "  [0.19997482]\n",
      "  [0.21991979]\n",
      "  [0.24374045]\n",
      "  [0.2381396 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008185068727470934\n",
      "Predicción post entrenamiento : [[0.24026766]]\n",
      "PERDIDAAAA despues: 0.0008028328302316368\n",
      "loss en el callback: 8.466370491078123e-05, batch 11, lote_designado 1\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "ejemplar: [[0.1656296 ]\n",
      " [0.17749456]\n",
      " [0.18482278]\n",
      " [0.19997482]\n",
      " [0.21991979]\n",
      " [0.24374045]\n",
      " [0.2381396 ]\n",
      " [0.24054292]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.2485218]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[[0.1656296 ]\n",
      "  [0.17749456]\n",
      "  [0.18482278]\n",
      "  [0.19997482]\n",
      "  [0.21991979]\n",
      "  [0.24374045]\n",
      "  [0.2381396 ]\n",
      "  [0.24054292]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017005562549456954\n",
      "Predicción post entrenamiento : [[0.24753839]]\n",
      "PERDIDAAAA despues: 0.0016204154817387462\n",
      "loss en el callback: 0.0012101331958547235, batch 12, lote_designado 1\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "ejemplar: [[0.17749456]\n",
      " [0.18482278]\n",
      " [0.19997482]\n",
      " [0.21991979]\n",
      " [0.24374045]\n",
      " [0.2381396 ]\n",
      " [0.24054292]\n",
      " [0.2485218 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.25629508]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[[0.17749456]\n",
      "  [0.18482278]\n",
      "  [0.19997482]\n",
      "  [0.21991979]\n",
      "  [0.24374045]\n",
      "  [0.2381396 ]\n",
      "  [0.24054292]\n",
      "  [0.2485218 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0040127928368747234\n",
      "Predicción post entrenamiento : [[0.2551471]]\n",
      "PERDIDAAAA despues: 0.003868668805807829\n",
      "loss en el callback: 0.001999486004933715, batch 13, lote_designado 1\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "ejemplar: [[0.18482278]\n",
      " [0.19997482]\n",
      " [0.21991979]\n",
      " [0.24374045]\n",
      " [0.2381396 ]\n",
      " [0.24054292]\n",
      " [0.2485218 ]\n",
      " [0.25629508]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.26388255]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[[0.18482278]\n",
      "  [0.19997482]\n",
      "  [0.21991979]\n",
      "  [0.24374045]\n",
      "  [0.2381396 ]\n",
      "  [0.24054292]\n",
      "  [0.2485218 ]\n",
      "  [0.25629508]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004496990703046322\n",
      "Predicción post entrenamiento : [[0.2620297]]\n",
      "PERDIDAAAA despues: 0.004251922480762005\n",
      "loss en el callback: 0.005226180888712406, batch 14, lote_designado 1\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "ejemplar: [[0.19997482]\n",
      " [0.21991979]\n",
      " [0.24374045]\n",
      " [0.2381396 ]\n",
      " [0.24054292]\n",
      " [0.2485218 ]\n",
      " [0.25629508]\n",
      " [0.26388255]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.27161294]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[[0.19997482]\n",
      "  [0.21991979]\n",
      "  [0.24374045]\n",
      "  [0.2381396 ]\n",
      "  [0.24054292]\n",
      "  [0.2485218 ]\n",
      "  [0.25629508]\n",
      "  [0.26388255]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0032895843032747507\n",
      "Predicción post entrenamiento : [[0.27005488]]\n",
      "PERDIDAAAA despues: 0.0031132863368839025\n",
      "loss en el callback: 0.004057062324136496, batch 15, lote_designado 1\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "ejemplar: [[0.21991979]\n",
      " [0.24374045]\n",
      " [0.2381396 ]\n",
      " [0.24054292]\n",
      " [0.2485218 ]\n",
      " [0.25629508]\n",
      " [0.26388255]\n",
      " [0.27161294]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.2785729]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[[0.21991979]\n",
      "  [0.24374045]\n",
      "  [0.2381396 ]\n",
      "  [0.24054292]\n",
      "  [0.2485218 ]\n",
      "  [0.25629508]\n",
      "  [0.26388255]\n",
      "  [0.27161294]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009457139298319817\n",
      "Predicción post entrenamiento : [[0.27641192]]\n",
      "PERDIDAAAA despues: 0.00904151052236557\n",
      "loss en el callback: 0.008496289141476154, batch 16, lote_designado 1\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "ejemplar: [[0.24374045]\n",
      " [0.2381396 ]\n",
      " [0.24054292]\n",
      " [0.2485218 ]\n",
      " [0.25629508]\n",
      " [0.26388255]\n",
      " [0.27161294]\n",
      " [0.27857289]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.28237057]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[[0.24374045]\n",
      "  [0.2381396 ]\n",
      "  [0.24054292]\n",
      "  [0.2485218 ]\n",
      "  [0.25629508]\n",
      "  [0.26388255]\n",
      "  [0.27161294]\n",
      "  [0.27857289]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011501412838697433\n",
      "Predicción post entrenamiento : [[0.28001985]]\n",
      "PERDIDAAAA despues: 0.011002735234797001\n",
      "loss en el callback: 0.01177382841706276, batch 17, lote_designado 1\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "ejemplar: [[0.2381396 ]\n",
      " [0.24054292]\n",
      " [0.2485218 ]\n",
      " [0.25629508]\n",
      " [0.26388255]\n",
      " [0.27161294]\n",
      " [0.27857289]\n",
      " [0.28237057]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.28201893]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[[0.2381396 ]\n",
      "  [0.24054292]\n",
      "  [0.2485218 ]\n",
      "  [0.25629508]\n",
      "  [0.26388255]\n",
      "  [0.27161294]\n",
      "  [0.27857289]\n",
      "  [0.28237057]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017959827557206154\n",
      "Predicción post entrenamiento : [[0.28044543]]\n",
      "PERDIDAAAA despues: 0.01754055917263031\n",
      "loss en el callback: 0.008556368760764599, batch 18, lote_designado 1\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "ejemplar: [[0.24054292]\n",
      " [0.2485218 ]\n",
      " [0.25629508]\n",
      " [0.26388255]\n",
      " [0.27161294]\n",
      " [0.27857289]\n",
      " [0.28237057]\n",
      " [0.28201893]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.28489548]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[[0.24054292]\n",
      "  [0.2485218 ]\n",
      "  [0.25629508]\n",
      "  [0.26388255]\n",
      "  [0.27161294]\n",
      "  [0.27857289]\n",
      "  [0.28237057]\n",
      "  [0.28201893]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015886666253209114\n",
      "Predicción post entrenamiento : [[0.28240642]]\n",
      "PERDIDAAAA despues: 0.015265407972037792\n",
      "loss en el callback: 0.01741686835885048, batch 19, lote_designado 1\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "ejemplar: [[0.2485218 ]\n",
      " [0.25629508]\n",
      " [0.26388255]\n",
      " [0.27161294]\n",
      " [0.27857289]\n",
      " [0.28237057]\n",
      " [0.28201893]\n",
      " [0.28489548]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.28774402]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[[0.2485218 ]\n",
      "  [0.25629508]\n",
      "  [0.26388255]\n",
      "  [0.27161294]\n",
      "  [0.27857289]\n",
      "  [0.28237057]\n",
      "  [0.28201893]\n",
      "  [0.28489548]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009133709594607353\n",
      "Predicción post entrenamiento : [[0.28503156]]\n",
      "PERDIDAAAA despues: 0.008622605353593826\n",
      "loss en el callback: 0.01768638752400875, batch 20, lote_designado 1\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "ejemplar: [[0.25629508]\n",
      " [0.26388255]\n",
      " [0.27161294]\n",
      " [0.27857289]\n",
      " [0.28237057]\n",
      " [0.28201893]\n",
      " [0.28489548]\n",
      " [0.28774402]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.28994766]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[[0.25629508]\n",
      "  [0.26388255]\n",
      "  [0.27161294]\n",
      "  [0.27857289]\n",
      "  [0.28237057]\n",
      "  [0.28201893]\n",
      "  [0.28489548]\n",
      "  [0.28774402]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010810431092977524\n",
      "Predicción post entrenamiento : [[0.28963146]]\n",
      "PERDIDAAAA despues: 0.01074477843940258\n",
      "loss en el callback: 0.0005307384417392313, batch 21, lote_designado 1\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "ejemplar: [[0.26388255]\n",
      " [0.27161294]\n",
      " [0.27857289]\n",
      " [0.28237057]\n",
      " [0.28201893]\n",
      " [0.28489548]\n",
      " [0.28774402]\n",
      " [0.28994766]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.29398453]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[[0.26388255]\n",
      "  [0.27161294]\n",
      "  [0.27857289]\n",
      "  [0.28237057]\n",
      "  [0.28201893]\n",
      "  [0.28489548]\n",
      "  [0.28774402]\n",
      "  [0.28994766]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007308234344236553\n",
      "Predicción post entrenamiento : [[0.2933744]]\n",
      "PERDIDAAAA despues: 0.0006982068298384547\n",
      "loss en el callback: 0.0012163803912699223, batch 22, lote_designado 1\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "ejemplar: [[0.27161294]\n",
      " [0.27857289]\n",
      " [0.28237057]\n",
      " [0.28201893]\n",
      " [0.28489548]\n",
      " [0.28774402]\n",
      " [0.28994766]\n",
      " [0.29398453]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.29700956]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[[0.27161294]\n",
      "  [0.27857289]\n",
      "  [0.28237057]\n",
      "  [0.28201893]\n",
      "  [0.28489548]\n",
      "  [0.28774402]\n",
      "  [0.28994766]\n",
      "  [0.29398453]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.013564699154813e-05\n",
      "Predicción post entrenamiento : [[0.29620013]]\n",
      "PERDIDAAAA despues: 1.3526543625630438e-05\n",
      "loss en el callback: 0.0019987612031400204, batch 23, lote_designado 1\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "ejemplar: [[0.27857289]\n",
      " [0.28237057]\n",
      " [0.28201893]\n",
      " [0.28489548]\n",
      " [0.28774402]\n",
      " [0.28994766]\n",
      " [0.29398453]\n",
      " [0.29700956]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.29889658]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[[0.27857289]\n",
      "  [0.28237057]\n",
      "  [0.28201893]\n",
      "  [0.28489548]\n",
      "  [0.28774402]\n",
      "  [0.28994766]\n",
      "  [0.29398453]\n",
      "  [0.29700956]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003538061573635787\n",
      "Predicción post entrenamiento : [[0.29802662]]\n",
      "PERDIDAAAA despues: 0.00038729040534235537\n",
      "loss en el callback: 0.002256491919979453, batch 24, lote_designado 1\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "ejemplar: [[0.28237057]\n",
      " [0.28201893]\n",
      " [0.28489548]\n",
      " [0.28774402]\n",
      " [0.28994766]\n",
      " [0.29398453]\n",
      " [0.29700956]\n",
      " [0.29889658]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.2997911]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[[0.28237057]\n",
      "  [0.28201893]\n",
      "  [0.28489548]\n",
      "  [0.28774402]\n",
      "  [0.28994766]\n",
      "  [0.29398453]\n",
      "  [0.29700956]\n",
      "  [0.29889658]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00016585364937782288\n",
      "Predicción post entrenamiento : [[0.3006017]]\n",
      "PERDIDAAAA despues: 0.00014563239528797567\n",
      "loss en el callback: 0.003532456699758768, batch 25, lote_designado 1\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "ejemplar: [[0.28201893]\n",
      " [0.28489548]\n",
      " [0.28774402]\n",
      " [0.28994766]\n",
      " [0.29398453]\n",
      " [0.29700956]\n",
      " [0.29889658]\n",
      " [0.2997911 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.30205294]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[[0.28201893]\n",
      "  [0.28489548]\n",
      "  [0.28774402]\n",
      "  [0.28994766]\n",
      "  [0.29398453]\n",
      "  [0.29700956]\n",
      "  [0.29889658]\n",
      "  [0.2997911 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00016946010873652995\n",
      "Predicción post entrenamiento : [[0.301718]]\n",
      "PERDIDAAAA despues: 0.00016085179231595248\n",
      "loss en el callback: 0.0005128714838065207, batch 26, lote_designado 1\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "ejemplar: [[0.28489548]\n",
      " [0.28774402]\n",
      " [0.28994766]\n",
      " [0.29398453]\n",
      " [0.29700956]\n",
      " [0.29889658]\n",
      " [0.2997911 ]\n",
      " [0.30205294]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.3038134]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[[0.28489548]\n",
      "  [0.28774402]\n",
      "  [0.28994766]\n",
      "  [0.29398453]\n",
      "  [0.29700956]\n",
      "  [0.29889658]\n",
      "  [0.2997911 ]\n",
      "  [0.30205294]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000440046627772972\n",
      "Predicción post entrenamiento : [[0.3033075]]\n",
      "PERDIDAAAA despues: 0.00041907798731699586\n",
      "loss en el callback: 0.0012780434917658567, batch 27, lote_designado 1\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "ejemplar: [[0.28774402]\n",
      " [0.28994766]\n",
      " [0.29398453]\n",
      " [0.29700956]\n",
      " [0.29889658]\n",
      " [0.2997911 ]\n",
      " [0.30205294]\n",
      " [0.3038134 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.30534524]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[[0.28774402]\n",
      "  [0.28994766]\n",
      "  [0.29398453]\n",
      "  [0.29700956]\n",
      "  [0.29889658]\n",
      "  [0.2997911 ]\n",
      "  [0.30205294]\n",
      "  [0.3038134 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.420979919610545e-05\n",
      "Predicción post entrenamiento : [[0.3051627]]\n",
      "PERDIDAAAA despues: 3.210780778317712e-05\n",
      "loss en el callback: 0.00017000912339426577, batch 28, lote_designado 1\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "ejemplar: [[0.28994766]\n",
      " [0.29398453]\n",
      " [0.29700956]\n",
      " [0.29889658]\n",
      " [0.2997911 ]\n",
      " [0.30205294]\n",
      " [0.3038134 ]\n",
      " [0.30534524]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.30711225]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[[0.28994766]\n",
      "  [0.29398453]\n",
      "  [0.29700956]\n",
      "  [0.29889658]\n",
      "  [0.2997911 ]\n",
      "  [0.30205294]\n",
      "  [0.3038134 ]\n",
      "  [0.30534524]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009765736758708954\n",
      "Predicción post entrenamiento : [[0.30627066]]\n",
      "PERDIDAAAA despues: 0.0009246824192814529\n",
      "loss en el callback: 0.0035774230491369963, batch 29, lote_designado 1\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "ejemplar: [[0.29398453]\n",
      " [0.29700956]\n",
      " [0.29889658]\n",
      " [0.2997911 ]\n",
      " [0.30205294]\n",
      " [0.3038134 ]\n",
      " [0.30534524]\n",
      " [0.30711225]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.3082443]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[[0.29398453]\n",
      "  [0.29700956]\n",
      "  [0.29889658]\n",
      "  [0.2997911 ]\n",
      "  [0.30205294]\n",
      "  [0.3038134 ]\n",
      "  [0.30534524]\n",
      "  [0.30711225]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001125238137319684\n",
      "Predicción post entrenamiento : [[0.30817035]]\n",
      "PERDIDAAAA despues: 0.0011202831519767642\n",
      "loss en el callback: 4.1100742237176746e-05, batch 30, lote_designado 1\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "ejemplar: [[0.29700956]\n",
      " [0.29889658]\n",
      " [0.2997911 ]\n",
      " [0.30205294]\n",
      " [0.3038134 ]\n",
      " [0.30534524]\n",
      " [0.30711225]\n",
      " [0.30824429]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.30969602]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[[0.29700956]\n",
      "  [0.29889658]\n",
      "  [0.2997911 ]\n",
      "  [0.30205294]\n",
      "  [0.3038134 ]\n",
      "  [0.30534524]\n",
      "  [0.30711225]\n",
      "  [0.30824429]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011711049592122436\n",
      "Predicción post entrenamiento : [[0.30878043]]\n",
      "PERDIDAAAA despues: 0.0011092779459431767\n",
      "loss en el callback: 0.004643429070711136, batch 31, lote_designado 1\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "ejemplar: [[0.29889658]\n",
      " [0.2997911 ]\n",
      " [0.30205294]\n",
      " [0.3038134 ]\n",
      " [0.30534524]\n",
      " [0.30711225]\n",
      " [0.30824429]\n",
      " [0.30969602]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.31001642]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[[0.29889658]\n",
      "  [0.2997911 ]\n",
      "  [0.30205294]\n",
      "  [0.3038134 ]\n",
      "  [0.30534524]\n",
      "  [0.30711225]\n",
      "  [0.30824429]\n",
      "  [0.30969602]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000611945753917098\n",
      "Predicción post entrenamiento : [[0.30986753]]\n",
      "PERDIDAAAA despues: 0.000619334343355149\n",
      "loss en el callback: 0.00014158181147649884, batch 32, lote_designado 1\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "ejemplar: [[0.2997911 ]\n",
      " [0.30205294]\n",
      " [0.3038134 ]\n",
      " [0.30534524]\n",
      " [0.30711225]\n",
      " [0.30824429]\n",
      " [0.30969602]\n",
      " [0.31001642]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.3110343]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[[0.2997911 ]\n",
      "  [0.30205294]\n",
      "  [0.3038134 ]\n",
      "  [0.30534524]\n",
      "  [0.30711225]\n",
      "  [0.30824429]\n",
      "  [0.30969602]\n",
      "  [0.31001642]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001992889679968357\n",
      "Predicción post entrenamiento : [[0.31180343]]\n",
      "PERDIDAAAA despues: 0.001924809766933322\n",
      "loss en el callback: 0.004860616754740477, batch 33, lote_designado 1\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "ejemplar: [[0.30205294]\n",
      " [0.3038134 ]\n",
      " [0.30534524]\n",
      " [0.30711225]\n",
      " [0.30824429]\n",
      " [0.30969602]\n",
      " [0.31001642]\n",
      " [0.31103429]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.31311724]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[[0.30205294]\n",
      "  [0.3038134 ]\n",
      "  [0.30534524]\n",
      "  [0.30711225]\n",
      "  [0.30824429]\n",
      "  [0.30969602]\n",
      "  [0.31001642]\n",
      "  [0.31103429]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005557318218052387\n",
      "Predicción post entrenamiento : [[0.31300396]]\n",
      "PERDIDAAAA despues: 0.0005610855296254158\n",
      "loss en el callback: 8.700838952790946e-05, batch 34, lote_designado 1\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "ejemplar: [[0.3038134 ]\n",
      " [0.30534524]\n",
      " [0.30711225]\n",
      " [0.30824429]\n",
      " [0.30969602]\n",
      " [0.31001642]\n",
      " [0.31103429]\n",
      " [0.31311724]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.31413767]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[[0.3038134 ]\n",
      "  [0.30534524]\n",
      "  [0.30711225]\n",
      "  [0.30824429]\n",
      "  [0.30969602]\n",
      "  [0.31001642]\n",
      "  [0.31103429]\n",
      "  [0.31311724]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003784570435527712\n",
      "Predicción post entrenamiento : [[0.31396356]]\n",
      "PERDIDAAAA despues: 0.0003852614318020642\n",
      "loss en el callback: 0.00020461158419493586, batch 35, lote_designado 1\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "ejemplar: [[0.30534524]\n",
      " [0.30711225]\n",
      " [0.30824429]\n",
      " [0.30969602]\n",
      " [0.31001642]\n",
      " [0.31103429]\n",
      " [0.31311724]\n",
      " [0.31413767]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.3150009]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[[0.30534524]\n",
      "  [0.30711225]\n",
      "  [0.30824429]\n",
      "  [0.30969602]\n",
      "  [0.31001642]\n",
      "  [0.31103429]\n",
      "  [0.31311724]\n",
      "  [0.31413767]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004862789995968342\n",
      "Predicción post entrenamiento : [[0.31593508]]\n",
      "PERDIDAAAA despues: 0.004733374807983637\n",
      "loss en el callback: 0.00888843834400177, batch 36, lote_designado 1\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "ejemplar: [[0.30711225]\n",
      " [0.30824429]\n",
      " [0.30969602]\n",
      " [0.31001642]\n",
      " [0.31103429]\n",
      " [0.31311724]\n",
      " [0.31413767]\n",
      " [0.31500089]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.3169102]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[[0.30711225]\n",
      "  [0.30824429]\n",
      "  [0.30969602]\n",
      "  [0.31001642]\n",
      "  [0.31103429]\n",
      "  [0.31311724]\n",
      "  [0.31413767]\n",
      "  [0.31500089]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06461066007614136\n",
      "Predicción post entrenamiento : [[0.31944954]]\n",
      "PERDIDAAAA despues: 0.06332617998123169\n",
      "loss en el callback: 0.05566757544875145, batch 37, lote_designado 1\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "ejemplar: [[0.30824429]\n",
      " [0.30969602]\n",
      " [0.31001642]\n",
      " [0.31103429]\n",
      " [0.31311724]\n",
      " [0.31413767]\n",
      " [0.31500089]\n",
      " [0.31691021]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.32029593]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[[0.30824429]\n",
      "  [0.30969602]\n",
      "  [0.31001642]\n",
      "  [0.31103429]\n",
      "  [0.31311724]\n",
      "  [0.31413767]\n",
      "  [0.31500089]\n",
      "  [0.31691021]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07616749405860901\n",
      "Predicción post entrenamiento : [[0.32300556]]\n",
      "PERDIDAAAA despues: 0.07467920333147049\n",
      "loss en el callback: 0.08158309012651443, batch 38, lote_designado 1\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "ejemplar: [[0.30969602]\n",
      " [0.31001642]\n",
      " [0.31103429]\n",
      " [0.31311724]\n",
      " [0.31413767]\n",
      " [0.31500089]\n",
      " [0.31691021]\n",
      " [0.32029593]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.32387573]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[[0.30969602]\n",
      "  [0.31001642]\n",
      "  [0.31103429]\n",
      "  [0.31311724]\n",
      "  [0.31413767]\n",
      "  [0.31500089]\n",
      "  [0.31691021]\n",
      "  [0.32029593]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06285437196493149\n",
      "Predicción post entrenamiento : [[0.3263518]]\n",
      "PERDIDAAAA despues: 0.06161896511912346\n",
      "loss en el callback: 0.05707096308469772, batch 39, lote_designado 1\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "ejemplar: [[0.31001642]\n",
      " [0.31103429]\n",
      " [0.31311724]\n",
      " [0.31413767]\n",
      " [0.31500089]\n",
      " [0.31691021]\n",
      " [0.32029593]\n",
      " [0.32387573]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.3272044]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[[0.31001642]\n",
      "  [0.31103429]\n",
      "  [0.31311724]\n",
      "  [0.31413767]\n",
      "  [0.31500089]\n",
      "  [0.31691021]\n",
      "  [0.32029593]\n",
      "  [0.32387573]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07792456448078156\n",
      "Predicción post entrenamiento : [[0.32978722]]\n",
      "PERDIDAAAA despues: 0.07648924738168716\n",
      "loss en el callback: 0.11341724544763565, batch 40, lote_designado 1\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "ejemplar: [[0.31103429]\n",
      " [0.31311724]\n",
      " [0.31413767]\n",
      " [0.31500089]\n",
      " [0.31691021]\n",
      " [0.32029593]\n",
      " [0.32387573]\n",
      " [0.32720441]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.33094573]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[[0.31103429]\n",
      "  [0.31311724]\n",
      "  [0.31413767]\n",
      "  [0.31500089]\n",
      "  [0.31691021]\n",
      "  [0.32029593]\n",
      "  [0.32387573]\n",
      "  [0.32720441]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06436947733163834\n",
      "Predicción post entrenamiento : [[0.33328566]]\n",
      "PERDIDAAAA despues: 0.0631876140832901\n",
      "loss en el callback: 0.05728232488036156, batch 41, lote_designado 1\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "ejemplar: [[0.31311724]\n",
      " [0.31413767]\n",
      " [0.31500089]\n",
      " [0.31691021]\n",
      " [0.32029593]\n",
      " [0.32387573]\n",
      " [0.32720441]\n",
      " [0.33094573]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.3346758]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[[0.31311724]\n",
      "  [0.31413767]\n",
      "  [0.31500089]\n",
      "  [0.31691021]\n",
      "  [0.32029593]\n",
      "  [0.32387573]\n",
      "  [0.32720441]\n",
      "  [0.33094573]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05480093136429787\n",
      "Predicción post entrenamiento : [[0.33668992]]\n",
      "PERDIDAAAA despues: 0.053861990571022034\n",
      "loss en el callback: 0.04238402843475342, batch 42, lote_designado 1\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "ejemplar: [[0.31413767]\n",
      " [0.31500089]\n",
      " [0.31691021]\n",
      " [0.32029593]\n",
      " [0.32387573]\n",
      " [0.32720441]\n",
      " [0.33094573]\n",
      " [0.33467579]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.33813596]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[[0.31413767]\n",
      "  [0.31500089]\n",
      "  [0.31691021]\n",
      "  [0.32029593]\n",
      "  [0.32387573]\n",
      "  [0.32720441]\n",
      "  [0.33094573]\n",
      "  [0.33467579]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09280440211296082\n",
      "Predicción post entrenamiento : [[0.34081307]]\n",
      "PERDIDAAAA despues: 0.0911804661154747\n",
      "loss en el callback: 0.09028764069080353, batch 43, lote_designado 1\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "ejemplar: [[0.31500089]\n",
      " [0.31691021]\n",
      " [0.32029593]\n",
      " [0.32387573]\n",
      " [0.32720441]\n",
      " [0.33094573]\n",
      " [0.33467579]\n",
      " [0.33813596]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.3426404]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[[0.31500089]\n",
      "  [0.31691021]\n",
      "  [0.32029593]\n",
      "  [0.32387573]\n",
      "  [0.32720441]\n",
      "  [0.33094573]\n",
      "  [0.33467579]\n",
      "  [0.33813596]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10183669626712799\n",
      "Predicción post entrenamiento : [[0.345364]]\n",
      "PERDIDAAAA despues: 0.10010580718517303\n",
      "loss en el callback: 0.07541578263044357, batch 44, lote_designado 1\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "ejemplar: [[0.31691021]\n",
      " [0.32029593]\n",
      " [0.32387573]\n",
      " [0.32720441]\n",
      " [0.33094573]\n",
      " [0.33467579]\n",
      " [0.33813596]\n",
      " [0.3426404 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.34771597]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[[0.31691021]\n",
      "  [0.32029593]\n",
      "  [0.32387573]\n",
      "  [0.32720441]\n",
      "  [0.33094573]\n",
      "  [0.33467579]\n",
      "  [0.33813596]\n",
      "  [0.3426404 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10580642521381378\n",
      "Predicción post entrenamiento : [[0.3502698]]\n",
      "PERDIDAAAA despues: 0.10415153950452805\n",
      "loss en el callback: 0.07158462703227997, batch 45, lote_designado 1\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "ejemplar: [[0.32029593]\n",
      " [0.32387573]\n",
      " [0.32720441]\n",
      " [0.33094573]\n",
      " [0.33467579]\n",
      " [0.33813596]\n",
      " [0.3426404 ]\n",
      " [0.34771597]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.35300127]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[[0.32029593]\n",
      "  [0.32387573]\n",
      "  [0.32720441]\n",
      "  [0.33094573]\n",
      "  [0.33467579]\n",
      "  [0.33813596]\n",
      "  [0.3426404 ]\n",
      "  [0.34771597]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12786062061786652\n",
      "Predicción post entrenamiento : [[0.35608926]]\n",
      "PERDIDAAAA despues: 0.12566177546977997\n",
      "loss en el callback: 0.15541352331638336, batch 46, lote_designado 1\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "ejemplar: [[0.32387573]\n",
      " [0.32720441]\n",
      " [0.33094573]\n",
      " [0.33467579]\n",
      " [0.33813596]\n",
      " [0.3426404 ]\n",
      " [0.34771597]\n",
      " [0.35300127]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.35891995]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[[0.32387573]\n",
      "  [0.32720441]\n",
      "  [0.33094573]\n",
      "  [0.33467579]\n",
      "  [0.33813596]\n",
      "  [0.3426404 ]\n",
      "  [0.34771597]\n",
      "  [0.35300127]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11907382309436798\n",
      "Predicción post entrenamiento : [[0.3618386]]\n",
      "PERDIDAAAA despues: 0.11706805229187012\n",
      "loss en el callback: 0.16621200740337372, batch 47, lote_designado 1\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "ejemplar: [[0.32720441]\n",
      " [0.33094573]\n",
      " [0.33467579]\n",
      " [0.33813596]\n",
      " [0.3426404 ]\n",
      " [0.34771597]\n",
      " [0.35300127]\n",
      " [0.35891995]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.36477283]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[[0.32720441]\n",
      "  [0.33094573]\n",
      "  [0.33467579]\n",
      "  [0.33813596]\n",
      "  [0.3426404 ]\n",
      "  [0.34771597]\n",
      "  [0.35300127]\n",
      "  [0.35891995]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13138066232204437\n",
      "Predicción post entrenamiento : [[0.3676744]]\n",
      "PERDIDAAAA despues: 0.12928563356399536\n",
      "loss en el callback: 0.11280737072229385, batch 48, lote_designado 1\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "ejemplar: [[0.33094573]\n",
      " [0.33467579]\n",
      " [0.33813596]\n",
      " [0.3426404 ]\n",
      " [0.34771597]\n",
      " [0.35300127]\n",
      " [0.35891995]\n",
      " [0.36477283]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.3708384]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[[0.33094573]\n",
      "  [0.33467579]\n",
      "  [0.33813596]\n",
      "  [0.3426404 ]\n",
      "  [0.34771597]\n",
      "  [0.35300127]\n",
      "  [0.35891995]\n",
      "  [0.36477283]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12372786551713943\n",
      "Predicción post entrenamiento : [[0.3738032]]\n",
      "PERDIDAAAA despues: 0.12165091931819916\n",
      "loss en el callback: 0.13744425773620605, batch 49, lote_designado 1\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "ejemplar: [[0.33467579]\n",
      " [0.33813596]\n",
      " [0.3426404 ]\n",
      " [0.34771597]\n",
      " [0.35300127]\n",
      " [0.35891995]\n",
      " [0.36477283]\n",
      " [0.3708384 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.37717777]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[[0.33467579]\n",
      "  [0.33813596]\n",
      "  [0.3426404 ]\n",
      "  [0.34771597]\n",
      "  [0.35300127]\n",
      "  [0.35891995]\n",
      "  [0.36477283]\n",
      "  [0.3708384 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.15572188794612885\n",
      "Predicción post entrenamiento : [[0.38040584]]\n",
      "PERDIDAAAA despues: 0.15318460762500763\n",
      "loss en el callback: 0.1383333057165146, batch 50, lote_designado 1\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "ejemplar: [[0.33813596]\n",
      " [0.3426404 ]\n",
      " [0.34771597]\n",
      " [0.35300127]\n",
      " [0.35891995]\n",
      " [0.36477283]\n",
      " [0.3708384 ]\n",
      " [0.37717777]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.38407862]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[[0.33813596]\n",
      "  [0.3426404 ]\n",
      "  [0.34771597]\n",
      "  [0.35300127]\n",
      "  [0.35891995]\n",
      "  [0.36477283]\n",
      "  [0.3708384 ]\n",
      "  [0.37717777]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11590400338172913\n",
      "Predicción post entrenamiento : [[0.38685465]]\n",
      "PERDIDAAAA despues: 0.11402153223752975\n",
      "loss en el callback: 0.11324848979711533, batch 51, lote_designado 1\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "ejemplar: [[0.3426404 ]\n",
      " [0.34771597]\n",
      " [0.35300127]\n",
      " [0.35891995]\n",
      " [0.36477283]\n",
      " [0.3708384 ]\n",
      " [0.37717777]\n",
      " [0.38407862]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.39098838]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[[0.3426404 ]\n",
      "  [0.34771597]\n",
      "  [0.35300127]\n",
      "  [0.35891995]\n",
      "  [0.36477283]\n",
      "  [0.3708384 ]\n",
      "  [0.37717777]\n",
      "  [0.38407862]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07843882590532303\n",
      "Predicción post entrenamiento : [[0.39333093]]\n",
      "PERDIDAAAA despues: 0.07713215798139572\n",
      "loss en el callback: 0.12650233507156372, batch 52, lote_designado 1\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "ejemplar: [[0.34771597]\n",
      " [0.35300127]\n",
      " [0.35891995]\n",
      " [0.36477283]\n",
      " [0.3708384 ]\n",
      " [0.37717777]\n",
      " [0.38407862]\n",
      " [0.39098838]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.39776972]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[[0.34771597]\n",
      "  [0.35300127]\n",
      "  [0.35891995]\n",
      "  [0.36477283]\n",
      "  [0.3708384 ]\n",
      "  [0.37717777]\n",
      "  [0.38407862]\n",
      "  [0.39098838]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07617606222629547\n",
      "Predicción post entrenamiento : [[0.3998861]]\n",
      "PERDIDAAAA despues: 0.07501229643821716\n",
      "loss en el callback: 0.08918426930904388, batch 53, lote_designado 1\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "ejemplar: [[0.35300127]\n",
      " [0.35891995]\n",
      " [0.36477283]\n",
      " [0.3708384 ]\n",
      " [0.37717777]\n",
      " [0.38407862]\n",
      " [0.39098838]\n",
      " [0.39776972]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.4045633]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[[0.35300127]\n",
      "  [0.35891995]\n",
      "  [0.36477283]\n",
      "  [0.3708384 ]\n",
      "  [0.37717777]\n",
      "  [0.38407862]\n",
      "  [0.39098838]\n",
      "  [0.39776972]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09603086858987808\n",
      "Predicción post entrenamiento : [[0.40676576]]\n",
      "PERDIDAAAA despues: 0.09467069059610367\n",
      "loss en el callback: 0.06783150136470795, batch 54, lote_designado 1\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "ejemplar: [[0.35891995]\n",
      " [0.36477283]\n",
      " [0.3708384 ]\n",
      " [0.37717777]\n",
      " [0.38407862]\n",
      " [0.39098838]\n",
      " [0.39776972]\n",
      " [0.40456331]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.41169196]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[[0.35891995]\n",
      "  [0.36477283]\n",
      "  [0.3708384 ]\n",
      "  [0.37717777]\n",
      "  [0.38407862]\n",
      "  [0.39098838]\n",
      "  [0.39776972]\n",
      "  [0.40456331]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11036067456007004\n",
      "Predicción post entrenamiento : [[0.41407794]]\n",
      "PERDIDAAAA despues: 0.10878109931945801\n",
      "loss en el callback: 0.08117808401584625, batch 55, lote_designado 1\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "ejemplar: [[0.36477283]\n",
      " [0.3708384 ]\n",
      " [0.37717777]\n",
      " [0.38407862]\n",
      " [0.39098838]\n",
      " [0.39776972]\n",
      " [0.40456331]\n",
      " [0.41169196]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.41915035]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[[0.36477283]\n",
      "  [0.3708384 ]\n",
      "  [0.37717777]\n",
      "  [0.38407862]\n",
      "  [0.39098838]\n",
      "  [0.39776972]\n",
      "  [0.40456331]\n",
      "  [0.41169196]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09207447618246078\n",
      "Predicción post entrenamiento : [[0.42146638]]\n",
      "PERDIDAAAA despues: 0.09067430347204208\n",
      "loss en el callback: 0.11314421147108078, batch 56, lote_designado 1\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "ejemplar: [[0.3708384 ]\n",
      " [0.37717777]\n",
      " [0.38407862]\n",
      " [0.39098838]\n",
      " [0.39776972]\n",
      " [0.40456331]\n",
      " [0.41169196]\n",
      " [0.41915035]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.4267454]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[[0.3708384 ]\n",
      "  [0.37717777]\n",
      "  [0.38407862]\n",
      "  [0.39098838]\n",
      "  [0.39776972]\n",
      "  [0.40456331]\n",
      "  [0.41169196]\n",
      "  [0.41915035]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07430854439735413\n",
      "Predicción post entrenamiento : [[0.42855388]]\n",
      "PERDIDAAAA despues: 0.07332585752010345\n",
      "loss en el callback: 0.055117346346378326, batch 57, lote_designado 1\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "ejemplar: [[0.37717777]\n",
      " [0.38407862]\n",
      " [0.39098838]\n",
      " [0.39776972]\n",
      " [0.40456331]\n",
      " [0.41169196]\n",
      " [0.41915035]\n",
      " [0.42674541]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.4340338]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[[0.37717777]\n",
      "  [0.38407862]\n",
      "  [0.39098838]\n",
      "  [0.39776972]\n",
      "  [0.40456331]\n",
      "  [0.41169196]\n",
      "  [0.41915035]\n",
      "  [0.42674541]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09197712689638138\n",
      "Predicción post entrenamiento : [[0.43635395]]\n",
      "PERDIDAAAA despues: 0.0905752182006836\n",
      "loss en el callback: 0.11561088263988495, batch 58, lote_designado 1\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "ejemplar: [[0.38407862]\n",
      " [0.39098838]\n",
      " [0.39776972]\n",
      " [0.40456331]\n",
      " [0.41169196]\n",
      " [0.41915035]\n",
      " [0.42674541]\n",
      " [0.43403381]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.4420105]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[[0.38407862]\n",
      "  [0.39098838]\n",
      "  [0.39776972]\n",
      "  [0.40456331]\n",
      "  [0.41169196]\n",
      "  [0.41915035]\n",
      "  [0.42674541]\n",
      "  [0.43403381]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0780729353427887\n",
      "Predicción post entrenamiento : [[0.44383964]]\n",
      "PERDIDAAAA despues: 0.07705409079790115\n",
      "loss en el callback: 0.05666481703519821, batch 59, lote_designado 1\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "ejemplar: [[0.39098838]\n",
      " [0.39776972]\n",
      " [0.40456331]\n",
      " [0.41169196]\n",
      " [0.41915035]\n",
      " [0.42674541]\n",
      " [0.43403381]\n",
      " [0.44201049]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.44956544]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[[0.39098838]\n",
      "  [0.39776972]\n",
      "  [0.40456331]\n",
      "  [0.41169196]\n",
      "  [0.41915035]\n",
      "  [0.42674541]\n",
      "  [0.43403381]\n",
      "  [0.44201049]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07244078814983368\n",
      "Predicción post entrenamiento : [[0.45145237]]\n",
      "PERDIDAAAA despues: 0.07142861932516098\n",
      "loss en el callback: 0.0657372698187828, batch 60, lote_designado 1\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "ejemplar: [[0.39776972]\n",
      " [0.40456331]\n",
      " [0.41169196]\n",
      " [0.41915035]\n",
      " [0.42674541]\n",
      " [0.43403381]\n",
      " [0.44201049]\n",
      " [0.44956544]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.45727164]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[[0.39776972]\n",
      "  [0.40456331]\n",
      "  [0.41169196]\n",
      "  [0.41915035]\n",
      "  [0.42674541]\n",
      "  [0.43403381]\n",
      "  [0.44201049]\n",
      "  [0.44956544]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04703940078616142\n",
      "Predicción post entrenamiento : [[0.45882693]]\n",
      "PERDIDAAAA despues: 0.04636717960238457\n",
      "loss en el callback: 0.0472802110016346, batch 61, lote_designado 1\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "ejemplar: [[0.40456331]\n",
      " [0.41169196]\n",
      " [0.41915035]\n",
      " [0.42674541]\n",
      " [0.43403381]\n",
      " [0.44201049]\n",
      " [0.44956544]\n",
      " [0.45727164]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.46480253]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[[0.40456331]\n",
      "  [0.41169196]\n",
      "  [0.41915035]\n",
      "  [0.42674541]\n",
      "  [0.43403381]\n",
      "  [0.44201049]\n",
      "  [0.44956544]\n",
      "  [0.45727164]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.054645560681819916\n",
      "Predicción post entrenamiento : [[0.46629158]]\n",
      "PERDIDAAAA despues: 0.05395160987973213\n",
      "loss en el callback: 0.0413195863366127, batch 62, lote_designado 1\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "ejemplar: [[0.41169196]\n",
      " [0.41915035]\n",
      " [0.42674541]\n",
      " [0.43403381]\n",
      " [0.44201049]\n",
      " [0.44956544]\n",
      " [0.45727164]\n",
      " [0.46480253]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.47245565]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[[0.41169196]\n",
      "  [0.41915035]\n",
      "  [0.42674541]\n",
      "  [0.43403381]\n",
      "  [0.44201049]\n",
      "  [0.44956544]\n",
      "  [0.45727164]\n",
      "  [0.46480253]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06179335340857506\n",
      "Predicción post entrenamiento : [[0.47410405]]\n",
      "PERDIDAAAA despues: 0.0609765462577343\n",
      "loss en el callback: 0.05065023899078369, batch 63, lote_designado 1\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "ejemplar: [[0.41915035]\n",
      " [0.42674541]\n",
      " [0.43403381]\n",
      " [0.44201049]\n",
      " [0.44956544]\n",
      " [0.45727164]\n",
      " [0.46480253]\n",
      " [0.47245565]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.4804005]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[[0.41915035]\n",
      "  [0.42674541]\n",
      "  [0.43403381]\n",
      "  [0.44201049]\n",
      "  [0.44956544]\n",
      "  [0.45727164]\n",
      "  [0.46480253]\n",
      "  [0.47245565]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.058654844760894775\n",
      "Predicción post entrenamiento : [[0.48226598]]\n",
      "PERDIDAAAA despues: 0.05775473266839981\n",
      "loss en el callback: 0.08783432841300964, batch 64, lote_designado 1\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "ejemplar: [[0.42674541]\n",
      " [0.43403381]\n",
      " [0.44201049]\n",
      " [0.44956544]\n",
      " [0.45727164]\n",
      " [0.46480253]\n",
      " [0.47245565]\n",
      " [0.4804005 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.48862872]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[[0.42674541]\n",
      "  [0.43403381]\n",
      "  [0.44201049]\n",
      "  [0.44956544]\n",
      "  [0.45727164]\n",
      "  [0.46480253]\n",
      "  [0.47245565]\n",
      "  [0.4804005 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07164579629898071\n",
      "Predicción post entrenamiento : [[0.49042034]]\n",
      "PERDIDAAAA despues: 0.07068988680839539\n",
      "loss en el callback: 0.06538376957178116, batch 65, lote_designado 1\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "ejemplar: [[0.43403381]\n",
      " [0.44201049]\n",
      " [0.44956544]\n",
      " [0.45727164]\n",
      " [0.46480253]\n",
      " [0.47245565]\n",
      " [0.4804005 ]\n",
      " [0.48862872]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.49682513]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[[0.43403381]\n",
      "  [0.44201049]\n",
      "  [0.44956544]\n",
      "  [0.45727164]\n",
      "  [0.46480253]\n",
      "  [0.47245565]\n",
      "  [0.4804005 ]\n",
      "  [0.48862872]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10940290987491608\n",
      "Predicción post entrenamiento : [[0.49903926]]\n",
      "PERDIDAAAA despues: 0.1079431101679802\n",
      "loss en el callback: 0.11025575548410416, batch 66, lote_designado 1\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "ejemplar: [[0.44201049]\n",
      " [0.44956544]\n",
      " [0.45727164]\n",
      " [0.46480253]\n",
      " [0.47245565]\n",
      " [0.4804005 ]\n",
      " [0.48862872]\n",
      " [0.49682513]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.5055832]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[[0.44201049]\n",
      "  [0.44956544]\n",
      "  [0.45727164]\n",
      "  [0.46480253]\n",
      "  [0.47245565]\n",
      "  [0.4804005 ]\n",
      "  [0.48862872]\n",
      "  [0.49682513]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11104820668697357\n",
      "Predicción post entrenamiento : [[0.5078174]]\n",
      "PERDIDAAAA despues: 0.10956417769193649\n",
      "loss en el callback: 0.09071273356676102, batch 67, lote_designado 1\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "ejemplar: [[0.44956544]\n",
      " [0.45727164]\n",
      " [0.46480253]\n",
      " [0.47245565]\n",
      " [0.4804005 ]\n",
      " [0.48862872]\n",
      " [0.49682513]\n",
      " [0.50558323]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.5143438]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[[0.44956544]\n",
      "  [0.45727164]\n",
      "  [0.46480253]\n",
      "  [0.47245565]\n",
      "  [0.4804005 ]\n",
      "  [0.48862872]\n",
      "  [0.49682513]\n",
      "  [0.50558323]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07835633307695389\n",
      "Predicción post entrenamiento : [[0.5161562]]\n",
      "PERDIDAAAA despues: 0.07734495401382446\n",
      "loss en el callback: 0.07733822613954544, batch 68, lote_designado 1\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "ejemplar: [[0.45727164]\n",
      " [0.46480253]\n",
      " [0.47245565]\n",
      " [0.4804005 ]\n",
      " [0.48862872]\n",
      " [0.49682513]\n",
      " [0.50558323]\n",
      " [0.5143438 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.52279484]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[[0.45727164]\n",
      "  [0.46480253]\n",
      "  [0.47245565]\n",
      "  [0.4804005 ]\n",
      "  [0.48862872]\n",
      "  [0.49682513]\n",
      "  [0.50558323]\n",
      "  [0.5143438 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06812615692615509\n",
      "Predicción post entrenamiento : [[0.5237202]]\n",
      "PERDIDAAAA despues: 0.06764395534992218\n",
      "loss en el callback: 0.012980462983250618, batch 69, lote_designado 1\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "ejemplar: [[0.46480253]\n",
      " [0.47245565]\n",
      " [0.4804005 ]\n",
      " [0.48862872]\n",
      " [0.49682513]\n",
      " [0.50558323]\n",
      " [0.5143438 ]\n",
      " [0.52279484]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.5304645]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[[0.46480253]\n",
      "  [0.47245565]\n",
      "  [0.4804005 ]\n",
      "  [0.48862872]\n",
      "  [0.49682513]\n",
      "  [0.50558323]\n",
      "  [0.5143438 ]\n",
      "  [0.52279484]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0563848540186882\n",
      "Predicción post entrenamiento : [[0.5320279]]\n",
      "PERDIDAAAA despues: 0.05564481019973755\n",
      "loss en el callback: 0.05302618071436882, batch 70, lote_designado 1\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "ejemplar: [[0.47245565]\n",
      " [0.4804005 ]\n",
      " [0.48862872]\n",
      " [0.49682513]\n",
      " [0.50558323]\n",
      " [0.5143438 ]\n",
      " [0.52279484]\n",
      " [0.53046447]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.53895944]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[[0.47245565]\n",
      "  [0.4804005 ]\n",
      "  [0.48862872]\n",
      "  [0.49682513]\n",
      "  [0.50558323]\n",
      "  [0.5143438 ]\n",
      "  [0.52279484]\n",
      "  [0.53046447]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06032927706837654\n",
      "Predicción post entrenamiento : [[0.54052895]]\n",
      "PERDIDAAAA despues: 0.059560734778642654\n",
      "loss en el callback: 0.05166558176279068, batch 71, lote_designado 1\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "ejemplar: [[0.4804005 ]\n",
      " [0.48862872]\n",
      " [0.49682513]\n",
      " [0.50558323]\n",
      " [0.5143438 ]\n",
      " [0.52279484]\n",
      " [0.53046447]\n",
      " [0.53895944]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.54765016]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[[0.4804005 ]\n",
      "  [0.48862872]\n",
      "  [0.49682513]\n",
      "  [0.50558323]\n",
      "  [0.5143438 ]\n",
      "  [0.52279484]\n",
      "  [0.53046447]\n",
      "  [0.53895944]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10961330682039261\n",
      "Predicción post entrenamiento : [[0.5494187]]\n",
      "PERDIDAAAA despues: 0.10844539105892181\n",
      "loss en el callback: 0.05788043886423111, batch 72, lote_designado 1\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "ejemplar: [[0.48862872]\n",
      " [0.49682513]\n",
      " [0.50558323]\n",
      " [0.5143438 ]\n",
      " [0.52279484]\n",
      " [0.53046447]\n",
      " [0.53895944]\n",
      " [0.54765016]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.55668]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[[0.48862872]\n",
      "  [0.49682513]\n",
      "  [0.50558323]\n",
      "  [0.5143438 ]\n",
      "  [0.52279484]\n",
      "  [0.53046447]\n",
      "  [0.53895944]\n",
      "  [0.54765016]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10172883421182632\n",
      "Predicción post entrenamiento : [[0.5588611]]\n",
      "PERDIDAAAA despues: 0.1003422960639\n",
      "loss en el callback: 0.12918564677238464, batch 73, lote_designado 1\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "ejemplar: [[0.49682513]\n",
      " [0.50558323]\n",
      " [0.5143438 ]\n",
      " [0.52279484]\n",
      " [0.53046447]\n",
      " [0.53895944]\n",
      " [0.54765016]\n",
      " [0.55668002]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.56620514]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[[0.49682513]\n",
      "  [0.50558323]\n",
      "  [0.5143438 ]\n",
      "  [0.52279484]\n",
      "  [0.53046447]\n",
      "  [0.53895944]\n",
      "  [0.54765016]\n",
      "  [0.55668002]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07991400361061096\n",
      "Predicción post entrenamiento : [[0.56753916]]\n",
      "PERDIDAAAA despues: 0.07916155457496643\n",
      "loss en el callback: 0.03054630197584629, batch 74, lote_designado 1\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "ejemplar: [[0.50558323]\n",
      " [0.5143438 ]\n",
      " [0.52279484]\n",
      " [0.53046447]\n",
      " [0.53895944]\n",
      " [0.54765016]\n",
      " [0.55668002]\n",
      " [0.56620514]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.5749891]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[[0.50558323]\n",
      "  [0.5143438 ]\n",
      "  [0.52279484]\n",
      "  [0.53046447]\n",
      "  [0.53895944]\n",
      "  [0.54765016]\n",
      "  [0.55668002]\n",
      "  [0.56620514]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05919411778450012\n",
      "Predicción post entrenamiento : [[0.57627356]]\n",
      "PERDIDAAAA despues: 0.0585707426071167\n",
      "loss en el callback: 0.03347751498222351, batch 75, lote_designado 1\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "ejemplar: [[0.5143438 ]\n",
      " [0.52279484]\n",
      " [0.53046447]\n",
      " [0.53895944]\n",
      " [0.54765016]\n",
      " [0.55668002]\n",
      " [0.56620514]\n",
      " [0.57498908]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.5836952]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[[0.5143438 ]\n",
      "  [0.52279484]\n",
      "  [0.53046447]\n",
      "  [0.53895944]\n",
      "  [0.54765016]\n",
      "  [0.55668002]\n",
      "  [0.56620514]\n",
      "  [0.57498908]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05910545587539673\n",
      "Predicción post entrenamiento : [[0.5855425]]\n",
      "PERDIDAAAA despues: 0.05821064114570618\n",
      "loss en el callback: 0.10752950608730316, batch 76, lote_designado 1\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "ejemplar: [[0.52279484]\n",
      " [0.53046447]\n",
      " [0.53895944]\n",
      " [0.54765016]\n",
      " [0.55668002]\n",
      " [0.56620514]\n",
      " [0.57498908]\n",
      " [0.58369517]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.59294444]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[[0.52279484]\n",
      "  [0.53046447]\n",
      "  [0.53895944]\n",
      "  [0.54765016]\n",
      "  [0.55668002]\n",
      "  [0.56620514]\n",
      "  [0.57498908]\n",
      "  [0.58369517]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03702162951231003\n",
      "Predicción post entrenamiento : [[0.59440255]]\n",
      "PERDIDAAAA despues: 0.03646264597773552\n",
      "loss en el callback: 0.06400680541992188, batch 77, lote_designado 1\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "ejemplar: [[0.53046447]\n",
      " [0.53895944]\n",
      " [0.54765016]\n",
      " [0.55668002]\n",
      " [0.56620514]\n",
      " [0.57498908]\n",
      " [0.58369517]\n",
      " [0.59294444]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.60188574]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[[0.53046447]\n",
      "  [0.53895944]\n",
      "  [0.54765016]\n",
      "  [0.55668002]\n",
      "  [0.56620514]\n",
      "  [0.57498908]\n",
      "  [0.58369517]\n",
      "  [0.59294444]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03509749099612236\n",
      "Predicción post entrenamiento : [[0.60321933]]\n",
      "PERDIDAAAA despues: 0.03459958732128143\n",
      "loss en el callback: 0.05406704172492027, batch 78, lote_designado 1\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "ejemplar: [[0.53895944]\n",
      " [0.54765016]\n",
      " [0.55668002]\n",
      " [0.56620514]\n",
      " [0.57498908]\n",
      " [0.58369517]\n",
      " [0.59294444]\n",
      " [0.60188574]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.6110334]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[[0.53895944]\n",
      "  [0.54765016]\n",
      "  [0.55668002]\n",
      "  [0.56620514]\n",
      "  [0.57498908]\n",
      "  [0.58369517]\n",
      "  [0.59294444]\n",
      "  [0.60188574]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04979119449853897\n",
      "Predicción post entrenamiento : [[0.6128793]]\n",
      "PERDIDAAAA despues: 0.048970818519592285\n",
      "loss en el callback: 0.1756887435913086, batch 79, lote_designado 1\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "ejemplar: [[0.54765016]\n",
      " [0.55668002]\n",
      " [0.56620514]\n",
      " [0.57498908]\n",
      " [0.58369517]\n",
      " [0.59294444]\n",
      " [0.60188574]\n",
      " [0.61103338]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.6208455]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[[0.54765016]\n",
      "  [0.55668002]\n",
      "  [0.56620514]\n",
      "  [0.57498908]\n",
      "  [0.58369517]\n",
      "  [0.59294444]\n",
      "  [0.60188574]\n",
      "  [0.61103338]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03672217205166817\n",
      "Predicción post entrenamiento : [[0.62137127]]\n",
      "PERDIDAAAA despues: 0.03652094304561615\n",
      "loss en el callback: 0.005487995222210884, batch 80, lote_designado 1\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "ejemplar: [[0.55668002]\n",
      " [0.56620514]\n",
      " [0.57498908]\n",
      " [0.58369517]\n",
      " [0.59294444]\n",
      " [0.60188574]\n",
      " [0.61103338]\n",
      " [0.6208455 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.6294545]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[[0.55668002]\n",
      "  [0.56620514]\n",
      "  [0.57498908]\n",
      "  [0.58369517]\n",
      "  [0.59294444]\n",
      "  [0.60188574]\n",
      "  [0.61103338]\n",
      "  [0.6208455 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02951020747423172\n",
      "Predicción post entrenamiento : [[0.63028324]]\n",
      "PERDIDAAAA despues: 0.029226163402199745\n",
      "loss en el callback: 0.014496966265141964, batch 81, lote_designado 1\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "ejemplar: [[0.56620514]\n",
      " [0.57498908]\n",
      " [0.58369517]\n",
      " [0.59294444]\n",
      " [0.60188574]\n",
      " [0.61103338]\n",
      " [0.6208455 ]\n",
      " [0.62945449]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.6384028]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[[0.56620514]\n",
      "  [0.57498908]\n",
      "  [0.58369517]\n",
      "  [0.59294444]\n",
      "  [0.60188574]\n",
      "  [0.61103338]\n",
      "  [0.6208455 ]\n",
      "  [0.62945449]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.027150548994541168\n",
      "Predicción post entrenamiento : [[0.63969207]]\n",
      "PERDIDAAAA despues: 0.02672734297811985\n",
      "loss en el callback: 0.051752761006355286, batch 82, lote_designado 1\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "ejemplar: [[0.57498908]\n",
      " [0.58369517]\n",
      " [0.59294444]\n",
      " [0.60188574]\n",
      " [0.61103338]\n",
      " [0.6208455 ]\n",
      " [0.62945449]\n",
      " [0.63840282]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.64770997]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[[0.57498908]\n",
      "  [0.58369517]\n",
      "  [0.59294444]\n",
      "  [0.60188574]\n",
      "  [0.61103338]\n",
      "  [0.6208455 ]\n",
      "  [0.62945449]\n",
      "  [0.63840282]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02125207707285881\n",
      "Predicción post entrenamiento : [[0.648897]]\n",
      "PERDIDAAAA despues: 0.020907394587993622\n",
      "loss en el callback: 0.04157911613583565, batch 83, lote_designado 1\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "ejemplar: [[0.58369517]\n",
      " [0.59294444]\n",
      " [0.60188574]\n",
      " [0.61103338]\n",
      " [0.6208455 ]\n",
      " [0.62945449]\n",
      " [0.63840282]\n",
      " [0.64770997]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.65701336]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[[0.58369517]\n",
      "  [0.59294444]\n",
      "  [0.60188574]\n",
      "  [0.61103338]\n",
      "  [0.6208455 ]\n",
      "  [0.62945449]\n",
      "  [0.63840282]\n",
      "  [0.64770997]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010641387663781643\n",
      "Predicción post entrenamiento : [[0.657077]]\n",
      "PERDIDAAAA despues: 0.010628258809447289\n",
      "loss en el callback: 9.142301860265434e-05, batch 84, lote_designado 1\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "ejemplar: [[0.59294444]\n",
      " [0.60188574]\n",
      " [0.61103338]\n",
      " [0.6208455 ]\n",
      " [0.62945449]\n",
      " [0.63840282]\n",
      " [0.64770997]\n",
      " [0.65701336]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.66532516]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[[0.59294444]\n",
      "  [0.60188574]\n",
      "  [0.61103338]\n",
      "  [0.6208455 ]\n",
      "  [0.62945449]\n",
      "  [0.63840282]\n",
      "  [0.64770997]\n",
      "  [0.65701336]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004906827118247747\n",
      "Predicción post entrenamiento : [[0.6663775]]\n",
      "PERDIDAAAA despues: 0.004760507494211197\n",
      "loss en el callback: 0.04270188882946968, batch 85, lote_designado 1\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "ejemplar: [[0.60188574]\n",
      " [0.61103338]\n",
      " [0.6208455 ]\n",
      " [0.62945449]\n",
      " [0.63840282]\n",
      " [0.64770997]\n",
      " [0.65701336]\n",
      " [0.66532516]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.6746155]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[[0.60188574]\n",
      "  [0.61103338]\n",
      "  [0.6208455 ]\n",
      "  [0.62945449]\n",
      "  [0.63840282]\n",
      "  [0.64770997]\n",
      "  [0.65701336]\n",
      "  [0.66532516]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012655319878831506\n",
      "Predicción post entrenamiento : [[0.6751764]]\n",
      "PERDIDAAAA despues: 0.0012259407667443156\n",
      "loss en el callback: 0.008837969042360783, batch 86, lote_designado 1\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "ejemplar: [[0.61103338]\n",
      " [0.6208455 ]\n",
      " [0.62945449]\n",
      " [0.63840282]\n",
      " [0.64770997]\n",
      " [0.65701336]\n",
      " [0.66532516]\n",
      " [0.6746155 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.68348086]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[[0.61103338]\n",
      "  [0.6208455 ]\n",
      "  [0.62945449]\n",
      "  [0.63840282]\n",
      "  [0.64770997]\n",
      "  [0.65701336]\n",
      "  [0.66532516]\n",
      "  [0.6746155 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000820606539491564\n",
      "Predicción post entrenamiento : [[0.6837435]]\n",
      "PERDIDAAAA despues: 0.0008056294755078852\n",
      "loss en el callback: 0.001949548372067511, batch 87, lote_designado 1\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "ejemplar: [[0.6208455 ]\n",
      " [0.62945449]\n",
      " [0.63840282]\n",
      " [0.64770997]\n",
      " [0.65701336]\n",
      " [0.66532516]\n",
      " [0.6746155 ]\n",
      " [0.68348086]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.69205093]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[[0.6208455 ]\n",
      "  [0.62945449]\n",
      "  [0.63840282]\n",
      "  [0.64770997]\n",
      "  [0.65701336]\n",
      "  [0.66532516]\n",
      "  [0.6746155 ]\n",
      "  [0.68348086]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002264321781694889\n",
      "Predicción post entrenamiento : [[0.6918587]]\n",
      "PERDIDAAAA despues: 0.002282652771100402\n",
      "loss en el callback: 0.0008614949765615165, batch 88, lote_designado 1\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "ejemplar: [[0.62945449]\n",
      " [0.63840282]\n",
      " [0.64770997]\n",
      " [0.65701336]\n",
      " [0.66532516]\n",
      " [0.6746155 ]\n",
      " [0.68348086]\n",
      " [0.69205093]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.69996154]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[[0.62945449]\n",
      "  [0.63840282]\n",
      "  [0.64770997]\n",
      "  [0.65701336]\n",
      "  [0.66532516]\n",
      "  [0.6746155 ]\n",
      "  [0.68348086]\n",
      "  [0.69205093]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013095156755298376\n",
      "Predicción post entrenamiento : [[0.70039576]]\n",
      "PERDIDAAAA despues: 0.0012782778358086944\n",
      "loss en el callback: 0.005800374783575535, batch 89, lote_designado 1\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "ejemplar: [[0.63840282]\n",
      " [0.64770997]\n",
      " [0.65701336]\n",
      " [0.66532516]\n",
      " [0.6746155 ]\n",
      " [0.68348086]\n",
      " [0.69205093]\n",
      " [0.69996154]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.7086042]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[[0.63840282]\n",
      "  [0.64770997]\n",
      "  [0.65701336]\n",
      "  [0.66532516]\n",
      "  [0.6746155 ]\n",
      "  [0.68348086]\n",
      "  [0.69205093]\n",
      "  [0.69996154]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016837486764416099\n",
      "Predicción post entrenamiento : [[0.70896167]]\n",
      "PERDIDAAAA despues: 0.0017132111825048923\n",
      "loss en el callback: 0.0042779636569321156, batch 90, lote_designado 1\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "ejemplar: [[0.64770997]\n",
      " [0.65701336]\n",
      " [0.66532516]\n",
      " [0.6746155 ]\n",
      " [0.68348086]\n",
      " [0.69205093]\n",
      " [0.69996154]\n",
      " [0.70860422]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.71717227]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[[0.64770997]\n",
      "  [0.65701336]\n",
      "  [0.66532516]\n",
      "  [0.6746155 ]\n",
      "  [0.68348086]\n",
      "  [0.69205093]\n",
      "  [0.69996154]\n",
      "  [0.70860422]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002235101070255041\n",
      "Predicción post entrenamiento : [[0.71639454]]\n",
      "PERDIDAAAA despues: 0.0021621694322675467\n",
      "loss en el callback: 0.01419833768159151, batch 91, lote_designado 1\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "ejemplar: [[0.65701336]\n",
      " [0.66532516]\n",
      " [0.6746155 ]\n",
      " [0.68348086]\n",
      " [0.69205093]\n",
      " [0.69996154]\n",
      " [0.70860422]\n",
      " [0.71717227]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.7244755]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[[0.65701336]\n",
      "  [0.66532516]\n",
      "  [0.6746155 ]\n",
      "  [0.68348086]\n",
      "  [0.69205093]\n",
      "  [0.69996154]\n",
      "  [0.70860422]\n",
      "  [0.71717227]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007754151010885835\n",
      "Predicción post entrenamiento : [[0.72476214]]\n",
      "PERDIDAAAA despues: 0.0007914609159342945\n",
      "loss en el callback: 0.002514392603188753, batch 92, lote_designado 1\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "ejemplar: [[0.66532516]\n",
      " [0.6746155 ]\n",
      " [0.68348086]\n",
      " [0.69205093]\n",
      " [0.69996154]\n",
      " [0.70860422]\n",
      " [0.71717227]\n",
      " [0.7244755 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.7326749]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[[0.66532516]\n",
      "  [0.6746155 ]\n",
      "  [0.68348086]\n",
      "  [0.69205093]\n",
      "  [0.69996154]\n",
      "  [0.70860422]\n",
      "  [0.71717227]\n",
      "  [0.7244755 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00588712003082037\n",
      "Predicción post entrenamiento : [[0.73234546]]\n",
      "PERDIDAAAA despues: 0.005836674943566322\n",
      "loss en el callback: 0.003309472929686308, batch 93, lote_designado 1\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "ejemplar: [[0.6746155 ]\n",
      " [0.68348086]\n",
      " [0.69205093]\n",
      " [0.69996154]\n",
      " [0.70860422]\n",
      " [0.71717227]\n",
      " [0.7244755 ]\n",
      " [0.7326749 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.7403322]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[[0.6746155 ]\n",
      "  [0.68348086]\n",
      "  [0.69205093]\n",
      "  [0.69996154]\n",
      "  [0.70860422]\n",
      "  [0.71717227]\n",
      "  [0.7244755 ]\n",
      "  [0.7326749 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0037853901740163565\n",
      "Predicción post entrenamiento : [[0.7402048]]\n",
      "PERDIDAAAA despues: 0.0037697325460612774\n",
      "loss en el callback: 0.0004894077428616583, batch 94, lote_designado 1\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "ejemplar: [[0.68348086]\n",
      " [0.69205093]\n",
      " [0.69996154]\n",
      " [0.70860422]\n",
      " [0.71717227]\n",
      " [0.7244755 ]\n",
      " [0.7326749 ]\n",
      " [0.74033219]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.7479585]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[[0.68348086]\n",
      "  [0.69205093]\n",
      "  [0.69996154]\n",
      "  [0.70860422]\n",
      "  [0.71717227]\n",
      "  [0.7244755 ]\n",
      "  [0.7326749 ]\n",
      "  [0.74033219]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00516442721709609\n",
      "Predicción post entrenamiento : [[0.7470968]]\n",
      "PERDIDAAAA despues: 0.005041318945586681\n",
      "loss en el callback: 0.018216099590063095, batch 95, lote_designado 1\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "ejemplar: [[0.69205093]\n",
      " [0.69996154]\n",
      " [0.70860422]\n",
      " [0.71717227]\n",
      " [0.7244755 ]\n",
      " [0.7326749 ]\n",
      " [0.74033219]\n",
      " [0.74795848]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.7546812]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[[0.69205093]\n",
      "  [0.69996154]\n",
      "  [0.70860422]\n",
      "  [0.71717227]\n",
      "  [0.7244755 ]\n",
      "  [0.7326749 ]\n",
      "  [0.74033219]\n",
      "  [0.74795848]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000630967493634671\n",
      "Predicción post entrenamiento : [[0.7550687]]\n",
      "PERDIDAAAA despues: 0.0006505844066850841\n",
      "loss en el callback: 0.0053519136272370815, batch 96, lote_designado 1\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "ejemplar: [[0.69996154]\n",
      " [0.70860422]\n",
      " [0.71717227]\n",
      " [0.7244755 ]\n",
      " [0.7326749 ]\n",
      " [0.74033219]\n",
      " [0.74795848]\n",
      " [0.75468123]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.76252335]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[[0.69996154]\n",
      "  [0.70860422]\n",
      "  [0.71717227]\n",
      "  [0.7244755 ]\n",
      "  [0.7326749 ]\n",
      "  [0.74033219]\n",
      "  [0.74795848]\n",
      "  [0.75468123]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003750923788174987\n",
      "Predicción post entrenamiento : [[0.7625228]]\n",
      "PERDIDAAAA despues: 0.0037508581299334764\n",
      "loss en el callback: 1.8517059885425624e-08, batch 97, lote_designado 1\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "ejemplar: [[0.70860422]\n",
      " [0.71717227]\n",
      " [0.7244755 ]\n",
      " [0.7326749 ]\n",
      " [0.74033219]\n",
      " [0.74795848]\n",
      " [0.75468123]\n",
      " [0.76252335]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.7699966]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[[0.70860422]\n",
      "  [0.71717227]\n",
      "  [0.7244755 ]\n",
      "  [0.7326749 ]\n",
      "  [0.74033219]\n",
      "  [0.74795848]\n",
      "  [0.75468123]\n",
      "  [0.76252335]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.074215889384504e-06\n",
      "Predicción post entrenamiento : [[0.77027637]]\n",
      "PERDIDAAAA despues: 7.53160338717862e-06\n",
      "loss en el callback: 0.002902749925851822, batch 98, lote_designado 1\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "ejemplar: [[0.71717227]\n",
      " [0.7244755 ]\n",
      " [0.7326749 ]\n",
      " [0.74033219]\n",
      " [0.74795848]\n",
      " [0.75468123]\n",
      " [0.76252335]\n",
      " [0.76999658]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.7775274]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[[0.71717227]\n",
      "  [0.7244755 ]\n",
      "  [0.7326749 ]\n",
      "  [0.74033219]\n",
      "  [0.74795848]\n",
      "  [0.75468123]\n",
      "  [0.76252335]\n",
      "  [0.76999658]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005014779744669795\n",
      "Predicción post entrenamiento : [[0.77769494]]\n",
      "PERDIDAAAA despues: 0.0005090101039968431\n",
      "loss en el callback: 0.0009765662252902985, batch 99, lote_designado 1\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "ejemplar: [[0.7244755 ]\n",
      " [0.7326749 ]\n",
      " [0.74033219]\n",
      " [0.74795848]\n",
      " [0.75468123]\n",
      " [0.76252335]\n",
      " [0.76999658]\n",
      " [0.77752739]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.784694]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[[0.7244755 ]\n",
      "  [0.7326749 ]\n",
      "  [0.74033219]\n",
      "  [0.74795848]\n",
      "  [0.75468123]\n",
      "  [0.76252335]\n",
      "  [0.76999658]\n",
      "  [0.77752739]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015708530554547906\n",
      "Predicción post entrenamiento : [[0.78487813]]\n",
      "PERDIDAAAA despues: 0.0015854816883802414\n",
      "loss en el callback: 0.0010786426719278097, batch 100, lote_designado 1\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "ejemplar: [[0.7326749 ]\n",
      " [0.74033219]\n",
      " [0.74795848]\n",
      " [0.75468123]\n",
      " [0.76252335]\n",
      " [0.76999658]\n",
      " [0.77752739]\n",
      " [0.78469402]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.7919536]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[[0.7326749 ]\n",
      "  [0.74033219]\n",
      "  [0.74795848]\n",
      "  [0.75468123]\n",
      "  [0.76252335]\n",
      "  [0.76999658]\n",
      "  [0.77752739]\n",
      "  [0.78469402]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015935709234327078\n",
      "Predicción post entrenamiento : [[0.7914704]]\n",
      "PERDIDAAAA despues: 0.0015552248805761337\n",
      "loss en el callback: 0.006366738583892584, batch 101, lote_designado 1\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "ejemplar: [[0.74033219]\n",
      " [0.74795848]\n",
      " [0.75468123]\n",
      " [0.76252335]\n",
      " [0.76999658]\n",
      " [0.77752739]\n",
      " [0.78469402]\n",
      " [0.79195362]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.7983518]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[[0.74033219]\n",
      "  [0.74795848]\n",
      "  [0.75468123]\n",
      "  [0.76252335]\n",
      "  [0.76999658]\n",
      "  [0.77752739]\n",
      "  [0.78469402]\n",
      "  [0.79195362]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007841002196073532\n",
      "Predicción post entrenamiento : [[0.7975094]]\n",
      "PERDIDAAAA despues: 0.007692514918744564\n",
      "loss en el callback: 0.0200823787599802, batch 102, lote_designado 1\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "ejemplar: [[0.74795848]\n",
      " [0.75468123]\n",
      " [0.76252335]\n",
      " [0.76999658]\n",
      " [0.77752739]\n",
      " [0.78469402]\n",
      " [0.79195362]\n",
      " [0.79835182]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.80431783]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[[0.74795848]\n",
      "  [0.75468123]\n",
      "  [0.76252335]\n",
      "  [0.76999658]\n",
      "  [0.77752739]\n",
      "  [0.78469402]\n",
      "  [0.79195362]\n",
      "  [0.79835182]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012970427982509136\n",
      "Predicción post entrenamiento : [[0.8037567]]\n",
      "PERDIDAAAA despues: 0.012842933647334576\n",
      "loss en el callback: 0.010717520490288734, batch 103, lote_designado 1\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "ejemplar: [[0.75468123]\n",
      " [0.76252335]\n",
      " [0.76999658]\n",
      " [0.77752739]\n",
      " [0.78469402]\n",
      " [0.79195362]\n",
      " [0.79835182]\n",
      " [0.80431783]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.8104739]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[[0.75468123]\n",
      "  [0.76252335]\n",
      "  [0.76999658]\n",
      "  [0.77752739]\n",
      "  [0.78469402]\n",
      "  [0.79195362]\n",
      "  [0.79835182]\n",
      "  [0.80431783]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0031489101238548756\n",
      "Predicción post entrenamiento : [[0.8092628]]\n",
      "PERDIDAAAA despues: 0.0030144539196044207\n",
      "loss en el callback: 0.03691316768527031, batch 104, lote_designado 1\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "ejemplar: [[0.76252335]\n",
      " [0.76999658]\n",
      " [0.77752739]\n",
      " [0.78469402]\n",
      " [0.79195362]\n",
      " [0.79835182]\n",
      " [0.80431783]\n",
      " [0.81047392]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.81611633]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[[0.76252335]\n",
      "  [0.76999658]\n",
      "  [0.77752739]\n",
      "  [0.78469402]\n",
      "  [0.79195362]\n",
      "  [0.79835182]\n",
      "  [0.80431783]\n",
      "  [0.81047392]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00882014725357294\n",
      "Predicción post entrenamiento : [[0.8162117]]\n",
      "PERDIDAAAA despues: 0.008838069625198841\n",
      "loss en el callback: 0.0003411404904909432, batch 105, lote_designado 1\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "ejemplar: [[0.76999658]\n",
      " [0.77752739]\n",
      " [0.78469402]\n",
      " [0.79195362]\n",
      " [0.79835182]\n",
      " [0.80431783]\n",
      " [0.81047392]\n",
      " [0.81611633]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.8228466]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[[0.76999658]\n",
      "  [0.77752739]\n",
      "  [0.78469402]\n",
      "  [0.79195362]\n",
      "  [0.79835182]\n",
      "  [0.80431783]\n",
      "  [0.81047392]\n",
      "  [0.81611633]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006585262599401176\n",
      "Predicción post entrenamiento : [[0.8235755]]\n",
      "PERDIDAAAA despues: 0.0006216475740075111\n",
      "loss en el callback: 0.021230949088931084, batch 106, lote_designado 1\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "ejemplar: [[0.77752739]\n",
      " [0.78469402]\n",
      " [0.79195362]\n",
      " [0.79835182]\n",
      " [0.80431783]\n",
      " [0.81047392]\n",
      " [0.81611633]\n",
      " [0.82284659]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.8300302]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[[0.77752739]\n",
      "  [0.78469402]\n",
      "  [0.79195362]\n",
      "  [0.79835182]\n",
      "  [0.80431783]\n",
      "  [0.81047392]\n",
      "  [0.81611633]\n",
      "  [0.82284659]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005690103862434626\n",
      "Predicción post entrenamiento : [[0.8298477]]\n",
      "PERDIDAAAA despues: 0.005717671476304531\n",
      "loss en el callback: 0.0009150488767772913, batch 107, lote_designado 1\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "ejemplar: [[0.78469402]\n",
      " [0.79195362]\n",
      " [0.79835182]\n",
      " [0.80431783]\n",
      " [0.81047392]\n",
      " [0.81611633]\n",
      " [0.82284659]\n",
      " [0.8300302 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.8360467]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[[0.78469402]\n",
      "  [0.79195362]\n",
      "  [0.79835182]\n",
      "  [0.80431783]\n",
      "  [0.81047392]\n",
      "  [0.81611633]\n",
      "  [0.82284659]\n",
      "  [0.8300302 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002131624612957239\n",
      "Predicción post entrenamiento : [[0.83670884]]\n",
      "PERDIDAAAA despues: 0.0020709207747131586\n",
      "loss en el callback: 0.018125372007489204, batch 108, lote_designado 1\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "ejemplar: [[0.79195362]\n",
      " [0.79835182]\n",
      " [0.80431783]\n",
      " [0.81047392]\n",
      " [0.81611633]\n",
      " [0.82284659]\n",
      " [0.8300302 ]\n",
      " [0.8360467 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.8427082]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[[0.79195362]\n",
      "  [0.79835182]\n",
      "  [0.80431783]\n",
      "  [0.81047392]\n",
      "  [0.81611633]\n",
      "  [0.82284659]\n",
      "  [0.8300302 ]\n",
      "  [0.8360467 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004235342610627413\n",
      "Predicción post entrenamiento : [[0.84193206]]\n",
      "PERDIDAAAA despues: 0.004336962942034006\n",
      "loss en el callback: 0.014268893748521805, batch 109, lote_designado 1\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "ejemplar: [[0.79835182]\n",
      " [0.80431783]\n",
      " [0.81047392]\n",
      " [0.81611633]\n",
      " [0.82284659]\n",
      " [0.8300302 ]\n",
      " [0.8360467 ]\n",
      " [0.84270817]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.84766775]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[[0.79835182]\n",
      "  [0.80431783]\n",
      "  [0.81047392]\n",
      "  [0.81611633]\n",
      "  [0.82284659]\n",
      "  [0.8300302 ]\n",
      "  [0.8360467 ]\n",
      "  [0.84270817]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001756442477926612\n",
      "Predicción post entrenamiento : [[0.84717906]]\n",
      "PERDIDAAAA despues: 0.001797643955796957\n",
      "loss en el callback: 0.006088790949434042, batch 110, lote_designado 1\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "ejemplar: [[0.80431783]\n",
      " [0.81047392]\n",
      " [0.81611633]\n",
      " [0.82284659]\n",
      " [0.8300302 ]\n",
      " [0.8360467 ]\n",
      " [0.84270817]\n",
      " [0.84766775]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.85287577]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[[0.80431783]\n",
      "  [0.81047392]\n",
      "  [0.81611633]\n",
      "  [0.82284659]\n",
      "  [0.8300302 ]\n",
      "  [0.8360467 ]\n",
      "  [0.84270817]\n",
      "  [0.84766775]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00048307268298231065\n",
      "Predicción post entrenamiento : [[0.8529936]]\n",
      "PERDIDAAAA despues: 0.00047790666576474905\n",
      "loss en el callback: 0.00045680656330659986, batch 111, lote_designado 1\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "ejemplar: [[0.81047392]\n",
      " [0.81611633]\n",
      " [0.82284659]\n",
      " [0.8300302 ]\n",
      " [0.8360467 ]\n",
      " [0.84270817]\n",
      " [0.84766775]\n",
      " [0.85287577]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.8587712]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[[0.81047392]\n",
      "  [0.81611633]\n",
      "  [0.82284659]\n",
      "  [0.8300302 ]\n",
      "  [0.8360467 ]\n",
      "  [0.84270817]\n",
      "  [0.84766775]\n",
      "  [0.85287577]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029637939296662807\n",
      "Predicción post entrenamiento : [[0.8584181]]\n",
      "PERDIDAAAA despues: 0.003002364421263337\n",
      "loss en el callback: 0.0034905949141830206, batch 112, lote_designado 1\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "ejemplar: [[0.81611633]\n",
      " [0.82284659]\n",
      " [0.8300302 ]\n",
      " [0.8360467 ]\n",
      " [0.84270817]\n",
      " [0.84766775]\n",
      " [0.85287577]\n",
      " [0.8587712 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 1.0\n",
      "Predicción : [[0.8642159]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[[0.81611633]\n",
      "  [0.82284659]\n",
      "  [0.8300302 ]\n",
      "  [0.8360467 ]\n",
      "  [0.84270817]\n",
      "  [0.84766775]\n",
      "  [0.85287577]\n",
      "  [0.8587712 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01843731850385666\n",
      "Predicción post entrenamiento : [[0.8650703]]\n",
      "PERDIDAAAA despues: 0.018206028267741203\n",
      "loss en el callback: 0.02693459764122963, batch 113, lote_designado 1\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "ejemplar: [[0.82284659]\n",
      " [0.8300302 ]\n",
      " [0.8360467 ]\n",
      " [0.84270817]\n",
      " [0.84766775]\n",
      " [0.85287577]\n",
      " [0.8587712 ]\n",
      " [0.86421591]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.87102044]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[[0.82284659]\n",
      "  [0.8300302 ]\n",
      "  [0.8360467 ]\n",
      "  [0.84270817]\n",
      "  [0.84766775]\n",
      "  [0.85287577]\n",
      "  [0.8587712 ]\n",
      "  [0.86421591]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009906941093504429\n",
      "Predicción post entrenamiento : [[0.8725405]]\n",
      "PERDIDAAAA despues: 0.009606662206351757\n",
      "loss en el callback: 0.17645715177059174, batch 114, lote_designado 1\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "ejemplar: [[0.8300302 ]\n",
      " [0.8360467 ]\n",
      " [0.84270817]\n",
      " [0.84766775]\n",
      " [0.85287577]\n",
      " [0.8587712 ]\n",
      " [0.86421591]\n",
      " [0.87102044]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.87830806]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[[0.8300302 ]\n",
      "  [0.8360467 ]\n",
      "  [0.84270817]\n",
      "  [0.84766775]\n",
      "  [0.85287577]\n",
      "  [0.8587712 ]\n",
      "  [0.86421591]\n",
      "  [0.87102044]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00011013892071787268\n",
      "Predicción post entrenamiento : [[0.8788522]]\n",
      "PERDIDAAAA despues: 9.901400335365906e-05\n",
      "loss en el callback: 0.012872428633272648, batch 115, lote_designado 1\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "ejemplar: [[0.8360467 ]\n",
      " [0.84270817]\n",
      " [0.84766775]\n",
      " [0.85287577]\n",
      " [0.8587712 ]\n",
      " [0.86421591]\n",
      " [0.87102044]\n",
      " [0.87830806]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.88426125]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[[0.8360467 ]\n",
      "  [0.84270817]\n",
      "  [0.84766775]\n",
      "  [0.85287577]\n",
      "  [0.8587712 ]\n",
      "  [0.86421591]\n",
      "  [0.87102044]\n",
      "  [0.87830806]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.977757296524942e-05\n",
      "Predicción post entrenamiento : [[0.8837046]]\n",
      "PERDIDAAAA despues: 3.3065931347664446e-05\n",
      "loss en el callback: 0.009324075654149055, batch 116, lote_designado 1\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "ejemplar: [[0.84270817]\n",
      " [0.84766775]\n",
      " [0.85287577]\n",
      " [0.8587712 ]\n",
      " [0.86421591]\n",
      " [0.87102044]\n",
      " [0.87830806]\n",
      " [0.88426125]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.8890631]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[[0.84270817]\n",
      "  [0.84766775]\n",
      "  [0.85287577]\n",
      "  [0.8587712 ]\n",
      "  [0.86421591]\n",
      "  [0.87102044]\n",
      "  [0.87830806]\n",
      "  [0.88426125]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001613414497114718\n",
      "Predicción post entrenamiento : [[0.88895124]]\n",
      "PERDIDAAAA despues: 0.0016044393414631486\n",
      "loss en el callback: 0.00047848798567429185, batch 117, lote_designado 1\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "ejemplar: [[0.84766775]\n",
      " [0.85287577]\n",
      " [0.8587712 ]\n",
      " [0.86421591]\n",
      " [0.87102044]\n",
      " [0.87830806]\n",
      " [0.88426125]\n",
      " [0.88906312]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.89407456]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[[0.84766775]\n",
      "  [0.85287577]\n",
      "  [0.8587712 ]\n",
      "  [0.86421591]\n",
      "  [0.87102044]\n",
      "  [0.87830806]\n",
      "  [0.88426125]\n",
      "  [0.88906312]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0035882224328815937\n",
      "Predicción post entrenamiento : [[0.89298725]]\n",
      "PERDIDAAAA despues: 0.003459141356870532\n",
      "loss en el callback: 0.03265029564499855, batch 118, lote_designado 1\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "ejemplar: [[0.85287577]\n",
      " [0.8587712 ]\n",
      " [0.86421591]\n",
      " [0.87102044]\n",
      " [0.87830806]\n",
      " [0.88426125]\n",
      " [0.88906312]\n",
      " [0.89407456]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.8983687]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[[0.85287577]\n",
      "  [0.8587712 ]\n",
      "  [0.86421591]\n",
      "  [0.87102044]\n",
      "  [0.87830806]\n",
      "  [0.88426125]\n",
      "  [0.88906312]\n",
      "  [0.89407456]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018726222915574908\n",
      "Predicción post entrenamiento : [[0.898263]]\n",
      "PERDIDAAAA despues: 0.0018634820589795709\n",
      "loss en el callback: 0.0004072703595738858, batch 119, lote_designado 1\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "ejemplar: [[0.8587712 ]\n",
      " [0.86421591]\n",
      " [0.87102044]\n",
      " [0.87830806]\n",
      " [0.88426125]\n",
      " [0.88906312]\n",
      " [0.89407456]\n",
      " [0.89836872]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.90385705]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[[0.8587712 ]\n",
      "  [0.86421591]\n",
      "  [0.87102044]\n",
      "  [0.87830806]\n",
      "  [0.88426125]\n",
      "  [0.88906312]\n",
      "  [0.89407456]\n",
      "  [0.89836872]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008188112988136709\n",
      "Predicción post entrenamiento : [[0.90410614]]\n",
      "PERDIDAAAA despues: 0.0008331285789608955\n",
      "loss en el callback: 0.002610456198453903, batch 120, lote_designado 1\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "ejemplar: [[0.86421591]\n",
      " [0.87102044]\n",
      " [0.87830806]\n",
      " [0.88426125]\n",
      " [0.88906312]\n",
      " [0.89407456]\n",
      " [0.89836872]\n",
      " [0.90385705]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.90970755]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[[0.86421591]\n",
      "  [0.87102044]\n",
      "  [0.87830806]\n",
      "  [0.88426125]\n",
      "  [0.88906312]\n",
      "  [0.89407456]\n",
      "  [0.89836872]\n",
      "  [0.90385705]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002774694235995412\n",
      "Predicción post entrenamiento : [[0.9089971]]\n",
      "PERDIDAAAA despues: 0.002700354903936386\n",
      "loss en el callback: 0.01706068217754364, batch 121, lote_designado 1\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "ejemplar: [[0.87102044]\n",
      " [0.87830806]\n",
      " [0.88426125]\n",
      " [0.88906312]\n",
      " [0.89407456]\n",
      " [0.89836872]\n",
      " [0.90385705]\n",
      " [0.90970755]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.91470116]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[[0.87102044]\n",
      "  [0.87830806]\n",
      "  [0.88426125]\n",
      "  [0.88906312]\n",
      "  [0.89407456]\n",
      "  [0.89836872]\n",
      "  [0.90385705]\n",
      "  [0.90970755]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004178720526397228\n",
      "Predicción post entrenamiento : [[0.9141605]]\n",
      "PERDIDAAAA despues: 0.004109111614525318\n",
      "loss en el callback: 0.0095913615077734, batch 122, lote_designado 1\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "ejemplar: [[0.87830806]\n",
      " [0.88426125]\n",
      " [0.88906312]\n",
      " [0.89407456]\n",
      " [0.89836872]\n",
      " [0.90385705]\n",
      " [0.90970755]\n",
      " [0.91470116]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.91952646]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[[0.87830806]\n",
      "  [0.88426125]\n",
      "  [0.88906312]\n",
      "  [0.89407456]\n",
      "  [0.89836872]\n",
      "  [0.90385705]\n",
      "  [0.90970755]\n",
      "  [0.91470116]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005902825854718685\n",
      "Predicción post entrenamiento : [[0.9186487]]\n",
      "PERDIDAAAA despues: 0.0057687233202159405\n",
      "loss en el callback: 0.02561420015990734, batch 123, lote_designado 1\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "ejemplar: [[0.88426125]\n",
      " [0.88906312]\n",
      " [0.89407456]\n",
      " [0.89836872]\n",
      " [0.90385705]\n",
      " [0.90970755]\n",
      " [0.91470116]\n",
      " [0.91952646]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.9234512]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[[0.88426125]\n",
      "  [0.88906312]\n",
      "  [0.89407456]\n",
      "  [0.89836872]\n",
      "  [0.90385705]\n",
      "  [0.90970755]\n",
      "  [0.91470116]\n",
      "  [0.91952646]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010103135369718075\n",
      "Predicción post entrenamiento : [[0.9237046]]\n",
      "PERDIDAAAA despues: 0.010154147632420063\n",
      "loss en el callback: 0.0035555565264075994, batch 124, lote_designado 1\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "ejemplar: [[0.88906312]\n",
      " [0.89407456]\n",
      " [0.89836872]\n",
      " [0.90385705]\n",
      " [0.90970755]\n",
      " [0.91470116]\n",
      " [0.91952646]\n",
      " [0.92345119]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.9282554]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[[0.88906312]\n",
      "  [0.89407456]\n",
      "  [0.89836872]\n",
      "  [0.90385705]\n",
      "  [0.90970755]\n",
      "  [0.91470116]\n",
      "  [0.91952646]\n",
      "  [0.92345119]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.023638861253857613\n",
      "Predicción post entrenamiento : [[0.9262875]]\n",
      "PERDIDAAAA despues: 0.023037604987621307\n",
      "loss en el callback: 0.11151335388422012, batch 125, lote_designado 1\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "ejemplar: [[0.89407456]\n",
      " [0.89836872]\n",
      " [0.90385705]\n",
      " [0.90970755]\n",
      " [0.91470116]\n",
      " [0.91952646]\n",
      " [0.92345119]\n",
      " [0.92825538]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.93089074]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[[0.89407456]\n",
      "  [0.89836872]\n",
      "  [0.90385705]\n",
      "  [0.90970755]\n",
      "  [0.91470116]\n",
      "  [0.91952646]\n",
      "  [0.92345119]\n",
      "  [0.92825538]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.021520476788282394\n",
      "Predicción post entrenamiento : [[0.9296981]]\n",
      "PERDIDAAAA despues: 0.02117198519408703\n",
      "loss en el callback: 0.04725799709558487, batch 126, lote_designado 1\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "ejemplar: [[0.89836872]\n",
      " [0.90385705]\n",
      " [0.90970755]\n",
      " [0.91470116]\n",
      " [0.91952646]\n",
      " [0.92345119]\n",
      " [0.92825538]\n",
      " [0.93089074]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.9342795]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[[0.89836872]\n",
      "  [0.90385705]\n",
      "  [0.90970755]\n",
      "  [0.91470116]\n",
      "  [0.91952646]\n",
      "  [0.92345119]\n",
      "  [0.92825538]\n",
      "  [0.93089074]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00555549468845129\n",
      "Predicción post entrenamiento : [[0.9339211]]\n",
      "PERDIDAAAA despues: 0.005502196028828621\n",
      "loss en el callback: 0.004869372118264437, batch 127, lote_designado 1\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "ejemplar: [[0.90385705]\n",
      " [0.90970755]\n",
      " [0.91470116]\n",
      " [0.91952646]\n",
      " [0.92345119]\n",
      " [0.92825538]\n",
      " [0.93089074]\n",
      " [0.9342795 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.93865556]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[[0.90385705]\n",
      "  [0.90970755]\n",
      "  [0.91470116]\n",
      "  [0.91952646]\n",
      "  [0.92345119]\n",
      "  [0.92825538]\n",
      "  [0.93089074]\n",
      "  [0.9342795 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007112477440387011\n",
      "Predicción post entrenamiento : [[0.9375223]]\n",
      "PERDIDAAAA despues: 0.006922613363713026\n",
      "loss en el callback: 0.04111426696181297, batch 128, lote_designado 1\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "ejemplar: [[0.90970755]\n",
      " [0.91470116]\n",
      " [0.91952646]\n",
      " [0.92345119]\n",
      " [0.92825538]\n",
      " [0.93089074]\n",
      " [0.9342795 ]\n",
      " [0.93865556]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.9420176]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[[0.90970755]\n",
      "  [0.91470116]\n",
      "  [0.91952646]\n",
      "  [0.92345119]\n",
      "  [0.92825538]\n",
      "  [0.93089074]\n",
      "  [0.9342795 ]\n",
      "  [0.93865556]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01105288416147232\n",
      "Predicción post entrenamiento : [[0.94123125]]\n",
      "PERDIDAAAA despues: 0.010888157412409782\n",
      "loss en el callback: 0.02466161735355854, batch 129, lote_designado 1\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "ejemplar: [[0.91470116]\n",
      " [0.91952646]\n",
      " [0.92345119]\n",
      " [0.92825538]\n",
      " [0.93089074]\n",
      " [0.9342795 ]\n",
      " [0.93865556]\n",
      " [0.94201761]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.9452945]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[[0.91470116]\n",
      "  [0.91952646]\n",
      "  [0.92345119]\n",
      "  [0.92825538]\n",
      "  [0.93089074]\n",
      "  [0.9342795 ]\n",
      "  [0.93865556]\n",
      "  [0.94201761]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013313381001353264\n",
      "Predicción post entrenamiento : [[0.94496113]]\n",
      "PERDIDAAAA despues: 0.01323656179010868\n",
      "loss en el callback: 0.004490505903959274, batch 130, lote_designado 1\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "ejemplar: [[0.91952646]\n",
      " [0.92345119]\n",
      " [0.92825538]\n",
      " [0.93089074]\n",
      " [0.9342795 ]\n",
      " [0.93865556]\n",
      " [0.94201761]\n",
      " [0.9452945 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.9487506]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[[0.91952646]\n",
      "  [0.92345119]\n",
      "  [0.92825538]\n",
      "  [0.93089074]\n",
      "  [0.9342795 ]\n",
      "  [0.93865556]\n",
      "  [0.94201761]\n",
      "  [0.9452945 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0037819582503288984\n",
      "Predicción post entrenamiento : [[0.9491725]]\n",
      "PERDIDAAAA despues: 0.003834025701507926\n",
      "loss en el callback: 0.01007833518087864, batch 131, lote_designado 1\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "ejemplar: [[0.92345119]\n",
      " [0.92825538]\n",
      " [0.93089074]\n",
      " [0.9342795 ]\n",
      " [0.93865556]\n",
      " [0.94201761]\n",
      " [0.9452945 ]\n",
      " [0.94875062]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.9526738]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[[0.92345119]\n",
      "  [0.92825538]\n",
      "  [0.93089074]\n",
      "  [0.9342795 ]\n",
      "  [0.93865556]\n",
      "  [0.94201761]\n",
      "  [0.9452945 ]\n",
      "  [0.94875062]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008635888807475567\n",
      "Predicción post entrenamiento : [[0.95163625]]\n",
      "PERDIDAAAA despues: 0.00844412948936224\n",
      "loss en el callback: 0.039486028254032135, batch 132, lote_designado 1\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "ejemplar: [[0.92825538]\n",
      " [0.93089074]\n",
      " [0.9342795 ]\n",
      " [0.93865556]\n",
      " [0.94201761]\n",
      " [0.9452945 ]\n",
      " [0.94875062]\n",
      " [0.95267379]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.95506305]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[[0.92825538]\n",
      "  [0.93089074]\n",
      "  [0.9342795 ]\n",
      "  [0.93865556]\n",
      "  [0.94201761]\n",
      "  [0.9452945 ]\n",
      "  [0.94875062]\n",
      "  [0.95267379]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013332396745681763\n",
      "Predicción post entrenamiento : [[0.9552885]]\n",
      "PERDIDAAAA despues: 0.013384519144892693\n",
      "loss en el callback: 0.0027765845879912376, batch 133, lote_designado 1\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "ejemplar: [[0.93089074]\n",
      " [0.9342795 ]\n",
      " [0.93865556]\n",
      " [0.94201761]\n",
      " [0.9452945 ]\n",
      " [0.94875062]\n",
      " [0.95267379]\n",
      " [0.95506305]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.95835716]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[[0.93089074]\n",
      "  [0.9342795 ]\n",
      "  [0.93865556]\n",
      "  [0.94201761]\n",
      "  [0.9452945 ]\n",
      "  [0.94875062]\n",
      "  [0.95267379]\n",
      "  [0.95506305]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03046855516731739\n",
      "Predicción post entrenamiento : [[0.95690286]]\n",
      "PERDIDAAAA despues: 0.029962968081235886\n",
      "loss en el callback: 0.07933203130960464, batch 134, lote_designado 1\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "ejemplar: [[0.9342795 ]\n",
      " [0.93865556]\n",
      " [0.94201761]\n",
      " [0.9452945 ]\n",
      " [0.94875062]\n",
      " [0.95267379]\n",
      " [0.95506305]\n",
      " [0.95835716]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.96020764]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[[0.9342795 ]\n",
      "  [0.93865556]\n",
      "  [0.94201761]\n",
      "  [0.9452945 ]\n",
      "  [0.94875062]\n",
      "  [0.95267379]\n",
      "  [0.95506305]\n",
      "  [0.95835716]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.020141329616308212\n",
      "Predicción post entrenamiento : [[0.958486]]\n",
      "PERDIDAAAA despues: 0.019655628129839897\n",
      "loss en el callback: 0.10108015686273575, batch 135, lote_designado 1\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "ejemplar: [[0.93865556]\n",
      " [0.94201761]\n",
      " [0.9452945 ]\n",
      " [0.94875062]\n",
      " [0.95267379]\n",
      " [0.95506305]\n",
      " [0.95835716]\n",
      " [0.96020764]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.9618123]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[[0.93865556]\n",
      "  [0.94201761]\n",
      "  [0.9452945 ]\n",
      "  [0.94875062]\n",
      "  [0.95267379]\n",
      "  [0.95506305]\n",
      "  [0.95835716]\n",
      "  [0.96020764]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.029120102524757385\n",
      "Predicción post entrenamiento : [[0.9609436]]\n",
      "PERDIDAAAA despues: 0.02882436290383339\n",
      "loss en el callback: 0.030444130301475525, batch 136, lote_designado 1\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "ejemplar: [[0.94201761]\n",
      " [0.9452945 ]\n",
      " [0.94875062]\n",
      " [0.95267379]\n",
      " [0.95506305]\n",
      " [0.95835716]\n",
      " [0.96020764]\n",
      " [0.96181232]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.96396166]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[[0.94201761]\n",
      "  [0.9452945 ]\n",
      "  [0.94875062]\n",
      "  [0.95267379]\n",
      "  [0.95506305]\n",
      "  [0.95835716]\n",
      "  [0.96020764]\n",
      "  [0.96181232]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04137307032942772\n",
      "Predicción post entrenamiento : [[0.9626325]]\n",
      "PERDIDAAAA despues: 0.04083411395549774\n",
      "loss en el callback: 0.07088783383369446, batch 137, lote_designado 1\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "ejemplar: [[0.9452945 ]\n",
      " [0.94875062]\n",
      " [0.95267379]\n",
      " [0.95506305]\n",
      " [0.95835716]\n",
      " [0.96020764]\n",
      " [0.96181232]\n",
      " [0.96396166]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.96556455]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[[0.9452945 ]\n",
      "  [0.94875062]\n",
      "  [0.95267379]\n",
      "  [0.95506305]\n",
      "  [0.95835716]\n",
      "  [0.96020764]\n",
      "  [0.96181232]\n",
      "  [0.96396166]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03027978353202343\n",
      "Predicción post entrenamiento : [[0.96527743]]\n",
      "PERDIDAAAA despues: 0.0301799438893795\n",
      "loss en el callback: 0.004765032324939966, batch 138, lote_designado 1\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "ejemplar: [[0.94875062]\n",
      " [0.95267379]\n",
      " [0.95506305]\n",
      " [0.95835716]\n",
      " [0.96020764]\n",
      " [0.96181232]\n",
      " [0.96396166]\n",
      " [0.96556455]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9680918]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[[0.94875062]\n",
      "  [0.95267379]\n",
      "  [0.95506305]\n",
      "  [0.95835716]\n",
      "  [0.96020764]\n",
      "  [0.96181232]\n",
      "  [0.96396166]\n",
      "  [0.96556455]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03975936397910118\n",
      "Predicción post entrenamiento : [[0.9678964]]\n",
      "PERDIDAAAA despues: 0.039681483060121536\n",
      "loss en el callback: 0.0023025046102702618, batch 139, lote_designado 1\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "ejemplar: [[0.95267379]\n",
      " [0.95506305]\n",
      " [0.95835716]\n",
      " [0.96020764]\n",
      " [0.96181232]\n",
      " [0.96396166]\n",
      " [0.96556455]\n",
      " [0.96809179]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.97047704]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[[0.95267379]\n",
      "  [0.95506305]\n",
      "  [0.95835716]\n",
      "  [0.96020764]\n",
      "  [0.96181232]\n",
      "  [0.96396166]\n",
      "  [0.96556455]\n",
      "  [0.96809179]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04071628302335739\n",
      "Predicción post entrenamiento : [[0.97024035]]\n",
      "PERDIDAAAA despues: 0.040620818734169006\n",
      "loss en el callback: 0.003333477769047022, batch 140, lote_designado 1\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "ejemplar: [[0.95506305]\n",
      " [0.95835716]\n",
      " [0.96020764]\n",
      " [0.96181232]\n",
      " [0.96396166]\n",
      " [0.96556455]\n",
      " [0.96809179]\n",
      " [0.97047704]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.9723796]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[[0.95506305]\n",
      "  [0.95835716]\n",
      "  [0.96020764]\n",
      "  [0.96181232]\n",
      "  [0.96396166]\n",
      "  [0.96556455]\n",
      "  [0.96809179]\n",
      "  [0.97047704]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03008992411196232\n",
      "Predicción post entrenamiento : [[0.97172517]]\n",
      "PERDIDAAAA despues: 0.029863301664590836\n",
      "loss en el callback: 0.019770847633481026, batch 141, lote_designado 1\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "ejemplar: [[0.95835716]\n",
      " [0.96020764]\n",
      " [0.96181232]\n",
      " [0.96396166]\n",
      " [0.96556455]\n",
      " [0.96809179]\n",
      " [0.97047704]\n",
      " [0.97237962]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.97380304]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[[0.95835716]\n",
      "  [0.96020764]\n",
      "  [0.96181232]\n",
      "  [0.96396166]\n",
      "  [0.96556455]\n",
      "  [0.96809179]\n",
      "  [0.97047704]\n",
      "  [0.97237962]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03378212824463844\n",
      "Predicción post entrenamiento : [[0.97342396]]\n",
      "PERDIDAAAA despues: 0.03364291787147522\n",
      "loss en el callback: 0.008270842023193836, batch 142, lote_designado 1\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "ejemplar: [[0.96020764]\n",
      " [0.96181232]\n",
      " [0.96396166]\n",
      " [0.96556455]\n",
      " [0.96809179]\n",
      " [0.97047704]\n",
      " [0.97237962]\n",
      " [0.97380304]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.97515124]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[[0.96020764]\n",
      "  [0.96181232]\n",
      "  [0.96396166]\n",
      "  [0.96556455]\n",
      "  [0.96809179]\n",
      "  [0.97047704]\n",
      "  [0.97237962]\n",
      "  [0.97380304]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04621673747897148\n",
      "Predicción post entrenamiento : [[0.9747878]]\n",
      "PERDIDAAAA despues: 0.04606059193611145\n",
      "loss en el callback: 0.008174699731171131, batch 143, lote_designado 1\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "ejemplar: [[0.96181232]\n",
      " [0.96396166]\n",
      " [0.96556455]\n",
      " [0.96809179]\n",
      " [0.97047704]\n",
      " [0.97237962]\n",
      " [0.97380304]\n",
      " [0.97515124]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.9765454]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[[0.96181232]\n",
      "  [0.96396166]\n",
      "  [0.96556455]\n",
      "  [0.96809179]\n",
      "  [0.97047704]\n",
      "  [0.97237962]\n",
      "  [0.97380304]\n",
      "  [0.97515124]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08476955443620682\n",
      "Predicción post entrenamiento : [[0.97534496]]\n",
      "PERDIDAAAA despues: 0.08407197892665863\n",
      "loss en el callback: 0.07285793125629425, batch 144, lote_designado 1\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "ejemplar: [[0.96396166]\n",
      " [0.96556455]\n",
      " [0.96809179]\n",
      " [0.97047704]\n",
      " [0.97237962]\n",
      " [0.97380304]\n",
      " [0.97515124]\n",
      " [0.97654539]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.9772044]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[[0.96396166]\n",
      "  [0.96556455]\n",
      "  [0.96809179]\n",
      "  [0.97047704]\n",
      "  [0.97237962]\n",
      "  [0.97380304]\n",
      "  [0.97515124]\n",
      "  [0.97654539]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13839338719844818\n",
      "Predicción post entrenamiento : [[0.9744809]]\n",
      "PERDIDAAAA despues: 0.13637448847293854\n",
      "loss en el callback: 0.26207590103149414, batch 145, lote_designado 1\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "ejemplar: [[0.96556455]\n",
      " [0.96809179]\n",
      " [0.97047704]\n",
      " [0.97237962]\n",
      " [0.97380304]\n",
      " [0.97515124]\n",
      " [0.97654539]\n",
      " [0.97720438]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9762705]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[[0.96556455]\n",
      "  [0.96809179]\n",
      "  [0.97047704]\n",
      "  [0.97237962]\n",
      "  [0.97380304]\n",
      "  [0.97515124]\n",
      "  [0.97654539]\n",
      "  [0.97720438]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09697738289833069\n",
      "Predicción post entrenamiento : [[0.97482777]]\n",
      "PERDIDAAAA despues: 0.09608089923858643\n",
      "loss en el callback: 0.10379981994628906, batch 146, lote_designado 1\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "ejemplar: [[0.96809179]\n",
      " [0.97047704]\n",
      " [0.97237962]\n",
      " [0.97380304]\n",
      " [0.97515124]\n",
      " [0.97654539]\n",
      " [0.97720438]\n",
      " [0.9762705 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.9766614]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[[0.96809179]\n",
      "  [0.97047704]\n",
      "  [0.97237962]\n",
      "  [0.97380304]\n",
      "  [0.97515124]\n",
      "  [0.97654539]\n",
      "  [0.97720438]\n",
      "  [0.9762705 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07225140184164047\n",
      "Predicción post entrenamiento : [[0.9758454]]\n",
      "PERDIDAAAA despues: 0.07181339710950851\n",
      "loss en el callback: 0.04144950956106186, batch 147, lote_designado 1\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "ejemplar: [[0.97047704]\n",
      " [0.97237962]\n",
      " [0.97380304]\n",
      " [0.97515124]\n",
      " [0.97654539]\n",
      " [0.97720438]\n",
      " [0.9762705 ]\n",
      " [0.97666138]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.97739655]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[[0.97047704]\n",
      "  [0.97237962]\n",
      "  [0.97380304]\n",
      "  [0.97515124]\n",
      "  [0.97654539]\n",
      "  [0.97720438]\n",
      "  [0.9762705 ]\n",
      "  [0.97666138]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0976799800992012\n",
      "Predicción post entrenamiento : [[0.9766058]]\n",
      "PERDIDAAAA despues: 0.09718631207942963\n",
      "loss en el callback: 0.03853052109479904, batch 148, lote_designado 1\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "ejemplar: [[0.97237962]\n",
      " [0.97380304]\n",
      " [0.97515124]\n",
      " [0.97654539]\n",
      " [0.97720438]\n",
      " [0.9762705 ]\n",
      " [0.97666138]\n",
      " [0.97739655]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.97782236]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[[0.97237962]\n",
      "  [0.97380304]\n",
      "  [0.97515124]\n",
      "  [0.97654539]\n",
      "  [0.97720438]\n",
      "  [0.9762705 ]\n",
      "  [0.97666138]\n",
      "  [0.97739655]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07100636512041092\n",
      "Predicción post entrenamiento : [[0.9769375]]\n",
      "PERDIDAAAA despues: 0.0705355554819107\n",
      "loss en el callback: 0.04383710026741028, batch 149, lote_designado 1\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "ejemplar: [[0.97380304]\n",
      " [0.97515124]\n",
      " [0.97654539]\n",
      " [0.97720438]\n",
      " [0.9762705 ]\n",
      " [0.97666138]\n",
      " [0.97739655]\n",
      " [0.97782236]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.9778718]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[[0.97380304]\n",
      "  [0.97515124]\n",
      "  [0.97654539]\n",
      "  [0.97720438]\n",
      "  [0.9762705 ]\n",
      "  [0.97666138]\n",
      "  [0.97739655]\n",
      "  [0.97782236]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.090369313955307\n",
      "Predicción post entrenamiento : [[0.9767571]]\n",
      "PERDIDAAAA despues: 0.08970038592815399\n",
      "loss en el callback: 0.06681974232196808, batch 150, lote_designado 1\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "ejemplar: [[0.97515124]\n",
      " [0.97654539]\n",
      " [0.97720438]\n",
      " [0.9762705 ]\n",
      " [0.97666138]\n",
      " [0.97739655]\n",
      " [0.97782236]\n",
      " [0.97787178]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.9774768]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[[0.97515124]\n",
      "  [0.97654539]\n",
      "  [0.97720438]\n",
      "  [0.9762705 ]\n",
      "  [0.97666138]\n",
      "  [0.97739655]\n",
      "  [0.97782236]\n",
      "  [0.97787178]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.046383824199438095\n",
      "Predicción post entrenamiento : [[0.97731286]]\n",
      "PERDIDAAAA despues: 0.046313248574733734\n",
      "loss en el callback: 0.001881960779428482, batch 151, lote_designado 1\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "ejemplar: [[0.97654539]\n",
      " [0.97720438]\n",
      " [0.9762705 ]\n",
      " [0.97666138]\n",
      " [0.97739655]\n",
      " [0.97782236]\n",
      " [0.97787178]\n",
      " [0.97747678]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.97778136]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[[0.97654539]\n",
      "  [0.97720438]\n",
      "  [0.9762705 ]\n",
      "  [0.97666138]\n",
      "  [0.97739655]\n",
      "  [0.97782236]\n",
      "  [0.97787178]\n",
      "  [0.97747678]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02914866991341114\n",
      "Predicción post entrenamiento : [[0.9773495]]\n",
      "PERDIDAAAA despues: 0.029001401737332344\n",
      "loss en el callback: 0.010441325604915619, batch 152, lote_designado 1\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "ejemplar: [[0.97720438]\n",
      " [0.9762705 ]\n",
      " [0.97666138]\n",
      " [0.97739655]\n",
      " [0.97782236]\n",
      " [0.97787178]\n",
      " [0.97747678]\n",
      " [0.97778136]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.97750145]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[[0.97720438]\n",
      "  [0.9762705 ]\n",
      "  [0.97666138]\n",
      "  [0.97739655]\n",
      "  [0.97782236]\n",
      "  [0.97787178]\n",
      "  [0.97747678]\n",
      "  [0.97778136]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02634567953646183\n",
      "Predicción post entrenamiento : [[0.97688216]]\n",
      "PERDIDAAAA despues: 0.026145024225115776\n",
      "loss en el callback: 0.019274117425084114, batch 153, lote_designado 1\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "ejemplar: [[0.9762705 ]\n",
      " [0.97666138]\n",
      " [0.97739655]\n",
      " [0.97782236]\n",
      " [0.97787178]\n",
      " [0.97747678]\n",
      " [0.97778136]\n",
      " [0.97750145]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.97688895]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[[0.9762705 ]\n",
      "  [0.97666138]\n",
      "  [0.97739655]\n",
      "  [0.97782236]\n",
      "  [0.97787178]\n",
      "  [0.97747678]\n",
      "  [0.97778136]\n",
      "  [0.97750145]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004991571418941021\n",
      "Predicción post entrenamiento : [[0.97676677]]\n",
      "PERDIDAAAA despues: 0.004974320996552706\n",
      "loss en el callback: 0.0008542499854229391, batch 154, lote_designado 1\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "ejemplar: [[0.97666138]\n",
      " [0.97739655]\n",
      " [0.97782236]\n",
      " [0.97787178]\n",
      " [0.97747678]\n",
      " [0.97778136]\n",
      " [0.97750145]\n",
      " [0.97688895]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.97707796]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[[0.97666138]\n",
      "  [0.97739655]\n",
      "  [0.97782236]\n",
      "  [0.97787178]\n",
      "  [0.97747678]\n",
      "  [0.97778136]\n",
      "  [0.97750145]\n",
      "  [0.97688895]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00030180130852386355\n",
      "Predicción post entrenamiento : [[0.9771257]]\n",
      "PERDIDAAAA despues: 0.00030346240964718163\n",
      "loss en el callback: 0.0001369075325783342, batch 155, lote_designado 1\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "ejemplar: [[0.97739655]\n",
      " [0.97782236]\n",
      " [0.97787178]\n",
      " [0.97747678]\n",
      " [0.97778136]\n",
      " [0.97750145]\n",
      " [0.97688895]\n",
      " [0.97707796]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.97737026]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[[0.97739655]\n",
      "  [0.97782236]\n",
      "  [0.97787178]\n",
      "  [0.97747678]\n",
      "  [0.97778136]\n",
      "  [0.97750145]\n",
      "  [0.97688895]\n",
      "  [0.97707796]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00016940035857260227\n",
      "Predicción post entrenamiento : [[0.97718966]]\n",
      "PERDIDAAAA despues: 0.00016473176947329193\n",
      "loss en el callback: 0.001801209058612585, batch 156, lote_designado 1\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "ejemplar: [[0.97782236]\n",
      " [0.97787178]\n",
      " [0.97747678]\n",
      " [0.97778136]\n",
      " [0.97750145]\n",
      " [0.97688895]\n",
      " [0.97707796]\n",
      " [0.97737026]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.9772385]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[[0.97782236]\n",
      "  [0.97787178]\n",
      "  [0.97747678]\n",
      "  [0.97778136]\n",
      "  [0.97750145]\n",
      "  [0.97688895]\n",
      "  [0.97707796]\n",
      "  [0.97737026]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00795852579176426\n",
      "Predicción post entrenamiento : [[0.97724783]]\n",
      "PERDIDAAAA despues: 0.007960195653140545\n",
      "loss en el callback: 5.7390425354242325e-06, batch 157, lote_designado 1\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "ejemplar: [[0.97787178]\n",
      " [0.97747678]\n",
      " [0.97778136]\n",
      " [0.97750145]\n",
      " [0.97688895]\n",
      " [0.97707796]\n",
      " [0.97737026]\n",
      " [0.97723848]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.97715884]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[[0.97787178]\n",
      "  [0.97747678]\n",
      "  [0.97778136]\n",
      "  [0.97750145]\n",
      "  [0.97688895]\n",
      "  [0.97707796]\n",
      "  [0.97737026]\n",
      "  [0.97723848]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00713714025914669\n",
      "Predicción post entrenamiento : [[0.97646576]]\n",
      "PERDIDAAAA despues: 0.00702051492407918\n",
      "loss en el callback: 0.022766511887311935, batch 158, lote_designado 1\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "ejemplar: [[0.97747678]\n",
      " [0.97778136]\n",
      " [0.97750145]\n",
      " [0.97688895]\n",
      " [0.97707796]\n",
      " [0.97737026]\n",
      " [0.97723848]\n",
      " [0.97715884]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.97633344]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[[0.97747678]\n",
      "  [0.97778136]\n",
      "  [0.97750145]\n",
      "  [0.97688895]\n",
      "  [0.97707796]\n",
      "  [0.97737026]\n",
      "  [0.97723848]\n",
      "  [0.97715884]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010219443589448929\n",
      "Predicción post entrenamiento : [[0.97587407]]\n",
      "PERDIDAAAA despues: 0.010126777924597263\n",
      "loss en el callback: 0.012039483524858952, batch 159, lote_designado 1\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "ejemplar: [[0.97778136]\n",
      " [0.97750145]\n",
      " [0.97688895]\n",
      " [0.97707796]\n",
      " [0.97737026]\n",
      " [0.97723848]\n",
      " [0.97715884]\n",
      " [0.97633344]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.9758236]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[[0.97778136]\n",
      "  [0.97750145]\n",
      "  [0.97688895]\n",
      "  [0.97707796]\n",
      "  [0.97737026]\n",
      "  [0.97723848]\n",
      "  [0.97715884]\n",
      "  [0.97633344]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015622645616531372\n",
      "Predicción post entrenamiento : [[0.9758784]]\n",
      "PERDIDAAAA despues: 0.01563635654747486\n",
      "loss en el callback: 0.00020226601918693632, batch 160, lote_designado 1\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "ejemplar: [[0.97750145]\n",
      " [0.97688895]\n",
      " [0.97707796]\n",
      " [0.97737026]\n",
      " [0.97723848]\n",
      " [0.97715884]\n",
      " [0.97633344]\n",
      " [0.97582358]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.9757082]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[[0.97750145]\n",
      "  [0.97688895]\n",
      "  [0.97707796]\n",
      "  [0.97737026]\n",
      "  [0.97723848]\n",
      "  [0.97715884]\n",
      "  [0.97633344]\n",
      "  [0.97582358]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01608138531446457\n",
      "Predicción post entrenamiento : [[0.97535616]]\n",
      "PERDIDAAAA despues: 0.01599222607910633\n",
      "loss en el callback: 0.007814413867890835, batch 161, lote_designado 1\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "ejemplar: [[0.97688895]\n",
      " [0.97707796]\n",
      " [0.97737026]\n",
      " [0.97723848]\n",
      " [0.97715884]\n",
      " [0.97633344]\n",
      " [0.97582358]\n",
      " [0.97570819]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.97521925]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[[0.97688895]\n",
      "  [0.97707796]\n",
      "  [0.97737026]\n",
      "  [0.97723848]\n",
      "  [0.97715884]\n",
      "  [0.97633344]\n",
      "  [0.97582358]\n",
      "  [0.97570819]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00016388064250349998\n",
      "Predicción post entrenamiento : [[0.9754503]]\n",
      "PERDIDAAAA despues: 0.00016984905232675374\n",
      "loss en el callback: 0.0035210163332521915, batch 162, lote_designado 1\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "ejemplar: [[0.97707796]\n",
      " [0.97737026]\n",
      " [0.97723848]\n",
      " [0.97715884]\n",
      " [0.97633344]\n",
      " [0.97582358]\n",
      " [0.97570819]\n",
      " [0.97521925]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.97544086]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[[0.97707796]\n",
      "  [0.97737026]\n",
      "  [0.97723848]\n",
      "  [0.97715884]\n",
      "  [0.97633344]\n",
      "  [0.97582358]\n",
      "  [0.97570819]\n",
      "  [0.97521925]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.774383680545725e-05\n",
      "Predicción post entrenamiento : [[0.975881]]\n",
      "PERDIDAAAA despues: 6.462643796112388e-05\n",
      "loss en el callback: 0.015959665179252625, batch 163, lote_designado 1\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "ejemplar: [[0.97737026]\n",
      " [0.97723848]\n",
      " [0.97715884]\n",
      " [0.97633344]\n",
      " [0.97582358]\n",
      " [0.97570819]\n",
      " [0.97521925]\n",
      " [0.97544086]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.975764]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[[0.97737026]\n",
      "  [0.97723848]\n",
      "  [0.97715884]\n",
      "  [0.97633344]\n",
      "  [0.97582358]\n",
      "  [0.97570819]\n",
      "  [0.97521925]\n",
      "  [0.97544086]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012280328664928675\n",
      "Predicción post entrenamiento : [[0.9742006]]\n",
      "PERDIDAAAA despues: 0.0011209056247025728\n",
      "loss en el callback: 0.09760984033346176, batch 164, lote_designado 1\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "ejemplar: [[0.97723848]\n",
      " [0.97715884]\n",
      " [0.97633344]\n",
      " [0.97582358]\n",
      " [0.97570819]\n",
      " [0.97521925]\n",
      " [0.97544086]\n",
      " [0.97576398]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.97392684]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[[0.97723848]\n",
      "  [0.97715884]\n",
      "  [0.97633344]\n",
      "  [0.97582358]\n",
      "  [0.97570819]\n",
      "  [0.97521925]\n",
      "  [0.97544086]\n",
      "  [0.97576398]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.0608838440239197e-06\n",
      "Predicción post entrenamiento : [[0.97419]]\n",
      "PERDIDAAAA despues: 2.885691628762288e-06\n",
      "loss en el callback: 0.005497528240084648, batch 165, lote_designado 1\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "ejemplar: [[0.97715884]\n",
      " [0.97633344]\n",
      " [0.97582358]\n",
      " [0.97570819]\n",
      " [0.97521925]\n",
      " [0.97544086]\n",
      " [0.97576398]\n",
      " [0.97392684]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.97386056]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[[0.97715884]\n",
      "  [0.97633344]\n",
      "  [0.97582358]\n",
      "  [0.97570819]\n",
      "  [0.97521925]\n",
      "  [0.97544086]\n",
      "  [0.97576398]\n",
      "  [0.97392684]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005308359395712614\n",
      "Predicción post entrenamiento : [[0.9742085]]\n",
      "PERDIDAAAA despues: 0.0005149252829141915\n",
      "loss en el callback: 0.008710749447345734, batch 166, lote_designado 1\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "ejemplar: [[0.97633344]\n",
      " [0.97582358]\n",
      " [0.97570819]\n",
      " [0.97521925]\n",
      " [0.97544086]\n",
      " [0.97576398]\n",
      " [0.97392684]\n",
      " [0.97386056]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.973802]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[[0.97633344]\n",
      "  [0.97582358]\n",
      "  [0.97570819]\n",
      "  [0.97521925]\n",
      "  [0.97544086]\n",
      "  [0.97576398]\n",
      "  [0.97392684]\n",
      "  [0.97386056]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005116761894896626\n",
      "Predicción post entrenamiento : [[0.973812]]\n",
      "PERDIDAAAA despues: 0.000512129336129874\n",
      "loss en el callback: 6.398681307473453e-06, batch 167, lote_designado 1\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "ejemplar: [[0.97582358]\n",
      " [0.97570819]\n",
      " [0.97521925]\n",
      " [0.97544086]\n",
      " [0.97576398]\n",
      " [0.97392684]\n",
      " [0.97386056]\n",
      " [0.97380197]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.9735436]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[[0.97582358]\n",
      "  [0.97570819]\n",
      "  [0.97521925]\n",
      "  [0.97544086]\n",
      "  [0.97576398]\n",
      "  [0.97392684]\n",
      "  [0.97386056]\n",
      "  [0.97380197]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006047671660780907\n",
      "Predicción post entrenamiento : [[0.97326094]]\n",
      "PERDIDAAAA despues: 0.006003790535032749\n",
      "loss en el callback: 0.005428634583950043, batch 168, lote_designado 1\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "ejemplar: [[0.97570819]\n",
      " [0.97521925]\n",
      " [0.97544086]\n",
      " [0.97576398]\n",
      " [0.97392684]\n",
      " [0.97386056]\n",
      " [0.97380197]\n",
      " [0.97354358]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.9730544]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[[0.97570819]\n",
      "  [0.97521925]\n",
      "  [0.97544086]\n",
      "  [0.97576398]\n",
      "  [0.97392684]\n",
      "  [0.97386056]\n",
      "  [0.97380197]\n",
      "  [0.97354358]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008392962627112865\n",
      "Predicción post entrenamiento : [[0.97276974]]\n",
      "PERDIDAAAA despues: 0.008340884000062943\n",
      "loss en el callback: 0.00583754014223814, batch 169, lote_designado 1\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "ejemplar: [[0.97521925]\n",
      " [0.97544086]\n",
      " [0.97576398]\n",
      " [0.97392684]\n",
      " [0.97386056]\n",
      " [0.97380197]\n",
      " [0.97354358]\n",
      " [0.97305441]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.97251004]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[[0.97521925]\n",
      "  [0.97544086]\n",
      "  [0.97576398]\n",
      "  [0.97392684]\n",
      "  [0.97386056]\n",
      "  [0.97380197]\n",
      "  [0.97354358]\n",
      "  [0.97305441]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0030717772897332907\n",
      "Predicción post entrenamiento : [[0.9727989]]\n",
      "PERDIDAAAA despues: 0.0031038783490657806\n",
      "loss en el callback: 0.007227438502013683, batch 170, lote_designado 1\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "ejemplar: [[0.97544086]\n",
      " [0.97576398]\n",
      " [0.97392684]\n",
      " [0.97386056]\n",
      " [0.97380197]\n",
      " [0.97354358]\n",
      " [0.97305441]\n",
      " [0.97251004]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.97258276]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[[0.97544086]\n",
      "  [0.97576398]\n",
      "  [0.97392684]\n",
      "  [0.97386056]\n",
      "  [0.97380197]\n",
      "  [0.97354358]\n",
      "  [0.97305441]\n",
      "  [0.97251004]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0027861723210662603\n",
      "Predicción post entrenamiento : [[0.97260565]]\n",
      "PERDIDAAAA despues: 0.0027885891031473875\n",
      "loss en el callback: 4.2023344576591626e-05, batch 171, lote_designado 1\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "ejemplar: [[0.97576398]\n",
      " [0.97392684]\n",
      " [0.97386056]\n",
      " [0.97380197]\n",
      " [0.97354358]\n",
      " [0.97305441]\n",
      " [0.97251004]\n",
      " [0.97258276]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.9722243]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[[0.97576398]\n",
      "  [0.97392684]\n",
      "  [0.97386056]\n",
      "  [0.97380197]\n",
      "  [0.97354358]\n",
      "  [0.97305441]\n",
      "  [0.97251004]\n",
      "  [0.97258276]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00011196800187462941\n",
      "Predicción post entrenamiento : [[0.97278035]]\n",
      "PERDIDAAAA despues: 0.00012404490553308278\n",
      "loss en el callback: 0.030519576743245125, batch 172, lote_designado 1\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "ejemplar: [[0.97392684]\n",
      " [0.97386056]\n",
      " [0.97380197]\n",
      " [0.97354358]\n",
      " [0.97305441]\n",
      " [0.97251004]\n",
      " [0.97258276]\n",
      " [0.9722243 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.9721868]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[[0.97392684]\n",
      "  [0.97386056]\n",
      "  [0.97380197]\n",
      "  [0.97354358]\n",
      "  [0.97305441]\n",
      "  [0.97251004]\n",
      "  [0.97258276]\n",
      "  [0.9722243 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.5661413272027858e-05\n",
      "Predicción post entrenamiento : [[0.972117]]\n",
      "PERDIDAAAA despues: 1.5113848348846659e-05\n",
      "loss en el callback: 0.0003435446706134826, batch 173, lote_designado 1\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "ejemplar: [[0.97386056]\n",
      " [0.97380197]\n",
      " [0.97354358]\n",
      " [0.97305441]\n",
      " [0.97251004]\n",
      " [0.97258276]\n",
      " [0.9722243 ]\n",
      " [0.9721868 ]]\n",
      "ejemplar: (8, 1)\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.9719395]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[[0.97386056]\n",
      "  [0.97380197]\n",
      "  [0.97354358]\n",
      "  [0.97305441]\n",
      "  [0.97251004]\n",
      "  [0.97258276]\n",
      "  [0.9722243 ]\n",
      "  [0.9721868 ]]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00020082242554053664\n",
      "Predicción post entrenamiento : [[0.9726658]]\n",
      "PERDIDAAAA despues: 0.00022193448967300355\n",
      "loss en el callback: 0.06287870556116104, batch 174, lote_designado 1\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14400068510214092,\n",
       " 0.1429960155831332,\n",
       " 0.1465372722408557,\n",
       " 0.1547590172336768,\n",
       " 0.15723937985630604,\n",
       " 0.15853740260568555,\n",
       " 0.16502708278923658,\n",
       " 0.16284197557120933,\n",
       " 0.16286658361842465,\n",
       " 0.1675762241267136]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import src.modelos.LSTM.entrenamientos as entrena_lstm\n",
    "entrena_lstm.entrena(red,c_entrenamiento_n,y_entrenamiento_n,8)\n",
    "\n",
    "# red.save('redes/DWT_LSTM/auto_predictiva/LSTM_prueba')\n",
    "# red = load_model('redes/DWT_LSTM/auto_predictiva/LSTM_ap_SGD_lr0.01_e10_bs1_df05.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<keras.src.layers.rnn.lstm.LSTM object at 0x000002112F202B50>, <keras.src.layers.regularization.dropout.Dropout object at 0x000002112EEB8050>, <keras.src.layers.rnn.lstm.LSTM object at 0x000002112F2B7FD0>, <keras.src.layers.regularization.dropout.Dropout object at 0x000002112F201310>, <keras.src.layers.rnn.lstm.LSTM object at 0x000002112E10A990>, <keras.src.layers.regularization.dropout.Dropout object at 0x000002112F2ECB50>, <keras.src.layers.rnn.lstm.LSTM object at 0x000002112F291710>, <keras.src.layers.regularization.dropout.Dropout object at 0x000002112F292210>, <keras.src.layers.core.dense.Dense object at 0x000002112F21D8D0>]\n"
     ]
    }
   ],
   "source": [
    "# print(loss_m)\n",
    "# plt.plot(range(len(loss_m)),loss_m)\n",
    "# plt.show()\n",
    "# losses = history.history['loss']\n",
    "# print(losses)\n",
    "# plt.plot(range(len(losses)),losses)\n",
    "# plt.show()\n",
    "print(red.layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAC3QklEQVR4nOzdd1iV9f/H8edhbxQHDhBwz1Bx5N6i5t5abrNlZbb0m9nepTZM0zK10sytufceONBUHIBbQREEZXPO/fuD333LkSGHdRjvx3VxBfe57/u8DxjnxWfqFEVREEIIIYQoJizMXYAQQgghRF6ScCOEEEKIYkXCjRBCCCGKFQk3QgghhChWJNwIIYQQoliRcCOEEEKIYkXCjRBCCCGKFQk3QgghhChWJNwIIYQQoliRcCOEyFe7d+9Gp9OxYsUKszz/woUL0el0XLlyxSzPby6jR4/G29vb6JhOp+PDDz/Ms+do37497du3z7P7CZFXJNwIkYGQkBBeeOEFqlatip2dHS4uLrRq1Yrvv/+e+Ph4o3OTk5P54YcfaNq0Kc7Ozjg5OdG0aVN++OEHkpOT093b29sbnU5H586dM3zu+fPno9Pp0Ol0HDt2TDv+4YcfotPpiIiIeGL9//33HwMHDsTLyws7OzsqV65Mly5d+PHHH43O+/zzz1mzZk02viPmceXKFe17odPpsLS0pEqVKvTr14/AwEBzl5epolp3Rs6dO8eHH35Y4sKhKNqszF2AEIXNhg0bGDRoELa2towcOZL69euTlJTE/v37efvttzl79izz5s0DIDY2lmeeeYY9e/bQs2dPRo8ejYWFBZs3b+b1119n1apVbNiwAUdHR6PnsLOzY9euXYSFhVGhQgWjx/766y/s7OxISEjIUf0HDx6kQ4cOVKlSheeff54KFSpw/fp1Dh8+zPfff8+rr76qnfv5558zcOBA+vbtm6PnKijDhg2jR48e6PV6goKCmDNnDps2beLw4cM0bNgwy2tHjBjB0KFDsbW1LZhi08hN3fkhPj4eKyvTfu2fO3eOjz76iPbt26drCdq6dWseVidE3pFwI0Qaly9fZujQoXh5ebFz504qVqyoPfbKK68QHBzMhg0btGOTJ09mz549/Pjjj0ycOFE7/tJLLzF79mwmTpzIW2+9xZw5c4yep1WrVgQEBLBs2TJef/117fiNGzfYt28f/fr1Y+XKlTl6DZ999hmurq4EBARQqlQpo8fu3LmTo3uaW+PGjXnuuee0r1u1akXv3r2ZM2cOv/zyS4bXxMbG4ujoiKWlJZaWlgVVqpHc1J0f7Ozs8vR+NjY2eXo/IfKKdEsJkcbXX3/Nw4cP+e2334yCjap69epaGLlx4wa//fYbHTt2NAo2qldeeYUOHTrw66+/cuPGDaPH7Ozs6N+/P0uWLDE6vnTpUkqXLo2/v3+OX0NISAj16tVLF2wAypcvr32u0+mIjY1l0aJFWvfJ6NGjtcdPnjxJ9+7dcXFxwcnJiU6dOnH48OF097x//z5vvPEG3t7e2Nra4uHhwciRI7PsPktMTKRnz564urpy8OBBk19jx44dgdQwCo/G1ezZs4eXX36Z8uXL4+HhYfTY490qmzZtol27djg7O+Pi4kLTpk3T/TyOHDlCt27dcHV1xcHBgXbt2nHgwAGT681J3WqNbdq0wdHREWdnZ5555hnOnj2b7r5r1qyhfv362NnZUb9+fVavXp3h82c05ubmzZuMGzeOSpUqYWtri4+PDy+99BJJSUksXLiQQYMGAdChQwft38nu3buBjMfc3Llzh3HjxuHu7o6dnR2+vr4sWrTI6By12+7bb79l3rx5VKtWDVtbW5o2bUpAQEC2v59CZEZaboRIY/369VStWpWWLVs+8dxNmzah1+sZOXJkpueMHDmSXbt2sXnzZsaPH2/02PDhw+natSshISFUq1YNgCVLljBw4ECsra1z/Bq8vLw4dOgQZ86coX79+pme98cffzB+/HiaNWvGhAkTALQ6zp49S5s2bXBxceGdd97B2tqaX375hfbt27Nnzx6aN28OwMOHD2nTpg1BQUGMHTuWxo0bExERwbp167hx4wZly5ZN97zx8fH06dOHY8eOsX37dpo2bWryawwJCQGgTJkyRsdffvllypUrx/Tp04mNjc30+oULFzJ27Fjq1avH1KlTKVWqFCdPnmTz5s0MHz4cgJ07d9K9e3f8/Pz44IMPsLCw4Pfff6djx47s27ePZs2a5Wvdf/zxB6NGjcLf35+vvvqKuLg45syZQ+vWrTl58qTWRbR161YGDBhA3bp1+eKLL7h37x5jxowxCkmZuXXrFs2aNeP+/ftMmDCB2rVrc/PmTVasWEFcXBxt27bltdde44cffuB///sfderUAdD++7j4+Hjat29PcHAwEydOxMfHh+XLlzN69Gju379v1EoJqf/eHzx4wAsvvIBOp+Prr7+mf//+hIaG5ur/ASFQhBCKoihKdHS0Aih9+vTJ1vmTJk1SAOXkyZOZnnPixAkFUCZPnqwd8/LyUp555hklJSVFqVChgvLJJ58oiqIo586dUwBlz549yu+//64ASkBAgHbdBx98oADK3bt3s6xr69atiqWlpWJpaam0aNFCeeedd5QtW7YoSUlJ6c51dHRURo0ale543759FRsbGyUkJEQ7duvWLcXZ2Vlp27atdmz69OkKoKxatSrdPQwGg6IoirJr1y4FUJYvX648ePBAadeunVK2bNksv2+qy5cvK4Dy0UcfKXfv3lXCwsKU3bt3K40aNVIAZeXKlYqiKNr3q3Xr1kpKSorRPdTHLl++rCiKoty/f19xdnZWmjdvrsTHx2dYs8FgUGrUqKH4+/trxxRFUeLi4hQfHx+lS5cu+Vr3gwcPlFKlSinPP/+80X3DwsIUV1dXo+MNGzZUKlasqNy/f187tnXrVgVQvLy8jK4HlA8++ED7euTIkYqFhYXRv7PHvxfLly9XAGXXrl3pzmnXrp3Srl077etZs2YpgPLnn39qx5KSkpQWLVooTk5OSkxMjNH3p0yZMkpkZKR27tq1axVAWb9+fbrnEsIU0i0lxP+LiYkBwNnZOVvnP3jw4Innq4+p907L0tKSwYMHs3TpUiB1ILGnpydt2rQxqe7HdenShUOHDtG7d29OnTrF119/jb+/P5UrV2bdunVPvF6v17N161b69u1L1apVteMVK1Zk+PDh7N+/X3s9K1euxNfXl379+qW7j06nM/o6Ojqarl27cv78eXbv3m3SgNoPPviAcuXKUaFCBdq3b09ISAhfffUV/fv3Nzrv+eeff+L4mm3btvHgwQOmTJmSbgyKWnNgYCCXLl1i+PDh3Lt3j4iICCIiIoiNjaVTp07s3bsXg8GQb3Vv27aN+/fvM2zYMO25IyIisLS0pHnz5uzatQuA27dvExgYyKhRo3B1ddWu79KlC3Xr1s2yNoPBwJo1a+jVqxdNmjRJ9/jjP7/s2LhxIxUqVGDYsGHaMWtra1577TUePnzInj17jM4fMmQIpUuX1r5W/+2Hhoaa/NxCpCXdUkL8PxcXF+BRaHkSNbhkdf6TAtDw4cP54YcfOHXqFEuWLGHo0KE5elN5XNOmTVm1ahVJSUmcOnWK1atXM3PmTAYOHEhgYGCWb3x3794lLi6OWrVqpXusTp06GAwGrl+/Tr169QgJCWHAgAHZqmnSpEkkJCRw8uRJ6tWrZ9LrmTBhAoMGDcLCwoJSpUpRr169DGc/+fj4PPFeatdQVl12ly5dAmDUqFGZnhMdHW30xpyXdavPr47ReZz6b/Xq1asA1KhRI905tWrV4sSJE5nWdvfuXWJiYrL8Ppjq6tWr1KhRAwsL47+b1W4stV5VlSpVjL5Wv59RUVF5VpMomSTcCPH/XFxcqFSpEmfOnMnW+eov7NOnT2faCnH69GmATMNE8+bNqVatGpMmTeLy5cvaeI+8YmNjQ9OmTWnatCk1a9ZkzJgxLF++nA8++CBPnyc7+vTpw99//82XX37J4sWL070BZqVGjRqZrguUlr29fW5K1KitMt98802mP1snJ6cn3iendavP/8cff6RbKgAweTp3YZVZK5uiKAVciShuisf/IULkkZ49ezJv3jwOHTpEixYtsjy3e/fuWFpa8scff2Q6qHjx4sVYWVnRrVu3TO8zbNgwPv30U+rUqZOva5+oXQ+3b9/WjmXUSlSuXDkcHBy4cOFCusfOnz+PhYUFnp6eQOoA5OyGwb59+9K1a1dGjx6Ns7NzuunxBUUdNH3mzBmqV6+e5TkuLi7ZCid5TX3+8uXLZ/n8Xl5ewKOWnrQy+vmlVa5cOVxcXJ748zOlJdHLy4vTp09jMBiMwuv58+eN6hUiv8mYGyHSeOedd3B0dGT8+PGEh4enezwkJITvv/8eAE9PT8aMGcP27dszfKOeO3cuO3fuZNy4cVnOXBk/fjwffPAB3333XZ68hl27dmX4l+/GjRsBjLqbHB0duX//vtF5lpaWdO3albVr1xpNnw4PD2fJkiW0bt1a6xYZMGCA1u31uIxqGDlyJD/88ANz587l3XffzcnLy7WuXbvi7OzMF198kW6hRLVmPz8/qlWrxrfffsvDhw/T3ePu3bv5WqO/vz8uLi58/vnnGa5yrT5/xYoVadiwIYsWLSI6Olp7fNu2bZw7dy7L57CwsKBv376sX7/eaCVslfq9UNfcefzfSUZ69OhBWFgYy5Yt046lpKTw448/4uTkRLt27Z54DyHygrTcCJFGtWrVWLJkCUOGDKFOnTpGKxQfPHhQm9aqmjlzJufPn+fll19m8+bNWgvNli1bWLt2Le3atXtiaPHy8srT/X5effVV4uLi6NevH7Vr19ZqX7ZsGd7e3owZM0Y718/Pj+3btzNjxgwqVaqEj48PzZs359NPP2Xbtm20bt2al19+GSsrK3755RcSExP5+uuvtevffvttVqxYwaBBgxg7dix+fn5ERkaybt065s6di6+vb7r6Jk6cSExMDO+99x6urq7873//y7PXnh0uLi7MnDmT8ePH07RpU4YPH07p0qU5deoUcXFxLFq0CAsLC3799Ve6d+9OvXr1GDNmDJUrV+bmzZvs2rULFxcX1q9fn681zpkzhxEjRtC4cWOGDh1KuXLluHbtGhs2bKBVq1b89NNPAHzxxRc888wztG7dmrFjxxIZGcmPP/5IvXr1MgxmaX3++eds3bqVdu3aMWHCBOrUqcPt27dZvnw5+/fvp1SpUjRs2BBLS0u++uoroqOjsbW1pWPHjkZrJqkmTJjAL7/8wujRozl+/Dje3t6sWLGCAwcOMGvWrGwP1hci18w6V0uIQurixYvK888/r3h7eys2NjaKs7Oz0qpVK+XHH39UEhISjM5NTExUZs6cqfj5+SmOjo6Kg4OD0rhxY2XWrFkZTr9Wp4JnJTdTwTdt2qSMHTtWqV27tuLk5KTY2Ngo1atXV1599VUlPDzc6Nzz588rbdu2Vezt7RXAaFr4iRMnFH9/f8XJyUlxcHBQOnTooBw8eDDd8927d0+ZOHGiUrlyZcXGxkbx8PBQRo0apURERCiKYjwVPK133nlHAZSffvop09eiThn+5ptvsnzNGX2/Hn9MnQquWrdundKyZUvF3t5ecXFxUZo1a6YsXbrU6JyTJ08q/fv3V8qUKaPY2toqXl5eyuDBg5UdO3ZkWU9e1K0oqd87f39/xdXVVbGzs1OqVaumjB49Wjl27JjReStXrlTq1Kmj2NraKnXr1lVWrVqljBo16olTwRVFUa5evaqMHDlSKVeunGJra6tUrVpVeeWVV5TExETtnPnz5ytVq1ZVLC0tjaaFPz4VXFEUJTw8XBkzZoxStmxZxcbGRmnQoIHy+++/Z/v7k1GNQphKpygycksIIYQQxYeMuRFCCCFEsSLhRgghhBDFioQbIYQQQhQrEm6EEEIIUaxIuBFCCCFEsSLhRgghhBDFSolbxM9gMHDr1i2cnZ3zZINCIYQQQuQ/RVF48OABlSpVeuLedCUu3Ny6dUvbF0cIIYQQRcv169ez3NIGSmC4UZf/vn79urY/jhBCCCEKt5iYGDw9PbO1jUeJCzdqV5SLi4uEGyGEEKKIyc6QEhlQLIQQQohiRcKNEEIIIYoVCTdCCCGEKFYk3AghhBCiWJFwI4QQQohiRcKNEEIIIYoVCTdCCCGEKFYk3AghhBCiWJFwI4QQQohiRcKNEEIIIYoVs4abvXv30qtXLypVqoROp2PNmjVPvGb37t00btwYW1tbqlevzsKFC/O9TiGEEEIUHWYNN7Gxsfj6+jJ79uxsnX/58mWeeeYZOnToQGBgIJMmTWL8+PFs2bIlnysVQgghRFFh1o0zu3fvTvfu3bN9/ty5c/Hx8eG7774DoE6dOuzfv5+ZM2fi7++fX2UKIUShpdfrSU5Oxs7OztylCFFoFKkxN4cOHaJz585Gx/z9/Tl06FCm1yQmJhITE2P0IYQQxYW/vz9VqlQhKirK3KUIUWgUqXATFhaGu7u70TF3d3diYmKIj4/P8JovvvgCV1dX7cPT07MgShVCiHynKAp79+7l7t277Ny509zliAK0bds27O3tWbx4sblLKZSKVLjJialTpxIdHa19XL9+3dwlCSFEnoiOjiY5ORlInaAhSo6ff/6ZhIQEVqxYYe5SCiWzjrkxVYUKFQgPDzc6Fh4ejouLC/b29hleY2tri62tbUGUJ4QQBeru3bva5xJuSo7ExES2bdsGwPnz581cTeFUpFpuWrRowY4dO4yObdu2jRYtWpipIiGEMJ+04ebUqVNER0ebsRpRUPbt20dsbCwAoaGhJCUlmbmiwses4ebhw4cEBgYSGBgIpE71DgwM5Nq1a0Bql9LIkSO181988UVCQ0N55513OH/+PD///DP//PMPb7zxhjnKF0IIs0obbhRF4cCBA2asRhSUDRs2aJ/r9XpCQkLMWE3hZNZwc+zYMRo1akSjRo0AmDx5Mo0aNWL69OkA3L59Wws6AD4+PmzYsIFt27bh6+vLd999x6+//irTwIUQJVLacAPSNVVSbNy4EQALi9S3cOmaSs+sY27at2+PoiiZPp7R6sPt27fn5MmT+ViVEEIUDWq4cXBwIC4ujn379pm5IpHfgoODuXjxIlZWVvTo0YN169ZJuMlAkRpzI4QQ4hE13KiLoQYEBBAXF2fOkkQ+U1tt2rRpQ7NmzQBpucmIhBshhCii1HDTrFkzKleuTHJyMkeOHDFzVSI/qeGmR48e1KpVC4ALFy6Ys6RCScKNEEIUUREREQCUK1eONm3aALB//35zliTyUGxsLAcPHsRgMACQkpKidT36+/tTu3ZtILXlJqshHpm5cuUK69evz9G1hZ2EGyGEKKLUlpty5cpRt25dAKNJGMK8oqOjcxwc/vvvPxo3bkyrVq1YtGgRAKdPnyYuLg5XV1fq1atH9erVsbCwIDo6Ot0acE+yf/9+fH196d27t7ZfY3Ei4UYIIYqotOGmfPnyANy5c8ecJQlSW1wmTZpE6dKlef31102+ftmyZTRv3pyLFy8CsH79egBtH8Wnn34aCwsL7Ozs8PHxAUwbd7Nx40a6du2q7bU4bdo0zp07Z3KdhZmEGyGEKKIk3BQ+p0+fpkGDBnz//fc5WnsoKSmJ8ePHEx8fT8OGDQHYtWsXer2egwcPAhgtXGvquJvw8HD69+9PfHw8zzzzDP7+/iQmJjJq1ChtK4/iQMKNEEIUQbGxsdqGweXKldM2FTa1e0LkrXfffZfLly/j6uoKpG74bIqoqCgePnwIwOHDh3F1deX+/fucPHlSa7lJG27SjrvJjqNHj5KYmEjNmjVZvXo1CxYsoHTp0hw7dowvv/zSpFoLMwk3QghRBKmtNra2tjg5OUnLTSERFBQEwC+//AKkhk11QHB23L9/HwBXV1dsbW1p3749AEuWLOHy5cvodDqaN2+unW9quDlz5gwATZo0wdramkqVKvHTTz8BqdsZ6fX6bNdamEm4EUKIIihtl5ROp9PCTWxsrLbvkChYSUlJXL9+HYCWLVsCqdsj3Lt3L9v3UMNNqVKlAOjUqRPwKCzVq1dPaxUC08PN2bNntfuohg0bxooVK9i5cyeWlpbZrrUwk3AjhBBFUNpwA+Ds7Iytra3RY6JgXbt2DYPBgL29PR4eHpQtWxYwrWsqs3CjLs74+EbRNWvWBODq1askJiY+8f5qy039+vW1YzqdjgEDBmBlZdZNC/KUhBshhCiCHg83aVtvpGvKPEJDQwGoWrUqOp2OChUqAKaNg3o83NSpU4eKFStqjz8ebsqXL4+DgwOKojxxGQC9Xq+18KRtuSmOJNwIIUQR9Hi4AWRQsZmlDTfw6OeRm5YbnU5Hx44dtccfDzc6nU6bDn758uUs7x0SEkJiYiL29vbaNcWVhBshhCiCMgo30nJjXo+HG7XlJjfhBtDCjZubm9YNlZa3tzfw5HCjdknVrVtX21G8uCo+HWxCCFGCSLgpfPIr3AwcOJAVK1bQrVu3DENJdltu1MHEacfbFFcSboQQogiScFP45Fe4cXFx0TbMzEh2w43aclPcx9uAdEsJIUSRJGNuChdFUQgJCQHSh5vcDCjODjXcXLlyJcvzSlLLjYQbIYQogqTlpnCJiorS9mpSx8DkxYDi7MhOy01SUpK2RYO03AghhCiUJNwULmqXVMWKFXFwcADyrlvqSdQwdffuXW3rhsddunSJlJQUnJ2d8fT0zPa9iyoJN0IIUcQkJiby4MEDQMJNYfH4eBt4FG4iIiKyvSllTsJNqVKltPMz65pKuzKxTqfL9r2LKgk3QghRxKitNlZWVkZvgmo3yN27d4vNHkFFRUbhpkyZMtp2BtkNnDkJN5B511RYWBiffPIJb7/9NlAyxtuAhBshhChy1HBTtmxZo7/C1eX+DQYDkZGRZqmtpFLDTdrF8SwsLEwed5OX4UZRFNq2bcv06dO5du0aLi4uDB8+3KT7FlUSboQQoojJaLwNgLW1NW5uboB0TRW0jFpuwLQZUwkJCSQkJAA5Dzdpu6Vu3brFpUuXsLCwYNGiRdy+fZsOHTqYdN+iSsKNEEIUUrGxsSiKku64OuXYw8Mj3WMy7sY8Mgs3prTcREdHA6lbKri4uJj0/BmtUnz8+HEgdUXikSNHagOdSwIJN0IIUQicPHnS6K/7f//9FycnJ2bMmJHu3FOnTgHg6+ub7jFZ66bgJScna5tWZtZyk51wo3ZJubi4mLw9QkbdUmq48fPzM+lexYGEGyGEMLOgoCCaNGlCr169tGMLFiwA4Jtvvkk30yYwMBCAhg0bpruXtNwUvFu3bqHX67G2tjbawRtyFm5M7ZIC43CjtvZJuBFCCGE2J06cwGAwEBAQQHBwMMnJyezYsQNIbYFJu/S+Xq/nv//+AzJuuZFwU/AiIiKA1O/94y0uBRVu1G6pmJgYoqKiAAk3QgghzCjtIND169dz5MgRbbVbgF9//VX7PDg4mLi4OOzt7alRo0a6e0m4KXhquFFnq6VVUOHGwcFB+9lfvnyZW7duERYWhoWFRYYtfMWdhBshhDCzq1evap+vW7eOLVu2ANCkSRMANm7cyM2bN4FH420aNGigraGSlvoGJ2NuCk52wo3688hogLgqN+EGHnVNXbhwQWu1qVOnTokaSKyScCOEEGaWtuVm3759LF++HICXX36ZNm3aYDAYWLhwIZD1YGJ4NKBYWm4KTlbhRv153Lx5k9GjR+Pi4sK6desyvE9uw03btm0B+Omnn0p0lxRIuBFCCLNTw421tTV6vV7b4LBr166MHz8eSO2a0uv1WQ4mhsLdchMdHa0FgeIkOy03sbGxLFq0iIcPH/LBBx9k2IKT23DzxhtvYGdnx6FDh5g/fz4g4UYIIYQZGAwGrVtq8ODB2vH69etTuXJlBg4ciJubG1euXGH58uVPbLmpWrUqOp2Oy5cva91bhYGiKLRs2ZL69etrb+LFRVbhxsXFRVuzpnbt2tjZ2REYGMjRo0fTnZvbcFOxYkUmTJgApM7gAgk3QgghzCAsLIykpCQsLS15+eWXteP+/v5A6kDR119/HYBp06ZpY2+eeuqpDO9XsWJFXn31VQAmTJigbbBpbhEREZw7d47w8HB2795t7nLyVFbhRqfT8ccffzBr1ixOnjzJkCFDAJg7d266c3MbbgDeffddbG1tAUrsYGKQcCOEyKG7d++yYcMGbbl4kTNql5SHhwdPP/20turwM888o53z6quv4uzsrK1MXK1aNZydnTO952effYa3tzfXrl1jypQp+Ve8CdIOmt65c6cZK8l7WYUbgN69e/P6669jZ2fHiy++CMDff/+tTdlW5UW4qVSpEs8//zyQ2lLk6OiY43sVZRJuhBA58sILL9CzZ0+qVKnC9OnTjaYui+xTw423tzcWFhasXbuWxYsXG+0BVLp0aSZOnKh9nVmXlMrJyUmbPv7zzz9r43QyExERQXx8fM5eQDalHTRd0sJNWs2bN8fX15eEhAQWLVpk9FhehBuA6dOnM3jwYD755JNc3acok3AjhMgRdS+du3fv8sknn2h/kQrTpA03AI0bN2bEiBHpznvjjTewt7cHMh9MnFanTp3o3bs3kLqVQ2YuXbqEl5cXPXv2NK1wE6UNN2fPni2UA55zypRwo9PptP9X1EG/qrwKN+XKlWPZsmX0798/V/cpyiTcCCFyRP2FPmnSJCB1fZbHtwkQT/Z4uMlMuXLl+PTTT6lQoQIDBw7M1r27dOkCwN69ezM9Z9GiRcTFxbFz505OnjyZrfvmRNpuKYBdu3bl23MVJEVRTAo3AMOGDcPKyopz585pXY2Qd+FGSLgRQuTQvXv3gNTxIGXLliU2NpYjR46YuaqiJ7vhBmDy5Mncvn2bOnXqZOve7dq1A+DgwYMZBk9FUVi6dKn29W+//Zat++aE+jrd3NyA4tM1FRMTQ0pKCgBlypTJ1jWurq60bt0awGhrDQk3eUfCjRDCZHFxcdpA4rJly9KpUycAtm/fbs6yiiRTwo2p6tWrh5ubG7GxsZw4cSLd4wEBAVr3IsCff/6Zb2Nv1Nf57LPPAsUn3KitNo6Ojlq3YXaoA8bVcJOQkKD9PyXhJvck3AghTKb+Qre2tsbZ2ZnOnTsDEm5MlXaNm/wINxYWFrRp0waAPXv2pHv877//BlLX1/H29iY6OpqVK1fmeR2Komivc8SIEVhaWhISEpKuq6ooUlsws9slperRoweQ2j0XGxtLdHQ0kDomR10XR+SchBshhMnUX+hlypRBp9Np4ebw4cMya8oE4eHhJCUlYWFhQeXKlfPlOdQl+R8PN3q9nmXLlgGprSljx44FjDfpzK4tW7ZQoUIFpk+fjl6vT/d4VFSUtt5O/fr1adq0KYC283lRZup4G1WdOnXw9vYmMTGRXbt2aV1SLi4u6XYWF6aT76AQwmRpww2ktjpUq1YNvV6f5eBVYSztGjfW1tb58hzquJv9+/cbBY/9+/dz69YtSpUqhb+/P6NHj8bCwoI9e/aYHDrWr19PeHg4n3zyCV27dk03E0p9ne7u7tjb22sLFOZHK1FBy2m40el0WuvNhg0bZLxNHpNwI4Qw2ePhBpCuqRzIz/E2Kl9fX5ydnYmJidG2bgC0gcT9+/fH1tYWT09PbTxMr169MuzGykxYWJj2+c6dO+nUqRMGg0E79njX29ChQ4HUFp+7d+/m7IUVEjkNN2A87kZd0E/CTd6QcCOEMFlGv9Al3JiuIMKNlZWVNjNHbVVLTk5mxYoVwKOgATBv3jy6detGfHw8PXr0yHYrnBpuPv74Y1xdXTl79ixbt27VHldfp5eXF5C6cm7jxo3R6/VaHUVVbsJN+/btsbOz49q1a7z55puAhJu8IuFGCGGyjFpuOnTogE6n4+zZs9y+fdtcpRUpj7/p5xe1a0pdzG/79u3cu3eP8uXLG62EbGdnx+rVq+natStxcXH06NGD/fv3P/H+arjp0KEDo0ePBmDOnDna4xmFOLWVaMmSJTl+XYVBbsKNg4MDw4cPB+DcuXNA9qeTi6xJuBFCmCyjcFOmTBkaNGgAwIEDB8xSV1Gjfh/d3d3z9XkGDx6MpaUlO3bsICAgQOuSGjRoEFZWVkbn2tnZsWbNGrp06UJsbCzdu3fn4MGDWd5fDTcVKlTghRdeAFKD1PXr14GMw82QIUPQ6XTs37+/SM+ayk24gdQB3CdOnODLL79k+PDhvPPOO3lZXokl4UYIYbLMfqGr3R8SbrJHnVmW31N/fXx8tJaS6dOns2bNGiB1pdyM2Nvbs3btWjp16sTDhw/p3bt3puvfPHz4kNjYWCA13NSpU4d27dphMBi0mVdqeEnbQlW5cmWt1SjtQoJFTW7DjU6no1GjRrz77rv89ddfNG/ePC/LK7Ek3AghgNRuhGrVqmnN41nJqOUGoFWrVoCEm+xS1zYpiHVNpk6dik6nY/PmzTx48IAqVarQokWLTM+3t7dn3bp1eHl5ce/ePdavX5/heWqrjaOjI05OTgBGeyclJydnOrZI7ZJZvnx5bl6aWeU23Ij8IeFGCEFQUBCvv/46oaGh2Rrg+aRwc+LECe2v+az8999/nDlzJgcVFw9qy42rq2u+P1ft2rUZMGCA9vWQIUOeuJ6Kg4MDzz33HJC6enFG0nZJqfr370+5cuW4ffs2r776qhbiHh9b1L59eyB1vImiKKa9oEJCwk3hJOFGiBLOYDAwYcIEbe+hoKCgJ16TWbipUqUKHh4e6PV6jh49muU9YmNjadOmDS1atCAyMjKH1RdtBdUtpXrvvfe0z9POksqK2p21adOmDKdtZxRubGxs+OqrrwD45ZdfgNSNPx0dHY2urVKlChYWFiQkJBTJXcINBkOOVygW+UvCjRAl3K+//mo0I+b8+fNPvCazv1Z1Ol22u6YuXLhAdHQ0Dx8+ZN26daaWXSyoLRoF0XID0LBhQ+bOncuMGTNo1KhRtq6pU6cOfn5+pKSk8M8//6R7PKNwAzBmzBijGVMZzQiztrbGw8MDeDTouCi5f/++tp6PzHIqXCTcCFGCJSUlMWXKFABeeeUVIDV0pF2ALaNr1KX0M/qFrg4q3r9/Pzdu3KBly5b873//S3de2hBV1Nc6yQm9Xq913RXkXkIvvPACb7zxBjqdLtvXZNU1lVm4gdSxN/Pnz8fGxkZblfhx6jicy5cvZ7uewkIN+a6urvm2wrTIGQk3QpRgN2/eJCoqCjs7O2bMmIGNjQ3x8fFZTs1Vu5B0Ol2GC46pLTeHDh2iT58+HDp0iO+//z5dYErb/bV161atFaOkUAMiFGy4yYmhQ4diYWHB4cOHCQ4ONnosq3ADMH78eO7fv8+nn36a4eM+Pj5A0Wy5kfE26SXpk7h6/yrBkcFPPjkfWT35FCFEcaUutlexYkVsbGyoWbMmZ86cISgoSHvTeZz6C93NzQ1LS8t0jzdo0AAnJydiYmI4ceIEAHFxcVy5coWqVatq56VtuUlOTubff//VxneUBGqYs7W1xdbW1szVZK1ChQp07NiR7du3s3nzZiZOnKg99qRwA6kzrzJTHFpuSkKXlKIo3Iu/x42YG9rHrQe3jD5uPrhJRFzq96SjT0d2jDTfxqgSboQowW7dugVApUqVgNTxFWfOnOH8+fPapn6Py2wwscrKyooWLVqwbds2rK2tKV26NHfu3OHMmTNG4UZtuWnSpAnHjh1jxYoVJSrcFPRg4txq1KgR27dv5+LFi0bHsxNusqKGaDXcHDp0iK5du/LNN99oU8oLq+LScqM36LkTe8couNyIucHNBzeNvk7UJ2brfjaWNujIfrdnfpBwI0QJlrblBlLDDWQ9Y+pJ4QZg7NixnDhxglmzZrFlyxb+/PNPzpw5Q+/evQFISUnh0qVLAEybNo2+ffuyadMmHjx4gLOzc+5fWBFQ0IOJc6tmzZoA+RZu1G6pJUuW8PDhQ+bMmVPow436b7gwh5sUQwq3HtzKMrjcenCLFENKtu5X3rE8lZ0rU9mlMh7OHlRyrkQl50pUdqmsfV7GvoxJY7ryg4QbIUqwjFpuIOtwk52/VocOHaotr3/jxg0Ao/VsLl++TFJSEvb29vTq1Yvq1asTHBzM8uXLGTt2bO5eVBFR1Fpu1HCjvqFD6lRodQp3TsON2i119epV9Ho9AQEBAJw+fZo7d+5Qvnz5XFSdf7Zs2cI333wDPBpEbw4PEh9wLfoaV6Ovpv73/lWuxfz/f6OvcfPBTQxK5hMEVBY6Cyo6VcTDxQMPFw8qO1fWPlc/KjlXwtaqcHehqswebmbPns0333xDWFgYvr6+/PjjjzRr1izT82fNmsWcOXO4du0aZcuWZeDAgXzxxRfY2dkVYNVCFA9quFFbbmrXrg2khhtFUTL86ys7LTeAdm39+vUB43CjjrepVasWFhYWjBs3jqlTpzJ16lT69u2Lm5tbbl5WkVDUwk2NGjWA1BaWpKQkbGxsiIyMJCUl9S/+nIaQypUrY2VlRXJyMteuXSMwMFB7bNeuXQwZMiTXtee1wMBABg4ciF6vZ+TIkYwfPz5fnsegGLgTe0cLKlejr6YLL1EJUU+8j7WFdWpLixpUnP8/wKQ5VsGpAlYWZo8Eecasr2TZsmVMnjyZuXPn0rx5c2bNmoW/vz8XLlzI8H+UJUuWMGXKFBYsWEDLli25ePEio0ePRqfTMWPGDDO8AiGKNrVbSm25qVWrFjqdjsjISCIiIihXrly6a7IbblRquLlw4QLJyclYW1tr4UYNU2+88QaLFy8mKCiId955R9uTqDgrat1SFSpUwMnJiYcPHxIaGkrt2rW1LqmyZctiY2OTo/taWlpSpUoVQkND+ffff0lMfDSuY8eOHYUy3IwdO5aHDx/SsWNH5s+fn+MuGINi4NaDW1yOuszl+5e5HHU5NcD8fyvMtehrJOmTnnif0nalqeJaBa9SXlRx+f//ulbByzX1v+5O7ljoStbkaLOGmxkzZvD8888zZswYAObOncuGDRtYsGCBtvZGWgcPHqRVq1bafiTe3t4MGzaMI0eOFGjdQhQXj7fc2Nvb4+3tzeXLlwkKCsqTcFOlShXtTTE4OJg6depo3V5qN5itrS3z5s2jTZs2/PbbbyQnJ3P48GF0Oh1bt26lSpUquX6thU1Ra7nR6XTUqFGDkydPcvHiRaNwk9MuKZWPjw+hoaHaIoEODg7ExcWxY4f5ZttkJiEhgVOnTgGwcOHCJ4a6qPgoLt+/TGhUqBZiQqNCuXz/MlfuX3lieLHQWVDJuZIWVLxcvYzCi6erJy62RePfUEEyW7hJSkri+PHjTJ06VTtmYWFB586dOXToUIbXtGzZkj///JOjR4/SrFkzQkND2bhxIyNGjMj0eRITE43+ElB/oQgh0rfcQGrgUMNN27Zt011j6gwRCwsL6tWrx5EjRzhz5gx16tRJ13IDqeMWXnjhBX755RcWL16sHX/22WfZtWsXVlbFp8kcil64gdRxNydPntTG3eRVuFHH3airWo8ZM4a5c+cSGhrKlStX0m24mZklS5ZQunRpunfvnqt6snLp0iUMBgOurq54eHiQkJLA1ftXtcByOeoyofcfBZn7CfezvJ+lzhKvUl74lPLBp5QP3qW8H7XCuFahsnNlrC1lgUBTme23RUREBHq9Hnd3d6Pj7u7umS7/Pnz4cCIiImjdujWKopCSksKLL76Y4eqnqi+++IKPPvooT2sXojhISEjQFuRLG25q167Nxo0bMx1UbGrLDaR2TanhZuDAgelablRfffUVCQkJODg40Lx5c1599VX279/Pxx9/zMcff2zS6yvsilq3FDwad6POmMrLlhtA2zyzY8eOnDx5koMHD7Jjxw7GjRv3xHtcvHiRZ599FgsLCzZt2kTXrl1zVVNacclxhEaFEhwZzMr9K6EnKD4KXrO8uBFzA4WsN/10d3THp3RqeKlauuqj/5b2wcPFo1iNdSksitR3dPfu3Xz++ef8/PPPNG/enODgYF5//XU++eQT3n///QyvmTp1KpMnT9a+jomJwdPTs6BKFqLQUt+YbG1tjVYaVgPHyZMnM7wuJ+GmXr16QOqg4jt37nD//n0sLCy0N0uVq6srCxcu1L62sbFh+PDhfPrpp3Tp0oU2bdpk+zkLu6LacgPkecvN4wtGNm3alE6dOpkUbvbs2QOkzuAaOnQox44dM1pX6UnikuMIjgzWPi7du0RwVOrnN2JuGJ/cBGKI0X6GjtaOWlipWqqqUZDxLuWNo41jBs8o8pPZwk3ZsmWxtLRMtxNseHh4pv+jvP/++4wYMUIbmd6gQQNiY2OZMGEC7733HhYW6QdMFYXVP4Uwh7TTwNMOiGzTpg0WFhbs3buXVatW0b9/f6PrcrJwWdoZU2qrjY+PzxNnOQ4bNozNmzezePFi5syZU6zCjbTcPJK226l8+fJ4eHjQqVMnPvnkE3bs2KHN3Lty5Qp+fn4MHTqU2bNnG91D3fzV0tKSqKgo+vXrx6FDh3BwcNDOSUhJ4NK9S1y4d+FRiIm8RHBkMLce3MqyRldbV2qUqcGd83e4dvIagzsP5vURr1PdrTrlHMqZfV0XYcxs4cbGxgY/Pz927NhB3759gdTEvWPHDqOlvdOKi4tLF2DU5d/V5kwhRPY8voCfqlatWkyZMoXPP/+cF198kdatW2uzF/V6PVFRqVNPTe2WAggODtY26Ew73iYrzz77LIsXL+bo0aPZfr6ioCi33Ny8eZPY2Nh8ablp2rQpOp2Op59+Gjs7O+7cucPFixepVasWa9asITIykt9++40vv/zSaMFHNdz88ssvvPvpu5yOOc1Lv72EWw03zt87z4WIC1y5fyXLLqTSdqWpUaYG1d2qU7109Uefu1XXFqZr1KgR1wKv8eykZ2np2TJXr1vkH7N2S02ePJlRo0bRpEkTmjVrxqxZs4iNjdVmT40cOZLKlSvzxRdfANCrVy9mzJhBo0aNtG6p999/n169emW4x40QInOPL+CX1vTp01m/fj3//fcfL774IitXrkSn03H//n3tDwlT1qKpUKECbm5uREZGcu7cOUqXLm00mSAr6rpXISEhREREFOrVYE1RFMONm5ub9nMMDg7Os3Dj7u6Ora0tiYmJNG3aFEhtdW/atCn79u3jwIED1KpVSxtwnJiYyPpN63mq/VOcjzhPwOUAQn1DoRNMvjOZmNGp39vFkYvhscm0rrau1Cpbi5plalK9dGpwUUOMm33W/6YNBgMXLlwAsh/OhXmYNdwMGTKEu3fvMn36dMLCwmjYsCGbN2/WBhlfu3bNqKVm2rRp6HQ6pk2bxs2bNylXrhy9evXis88+M9dLEKLIyqzlBlLfWBYvXkzTpk1ZvXo1u3fvpkOHDtpfx+7u7iata6LT6ejbty9LlizhtddeY8qUKZQuXTpb15YqVYpatWpx4cIFAgIC8nUmTEEqit1SkNp6c/jwYRYuXKhN/vDy8srVPdXxV2fOnKF58+ba8datW7PvyD5WH10NjWCTfhM8C5SFZ889C2nHvPum/icmKQYLLDBEGnCIc+DFgS9Sq2wtapetTa0ytSjvWD7HXUjXr18nPj4ea2trk8bzCDNQSpjo6GgFUKKjo81dihBmNWrUKAVQvvjii0zPeemllxRA6dmzp6IoitKpUycFUN555x2Tn89gMCiJiYk5qnXEiBEKoHzwwQc5ur4wcnd3VwAlMDDQ3KWYRP1ZqB/PPvtsntx3045NyoufvKj8evxX5c0tbyrd/+yulPu8nMKHZPpR6stSSvP5zZXaU2ortEbp/mZ35eyds0rY3TBFp9MpgHL79u08qU9RFGXTpk0KoNStWzfP7imyz5T37yI1W0oIkXeyarlRTZo0iblz5/Lvv/+yevVqduzYgYWFBS+//LLJz6fT6XK8im3z5s35448/itW4G7Vbqii23KiqV6/OnDlzTLr+QeIDzt09x9m7Z43+ey36WuoJ6zO6CGqWrsnF/Rep4lCF6OBookOiWbF2BZ06daJx48ZwEka/Opq65eoCqRNOTp8+zf79+xk4cGBOX64RtaXq8SUMROEj4UaIArJu3Tpq165t9OZgTlmNuVHVrFmTXr16sW7dOm1l8D59+uS6G8JU6ribo0ePZrrnVVGSnJxMfHw8ULTG3EDqgHMAa2tr/v7770x3cdcb9FyKvMTp8NNGH1ejr2Z674pOFalbri71ytWjXvl61C1Xl/F9xnMh8AKJXolwFfpP6k9MqRgWnF7A2rVradq0qbZicKtWrbR7tWnThtOnT7Nv3748CzfqTD8Zb1P4SbgRogCcPHmSPn364Ovra7QxoDllp+UGUgf+r1u3joSEBABeffXVfK/tcb6+vtjY2HDv3j1CQ0OpVq1agdeQl9KulJ5ZOCisevXqxfjx4+nRowd+fn4A3Iu7Zxxi7pzmzJ0zJKQkZHiPik4VU8NL2brUK1+PeuXqUadcnQwH9LZr1o4LgRe4ejU1FLVq1QobGxsWLFjAqlWrsLOzw2Aw4OPjQ+XKlbXr2rRpw+zZs9m3b1+evXZpuSk6JNwIUQDUvyzPnDmjbR5pTomJidpifFm13AC0bdsWPz8/jh8/Tv369Wnfvn0BVGjMxsaGRo0aceTIEY4cOWLWcPPDDz/w7bffsnr1au3N3VTqYGIHBwez/1swRbI+meCYYDq81oEj4UeY99c8ToefznSNGAdrBxqUb8BT7k9pH/XL13/irKS0Wrduzbx587SvW7VqRalSpXBwcODmzZt88803AOnWQFK/PnXqFDExMXnSQiYtN0WHhBshCoC6oqteryc0NFRr2jeXtKsTP2nWkk6n49tvv+X555/nq6++MluXUPPmzTly5AhHjx7VusjM4e+//+b69eu89NJLHD58OMPFQ5+kKEwDj0uO43T4aU7cPsHJ2yc5EXaCM3fOZLrRY9XSVVMDTPlHQaaaW7Vc70adtqvJx8dHa2n89ddfjTbafHwbnkqVKlG1alVCQ0M5ePAg3bp1y1Ud9+7d4+7duwBm//9XPJmEGyEKgBpuAG1BMnNKuxt4dsJK+/btjV6DOahThI8cOfKEM/PXzZs3AQgICODPP/9k5MiRJt+jsIWb6IRoAsMCU4NM2ElO3D5BUEQQBsWQ7lxnG2ejlhi1NSa/dqb28fGhQoUKhIWF0bLlo0Xzhg0bxrBhw7K8tk2bNoSGhrJ///5chxt1fRsPDw+cnJxydS+R/yTcCFEA0gaDCxcu0KtXLzNWk/3xNoWJGm5OnDhBbGwsjo4Fv1+PwWDQgiHAlClT6N+/v8lvduZc4+Ze3D2O3z5uFGSCI4MzPLe8Y3n8KvrRqEIjGldsTKOKjfAu5Z3r1hhT6HQ6/P39WbRokcmbYbZs2ZJFixYREBCQ6zrUn3tBD6YXOSPhRoh8pihKupYbc7txI3UjwKIUbqpWrYqXlxdXr15l9+7dPPPMMwVew507d0hJSUGn0+Hj40NoaCiff/45n3/++ROvffjwIbNmzWLAgAEF1nITmxTLidsnCLgVwNGbRwm4FUBoVGiG51ZxrZIaYP4/yDSu2JiKTtlr2ctvM2fOZNCgQfTo0cOk69RtHdIG0py6c+cOgLYViSjcJNwIkc/Cw8OJjY3Vvlabt81JHeBclAZG6nQ6unfvzty5c9m8ebNZwo3aJVWhQgW+++47+vXrx9dff03v3r15+umn2bZtGzNnzuTLL7/kqaeeMrp22bJlvP/++xw6dIiePXsCedtyk6xP5sydM1qIOXrzKGfvns2wa6m6W3X8KvppYaZRxUaUdSi821qULl06Rz9vNbyrLZW5oY63KVeuXK7vJfKfhBsh8pnaaqPT6VAUpVC03KiL4aVd6r4o6NatG3PnzmXTpk1meX61xcvDw4O+ffsyfPhwlixZwrPPPsunn37K6NGjSUpKwtvbm59//tno2pCQEAAOHjxI69atgZy33CiKQnBksFGQORl2MsOp15WcK9GscjOaVmpKs8rN8KvoR2n77G19UdSpe17du3ePpKSkHC8iCdJyU9RIuBEin6nhplmzZhw5coSwsLA8m5qaEw8ePODs2bMA2iaFRUXHjh2xtrYmJCSES5cuUaNGjQJ9frXlRl1PZfbs2ezfv5/Q0FCjGVzq9zctNRjdv39fC5fZ/TcQlxzHsVvHOHj9IAevH+TQjUNExEWkO8/V1pWmlZvSrFIzmlZuStNKTansUjmDO5YMbm5uWFlZkZKSwp07d/Dw8MjxvaTlpmiRcCNEPlPDTZMmTbhy5Qrh4eFcvHiRJk2aZHpNaGgoTZs2ZeTIkcycOTNP6zlx4gSKouDp6VmkxtxA6oJ3bdq0YefOnWzevLnAw03alhtI3dRz8eLFdOjQAUVRaNGiBYcOHeLs2bPpVlK+fv269vmOHTuAjLulFEXhesz11BBz/RAHbxwkMCyQFEOK0Xm2lrY0rthYa5FpWrkp1d2qF+hg38LOwsKCChUqcOPGDW7fvi3hpgSRcCNEPlPDTY0aNahZs2a2ws2KFSuIjIxkzpw5fPzxx3m6iq3aaqBuaVDUdO/enZ07d7Jp06YMV0u+ceMGP/74I926daN9+/Z5OiD28ZYbgHbt2rFq1SquXr3K2LFjcXV15d69e9y5cwd3d3ejulQPHjwAUltukvRJnLx9MrVV5kZqoLn54Ga6567kXImWni1p6dGSlp4taVSxETaWOe9mKSnUcKOu7ZRT0i1VtEi4ESKfpQ03tWrVYt++fU8cVLx3714gdSXhf//912g9j5SUFEaPHo23tzeffvqpyfUU9XDTrVs33n77bXbt2kV8fDz29vZGj7/33nssXryYr7/+mtatW/Ptt9/m2dgiNdw83gLQt29f7fOqVasSEhLC2bNntXCjKMqjcGMNeAJeMC95HtO+mEaiPtHofpY6SxpVbERLj5a08GxBS8+WeLp4FoqZS0WNOu4mt+FGWm6KFgk3QuQjRVEIDk5dQ6R69erapplZDSrW6/Xs379f+3r58uVG4SYgIIC//voLgMGDB6eblfMkRT3c1KtXDw8PD27cuMGePXuMFmdTFEXr8tHpdOzfv59hw4YRGprx9GdTqQElbctNRvWp4aZjx47cT7jPxjMbSWidAN5ARcAy9dxLSanBt4x9mdRWGc+WtPBoQZNKTXC0Kfh1fIojtes1N+FGr9cTEZE6xklabooG6ZwVIh/dunWLuLg4LC0t8fHx0VYmzqrl5syZM0RHR2NpmfoOuGnTJq0bAzDaeHPGjBkm1RMWFsa1a9fQ6XQ53hfJ3NQp4QCbN282euzSpUvcvHkTGxsbjh07BsDVq1fR6/U5ei41nBoMBqPWl6zGbvjU84E6MO/6PBr90gi3r9x4dsOz0BrwIDXYRAOn4DXv1zj/ynnuvn2XdcPWMaX1FNp5t5Ngk4fUlpvcTAePjIxEURQAypQpkyd1ifwl4UaIfBAQEMCWLVu0Lilvb2+sra2NWm7UX5aPU7ukOnXqRI0aNUhISODff//VHlfXqAFYsmSJSb+01ZVa69atW+R2o05Lba15fEr4zp07gdSVaX19fbG0tMRgMBAeHp6j51m2bBk1atTgq6++IiYmRluvKG3LzZ3YO/x95m9e/PdF6s6uy/e238MQOON4hsCwQBQUKtlWghPgfdKbXsG9YCawGobUGEKtsrWkuykf5UW3lDrexs3NrUhtdFqSSbgRIo9FR0fToUMHunXrxnPPPQegzeqpWrUqlpaWxMbGZrpqqhpu2rVrx6BBg4DUrimV2nJjZ2dHcnIyP/30U7ZrK+pdUqrOnTtjZWXFxYsXjbqc1HDTsWNHLC0ttTe2nK5Qu2fPHgD++ecfbbxNKfdS7Lyxkzc2v8FTc57C/Vt3hq0cxi/HfyEoInXXaO6A7Slblg5Yys3JN5nmOg3WgS++dG7aWbt/YdlbqjjLi3Aj422KHgk3QuSxLVu2aH/hq2+IarixsbHRloTPaNyNoijs27cPSN30Tw03ateUXq/n9OnTAHz44YcAzJkzR1sgLjObN29m0qRJ/Pbbb0DRDzcuLi7abtFq643BYGDXrl1AariB1J2h4dHPwVShoaFgCYH3A5m2cxqMg/sv3KfX0l7MOjKL/+78B8BT7k8xqfkkVg9ZzfVXr2Mx14LE1Ym0K9OOSs6VtGngnp6ePP3009r9zbG3VEmTF6sUqy03Em6KDgk3QuSxdevWATBkyBDtDbhdu3ba49WqVQPg8uXL6a69dOkS4eHh2Nra0rRpU3x9falevToJCQls3bqVS5cuER8fj6OjI5MnT6ZatWpERUVRvXp1OnTowPHjx9PdMyAggO7du/P9999z+/ZtrK2t6dSpU3689AKldk2p427+++8/IiIicHR01BYnVLuPTGm5MSgGTtw+wVf7v2Kf9z6YAoyG1fdWp85ysoCqpavyfOPn+XvA34S/Fc6pF08xs9tM+tbui4ebh/YzVhfzSztWp2HDhpQvXx4XFxd5sywAaVtuMusKfhK15UYGExcdEm6EyEPJycls2LABgIkTJ7Jv3z7CwsIYMGCAdk7VqlUBMpzBo7baNG/eHDs7O3Q6HX369AFg7dq1WpfUU089hbW1NatWrcLf3x+dTsfu3buZOnVqunuqXVpNmzblr7/+4vLlywW++F1+UAcV79y5k4SEBK1Lqk2bNtoy+9ltubkbe5e/Tv/FiNUjqPhdRfzm+TFlxxTiK8WnTt1+CLozOlgLg28NJuS1EOb1mseQ+kMo75j+Da9+/frAo3CTtuVGHewcGBiInZ1d7r8RIktquElISNA2LDWVdEsVPTIVXIg8dODAAe7fv0+ZMmVo0aIFOp3OaCE3yF64adu2rXasd+/efPfdd2zYsEH7y7Fhw4ZAasjZvHkz27dvp0uXLumW/VcUhdWrVwPw1ltvMXjw4Lx5oYXAU089RcWKFbl9+zZbt27VQmXaVqnMWm5SDCkcvnGYzcGb2RKyheO3jqPw6K96JxsnnnZ/mu3ztkMocBft8dq9nrzZaL169Vi9enWGLTeQGnJEwbC3t8fV1ZXo6Ghu376d7a5AvV6PoihYWVnJAn5FkIQbIXJp3rx5/Pnnn/z0009al1TPnj21qdyPyyrcnDx5EjAeE9OyZUvc3NyIjIxk0aJFAPj6+hpdp652fOvWLaKjo7Vf4OfOnSM4OBhbW1utpaO40Ol0dOvWjd9//11r3QLo0KGD9nnalptr0dfYEryFLSFb2B66nejEaKP7NazQkG7VuuFf3Z+Wni05sPcA249sp2zZskTwaB+n7CzhX69ePSB1Wn92p5CL/FOhQgWio6MJCwujdu0nh9OUlBQaNWoEpG5XIi03RY+EGyFy6ZtvviE4OJh27dpha2sLpLa2ZCazcJOcnMz58+cBaNCggXbcysqKZ555hj/++ENbSExtuVGVKlWKChUqEBYWxoULF7RwpLbadO7cuUhP/c7MoEGD+P3334HU4DB8+HAaN24MgN6gJ9olGjrBnnp78JrlZXRtGfsydK3WFf9q/nSt1pWKzsb7bKk/nyZNmnD16lWCglJnQmW1gJ9KXVgxMDCQK1eukJCQkO1rRd6rUKECFy5cyHTG1EcffcTff//Nnj17KF++PJcvX+bMmTNAakCVlpuiR8KNELnw4MEDbQXi+/fvA2Bra0vXrl0zvUadLXX37l0ePHighY5Lly6RlJSEk5MTVapUMbqmT58+/PHHH0DqZoBpw4+qTp06hIWFERQUlC7c9OvXLxevsvDq3r07Bw4coHTp0tSuXZuHSQ9ZFbSK9RfXs/HSRu7G3YU2kEgiFjoLnvZ4Wmud8avoh6VFxq1r8CjcVK1aFR8fHy3cZKf1pU6dOtSsWZOLFy/yww8/AKlvjGr4FQXrSTOmfvnlF27fvs22bdt49tlnjRbZDAgIkJabIkgGFAuRC+qCehUrVtS6fbp164aTk1Om17i6umqrnKadMfXff6nTiuvXr4+FhfH/ml27dtUGydasWRMHB4d0961Tpw6A9iZ89epVTpw4gYWFRZYtSUVd5bqV2fFgB93+6kbZb8oycPlAFp1axN24u7jYuMB/wEq4NvEaB8Ye4P1279OscrMsgw0Yh5u0XV3ZaX3R6XSMHDkSSH3jBBlnY05ZrXUTFRWlhZ5z584BpAs3MhW86JGWGyFyQZ295Ofnx8qVK1m/fj2tW7d+4nVVq1bl3r17hIaGal0YarjJqFXG2dmZjh07snnz5nRdUqrHw83atWsBaN26dbH6pawoCsduHWPN+TWsv7heW2tGVd2tOr1q9qJXzV608mxFKZdSxMfHkxCVAG6PzouNjUWn02UYFME43LRp0wYXFxfc3Nxwc3PL8PzHPffcc0ybNo34+HhAxtuYU1bhRv3/BTION4cPHyYyMhKQbqmiRMKNELmgDgBu1KgRNjY2RlO+s1K1alUCAgKMxt2offzqNOLHvf3225w7d44xY8Zk+LgabtRxO+vXrwcwGmxbVOkNeg5eP8jKoJWsClrF9Zjr2mMWOgtaebZKDTS1elGrjPF2BpUrVyY4OJhbt25p688kJSXRqFEj9Ho9QUFBWqtYWmnDTdmyZTlx4gS2trbZ3irBy8uLdu3aaascS8uN+WTVLaUGGng0dT9tuFH/vwTZV6ookXAjRC6oLTeZtaZkJqNBxVm13EDqqrtXr17N9J7qLJCQkBDu3bunvan27NnTpNoKi2R9Mruv7GZV0CpWn19NeOyj/aEcrR3pUaMHvWv1pnv17pRxyPxNp1KlSgQHBxutdXPkyBFt36+goKB0s89iYmK0wdvqGCk1GJli5MiR2s9BWm7MJ6uWm7TLJ4SEhJCQkKD9gaDT6Yw2zLSykrfMokJ+UkLkUHJysvZXnTptNLseDzcPHz7UPs+s5eZJKlWqhLOzMw8ePGDu3LkkJydTvXp1bbPOoiAhJYFtIdtYdX4V6y6sIzI+UnuslF0petfqTf/a/elarSv21vbZumdGa91s375d+/zMmTPpwo06Fqps2bK52v9p4MCBvPLKKyQkJEjLjRllFW7SttwYDAaOHj2qjbFp3769tqVHceraLQkk3AiRQ0FBQSQlJeHi4oK3t7dJ1z4ebtS/Ht3d3XP8S1Sn01GnTh2OHj3Kjz/+CECPHj1ydK+ClJCSwKZLm/jn3D9suLiBB0kPtMfKOZSjb+2+DKgzgA4+HbCxTN999CRquEnbcpM23KgtZmml7ZLKDRcXF9577z2WLl1K586dn3yByBdqt1RERATJyclGO3ur4cbBwYG4uDhthmGlSpXo2LGjFm5kvE3RIuFGiBxSx9s0bNgw2+MwVOqb5uXLlzEYDFoLUGZdUtmlhpvw8NQunGeeeSZX98svKYYUdoTuYOmZpaw+v5qYxEfL4ld2rkz/Ov0ZUGcArau0fuKspidRF/JTW25iYmI4cuSI9nh+hhuAadOmMW3atFzfR+RcmTJlsLS0RK/Xc+fOHS3wRkdHawssPvPMMyxfvlwLN7Vq1dL2KANpuSlqJNwIkUPqeBtTu6QgdfyFlZUVSUlJ3L59+4njbbJLHVQMqX+Jpt3GwdwMioED1w6w9MxSlp9bTkRcmlV/XTwYXHcwg+oNolnlZljo8m6Visdbbvbs2YNer9fe7NIOGI2IiMDe3j5Pw40wPwsLC8qXL8/t27cJDw/X/k2oM6UqVapEy5YtWb58uTaurVatWtrK3yDhpqiRcCNEDuV0MDGkrjrs5eVFSEgIoaGhRmvc5EbacNO5c2ezb8yoKAonbp9g6ZmlLDu7jBsxN7THyjmUY1DdQQytP5RWVVrlaaBJ6/GWG7VLauDAgSxbtoxr164RHR3NrVu3aNSoEVZWVtjbp47nkXBTfKjhRh1PA4+6pOrWrUvdunWNzq9VqxZlypShWrVqhISESLdUESPhRogcUBQlV+EGUt84Q0JCOHnyJKdPnwZy33KTdt8cc463uRFzg79O/8Xi04s5d/fRgE0XWxf61+nPsPrD6OjTESuL/P8VlLblRlEULdwMGjSIAwcOcOPGDc6cOcPmzZtJTEwkMTGR2NhYQMJNcaJuYKt22cKjcFOvXj1tPzBVrVq1AGjXrh0hISFUr169gCoVeUHCjRA5cPz4ce7fv4+1tXW6v/iyS33jfP3114HU1pyc3ivtPd3c3Hjw4EGBj7eJTYpl9fnVLD61mO2h27VdtO2s7OhdqzfD6g+jW/Vu2FkVbGuSOpg0ISGBc+fOce7cOXQ6HR06dKBBgwZauFmzZg0AU6ZM4d69eyiKQps2bQq0VpF/Mgo36kD+unXrUqlSJVxcXIiJSR3/pYabb775ht69exeJwfnikVyFm4SEBLM3ewtR0PR6PS+//DIA/fv3z3ABuOxI20pTt25dpk6diqOjY65qs7KyYufOncTFxRXIuioGxcCeK3tYfHoxK86t4GHSQ+2xNlXaMMp3FAPrDsTVzjXfa8mMnZ0dZcqU4d69e7Rr1w5IXVHazc2NBg0asGnTJtauXcuZM2ewtLTknXfeoXTp0marV+QPtVsps24pnU5H3bp1OXz4MLa2tnh5pW606ubmViwWwixpTA43BoOBzz77jLlz5xIeHs7FixepWrUq77//Pt7e3owbNy4/6hSi0Jg9ezYBAQG4uroyc+bMHN/n+eefx97envr169O0aVOTZ1xl5vE1W/LDlftXWHByAYtOLeJa9DXteLXS1RjpO5LnnnqOqqULT5eOl5cX9+7d4969ezg5OfHmm28Cj8Y4bdq0CUjtgpBgUzw93nLz4MEDrl1L/bertpjWq1ePw4cPU6NGDSwtczdLT5iXyeHm008/ZdGiRXz99dc8//zz2vH69esza9YsCTeiWLt+/TrvvfceAF999ZXW5ZETNjY2jB07Nq9Ky3dJ+iTWXVjH/BPz2RayTet2crV1ZXC9wYzyHUVLz5Z5FtLy0syZM1m9ejUdO3akS5cuWovz42Oc+vbta4bqREF4PNxcvHhRO67uF6bu85bbgf3C/EwON4sXL2bevHl06tSJF198UTvu6+urLVktRHH1+eef8/DhQ1q1amUU7ouzCxEX+O3kbywMXMjduLva8U4+nRjXaBx9a/fN9mrB5tK2bdsMp8XXrl1bmxIOFOvd00u6x7ulrly5AjzaXgNgzJgxxMbGMmjQoAKvT+Qtk8PNzZs3Mxw1bjAYSE5OzpOihCiMEhISWLp0KQAfffQRFhb5M3W5MIhPjmdl0Ermn5jP3qt7teMVnCowpuEYxjUaRzU30/daKmzs7OyoUaMG58+fp2HDhto4C1H8PN5yo3ZJpf2ZOzs7M3Xq1IIvTuQ5k8NN3bp12bdvX7pfAitWrMjRYmZCFBVr164lOjqaKlWq0KFDB3OXky9CIkP4OeBnfg/8naiEKCB11+0eNXowvtF4nqn5TIFM3y5Ifn5+nD9/nn79+pm7FJGP1HBz9+5dDAaDtlhflSpVzFmWyCcm/5aaPn06o0aN4ubNmxgMBlatWsWFCxdYvHgx//77b37UKEShsHDhQiB1p+fi1GpjUAxsCd7CTwE/senSJm0sjZerF+Mbj2d0w9F4uBTfHa0///xzGjVqxCuvvGLuUkQ+UlcY1uv1REZGZthyI4oPk8NNnz59WL9+PR9//DGOjo5Mnz6dxo0bs379erp06ZIfNQphdrdu3WLr1q1AargpDqLio/g98Hd+DviZkKgQ7Xj36t2Z2Gwi3ap3y7dVgwuTKlWqaLOnRPFlbW2Nm5sbkZGRhIeHS8tNMZej9uU2bdqwbdu2vK5FiELrzz//xGAw0KpVK2rUqGHucnLlVNgpZgfM5s/TfxKfEg9AKbtSjGk4hpebvkx1N1mJVRRP7u7uWriRlpvizeRwExAQgMFgoHnz5kbHjxw5gqWlpdFGY0IUF3/++ScAo0ePNm8hOWRQDGy4uIHvDn3Hnqt7tONPuT/FxKYTGd5gOI42uVtAUIjCzt3dnaCgIC5fvkxEROrGrdJyUzyZ3Ob8yiuvcP369XTHb968KX3WoljS6/XaSqb+/v5mrsY08cnxzDs+j7qz69L7797suboHKwsrhtQbwt7Rewl8IZDn/Z6XYCNKBHU6+LFjxwBwcXGhVKlSZqxI5BeTW27OnTtH48aN0x1v1KiR9gYgRHFy79499Ho9Op2OChUqmLucbLkbe5efA35mdsBsbW0aV1tXXvB7gVebv1qsBwgLkRl1xlRAQAAgrTbFmcnhxtbWlvDw8HS75d6+fRsrq+I1RVQISP23DVC2bFmsra3NXE3WLkRcYObhmSw6tYiElAQAqrhW4Y2n32Bco3E42zqbuUIhzEcNN6dPnwZkvE1xZnIa6dq1K1OnTmXt2rW4uqZuhnf//n3+97//yWwpUSyFhYUB5Gqrhfx2+MZhvtj/BesvrNemcjep1IS3WrzFgLoDit3aNELkhNotpS44Ky03xZfJv/G+/fZb2rZti5eXl7ZoX2BgIO7u7vzxxx95XqAQ5qa23BS2LilFUdh9ZTef7vuUnZd3asd71ezFWy3fok2VNoVynychzEVtuVFJuCm+TA43lStX5vTp0/z111+cOnUKe3t7xowZw7Bhwwp9k70QOVHYWm4URWHjpY18tu8zDt04BICVhRUjnhrBO63eoXbZ2mauUIjC6fFwI91SxVeO2qodHR2ZMGFCXtciRKFUWFpuDIqBVUGr+GzfZwSGBQJga2nL+Mbjebvl23iVkl/UQmRF7ZZSSctN8ZWtcLNu3Tq6d++OtbU169aty/Jc2VVXFDdquDFXy41BMbA6aDUf7vmQM3fOAOBo7chLTV5icovJVHQuHC1KQhR20nJTcmQr3PTt25ewsDDKly9P3759Mz1Pp9Oh1+vzqjYhCgVzdUspisL6i+v5YPcHWkuNq60rrzd/ndeav0YZhzIFWo8QRZ2DgwNOTk48fPgQKyurQtPVLPJetsKNwWDI8HMhSoKC7pZSFIXNwZuZvns6x26lLjbmbOPMpKcn8cbTb1DavnSB1CFEcVS+fHkePnyIh4cHlpaW5i5H5BOTVihOTk6mU6dOXLp0Kc8KmD17Nt7e3tjZ2dG8eXOOHj2a5fn379/nlVdeoWLFitja2lKzZk02btyYZ/UI8biCbLnZfWU3rRa0oseSHhy7dQwHawemtJrC5dcv83GHjyXYCJFLateUjLcp3kwaUGxtba0tfpQXli1bxuTJk5k7dy7Nmzdn1qxZ+Pv7c+HChXQDvwCSkpLo0qUL5cuXZ8WKFVSuXJmrV6/K8tki1wwGAy+99BLOzs58++232vGHDx/y8OFDIH9bbk6FnWLKjilsDt4MgJ2VHS83eZl3W79Lecf0/y8IIXJGDTcy3qZ4M3m21HPPPcdvv/3Gl19+mesnnzFjBs8//zxjxowBYO7cuWzYsIEFCxYwZcqUdOcvWLCAyMhIDh48qE079/b2znUdQpw+fZp58+YBMH78eGrXTp1OrbbaODo64uyc96v7Xrl/hem7pvPn6T9RULCysGJC4wlMaztNBgoLkQ88PFK3Hnl8lX1RvJgcblJSUliwYAHbt2/Hz88PR0fjDfdmzJiRrfskJSVx/Phxpk6dqh2zsLCgc+fOHDp0KMNr1q1bR4sWLXjllVdYu3Yt5cqVY/jw4bz77ruZ9p0mJiaSmJiofR0TE5Ot+kTJkvbf3MqVK3nvvfeA/JspFREXwef7Pmd2wGyS9EkADKk3hE87fkp1t+p5+lxCiEcmT56Ms7MzL774orlLEfnI5HBz5swZbePMixcvGj1mymqoERER6PX6dFPz3N3dOX/+fIbXhIaGsnPnTp599lk2btxIcHAwL7/8MsnJyXzwwQcZXvPFF1/w0UcfZbsuUTKcP3+e4OBgevbsCWQebtSWm7zqkkpMSWTW4Vl8vv9zYhJTg3ZHn4581fkrmlRqkifPIYTInI+PD59//rm5yxD5zORws2vXrvyoI1sMBgPly5dn3rx5WFpa4ufnx82bN/nmm28yDTdTp05l8uTJ2tcxMTF4enoWVMmiEFIUhZ49exISEsKePXto27atUbg5efIkISEhVKtWLc9abhRFYe2Ftby59U1Co0IB8HX35avOX9G1WlfZJkEIIfKQSbOlli1bxrPPPsugQYOYO3durp64bNmyWFpaEh4ebnQ8PDw807+SK1asSM2aNY26oOrUqUNYWBhJSUkZXmNra4uLi4vRhyjZgoKCCAkJAVL/Td+5c4fg4GAAmjRJbT1ZuXIlkDfTwM/cOUOXP7rQb1k/QqNCqehUkUV9F3HihRP4V/eXYCOEEHks2+Fmzpw5DBs2jGPHjnHp0iVeeeUV3n777Rw/sY2NDX5+fuzYsUM7ZjAY2LFjBy1atMjwmlatWhEcHGy01s7FixepWLEiNjY2Oa5FlCybN2/WPl+1ahUHDx4EUoPyuHHjAFixYgWQu2ng9+LuMXHjRHzn+rLj8g5sLW15r817XHz1IiN9R2KhM+lvCyGEENmlZFPdunWVDz/8UPv6jz/+UBwcHLJ7eYb+/vtvxdbWVlm4cKFy7tw5ZcKECUqpUqWUsLAwRVEUZcSIEcqUKVO0869du6Y4OzsrEydOVC5cuKD8+++/Svny5ZVPP/00288ZHR2tAEp0dHSuahdFV5cuXRRA+2jdurUCKGPHjlXCwsIUnU6nAMqVK1cUf39/BVAWLFiQ7fun6FOUn478pJT+srTChyh8iDJg2QAlNDI0H1+VEEIUb6a8f2d7zE1oaCijRo3Svh4+fDjjxo3j9u3bOR6PMGTIEO7evcv06dMJCwujYcOGbN68WRtkfO3aNSwsHv116+npyZYtW3jjjTd46qmnqFy5Mq+//jrvvvtujp5flDyxsbHs2bMHgObNm3PkyBH2798PQMuWLXF3d6dt27bs2bOHRYsWmdxyc+TGEV7a8BInw04C8JT7U8zyn0UHnw758GqEEEJkRKcoipKdEy0sLAgPD6dcuXLaMWdnZ06dOlWk1guIiYnB1dWV6OhoGX9TAm3YsIGePXvi5eXFDz/8QJ8+fbTHzp49S926dfn7778ZNmwY5cuXJyUlhcjISAIDA/H19c30vpHxkUzdPpX5J+ajoFDKrhSfdfyMCX4TsLIwedy+EEKIx5jy/m3Sb933338fBwcH7eukpCQ+++wzXF1dtWPZXedGCHNQx9t069aNrl27apvolSpVSlu4b8CAAXh6enL9+nXtuswGFBsUA4sCF/HO9neIiIsAYJTvKL7u8rWsLCyEEGaS7XDTtm1bLly4YHSsZcuWhIaGal/LrA9R2Knhpnv37tjZ2dGrVy+WLl1K8+bNtS5Qa2trXnvtNW3AvKWlJWXLlk13r//C/+OlDS9x4PoBAOqVq8fPz/xMW6+2BfRqhBBCZCTb3VLFhXRLlVyhoaFUq1YNKysrIiMjtW7VcePG8dlnn+Hv76+dGx0djYeHBw8fPqRixYrcunVLeywxJZFP9n7CVwe+IsWQgqO1Ix+2/5DXm7+OtaW1OV6aEEIUe/nWLSVEUaa2MtaqVUvbJ8rX15djx46lO9fV1ZXx48cza9Yso8HEh64fYty6cQRFBAHQv05/ZvnPwtNVFoYUQojCQsKNKDHi4+MBcHJyytb5U6ZM4eLFiwwfPpzYpFje2/kePxz5AQUFd0d3fn7mZ/rX6Z+fJQshhMgBCTeixIiLiwMwGhSfFXd3dzZs2MDB6wfxnetLSFTqqsajfEcxw38GbvZu+VarEEKInJNwI0oMU8NNkj6JD3d/yFcHvsKgGPB08WRer3l0q94tP8sUQgiRSyaHm+TkZKytMx40GRERkeGsEiEKAzXc2NvbP/Hcs3fO8tzq5wgMCwRgpO9Ifuj2A652rllfKIQQwuxM3txm6NChZDTBKjw8nPbt2+dFTULkC3XMTVYtNwbFwIxDM/Cb50dgWCBl7MuwYtAKFvVdJMFGCCGKCJPDzbVr1xg/frzRsbCwMNq3b68tgiZEYfSkbqlr0dfovLgzb259k0R9Ij1q9ODMy2cYUHdAQZYphBAil0wONxs3buTgwYNMnjwZgFu3btGuXTsaNGjAP//8k+cFCpFXMgs3iqLwx6k/aDCnAbuu7MLB2oFfev7Cv8P+pYJTxisTCyGEKLxMHnNTrlw5tm7dSuvWrQH4999/ady4MX/99ZfRJpdCFDYZjbmJjI/khX9fYMW5FQC08GjB4n6Lqe5W3Sw1CiGEyL0czZby9PRk27ZttGnThi5duvDHH3/I1gui0Ht8zM2BawcYtnIY12OuY2VhxUftP+KdVu/IRpdCCFHEZeu3eOnSpTMML3Fxcaxfv54yZcpoxyIjI/OuOiHykNpyY2dvx5f7v2TazmnoFT013GqwdMBS/Cr5mblCIYQQeSFb4WbWrFn5XIYQ+S8uLg4c4bfE3zi34xwAwxsMZ+4zc3G2dTZzdUIIIfJKtsLNqFGj8rsOIfLdLYtb8CKcSzyHvZU9P/X4iTENx0iXqhBCFDMmDy7YuHEjlpaWRjsoA2zduhW9Xk/37t3zrDgh8srCwIUE1A8AC/Cw9WDz2M3UK1/P3GUJIYTIByZPb5oyZQp6vT7dcYPBwJQpU/KkKCHySoohhclbJjNm7RgUCwWC4Pv630uwEUKIYszkcHPp0iXq1q2b7njt2rUJDg7Ok6KEyAtR8VH0+KsHMw/PBKDsmbLwD5RxLvOEK4UQQhRlJocbV1dXQkND0x0PDg7G0dExT4oSIreC7gbR7NdmbAvdhoO1AysGrcAxwBGU7O0tJYQQougyOdz06dOHSZMmERISoh0LDg7mzTffpHfv3nlanBA5seHiBpr/2pzgyGC8XL04OPYgA+oOMHlXcCGEEEWTyeHm66+/xtHRkdq1a+Pj44OPjw916tShTJkyfPvtt/lRoxDZoigKX+3/il5Le/Eg6QFtvdoS8HwAvhV8gextnCmEEKLoM3m2lKurKwcPHmTbtm2cOnUKe3t7nnrqKdq2bZsf9QmRLfHJ8YxfP54l/y0B4EW/F/m++/fYWNoAqcEno+0XhBBCFD85Wmdep9PRtWtXunbtmtf1CGGyGzE36Pt3X47fPo6VhRU/dPuBl5q+ZHROUlISBoMBkJYbIYQo7nK00+WePXvo1asX1atXp3r16vTu3Zt9+/bldW1CPNGh64doMq8Jx28fp4x9GbaP2J4u2MCjrRdAwo0QQhR3JoebP//8k86dO+Pg4MBrr73Ga6+9hr29PZ06dWLJkiX5UaMQGfrn7D+0X9Se8NhwGpRvQMDzAbTzbpfhuep4GysrK6ytrQuwSiGEEAVNpyiKYsoFderUYcKECbzxxhtGx2fMmMH8+fMJCgrK0wLzWkxMDK6urkRHR+Pi4mLuckQOzTw0k8lbJwPQt3Zf/uj3B042TpmeHxwcTI0aNXB2diYmJqagyhRCCJFHTHn/NrnlJjQ0lF69eqU73rt3by5fvmzq7YQwiUEx8OaWN7Vg82qzV1kxaEWWwQaQaeBCCFGCmBxuPD092bFjR7rj27dvx9PTM0+KEiIjiSmJDF85nBmHZwDwdeev+b7b91haWD7xWgk3QghRcpg8W+rNN9/ktddeIzAwkJYtWwJw4MABFi5cyPfff5/nBQoBEJccR6+lvdh5eSfWFtYs7LuQ4Q2GZ/t6WeNGCCFKDpPDzUsvvUSFChX47rvv+Oeff4DUcTjLli2jT58+eV6gEGmDjbONM2uGrqGjT0fT7iFr3AghRImRo3Vu+vXrR79+/fK6FiHSSUhJoO/ffbVgs3XEVp72eNrk+0i3lBBClBwmj7mpWrUq9+7dS3f8/v37VK1aNU+KEgJSx9j0W9aPbaHbcLR2ZNOzm3IUbEDCjRBClCQmh5srV66g1+vTHU9MTOTmzZt5UpQQSfokBi4fyObgzThYO7Dx2Y20qtIqx/eTcCOEECVHtrul1q1bp32+ZcsWXF1dta/1ej07duzA29s7T4sTJVOyPpnBywfz78V/sbey599h/9LWK3d7l6kDimXMjRBCFH/ZDjd9+/YFUveVGjVqlNFj1tbWeHt789133+VpcaLkSdYnM2zlMNZeWIudlR3rhq2jg0+HXN9XWm6EEKLkyHa4UTcd9PHxISAggLJly+ZbUaJkSjGk8Nzq51gZtBIbSxvWDFlD56qd8+TeEm6EEKLkMHm2lKxCLPKD3qBn5OqR/HP2H6wtrFk1eBX+1f3z7P4SboQQouTI9oDiQ4cO8e+//xodW7x4MT4+PpQvX54JEyaQmJiY5wWK4k9v0DNm7RiWnlmKlYUVKwav4Jmaz+Tpc8iYGyGEKDmyHW4+/vhjzp49q33933//MW7cODp37syUKVNYv349X3zxRb4UKYqvJH0SI1aP4I/Tf2Cps+Sfgf/Qu1bvPH8eabkRQoiSI9vhJjAwkE6dOmlf//333zRv3pz58+czefJkfvjhB23FYiGyIzYplj5/99FabP4e+Df96uTP4pASboQQouTI9pibqKgo3N3dta/37NlD9+7dta+bNm3K9evX87Y6UWw9SHxA97+6c+D6ARysHVg5eCXdqnfLt+eTcCOEECVHtltu3N3dtcHESUlJnDhxgqeffrRa7IMHD7C2ts77CkWx8yDxAd3+6saB6wdwtXVl24ht+RpsQMbcCCFESZLtcNOjRw+mTJnCvn37mDp1Kg4ODrRp00Z7/PTp01SrVi1fihTFx8Okh3T7qxsHrx+klF0pdozcQUvPlvn+vNJyI4QQJUe2u6U++eQT+vfvT7t27XBycmLRokXY2Nhojy9YsICuXbvmS5GieEgxpDBs5TAt2GwfsR2/Sn4F8twSboQQouTIdrgpW7Yse/fuJTo6GicnJywtLY0eX758OU5OTnleoCgeFEXh9U2v8+/Ff7GzsmPj8I0FFmxAwo0QQpQkJi/il3ZPqbTc3NxyXYwovn448gM/H/sZHTr+7PcnLTxbFOjzy5gbIYQoOUzeFVwIUx2+cZi3tr0FwDddvmFA3QEFXoO03AghRMkh4Ubkq3tx9xi8fDAphhSG1BvC5BaTzVKHhBshhCg5JNyIfGNQDIxaM4rrMdep4VaDeb3modPpCryO5ORkUlJSAAk3QghREki4Efnmu4PfseHSBmwtbfln0D+42LqYpQ611QZkzI0QQpQE2R5QvG7dumyd17t33u8LJIqeA9cOMHXHVAC+7/Y9DSs0NFst6mBinU6Hra2t2eoQQghRMLIdbvr27fvEc3Q6HXq9Pjf1iGIgIi6CoSuHolf0DKs/jAl+E8xaT9rxNuboFhNCCFGwsh1uDAZDftYhigmDYmDE6hHciLlBzTI1+aXnL2YPFDKYWAghShYZcyPy1Ff7v2Jz8GbsrOxYPmg5zrbO5i5JCzcy3kYIIUqGbLfc7N27N1vntW3bNsfFiKJt79W9TNs1DYCfuv/EU+5PmbmiVOqYG2m5EUKIkiHb4aZ9+/Za94KiKBmek9MxN7Nnz+abb74hLCwMX19ffvzxR5o1a/bE6/7++2+GDRtGnz59WLNmjcnPK/LOndg7DF0xFINiYKTvSMY2GmvukjTSLSWEECVLtrulSpcujaenJ++//z6XLl0iKioq3UdkZKTJBSxbtozJkyfzwQcfcOLECXx9ffH39+fOnTtZXnflyhXeeusto53JhXnoDXqeXfUstx/epm65uvzc42ezj7NJS8KNEEKULNkON7dv3+arr77i0KFDNGjQgHHjxnHw4EFcXFxwdXXVPkw1Y8YMnn/+ecaMGUPdunWZO3cuDg4OLFiwINNr9Ho9zz77LB999BFVq1Y1+TlF3vps32dsD92Og7UDywctx9HG0dwlGZExN0IIUbJkO9zY2NgwZMgQtmzZwvnz53nqqaeYOHEinp6evPfee9oKsKZISkri+PHjdO7c+VFBFhZ07tyZQ4cOZXrdxx9/TPny5Rk3bpzJzyny1voL6/lw94cAzHlmDnXL1TVvQRmQMTdCCFGy5Gi2VJUqVZg+fTrbt2+nZs2afPnll8TExJh8n4iICPR6Pe7u7kbH3d3dCQsLy/Ca/fv389tvvzF//vxsPUdiYiIxMTFGHyJvHL91nKErh6Kg8ILfC4z0HWnukjIk3VJCCFGymBxuEhMTWbJkCZ07d6Z+/fqULVuWDRs24Obmlh/1GXnw4AEjRoxg/vz5lC1bNlvXfPHFF0bdZp6envlcZclw9f5Vei7tSVxyHF2rdeXH7j+au6RMSbgRQoiSJduzpY4ePcrvv//O33//jbe3N2PGjOGff/7JVagpW7YslpaWhIeHGx0PDw+nQoUK6c4PCQnhypUr9OrVSzumLi5oZWXFhQsXqFatmtE1U6dOZfLkRztRx8TESMDJpRO3T9BzSU/CHoZRv3x9/hn4D9aW1uYuK1My5kYIIUqWbIebp59+mipVqvDaa6/h5+cHpHYRPc6UvaVsbGzw8/Njx44d2vYOBoOBHTt2MHHixHTn165dm//++8/o2LRp03jw4AHff/99hqHF1tZW9hPKQ/9e/JchK4YQlxxHvXL12Dh8I652pg8kL0jSciOEECVLtsMNwLVr1/jkk08yfTwn69xMnjyZUaNG0aRJE5o1a8asWbOIjY1lzJgxAIwcOZLKlSvzxRdfYGdnR/369Y2uL1WqFEC64yLvBUcGM2j5IBJSEuhStQvLBy0v9MEGZECxEEKUNGbfW2rIkCHcvXuX6dOnExYWRsOGDdm8ebM2yPjatWtYWMguEeZmUAyMXzeehJQEOvp0ZMPwDYW6KyqtBw8eABJuhBCipDCp5Sa/TJw4McNuKIDdu3dnee3ChQvzviCRzq8nfmXP1T04WDswv9f8IhNsAK5evQogY62EEKKEMLlJZPny5fTv35/69etTv359+vfvz4oVK/KjNlFI3Hpwi7e3vQ3Apx0+pWrporVwYnBwMADVq1c3cyVCCCEKQrbDjcFgYMiQIQwZMoRz585RvXp1qlevztmzZxkyZAhDhw7NdM8pUbR9vOdjYhJjaFqpKa81f83c5ZgkNjZWWzPp8Zl0Qgghiqdsd0t9//33bN++nXXr1tGzZ0+jx9atW8eYMWP4/vvvmTRpUl7XKMwoNCqU307+BsB3Xb/D0sLSzBWZJiQkBAA3NzdKly5t5mqEEEIUhGy33Pz+++9888036YINpE7//vrrr7PcD0oUTR/v+ZgUQwr+1fxp41X0NilVw4202gghRMmR7XBz6dIloz2gHte5c2cuXbqUJ0WJwiHobhB/nP4DgE86ZL4EQGEm422EEKLkyXa4sbe35/79+5k+HhMTg52dXV7UJAqJj/Z8hEEx0KdWH5pWbmrucnJEWm6EEKLkyXa4adGiBXPmzMn08dmzZ9OiRYs8KUqY34WIC/xz9h8APmr/kZmryTlpuRFCiJIn2wOK33vvPdq3b8+9e/d46623qF27NoqiEBQUxHfffcfatWvZtWtXftYqCtCXB75EQaF3rd74VvA1dzlPdPDgQXbu3Mm7776LtfWjNXik5UYIIUqebIebli1bsmzZMiZMmMDKlSuNHitdujRLly6lVatWeV6gKHhX7l/hj1OpY23ea/Oemat5MkVRGD58OFevXqV8+fJMmDABgKSkJK5duwZIy40QQpQkJq1Q3K9fP/z9/dmyZYs2eLhmzZp07dpVlrYvRr4+8DV6RU/nqp1pVrmZuct5oiNHjmirEC9atEgLN1euXMFgMODo6Kht5yGEEKL4M3n7BQcHB/r165cftYhC4Hr0dW1dm2ltppm5muxZtmyZ9vnBgwe5ePEiNWvW1MbbVKtWDZ1OZ67yhBBCFLBsDyjeuXMndevWJSYmJt1j0dHR1KtXj3379uVpcaLgvbfzPZL0SbTzakdbr7bmLueJDAYDy5cvB6Bs2bJAausNyHgbIYQoqbIdbmbNmsXzzz+Pi4tLusdcXV154YUXmDFjRp4WJwrWidsntHVtvu36bZFo7Th48CA3b97ExcWFmTNnArB48WL0er3MlBJCiBIq2+Hm1KlTdOvWLdPHu3btyvHjx/OkKFHwFEXhza1vAvBsg2dpUqmJmSvKHrVLqm/fvgwcOJBSpUpx48YNdu3aJS03QghRQmU73ISHhxtNsX2clZUVd+/ezZOiRMH79+K/7L6yG1tLWz7r+Jm5y8kWvV6v7Ug/ZMgQ7OzsGDZsGACDBw/Wukml5UYIIUqWbIebypUrc+bMmUwfP336NBUrVsyTokTBik+O5/XNrwMw6elJeJXyMnNF2XPmzBnCwsJwcXHRtgZ59913qVmzJlFRUdr4MGm5EUKIkiXb4aZHjx68//77JCQkpHssPj6eDz74IMNNNUXh98X+L7h8/zIeLh5Ma1s0ZkgBXL58GUhdjsDGxgYALy8vzp07x9q1a+nRowcvvPACXl5FI6wJIYTIG9meCj5t2jRWrVpFzZo1mThxIrVq1QLg/PnzzJ49G71ez3vvFf4F34SxS/cu8dWBrwCY5T8LJxsnM1eUferaNo+HF0tLS3r37k3v3r3NUZYQQggzy3a4cXd35+DBg7z00ktMnToVRVEA0Ol0+Pv7M3v2bFkorYhRFIWXN75Mkj6JbtW70b9Of3OXZBJ19WFpmRFCCJGWSYv4eXl5sXHjRqKioggODkZRFGrUqEHp0qXzqz6Rj+Yem8v20O3YWdnxY/cfi8TU77Qya7kRQghRsmV7zE1apUuXpmnTpjRr1kyCTREVHBnMW9veAuDLTl9S3a1gZhRFRUXRoUMHXn/9dWJjY3N1L7XlpkqVKnlRmhBCiGIiR+FGFG16g55Ra0YRlxxHB+8OvNr81QJ77hUrVrB7925++OEHGjdunKu1kaTlRgghREYk3JQwiqLw8oaXOXj9IM42zvze53csdAX3z2Dz5s0AWFhYcPHiRdq0aaOFFFPEx8dz584dQMKNEEIIYxJuSpjpu6Yz78Q8dOhY2Hdhga5pk5yczPbt2wHYsGEDjRo1Ij4+npUrV5p8r+vXrwPg6OgoXaNCCCGMSLgpAUKjQplxaAY9l/Tk032fAjDnmTkFPjvqyJEjxMTE4ObmRpcuXRg1ahQA69evN/leabukitpAaCGEEPnLpNlSouiJS46j8S+NiU6M1o593P5jXmjyQoHXonZJde3aFUtLS3r16sWkSZPYt28fUVFRJrXAyHgbIYQQmZGWm2Lu+K3jRCdGU8quFF93/poTE07wfrv3zVLLli1bALQNWKtWrUrdunXR6/Va8FFt27aNESNGEBUVleG9ZKaUEEKIzEi4KeYO3zgMQAfvDrzd6m0aVWxkljru3r2rzYzq2rWrdrxXr16AcddUSkoK48aN488//2TOnDkZ3k9aboQQQmRGwk0xd/hmarhp4dHCrHVs27YNRVHw9fU12mBVDTebNm0iOTkZgLVr12oDhjMbjyPhRgghRGYk3BRjiqJw6PohAJ72eNqstajdTmqXlOrpp5+mbNmy3L9/nwMHDgDwww8/aI8fOXJEm/KdlnRLCSGEyIyEm2Lsesx1bj+8jaXOEr9Kfmarw2AwaONt/P39jR6ztLSkR48eAHzwwQfs27ePvXv3YmlpSdWqVVEUhY0bNxpdo9frtZYdabkRQgjxOAk3xZg63sa3gi8O1g5mq+PUqVPcuXMHR0dHWrVqle7x1157DUdHR/bu3UvHjh0B6N+/PyNGjADSd02FhYWRkpKCpaUllSpVyv8XIIQQokiRcFOMqeHG3ONt1C6pTp06YWNjk+5xPz8/9u7dS4UKFUhJSQHg1Vdf1cbjbN26lcTERO18dbyNh4cHlpaW+V2+EEKIIkbCTTGmhhtzj7fJrEsqrcaNG3P48GHatGnD8OHDad26NY0bN6ZSpUo8fPiQ3bt3a+fKYGIhhBBZkUX8iqnElERO3D4BmDfcxMTEaAOFHx9M/DgvLy/27t1rdKxnz57MmzePt99+m507d1KqVCm2bt2qnS+EEEI8TsJNMXUq/BSJ+kTKOpSlWulqZqtj586dpKSkUKNGDapWrWry9YMHD2bevHn8999//Pfff0aP1atXL6/KFEIIUYxIuCmmDlxLbS1pXrm5Wfdeyk6XVFY6derEkSNHCAgI4Ny5c8TGxuLh4UG1atUYOnRoXpYqhBCimJBwU0xtv5y6+3Z77/Zmq0FRlEzXtzFFs2bNaNasWV6VJYQQopiTAcXFUJI+iT1X9gDQpWoXs9URHR3NlStXAGjbtq3Z6hBCCFGySLgphg5dP0RscizlHcvTwL2B2epQVxZ2cXHB2dnZbHUIIYQoWSTcFEPbQ1O7pDpX7YyFznw/4vDwcADKly9vthqEEEKUPBJuiqFtodsA6OzT2ax1qC03Em6EEEIUJAk3xUxUfBQBtwIA6FLNfONt4FHLjbu7u1nrEEIIUbJIuClmdl3ZhUExULtsbTxcPMxai7TcCCGEMAcJN8XMtpDC0SUF0nIjhBDCPCTcFCOKorApeBNg/i4pkJYbIYQQ5iHhphgJuBXA1eirOFo70rmqtNwIIYQomSTcFCP/nP0HgF61euFg7WDmaqTlRgghhHlIuCkmFEVh+bnlAAyuO9jM1aSScCOEEMIcJNwUE0dvHuVa9DWcbJzoVt14H6c1a9awdu3aAq0nISGB6OhoQLqlhBBCFCzZOLOY0LqkavbC3tpeOx4REcHAgQNRFIWrV6/i4VEw08Pv3r0LgLW1NaVKlSqQ5xRCCCFAWm6KBaMuqXrGXVIBAQHo9XoMBgNr1qwpsJrSbr2g0+kK7HmFEEIICTfFwMLAhVyPuZ5hl9SxY8e0z1etWlVgNcl4GyGEEOYi4aaIO3PnDK9sfAWAqa2nYmdlZ/R4QECA9vmePXu07qL8JtPAhRBCmIuEmyLsYdJDBi0fRHxKPP7V/JnSeorR44qiaOHGyckJg8HAunXrsn1/RVFISUnJUW3SciOEEMJcJNwUYe9ue5fzEeep7FyZP/r9gYXO+Md58+ZNwsLCsLS05LXXXgNSu6YMBgN79+4lLCwsy/u/9dZbODo6cvr0aZNrSzvmRgghhChIhSLczJ49G29vb+zs7GjevDlHjx7N9Nz58+fTpk0bSpcuTenSpencuXOW5xdXp8JOMff4XAAW91tMOcdy6c5Rx9vUr1+f5557DoBt27bh6+tLu3btqFmzJvPmzUNRlHTX3r17l59++omkpCRWr15tcn1qy410SwkhhChoZg83y5YtY/LkyXzwwQecOHECX19f/P39tTfHx+3evZthw4axa9cuDh06hKenJ127duXmzZsFXLn5KIrCpC2TMCgGBtUdREefjhmep3ZJNWnShDp16lC7dm2Sk5M5c+YMFhYWPHjwgBdeeIFu3bqRkJBgdO3ChQtJSkoC4PDhwybXKN1SQgghzMXs4WbGjBk8//zzjBkzhrp16zJ37lwcHBxYsGBBhuf/9ddfvPzyyzRs2JDatWvz66+/YjAY2LFjRwFXnr/mBMxhdVDGLSYrg1ay+8pu7Kzs+KbLN5neQw03TZs2BeCjjz6ifv36fPTRR9y5c4eZM2dib2/P1q1bmT9/vnadwWDgl19+0b4+evRohq07WZEBxUIIIczFrOEmKSmJ48eP07nzo00eLSws6Ny5M4cOHcrWPeLi4khOTsbNzS2/yixw16Ov8/LGlxm8YjA3Y4xbpGKTYnlr61sAvNPyHbxKeWV4D0VRtG6pJk2aADB48GD+++8/pk+fTpkyZZg0aRLfffcdAF9++aXWerN9+3ZCQkJwcXHB1taWyMhIgoODTXoN0nIjhBDCXMwabiIiItDr9en+und3d3/iYFfVu+++S6VKlYwCUlqJiYnExMQYfRR29+LvAZBiSOHngJ+NHpu+azpXo69SxbUK77R6J9N7hISEEBUVhY2NDQ0aNMj0vLFjx+Lh4cGtW7f47bffAJg7N3Usz8iRI2ncuDEAR44cyXb9BoNBm3IuLTdCCCEKmtm7pXLjyy+/5O+//2b16tXY2dlleM4XX3yBq6ur9uHp6VnAVZouNilW+/yX478QnxwPwLFbx5h1ZBYAc5+Zi6ONY6b3UFttGjZsiI2NTabn2draMmVK6hTyL774gtGjR2srGb/wwgs0b94cMC3cREZGotfrAShbtmy2rxNCCCHyglnDTdmyZbG0tNTGZ6jCw8OpUKFCltd+++23fPnll2zdupWnnnoq0/OmTp1KdHS09nH9+vU8qT0/xSY/Cjf34u+x5L8lJKQk8Pz65zEoBobVH0b3Gt2zvMfZs2cB8PX1feLzjRs3jkqVKnHz5k0WLVqEoii8/vrr1K9f36Rws2nTJl599VXtuUuXLp1lsBJCCCHyg1nDjY2NDX5+fkaDgdXBwS1atMj0uq+//ppPPvmEzZs3a+NJMmNra4uLi4vRR2GXtuUG4OO9H1Pzx5oEhgXiZu/GrG6znngPdYxMzZo1n3iunZ0dX375JQBt27bl8OHDzJqV+hxquAkMDEw3o+pxr776Kj/99BO9evUCpEtKCCGEeZi9W2ry5MnMnz+fRYsWERQUxEsvvURsbCxjxowBUsd9TJ06VTv/q6++4v3332fBggV4e3sTFhZGWFgYDx8+NNdLyHMPk1JfS9NKTXG0duRa9DWux1ynsnNllg5YSnnHJw/SvXTpEgDVq1fP1nOOGDGChw8fsnv3bi3QAHh7e1OuXDmSk5M5efJkptdHREQQEhICwIMHDwAZTCyEEMI8zB5uhgwZwrfffsv06dNp2LAhgYGBbN68Wfur/9q1a9y+fVs7f86cOSQlJTFw4EAqVqyofXz77bfmegl5Tu2WquxSmc87fU7dcnWZ0XUGwa8F07Va1yderyiKFm5q1KiR7ed1dHRMt4O3Tqfj6aefBrLumlIXUvTy8sLPzw+AqlWrZvu5hRBCiLxiZe4CACZOnMjEiRMzfGz37t1GX1+5ciX/CzIztVvKycaJ15q/xmvNXzPp+oiICGJiYtDpdFSrVi3X9TRv3pz169ezYsUKXnjhBezt7dOdo4abdu3a8fPPP7N8+XL8/f1z/dxCCCGEqczeciPSU1tuHK0znw2VFbXVxsPDI9NZZKbo168fNjY2HDhwgE6dOmW4s7jaqtOsWTMcHR0ZPXo0FStWzPVzCyGEEKaScFMIqWNuchtuTOmSykrdunXZvn07pUuX5tChQ7Rr147ExETtcUVRtJabtON1hBBCCHOQcFMIqd1SWa1jkxV1plRehRuANm3acPDgQcqUKUNQUBB79+7VHgsJCSEyMhJbW9ssp+ULIYQQBUHCTSGkdks52Tjl6Pq8brlR1a5dm549ewIYTd9XW20aNWok69oIIYQwOwk3hVBux9yoLTfZnQZuik6dOgHG4SbteBshhBDC3CTcFEK56ZbK6TTw7FLDzYkTJ4iKigKQ8TZCCCEKFQk3hVBuBhTfvXtXmwaeH+vMVKpUidq1a2MwGNizZw9JSUna4n7SciOEEKIwKBTr3AhjmY25URSF0NBQjhw5QqVKlWjfvn26a9UuKU9PzzyZBp6RTp06cf78eXbs2EFMTAyJiYmUKVMmT9bUEUIIIXJLwk0hlFG3VEhICB07duTatWsAWFlZcfnyZTw8PIyuzc8uKVWnTp2YPXs269ev56+//gLgzTffTLe6sRBCCGEO0i1VCGU0oHjDhg1cu3YNGxsbHBwcSElJMZqOrcqPaeCPa9++PRYWFly9epWoqCgaNWrEW2+9lW/PJ4QQQphCwk0hpI25SdNyo7bITJo0iQkTJgCwf/9+7fHExEQuXrxIQEAAkD8zpVSlS5emcePGQGoL0oIFC7C2ts635xNCCCFMIeGmEEq7t5QqbYtM69atgUfhJiwsDA8PD2rVqsWWLVsAqFmzZr7WOGjQIABtw1MhhBCisJAxN4VMsj6ZZEMyYNwtlXbtmjp16gBw5swZoqKi+PPPP4mIiMDW1hYfHx8aNmxI586d87XON998kwEDBsggYiGEEIWOtNwUMup4G3jULZWcnMzly5eB1JYbd3d3atSogaIoHDp0iCVLlgDw/fffExQUxNKlSzPcuTsvWVpaSrARQghRKEm4KWTU8TZWFlbYWKZuZXD16lX0ej329vbaTttq19T8+fM5efIkVlZWDBw40DxFCyGEEIWIhJtCJqvxNtWqVcPCIvVHpoabNWvWANC9e3fKlClTgJUKIYQQhZOEm0Imo2ngGa1do4Yb1fDhwwugOiGEEKLwk3BTyGS0gF9GG2HWqFGDcuXKpZ7r6EivXr0KsEohhBCi8JJwU8hktK9URuFGp9NprTd9+/bF0TFnO4gLIYQQxY1MBc8jR4KO8PHqj3GwdmD528tzfB+tWyqDBfweX3V42rRpAHz44Yc5fj4hhBCiuJFwk0cCLweyMXkjVpG5+5Y+PqA4JSVFmwb++KrDjRs3ZtWqVbl6PiGEEKK4kW6pPOJZ1hMAvbU+V/d5fEDx1atXSUlJwc7OjsqVK+euSCGEEKIEkHCTR7zKewGg2CkkJSfl+D6PDyjOaBq4EEIIITIn75Z5xKeCj/b51fCrOb7P4wOKMxpMLIQQQojMyZibPOJg5wCJgC1cCb9CDY8aT7wmI2q3lDrmRh1MLOFG5CW9Xk9ycrK5yxBCCCM2NjZ50ksh4SYPWSZZorfVcy3iWo7voXVLPdZy8/hMKSFyQlEUwsLCuH//vrlLEUKIdCwsLPDx8cHGxiZX95Fwk4ds9DbEE8/NyJs5vsfjU8HVmVI+Pj6ZXiNEdqnBpnz58jg4OKDT6cxdkhBCAGAwGLh16xa3b9+mSpUqufr9JOEmD9kr9sQTT1h0WI7vkXbMjaIoXL2aOn7H29s7L0oUJZher9eCjexDJoQojMqVK8etW7dISUnB2to6x/eRAcV5yNEitbXlzoM7Ob5H2jE3kZGRxMamfl2lSpXcFyhKNHWMjYODg5krEUKIjKndUXp97pZVkXCTh5ytnQGIiI3I8T3STgW/cuUKAO7u7tjZ2eW6PiEA6YoSQhRaefX7ScJNHiplWwqAqISoHN8j7SJ+0iUlRPH24Ycf0rBhQ5Ouad++PZMmTTJ7HQXF29ubWbNmFchz5cf3VpiHhJs85GbvBkBMckyO76GNubF5FG68vLxyX5wQRVhYWBivvvoqVatWxdbWFk9PT3r16sWOHTuMzjt48CA9evSgdOnS2NnZ0aBBA2bMmJGuiVun06HT6Th8+LDR8cTERMqUKYNOp2P37t1G569ZsybPX9dbb72V7jU8yapVq/jkk0/yvJYnWb16NU8//TSurq44OztTr149oyBQmANSdpnreyvynoSbPFTOqRwAsYbYHN8j7d5SEm6EgCtXruDn58fOnTv55ptv+O+//9i8eTMdOnTglVde0c5bvXo17dq1w8PDg127dnH+/Hlef/11Pv30U4YOHYqiKEb39fT05Pfffzc6tnr1apycnPL9NSmKQkpKCk5OTiYP7nZzc8PZ2TmfKsvYjh07GDJkCAMGDODo0aMcP36czz77rNislZSUlLqqvDm+tyJ/SLjJQxVcKwAQR1yO75G2W0odcyPdUqIke/nll9HpdBw9epQBAwZQs2ZN6tWrx+TJk7WWl9jYWJ5//nl69+7NvHnzaNiwId7e3owfP55FixaxYsUK/vnnH6P7jho1ir///pv4+Hjt2IIFCxg1apTJNSYmJvLaa69Rvnx57OzsaN26NQEBAdrju3fvRqfTsWnTJvz8/LC1tWX//v3pWjtSUlJ47bXXKFWqFGXKlOHdd99l1KhR9O3bVzvn8a4Tb29vPv/8c8aOHYuzszNVqlRh3rx5RvW9++671KxZEwcHB6pWrcr7779vUjBZv349rVq14u2336ZWrVrUrFmTvn37Mnv2bAAWLlzIRx99xKlTp7RWsYULFwJw7do1+vTpg5OTEy4uLgwePJjw8PB092/atCl2dnaULVuWfv36ZVrLr7/+SqlSpTJt8Vq4cCGlSpVizZo11KhRAzs7O/z9/bl+/bp2jvp9//XXX/Hx8dHGND7+vU1MTOTdd9/F09MTW1tbqlevzm+//aY9fubMGbp3746TkxPu7u6MGDGCiIhHYy5XrFhBgwYNsLe3p0yZMnTu3FmbJCLyl4SbPOTh5gFAkkXO9pZSFMVoQLG03Ij8pigKsbGxBf7xeCtKZiIjI9m8eTOvvPIKjo6O6R4vVaoUAFu3buXevXu89dZb6c7p1asXNWvWZOnSpUbH/fz88Pb2ZuXKlUDqm/DevXsZMWKEid9FeOedd1i5ciWLFi3ixIkTVK9eHX9/fyIjI43OmzJlCl9++SVBQUE89dRT6e7z1Vdf8ddff/H7779z4MABYmJistUd9t1339GkSRNOnjzJyy+/zEsvvcSFCxe0x52dnVm4cCHnzp3j+++/Z/78+cycOTPbr69ChQqcPXuWM2fOZPj4kCFDePPNN6lXrx63b9/m9u3bDBkyBIPBQJ8+fYiMjGTPnj1s27aN0NBQhgwZol27YcMG+vXrR48ePTh58iQ7duygWbNmGT7P119/zZQpU9i6dSudOnXKtN64uDg+++wzFi9ezIEDB7h//z5Dhw41Oic4OJiVK1eyatUqAgMDM7zPyJEjWbp0KT/88ANBQUH88ssvWsve/fv36dixI40aNeLYsWNs3ryZ8PBwBg8eDMDt27cZNmwYY8eOJSgoiN27d9O/f/9s/9sXuaSUMNHR0QqgREdH5/m91x5aq/Ahiu5dXY6uT0hOUPgQhQ9R7sffV0qXLq0Ayn///ZfHlYqSKD4+Xjl37pwSHx+vHXv48KECFPjHw4cPs1XzkSNHFEBZtWpVlud9+eWXCqBERUVl+Hjv3r2VOnXqaF8DyurVq5VZs2YpHTp0UBRFUT766COlX79+SlRUlAIou3btSnd+Rh4+fKhYW1srf/31l3YsKSlJqVSpkvL1118riqIou3btUgBlzZo1Rtd+8MEHiq+vr/a1u7u78s0332hfp6SkKFWqVFH69OmjHWvXrp3y+uuva197eXkpzz33nPa1wWBQypcvr8yZMyfDehVFUb755hvFz88v0zoyeo09evRQAMXLy0sZMmSI8ttvvykJCQlZ3mPr1q2KpaWlcu3aNe3Y2bNnFUA5evSooiiK0qJFC+XZZ5/N9Lm9vLyUmTNnKu+8845SsWJF5cyZM5meqyiK8vvvvyuAcvjwYe1YUFCQAihHjhzRarW2tlbu3LljdG3a7+2FCxcUQNm2bVuGz/PJJ58oXbt2NTp2/fp1BVAuXLigHD9+XAGUK1euZFmvMJbR7ymVKe/f0nKTh7zLewOg2Cqk6FNMvl4dTAygT9ATFZU660pabkRJpZj4V66p5z/33HMcOnSI0NBQFi5cyNixY026HiAkJITk5GRatWqlHbO2tqZZs2YEBQUZndukSZNM7xMdHU14eLhRq4WlpSV+fn5PrCFtK5BOp6NChQrcufNova1ly5bRqlUrKlSogJOTE9OmTePatexvE+Po6MiGDRsIDg5m2rRpODk58eabb9KsWTPi4jLvhg8KCsLT0xNPT0/tWN26dSlVqpT2vQkMDMyyFQZSW6bmz5/P/v37qVev3hPrtbKyomnTptrXtWvXNnpOSP29Wq5cuUzvERgYiKWlJe3atcvw8VOnTrFr1y6cnJy0j9q1awOp/yZ8fX3p1KkTDRo0YNCgQcyfP1/7nS7yn4SbPOTt7p36iQXcjDB9CwZ1vI2tpS03r6deLwPcRH5ycHDg4cOHBf6R3YUEa9SogU6n4/z581meV7NmTYB0YUIVFBSknZNWmTJl6NmzJ+PGjSMhIYHu3btnq66cyqhrLS88vpKrTqfDYDAAcOjQIZ599ll69OjBv//+y8mTJ3nvvfe0QbSmqFatGuPHj+fXX3/lxIkTnDt3jmXLluWqdnt7+yee06ZNG/R6fbpxU7nxpJ/Fk+p6+PAhvXr1IjAw0Ojj0qVLtG3bFktLS7Zt28amTZuoW7cuP/74I7Vq1dK21BH5S8JNHnJxdIH//30RcjvE5OtlvI0oaDqdDkdHxwL/yO5CXW5ubvj7+zN79uwMB2KqG4B27doVNzc3vvvuu3TnrFu3jkuXLjFs2LAMn2Ps2LHs3r2bkSNHYmlpmf1v3v+rVq0aNjY2HDhwQDuWnJxMQEAAdevWzfZ9XF1dcXd3NxqIrNfrOXHihMk1pXXw4EG8vLx47733aNKkCTVq1NB+v+SGt7c3Dg7/196dR0VxrH8D/w7CsM0AArIpi4C4RNCgQohxiyiocYkG1+seNArGuCAx6gXNjeCKy1Xxl6gY1xuvghE1BhcMAlFAMRp1BIJiAqhREZGded4/eOmbkQFFlgnj8zlnzqGrqruf6uqBorq6W09oF7FYXO2W+44dO+LevXsKk3lv3LiBvLw84di4uLi89HZ4Nzc3nDx5EitXrsTatWtfGlt5eTmSk5OFZZlMhry8PHTs2PGV6+fs7Ay5XI7z588rzXd1dcWvv/4KOzs7ODo6KnyqOk4ikQg9e/bE8uXLceXKFYjFYkRGRr5yDOz18bulGliL0haoEFfg3sN7Ly/8An6AH2PVbdmyBT179oSbmxtWrFgBFxcXlJeXIyYmBtu2bcPNmzehr6+P7du3Y+zYsZgxYwb8/f1hYGCAM2fOICAgAB999JEw0fNF3t7eePjwIQwMDF4rPn19fcyaNQsBAQEwNjaGjY0NVq9ejcLCQkyfPr1O25ozZw5CQkLg6OiIDh06YPPmzXjy5Em9ntrarl07ZGVl4eDBg+jRoweOHz9e5z+wwcHBKCwsxODBg2Fra4u8vDxs2rQJZWVlGDBgAIDK31WZmZlITU1FmzZtIJVK4enpCWdnZ0yYMAEbNmxAeXk5Zs+ejT59+giX6IKCgtC/f384ODhg7NixKC8vx4kTJxAYGKgQw7vvvosTJ05g0KBB0NTUrPVhe1paWpgzZw42bdoETU1N+Pv745133qlxorIydnZ2mDx5MqZNm4ZNmzahS5cuuHv3Lh48eIDRo0fDz88PX3/9NcaNG4dFixbB2NgY6enpOHjwIL755hskJyfjzJkzGDhwIMzMzHDx4kU8fPiwTh0s9vp45KaBaZVXDg///vh3pflyuRyFxcqvUVfNueFn3DD2P/b29rh8+TL69euHBQsWoHPnzhgwYADOnDmDbdu2CeU++ugjnDt3DllZWejVqxfat2+PsLAwLFmyBAcPHqyxgyASiWBqaiq80+Z1hIaGYtSoUZg4cSJcXV2Rnp6OU6dOoWXLlnXaTmBgIMaNG4dJkybBw8MDEokEXl5e9Xr9yrBhwzBv3jz4+/uja9euSEhIwLJly+q0jT59+uC3337DpEmT0KFDBwwaNAi5ubn48ccf0b59ewDAqFGj4O3tjX79+qFVq1Y4cOAARCIRjh49ipYtW6J3797w9PSEvb29wqWsvn374tChQ/j+++/RtWtXvP/++7h06ZLSON577z0cP34cS5cuxebNm2uMV09PD4GBgRg/fjx69uwJiUTyWpfPtm3bho8++gizZ89Ghw4d4OvrK4xUWVlZIT4+HhUVFRg4cCCcnZ3x2WefwcjICBoaGjAwMMBPP/2EwYMHw8nJCUuXLsW6desa/dInqySius7Aa+by8/NhaGiIp0+fvvZ/arVp+VlL5LXMg7+FPzbPrP7l8/qXF34s+xHh7uGYOXimQt7x28fxwYEP0N2qO9rGtMWhQ4cQFhbGjwNnDaK4uBiZmZkKz/Vgf29yuRwdO3bE6NGj+cm5rygiIgKfffaZcMmSNS+1/Z6qy99vHrlpYFVvBr//7L7S/LhHcYAGsOWnLdXylF2W4pEbxt4cd+/exddff43bt2/j2rVrmDVrFjIzMzF+/HhVh8ZYs8KdmwYm1ay8s+lR4aNqeQVFBSiSVD4NNb0kvVq+sgnFPOeGsTeHhoYGIiIi0KNHD/Ts2RPXrl3D6dOneZ4GY3XEE4obmPBm8KLqzzP4IfkH4YgXGRQh+1E2rEyshPyqOTdapCU8npxHbhh7c1hbWyvcdcXqbsqUKZgyZYqqw2AqxiM3DazqzeBPy55Wy/vxlx//t6AB7D23VyE/v7jybeInj56s3JaxcZ0nJDLGGGNvOu7cNLCqN4MXVBRUy7v8h+LzKk5cPyH8XFpWis3HKicglz4rxVtvvYX//ve/9boFlDHGGHsTceemgZkbmAMACqn67d6/Ff4GANDPq5x0fC3vGoDKOyK6LumK+9L7QDnw+Qef4+rVq+jXr18TRc0YY4ypD+7cNDCrlpVzaEpbKD7aXC6XI08nDwAw3rHyzofH+o9RXFqMvsv74qb+TYCA+XbzEeIX8lpPSmWMMcYYd24aXBuTNgCAMs0yhfQkWRJIl4AKIHRiKFAMQAy8F/we4jTiAADjDcdj3fTqj49njDHG2Kvjzk0Da2veFgBAOiS8uA4AopOjAQA6BTowNjCGabEpACBFOwUA8E75O9g3b18TR8sYY4ypH+7cNLC/vhk8+1G2kJ6QmQAAsNKovGzV1birkGeZZ4m44LimCpExVoMpU6ZgxIgRwnLfvn1V8oTw2NhYiEQitX7KbkREBIyMjBpse3Z2dtiwYUODbe/v5sVzszEFBweja9euTbKvxsKdmwZmbGAM/P8rUnfu3xHSb+XdAgB0Nu0MAPi498cAAbp5uri87DI0W/AjhxhTZsqUKRCJRBCJRBCLxXB0dMSKFStQXl7e6Ps+cuTIK7/2QBUdkitXrsDHxwfm5ubQ0dFBu3bt4Ovri9u3byuU2717N3r06AE9PT1IpVL06dMH0dHRSuNv2bIliouLFfKSkpKENnix/N+lA5aUlIQZM2Y0+n6uXr2KYcOGwczMDDo6OrCzs8OYMWPw4MEDAH+/4/I6Fi5c+NI3tf/dceemEWiUVB7Wuw/uCmkPNCpP/N5OvQEAY/qMwfmR55H7r1xYGFs0fZCMNSPe3t7IyclBWloaFixYgODgYKxZs0Zp2dLSUqXpr8PY2BhSqbTBtteQoqOj8c4776CkpAT79u3DzZs3sXfvXhgaGiq8GHPhwoWYOXMmxowZg19++QWXLl3Ce++9h+HDh+Pf//53te1KpdJqbw3fsWMHbGxsGr1O9dGqVSvo6ek16j4ePnyI/v37w9jYGKdOncLNmzexa9cuWFlZCS/UbM6ICOXl5ZBIJDAxMVF1OPVDb5inT58SAHr69Gmj7UP/M31CMGhi2EQiIrqacZUQDEIw6Pa92422X8ZqU1RURDdu3KCioiJVh1InkydPpuHDhyukDRgwgN555x2F/H/9619kaWlJdnZ2RESUlZVFPj4+ZGhoSC1btqRhw4ZRZmamsI3y8nKaN28eGRoakrGxMQUEBNCkSZMU9tWnTx+aO3eusFxcXEyLFi2iNm3akFgsJgcHB/rmm28oMzOTACh8Jk+eTEREFRUVtHLlSrKzsyMdHR1ycXGhQ4cOKdTn+PHj1K5dO9LR0aG+ffvSrl27CAA9efJE6TF5/vw5mZqa0ogRI5TmV62XmJhIAGjTpk3VysyfP5+0tLQoKyuLiIjOnTtHAGjp0qXk6ekplCssLCRDQ0NatmwZ/fVPRlX5mmKsimPGjBlkZmZG2tra9NZbb9GxY8eIiGjXrl1kaGioUH7r1q1kb29PWlpa5OTkRN9++62QJ5fLKSgoiKytrUksFpOlpSXNmTNHyLe1taWwsDBhGQB9/fXXNGLECNLV1SVHR0c6evSowv6OHj1Kjo6OpK2tTX379qWIiIha6xQZGUmamppUVlamNL+286C4uJjmzJlDrVq1Im1tberZsyddunRJYf3r16/TkCFDSCqVkkQioffee4/S09OJqPr34NKlS2RqakqhoaG1xnLgwAHy8PAQjn9sbKxQpqoNT5w4Qa6urqSlpUXnzp2joKAg6tKli8L2duzYQZ06dSKxWEwWFhbk5+cn5D158oSmT59OpqamJJVKqV+/fpSamirkp6amUt++fUkikZBUKiVXV1dKSkpSGndtv6fq8vebR24aQW/TytGZ7+98DwD44j9fAKh8vk27Nu1UFhdjLyIiPC993uQfIqpX3Lq6ugojNGfOnIFMJkNMTAyio6NRVlYGLy8vSKVSxMXFIT4+HhKJBN7e3sJ669atQ0REBHbu3IkLFy7g8ePH1UYsXjRp0iQcOHAAmzZtws2bN7F9+3ZIJBJYW1vj8OHDAACZTIacnBxs3LgRABASEoJvv/0W4eHh+PXXXzFv3jz84x//wPnz5wEA9+7dw8iRIzF06FCkpqbi448/xueff15rHKdOncKff/6JRYsWKc2vmsty4MABSCQSzJw5s1qZBQsWoKysTIi7ysSJExEXF4esrCwAwOHDh2FnZwdXV9daY3qRXC7HoEGDEB8fj7179+LGjRsIDQ2t8TEXkZGRmDt3LhYsWIDr169j5syZmDp1Ks6dOyfEERYWhu3btyMtLQ1RUVFwdnauNYbly5dj9OjR+OWXXzB48GBMmDABjx8/BgBkZmbio48+wogRI3D16lXMnDkTS5YsqXV7FhYWKC8vR2RkpNJzuLbzYNGiRTh8+DB2796Ny5cvw9HREV5eXkI8f/zxB3r37g1tbW2cPXsWKSkpmDZtmtLLr2fPnsWAAQPw1VdfITAwsNaYAwICsGDBAly5cgUeHh4YOnQoHj1SfPfh559/jtDQUNy8eRMuLi7VtrFt2zb4+flhxowZuHbtGr7//ns4OjoK+T4+Pnjw4AFOnjyJlJQUuLq6on///kLdJkyYgDZt2iApKQkpKSn4/PPPoaWlVWvc9fbS7o+aaYqRm59v/EwIqhypSfg1gcTzxAojOYypgrL/iApKCoRRxab8FJQUvHLcf/2PVS6XU0xMDGlra9PChQuFfHNzcyopKRHW2bNnD7Vv357kcrmQVlJSQrq6unTq1CkiIrK0tKTVq1cL+WVlZdSmTZsaR25kMhkBoJiYGKVxKhvJKC4uJj09PUpISFAoO336dBo3bhwRES1evJg6deqkkB8YGFjrCMKqVasIAD1+/FhpfhVvb+9q/4H/lYGBAc2aNata/CNGjKDly5cTEVG/fv1o48aNFBkZWaeRm1OnTpGGhgbJZDKl+S+O3Lz77rvk6+urUMbHx4cGDx5MRETr1q0jJycnKi0tVbo9ZSM3S5cuFZYLCgoIAJ08eZKIKo9x586dFbaxZMmSl45GffHFF6SpqUnGxsbk7e1Nq1evptzcXCFf2XEpKCggLS0t2rdvn5BWWlpKVlZWwjm4ePFiatu2bY31q/oeHDlyhCQSCR08eLDGGIn+N3Lz15GdqnN81apVCrFGRUUprPviyI2VlRUtWbJE6X7i4uLIwMCAiouLFdIdHBxo+/btREQklUopIiKi1nirqNXIzZYtW2BnZwcdHR24u7vj0qVLtZY/dOgQOnToAB0dHTg7O+PEiRO1lm9q7h3dYZRnBAAY9fUolBqWAmXAygkrVRsYY81UdHQ0JBIJdHR0MGjQIIwZMwbBwcFCvrOzM8RisbB89epVpKenQyqVQiKRQCKRwNjYGMXFxcjIyMDTp0+Rk5MDd3d3YR1NTU107969xhhSU1PRokUL9OnT55XjTk9PR2FhIQYMGCDEIZFI8O233yIjIwMAcPPmTYU4AMDDw6PW7VIdRr7qUrbKtGnTEBERgd9++w2JiYmYMGFCnbeRmpqKNm3awMnJ6ZXK37x5Ez179lRI69mzJ27evAmgcnSgqKgI9vb28PX1RWRk5Esnlf91FEJfXx8GBgbCxF+ZTIYePXoolHdzc3tpnF999RVyc3MRHh6Ot956C+Hh4ejQoQOuXbtW4zoZGRkoKytTqJ+Wlhbc3NyE+qWmpqJXr161jmhcvHgRPj4+2LNnD8aMGfPSWAHFc6nqHK/aZ5XazvsHDx4gOzsb/fv3V5p/9epVFBQUwMTEROEcz8zMFM7x+fPn4+OPP4anpydCQ0OF9Mak8lt0/vOf/2D+/PkIDw+Hu7s7NmzYAC8vL8hkMpiZmVUrn5CQgHHjxiEkJAQffPAB9u/fjxEjRuDy5cvo3LmzCmqg3Aj7EYh4EoEcoxwAgH2xPdq0aqPiqBhTpKelh4LF1d+D1hT7rYt+/fph27ZtEIvFsLKygqam4q8ufX19heWCggJ069YN+/ZVf3ZUq1at6h4wKi+F1VVBQeWxPX78OFq3bq2Qp62t/VpxABA6DLdu3aq1I+Tk5IQLFy6gtLRUofMHANnZ2cjPz1fa+Rg0aBBmzJiB6dOnY+jQoa81ufR1jldtrK2tIZPJcPr0acTExGD27NlYs2YNzp8/X2OH4MV0kUik8Pyx12ViYgIfHx/4+Phg5cqVePvtt7F27Vrs3r37tbf5KsfLwcEBJiYm2LlzJ4YMGdJgl3Ze/P7UJa6CggJYWloiNja2Wl7V5dHg4GCMHz8ex48fx8mTJxEUFISDBw/iww8/rE/YtVL5yM369evh6+uLqVOnolOnTggPD4eenh527typtPzGjRvh7e2NgIAAdOzYEV9++SVcXV2VzvpXpeVjlwN/+adizntzVBcMYzUQiUTQF+s3+aeuL4TV19eHo6MjbGxsqnVslHF1dUVaWhrMzMzg6Oio8DE0NIShoSEsLS1x8eJFYZ3y8nKkpKTUuE1nZ2fI5XJhrsyLqjoPFRUVQlqnTp2gra2NrKysanFYW1sDADp27FhttPrnn3+utX4DBw6EqakpVq9erTS/6jbksWPHoqCgANu3b69WZu3atdDS0sKoUaOq5WlqamLSpEmIjY3FtGnTao2lJi4uLvj999+r3ZZek44dOyI+Pl4hLT4+Hp06dRKWdXV1MXToUGzatAmxsbFITEysdcSkNu3bt0dycrJCWlJSUp23IxaL4eDgINwtpew8cHBwgFgsVqhfWVkZkpKShPq5uLggLi4OZWWKT7f/K1NTU5w9exbp6ekYPXp0rWWr/PVcqjrHO3bs+Mr1k0qlsLOzq/HWcFdXV+Tm5kJTU7PaOW5qaiqUc3Jywrx58/Djjz9i5MiR2LVr1yvH8DpU2rkpLS1FSkoKPD09hTQNDQ14enoiMTFR6TqJiYkK5QHAy8urxvIlJSXIz89X+DQFGzMbtH5e+Z+a5jNN+A/1b5L9MsYqJzCamppi+PDhiIuLQ2ZmJmJjY/Hpp5/i999/BwDMnTsXoaGhiIqKwq1btzB79uxan01iZ2eHyZMnY9q0aYiKihK2+d133wEAbG1tIRKJEB0djYcPH6KgoABSqRQLFy7EvHnzsHv3bmRkZODy5cvYvHmz8F/+J598grS0NAQEBEAmk2H//v2IiIiotX76+vr45ptvcPz4cQwbNgynT5/GnTt3kJycjEWLFuGTTz4BUHlJYu7cuQgICMC6deuQkZGBW7duYenSpdi4cSPWrVsndLJe9OWXX+Lhw4fw8vKq49Gv1KdPH/Tu3RujRo1CTEwMMjMzcfLkSfzwww9KywcEBCAiIgLbtm1DWloa1q9fjyNHjmDhwoUAKh/6t2PHDly/fh2//fYb9u7dC11dXdja2r5WfDNnzsStW7cQGBiI27dv47vvvhOOe02d7+joaPzjH/9AdHQ0bt++DZlMhrVr1+LEiRMYPnw4AOXngb6+PmbNmoWAgAD88MMPuHHjBnx9fVFYWIjp06cDAPz9/ZGfn4+xY8ciOTkZaWlp2LNnD2QymUIMZmZmOHv2LG7duoVx48a99NLcli1bEBkZiVu3bsHPzw9Pnjypc4c1ODgY69atw6ZNm5CWliacwwDg6ekJDw8PjBgxAj/++CPu3LmDhIQELFmyBMnJySgqKoK/vz9iY2Nx9+5dxMfHIykpqU4drNfySjN8Gskff/xBAKpNtgsICCA3Nzel62hpadH+/fsV0rZs2UJmZmZKywcFBVW7NQ+NPKG4yp7Te0hzgSb5h/s3+r4Yexl1uhX8VfJzcnJo0qRJZGpqStra2mRvb0++vr7Cd7+srIzmzp1LBgYGZGRkRPPnz3/preBFRUU0b948srS0JLFYTI6OjrRz504hf8WKFWRhYUEikUi4BVgul9OGDRuoffv2pKWlRa1atSIvLy86f/68sN6xY8eEW5J79epFO3fufOnEViKipKQkGjlypHB7saOjI82YMYPS0tIUyu3YsYO6detGOjo6pK+vT7169aLvv/9eoczLJgjXdUIxEdGjR49o6tSpZGJiQjo6OtS5c2eKjo4morrfCh4ZGUnu7u5kYGBA+vr69M4779Dp06eFfGUTiiMjIxW2b2hoSLt27RKWX7wVfNu2bQSgxu9IRkYG+fr6kpOTE+nq6pKRkRH16NFDYZtEys+DoqIimjNnjnA+KrsV/OrVqzRw4EDS09MjqVRKvXr1ooyMDCKqfp5nZ2eTk5MTjR49msrLy6vFWjWheP/+/eTm5kZisZg6depEZ8+eFcrU1IbKbgUPDw8XzuEXb8PPz8+nOXPmkJWVFWlpaZG1tTVNmDCBsrKyqKSkhMaOHSvcwm9lZUX+/v41HuOGmlAsIqrnPZn1kJ2djdatWyMhIUHhuvGiRYtw/vx5hSHjKmKxGLt378a4ceOEtK1bt2L58uW4f/9+tfIlJSUoKSkRlvPz82FtbY2nT5/CwMCggWvE2N9XcXExMjMz0bZtW+jo6Kg6HMb+dr766iuEh4fj3r17qg6l3u7cuYO2bdviypUrzepVCrX9nsrPz4ehoeEr/f1W6YRiU1NTtGjRolqn5P79+7CwUP7UXgsLizqV19bWrtfEPcYYY+pp69at6NGjB0xMTBAfH481a9bA35+nEKgDlc65EYvF6Natm8JEJblcjjNnztR4B4CHh0e1iU0xMTEvvXWSMcYY+6u0tDQMHz4cnTp1wpdffim82oM1fyq/FXz+/PmYPHkyunfvDjc3N2zYsAHPnz/H1KlTAVQ+EbR169YICQkBUDkJsE+fPli3bh2GDBmCgwcPIjk5Gf/3f/+nymowxhhrZsLCwhAWFqbqMBqFnZ1dvZ8E3pypvHMzZswYPHz4EP/85z+Rm5uLrl274ocffoC5uTkAICsrCxoa/xtgevfdd7F//34sXboUX3zxBdq1a4eoqKi/1TNuGGOMMaY6Kp1QrAp1mZDEmDrhCcWMsb+7hppQrPKH+DHGmtYb9v8MY6wZaajfT9y5YewNUfWo9sLCQhVHwhhjypWWlgJAjW+Pf1Uqn3PDGGsaLVq0gJGRkfDiQD09vTq/BoExxhqLXC7Hw4cPoaen90qvWakNd24Ye4NUPQ+qqoPDGGN/JxoaGrCxsan3P17cuWHsDSISiWBpaQkzM7NXeukeY4w1JbFYrHCH9Ovizg1jb6AWLVrU+5o2Y4z9XfGEYsYYY4ypFe7cMMYYY0ytcOeGMcYYY2rljZtzU/WAoPz8fBVHwhhjjLFXVfV3+1Ue9PfGdW6ePXsGALC2tlZxJIwxxhirq2fPnsHQ0LDWMm/cu6Xkcjmys7MhlUob/AFm+fn5sLa2xr1799T+vVVvUl0Brq86e5PqCnB91Zm615WI8OzZM1hZWb30dvE3buRGQ0MDbdq0adR9GBgYqOWJpcybVFeA66vO3qS6AlxfdabOdX3ZiE0VnlDMGGOMMbXCnRvGGGOMqRXu3DQgbW1tBAUFQVtbW9WhNLo3qa4A11edvUl1Bbi+6uxNquvLvHETihljjDGm3njkhjHGGGNqhTs3jDHGGFMr3LlhjDHGmFrhzg1jjDHG1Ap3bhrIli1bYGdnBx0dHbi7u+PSpUuqDqlBhISEoEePHpBKpTAzM8OIESMgk8kUyvTt2xcikUjh88knn6go4tcXHBxcrR4dOnQQ8ouLi+Hn5wcTExNIJBKMGjUK9+/fV2HE9WNnZ1etviKRCH5+fgCaf7v+9NNPGDp0KKysrCASiRAVFaWQT0T45z//CUtLS+jq6sLT0xNpaWkKZR4/fowJEybAwMAARkZGmD59OgoKCpqwFq+mtrqWlZUhMDAQzs7O0NfXh5WVFSZNmoTs7GyFbSg7H0JDQ5u4Jq/mZW07ZcqUanXx9vZWKNNc2hZ4eX2VfY9FIhHWrFkjlGlO7dsQuHPTAP7zn/9g/vz5CAoKwuXLl9GlSxd4eXnhwYMHqg6t3s6fPw8/Pz/8/PPPiImJQVlZGQYOHIjnz58rlPP19UVOTo7wWb16tYoirp+33npLoR4XLlwQ8ubNm4djx47h0KFDOH/+PLKzszFy5EgVRls/SUlJCnWNiYkBAPj4+AhlmnO7Pn/+HF26dMGWLVuU5q9evRqbNm1CeHg4Ll68CH19fXh5eaG4uFgoM2HCBPz666+IiYlBdHQ0fvrpJ8yYMaOpqvDKaqtrYWEhLl++jGXLluHy5cs4cuQIZDIZhg0bVq3sihUrFNp7zpw5TRF+nb2sbQHA29tboS4HDhxQyG8ubQu8vL5/rWdOTg527twJkUiEUaNGKZRrLu3bIIjVm5ubG/n5+QnLFRUVZGVlRSEhISqMqnE8ePCAAND58+eFtD59+tDcuXNVF1QDCQoKoi5duijNy8vLIy0tLTp06JCQdvPmTQJAiYmJTRRh45o7dy45ODiQXC4nIvVpVyIiABQZGSksy+VysrCwoDVr1ghpeXl5pK2tTQcOHCAiohs3bhAASkpKEsqcPHmSRCIR/fHHH00We129WFdlLl26RADo7t27QpqtrS2FhYU1bnCNQFl9J0+eTMOHD69xnebatkSv1r7Dhw+n999/XyGtubbv6+KRm3oqLS1FSkoKPD09hTQNDQ14enoiMTFRhZE1jqdPnwIAjI2NFdL37dsHU1NTdO7cGYsXL0ZhYaEqwqu3tLQ0WFlZwd7eHhMmTEBWVhYAICUlBWVlZQrt3KFDB9jY2KhFO5eWlmLv3r2YNm2awgtl1aVdX5SZmYnc3FyF9jQ0NIS7u7vQnomJiTAyMkL37t2FMp6entDQ0MDFixebPOaG9PTpU4hEIhgZGSmkh4aGwsTEBG+//TbWrFmD8vJy1QTYAGJjY2FmZob27dtj1qxZePTokZCnzm17//59HD9+HNOnT6+Wp07t+zJv3IszG9qff/6JiooKmJubK6Sbm5vj1q1bKoqqccjlcnz22Wfo2bMnOnfuLKSPHz8etra2sLKywi+//ILAwEDIZDIcOXJEhdHWnbu7OyIiItC+fXvk5ORg+fLl6NWrF65fv47c3FyIxeJqfwzMzc2Rm5urmoAbUFRUFPLy8jBlyhQhTV3aVZmqNlP2va3Ky83NhZmZmUK+pqYmjI2Nm3WbFxcXIzAwEOPGjVN4ueKnn34KV1dXGBsbIyEhAYsXL0ZOTg7Wr1+vwmhfj7e3N0aOHIm2bdsiIyMDX3zxBQYNGoTExES0aNFCbdsWAHbv3g2pVFrtkrk6te+r4M4Ne2V+fn64fv26wjwUAArXqZ2dnWFpaYn+/fsjIyMDDg4OTR3maxs0aJDws4uLC9zd3WFra4vvvvsOurq6Koys8e3YsQODBg2ClZWVkKYu7cr+p6ysDKNHjwYRYdu2bQp58+fPF352cXGBWCzGzJkzERIS0uwe5z927FjhZ2dnZ7i4uMDBwQGxsbHo37+/CiNrfDt37sSECROgo6OjkK5O7fsq+LJUPZmamqJFixbV7pq5f/8+LCwsVBRVw/P390d0dDTOnTuHNm3a1FrW3d0dAJCent4UoTUaIyMjODk5IT09HRYWFigtLUVeXp5CGXVo57t37+L06dP4+OOPay2nLu0KQGiz2r63FhYW1W4KKC8vx+PHj5tlm1d1bO7evYuYmBiFURtl3N3dUV5ejjt37jRNgI3I3t4epqamwrmrbm1bJS4uDjKZ7KXfZUC92lcZ7tzUk1gsRrdu3XDmzBkhTS6X48yZM/Dw8FBhZA2DiODv74/IyEicPXsWbdu2fek6qampAABLS8tGjq5xFRQUICMjA5aWlujWrRu0tLQU2lkmkyErK6vZt/OuXbtgZmaGIUOG1FpOXdoVANq2bQsLCwuF9szPz8fFixeF9vTw8EBeXh5SUlKEMmfPnoVcLhc6es1FVccmLS0Np0+fhomJyUvXSU1NhYaGRrXLN83R77//jkePHgnnrjq17V/t2LED3bp1Q5cuXV5aVp3aVylVz2hWBwcPHiRtbW2KiIigGzdu0IwZM8jIyIhyc3NVHVq9zZo1iwwNDSk2NpZycnKET2FhIRERpaen04oVKyg5OZkyMzPp6NGjZG9vT71791Zx5HW3YMECio2NpczMTIqPjydPT08yNTWlBw8eEBHRJ598QjY2NnT27FlKTk4mDw8P8vDwUHHU9VNRUUE2NjYUGBiokK4O7frs2TO6cuUKXblyhQDQ+vXr6cqVK8IdQqGhoWRkZERHjx6lX375hYYPH05t27aloqIiYRve3t709ttv08WLF+nChQvUrl07GjdunKqqVKPa6lpaWkrDhg2jNm3aUGpqqsL3uKSkhIiIEhISKCwsjFJTUykjI4P27t1LrVq1okmTJqm4ZsrVVt9nz57RwoULKTExkTIzM+n06dPk6upK7dq1o+LiYmEbzaVtiV5+LhMRPX36lPT09Gjbtm3V1m9u7dsQuHPTQDZv3kw2NjYkFovJzc2Nfv75Z1WH1CAAKP3s2rWLiIiysrKod+/eZGxsTNra2uTo6EgBAQH09OlT1Qb+GsaMGUOWlpYkFoupdevWNGbMGEpPTxfyi4qKaPbs2dSyZUvS09OjDz/8kHJyclQYcf2dOnWKAJBMJlNIV4d2PXfunNJzd/LkyURUeTv4smXLyNzcnLS1tal///7VjsOjR49o3LhxJJFIyMDAgKZOnUrPnj1TQW1qV1tdMzMza/wenzt3joiIUlJSyN3dnQwNDUlHR4c6duxIK1euVOgM/J3UVt/CwkIaOHAgtWrVirS0tMjW1pZ8fX2r/bPZXNqW6OXnMhHR9u3bSVdXl/Ly8qqt39zatyGIiIgadWiIMcYYY6wJ8ZwbxhhjjKkV7twwxhhjTK1w54YxxhhjaoU7N4wxxhhTK9y5YYwxxpha4c4NY4wxxtQKd24YY4wxpla4c8MYY4wxtcKdG8ZYo3j48CFmzZoFGxsbaGtrw8LCAl5eXoiPj1d1aIwxNaep6gAYY+pp1KhRKC0txe7du2Fvb4/79+/jzJkzePTokapDY4ypOR65YYw1uLy8PMTFxWHVqlXo168fbG1t4ebmhsWLF2PYsGFCmY8//hitWrWCgYEB3n//fVy9elXYRnBwMLp27YqdO3fCxsYGEokEs2fPRkVFBVavXg0LCwuYmZnhq6++Utj3+vXr4ezsDH19fVhbW2P27NkoKCgQ8iMiImBkZIRTp06hY8eOkEgk8Pb2Rk5OjlAmKSkJAwYMgKmpKQwNDdGnTx9cvnxZyCciBAcHC6NSVlZW+PTTTxvrcDLG6og7N4yxBieRSCCRSBAVFYWSkhKlZXx8fPDgwQOcPHkSKSkpcHV1Rf/+/fH48WOhTEZGBk6ePIkffvgBBw4cwI4dOzBkyBD8/vvvOH/+PFatWoWlS5fi4sWLwjoaGhrYtGkTfv31V+zevRtnz57FokWLFPZdWFiItWvXYs+ePfjpp5+QlZWFhQsXCvnPnj3D5MmTceHCBfz8889o164dBg8ejGfPngEADh8+jLCwMGzfvh1paWmIioqCs7NzQx5Cxlh9qPjFnYwxNfXf//6XWrZsSTo6OvTuu+/S4sWL6erVq0REFBcXRwYGBtXeSuzg4EDbt28nIqKgoCDS09Oj/Px8Id/Ly4vs7OyooqJCSGvfvj2FhITUGMehQ4fIxMREWN61axcBUHjj+5YtW8jc3LzGbVRUVJBUKqVjx44REdG6devIycmJSktLX+VQMMaaGI/cMMYaxahRo5CdnY3vv/8e3t7eiI2NhaurKyIiInD16lUUFBTAxMREGOWRSCTIzMxERkaGsA07OztIpVJh2dzcHJ06dYKGhoZC2oMHD4Tl06dPo3///mjdujWkUikmTpyIR48eobCwUCijp6cHBwcHYdnS0lJhG/fv34evry/atWsHQ0NDGBgYoKCgAFlZWQAqR52Kiopgb28PX19fREZGory8vGEPIGPstXHnhjHWaHR0dDBgwAAsW7YMCQkJmDJlCoKCglBQUABLS0ukpqYqfGQyGQICAoT1tbS0FLYnEomUpsnlcgDAnTt38MEHH8DFxQWHDx9GSkoKtmzZAgAoLS2tdbtEJCxPnjwZqamp2LhxIxISEpCamgoTExNhG9bW1pDJZNi6dSt0dXUxe/Zs9O7dG2VlZQ1w1Bhj9cV3SzHGmkynTp0QFRUFV1dX5ObmQlNTE3Z2dg22/ZSUFMjlcqxbt04Y3fnuu+/qvJ34+Hhs3boVgwcPBgDcu3cPf/75p0IZXV1dDB06FEOHDoWfnx86dOiAa9euwdXVtf4VYYzVC3duGGMN7tGjR/Dx8cG0adPg4uICqVSK5ORkrF69GsOHD4enpyc8PDwwYsQIrF69Gk5OTsjOzsbx48fx4Ycfonv37q+1X0dHR5SVlWHz5s0YOnQo4uPjER4eXufttGvXDnv27EH37t2Rn5+PgIAA6OrqCvkRERGoqKiAu7s79PT0sHfvXujq6sLW1va14maMNSy+LMUYa3ASiQTu7u4ICwtD79690blzZyxbtgy+vr7497//DZFIhBMnTqB3796YOnUqnJycMHbsWNy9exfm5uavvd8uXbpg/fr1WLVqFTp37ox9+/YhJCSkztvZsWMHnjx5AldXV0ycOBGffvopzMzMhHwjIyN8/fXX6NmzJ1xcXHD69GkcO3YMJiYmrx07Y6zhiOivF5oZY4wxxpo5HrlhjDHGmFrhzg1jjDHG1Ap3bhhjjDGmVrhzwxhjjDG1wp0bxhhjjKkV7twwxhhjTK1w54YxxhhjaoU7N4wxxhhTK9y5YYwxxpha4c4NY4wxxtQKd24YY4wxpla4c8MYY4wxtfL/AN08uZgyWJdRAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predice el conjunto de entrenamiento usando la prediccion predictiva a partir de los primeros (usando los datos que predice)\n",
    "red_ap_X_entrenamiento_n = c_entrenamiento_n[:time_steps].reshape(8)\n",
    "red_ap_precios_predichos_n = utls.genera_prediccion_predictiva(red_ap_X_entrenamiento_n,8,182,red)\n",
    "\n",
    "#Sin normalizar\n",
    "plt.plot(c_entrenamiento_n, color = 'black', label = 'COMI original Stock prices')\n",
    "plt.plot(red_ap_precios_predichos_n, color = 'green', label = 'Predicted COMI closing Stock prices') #ts_cierre_s_pred[:,0]\n",
    "plt.title('COMI Stock Price Prediction')\n",
    "plt.xlabel('Semanas')\n",
    "plt.ylabel('COMI Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ahora, el modelo ha sido entrenado de manera iterativa\n",
    "\n",
    "red_ap_X_prueba_n = np.reshape(X_prueba_n[0,:], (1, X_prueba_n[0,:].shape[0], 1))\n",
    "red_ap_precios_predichos = red.predict(red_ap_X_prueba_n)\n",
    "f_predicted_sp_cierre = m_m_s.inverse_transform(red_ap_precios_predichos)\n",
    "\n",
    "# Predice el conjunto de prueba usando la prediccion predictiva (ñps datos que va prediciendo)\n",
    "\n",
    "red_ap_precios_predichos = utls.genera_prediccion_predictiva(red_ap_X_prueba_n.reshape(8),8,78,red)\n",
    "temp = red_ap_precios_predichos\n",
    "red_ap_precios_predichos = m_m_s_prueba.inverse_transform(red_ap_precios_predichos.reshape(86,1))\n",
    "\n",
    "#Sin normalizar\n",
    "plt.plot(m_m_s_prueba.inverse_transform(c_prueba_n), color = 'black', label = 'COMI original Stock prices') #c_prueba_n\n",
    "plt.plot(red_ap_precios_predichos, color = 'green', label = 'Predicted COMI closing Stock prices')\n",
    "plt.title('COMI Stock Price Prediction')\n",
    "plt.xlabel('Semanas')\n",
    "plt.ylabel('COMI Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
