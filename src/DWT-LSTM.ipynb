{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import reader1 as rd\n",
    "import utilerias as utls\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import PIL.Image\n",
    "# Llamamos a la función antes de ejecutar el script\n",
    "utls.eliminar_archivos_registro(\"logs/lstm\")\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('logs/lstm')\n",
    "DATOS = 'Datos históricos COMI 3ene16-31dic2020 semanal.csv'\n",
    "cierre = rd.leer_archivo(DATOS).astype(float)\n",
    "c_entrenamiento = np.array(cierre[:int(len(cierre) * 0.7)])\n",
    "\n",
    "#Se convierte en un arreglo bidimensional\n",
    "c_entrenamiento = np.reshape(c_entrenamiento, (c_entrenamiento.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "m_m_s = MinMaxScaler(feature_range=(0,1))\n",
    "c_entrenamiento_n = m_m_s.fit_transform(c_entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 8\n",
    "N = len(c_entrenamiento_n) #182\n",
    "X_entrenamiento = []\n",
    "y_entrenamiento = []\n",
    "for i in range(time_steps, N):\n",
    "    X_entrenamiento.append(c_entrenamiento_n[i-time_steps:i, 0])#toma paquetes de 8 en 8\n",
    "    y_entrenamiento.append(c_entrenamiento_n[i, 0])#se toma el elemento 8+1\n",
    "X_entrenamiento, y_entrenamiento = np.array(X_entrenamiento), np.array(y_entrenamiento)\n",
    "#Se le da una tercera dimension al conjunto de entradas de entrenamiento\n",
    "X_entrenamiento = np.reshape(X_entrenamiento, (X_entrenamiento.shape[0], X_entrenamiento.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.models import load_model\n",
    "\n",
    "red = load_model('models/LSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04610616 0.10422317 0.1542038  0.15575358 0.12553274 0.14567997\n",
      " 0.14645486 0.19604804 0.2305308  0.20844634 0.21193336 0.207284\n",
      " 0.19294847 0.19682294 0.21425804 0.18132507 0.17512592 0.14800465\n",
      " 0.15885316 0.19217358 0.18597443 0.26695079 0.29252228 0.31770632\n",
      " 0.31266951 0.28903526 0.28283611 0.29949632 0.27586207 0.27469973\n",
      " 0.27547462 0.33475397 0.35567609 0.3366912  0.33359163 0.3847346\n",
      " 0.57109647 0.59628051 0.57458349 0.60635413 0.58465711 0.56877179\n",
      " 0.64277412 0.66175901 0.67299496 0.7105773  0.7039907  0.7272375\n",
      " 0.72258814 0.77179388 0.72452538 0.67105773 0.67376986 0.71445176\n",
      " 0.74389771 0.72258814 0.69934134 0.73731112 0.7214258  0.71871368\n",
      " 0.6741573  0.69856645 0.72103836 0.72258814 0.75629601 0.82758621\n",
      " 0.83882216 0.79426579 0.78380473 0.76791941 0.78457962 0.87872917\n",
      " 0.8756296  0.84889578 0.81828749 0.82681131 0.78535451 0.78922898\n",
      " 0.8341728  0.81247578 0.80123983 0.80317706 0.7934909  0.76017048\n",
      " 0.73537389 0.71018985 0.71212708 0.7396358  0.73614878 0.66757071\n",
      " 0.66989539 0.69662921 0.65594731 0.67880666 0.67609454 0.72956219\n",
      " 0.70127857 0.76753196 0.75513367 0.74506005 0.7520341  0.7098024\n",
      " 0.69043007 0.75435878 0.7222007  0.84850833 0.905463   0.8822162\n",
      " 0.90778768 0.88957768 0.87485471 0.91321193 1.         0.97055405\n",
      " 0.88880279 0.87795428 0.84889578 0.8341728  0.85509492 0.87524215\n",
      " 0.85703216 0.85005812 0.84269663 0.82293685 0.77450601 0.78419217\n",
      " 0.85974429 0.85432003 0.83688493 0.82991089 0.887253   0.85974429\n",
      " 0.83959706 0.78380473 0.81828749 0.79116621 0.76055792 0.79155366\n",
      " 0.7686943  0.7686943  0.79891515 0.79000387 0.76017048 0.68539326\n",
      " 0.60519179 0.66485858 0.70786517 0.66485858 0.71135219 0.67725688\n",
      " 0.76210771 0.80705153 0.81518791 0.90623789 0.95970554 0.9643549\n",
      " 0.8880279  0.89267726 0.87524215 0.85083301 0.84889578 0.96241767\n",
      " 0.96784192 0.94072065 0.97249128 0.99690043 0.95118171 0.89577683\n",
      " 0.8814413  0.9170864  0.91979853 0.96164277 0.96822937 0.95776831]\n"
     ]
    }
   ],
   "source": [
    "print(y_entrenamiento)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#Se entrena con un aprendizaje por reforzamiento del profesor\\nred = Sequential()\\nred.add(LSTM(units=50,return_sequences=True,input_shape=(X_entrenamiento.shape[1], 1)))#tiene un tamaño de entrada de 8 y de salida 1, input_shape = (8, 1)\\nred.add(Dropout(0.2))#Se apagan aleatoriamente el 20% de las neuronas de la capa anterior\\nred.add(LSTM(units=50,return_sequences=True))\\nred.add(Dropout(0.2))\\nred.add(LSTM(units=50,return_sequences=True))\\nred.add(Dropout(0.2))\\nred.add(LSTM(units=50))\\nred.add(Dropout(0.2))\\nred.add(Dense(units=1))\\nred.compile(optimizer=Adam(learning_rate=0.0001),loss='mean_squared_error')# mejor, , SGD(learning_rate=0.1)\\nhistory = red.fit(X_entrenamiento,y_entrenamiento,epochs=60,batch_size=32)#batch_size=32\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#Se entrena con un aprendizaje por reforzamiento del profesor\n",
    "red = Sequential()\n",
    "red.add(LSTM(units=50,return_sequences=True,input_shape=(X_entrenamiento.shape[1], 1)))#tiene un tamaño de entrada de 8 y de salida 1, input_shape = (8, 1)\n",
    "red.add(Dropout(0.2))#Se apagan aleatoriamente el 20% de las neuronas de la capa anterior\n",
    "red.add(LSTM(units=50,return_sequences=True))\n",
    "red.add(Dropout(0.2))\n",
    "red.add(LSTM(units=50,return_sequences=True))\n",
    "red.add(Dropout(0.2))\n",
    "red.add(LSTM(units=50))\n",
    "red.add(Dropout(0.2))\n",
    "red.add(Dense(units=1))\n",
    "red.compile(optimizer=Adam(learning_rate=0.0001),loss='mean_squared_error')# mejor, , SGD(learning_rate=0.1)\n",
    "history = red.fit(X_entrenamiento,y_entrenamiento,epochs=60,batch_size=32)#batch_size=32\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"losses = history.history['loss']\\nprint(losses)\\nplt.plot(range(len(losses)),losses)\\nplt.show()\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtener la pérdida durante el entrenamiento\n",
    "\"\"\"losses = history.history['loss']\n",
    "print(losses)\n",
    "plt.plot(range(len(losses)),losses)\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "precios_reales = cierre[int(len(cierre) * 0.7):] #verdaderos valores del conjunto de prueba\n",
    "precios_reales = np.reshape(precios_reales, (precios_reales.shape[0], 1)) #se le da una dimension mas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0)\n",
    "# inputs = dataset_total[len(dataset_total) - len(dataset_test) - time_steps:].values\n",
    "\n",
    "inputs_cierre = cierre[len(cierre) - len(precios_reales) - time_steps:]#toma los ultimos 86 elementos, los ultimos 8 de entrenamiento y todos los de prueba  \n",
    "#print(len(cierre) - len(precios_reales) - time_steps)\n",
    "inputs_cierre = np.array(inputs_cierre).reshape(-1,1)\n",
    "#print(len(inputs_cierre))\n",
    "#print(inputs_cierre.shape)\n",
    "m_m_s_entrenamiento = MinMaxScaler(feature_range=(0,1))\n",
    "inputs_cierre = m_m_s_entrenamiento.fit_transform(inputs_cierre)# se normalizan los datos usandlo los parametros que se le dieron a m_m_s\n",
    "#inputs_cierre = m_m_s.transform(inputs_cierre) \n",
    "X_entrenamiento = []\n",
    "for i in range(time_steps, len(inputs_cierre)):\n",
    "    X_entrenamiento.append(inputs_cierre[i-time_steps:i, 0]) # setoman en paquetes de 8 \n",
    "X_entrenamiento = np.array(X_entrenamiento)\n",
    "X_entrenamiento = np.reshape(X_entrenamiento, (X_entrenamiento.shape[0], X_entrenamiento.shape[1], 1))#(78, 8, 1)\n",
    "\n",
    "precios_predichos = red.predict(X_entrenamiento)\n",
    "s_normalizar = precios_predichos\n",
    "precios_predichos = m_m_s_entrenamiento.inverse_transform(precios_predichos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#La normalización funciona correctamente\n",
    "plt.plot(precios_reales, color = 'black', label = 'COMI original Stock prices')\n",
    "plt.plot(precios_predichos, color = 'green', label = 'Predicted COMI closing Stock prices')\n",
    "plt.title('COMI Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('COMI Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo entrenado\n",
    "# red.save('models/LSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y_entrenamiento.size)\n",
    "# plt.plot(y_entrenamiento)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_cierre_s_pred = c_entrenamiento_n\n",
    "\n",
    "# loss_m = []\n",
    "# for epoch in range(100):  # Número de épocas\n",
    "#     ts_cierre_s_pred = c_entrenamiento_n[:time_steps]#se obtienen los primeros time_steps(8) elementos del trainig set\n",
    "#     loss = []\n",
    "#     X_train_c_pred = []\n",
    "#     # print(f\"grtrt: {ts_cierre_s_pred}\")\n",
    "#     for i in range(time_steps, N):\n",
    "#         # Obtener las características y la etiqueta actual\n",
    "#         x_actual = ts_cierre_s_pred[i-time_steps:i,0]\n",
    "#         X_train_c_pred.append(x_actual)\n",
    "#         x_actual = x_actual.reshape(1,time_steps,1)\n",
    "\n",
    "#         y_actual = np.array([y_entrenamiento[i-time_steps]])\n",
    "\n",
    "#         print(f\"x_actual: {x_actual}\")\n",
    "#         print(f\"y_actual: {y_actual}\")\n",
    "        \n",
    "#         # Entrenar el modelo con las nuevas características y la etiqueta real\n",
    "#         #loss.append(red.train_on_batch(x_actual, y_actual))\n",
    "\n",
    "#         # Predicción del modelo\n",
    "#         #prediccion = red.predict(x_actual)#.reshape(1,1,1)\n",
    "#         prediccion = red(x_actual)\n",
    "        \n",
    "#         # Agregar la predicción a las características para el siguiente paso\n",
    "#         # print(ts_cierre_s_pred)\n",
    "#         print(f\"prediccion: {prediccion}\")\n",
    "#         ts_cierre_s_pred = np.concatenate([ts_cierre_s_pred, prediccion])\n",
    "\n",
    "\n",
    "\n",
    "#     # print(f\"mean: {np.mean(np.array(loss))}\")\n",
    "#     # loss_m.append(np.mean(np.array(loss)))\n",
    "#     X_train_c_pred = np.array(X_train_c_pred)\n",
    "#     X_train_c_pred = np.reshape(X_train_c_pred, (X_train_c_pred.shape[0], X_train_c_pred.shape[1], 1))\n",
    "#     history = red.fit(X_train_c_pred, y_entrenamiento, epochs=1, batch_size=32)\n",
    "#     loss = history.history['loss']\n",
    "#     loss_m.append(loss)\n",
    "#     loss_m.append(mean_squared_error(c_entrenamiento_n,ts_cierre_s_pred[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "from keras import backend as K\n",
    "\n",
    "class CustomLearningRateScheduler(Callback):\n",
    "    def __init__(self, initial_lr, decay_factor):\n",
    "        super(CustomLearningRateScheduler, self).__init__()\n",
    "        self.initial_lr = initial_lr\n",
    "        self.decay_factor = decay_factor\n",
    "        self.iteration = 0  # Contador de iteraciones\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        #lr = self.initial_lr * (self.decay_factor ** self.iteration)\n",
    "        lr = self.initial_lr / (1 + self.decay_factor * self.iteration)\n",
    "        print(f\"lr: {lr}, batch: {batch}\")\n",
    "        if (logs['epoca'] == 1):\n",
    "            writer.add_scalar(\"Learning Rate en cada batch: \",lr,batch)\n",
    "        #print(red.summary())\n",
    "        K.set_value(red.optimizer.lr, lr)\n",
    "        self.iteration += 1\n",
    "    \n",
    "    def reset(self):\n",
    "        K.set_value(red.optimizer.lr, self.initial_lr)\n",
    "        self.iteration = 0\n",
    "        print(\"Se resetea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_entrenamiento: [0.04610616 0.10422317 0.1542038  0.15575358 0.12553274 0.14567997\n",
      " 0.14645486 0.19604804 0.2305308  0.20844634 0.21193336 0.207284\n",
      " 0.19294847 0.19682294 0.21425804 0.18132507 0.17512592 0.14800465\n",
      " 0.15885316 0.19217358 0.18597443 0.26695079 0.29252228 0.31770632\n",
      " 0.31266951 0.28903526 0.28283611 0.29949632 0.27586207 0.27469973\n",
      " 0.27547462 0.33475397 0.35567609 0.3366912  0.33359163 0.3847346\n",
      " 0.57109647 0.59628051 0.57458349 0.60635413 0.58465711 0.56877179\n",
      " 0.64277412 0.66175901 0.67299496 0.7105773  0.7039907  0.7272375\n",
      " 0.72258814 0.77179388 0.72452538 0.67105773 0.67376986 0.71445176\n",
      " 0.74389771 0.72258814 0.69934134 0.73731112 0.7214258  0.71871368\n",
      " 0.6741573  0.69856645 0.72103836 0.72258814 0.75629601 0.82758621\n",
      " 0.83882216 0.79426579 0.78380473 0.76791941 0.78457962 0.87872917\n",
      " 0.8756296  0.84889578 0.81828749 0.82681131 0.78535451 0.78922898\n",
      " 0.8341728  0.81247578 0.80123983 0.80317706 0.7934909  0.76017048\n",
      " 0.73537389 0.71018985 0.71212708 0.7396358  0.73614878 0.66757071\n",
      " 0.66989539 0.69662921 0.65594731 0.67880666 0.67609454 0.72956219\n",
      " 0.70127857 0.76753196 0.75513367 0.74506005 0.7520341  0.7098024\n",
      " 0.69043007 0.75435878 0.7222007  0.84850833 0.905463   0.8822162\n",
      " 0.90778768 0.88957768 0.87485471 0.91321193 1.         0.97055405\n",
      " 0.88880279 0.87795428 0.84889578 0.8341728  0.85509492 0.87524215\n",
      " 0.85703216 0.85005812 0.84269663 0.82293685 0.77450601 0.78419217\n",
      " 0.85974429 0.85432003 0.83688493 0.82991089 0.887253   0.85974429\n",
      " 0.83959706 0.78380473 0.81828749 0.79116621 0.76055792 0.79155366\n",
      " 0.7686943  0.7686943  0.79891515 0.79000387 0.76017048 0.68539326\n",
      " 0.60519179 0.66485858 0.70786517 0.66485858 0.71135219 0.67725688\n",
      " 0.76210771 0.80705153 0.81518791 0.90623789 0.95970554 0.9643549\n",
      " 0.8880279  0.89267726 0.87524215 0.85083301 0.84889578 0.96241767\n",
      " 0.96784192 0.94072065 0.97249128 0.99690043 0.95118171 0.89577683\n",
      " 0.8814413  0.9170864  0.91979853 0.96164277 0.96822937 0.95776831]\n",
      "0\n",
      "[[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "ejemplar: [0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      " 0.03448276 0.04223169]\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.24278472]]\n",
      "Lr que voy a aplicar en el lote: 1 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      "  0.03448276 0.04223169]]\n",
      "verdaderas salidas: [0.04610616]\n",
      "PERDIDAAAA antes: 0.03868245705962181\n",
      "Predicción post entrenamiento : [[0.24153998]]\n",
      "PERDIDAAAA despues: 0.038194380700588226\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "[[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24278472]]]\n",
      "ejemplar: [0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      " 0.04223169 0.24278472]\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.22595689]]\n",
      "Lr que voy a aplicar en el lote: 2 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      "  0.04223169 0.24278472]]\n",
      "verdaderas salidas: [0.10422317]\n",
      "PERDIDAAAA antes: 0.014819097705185413\n",
      "Predicción post entrenamiento : [[0.22410107]]\n",
      "PERDIDAAAA despues: 0.014370710588991642\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "[[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24278472]\n",
      "  [0.22595689]]]\n",
      "ejemplar: [0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      " 0.24278472 0.22595689]\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.2282132]]\n",
      "Lr que voy a aplicar en el lote: 3 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      "  0.24278472 0.22595689]]\n",
      "verdaderas salidas: [0.1542038]\n",
      "PERDIDAAAA antes: 0.0054773916490375996\n",
      "Predicción post entrenamiento : [[0.22618432]]\n",
      "PERDIDAAAA despues: 0.005181195214390755\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "[[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24278472]\n",
      "  [0.22595689]\n",
      "  [0.22821321]]]\n",
      "ejemplar: [0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.24278472\n",
      " 0.22595689 0.22821321]\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.23805818]]\n",
      "Lr que voy a aplicar en el lote: 4 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.24278472\n",
      "  0.22595689 0.22821321]]\n",
      "verdaderas salidas: [0.15575358]\n",
      "PERDIDAAAA antes: 0.006774046458303928\n",
      "Predicción post entrenamiento : [[0.23590279]]\n",
      "PERDIDAAAA despues: 0.00642389478161931\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "[[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24278472]\n",
      "  [0.22595689]\n",
      "  [0.22821321]\n",
      "  [0.23805818]]]\n",
      "ejemplar: [0.05656722 0.02595893 0.03448276 0.04223169 0.24278472 0.22595689\n",
      " 0.22821321 0.23805818]\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.24962816]]\n",
      "Lr que voy a aplicar en el lote: 5 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.05656722 0.02595893 0.03448276 0.04223169 0.24278472 0.22595689\n",
      "  0.22821321 0.23805818]]\n",
      "verdaderas salidas: [0.12553274]\n",
      "PERDIDAAAA antes: 0.015399671159684658\n",
      "Predicción post entrenamiento : [[0.24676807]]\n",
      "PERDIDAAAA despues: 0.014698004350066185\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "[[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24278472]\n",
      "  [0.22595689]\n",
      "  [0.22821321]\n",
      "  [0.23805818]\n",
      "  [0.24962816]]]\n",
      "ejemplar: [0.02595893 0.03448276 0.04223169 0.24278472 0.22595689 0.22821321\n",
      " 0.23805818 0.24962816]\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.25878137]]\n",
      "Lr que voy a aplicar en el lote: 6 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.02595893 0.03448276 0.04223169 0.24278472 0.22595689 0.22821321\n",
      "  0.23805818 0.24962816]]\n",
      "verdaderas salidas: [0.14567997]\n",
      "PERDIDAAAA antes: 0.012791928835213184\n",
      "Predicción post entrenamiento : [[0.25576264]]\n",
      "PERDIDAAAA despues: 0.012118194252252579\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "[[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24278472]\n",
      "  [0.22595689]\n",
      "  [0.22821321]\n",
      "  [0.23805818]\n",
      "  [0.24962816]\n",
      "  [0.25878137]]]\n",
      "ejemplar: [0.03448276 0.04223169 0.24278472 0.22595689 0.22821321 0.23805818\n",
      " 0.24962816 0.25878137]\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.2800611]]\n",
      "Lr que voy a aplicar en el lote: 7 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.03448276 0.04223169 0.24278472 0.22595689 0.22821321 0.23805818\n",
      "  0.24962816 0.25878137]]\n",
      "verdaderas salidas: [0.14645486]\n",
      "PERDIDAAAA antes: 0.01785062812268734\n",
      "Predicción post entrenamiento : [[0.27681634]]\n",
      "PERDIDAAAA despues: 0.016994116827845573\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "[[[0.04223169]\n",
      "  [0.24278472]\n",
      "  [0.22595689]\n",
      "  [0.22821321]\n",
      "  [0.23805818]\n",
      "  [0.24962816]\n",
      "  [0.25878137]\n",
      "  [0.2800611 ]]]\n",
      "ejemplar: [0.04223169 0.24278472 0.22595689 0.22821321 0.23805818 0.24962816\n",
      " 0.25878137 0.2800611 ]\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.30718186]]\n",
      "Lr que voy a aplicar en el lote: 8 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.04223169 0.24278472 0.22595689 0.22821321 0.23805818 0.24962816\n",
      "  0.25878137 0.2800611 ]]\n",
      "verdaderas salidas: [0.19604804]\n",
      "PERDIDAAAA antes: 0.012350727804005146\n",
      "Predicción post entrenamiento : [[0.30287167]]\n",
      "PERDIDAAAA despues: 0.011411289684474468\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "[[[0.24278472]\n",
      "  [0.22595689]\n",
      "  [0.22821321]\n",
      "  [0.23805818]\n",
      "  [0.24962816]\n",
      "  [0.25878137]\n",
      "  [0.2800611 ]\n",
      "  [0.30718186]]]\n",
      "ejemplar: [0.24278472 0.22595689 0.22821321 0.23805818 0.24962816 0.25878137\n",
      " 0.2800611  0.30718186]\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.3398323]]\n",
      "Lr que voy a aplicar en el lote: 9 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.24278472 0.22595689 0.22821321 0.23805818 0.24962816 0.25878137\n",
      "  0.2800611  0.30718186]]\n",
      "verdaderas salidas: [0.2305308]\n",
      "PERDIDAAAA antes: 0.011946819722652435\n",
      "Predicción post entrenamiento : [[0.3348841]]\n",
      "PERDIDAAAA despues: 0.010889613069593906\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "[[[0.22595689]\n",
      "  [0.22821321]\n",
      "  [0.23805818]\n",
      "  [0.24962816]\n",
      "  [0.25878137]\n",
      "  [0.2800611 ]\n",
      "  [0.30718186]\n",
      "  [0.33983231]]]\n",
      "ejemplar: [0.22595689 0.22821321 0.23805818 0.24962816 0.25878137 0.2800611\n",
      " 0.30718186 0.33983231]\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.33602726]]\n",
      "Lr que voy a aplicar en el lote: 10 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.22595689 0.22821321 0.23805818 0.24962816 0.25878137 0.2800611\n",
      "  0.30718186 0.33983231]]\n",
      "verdaderas salidas: [0.20844634]\n",
      "PERDIDAAAA antes: 0.01627689227461815\n",
      "Predicción post entrenamiento : [[0.33026722]]\n",
      "PERDIDAAAA despues: 0.014840327203273773\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "[[[0.22821321]\n",
      "  [0.23805818]\n",
      "  [0.24962816]\n",
      "  [0.25878137]\n",
      "  [0.2800611 ]\n",
      "  [0.30718186]\n",
      "  [0.33983231]\n",
      "  [0.33602726]]]\n",
      "ejemplar: [0.22821321 0.23805818 0.24962816 0.25878137 0.2800611  0.30718186\n",
      " 0.33983231 0.33602726]\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.33686727]]\n",
      "Lr que voy a aplicar en el lote: 11 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.22821321 0.23805818 0.24962816 0.25878137 0.2800611  0.30718186\n",
      "  0.33983231 0.33602726]]\n",
      "verdaderas salidas: [0.21193336]\n",
      "PERDIDAAAA antes: 0.015608482994139194\n",
      "Predicción post entrenamiento : [[0.33103943]]\n",
      "PERDIDAAAA despues: 0.014186255633831024\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "[[[0.23805818]\n",
      "  [0.24962816]\n",
      "  [0.25878137]\n",
      "  [0.2800611 ]\n",
      "  [0.30718186]\n",
      "  [0.33983231]\n",
      "  [0.33602726]\n",
      "  [0.33686727]]]\n",
      "ejemplar: [0.23805818 0.24962816 0.25878137 0.2800611  0.30718186 0.33983231\n",
      " 0.33602726 0.33686727]\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.33999372]]\n",
      "Lr que voy a aplicar en el lote: 12 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.23805818 0.24962816 0.25878137 0.2800611  0.30718186 0.33983231\n",
      "  0.33602726 0.33686727]]\n",
      "verdaderas salidas: [0.207284]\n",
      "PERDIDAAAA antes: 0.01761186681687832\n",
      "Predicción post entrenamiento : [[0.3333195]]\n",
      "PERDIDAAAA despues: 0.015884943306446075\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "[[[0.24962816]\n",
      "  [0.25878137]\n",
      "  [0.2800611 ]\n",
      "  [0.30718186]\n",
      "  [0.33983231]\n",
      "  [0.33602726]\n",
      "  [0.33686727]\n",
      "  [0.33999372]]]\n",
      "ejemplar: [0.24962816 0.25878137 0.2800611  0.30718186 0.33983231 0.33602726\n",
      " 0.33686727 0.33999372]\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.34329385]]\n",
      "Lr que voy a aplicar en el lote: 13 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.24962816 0.25878137 0.2800611  0.30718186 0.33983231 0.33602726\n",
      "  0.33686727 0.33999372]]\n",
      "verdaderas salidas: [0.19294847]\n",
      "PERDIDAAAA antes: 0.022603729739785194\n",
      "Predicción post entrenamiento : [[0.3362612]]\n",
      "PERDIDAAAA despues: 0.020538540557026863\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "[[[0.25878137]\n",
      "  [0.2800611 ]\n",
      "  [0.30718186]\n",
      "  [0.33983231]\n",
      "  [0.33602726]\n",
      "  [0.33686727]\n",
      "  [0.33999372]\n",
      "  [0.34329385]]]\n",
      "ejemplar: [0.25878137 0.2800611  0.30718186 0.33983231 0.33602726 0.33686727\n",
      " 0.33999372 0.34329385]\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.34682918]]\n",
      "Lr que voy a aplicar en el lote: 14 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.25878137 0.2800611  0.30718186 0.33983231 0.33602726 0.33686727\n",
      "  0.33999372 0.34329385]]\n",
      "verdaderas salidas: [0.19682294]\n",
      "PERDIDAAAA antes: 0.0225018709897995\n",
      "Predicción post entrenamiento : [[0.33994356]]\n",
      "PERDIDAAAA despues: 0.020483510568737984\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "[[[0.2800611 ]\n",
      "  [0.30718186]\n",
      "  [0.33983231]\n",
      "  [0.33602726]\n",
      "  [0.33686727]\n",
      "  [0.33999372]\n",
      "  [0.34329385]\n",
      "  [0.34682918]]]\n",
      "ejemplar: [0.2800611  0.30718186 0.33983231 0.33602726 0.33686727 0.33999372\n",
      " 0.34329385 0.34682918]\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.3513983]]\n",
      "Lr que voy a aplicar en el lote: 15 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.2800611  0.30718186 0.33983231 0.33602726 0.33686727 0.33999372\n",
      "  0.34329385 0.34682918]]\n",
      "verdaderas salidas: [0.21425804]\n",
      "PERDIDAAAA antes: 0.01880744658410549\n",
      "Predicción post entrenamiento : [[0.34411296]]\n",
      "PERDIDAAAA despues: 0.016862299293279648\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "[[[0.30718186]\n",
      "  [0.33983231]\n",
      "  [0.33602726]\n",
      "  [0.33686727]\n",
      "  [0.33999372]\n",
      "  [0.34329385]\n",
      "  [0.34682918]\n",
      "  [0.35139829]]]\n",
      "ejemplar: [0.30718186 0.33983231 0.33602726 0.33686727 0.33999372 0.34329385\n",
      " 0.34682918 0.35139829]\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.35368487]]\n",
      "Lr que voy a aplicar en el lote: 16 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.30718186 0.33983231 0.33602726 0.33686727 0.33999372 0.34329385\n",
      "  0.34682918 0.35139829]]\n",
      "verdaderas salidas: [0.18132507]\n",
      "PERDIDAAAA antes: 0.029707903042435646\n",
      "Predicción post entrenamiento : [[0.3444074]]\n",
      "PERDIDAAAA despues: 0.02659585140645504\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "[[[0.33983231]\n",
      "  [0.33602726]\n",
      "  [0.33686727]\n",
      "  [0.33999372]\n",
      "  [0.34329385]\n",
      "  [0.34682918]\n",
      "  [0.35139829]\n",
      "  [0.35368487]]]\n",
      "ejemplar: [0.33983231 0.33602726 0.33686727 0.33999372 0.34329385 0.34682918\n",
      " 0.35139829 0.35368487]\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.35027558]]\n",
      "Lr que voy a aplicar en el lote: 17 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.33983231 0.33602726 0.33686727 0.33999372 0.34329385 0.34682918\n",
      "  0.35139829 0.35368487]]\n",
      "verdaderas salidas: [0.17512592]\n",
      "PERDIDAAAA antes: 0.030677400529384613\n",
      "Predicción post entrenamiento : [[0.34109893]]\n",
      "PERDIDAAAA despues: 0.027547039091587067\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "[[[0.33602726]\n",
      "  [0.33686727]\n",
      "  [0.33999372]\n",
      "  [0.34329385]\n",
      "  [0.34682918]\n",
      "  [0.35139829]\n",
      "  [0.35368487]\n",
      "  [0.35027558]]]\n",
      "ejemplar: [0.33602726 0.33686727 0.33999372 0.34329385 0.34682918 0.35139829\n",
      " 0.35368487 0.35027558]\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.3415329]]\n",
      "Lr que voy a aplicar en el lote: 18 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.33602726 0.33686727 0.33999372 0.34329385 0.34682918 0.35139829\n",
      "  0.35368487 0.35027558]]\n",
      "verdaderas salidas: [0.14800465]\n",
      "PERDIDAAAA antes: 0.03745317831635475\n",
      "Predicción post entrenamiento : [[0.33176553]]\n",
      "PERDIDAAAA despues: 0.03376806154847145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "[[[0.33686727]\n",
      "  [0.33999372]\n",
      "  [0.34329385]\n",
      "  [0.34682918]\n",
      "  [0.35139829]\n",
      "  [0.35368487]\n",
      "  [0.35027558]\n",
      "  [0.34153289]]]\n",
      "ejemplar: [0.33686727 0.33999372 0.34329385 0.34682918 0.35139829 0.35368487\n",
      " 0.35027558 0.34153289]\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.33319843]]\n",
      "Lr que voy a aplicar en el lote: 19 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.33686727 0.33999372 0.34329385 0.34682918 0.35139829 0.35368487\n",
      "  0.35027558 0.34153289]]\n",
      "verdaderas salidas: [0.15885316]\n",
      "PERDIDAAAA antes: 0.030396273359656334\n",
      "Predicción post entrenamiento : [[0.3227101]]\n",
      "PERDIDAAAA despues: 0.02684909664094448\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "[[[0.33999372]\n",
      "  [0.34329385]\n",
      "  [0.34682918]\n",
      "  [0.35139829]\n",
      "  [0.35368487]\n",
      "  [0.35027558]\n",
      "  [0.34153289]\n",
      "  [0.33319843]]]\n",
      "ejemplar: [0.33999372 0.34329385 0.34682918 0.35139829 0.35368487 0.35027558\n",
      " 0.34153289 0.33319843]\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.32424328]]\n",
      "Lr que voy a aplicar en el lote: 20 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.33999372 0.34329385 0.34682918 0.35139829 0.35368487 0.35027558\n",
      "  0.34153289 0.33319843]]\n",
      "verdaderas salidas: [0.19217358]\n",
      "PERDIDAAAA antes: 0.017442407086491585\n",
      "Predicción post entrenamiento : [[0.31416392]]\n",
      "PERDIDAAAA despues: 0.014881646260619164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "[[[0.34329385]\n",
      "  [0.34682918]\n",
      "  [0.35139829]\n",
      "  [0.35368487]\n",
      "  [0.35027558]\n",
      "  [0.34153289]\n",
      "  [0.33319843]\n",
      "  [0.32424328]]]\n",
      "ejemplar: [0.34329385 0.34682918 0.35139829 0.35368487 0.35027558 0.34153289\n",
      " 0.33319843 0.32424328]\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.31520835]]\n",
      "Lr que voy a aplicar en el lote: 21 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.34329385 0.34682918 0.35139829 0.35368487 0.35027558 0.34153289\n",
      "  0.33319843 0.32424328]]\n",
      "verdaderas salidas: [0.18597443]\n",
      "PERDIDAAAA antes: 0.016701404005289078\n",
      "Predicción post entrenamiento : [[0.30572048]]\n",
      "PERDIDAAAA despues: 0.014339115470647812\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "[[[0.34682918]\n",
      "  [0.35139829]\n",
      "  [0.35368487]\n",
      "  [0.35027558]\n",
      "  [0.34153289]\n",
      "  [0.33319843]\n",
      "  [0.32424328]\n",
      "  [0.31520835]]]\n",
      "ejemplar: [0.34682918 0.35139829 0.35368487 0.35027558 0.34153289 0.33319843\n",
      " 0.32424328 0.31520835]\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.30599612]]\n",
      "Lr que voy a aplicar en el lote: 22 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.34682918 0.35139829 0.35368487 0.35027558 0.34153289 0.33319843\n",
      "  0.32424328 0.31520835]]\n",
      "verdaderas salidas: [0.26695079]\n",
      "PERDIDAAAA antes: 0.0015245381509885192\n",
      "Predicción post entrenamiento : [[0.29706842]]\n",
      "PERDIDAAAA despues: 0.0009070716914720833\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "[[[0.35139829]\n",
      "  [0.35368487]\n",
      "  [0.35027558]\n",
      "  [0.34153289]\n",
      "  [0.33319843]\n",
      "  [0.32424328]\n",
      "  [0.31520835]\n",
      "  [0.30599612]]]\n",
      "ejemplar: [0.35139829 0.35368487 0.35027558 0.34153289 0.33319843 0.32424328\n",
      " 0.31520835 0.30599612]\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.29626483]]\n",
      "Lr que voy a aplicar en el lote: 23 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.35139829 0.35368487 0.35027558 0.34153289 0.33319843 0.32424328\n",
      "  0.31520835 0.30599612]]\n",
      "verdaderas salidas: [0.29252228]\n",
      "PERDIDAAAA antes: 1.4006649507791735e-05\n",
      "Predicción post entrenamiento : [[0.2884166]]\n",
      "PERDIDAAAA despues: 1.6856667571119033e-05\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "[[[0.35368487]\n",
      "  [0.35027558]\n",
      "  [0.34153289]\n",
      "  [0.33319843]\n",
      "  [0.32424328]\n",
      "  [0.31520835]\n",
      "  [0.30599612]\n",
      "  [0.29626483]]]\n",
      "ejemplar: [0.35368487 0.35027558 0.34153289 0.33319843 0.32424328 0.31520835\n",
      " 0.30599612 0.29626483]\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.2860897]]\n",
      "Lr que voy a aplicar en el lote: 24 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.35368487 0.35027558 0.34153289 0.33319843 0.32424328 0.31520835\n",
      "  0.30599612 0.29626483]]\n",
      "verdaderas salidas: [0.31770632]\n",
      "PERDIDAAAA antes: 0.0009996112203225493\n",
      "Predicción post entrenamiento : [[0.27948767]]\n",
      "PERDIDAAAA despues: 0.0014606650220230222\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "[[[0.35027558]\n",
      "  [0.34153289]\n",
      "  [0.33319843]\n",
      "  [0.32424328]\n",
      "  [0.31520835]\n",
      "  [0.30599612]\n",
      "  [0.29626483]\n",
      "  [0.28608969]]]\n",
      "ejemplar: [0.35027558 0.34153289 0.33319843 0.32424328 0.31520835 0.30599612\n",
      " 0.29626483 0.28608969]\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.275746]]\n",
      "Lr que voy a aplicar en el lote: 25 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.35027558 0.34153289 0.33319843 0.32424328 0.31520835 0.30599612\n",
      "  0.29626483 0.28608969]]\n",
      "verdaderas salidas: [0.31266951]\n",
      "PERDIDAAAA antes: 0.001363346935249865\n",
      "Predicción post entrenamiento : [[0.27032265]]\n",
      "PERDIDAAAA despues: 0.0017932569608092308\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "[[[0.34153289]\n",
      "  [0.33319843]\n",
      "  [0.32424328]\n",
      "  [0.31520835]\n",
      "  [0.30599612]\n",
      "  [0.29626483]\n",
      "  [0.28608969]\n",
      "  [0.27574599]]]\n",
      "ejemplar: [0.34153289 0.33319843 0.32424328 0.31520835 0.30599612 0.29626483\n",
      " 0.28608969 0.27574599]\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.26586914]]\n",
      "Lr que voy a aplicar en el lote: 26 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.34153289 0.33319843 0.32424328 0.31520835 0.30599612 0.29626483\n",
      "  0.28608969 0.27574599]]\n",
      "verdaderas salidas: [0.28903526]\n",
      "PERDIDAAAA antes: 0.0005366691038943827\n",
      "Predicción post entrenamiento : [[0.2613797]]\n",
      "PERDIDAAAA despues: 0.0007648306200280786\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "[[[0.33319843]\n",
      "  [0.32424328]\n",
      "  [0.31520835]\n",
      "  [0.30599612]\n",
      "  [0.29626483]\n",
      "  [0.28608969]\n",
      "  [0.27574599]\n",
      "  [0.26586914]]]\n",
      "ejemplar: [0.33319843 0.32424328 0.31520835 0.30599612 0.29626483 0.28608969\n",
      " 0.27574599 0.26586914]\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.25693813]]\n",
      "Lr que voy a aplicar en el lote: 27 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.33319843 0.32424328 0.31520835 0.30599612 0.29626483 0.28608969\n",
      "  0.27574599 0.26586914]]\n",
      "verdaderas salidas: [0.28283611]\n",
      "PERDIDAAAA antes: 0.000670705339871347\n",
      "Predicción post entrenamiento : [[0.25292626]]\n",
      "PERDIDAAAA despues: 0.0008945990703068674\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "[[[0.32424328]\n",
      "  [0.31520835]\n",
      "  [0.30599612]\n",
      "  [0.29626483]\n",
      "  [0.28608969]\n",
      "  [0.27574599]\n",
      "  [0.26586914]\n",
      "  [0.25693813]]]\n",
      "ejemplar: [0.32424328 0.31520835 0.30599612 0.29626483 0.28608969 0.27574599\n",
      " 0.26586914 0.25693813]\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.24840409]]\n",
      "Lr que voy a aplicar en el lote: 28 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.32424328 0.31520835 0.30599612 0.29626483 0.28608969 0.27574599\n",
      "  0.26586914 0.25693813]]\n",
      "verdaderas salidas: [0.29949632]\n",
      "PERDIDAAAA antes: 0.002610416617244482\n",
      "Predicción post entrenamiento : [[0.24517186]]\n",
      "PERDIDAAAA despues: 0.0029511472675949335\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "[[[0.31520835]\n",
      "  [0.30599612]\n",
      "  [0.29626483]\n",
      "  [0.28608969]\n",
      "  [0.27574599]\n",
      "  [0.26586914]\n",
      "  [0.25693813]\n",
      "  [0.24840409]]]\n",
      "ejemplar: [0.31520835 0.30599612 0.29626483 0.28608969 0.27574599 0.26586914\n",
      " 0.25693813 0.24840409]\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.24063168]]\n",
      "Lr que voy a aplicar en el lote: 29 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.31520835 0.30599612 0.29626483 0.28608969 0.27574599 0.26586914\n",
      "  0.25693813 0.24840409]]\n",
      "verdaderas salidas: [0.27586207]\n",
      "PERDIDAAAA antes: 0.0012411798816174269\n",
      "Predicción post entrenamiento : [[0.23778418]]\n",
      "PERDIDAAAA despues: 0.0014499258249998093\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "[[[0.30599612]\n",
      "  [0.29626483]\n",
      "  [0.28608969]\n",
      "  [0.27574599]\n",
      "  [0.26586914]\n",
      "  [0.25693813]\n",
      "  [0.24840409]\n",
      "  [0.24063168]]]\n",
      "ejemplar: [0.30599612 0.29626483 0.28608969 0.27574599 0.26586914 0.25693813\n",
      " 0.24840409 0.24063168]\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.23323122]]\n",
      "Lr que voy a aplicar en el lote: 30 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.30599612 0.29626483 0.28608969 0.27574599 0.26586914 0.25693813\n",
      "  0.24840409 0.24063168]]\n",
      "verdaderas salidas: [0.27469973]\n",
      "PERDIDAAAA antes: 0.0017196366097778082\n",
      "Predicción post entrenamiento : [[0.23100372]]\n",
      "PERDIDAAAA despues: 0.0019093404989689589\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "[[[0.29626483]\n",
      "  [0.28608969]\n",
      "  [0.27574599]\n",
      "  [0.26586914]\n",
      "  [0.25693813]\n",
      "  [0.24840409]\n",
      "  [0.24063168]\n",
      "  [0.23323122]]]\n",
      "ejemplar: [0.29626483 0.28608969 0.27574599 0.26586914 0.25693813 0.24840409\n",
      " 0.24063168 0.23323122]\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.226468]]\n",
      "Lr que voy a aplicar en el lote: 31 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.29626483 0.28608969 0.27574599 0.26586914 0.25693813 0.24840409\n",
      "  0.24063168 0.23323122]]\n",
      "verdaderas salidas: [0.27547462]\n",
      "PERDIDAAAA antes: 0.0024016478564590216\n",
      "Predicción post entrenamiento : [[0.22483462]]\n",
      "PERDIDAAAA despues: 0.002564408350735903\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "[[[0.28608969]\n",
      "  [0.27574599]\n",
      "  [0.26586914]\n",
      "  [0.25693813]\n",
      "  [0.24840409]\n",
      "  [0.24063168]\n",
      "  [0.23323122]\n",
      "  [0.226468  ]]]\n",
      "ejemplar: [0.28608969 0.27574599 0.26586914 0.25693813 0.24840409 0.24063168\n",
      " 0.23323122 0.226468  ]\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.22041263]]\n",
      "Lr que voy a aplicar en el lote: 32 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.28608969 0.27574599 0.26586914 0.25693813 0.24840409 0.24063168\n",
      "  0.23323122 0.226468  ]]\n",
      "verdaderas salidas: [0.33475397]\n",
      "PERDIDAAAA antes: 0.013073940761387348\n",
      "Predicción post entrenamiento : [[0.2194679]]\n",
      "PERDIDAAAA despues: 0.01329087745398283\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "[[[0.27574599]\n",
      "  [0.26586914]\n",
      "  [0.25693813]\n",
      "  [0.24840409]\n",
      "  [0.24063168]\n",
      "  [0.23323122]\n",
      "  [0.226468  ]\n",
      "  [0.22041263]]]\n",
      "ejemplar: [0.27574599 0.26586914 0.25693813 0.24840409 0.24063168 0.23323122\n",
      " 0.226468   0.22041263]\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.21526472]]\n",
      "Lr que voy a aplicar en el lote: 33 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.27574599 0.26586914 0.25693813 0.24840409 0.24063168 0.23323122\n",
      "  0.226468   0.22041263]]\n",
      "verdaderas salidas: [0.35567609]\n",
      "PERDIDAAAA antes: 0.01971535012125969\n",
      "Predicción post entrenamiento : [[0.21497895]]\n",
      "PERDIDAAAA despues: 0.01979568414390087\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "[[[0.26586914]\n",
      "  [0.25693813]\n",
      "  [0.24840409]\n",
      "  [0.24063168]\n",
      "  [0.23323122]\n",
      "  [0.226468  ]\n",
      "  [0.22041263]\n",
      "  [0.21526472]]]\n",
      "ejemplar: [0.26586914 0.25693813 0.24840409 0.24063168 0.23323122 0.226468\n",
      " 0.22041263 0.21526472]\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.2110809]]\n",
      "Lr que voy a aplicar en el lote: 34 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.26586914 0.25693813 0.24840409 0.24063168 0.23323122 0.226468\n",
      "  0.22041263 0.21526472]]\n",
      "verdaderas salidas: [0.3366912]\n",
      "PERDIDAAAA antes: 0.01577794924378395\n",
      "Predicción post entrenamiento : [[0.21131209]]\n",
      "PERDIDAAAA despues: 0.01571992225944996\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "[[[0.25693813]\n",
      "  [0.24840409]\n",
      "  [0.24063168]\n",
      "  [0.23323122]\n",
      "  [0.226468  ]\n",
      "  [0.22041263]\n",
      "  [0.21526472]\n",
      "  [0.21108089]]]\n",
      "ejemplar: [0.25693813 0.24840409 0.24063168 0.23323122 0.226468   0.22041263\n",
      " 0.21526472 0.21108089]\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.2077325]]\n",
      "Lr que voy a aplicar en el lote: 35 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.25693813 0.24840409 0.24063168 0.23323122 0.226468   0.22041263\n",
      "  0.21526472 0.21108089]]\n",
      "verdaderas salidas: [0.33359163]\n",
      "PERDIDAAAA antes: 0.015840522944927216\n",
      "Predicción post entrenamiento : [[0.20835908]]\n",
      "PERDIDAAAA despues: 0.015683194622397423\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "[[[0.24840409]\n",
      "  [0.24063168]\n",
      "  [0.23323122]\n",
      "  [0.226468  ]\n",
      "  [0.22041263]\n",
      "  [0.21526472]\n",
      "  [0.21108089]\n",
      "  [0.2077325 ]]]\n",
      "ejemplar: [0.24840409 0.24063168 0.23323122 0.226468   0.22041263 0.21526472\n",
      " 0.21108089 0.2077325 ]\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.20505115]]\n",
      "Lr que voy a aplicar en el lote: 36 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.24840409 0.24063168 0.23323122 0.226468   0.22041263 0.21526472\n",
      "  0.21108089 0.2077325 ]]\n",
      "verdaderas salidas: [0.3847346]\n",
      "PERDIDAAAA antes: 0.0322861410677433\n",
      "Predicción post entrenamiento : [[0.20629042]]\n",
      "PERDIDAAAA despues: 0.03184232488274574\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "[[[0.24063168]\n",
      "  [0.23323122]\n",
      "  [0.226468  ]\n",
      "  [0.22041263]\n",
      "  [0.21526472]\n",
      "  [0.21108089]\n",
      "  [0.2077325 ]\n",
      "  [0.20505115]]]\n",
      "ejemplar: [0.24063168 0.23323122 0.226468   0.22041263 0.21526472 0.21108089\n",
      " 0.2077325  0.20505115]\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.20328414]]\n",
      "Lr que voy a aplicar en el lote: 37 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.24063168 0.23323122 0.226468   0.22041263 0.21526472 0.21108089\n",
      "  0.2077325  0.20505115]]\n",
      "verdaderas salidas: [0.57109647]\n",
      "PERDIDAAAA antes: 0.13528591394424438\n",
      "Predicción post entrenamiento : [[0.20571615]]\n",
      "PERDIDAAAA despues: 0.133502796292305\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "[[[0.23323122]\n",
      "  [0.226468  ]\n",
      "  [0.22041263]\n",
      "  [0.21526472]\n",
      "  [0.21108089]\n",
      "  [0.2077325 ]\n",
      "  [0.20505115]\n",
      "  [0.20328414]]]\n",
      "ejemplar: [0.23323122 0.226468   0.22041263 0.21526472 0.21108089 0.2077325\n",
      " 0.20505115 0.20328414]\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.20299536]]\n",
      "Lr que voy a aplicar en el lote: 38 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.23323122 0.226468   0.22041263 0.21526472 0.21108089 0.2077325\n",
      "  0.20505115 0.20328414]]\n",
      "verdaderas salidas: [0.59628051]\n",
      "PERDIDAAAA antes: 0.15467321872711182\n",
      "Predicción post entrenamiento : [[0.20655645]]\n",
      "PERDIDAAAA despues: 0.15188485383987427\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "[[[0.226468  ]\n",
      "  [0.22041263]\n",
      "  [0.21526472]\n",
      "  [0.21108089]\n",
      "  [0.2077325 ]\n",
      "  [0.20505115]\n",
      "  [0.20328414]\n",
      "  [0.20299536]]]\n",
      "ejemplar: [0.226468   0.22041263 0.21526472 0.21108089 0.2077325  0.20505115\n",
      " 0.20328414 0.20299536]\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.20416963]]\n",
      "Lr que voy a aplicar en el lote: 39 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.226468   0.22041263 0.21526472 0.21108089 0.2077325  0.20505115\n",
      "  0.20328414 0.20299536]]\n",
      "verdaderas salidas: [0.57458349]\n",
      "PERDIDAAAA antes: 0.13720640540122986\n",
      "Predicción post entrenamiento : [[0.20867063]]\n",
      "PERDIDAAAA despues: 0.133892223238945\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "[[[0.22041263]\n",
      "  [0.21526472]\n",
      "  [0.21108089]\n",
      "  [0.2077325 ]\n",
      "  [0.20505115]\n",
      "  [0.20328414]\n",
      "  [0.20299536]\n",
      "  [0.20416963]]]\n",
      "ejemplar: [0.22041263 0.21526472 0.21108089 0.2077325  0.20505115 0.20328414\n",
      " 0.20299536 0.20416963]\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.20664826]]\n",
      "Lr que voy a aplicar en el lote: 40 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.22041263 0.21526472 0.21108089 0.2077325  0.20505115 0.20328414\n",
      "  0.20299536 0.20416963]]\n",
      "verdaderas salidas: [0.60635413]\n",
      "PERDIDAAAA antes: 0.15976476669311523\n",
      "Predicción post entrenamiento : [[0.21219546]]\n",
      "PERDIDAAAA despues: 0.15536105632781982\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "[[[0.21526472]\n",
      "  [0.21108089]\n",
      "  [0.2077325 ]\n",
      "  [0.20505115]\n",
      "  [0.20328414]\n",
      "  [0.20299536]\n",
      "  [0.20416963]\n",
      "  [0.20664826]]]\n",
      "ejemplar: [0.21526472 0.21108089 0.2077325  0.20505115 0.20328414 0.20299536\n",
      " 0.20416963 0.20664826]\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.2105726]]\n",
      "Lr que voy a aplicar en el lote: 41 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.21526472 0.21108089 0.2077325  0.20505115 0.20328414 0.20299536\n",
      "  0.20416963 0.20664826]]\n",
      "verdaderas salidas: [0.58465711]\n",
      "PERDIDAAAA antes: 0.13993923366069794\n",
      "Predicción post entrenamiento : [[0.21700715]]\n",
      "PERDIDAAAA despues: 0.1351664960384369\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "[[[0.21108089]\n",
      "  [0.2077325 ]\n",
      "  [0.20505115]\n",
      "  [0.20328414]\n",
      "  [0.20299536]\n",
      "  [0.20416963]\n",
      "  [0.20664826]\n",
      "  [0.2105726 ]]]\n",
      "ejemplar: [0.21108089 0.2077325  0.20505115 0.20328414 0.20299536 0.20416963\n",
      " 0.20664826 0.2105726 ]\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.21580768]]\n",
      "Lr que voy a aplicar en el lote: 42 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.21108089 0.2077325  0.20505115 0.20328414 0.20299536 0.20416963\n",
      "  0.20664826 0.2105726 ]]\n",
      "verdaderas salidas: [0.56877179]\n",
      "PERDIDAAAA antes: 0.1245836615562439\n",
      "Predicción post entrenamiento : [[0.22295809]]\n",
      "PERDIDAAAA despues: 0.11958710849285126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "[[[0.2077325 ]\n",
      "  [0.20505115]\n",
      "  [0.20328414]\n",
      "  [0.20299536]\n",
      "  [0.20416963]\n",
      "  [0.20664826]\n",
      "  [0.2105726 ]\n",
      "  [0.21580768]]]\n",
      "ejemplar: [0.2077325  0.20505115 0.20328414 0.20299536 0.20416963 0.20664826\n",
      " 0.2105726  0.21580768]\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.22221269]]\n",
      "Lr que voy a aplicar en el lote: 43 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.2077325  0.20505115 0.20328414 0.20299536 0.20416963 0.20664826\n",
      "  0.2105726  0.21580768]]\n",
      "verdaderas salidas: [0.64277412]\n",
      "PERDIDAAAA antes: 0.17687192559242249\n",
      "Predicción post entrenamiento : [[0.230301]]\n",
      "PERDIDAAAA despues: 0.1701340675354004\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "[[[0.20505115]\n",
      "  [0.20328414]\n",
      "  [0.20299536]\n",
      "  [0.20416963]\n",
      "  [0.20664826]\n",
      "  [0.2105726 ]\n",
      "  [0.21580768]\n",
      "  [0.22221269]]]\n",
      "ejemplar: [0.20505115 0.20328414 0.20299536 0.20416963 0.20664826 0.2105726\n",
      " 0.21580768 0.22221269]\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.23007472]]\n",
      "Lr que voy a aplicar en el lote: 44 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.20505115 0.20328414 0.20299536 0.20416963 0.20664826 0.2105726\n",
      "  0.21580768 0.22221269]]\n",
      "verdaderas salidas: [0.66175901]\n",
      "PERDIDAAAA antes: 0.18635134398937225\n",
      "Predicción post entrenamiento : [[0.23918122]]\n",
      "PERDIDAAAA despues: 0.17857199907302856\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "[[[0.20328414]\n",
      "  [0.20299536]\n",
      "  [0.20416963]\n",
      "  [0.20664826]\n",
      "  [0.2105726 ]\n",
      "  [0.21580768]\n",
      "  [0.22221269]\n",
      "  [0.23007472]]]\n",
      "ejemplar: [0.20328414 0.20299536 0.20416963 0.20664826 0.2105726  0.21580768\n",
      " 0.22221269 0.23007472]\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.23958835]]\n",
      "Lr que voy a aplicar en el lote: 45 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.20328414 0.20299536 0.20416963 0.20664826 0.2105726  0.21580768\n",
      "  0.22221269 0.23007472]]\n",
      "verdaderas salidas: [0.67299496]\n",
      "PERDIDAAAA antes: 0.1878412961959839\n",
      "Predicción post entrenamiento : [[0.24975751]]\n",
      "PERDIDAAAA despues: 0.1791299283504486\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "[[[0.20299536]\n",
      "  [0.20416963]\n",
      "  [0.20664826]\n",
      "  [0.2105726 ]\n",
      "  [0.21580768]\n",
      "  [0.22221269]\n",
      "  [0.23007472]\n",
      "  [0.23958835]]]\n",
      "ejemplar: [0.20299536 0.20416963 0.20664826 0.2105726  0.21580768 0.22221269\n",
      " 0.23007472 0.23958835]\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.2509022]]\n",
      "Lr que voy a aplicar en el lote: 46 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.20299536 0.20416963 0.20664826 0.2105726  0.21580768 0.22221269\n",
      "  0.23007472 0.23958835]]\n",
      "verdaderas salidas: [0.7105773]\n",
      "PERDIDAAAA antes: 0.21130120754241943\n",
      "Predicción post entrenamiento : [[0.26220345]]\n",
      "PERDIDAAAA despues: 0.20103910565376282\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "[[[0.20416963]\n",
      "  [0.20664826]\n",
      "  [0.2105726 ]\n",
      "  [0.21580768]\n",
      "  [0.22221269]\n",
      "  [0.23007472]\n",
      "  [0.23958835]\n",
      "  [0.25090221]]]\n",
      "ejemplar: [0.20416963 0.20664826 0.2105726  0.21580768 0.22221269 0.23007472\n",
      " 0.23958835 0.25090221]\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.26412046]]\n",
      "Lr que voy a aplicar en el lote: 47 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.20416963 0.20664826 0.2105726  0.21580768 0.22221269 0.23007472\n",
      "  0.23958835 0.25090221]]\n",
      "verdaderas salidas: [0.7039907]\n",
      "PERDIDAAAA antes: 0.193485826253891\n",
      "Predicción post entrenamiento : [[0.27652916]]\n",
      "PERDIDAAAA despues: 0.18272335827350616\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "[[[0.20664826]\n",
      "  [0.2105726 ]\n",
      "  [0.21580768]\n",
      "  [0.22221269]\n",
      "  [0.23007472]\n",
      "  [0.23958835]\n",
      "  [0.25090221]\n",
      "  [0.26412046]]]\n",
      "ejemplar: [0.20664826 0.2105726  0.21580768 0.22221269 0.23007472 0.23958835\n",
      " 0.25090221 0.26412046]\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.27926603]]\n",
      "Lr que voy a aplicar en el lote: 48 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.20664826 0.2105726  0.21580768 0.22221269 0.23007472 0.23958835\n",
      "  0.25090221 0.26412046]]\n",
      "verdaderas salidas: [0.7272375]\n",
      "PERDIDAAAA antes: 0.20067845284938812\n",
      "Predicción post entrenamiento : [[0.29299578]]\n",
      "PERDIDAAAA despues: 0.18856589496135712\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "[[[0.2105726 ]\n",
      "  [0.21580768]\n",
      "  [0.22221269]\n",
      "  [0.23007472]\n",
      "  [0.23958835]\n",
      "  [0.25090221]\n",
      "  [0.26412046]\n",
      "  [0.27926603]]]\n",
      "ejemplar: [0.2105726  0.21580768 0.22221269 0.23007472 0.23958835 0.25090221\n",
      " 0.26412046 0.27926603]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.2966477]]\n",
      "Lr que voy a aplicar en el lote: 49 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.2105726  0.21580768 0.22221269 0.23007472 0.23958835 0.25090221\n",
      "  0.26412046 0.27926603]]\n",
      "verdaderas salidas: [0.72258814]\n",
      "PERDIDAAAA antes: 0.18142524361610413\n",
      "Predicción post entrenamiento : [[0.311638]]\n",
      "PERDIDAAAA despues: 0.16888000071048737\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "[[[0.21580768]\n",
      "  [0.22221269]\n",
      "  [0.23007472]\n",
      "  [0.23958835]\n",
      "  [0.25090221]\n",
      "  [0.26412046]\n",
      "  [0.27926603]\n",
      "  [0.2966477 ]]]\n",
      "ejemplar: [0.21580768 0.22221269 0.23007472 0.23958835 0.25090221 0.26412046\n",
      " 0.27926603 0.2966477 ]\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.31630197]]\n",
      "Lr que voy a aplicar en el lote: 50 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.21580768 0.22221269 0.23007472 0.23958835 0.25090221 0.26412046\n",
      "  0.27926603 0.2966477 ]]\n",
      "verdaderas salidas: [0.77179388]\n",
      "PERDIDAAAA antes: 0.20747290551662445\n",
      "Predicción post entrenamiento : [[0.3326982]]\n",
      "PERDIDAAAA despues: 0.19280503690242767\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "[[[0.22221269]\n",
      "  [0.23007472]\n",
      "  [0.23958835]\n",
      "  [0.25090221]\n",
      "  [0.26412046]\n",
      "  [0.27926603]\n",
      "  [0.2966477 ]\n",
      "  [0.31630197]]]\n",
      "ejemplar: [0.22221269 0.23007472 0.23958835 0.25090221 0.26412046 0.27926603\n",
      " 0.2966477  0.31630197]\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.3385323]]\n",
      "Lr que voy a aplicar en el lote: 51 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.22221269 0.23007472 0.23958835 0.25090221 0.26412046 0.27926603\n",
      "  0.2966477  0.31630197]]\n",
      "verdaderas salidas: [0.72452538]\n",
      "PERDIDAAAA antes: 0.148990660905838\n",
      "Predicción post entrenamiento : [[0.35635015]]\n",
      "PERDIDAAAA despues: 0.1355530023574829\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "[[[0.23007472]\n",
      "  [0.23958835]\n",
      "  [0.25090221]\n",
      "  [0.26412046]\n",
      "  [0.27926603]\n",
      "  [0.2966477 ]\n",
      "  [0.31630197]\n",
      "  [0.3385323 ]]]\n",
      "ejemplar: [0.23007472 0.23958835 0.25090221 0.26412046 0.27926603 0.2966477\n",
      " 0.31630197 0.3385323 ]\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.36359483]]\n",
      "Lr que voy a aplicar en el lote: 52 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.23007472 0.23958835 0.25090221 0.26412046 0.27926603 0.2966477\n",
      "  0.31630197 0.3385323 ]]\n",
      "verdaderas salidas: [0.67105773]\n",
      "PERDIDAAAA antes: 0.09453341364860535\n",
      "Predicción post entrenamiento : [[0.3826092]]\n",
      "PERDIDAAAA despues: 0.0832025408744812\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "[[[0.23958835]\n",
      "  [0.25090221]\n",
      "  [0.26412046]\n",
      "  [0.27926603]\n",
      "  [0.2966477 ]\n",
      "  [0.31630197]\n",
      "  [0.3385323 ]\n",
      "  [0.36359483]]]\n",
      "ejemplar: [0.23958835 0.25090221 0.26412046 0.27926603 0.2966477  0.31630197\n",
      " 0.3385323  0.36359483]\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.391508]]\n",
      "Lr que voy a aplicar en el lote: 53 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.23958835 0.25090221 0.26412046 0.27926603 0.2966477  0.31630197\n",
      "  0.3385323  0.36359483]]\n",
      "verdaderas salidas: [0.67376986]\n",
      "PERDIDAAAA antes: 0.07967173308134079\n",
      "Predicción post entrenamiento : [[0.41184512]]\n",
      "PERDIDAAAA despues: 0.06860455870628357\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "[[[0.25090221]\n",
      "  [0.26412046]\n",
      "  [0.27926603]\n",
      "  [0.2966477 ]\n",
      "  [0.31630197]\n",
      "  [0.3385323 ]\n",
      "  [0.36359483]\n",
      "  [0.39150801]]]\n",
      "ejemplar: [0.25090221 0.26412046 0.27926603 0.2966477  0.31630197 0.3385323\n",
      " 0.36359483 0.39150801]\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.42266852]]\n",
      "Lr que voy a aplicar en el lote: 54 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.25090221 0.26412046 0.27926603 0.2966477  0.31630197 0.3385323\n",
      "  0.36359483 0.39150801]]\n",
      "verdaderas salidas: [0.71445176]\n",
      "PERDIDAAAA antes: 0.08513747900724411\n",
      "Predicción post entrenamiento : [[0.4444643]]\n",
      "PERDIDAAAA despues: 0.07289324700832367\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "[[[0.26412046]\n",
      "  [0.27926603]\n",
      "  [0.2966477 ]\n",
      "  [0.31630197]\n",
      "  [0.3385323 ]\n",
      "  [0.36359483]\n",
      "  [0.39150801]\n",
      "  [0.42266852]]]\n",
      "ejemplar: [0.26412046 0.27926603 0.2966477  0.31630197 0.3385323  0.36359483\n",
      " 0.39150801 0.42266852]\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.4575268]]\n",
      "Lr que voy a aplicar en el lote: 55 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.26412046 0.27926603 0.2966477  0.31630197 0.3385323  0.36359483\n",
      "  0.39150801 0.42266852]]\n",
      "verdaderas salidas: [0.74389771]\n",
      "PERDIDAAAA antes: 0.08200830966234207\n",
      "Predicción post entrenamiento : [[0.48112157]]\n",
      "PERDIDAAAA despues: 0.06905131042003632\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "[[[0.27926603]\n",
      "  [0.2966477 ]\n",
      "  [0.31630197]\n",
      "  [0.3385323 ]\n",
      "  [0.36359483]\n",
      "  [0.39150801]\n",
      "  [0.42266852]\n",
      "  [0.4575268 ]]]\n",
      "ejemplar: [0.27926603 0.2966477  0.31630197 0.3385323  0.36359483 0.39150801\n",
      " 0.42266852 0.4575268 ]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.49680796]]\n",
      "Lr que voy a aplicar en el lote: 56 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.27926603 0.2966477  0.31630197 0.3385323  0.36359483 0.39150801\n",
      "  0.42266852 0.4575268 ]]\n",
      "verdaderas salidas: [0.72258814]\n",
      "PERDIDAAAA antes: 0.05097667872905731\n",
      "Predicción post entrenamiento : [[0.522463]]\n",
      "PERDIDAAAA despues: 0.04005005583167076\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "[[[0.2966477 ]\n",
      "  [0.31630197]\n",
      "  [0.3385323 ]\n",
      "  [0.36359483]\n",
      "  [0.39150801]\n",
      "  [0.42266852]\n",
      "  [0.4575268 ]\n",
      "  [0.49680796]]]\n",
      "ejemplar: [0.2966477  0.31630197 0.3385323  0.36359483 0.39150801 0.42266852\n",
      " 0.4575268  0.49680796]\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.5412702]]\n",
      "Lr que voy a aplicar en el lote: 57 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.2966477  0.31630197 0.3385323  0.36359483 0.39150801 0.42266852\n",
      "  0.4575268  0.49680796]]\n",
      "verdaderas salidas: [0.69934134]\n",
      "PERDIDAAAA antes: 0.024986492469906807\n",
      "Predicción post entrenamiento : [[0.5682523]]\n",
      "PERDIDAAAA despues: 0.017184333875775337\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "[[[0.31630197]\n",
      "  [0.3385323 ]\n",
      "  [0.36359483]\n",
      "  [0.39150801]\n",
      "  [0.42266852]\n",
      "  [0.4575268 ]\n",
      "  [0.49680796]\n",
      "  [0.5412702 ]]]\n",
      "ejemplar: [0.31630197 0.3385323  0.36359483 0.39150801 0.42266852 0.4575268\n",
      " 0.49680796 0.5412702 ]\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.5907046]]\n",
      "Lr que voy a aplicar en el lote: 58 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.31630197 0.3385323  0.36359483 0.39150801 0.42266852 0.4575268\n",
      "  0.49680796 0.5412702 ]]\n",
      "verdaderas salidas: [0.73731112]\n",
      "PERDIDAAAA antes: 0.021493466570973396\n",
      "Predicción post entrenamiento : [[0.6200206]]\n",
      "PERDIDAAAA despues: 0.013757060281932354\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "[[[0.3385323 ]\n",
      "  [0.36359483]\n",
      "  [0.39150801]\n",
      "  [0.42266852]\n",
      "  [0.4575268 ]\n",
      "  [0.49680796]\n",
      "  [0.5412702 ]\n",
      "  [0.59070462]]]\n",
      "ejemplar: [0.3385323  0.36359483 0.39150801 0.42266852 0.4575268  0.49680796\n",
      " 0.5412702  0.59070462]\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.646834]]\n",
      "Lr que voy a aplicar en el lote: 59 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.3385323  0.36359483 0.39150801 0.42266852 0.4575268  0.49680796\n",
      "  0.5412702  0.59070462]]\n",
      "verdaderas salidas: [0.7214258]\n",
      "PERDIDAAAA antes: 0.005563938990235329\n",
      "Predicción post entrenamiento : [[0.6773598]]\n",
      "PERDIDAAAA despues: 0.001941813388839364\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "[[[0.36359483]\n",
      "  [0.39150801]\n",
      "  [0.42266852]\n",
      "  [0.4575268 ]\n",
      "  [0.49680796]\n",
      "  [0.5412702 ]\n",
      "  [0.59070462]\n",
      "  [0.64683402]]]\n",
      "ejemplar: [0.36359483 0.39150801 0.42266852 0.4575268  0.49680796 0.5412702\n",
      " 0.59070462 0.64683402]\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.7093044]]\n",
      "Lr que voy a aplicar en el lote: 60 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.36359483 0.39150801 0.42266852 0.4575268  0.49680796 0.5412702\n",
      "  0.59070462 0.64683402]]\n",
      "verdaderas salidas: [0.71871368]\n",
      "PERDIDAAAA antes: 8.853508188622072e-05\n",
      "Predicción post entrenamiento : [[0.7411194]]\n",
      "PERDIDAAAA despues: 0.0005020146491006017\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "[[[0.39150801]\n",
      "  [0.42266852]\n",
      "  [0.4575268 ]\n",
      "  [0.49680796]\n",
      "  [0.5412702 ]\n",
      "  [0.59070462]\n",
      "  [0.64683402]\n",
      "  [0.70930439]]]\n",
      "ejemplar: [0.39150801 0.42266852 0.4575268  0.49680796 0.5412702  0.59070462\n",
      " 0.64683402 0.70930439]\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.7791043]]\n",
      "Lr que voy a aplicar en el lote: 61 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.39150801 0.42266852 0.4575268  0.49680796 0.5412702  0.59070462\n",
      "  0.64683402 0.70930439]]\n",
      "verdaderas salidas: [0.6741573]\n",
      "PERDIDAAAA antes: 0.011013866402208805\n",
      "Predicción post entrenamiento : [[0.8047884]]\n",
      "PERDIDAAAA despues: 0.01706448197364807\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "[[[0.42266852]\n",
      "  [0.4575268 ]\n",
      "  [0.49680796]\n",
      "  [0.5412702 ]\n",
      "  [0.59070462]\n",
      "  [0.64683402]\n",
      "  [0.70930439]\n",
      "  [0.77910429]]]\n",
      "ejemplar: [0.42266852 0.4575268  0.49680796 0.5412702  0.59070462 0.64683402\n",
      " 0.70930439 0.77910429]\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.849476]]\n",
      "Lr que voy a aplicar en el lote: 62 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.42266852 0.4575268  0.49680796 0.5412702  0.59070462 0.64683402\n",
      "  0.70930439 0.77910429]]\n",
      "verdaderas salidas: [0.69856645]\n",
      "PERDIDAAAA antes: 0.02277369052171707\n",
      "Predicción post entrenamiento : [[0.8697789]]\n",
      "PERDIDAAAA despues: 0.029313698410987854\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "[[[0.4575268 ]\n",
      "  [0.49680796]\n",
      "  [0.5412702 ]\n",
      "  [0.59070462]\n",
      "  [0.64683402]\n",
      "  [0.70930439]\n",
      "  [0.77910429]\n",
      "  [0.84947598]]]\n",
      "ejemplar: [0.4575268  0.49680796 0.5412702  0.59070462 0.64683402 0.70930439\n",
      " 0.77910429 0.84947598]\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.92183864]]\n",
      "Lr que voy a aplicar en el lote: 63 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.4575268  0.49680796 0.5412702  0.59070462 0.64683402 0.70930439\n",
      "  0.77910429 0.84947598]]\n",
      "verdaderas salidas: [0.72103836]\n",
      "PERDIDAAAA antes: 0.04032076150178909\n",
      "Predicción post entrenamiento : [[0.93023264]]\n",
      "PERDIDAAAA despues: 0.04376225546002388\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "[[[0.49680796]\n",
      "  [0.5412702 ]\n",
      "  [0.59070462]\n",
      "  [0.64683402]\n",
      "  [0.70930439]\n",
      "  [0.77910429]\n",
      "  [0.84947598]\n",
      "  [0.92183864]]]\n",
      "ejemplar: [0.49680796 0.5412702  0.59070462 0.64683402 0.70930439 0.77910429\n",
      " 0.84947598 0.92183864]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.98966366]]\n",
      "Lr que voy a aplicar en el lote: 64 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.49680796 0.5412702  0.59070462 0.64683402 0.70930439 0.77910429\n",
      "  0.84947598 0.92183864]]\n",
      "verdaderas salidas: [0.72258814]\n",
      "PERDIDAAAA antes: 0.07132934033870697\n",
      "Predicción post entrenamiento : [[0.9855218]]\n",
      "PERDIDAAAA despues: 0.06913411617279053\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "[[[0.5412702 ]\n",
      "  [0.59070462]\n",
      "  [0.64683402]\n",
      "  [0.70930439]\n",
      "  [0.77910429]\n",
      "  [0.84947598]\n",
      "  [0.92183864]\n",
      "  [0.98966366]]]\n",
      "ejemplar: [0.5412702  0.59070462 0.64683402 0.70930439 0.77910429 0.84947598\n",
      " 0.92183864 0.98966366]\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[1.051731]]\n",
      "Lr que voy a aplicar en el lote: 65 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.5412702  0.59070462 0.64683402 0.70930439 0.77910429 0.84947598\n",
      "  0.92183864 0.98966366]]\n",
      "verdaderas salidas: [0.75629601]\n",
      "PERDIDAAAA antes: 0.08728180825710297\n",
      "Predicción post entrenamiento : [[1.0405086]]\n",
      "PERDIDAAAA despues: 0.08077679574489594\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "[[[0.59070462]\n",
      "  [0.64683402]\n",
      "  [0.70930439]\n",
      "  [0.77910429]\n",
      "  [0.84947598]\n",
      "  [0.92183864]\n",
      "  [0.98966366]\n",
      "  [1.05173099]]]\n",
      "ejemplar: [0.59070462 0.64683402 0.70930439 0.77910429 0.84947598 0.92183864\n",
      " 0.98966366 1.05173099]\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[1.1126087]]\n",
      "Lr que voy a aplicar en el lote: 66 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.59070462 0.64683402 0.70930439 0.77910429 0.84947598 0.92183864\n",
      "  0.98966366 1.05173099]]\n",
      "verdaderas salidas: [0.82758621]\n",
      "PERDIDAAAA antes: 0.08123779296875\n",
      "Predicción post entrenamiento : [[1.096185]]\n",
      "PERDIDAAAA despues: 0.07214528322219849\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "[[[0.64683402]\n",
      "  [0.70930439]\n",
      "  [0.77910429]\n",
      "  [0.84947598]\n",
      "  [0.92183864]\n",
      "  [0.98966366]\n",
      "  [1.05173099]\n",
      "  [1.11260867]]]\n",
      "ejemplar: [0.64683402 0.70930439 0.77910429 0.84947598 0.92183864 0.98966366\n",
      " 1.05173099 1.11260867]\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[1.1730415]]\n",
      "Lr que voy a aplicar en el lote: 67 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.64683402 0.70930439 0.77910429 0.84947598 0.92183864 0.98966366\n",
      "  1.05173099 1.11260867]]\n",
      "verdaderas salidas: [0.83882216]\n",
      "PERDIDAAAA antes: 0.11170252412557602\n",
      "Predicción post entrenamiento : [[1.1418267]]\n",
      "PERDIDAAAA despues: 0.09181176871061325\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "[[[0.70930439]\n",
      "  [0.77910429]\n",
      "  [0.84947598]\n",
      "  [0.92183864]\n",
      "  [0.98966366]\n",
      "  [1.05173099]\n",
      "  [1.11260867]\n",
      "  [1.17304146]]]\n",
      "ejemplar: [0.70930439 0.77910429 0.84947598 0.92183864 0.98966366 1.05173099\n",
      " 1.11260867 1.17304146]\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[1.2203338]]\n",
      "Lr que voy a aplicar en el lote: 68 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.70930439 0.77910429 0.84947598 0.92183864 0.98966366 1.05173099\n",
      "  1.11260867 1.17304146]]\n",
      "verdaderas salidas: [0.79426579]\n",
      "PERDIDAAAA antes: 0.18153394758701324\n",
      "Predicción post entrenamiento : [[1.1756682]]\n",
      "PERDIDAAAA despues: 0.1454678177833557\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "[[[0.77910429]\n",
      "  [0.84947598]\n",
      "  [0.92183864]\n",
      "  [0.98966366]\n",
      "  [1.05173099]\n",
      "  [1.11260867]\n",
      "  [1.17304146]\n",
      "  [1.22033381]]]\n",
      "ejemplar: [0.77910429 0.84947598 0.92183864 0.98966366 1.05173099 1.11260867\n",
      " 1.17304146 1.22033381]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[1.2524858]]\n",
      "Lr que voy a aplicar en el lote: 69 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.77910429 0.84947598 0.92183864 0.98966366 1.05173099 1.11260867\n",
      "  1.17304146 1.22033381]]\n",
      "verdaderas salidas: [0.78380473]\n",
      "PERDIDAAAA antes: 0.2196619212627411\n",
      "Predicción post entrenamiento : [[1.1917466]]\n",
      "PERDIDAAAA despues: 0.16641657054424286\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "[[[0.84947598]\n",
      "  [0.92183864]\n",
      "  [0.98966366]\n",
      "  [1.05173099]\n",
      "  [1.11260867]\n",
      "  [1.17304146]\n",
      "  [1.22033381]\n",
      "  [1.25248575]]]\n",
      "ejemplar: [0.84947598 0.92183864 0.98966366 1.05173099 1.11260867 1.17304146\n",
      " 1.22033381 1.25248575]\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[1.2626932]]\n",
      "Lr que voy a aplicar en el lote: 70 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.84947598 0.92183864 0.98966366 1.05173099 1.11260867 1.17304146\n",
      "  1.22033381 1.25248575]]\n",
      "verdaderas salidas: [0.76791941]\n",
      "PERDIDAAAA antes: 0.24480105936527252\n",
      "Predicción post entrenamiento : [[1.1915053]]\n",
      "PERDIDAAAA despues: 0.17942500114440918\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "[[[0.92183864]\n",
      "  [0.98966366]\n",
      "  [1.05173099]\n",
      "  [1.11260867]\n",
      "  [1.17304146]\n",
      "  [1.22033381]\n",
      "  [1.25248575]\n",
      "  [1.26269317]]]\n",
      "ejemplar: [0.92183864 0.98966366 1.05173099 1.11260867 1.17304146 1.22033381\n",
      " 1.25248575 1.26269317]\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[1.2549511]]\n",
      "Lr que voy a aplicar en el lote: 71 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.92183864 0.98966366 1.05173099 1.11260867 1.17304146 1.22033381\n",
      "  1.25248575 1.26269317]]\n",
      "verdaderas salidas: [0.78457962]\n",
      "PERDIDAAAA antes: 0.22124932706356049\n",
      "Predicción post entrenamiento : [[1.176269]]\n",
      "PERDIDAAAA despues: 0.1534205973148346\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "[[[0.98966366]\n",
      "  [1.05173099]\n",
      "  [1.11260867]\n",
      "  [1.17304146]\n",
      "  [1.22033381]\n",
      "  [1.25248575]\n",
      "  [1.26269317]\n",
      "  [1.25495112]]]\n",
      "ejemplar: [0.98966366 1.05173099 1.11260867 1.17304146 1.22033381 1.25248575\n",
      " 1.26269317 1.25495112]\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[1.2301114]]\n",
      "Lr que voy a aplicar en el lote: 72 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.98966366 1.05173099 1.11260867 1.17304146 1.22033381 1.25248575\n",
      "  1.26269317 1.25495112]]\n",
      "verdaderas salidas: [0.87872917]\n",
      "PERDIDAAAA antes: 0.12346944957971573\n",
      "Predicción post entrenamiento : [[1.1443983]]\n",
      "PERDIDAAAA despues: 0.07058010995388031\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "[[[1.05173099]\n",
      "  [1.11260867]\n",
      "  [1.17304146]\n",
      "  [1.22033381]\n",
      "  [1.25248575]\n",
      "  [1.26269317]\n",
      "  [1.25495112]\n",
      "  [1.23011136]]]\n",
      "ejemplar: [1.05173099 1.11260867 1.17304146 1.22033381 1.25248575 1.26269317\n",
      " 1.25495112 1.23011136]\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[1.1883738]]\n",
      "Lr que voy a aplicar en el lote: 73 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[1.05173099 1.11260867 1.17304146 1.22033381 1.25248575 1.26269317\n",
      "  1.25495112 1.23011136]]\n",
      "verdaderas salidas: [0.8756296]\n",
      "PERDIDAAAA antes: 0.09780893474817276\n",
      "Predicción post entrenamiento : [[1.1131829]]\n",
      "PERDIDAAAA despues: 0.056431569159030914\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "[[[1.11260867]\n",
      "  [1.17304146]\n",
      "  [1.22033381]\n",
      "  [1.25248575]\n",
      "  [1.26269317]\n",
      "  [1.25495112]\n",
      "  [1.23011136]\n",
      "  [1.1883738 ]]]\n",
      "ejemplar: [1.11260867 1.17304146 1.22033381 1.25248575 1.26269317 1.25495112\n",
      " 1.23011136 1.1883738 ]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[1.1477114]]\n",
      "Lr que voy a aplicar en el lote: 74 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[1.11260867 1.17304146 1.22033381 1.25248575 1.26269317 1.25495112\n",
      "  1.23011136 1.1883738 ]]\n",
      "verdaderas salidas: [0.84889578]\n",
      "PERDIDAAAA antes: 0.08929076790809631\n",
      "Predicción post entrenamiento : [[1.071603]]\n",
      "PERDIDAAAA despues: 0.04959847405552864\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "[[[1.17304146]\n",
      "  [1.22033381]\n",
      "  [1.25248575]\n",
      "  [1.26269317]\n",
      "  [1.25495112]\n",
      "  [1.23011136]\n",
      "  [1.1883738 ]\n",
      "  [1.1477114 ]]]\n",
      "ejemplar: [1.17304146 1.22033381 1.25248575 1.26269317 1.25495112 1.23011136\n",
      " 1.1883738  1.1477114 ]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[1.0951802]]\n",
      "Lr que voy a aplicar en el lote: 75 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[1.17304146 1.22033381 1.25248575 1.26269317 1.25495112 1.23011136\n",
      "  1.1883738  1.1477114 ]]\n",
      "verdaderas salidas: [0.81828749]\n",
      "PERDIDAAAA antes: 0.07666954398155212\n",
      "Predicción post entrenamiento : [[1.02369]]\n",
      "PERDIDAAAA despues: 0.04219018295407295\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "[[[1.22033381]\n",
      "  [1.25248575]\n",
      "  [1.26269317]\n",
      "  [1.25495112]\n",
      "  [1.23011136]\n",
      "  [1.1883738 ]\n",
      "  [1.1477114 ]\n",
      "  [1.09518015]]]\n",
      "ejemplar: [1.22033381 1.25248575 1.26269317 1.25495112 1.23011136 1.1883738\n",
      " 1.1477114  1.09518015]\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[1.0348135]]\n",
      "Lr que voy a aplicar en el lote: 76 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[1.22033381 1.25248575 1.26269317 1.25495112 1.23011136 1.1883738\n",
      "  1.1477114  1.09518015]]\n",
      "verdaderas salidas: [0.82681131]\n",
      "PERDIDAAAA antes: 0.04326491802930832\n",
      "Predicción post entrenamiento : [[0.9652671]]\n",
      "PERDIDAAAA despues: 0.019170010462403297\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "[[[1.25248575]\n",
      "  [1.26269317]\n",
      "  [1.25495112]\n",
      "  [1.23011136]\n",
      "  [1.1883738 ]\n",
      "  [1.1477114 ]\n",
      "  [1.09518015]\n",
      "  [1.03481352]]]\n",
      "ejemplar: [1.25248575 1.26269317 1.25495112 1.23011136 1.1883738  1.1477114\n",
      " 1.09518015 1.03481352]\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.96521485]]\n",
      "Lr que voy a aplicar en el lote: 77 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[1.25248575 1.26269317 1.25495112 1.23011136 1.1883738  1.1477114\n",
      "  1.09518015 1.03481352]]\n",
      "verdaderas salidas: [0.78535451]\n",
      "PERDIDAAAA antes: 0.03234974667429924\n",
      "Predicción post entrenamiento : [[0.90907544]]\n",
      "PERDIDAAAA despues: 0.015306872315704823\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "[[[1.26269317]\n",
      "  [1.25495112]\n",
      "  [1.23011136]\n",
      "  [1.1883738 ]\n",
      "  [1.1477114 ]\n",
      "  [1.09518015]\n",
      "  [1.03481352]\n",
      "  [0.96521485]]]\n",
      "ejemplar: [1.26269317 1.25495112 1.23011136 1.1883738  1.1477114  1.09518015\n",
      " 1.03481352 0.96521485]\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.8994891]]\n",
      "Lr que voy a aplicar en el lote: 78 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[1.26269317 1.25495112 1.23011136 1.1883738  1.1477114  1.09518015\n",
      "  1.03481352 0.96521485]]\n",
      "verdaderas salidas: [0.78922898]\n",
      "PERDIDAAAA antes: 0.01215729583054781\n",
      "Predicción post entrenamiento : [[0.8461791]]\n",
      "PERDIDAAAA despues: 0.0032433196902275085\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "[[[1.25495112]\n",
      "  [1.23011136]\n",
      "  [1.1883738 ]\n",
      "  [1.1477114 ]\n",
      "  [1.09518015]\n",
      "  [1.03481352]\n",
      "  [0.96521485]\n",
      "  [0.8994891 ]]]\n",
      "ejemplar: [1.25495112 1.23011136 1.1883738  1.1477114  1.09518015 1.03481352\n",
      " 0.96521485 0.8994891 ]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.8298929]]\n",
      "Lr que voy a aplicar en el lote: 79 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[1.25495112 1.23011136 1.1883738  1.1477114  1.09518015 1.03481352\n",
      "  0.96521485 0.8994891 ]]\n",
      "verdaderas salidas: [0.8341728]\n",
      "PERDIDAAAA antes: 1.8317643480258994e-05\n",
      "Predicción post entrenamiento : [[0.7865654]]\n",
      "PERDIDAAAA despues: 0.002266461029648781\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "[[[1.23011136]\n",
      "  [1.1883738 ]\n",
      "  [1.1477114 ]\n",
      "  [1.09518015]\n",
      "  [1.03481352]\n",
      "  [0.96521485]\n",
      "  [0.8994891 ]\n",
      "  [0.82989287]]]\n",
      "ejemplar: [1.23011136 1.1883738  1.1477114  1.09518015 1.03481352 0.96521485\n",
      " 0.8994891  0.82989287]\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.7655697]]\n",
      "Lr que voy a aplicar en el lote: 80 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[1.23011136 1.1883738  1.1477114  1.09518015 1.03481352 0.96521485\n",
      "  0.8994891  0.82989287]]\n",
      "verdaderas salidas: [0.81247578]\n",
      "PERDIDAAAA antes: 0.0022001834586262703\n",
      "Predicción post entrenamiento : [[0.72996247]]\n",
      "PERDIDAAAA despues: 0.0068084499798715115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "[[[1.1883738 ]\n",
      "  [1.1477114 ]\n",
      "  [1.09518015]\n",
      "  [1.03481352]\n",
      "  [0.96521485]\n",
      "  [0.8994891 ]\n",
      "  [0.82989287]\n",
      "  [0.76556969]]]\n",
      "ejemplar: [1.1883738  1.1477114  1.09518015 1.03481352 0.96521485 0.8994891\n",
      " 0.82989287 0.76556969]\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.70610315]]\n",
      "Lr que voy a aplicar en el lote: 81 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[1.1883738  1.1477114  1.09518015 1.03481352 0.96521485 0.8994891\n",
      "  0.82989287 0.76556969]]\n",
      "verdaderas salidas: [0.80123983]\n",
      "PERDIDAAAA antes: 0.00905099231749773\n",
      "Predicción post entrenamiento : [[0.676474]]\n",
      "PERDIDAAAA despues: 0.015566523186862469\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "[[[1.1477114 ]\n",
      "  [1.09518015]\n",
      "  [1.03481352]\n",
      "  [0.96521485]\n",
      "  [0.8994891 ]\n",
      "  [0.82989287]\n",
      "  [0.76556969]\n",
      "  [0.70610315]]]\n",
      "ejemplar: [1.1477114  1.09518015 1.03481352 0.96521485 0.8994891  0.82989287\n",
      " 0.76556969 0.70610315]\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.65162385]]\n",
      "Lr que voy a aplicar en el lote: 82 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[1.1477114  1.09518015 1.03481352 0.96521485 0.8994891  0.82989287\n",
      "  0.76556969 0.70610315]]\n",
      "verdaderas salidas: [0.80317706]\n",
      "PERDIDAAAA antes: 0.02296837605535984\n",
      "Predicción post entrenamiento : [[0.6277741]]\n",
      "PERDIDAAAA despues: 0.030766190961003304\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "[[[1.09518015]\n",
      "  [1.03481352]\n",
      "  [0.96521485]\n",
      "  [0.8994891 ]\n",
      "  [0.82989287]\n",
      "  [0.76556969]\n",
      "  [0.70610315]\n",
      "  [0.65162385]]]\n",
      "ejemplar: [1.09518015 1.03481352 0.96521485 0.8994891  0.82989287 0.76556969\n",
      " 0.70610315 0.65162385]\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.60138077]]\n",
      "Lr que voy a aplicar en el lote: 83 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[1.09518015 1.03481352 0.96521485 0.8994891  0.82989287 0.76556969\n",
      "  0.70610315 0.65162385]]\n",
      "verdaderas salidas: [0.7934909]\n",
      "PERDIDAAAA antes: 0.036906298249959946\n",
      "Predicción post entrenamiento : [[0.5830832]]\n",
      "PERDIDAAAA despues: 0.04427139088511467\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "[[[1.03481352]\n",
      "  [0.96521485]\n",
      "  [0.8994891 ]\n",
      "  [0.82989287]\n",
      "  [0.76556969]\n",
      "  [0.70610315]\n",
      "  [0.65162385]\n",
      "  [0.60138077]]]\n",
      "ejemplar: [1.03481352 0.96521485 0.8994891  0.82989287 0.76556969 0.70610315\n",
      " 0.65162385 0.60138077]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.55641055]]\n",
      "Lr que voy a aplicar en el lote: 84 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[1.03481352 0.96521485 0.8994891  0.82989287 0.76556969 0.70610315\n",
      "  0.65162385 0.60138077]]\n",
      "verdaderas salidas: [0.76017048]\n",
      "PERDIDAAAA antes: 0.04151809960603714\n",
      "Predicción post entrenamiento : [[0.54351825]]\n",
      "PERDIDAAAA despues: 0.046938180923461914\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "[[[0.96521485]\n",
      "  [0.8994891 ]\n",
      "  [0.82989287]\n",
      "  [0.76556969]\n",
      "  [0.70610315]\n",
      "  [0.65162385]\n",
      "  [0.60138077]\n",
      "  [0.55641055]]]\n",
      "ejemplar: [0.96521485 0.8994891  0.82989287 0.76556969 0.70610315 0.65162385\n",
      " 0.60138077 0.55641055]\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.51741475]]\n",
      "Lr que voy a aplicar en el lote: 85 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.96521485 0.8994891  0.82989287 0.76556969 0.70610315 0.65162385\n",
      "  0.60138077 0.55641055]]\n",
      "verdaderas salidas: [0.73537389]\n",
      "PERDIDAAAA antes: 0.04750619828701019\n",
      "Predicción post entrenamiento : [[0.5082911]]\n",
      "PERDIDAAAA despues: 0.05156659334897995\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "[[[0.8994891 ]\n",
      "  [0.82989287]\n",
      "  [0.76556969]\n",
      "  [0.70610315]\n",
      "  [0.65162385]\n",
      "  [0.60138077]\n",
      "  [0.55641055]\n",
      "  [0.51741475]]]\n",
      "ejemplar: [0.8994891  0.82989287 0.76556969 0.70610315 0.65162385 0.60138077\n",
      " 0.55641055 0.51741475]\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.4839525]]\n",
      "Lr que voy a aplicar en el lote: 86 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.8994891  0.82989287 0.76556969 0.70610315 0.65162385 0.60138077\n",
      "  0.55641055 0.51741475]]\n",
      "verdaderas salidas: [0.71018985]\n",
      "PERDIDAAAA antes: 0.05118332803249359\n",
      "Predicción post entrenamiento : [[0.47780624]]\n",
      "PERDIDAAAA despues: 0.054002128541469574\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "[[[0.82989287]\n",
      "  [0.76556969]\n",
      "  [0.70610315]\n",
      "  [0.65162385]\n",
      "  [0.60138077]\n",
      "  [0.55641055]\n",
      "  [0.51741475]\n",
      "  [0.48395249]]]\n",
      "ejemplar: [0.82989287 0.76556969 0.70610315 0.65162385 0.60138077 0.55641055\n",
      " 0.51741475 0.48395249]\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.45501816]]\n",
      "Lr que voy a aplicar en el lote: 87 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.82989287 0.76556969 0.70610315 0.65162385 0.60138077 0.55641055\n",
      "  0.51741475 0.48395249]]\n",
      "verdaderas salidas: [0.71212708]\n",
      "PERDIDAAAA antes: 0.06610500067472458\n",
      "Predicción post entrenamiento : [[0.45148188]]\n",
      "PERDIDAAAA despues: 0.06793592870235443\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "[[[0.76556969]\n",
      "  [0.70610315]\n",
      "  [0.65162385]\n",
      "  [0.60138077]\n",
      "  [0.55641055]\n",
      "  [0.51741475]\n",
      "  [0.48395249]\n",
      "  [0.45501816]]]\n",
      "ejemplar: [0.76556969 0.70610315 0.65162385 0.60138077 0.55641055 0.51741475\n",
      " 0.48395249 0.45501816]\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.43098697]]\n",
      "Lr que voy a aplicar en el lote: 88 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.76556969 0.70610315 0.65162385 0.60138077 0.55641055 0.51741475\n",
      "  0.48395249 0.45501816]]\n",
      "verdaderas salidas: [0.7396358]\n",
      "PERDIDAAAA antes: 0.09526411443948746\n",
      "Predicción post entrenamiento : [[0.4297448]]\n",
      "PERDIDAAAA despues: 0.09603244066238403\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "[[[0.70610315]\n",
      "  [0.65162385]\n",
      "  [0.60138077]\n",
      "  [0.55641055]\n",
      "  [0.51741475]\n",
      "  [0.48395249]\n",
      "  [0.45501816]\n",
      "  [0.43098697]]]\n",
      "ejemplar: [0.70610315 0.65162385 0.60138077 0.55641055 0.51741475 0.48395249\n",
      " 0.45501816 0.43098697]\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.4113463]]\n",
      "Lr que voy a aplicar en el lote: 89 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.70610315 0.65162385 0.60138077 0.55641055 0.51741475 0.48395249\n",
      "  0.45501816 0.43098697]]\n",
      "verdaderas salidas: [0.73614878]\n",
      "PERDIDAAAA antes: 0.10549665987491608\n",
      "Predicción post entrenamiento : [[0.41191727]]\n",
      "PERDIDAAAA despues: 0.10512606799602509\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "[[[0.65162385]\n",
      "  [0.60138077]\n",
      "  [0.55641055]\n",
      "  [0.51741475]\n",
      "  [0.48395249]\n",
      "  [0.45501816]\n",
      "  [0.43098697]\n",
      "  [0.41134629]]]\n",
      "ejemplar: [0.65162385 0.60138077 0.55641055 0.51741475 0.48395249 0.45501816\n",
      " 0.43098697 0.41134629]\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.3955032]]\n",
      "Lr que voy a aplicar en el lote: 90 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.65162385 0.60138077 0.55641055 0.51741475 0.48395249 0.45501816\n",
      "  0.43098697 0.41134629]]\n",
      "verdaderas salidas: [0.66757071]\n",
      "PERDIDAAAA antes: 0.07402073591947556\n",
      "Predicción post entrenamiento : [[0.39731833]]\n",
      "PERDIDAAAA despues: 0.07303635030984879\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "[[[0.60138077]\n",
      "  [0.55641055]\n",
      "  [0.51741475]\n",
      "  [0.48395249]\n",
      "  [0.45501816]\n",
      "  [0.43098697]\n",
      "  [0.41134629]\n",
      "  [0.39550319]]]\n",
      "ejemplar: [0.60138077 0.55641055 0.51741475 0.48395249 0.45501816 0.43098697\n",
      " 0.41134629 0.39550319]\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.38280508]]\n",
      "Lr que voy a aplicar en el lote: 91 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.60138077 0.55641055 0.51741475 0.48395249 0.45501816 0.43098697\n",
      "  0.41134629 0.39550319]]\n",
      "verdaderas salidas: [0.66989539]\n",
      "PERDIDAAAA antes: 0.08242085576057434\n",
      "Predicción post entrenamiento : [[0.3854738]]\n",
      "PERDIDAAAA despues: 0.08089566230773926\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "[[[0.55641055]\n",
      "  [0.51741475]\n",
      "  [0.48395249]\n",
      "  [0.45501816]\n",
      "  [0.43098697]\n",
      "  [0.41134629]\n",
      "  [0.39550319]\n",
      "  [0.38280508]]]\n",
      "ejemplar: [0.55641055 0.51741475 0.48395249 0.45501816 0.43098697 0.41134629\n",
      " 0.39550319 0.38280508]\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.37287894]]\n",
      "Lr que voy a aplicar en el lote: 92 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.55641055 0.51741475 0.48395249 0.45501816 0.43098697 0.41134629\n",
      "  0.39550319 0.38280508]]\n",
      "verdaderas salidas: [0.69662921]\n",
      "PERDIDAAAA antes: 0.10481424629688263\n",
      "Predicción post entrenamiento : [[0.3765227]]\n",
      "PERDIDAAAA despues: 0.10246819257736206\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "[[[0.51741475]\n",
      "  [0.48395249]\n",
      "  [0.45501816]\n",
      "  [0.43098697]\n",
      "  [0.41134629]\n",
      "  [0.39550319]\n",
      "  [0.38280508]\n",
      "  [0.37287894]]]\n",
      "ejemplar: [0.51741475 0.48395249 0.45501816 0.43098697 0.41134629 0.39550319\n",
      " 0.38280508 0.37287894]\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.36574936]]\n",
      "Lr que voy a aplicar en el lote: 93 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.51741475 0.48395249 0.45501816 0.43098697 0.41134629 0.39550319\n",
      "  0.38280508 0.37287894]]\n",
      "verdaderas salidas: [0.65594731]\n",
      "PERDIDAAAA antes: 0.08421485871076584\n",
      "Predicción post entrenamiento : [[0.370075]]\n",
      "PERDIDAAAA despues: 0.08172299712896347\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "[[[0.48395249]\n",
      "  [0.45501816]\n",
      "  [0.43098697]\n",
      "  [0.41134629]\n",
      "  [0.39550319]\n",
      "  [0.38280508]\n",
      "  [0.37287894]\n",
      "  [0.36574936]]]\n",
      "ejemplar: [0.48395249 0.45501816 0.43098697 0.41134629 0.39550319 0.38280508\n",
      " 0.37287894 0.36574936]\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.36093822]]\n",
      "Lr que voy a aplicar en el lote: 94 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.48395249 0.45501816 0.43098697 0.41134629 0.39550319 0.38280508\n",
      "  0.37287894 0.36574936]]\n",
      "verdaderas salidas: [0.67880666]\n",
      "PERDIDAAAA antes: 0.10104034841060638\n",
      "Predicción post entrenamiento : [[0.3659552]]\n",
      "PERDIDAAAA despues: 0.09787603467702866\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "[[[0.45501816]\n",
      "  [0.43098697]\n",
      "  [0.41134629]\n",
      "  [0.39550319]\n",
      "  [0.38280508]\n",
      "  [0.37287894]\n",
      "  [0.36574936]\n",
      "  [0.36093822]]]\n",
      "ejemplar: [0.45501816 0.43098697 0.41134629 0.39550319 0.38280508 0.37287894\n",
      " 0.36574936 0.36093822]\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.3582854]]\n",
      "Lr que voy a aplicar en el lote: 95 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.45501816 0.43098697 0.41134629 0.39550319 0.38280508 0.37287894\n",
      "  0.36574936 0.36093822]]\n",
      "verdaderas salidas: [0.67609454]\n",
      "PERDIDAAAA antes: 0.10100264847278595\n",
      "Predicción post entrenamiento : [[0.363891]]\n",
      "PERDIDAAAA despues: 0.09747104346752167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "[[[0.43098697]\n",
      "  [0.41134629]\n",
      "  [0.39550319]\n",
      "  [0.38280508]\n",
      "  [0.37287894]\n",
      "  [0.36574936]\n",
      "  [0.36093822]\n",
      "  [0.3582854 ]]]\n",
      "ejemplar: [0.43098697 0.41134629 0.39550319 0.38280508 0.37287894 0.36574936\n",
      " 0.36093822 0.3582854 ]\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.3575989]]\n",
      "Lr que voy a aplicar en el lote: 96 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.43098697 0.41134629 0.39550319 0.38280508 0.37287894 0.36574936\n",
      "  0.36093822 0.3582854 ]]\n",
      "verdaderas salidas: [0.72956219]\n",
      "PERDIDAAAA antes: 0.13835667073726654\n",
      "Predicción post entrenamiento : [[0.36391938]]\n",
      "PERDIDAAAA despues: 0.13369464874267578\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "[[[0.41134629]\n",
      "  [0.39550319]\n",
      "  [0.38280508]\n",
      "  [0.37287894]\n",
      "  [0.36574936]\n",
      "  [0.36093822]\n",
      "  [0.3582854 ]\n",
      "  [0.3575989 ]]]\n",
      "ejemplar: [0.41134629 0.39550319 0.38280508 0.37287894 0.36574936 0.36093822\n",
      " 0.3582854  0.3575989 ]\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.35884154]]\n",
      "Lr que voy a aplicar en el lote: 97 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.41134629 0.39550319 0.38280508 0.37287894 0.36574936 0.36093822\n",
      "  0.3582854  0.3575989 ]]\n",
      "verdaderas salidas: [0.70127857]\n",
      "PERDIDAAAA antes: 0.11726311594247818\n",
      "Predicción post entrenamiento : [[0.36571425]]\n",
      "PERDIDAAAA despues: 0.11260341107845306\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "[[[0.39550319]\n",
      "  [0.38280508]\n",
      "  [0.37287894]\n",
      "  [0.36574936]\n",
      "  [0.36093822]\n",
      "  [0.3582854 ]\n",
      "  [0.3575989 ]\n",
      "  [0.35884154]]]\n",
      "ejemplar: [0.39550319 0.38280508 0.37287894 0.36574936 0.36093822 0.3582854\n",
      " 0.3575989  0.35884154]\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.3617087]]\n",
      "Lr que voy a aplicar en el lote: 98 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.39550319 0.38280508 0.37287894 0.36574936 0.36093822 0.3582854\n",
      "  0.3575989  0.35884154]]\n",
      "verdaderas salidas: [0.76753196]\n",
      "PERDIDAAAA antes: 0.16469253599643707\n",
      "Predicción post entrenamiento : [[0.3693239]]\n",
      "PERDIDAAAA despues: 0.15856967866420746\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "[[[0.38280508]\n",
      "  [0.37287894]\n",
      "  [0.36574936]\n",
      "  [0.36093822]\n",
      "  [0.3582854 ]\n",
      "  [0.3575989 ]\n",
      "  [0.35884154]\n",
      "  [0.3617087 ]]]\n",
      "ejemplar: [0.38280508 0.37287894 0.36574936 0.36093822 0.3582854  0.3575989\n",
      " 0.35884154 0.3617087 ]\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.3662784]]\n",
      "Lr que voy a aplicar en el lote: 99 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.38280508 0.37287894 0.36574936 0.36093822 0.3582854  0.3575989\n",
      "  0.35884154 0.3617087 ]]\n",
      "verdaderas salidas: [0.75513367]\n",
      "PERDIDAAAA antes: 0.15120843052864075\n",
      "Predicción post entrenamiento : [[0.37452787]]\n",
      "PERDIDAAAA despues: 0.14486078917980194\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "[[[0.37287894]\n",
      "  [0.36574936]\n",
      "  [0.36093822]\n",
      "  [0.3582854 ]\n",
      "  [0.3575989 ]\n",
      "  [0.35884154]\n",
      "  [0.3617087 ]\n",
      "  [0.36627841]]]\n",
      "ejemplar: [0.37287894 0.36574936 0.36093822 0.3582854  0.3575989  0.35884154\n",
      " 0.3617087  0.36627841]\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.37238026]]\n",
      "Lr que voy a aplicar en el lote: 100 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.37287894 0.36574936 0.36093822 0.3582854  0.3575989  0.35884154\n",
      "  0.3617087  0.36627841]]\n",
      "verdaderas salidas: [0.74506005]\n",
      "PERDIDAAAA antes: 0.13889020681381226\n",
      "Predicción post entrenamiento : [[0.38122183]]\n",
      "PERDIDAAAA despues: 0.1323782354593277\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "[[[0.36574936]\n",
      "  [0.36093822]\n",
      "  [0.3582854 ]\n",
      "  [0.3575989 ]\n",
      "  [0.35884154]\n",
      "  [0.3617087 ]\n",
      "  [0.36627841]\n",
      "  [0.37238026]]]\n",
      "ejemplar: [0.36574936 0.36093822 0.3582854  0.3575989  0.35884154 0.3617087\n",
      " 0.36627841 0.37238026]\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.3799331]]\n",
      "Lr que voy a aplicar en el lote: 101 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.36574936 0.36093822 0.3582854  0.3575989  0.35884154 0.3617087\n",
      "  0.36627841 0.37238026]]\n",
      "verdaderas salidas: [0.7520341]\n",
      "PERDIDAAAA antes: 0.13845914602279663\n",
      "Predicción post entrenamiento : [[0.389379]]\n",
      "PERDIDAAAA despues: 0.13151870667934418\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "[[[0.36093822]\n",
      "  [0.3582854 ]\n",
      "  [0.3575989 ]\n",
      "  [0.35884154]\n",
      "  [0.3617087 ]\n",
      "  [0.36627841]\n",
      "  [0.37238026]\n",
      "  [0.37993309]]]\n",
      "ejemplar: [0.36093822 0.3582854  0.3575989  0.35884154 0.3617087  0.36627841\n",
      " 0.37238026 0.37993309]\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.388887]]\n",
      "Lr que voy a aplicar en el lote: 102 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.36093822 0.3582854  0.3575989  0.35884154 0.3617087  0.36627841\n",
      "  0.37238026 0.37993309]]\n",
      "verdaderas salidas: [0.7098024]\n",
      "PERDIDAAAA antes: 0.10298669338226318\n",
      "Predicción post entrenamiento : [[0.39878514]]\n",
      "PERDIDAAAA despues: 0.09673172980546951\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "[[[0.3582854 ]\n",
      "  [0.3575989 ]\n",
      "  [0.35884154]\n",
      "  [0.3617087 ]\n",
      "  [0.36627841]\n",
      "  [0.37238026]\n",
      "  [0.37993309]\n",
      "  [0.38888699]]]\n",
      "ejemplar: [0.3582854  0.3575989  0.35884154 0.3617087  0.36627841 0.37238026\n",
      " 0.37993309 0.38888699]\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.3990659]]\n",
      "Lr que voy a aplicar en el lote: 103 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.3582854  0.3575989  0.35884154 0.3617087  0.36627841 0.37238026\n",
      "  0.37993309 0.38888699]]\n",
      "verdaderas salidas: [0.69043007]\n",
      "PERDIDAAAA antes: 0.08489305526018143\n",
      "Predicción post entrenamiento : [[0.40927395]]\n",
      "PERDIDAAAA despues: 0.07904874533414841\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "[[[0.3575989 ]\n",
      "  [0.35884154]\n",
      "  [0.3617087 ]\n",
      "  [0.36627841]\n",
      "  [0.37238026]\n",
      "  [0.37993309]\n",
      "  [0.38888699]\n",
      "  [0.39906591]]]\n",
      "ejemplar: [0.3575989  0.35884154 0.3617087  0.36627841 0.37238026 0.37993309\n",
      " 0.38888699 0.39906591]\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.41030782]]\n",
      "Lr que voy a aplicar en el lote: 104 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.3575989  0.35884154 0.3617087  0.36627841 0.37238026 0.37993309\n",
      "  0.38888699 0.39906591]]\n",
      "verdaderas salidas: [0.75435878]\n",
      "PERDIDAAAA antes: 0.11837105453014374\n",
      "Predicción post entrenamiento : [[0.4210843]]\n",
      "PERDIDAAAA despues: 0.1110718622803688\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "[[[0.35884154]\n",
      "  [0.3617087 ]\n",
      "  [0.36627841]\n",
      "  [0.37238026]\n",
      "  [0.37993309]\n",
      "  [0.38888699]\n",
      "  [0.39906591]\n",
      "  [0.41030782]]]\n",
      "ejemplar: [0.35884154 0.3617087  0.36627841 0.37238026 0.37993309 0.38888699\n",
      " 0.39906591 0.41030782]\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.42286187]]\n",
      "Lr que voy a aplicar en el lote: 105 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.35884154 0.3617087  0.36627841 0.37238026 0.37993309 0.38888699\n",
      "  0.39906591 0.41030782]]\n",
      "verdaderas salidas: [0.7222007]\n",
      "PERDIDAAAA antes: 0.0896037295460701\n",
      "Predicción post entrenamiento : [[0.43407637]]\n",
      "PERDIDAAAA despues: 0.08301562815904617\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "[[[0.3617087 ]\n",
      "  [0.36627841]\n",
      "  [0.37238026]\n",
      "  [0.37993309]\n",
      "  [0.38888699]\n",
      "  [0.39906591]\n",
      "  [0.41030782]\n",
      "  [0.42286187]]]\n",
      "ejemplar: [0.3617087  0.36627841 0.37238026 0.37993309 0.38888699 0.39906591\n",
      " 0.41030782 0.42286187]\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.43657905]]\n",
      "Lr que voy a aplicar en el lote: 106 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.3617087  0.36627841 0.37238026 0.37993309 0.38888699 0.39906591\n",
      "  0.41030782 0.42286187]]\n",
      "verdaderas salidas: [0.84850833]\n",
      "PERDIDAAAA antes: 0.1696857511997223\n",
      "Predicción post entrenamiento : [[0.44875154]]\n",
      "PERDIDAAAA despues: 0.1598055213689804\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "[[[0.36627841]\n",
      "  [0.37238026]\n",
      "  [0.37993309]\n",
      "  [0.38888699]\n",
      "  [0.39906591]\n",
      "  [0.41030782]\n",
      "  [0.42286187]\n",
      "  [0.43657905]]]\n",
      "ejemplar: [0.36627841 0.37238026 0.37993309 0.38888699 0.39906591 0.41030782\n",
      " 0.42286187 0.43657905]\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.45199302]]\n",
      "Lr que voy a aplicar en el lote: 107 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.36627841 0.37238026 0.37993309 0.38888699 0.39906591 0.41030782\n",
      "  0.42286187 0.43657905]]\n",
      "verdaderas salidas: [0.905463]\n",
      "PERDIDAAAA antes: 0.20563501119613647\n",
      "Predicción post entrenamiento : [[0.4653564]]\n",
      "PERDIDAAAA despues: 0.19369378685951233\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "[[[0.37238026]\n",
      "  [0.37993309]\n",
      "  [0.38888699]\n",
      "  [0.39906591]\n",
      "  [0.41030782]\n",
      "  [0.42286187]\n",
      "  [0.43657905]\n",
      "  [0.45199302]]]\n",
      "ejemplar: [0.37238026 0.37993309 0.38888699 0.39906591 0.41030782 0.42286187\n",
      " 0.43657905 0.45199302]\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.46933421]]\n",
      "Lr que voy a aplicar en el lote: 108 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.37238026 0.37993309 0.38888699 0.39906591 0.41030782 0.42286187\n",
      "  0.43657905 0.45199302]]\n",
      "verdaderas salidas: [0.8822162]\n",
      "PERDIDAAAA antes: 0.17047154903411865\n",
      "Predicción post entrenamiento : [[0.4837674]]\n",
      "PERDIDAAAA despues: 0.15876147150993347\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "[[[0.37993309]\n",
      "  [0.38888699]\n",
      "  [0.39906591]\n",
      "  [0.41030782]\n",
      "  [0.42286187]\n",
      "  [0.43657905]\n",
      "  [0.45199302]\n",
      "  [0.46933421]]]\n",
      "ejemplar: [0.37993309 0.38888699 0.39906591 0.41030782 0.42286187 0.43657905\n",
      " 0.45199302 0.46933421]\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.48849994]]\n",
      "Lr que voy a aplicar en el lote: 109 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.37993309 0.38888699 0.39906591 0.41030782 0.42286187 0.43657905\n",
      "  0.45199302 0.46933421]]\n",
      "verdaderas salidas: [0.90778768]\n",
      "PERDIDAAAA antes: 0.17580221593379974\n",
      "Predicción post entrenamiento : [[0.5041726]]\n",
      "PERDIDAAAA despues: 0.16290511190891266\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "[[[0.38888699]\n",
      "  [0.39906591]\n",
      "  [0.41030782]\n",
      "  [0.42286187]\n",
      "  [0.43657905]\n",
      "  [0.45199302]\n",
      "  [0.46933421]\n",
      "  [0.48849994]]]\n",
      "ejemplar: [0.38888699 0.39906591 0.41030782 0.42286187 0.43657905 0.45199302\n",
      " 0.46933421 0.48849994]\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.5096942]]\n",
      "Lr que voy a aplicar en el lote: 110 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.38888699 0.39906591 0.41030782 0.42286187 0.43657905 0.45199302\n",
      "  0.46933421 0.48849994]]\n",
      "verdaderas salidas: [0.88957768]\n",
      "PERDIDAAAA antes: 0.14431144297122955\n",
      "Predicción post entrenamiento : [[0.52645105]]\n",
      "PERDIDAAAA despues: 0.13186095654964447\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "[[[0.39906591]\n",
      "  [0.41030782]\n",
      "  [0.42286187]\n",
      "  [0.43657905]\n",
      "  [0.45199302]\n",
      "  [0.46933421]\n",
      "  [0.48849994]\n",
      "  [0.50969422]]]\n",
      "ejemplar: [0.39906591 0.41030782 0.42286187 0.43657905 0.45199302 0.46933421\n",
      " 0.48849994 0.50969422]\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.5328112]]\n",
      "Lr que voy a aplicar en el lote: 111 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.39906591 0.41030782 0.42286187 0.43657905 0.45199302 0.46933421\n",
      "  0.48849994 0.50969422]]\n",
      "verdaderas salidas: [0.87485471]\n",
      "PERDIDAAAA antes: 0.1169937252998352\n",
      "Predicción post entrenamiento : [[0.5504697]]\n",
      "PERDIDAAAA despues: 0.10522562265396118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "[[[0.41030782]\n",
      "  [0.42286187]\n",
      "  [0.43657905]\n",
      "  [0.45199302]\n",
      "  [0.46933421]\n",
      "  [0.48849994]\n",
      "  [0.50969422]\n",
      "  [0.53281122]]]\n",
      "ejemplar: [0.41030782 0.42286187 0.43657905 0.45199302 0.46933421 0.48849994\n",
      " 0.50969422 0.53281122]\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.5577614]]\n",
      "Lr que voy a aplicar en el lote: 112 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.41030782 0.42286187 0.43657905 0.45199302 0.46933421 0.48849994\n",
      "  0.50969422 0.53281122]]\n",
      "verdaderas salidas: [0.91321193]\n",
      "PERDIDAAAA antes: 0.12634511291980743\n",
      "Predicción post entrenamiento : [[0.576723]]\n",
      "PERDIDAAAA despues: 0.1132248193025589\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "[[[0.42286187]\n",
      "  [0.43657905]\n",
      "  [0.45199302]\n",
      "  [0.46933421]\n",
      "  [0.48849994]\n",
      "  [0.50969422]\n",
      "  [0.53281122]\n",
      "  [0.55776137]]]\n",
      "ejemplar: [0.42286187 0.43657905 0.45199302 0.46933421 0.48849994 0.50969422\n",
      " 0.53281122 0.55776137]\n",
      "y: 1.0\n",
      "Predicción : [[0.585099]]\n",
      "Lr que voy a aplicar en el lote: 113 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.42286187 0.43657905 0.45199302 0.46933421 0.48849994 0.50969422\n",
      "  0.53281122 0.55776137]]\n",
      "verdaderas salidas: [1.]\n",
      "PERDIDAAAA antes: 0.1721428483724594\n",
      "Predicción post entrenamiento : [[0.605912]]\n",
      "PERDIDAAAA despues: 0.15530532598495483\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "[[[0.43657905]\n",
      "  [0.45199302]\n",
      "  [0.46933421]\n",
      "  [0.48849994]\n",
      "  [0.50969422]\n",
      "  [0.53281122]\n",
      "  [0.55776137]\n",
      "  [0.58509898]]]\n",
      "ejemplar: [0.43657905 0.45199302 0.46933421 0.48849994 0.50969422 0.53281122\n",
      " 0.55776137 0.58509898]\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.61552685]]\n",
      "Lr que voy a aplicar en el lote: 114 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.43657905 0.45199302 0.46933421 0.48849994 0.50969422 0.53281122\n",
      "  0.55776137 0.58509898]]\n",
      "verdaderas salidas: [0.97055405]\n",
      "PERDIDAAAA antes: 0.12604431807994843\n",
      "Predicción post entrenamiento : [[0.637789]]\n",
      "PERDIDAAAA despues: 0.11073257029056549\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "[[[0.45199302]\n",
      "  [0.46933421]\n",
      "  [0.48849994]\n",
      "  [0.50969422]\n",
      "  [0.53281122]\n",
      "  [0.55776137]\n",
      "  [0.58509898]\n",
      "  [0.61552685]]]\n",
      "ejemplar: [0.45199302 0.46933421 0.48849994 0.50969422 0.53281122 0.55776137\n",
      " 0.58509898 0.61552685]\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.64886236]]\n",
      "Lr que voy a aplicar en el lote: 115 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.45199302 0.46933421 0.48849994 0.50969422 0.53281122 0.55776137\n",
      "  0.58509898 0.61552685]]\n",
      "verdaderas salidas: [0.88880279]\n",
      "PERDIDAAAA antes: 0.057571396231651306\n",
      "Predicción post entrenamiento : [[0.67228556]]\n",
      "PERDIDAAAA despues: 0.04687970131635666\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "[[[0.46933421]\n",
      "  [0.48849994]\n",
      "  [0.50969422]\n",
      "  [0.53281122]\n",
      "  [0.55776137]\n",
      "  [0.58509898]\n",
      "  [0.61552685]\n",
      "  [0.64886236]]]\n",
      "ejemplar: [0.46933421 0.48849994 0.50969422 0.53281122 0.55776137 0.58509898\n",
      " 0.61552685 0.64886236]\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.68497777]]\n",
      "Lr que voy a aplicar en el lote: 116 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.46933421 0.48849994 0.50969422 0.53281122 0.55776137 0.58509898\n",
      "  0.61552685 0.64886236]]\n",
      "verdaderas salidas: [0.87795428]\n",
      "PERDIDAAAA antes: 0.03723994269967079\n",
      "Predicción post entrenamiento : [[0.70820653]]\n",
      "PERDIDAAAA despues: 0.028814304620027542\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "[[[0.48849994]\n",
      "  [0.50969422]\n",
      "  [0.53281122]\n",
      "  [0.55776137]\n",
      "  [0.58509898]\n",
      "  [0.61552685]\n",
      "  [0.64886236]\n",
      "  [0.68497777]]]\n",
      "ejemplar: [0.48849994 0.50969422 0.53281122 0.55776137 0.58509898 0.61552685\n",
      " 0.64886236 0.68497777]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.72263575]]\n",
      "Lr que voy a aplicar en el lote: 117 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.48849994 0.50969422 0.53281122 0.55776137 0.58509898 0.61552685\n",
      "  0.64886236 0.68497777]]\n",
      "verdaderas salidas: [0.84889578]\n",
      "PERDIDAAAA antes: 0.015941597521305084\n",
      "Predicción post entrenamiento : [[0.74593264]]\n",
      "PERDIDAAAA despues: 0.010601409710943699\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "[[[0.50969422]\n",
      "  [0.53281122]\n",
      "  [0.55776137]\n",
      "  [0.58509898]\n",
      "  [0.61552685]\n",
      "  [0.64886236]\n",
      "  [0.68497777]\n",
      "  [0.72263575]]]\n",
      "ejemplar: [0.50969422 0.53281122 0.55776137 0.58509898 0.61552685 0.64886236\n",
      " 0.68497777 0.72263575]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.76226497]]\n",
      "Lr que voy a aplicar en el lote: 118 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.50969422 0.53281122 0.55776137 0.58509898 0.61552685 0.64886236\n",
      "  0.68497777 0.72263575]]\n",
      "verdaderas salidas: [0.8341728]\n",
      "PERDIDAAAA antes: 0.005170734133571386\n",
      "Predicción post entrenamiento : [[0.7853419]]\n",
      "PERDIDAAAA despues: 0.002384453546255827\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "[[[0.53281122]\n",
      "  [0.55776137]\n",
      "  [0.58509898]\n",
      "  [0.61552685]\n",
      "  [0.64886236]\n",
      "  [0.68497777]\n",
      "  [0.72263575]\n",
      "  [0.76226497]]]\n",
      "ejemplar: [0.53281122 0.55776137 0.58509898 0.61552685 0.64886236 0.68497777\n",
      " 0.72263575 0.76226497]\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.80371433]]\n",
      "Lr que voy a aplicar en el lote: 119 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.53281122 0.55776137 0.58509898 0.61552685 0.64886236 0.68497777\n",
      "  0.72263575 0.76226497]]\n",
      "verdaderas salidas: [0.85509492]\n",
      "PERDIDAAAA antes: 0.002639963524416089\n",
      "Predicción post entrenamiento : [[0.8240126]]\n",
      "PERDIDAAAA despues: 0.0009661113726906478\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "[[[0.55776137]\n",
      "  [0.58509898]\n",
      "  [0.61552685]\n",
      "  [0.64886236]\n",
      "  [0.68497777]\n",
      "  [0.72263575]\n",
      "  [0.76226497]\n",
      "  [0.80371433]]]\n",
      "ejemplar: [0.55776137 0.58509898 0.61552685 0.64886236 0.68497777 0.72263575\n",
      " 0.76226497 0.80371433]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.8445252]]\n",
      "Lr que voy a aplicar en el lote: 120 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.55776137 0.58509898 0.61552685 0.64886236 0.68497777 0.72263575\n",
      "  0.76226497 0.80371433]]\n",
      "verdaderas salidas: [0.87524215]\n",
      "PERDIDAAAA antes: 0.0009435313404537737\n",
      "Predicción post entrenamiento : [[0.86347777]]\n",
      "PERDIDAAAA despues: 0.00013840127212461084\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "[[[0.58509898]\n",
      "  [0.61552685]\n",
      "  [0.64886236]\n",
      "  [0.68497777]\n",
      "  [0.72263575]\n",
      "  [0.76226497]\n",
      "  [0.80371433]\n",
      "  [0.84452522]]]\n",
      "ejemplar: [0.58509898 0.61552685 0.64886236 0.68497777 0.72263575 0.76226497\n",
      " 0.80371433 0.84452522]\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.88628083]]\n",
      "Lr que voy a aplicar en el lote: 121 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.58509898 0.61552685 0.64886236 0.68497777 0.72263575 0.76226497\n",
      "  0.80371433 0.84452522]]\n",
      "verdaderas salidas: [0.85703216]\n",
      "PERDIDAAAA antes: 0.0008554838132113218\n",
      "Predicción post entrenamiento : [[0.9061718]]\n",
      "PERDIDAAAA despues: 0.0024147022049874067\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "[[[0.61552685]\n",
      "  [0.64886236]\n",
      "  [0.68497777]\n",
      "  [0.72263575]\n",
      "  [0.76226497]\n",
      "  [0.80371433]\n",
      "  [0.84452522]\n",
      "  [0.88628083]]]\n",
      "ejemplar: [0.61552685 0.64886236 0.68497777 0.72263575 0.76226497 0.80371433\n",
      " 0.84452522 0.88628083]\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.9313267]]\n",
      "Lr que voy a aplicar en el lote: 122 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.61552685 0.64886236 0.68497777 0.72263575 0.76226497 0.80371433\n",
      "  0.84452522 0.88628083]]\n",
      "verdaderas salidas: [0.85005812]\n",
      "PERDIDAAAA antes: 0.006604576949030161\n",
      "Predicción post entrenamiento : [[0.9486119]]\n",
      "PERDIDAAAA despues: 0.00971284694969654\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "[[[0.64886236]\n",
      "  [0.68497777]\n",
      "  [0.72263575]\n",
      "  [0.76226497]\n",
      "  [0.80371433]\n",
      "  [0.84452522]\n",
      "  [0.88628083]\n",
      "  [0.93132669]]]\n",
      "ejemplar: [0.64886236 0.68497777 0.72263575 0.76226497 0.80371433 0.84452522\n",
      " 0.88628083 0.93132669]\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.9758354]]\n",
      "Lr que voy a aplicar en el lote: 123 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.64886236 0.68497777 0.72263575 0.76226497 0.80371433 0.84452522\n",
      "  0.88628083 0.93132669]]\n",
      "verdaderas salidas: [0.84269663]\n",
      "PERDIDAAAA antes: 0.017725933343172073\n",
      "Predicción post entrenamiento : [[0.98752815]]\n",
      "PERDIDAAAA despues: 0.020976174622774124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "[[[0.68497777]\n",
      "  [0.72263575]\n",
      "  [0.76226497]\n",
      "  [0.80371433]\n",
      "  [0.84452522]\n",
      "  [0.88628083]\n",
      "  [0.93132669]\n",
      "  [0.97583538]]]\n",
      "ejemplar: [0.68497777 0.72263575 0.76226497 0.80371433 0.84452522 0.88628083\n",
      " 0.93132669 0.97583538]\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[1.0163662]]\n",
      "Lr que voy a aplicar en el lote: 124 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.68497777 0.72263575 0.76226497 0.80371433 0.84452522 0.88628083\n",
      "  0.93132669 0.97583538]]\n",
      "verdaderas salidas: [0.82293685]\n",
      "PERDIDAAAA antes: 0.03741493821144104\n",
      "Predicción post entrenamiento : [[1.0268978]]\n",
      "PERDIDAAAA despues: 0.041600070893764496\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "[[[0.72263575]\n",
      "  [0.76226497]\n",
      "  [0.80371433]\n",
      "  [0.84452522]\n",
      "  [0.88628083]\n",
      "  [0.93132669]\n",
      "  [0.97583538]\n",
      "  [1.01636624]]]\n",
      "ejemplar: [0.72263575 0.76226497 0.80371433 0.84452522 0.88628083 0.93132669\n",
      " 0.97583538 1.01636624]\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[1.0569514]]\n",
      "Lr que voy a aplicar en el lote: 125 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.72263575 0.76226497 0.80371433 0.84452522 0.88628083 0.93132669\n",
      "  0.97583538 1.01636624]]\n",
      "verdaderas salidas: [0.77450601]\n",
      "PERDIDAAAA antes: 0.0797753855586052\n",
      "Predicción post entrenamiento : [[1.0549209]]\n",
      "PERDIDAAAA despues: 0.07863250374794006\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "[[[0.76226497]\n",
      "  [0.80371433]\n",
      "  [0.84452522]\n",
      "  [0.88628083]\n",
      "  [0.93132669]\n",
      "  [0.97583538]\n",
      "  [1.01636624]\n",
      "  [1.0569514 ]]]\n",
      "ejemplar: [0.76226497 0.80371433 0.84452522 0.88628083 0.93132669 0.97583538\n",
      " 1.01636624 1.0569514 ]\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[1.0856036]]\n",
      "Lr que voy a aplicar en el lote: 126 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.76226497 0.80371433 0.84452522 0.88628083 0.93132669 0.97583538\n",
      "  1.01636624 1.0569514 ]]\n",
      "verdaderas salidas: [0.78419217]\n",
      "PERDIDAAAA antes: 0.09084886312484741\n",
      "Predicción post entrenamiento : [[1.0774475]]\n",
      "PERDIDAAAA despues: 0.08599872142076492\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "[[[0.80371433]\n",
      "  [0.84452522]\n",
      "  [0.88628083]\n",
      "  [0.93132669]\n",
      "  [0.97583538]\n",
      "  [1.01636624]\n",
      "  [1.0569514 ]\n",
      "  [1.08560359]]]\n",
      "ejemplar: [0.80371433 0.84452522 0.88628083 0.93132669 0.97583538 1.01636624\n",
      " 1.0569514  1.08560359]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[1.1081582]]\n",
      "Lr que voy a aplicar en el lote: 127 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.80371433 0.84452522 0.88628083 0.93132669 0.97583538 1.01636624\n",
      "  1.0569514  1.08560359]]\n",
      "verdaderas salidas: [0.85974429]\n",
      "PERDIDAAAA antes: 0.06170947477221489\n",
      "Predicción post entrenamiento : [[1.0912906]]\n",
      "PERDIDAAAA despues: 0.053613681346178055\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "[[[0.84452522]\n",
      "  [0.88628083]\n",
      "  [0.93132669]\n",
      "  [0.97583538]\n",
      "  [1.01636624]\n",
      "  [1.0569514 ]\n",
      "  [1.08560359]\n",
      "  [1.10815823]]]\n",
      "ejemplar: [0.84452522 0.88628083 0.93132669 0.97583538 1.01636624 1.0569514\n",
      " 1.08560359 1.10815823]\n",
      "y: 0.854320030995738\n",
      "Predicción : [[1.1212105]]\n",
      "Lr que voy a aplicar en el lote: 128 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.84452522 0.88628083 0.93132669 0.97583538 1.01636624 1.0569514\n",
      "  1.08560359 1.10815823]]\n",
      "verdaderas salidas: [0.85432003]\n",
      "PERDIDAAAA antes: 0.07123048603534698\n",
      "Predicción post entrenamiento : [[1.1007894]]\n",
      "PERDIDAAAA despues: 0.06074715405702591\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "[[[0.88628083]\n",
      "  [0.93132669]\n",
      "  [0.97583538]\n",
      "  [1.01636624]\n",
      "  [1.0569514 ]\n",
      "  [1.08560359]\n",
      "  [1.10815823]\n",
      "  [1.12121046]]]\n",
      "ejemplar: [0.88628083 0.93132669 0.97583538 1.01636624 1.0569514  1.08560359\n",
      " 1.10815823 1.12121046]\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[1.1296822]]\n",
      "Lr que voy a aplicar en el lote: 129 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.88628083 0.93132669 0.97583538 1.01636624 1.0569514  1.08560359\n",
      "  1.10815823 1.12121046]]\n",
      "verdaderas salidas: [0.83688493]\n",
      "PERDIDAAAA antes: 0.08573023974895477\n",
      "Predicción post entrenamiento : [[1.1051141]]\n",
      "PERDIDAAAA despues: 0.0719468966126442\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "[[[0.93132669]\n",
      "  [0.97583538]\n",
      "  [1.01636624]\n",
      "  [1.0569514 ]\n",
      "  [1.08560359]\n",
      "  [1.10815823]\n",
      "  [1.12121046]\n",
      "  [1.12968218]]]\n",
      "ejemplar: [0.93132669 0.97583538 1.01636624 1.0569514  1.08560359 1.10815823\n",
      " 1.12121046 1.12968218]\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[1.1321778]]\n",
      "Lr que voy a aplicar en el lote: 130 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.93132669 0.97583538 1.01636624 1.0569514  1.08560359 1.10815823\n",
      "  1.12121046 1.12968218]]\n",
      "verdaderas salidas: [0.82991089]\n",
      "PERDIDAAAA antes: 0.09136531502008438\n",
      "Predicción post entrenamiento : [[1.1064929]]\n",
      "PERDIDAAAA despues: 0.07649760693311691\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "[[[0.97583538]\n",
      "  [1.01636624]\n",
      "  [1.0569514 ]\n",
      "  [1.08560359]\n",
      "  [1.10815823]\n",
      "  [1.12121046]\n",
      "  [1.12968218]\n",
      "  [1.13217783]]]\n",
      "ejemplar: [0.97583538 1.01636624 1.0569514  1.08560359 1.10815823 1.12121046\n",
      " 1.12968218 1.13217783]\n",
      "y: 0.887253002712127\n",
      "Predicción : [[1.130269]]\n",
      "Lr que voy a aplicar en el lote: 131 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.97583538 1.01636624 1.0569514  1.08560359 1.10815823 1.12121046\n",
      "  1.12968218 1.13217783]]\n",
      "verdaderas salidas: [0.887253]\n",
      "PERDIDAAAA antes: 0.059056807309389114\n",
      "Predicción post entrenamiento : [[1.102886]]\n",
      "PERDIDAAAA despues: 0.04649757966399193\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "[[[1.01636624]\n",
      "  [1.0569514 ]\n",
      "  [1.08560359]\n",
      "  [1.10815823]\n",
      "  [1.12121046]\n",
      "  [1.12968218]\n",
      "  [1.13217783]\n",
      "  [1.13026905]]]\n",
      "ejemplar: [1.01636624 1.0569514  1.08560359 1.10815823 1.12121046 1.12968218\n",
      " 1.13217783 1.13026905]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[1.1225561]]\n",
      "Lr que voy a aplicar en el lote: 132 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[1.01636624 1.0569514  1.08560359 1.10815823 1.12121046 1.12968218\n",
      "  1.13217783 1.13026905]]\n",
      "verdaderas salidas: [0.85974429]\n",
      "PERDIDAAAA antes: 0.06907003372907639\n",
      "Predicción post entrenamiento : [[1.090102]]\n",
      "PERDIDAAAA despues: 0.05306464433670044\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "[[[1.0569514 ]\n",
      "  [1.08560359]\n",
      "  [1.10815823]\n",
      "  [1.12121046]\n",
      "  [1.12968218]\n",
      "  [1.13217783]\n",
      "  [1.13026905]\n",
      "  [1.12255609]]]\n",
      "ejemplar: [1.0569514  1.08560359 1.10815823 1.12121046 1.12968218 1.13217783\n",
      " 1.13026905 1.12255609]\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[1.1054293]]\n",
      "Lr que voy a aplicar en el lote: 133 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[1.0569514  1.08560359 1.10815823 1.12121046 1.12968218 1.13217783\n",
      "  1.13026905 1.12255609]]\n",
      "verdaderas salidas: [0.83959706]\n",
      "PERDIDAAAA antes: 0.07066678255796432\n",
      "Predicción post entrenamiento : [[1.0719347]]\n",
      "PERDIDAAAA despues: 0.053980786353349686\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "[[[1.08560359]\n",
      "  [1.10815823]\n",
      "  [1.12121046]\n",
      "  [1.12968218]\n",
      "  [1.13217783]\n",
      "  [1.13026905]\n",
      "  [1.12255609]\n",
      "  [1.10542929]]]\n",
      "ejemplar: [1.08560359 1.10815823 1.12121046 1.12968218 1.13217783 1.13026905\n",
      " 1.12255609 1.10542929]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[1.0819049]]\n",
      "Lr que voy a aplicar en el lote: 134 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[1.08560359 1.10815823 1.12121046 1.12968218 1.13217783 1.13026905\n",
      "  1.12255609 1.10542929]]\n",
      "verdaderas salidas: [0.78380473]\n",
      "PERDIDAAAA antes: 0.08886371552944183\n",
      "Predicción post entrenamiento : [[1.0496706]]\n",
      "PERDIDAAAA despues: 0.07068465650081635\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "[[[1.10815823]\n",
      "  [1.12121046]\n",
      "  [1.12968218]\n",
      "  [1.13217783]\n",
      "  [1.13026905]\n",
      "  [1.12255609]\n",
      "  [1.10542929]\n",
      "  [1.08190489]]]\n",
      "ejemplar: [1.10815823 1.12121046 1.12968218 1.13217783 1.13026905 1.12255609\n",
      " 1.10542929 1.08190489]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[1.055607]]\n",
      "Lr que voy a aplicar en el lote: 135 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[1.10815823 1.12121046 1.12968218 1.13217783 1.13026905 1.12255609\n",
      "  1.10542929 1.08190489]]\n",
      "verdaderas salidas: [0.81828749]\n",
      "PERDIDAAAA antes: 0.05632052943110466\n",
      "Predicción post entrenamiento : [[1.0225983]]\n",
      "PERDIDAAAA despues: 0.04174289107322693\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "[[[1.12121046]\n",
      "  [1.12968218]\n",
      "  [1.13217783]\n",
      "  [1.13026905]\n",
      "  [1.12255609]\n",
      "  [1.10542929]\n",
      "  [1.08190489]\n",
      "  [1.05560696]]]\n",
      "ejemplar: [1.12121046 1.12968218 1.13217783 1.13026905 1.12255609 1.10542929\n",
      " 1.08190489 1.05560696]\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[1.024739]]\n",
      "Lr que voy a aplicar en el lote: 136 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[1.12121046 1.12968218 1.13217783 1.13026905 1.12255609 1.10542929\n",
      "  1.08190489 1.05560696]]\n",
      "verdaderas salidas: [0.79116621]\n",
      "PERDIDAAAA antes: 0.05455627292394638\n",
      "Predicción post entrenamiento : [[0.9977795]]\n",
      "PERDIDAAAA despues: 0.04268905520439148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "[[[1.12968218]\n",
      "  [1.13217783]\n",
      "  [1.13026905]\n",
      "  [1.12255609]\n",
      "  [1.10542929]\n",
      "  [1.08190489]\n",
      "  [1.05560696]\n",
      "  [1.02473903]]]\n",
      "ejemplar: [1.12968218 1.13217783 1.13026905 1.12255609 1.10542929 1.08190489\n",
      " 1.05560696 1.02473903]\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.9969877]]\n",
      "Lr que voy a aplicar en el lote: 137 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[1.12968218 1.13217783 1.13026905 1.12255609 1.10542929 1.08190489\n",
      "  1.05560696 1.02473903]]\n",
      "verdaderas salidas: [0.76055792]\n",
      "PERDIDAAAA antes: 0.05589902773499489\n",
      "Predicción post entrenamiento : [[0.96985716]]\n",
      "PERDIDAAAA despues: 0.043806158006191254\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "[[[1.13217783]\n",
      "  [1.13026905]\n",
      "  [1.12255609]\n",
      "  [1.10542929]\n",
      "  [1.08190489]\n",
      "  [1.05560696]\n",
      "  [1.02473903]\n",
      "  [0.9969877 ]]]\n",
      "ejemplar: [1.13217783 1.13026905 1.12255609 1.10542929 1.08190489 1.05560696\n",
      " 1.02473903 0.9969877 ]\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.9661485]]\n",
      "Lr que voy a aplicar en el lote: 138 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[1.13217783 1.13026905 1.12255609 1.10542929 1.08190489 1.05560696\n",
      "  1.02473903 0.9969877 ]]\n",
      "verdaderas salidas: [0.79155366]\n",
      "PERDIDAAAA antes: 0.030483350157737732\n",
      "Predicción post entrenamiento : [[0.93981683]]\n",
      "PERDIDAAAA despues: 0.021981963887810707\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "[[[1.13026905]\n",
      "  [1.12255609]\n",
      "  [1.10542929]\n",
      "  [1.08190489]\n",
      "  [1.05560696]\n",
      "  [1.02473903]\n",
      "  [0.9969877 ]\n",
      "  [0.9661485 ]]]\n",
      "ejemplar: [1.13026905 1.12255609 1.10542929 1.08190489 1.05560696 1.02473903\n",
      " 0.9969877  0.9661485 ]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.93347347]]\n",
      "Lr que voy a aplicar en el lote: 139 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[1.13026905 1.12255609 1.10542929 1.08190489 1.05560696 1.02473903\n",
      "  0.9969877  0.9661485 ]]\n",
      "verdaderas salidas: [0.7686943]\n",
      "PERDIDAAAA antes: 0.027152180671691895\n",
      "Predicción post entrenamiento : [[0.9072654]]\n",
      "PERDIDAAAA despues: 0.019201962277293205\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "[[[1.12255609]\n",
      "  [1.10542929]\n",
      "  [1.08190489]\n",
      "  [1.05560696]\n",
      "  [1.02473903]\n",
      "  [0.9969877 ]\n",
      "  [0.9661485 ]\n",
      "  [0.93347347]]]\n",
      "ejemplar: [1.12255609 1.10542929 1.08190489 1.05560696 1.02473903 0.9969877\n",
      " 0.9661485  0.93347347]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.89838314]]\n",
      "Lr que voy a aplicar en el lote: 140 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[1.12255609 1.10542929 1.08190489 1.05560696 1.02473903 0.9969877\n",
      "  0.9661485  0.93347347]]\n",
      "verdaderas salidas: [0.7686943]\n",
      "PERDIDAAAA antes: 0.016819199547171593\n",
      "Predicción post entrenamiento : [[0.87602544]]\n",
      "PERDIDAAAA despues: 0.011519976891577244\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "[[[1.10542929]\n",
      "  [1.08190489]\n",
      "  [1.05560696]\n",
      "  [1.02473903]\n",
      "  [0.9969877 ]\n",
      "  [0.9661485 ]\n",
      "  [0.93347347]\n",
      "  [0.89838314]]]\n",
      "ejemplar: [1.10542929 1.08190489 1.05560696 1.02473903 0.9969877  0.9661485\n",
      " 0.93347347 0.89838314]\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.8649393]]\n",
      "Lr que voy a aplicar en el lote: 141 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[1.10542929 1.08190489 1.05560696 1.02473903 0.9969877  0.9661485\n",
      "  0.93347347 0.89838314]]\n",
      "verdaderas salidas: [0.79891515]\n",
      "PERDIDAAAA antes: 0.004359185229986906\n",
      "Predicción post entrenamiento : [[0.8443183]]\n",
      "PERDIDAAAA despues: 0.0020614436361938715\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "[[[1.08190489]\n",
      "  [1.05560696]\n",
      "  [1.02473903]\n",
      "  [0.9969877 ]\n",
      "  [0.9661485 ]\n",
      "  [0.93347347]\n",
      "  [0.89838314]\n",
      "  [0.86493927]]]\n",
      "ejemplar: [1.08190489 1.05560696 1.02473903 0.9969877  0.9661485  0.93347347\n",
      " 0.89838314 0.86493927]\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.8320179]]\n",
      "Lr que voy a aplicar en el lote: 142 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[1.08190489 1.05560696 1.02473903 0.9969877  0.9661485  0.93347347\n",
      "  0.89838314 0.86493927]]\n",
      "verdaderas salidas: [0.79000387]\n",
      "PERDIDAAAA antes: 0.0017651764210313559\n",
      "Predicción post entrenamiento : [[0.8133572]]\n",
      "PERDIDAAAA despues: 0.0005453756311908364\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "[[[1.05560696]\n",
      "  [1.02473903]\n",
      "  [0.9969877 ]\n",
      "  [0.9661485 ]\n",
      "  [0.93347347]\n",
      "  [0.89838314]\n",
      "  [0.86493927]\n",
      "  [0.8320179 ]]]\n",
      "ejemplar: [1.05560696 1.02473903 0.9969877  0.9661485  0.93347347 0.89838314\n",
      " 0.86493927 0.8320179 ]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.8004959]]\n",
      "Lr que voy a aplicar en el lote: 143 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[1.05560696 1.02473903 0.9969877  0.9661485  0.93347347 0.89838314\n",
      "  0.86493927 0.8320179 ]]\n",
      "verdaderas salidas: [0.76017048]\n",
      "PERDIDAAAA antes: 0.0016261429991573095\n",
      "Predicción post entrenamiento : [[0.7838373]]\n",
      "PERDIDAAAA despues: 0.0005601202137768269\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "[[[1.02473903]\n",
      "  [0.9969877 ]\n",
      "  [0.9661485 ]\n",
      "  [0.93347347]\n",
      "  [0.89838314]\n",
      "  [0.86493927]\n",
      "  [0.8320179 ]\n",
      "  [0.80049592]]]\n",
      "ejemplar: [1.02473903 0.9969877  0.9661485  0.93347347 0.89838314 0.86493927\n",
      " 0.8320179  0.80049592]\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.7706243]]\n",
      "Lr que voy a aplicar en el lote: 144 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[1.02473903 0.9969877  0.9661485  0.93347347 0.89838314 0.86493927\n",
      "  0.8320179  0.80049592]]\n",
      "verdaderas salidas: [0.68539326]\n",
      "PERDIDAAAA antes: 0.007264324463903904\n",
      "Predicción post entrenamiento : [[0.75417435]]\n",
      "PERDIDAAAA despues: 0.004730836488306522\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "[[[0.9969877 ]\n",
      "  [0.9661485 ]\n",
      "  [0.93347347]\n",
      "  [0.89838314]\n",
      "  [0.86493927]\n",
      "  [0.8320179 ]\n",
      "  [0.80049592]\n",
      "  [0.77062428]]]\n",
      "ejemplar: [0.9969877  0.9661485  0.93347347 0.89838314 0.86493927 0.8320179\n",
      " 0.80049592 0.77062428]\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.7411559]]\n",
      "Lr que voy a aplicar en el lote: 145 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.9969877  0.9661485  0.93347347 0.89838314 0.86493927 0.8320179\n",
      "  0.80049592 0.77062428]]\n",
      "verdaderas salidas: [0.60519179]\n",
      "PERDIDAAAA antes: 0.018486252054572105\n",
      "Predicción post entrenamiento : [[0.72473425]]\n",
      "PERDIDAAAA despues: 0.014290404506027699\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "[[[0.9661485 ]\n",
      "  [0.93347347]\n",
      "  [0.89838314]\n",
      "  [0.86493927]\n",
      "  [0.8320179 ]\n",
      "  [0.80049592]\n",
      "  [0.77062428]\n",
      "  [0.74115592]]]\n",
      "ejemplar: [0.9661485  0.93347347 0.89838314 0.86493927 0.8320179  0.80049592\n",
      " 0.77062428 0.74115592]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.7114726]]\n",
      "Lr que voy a aplicar en el lote: 146 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.9661485  0.93347347 0.89838314 0.86493927 0.8320179  0.80049592\n",
      "  0.77062428 0.74115592]]\n",
      "verdaderas salidas: [0.66485858]\n",
      "PERDIDAAAA antes: 0.0021728642750531435\n",
      "Predicción post entrenamiento : [[0.69598836]]\n",
      "PERDIDAAAA despues: 0.0009690630249679089\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "[[[0.93347347]\n",
      "  [0.89838314]\n",
      "  [0.86493927]\n",
      "  [0.8320179 ]\n",
      "  [0.80049592]\n",
      "  [0.77062428]\n",
      "  [0.74115592]\n",
      "  [0.71147257]]]\n",
      "ejemplar: [0.93347347 0.89838314 0.86493927 0.8320179  0.80049592 0.77062428\n",
      " 0.74115592 0.71147257]\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.6828498]]\n",
      "Lr que voy a aplicar en el lote: 147 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.93347347 0.89838314 0.86493927 0.8320179  0.80049592 0.77062428\n",
      "  0.74115592 0.71147257]]\n",
      "verdaderas salidas: [0.70786517]\n",
      "PERDIDAAAA antes: 0.0006257679197005928\n",
      "Predicción post entrenamiento : [[0.66969407]]\n",
      "PERDIDAAAA despues: 0.0014570337953045964\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "[[[0.89838314]\n",
      "  [0.86493927]\n",
      "  [0.8320179 ]\n",
      "  [0.80049592]\n",
      "  [0.77062428]\n",
      "  [0.74115592]\n",
      "  [0.71147257]\n",
      "  [0.68284982]]]\n",
      "ejemplar: [0.89838314 0.86493927 0.8320179  0.80049592 0.77062428 0.74115592\n",
      " 0.71147257 0.68284982]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.65690136]]\n",
      "Lr que voy a aplicar en el lote: 148 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.89838314 0.86493927 0.8320179  0.80049592 0.77062428 0.74115592\n",
      "  0.71147257 0.68284982]]\n",
      "verdaderas salidas: [0.66485858]\n",
      "PERDIDAAAA antes: 6.331735494313762e-05\n",
      "Predicción post entrenamiento : [[0.6465337]]\n",
      "PERDIDAAAA despues: 0.00033580019953660667\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "[[[0.86493927]\n",
      "  [0.8320179 ]\n",
      "  [0.80049592]\n",
      "  [0.77062428]\n",
      "  [0.74115592]\n",
      "  [0.71147257]\n",
      "  [0.68284982]\n",
      "  [0.65690136]]]\n",
      "ejemplar: [0.86493927 0.8320179  0.80049592 0.77062428 0.74115592 0.71147257\n",
      " 0.68284982 0.65690136]\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.634408]]\n",
      "Lr que voy a aplicar en el lote: 149 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.86493927 0.8320179  0.80049592 0.77062428 0.74115592 0.71147257\n",
      "  0.68284982 0.65690136]]\n",
      "verdaderas salidas: [0.71135219]\n",
      "PERDIDAAAA antes: 0.005920405499637127\n",
      "Predicción post entrenamiento : [[0.6254931]]\n",
      "PERDIDAAAA despues: 0.007371778134256601\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "[[[0.8320179 ]\n",
      "  [0.80049592]\n",
      "  [0.77062428]\n",
      "  [0.74115592]\n",
      "  [0.71147257]\n",
      "  [0.68284982]\n",
      "  [0.65690136]\n",
      "  [0.634408  ]]]\n",
      "ejemplar: [0.8320179  0.80049592 0.77062428 0.74115592 0.71147257 0.68284982\n",
      " 0.65690136 0.634408  ]\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.6139272]]\n",
      "Lr que voy a aplicar en el lote: 150 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.8320179  0.80049592 0.77062428 0.74115592 0.71147257 0.68284982\n",
      "  0.65690136 0.634408  ]]\n",
      "verdaderas salidas: [0.67725688]\n",
      "PERDIDAAAA antes: 0.0040106503292918205\n",
      "Predicción post entrenamiento : [[0.60655594]]\n",
      "PERDIDAAAA despues: 0.004998623393476009\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "[[[0.80049592]\n",
      "  [0.77062428]\n",
      "  [0.74115592]\n",
      "  [0.71147257]\n",
      "  [0.68284982]\n",
      "  [0.65690136]\n",
      "  [0.634408  ]\n",
      "  [0.61392719]]]\n",
      "ejemplar: [0.80049592 0.77062428 0.74115592 0.71147257 0.68284982 0.65690136\n",
      " 0.634408   0.61392719]\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.59558517]]\n",
      "Lr que voy a aplicar en el lote: 151 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.80049592 0.77062428 0.74115592 0.71147257 0.68284982 0.65690136\n",
      "  0.634408   0.61392719]]\n",
      "verdaderas salidas: [0.76210771]\n",
      "PERDIDAAAA antes: 0.027729764580726624\n",
      "Predicción post entrenamiento : [[0.5898359]]\n",
      "PERDIDAAAA despues: 0.02967759035527706\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "[[[0.77062428]\n",
      "  [0.74115592]\n",
      "  [0.71147257]\n",
      "  [0.68284982]\n",
      "  [0.65690136]\n",
      "  [0.634408  ]\n",
      "  [0.61392719]\n",
      "  [0.59558517]]]\n",
      "ejemplar: [0.77062428 0.74115592 0.71147257 0.68284982 0.65690136 0.634408\n",
      " 0.61392719 0.59558517]\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.57941395]]\n",
      "Lr que voy a aplicar en el lote: 152 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.77062428 0.74115592 0.71147257 0.68284982 0.65690136 0.634408\n",
      "  0.61392719 0.59558517]]\n",
      "verdaderas salidas: [0.80705153]\n",
      "PERDIDAAAA antes: 0.05181887373328209\n",
      "Predicción post entrenamiento : [[0.5757046]]\n",
      "PERDIDAAAA despues: 0.05352141708135605\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "[[[0.74115592]\n",
      "  [0.71147257]\n",
      "  [0.68284982]\n",
      "  [0.65690136]\n",
      "  [0.634408  ]\n",
      "  [0.61392719]\n",
      "  [0.59558517]\n",
      "  [0.57941395]]]\n",
      "ejemplar: [0.74115592 0.71147257 0.68284982 0.65690136 0.634408   0.61392719\n",
      " 0.59558517 0.57941395]\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.56576616]]\n",
      "Lr que voy a aplicar en el lote: 153 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.74115592 0.71147257 0.68284982 0.65690136 0.634408   0.61392719\n",
      "  0.59558517 0.57941395]]\n",
      "verdaderas salidas: [0.81518791]\n",
      "PERDIDAAAA antes: 0.06221122294664383\n",
      "Predicción post entrenamiento : [[0.56395054]]\n",
      "PERDIDAAAA despues: 0.06312023103237152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "[[[0.71147257]\n",
      "  [0.68284982]\n",
      "  [0.65690136]\n",
      "  [0.634408  ]\n",
      "  [0.61392719]\n",
      "  [0.59558517]\n",
      "  [0.57941395]\n",
      "  [0.56576616]]]\n",
      "ejemplar: [0.71147257 0.68284982 0.65690136 0.634408   0.61392719 0.59558517\n",
      " 0.57941395 0.56576616]\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.5545995]]\n",
      "Lr que voy a aplicar en el lote: 154 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.71147257 0.68284982 0.65690136 0.634408   0.61392719 0.59558517\n",
      "  0.57941395 0.56576616]]\n",
      "verdaderas salidas: [0.90623789]\n",
      "PERDIDAAAA antes: 0.12364954501390457\n",
      "Predicción post entrenamiento : [[0.5550953]]\n",
      "PERDIDAAAA despues: 0.12330111861228943\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "[[[0.68284982]\n",
      "  [0.65690136]\n",
      "  [0.634408  ]\n",
      "  [0.61392719]\n",
      "  [0.59558517]\n",
      "  [0.57941395]\n",
      "  [0.56576616]\n",
      "  [0.55459952]]]\n",
      "ejemplar: [0.68284982 0.65690136 0.634408   0.61392719 0.59558517 0.57941395\n",
      " 0.56576616 0.55459952]\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.5465401]]\n",
      "Lr que voy a aplicar en el lote: 155 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.68284982 0.65690136 0.634408   0.61392719 0.59558517 0.57941395\n",
      "  0.56576616 0.55459952]]\n",
      "verdaderas salidas: [0.95970554]\n",
      "PERDIDAAAA antes: 0.17070569097995758\n",
      "Predicción post entrenamiento : [[0.54926455]]\n",
      "PERDIDAAAA despues: 0.16846179962158203\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "[[[0.65690136]\n",
      "  [0.634408  ]\n",
      "  [0.61392719]\n",
      "  [0.59558517]\n",
      "  [0.57941395]\n",
      "  [0.56576616]\n",
      "  [0.55459952]\n",
      "  [0.54654008]]]\n",
      "ejemplar: [0.65690136 0.634408   0.61392719 0.59558517 0.57941395 0.56576616\n",
      " 0.55459952 0.54654008]\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.541619]]\n",
      "Lr que voy a aplicar en el lote: 156 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.65690136 0.634408   0.61392719 0.59558517 0.57941395 0.56576616\n",
      "  0.55459952 0.54654008]]\n",
      "verdaderas salidas: [0.9643549]\n",
      "PERDIDAAAA antes: 0.1787056177854538\n",
      "Predicción post entrenamiento : [[0.54623705]]\n",
      "PERDIDAAAA despues: 0.17482250928878784\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "[[[0.634408  ]\n",
      "  [0.61392719]\n",
      "  [0.59558517]\n",
      "  [0.57941395]\n",
      "  [0.56576616]\n",
      "  [0.55459952]\n",
      "  [0.54654008]\n",
      "  [0.541619  ]]]\n",
      "ejemplar: [0.634408   0.61392719 0.59558517 0.57941395 0.56576616 0.55459952\n",
      " 0.54654008 0.541619  ]\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.539466]]\n",
      "Lr que voy a aplicar en el lote: 157 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.634408   0.61392719 0.59558517 0.57941395 0.56576616 0.55459952\n",
      "  0.54654008 0.541619  ]]\n",
      "verdaderas salidas: [0.8880279]\n",
      "PERDIDAAAA antes: 0.12149538844823837\n",
      "Predicción post entrenamiento : [[0.545466]]\n",
      "PERDIDAAAA despues: 0.11734865605831146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "[[[0.61392719]\n",
      "  [0.59558517]\n",
      "  [0.57941395]\n",
      "  [0.56576616]\n",
      "  [0.55459952]\n",
      "  [0.54654008]\n",
      "  [0.541619  ]\n",
      "  [0.53946602]]]\n",
      "ejemplar: [0.61392719 0.59558517 0.57941395 0.56576616 0.55459952 0.54654008\n",
      " 0.541619   0.53946602]\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.53945625]]\n",
      "Lr que voy a aplicar en el lote: 158 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.61392719 0.59558517 0.57941395 0.56576616 0.55459952 0.54654008\n",
      "  0.541619   0.53946602]]\n",
      "verdaderas salidas: [0.89267726]\n",
      "PERDIDAAAA antes: 0.1247650757431984\n",
      "Predicción post entrenamiento : [[0.5468056]]\n",
      "PERDIDAAAA despues: 0.11962718516588211\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "[[[0.59558517]\n",
      "  [0.57941395]\n",
      "  [0.56576616]\n",
      "  [0.55459952]\n",
      "  [0.54654008]\n",
      "  [0.541619  ]\n",
      "  [0.53946602]\n",
      "  [0.53945625]]]\n",
      "ejemplar: [0.59558517 0.57941395 0.56576616 0.55459952 0.54654008 0.541619\n",
      " 0.53946602 0.53945625]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.54161394]]\n",
      "Lr que voy a aplicar en el lote: 159 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.59558517 0.57941395 0.56576616 0.55459952 0.54654008 0.541619\n",
      "  0.53946602 0.53945625]]\n",
      "verdaderas salidas: [0.87524215]\n",
      "PERDIDAAAA antes: 0.11130779981613159\n",
      "Predicción post entrenamiento : [[0.54997665]]\n",
      "PERDIDAAAA despues: 0.1057976633310318\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "[[[0.57941395]\n",
      "  [0.56576616]\n",
      "  [0.55459952]\n",
      "  [0.54654008]\n",
      "  [0.541619  ]\n",
      "  [0.53946602]\n",
      "  [0.53945625]\n",
      "  [0.54161394]]]\n",
      "ejemplar: [0.57941395 0.56576616 0.55459952 0.54654008 0.541619   0.53946602\n",
      " 0.53945625 0.54161394]\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.5456678]]\n",
      "Lr que voy a aplicar en el lote: 160 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.57941395 0.56576616 0.55459952 0.54654008 0.541619   0.53946602\n",
      "  0.53945625 0.54161394]]\n",
      "verdaderas salidas: [0.85083301]\n",
      "PERDIDAAAA antes: 0.09312578290700912\n",
      "Predicción post entrenamiento : [[0.5549595]]\n",
      "PERDIDAAAA despues: 0.0875411406159401\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "[[[0.56576616]\n",
      "  [0.55459952]\n",
      "  [0.54654008]\n",
      "  [0.541619  ]\n",
      "  [0.53946602]\n",
      "  [0.53945625]\n",
      "  [0.54161394]\n",
      "  [0.54566783]]]\n",
      "ejemplar: [0.56576616 0.55459952 0.54654008 0.541619   0.53946602 0.53945625\n",
      " 0.54161394 0.54566783]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.55161005]]\n",
      "Lr que voy a aplicar en el lote: 161 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.56576616 0.55459952 0.54654008 0.541619   0.53946602 0.53945625\n",
      "  0.54161394 0.54566783]]\n",
      "verdaderas salidas: [0.84889578]\n",
      "PERDIDAAAA antes: 0.08837880939245224\n",
      "Predicción post entrenamiento : [[0.5616872]]\n",
      "PERDIDAAAA despues: 0.08248879015445709\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "[[[0.55459952]\n",
      "  [0.54654008]\n",
      "  [0.541619  ]\n",
      "  [0.53946602]\n",
      "  [0.53945625]\n",
      "  [0.54161394]\n",
      "  [0.54566783]\n",
      "  [0.55161005]]]\n",
      "ejemplar: [0.55459952 0.54654008 0.541619   0.53946602 0.53945625 0.54161394\n",
      " 0.54566783 0.55161005]\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.55934]]\n",
      "Lr que voy a aplicar en el lote: 162 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.55459952 0.54654008 0.541619   0.53946602 0.53945625 0.54161394\n",
      "  0.54566783 0.55161005]]\n",
      "verdaderas salidas: [0.96241767]\n",
      "PERDIDAAAA antes: 0.16247160732746124\n",
      "Predicción post entrenamiento : [[0.5706594]]\n",
      "PERDIDAAAA despues: 0.15347453951835632\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "[[[0.54654008]\n",
      "  [0.541619  ]\n",
      "  [0.53946602]\n",
      "  [0.53945625]\n",
      "  [0.54161394]\n",
      "  [0.54566783]\n",
      "  [0.55161005]\n",
      "  [0.55934   ]]]\n",
      "ejemplar: [0.54654008 0.541619   0.53946602 0.53945625 0.54161394 0.54566783\n",
      " 0.55161005 0.55934   ]\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.5693596]]\n",
      "Lr que voy a aplicar en el lote: 163 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.54654008 0.541619   0.53946602 0.53945625 0.54161394 0.54566783\n",
      "  0.55161005 0.55934   ]]\n",
      "verdaderas salidas: [0.96784192]\n",
      "PERDIDAAAA antes: 0.15878815948963165\n",
      "Predicción post entrenamiento : [[0.58189005]]\n",
      "PERDIDAAAA despues: 0.14895884692668915\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "[[[0.541619  ]\n",
      "  [0.53946602]\n",
      "  [0.53945625]\n",
      "  [0.54161394]\n",
      "  [0.54566783]\n",
      "  [0.55161005]\n",
      "  [0.55934   ]\n",
      "  [0.5693596 ]]]\n",
      "ejemplar: [0.541619   0.53946602 0.53945625 0.54161394 0.54566783 0.55161005\n",
      " 0.55934    0.5693596 ]\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.581596]]\n",
      "Lr que voy a aplicar en el lote: 164 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.541619   0.53946602 0.53945625 0.54161394 0.54566783 0.55161005\n",
      "  0.55934    0.5693596 ]]\n",
      "verdaderas salidas: [0.94072065]\n",
      "PERDIDAAAA antes: 0.12897051870822906\n",
      "Predicción post entrenamiento : [[0.59522915]]\n",
      "PERDIDAAAA despues: 0.11936439573764801\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "[[[0.53946602]\n",
      "  [0.53945625]\n",
      "  [0.54161394]\n",
      "  [0.54566783]\n",
      "  [0.55161005]\n",
      "  [0.55934   ]\n",
      "  [0.5693596 ]\n",
      "  [0.58159602]]]\n",
      "ejemplar: [0.53946602 0.53945625 0.54161394 0.54566783 0.55161005 0.55934\n",
      " 0.5693596  0.58159602]\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.5958728]]\n",
      "Lr que voy a aplicar en el lote: 165 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.53946602 0.53945625 0.54161394 0.54566783 0.55161005 0.55934\n",
      "  0.5693596  0.58159602]]\n",
      "verdaderas salidas: [0.97249128]\n",
      "PERDIDAAAA antes: 0.14184145629405975\n",
      "Predicción post entrenamiento : [[0.6106052]]\n",
      "PERDIDAAAA despues: 0.13096153736114502\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "[[[0.53945625]\n",
      "  [0.54161394]\n",
      "  [0.54566783]\n",
      "  [0.55161005]\n",
      "  [0.55934   ]\n",
      "  [0.5693596 ]\n",
      "  [0.58159602]\n",
      "  [0.59587282]]]\n",
      "ejemplar: [0.53945625 0.54161394 0.54566783 0.55161005 0.55934    0.5693596\n",
      " 0.58159602 0.59587282]\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.612145]]\n",
      "Lr que voy a aplicar en el lote: 166 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.53945625 0.54161394 0.54566783 0.55161005 0.55934    0.5693596\n",
      "  0.58159602 0.59587282]]\n",
      "verdaderas salidas: [0.99690043]\n",
      "PERDIDAAAA antes: 0.14803674817085266\n",
      "Predicción post entrenamiento : [[0.62802505]]\n",
      "PERDIDAAAA despues: 0.13606904447078705\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "[[[0.54161394]\n",
      "  [0.54566783]\n",
      "  [0.55161005]\n",
      "  [0.55934   ]\n",
      "  [0.5693596 ]\n",
      "  [0.58159602]\n",
      "  [0.59587282]\n",
      "  [0.61214501]]]\n",
      "ejemplar: [0.54161394 0.54566783 0.55161005 0.55934    0.5693596  0.58159602\n",
      " 0.59587282 0.61214501]\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.630495]]\n",
      "Lr que voy a aplicar en el lote: 167 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.54161394 0.54566783 0.55161005 0.55934    0.5693596  0.58159602\n",
      "  0.59587282 0.61214501]]\n",
      "verdaderas salidas: [0.95118171]\n",
      "PERDIDAAAA antes: 0.10283996164798737\n",
      "Predicción post entrenamiento : [[0.64736724]]\n",
      "PERDIDAAAA despues: 0.09230323135852814\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "[[[0.54566783]\n",
      "  [0.55161005]\n",
      "  [0.55934   ]\n",
      "  [0.5693596 ]\n",
      "  [0.58159602]\n",
      "  [0.59587282]\n",
      "  [0.61214501]\n",
      "  [0.63049501]]]\n",
      "ejemplar: [0.54566783 0.55161005 0.55934    0.5693596  0.58159602 0.59587282\n",
      " 0.61214501 0.63049501]\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.650798]]\n",
      "Lr que voy a aplicar en el lote: 168 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.54566783 0.55161005 0.55934    0.5693596  0.58159602 0.59587282\n",
      "  0.61214501 0.63049501]]\n",
      "verdaderas salidas: [0.89577683]\n",
      "PERDIDAAAA antes: 0.06001460552215576\n",
      "Predicción post entrenamiento : [[0.6681336]]\n",
      "PERDIDAAAA despues: 0.05182142183184624\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "[[[0.55161005]\n",
      "  [0.55934   ]\n",
      "  [0.5693596 ]\n",
      "  [0.58159602]\n",
      "  [0.59587282]\n",
      "  [0.61214501]\n",
      "  [0.63049501]\n",
      "  [0.65079802]]]\n",
      "ejemplar: [0.55161005 0.55934    0.5693596  0.58159602 0.59587282 0.61214501\n",
      " 0.63049501 0.65079802]\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.67259586]]\n",
      "Lr que voy a aplicar en el lote: 169 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.55161005 0.55934    0.5693596  0.58159602 0.59587282 0.61214501\n",
      "  0.63049501 0.65079802]]\n",
      "verdaderas salidas: [0.8814413]\n",
      "PERDIDAAAA antes: 0.04361641779541969\n",
      "Predicción post entrenamiento : [[0.6900618]]\n",
      "PERDIDAAAA despues: 0.03662610799074173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "[[[0.55934   ]\n",
      "  [0.5693596 ]\n",
      "  [0.58159602]\n",
      "  [0.59587282]\n",
      "  [0.61214501]\n",
      "  [0.63049501]\n",
      "  [0.65079802]\n",
      "  [0.67259586]]]\n",
      "ejemplar: [0.55934    0.5693596  0.58159602 0.59587282 0.61214501 0.63049501\n",
      " 0.65079802 0.67259586]\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.69562924]]\n",
      "Lr que voy a aplicar en el lote: 170 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.55934    0.5693596  0.58159602 0.59587282 0.61214501 0.63049501\n",
      "  0.65079802 0.67259586]]\n",
      "verdaderas salidas: [0.9170864]\n",
      "PERDIDAAAA antes: 0.049043282866477966\n",
      "Predicción post entrenamiento : [[0.7134067]]\n",
      "PERDIDAAAA despues: 0.041485436260700226\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "[[[0.5693596 ]\n",
      "  [0.58159602]\n",
      "  [0.59587282]\n",
      "  [0.61214501]\n",
      "  [0.63049501]\n",
      "  [0.65079802]\n",
      "  [0.67259586]\n",
      "  [0.69562924]]]\n",
      "ejemplar: [0.5693596  0.58159602 0.59587282 0.61214501 0.63049501 0.65079802\n",
      " 0.67259586 0.69562924]\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.7201727]]\n",
      "Lr que voy a aplicar en el lote: 171 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.5693596  0.58159602 0.59587282 0.61214501 0.63049501 0.65079802\n",
      "  0.67259586 0.69562924]]\n",
      "verdaderas salidas: [0.91979853]\n",
      "PERDIDAAAA antes: 0.03985048085451126\n",
      "Predicción post entrenamiento : [[0.73814625]]\n",
      "PERDIDAAAA despues: 0.03299755975604057\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "[[[0.58159602]\n",
      "  [0.59587282]\n",
      "  [0.61214501]\n",
      "  [0.63049501]\n",
      "  [0.65079802]\n",
      "  [0.67259586]\n",
      "  [0.69562924]\n",
      "  [0.7201727 ]]]\n",
      "ejemplar: [0.58159602 0.59587282 0.61214501 0.63049501 0.65079802 0.67259586\n",
      " 0.69562924 0.7201727 ]\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.7461174]]\n",
      "Lr que voy a aplicar en el lote: 172 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.58159602 0.59587282 0.61214501 0.63049501 0.65079802 0.67259586\n",
      "  0.69562924 0.7201727 ]]\n",
      "verdaderas salidas: [0.96164277]\n",
      "PERDIDAAAA antes: 0.04645119234919548\n",
      "Predicción post entrenamiento : [[0.7645868]]\n",
      "PERDIDAAAA despues: 0.038831066340208054\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "[[[0.59587282]\n",
      "  [0.61214501]\n",
      "  [0.63049501]\n",
      "  [0.65079802]\n",
      "  [0.67259586]\n",
      "  [0.69562924]\n",
      "  [0.7201727 ]\n",
      "  [0.74611741]]]\n",
      "ejemplar: [0.59587282 0.61214501 0.63049501 0.65079802 0.67259586 0.69562924\n",
      " 0.7201727  0.74611741]\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.77376163]]\n",
      "Lr que voy a aplicar en el lote: 173 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.59587282 0.61214501 0.63049501 0.65079802 0.67259586 0.69562924\n",
      "  0.7201727  0.74611741]]\n",
      "verdaderas salidas: [0.96822937]\n",
      "PERDIDAAAA antes: 0.03781769424676895\n",
      "Predicción post entrenamiento : [[0.79133576]]\n",
      "PERDIDAAAA despues: 0.03129134327173233\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "[[[0.61214501]\n",
      "  [0.63049501]\n",
      "  [0.65079802]\n",
      "  [0.67259586]\n",
      "  [0.69562924]\n",
      "  [0.7201727 ]\n",
      "  [0.74611741]\n",
      "  [0.77376163]]]\n",
      "ejemplar: [0.61214501 0.63049501 0.65079802 0.67259586 0.69562924 0.7201727\n",
      " 0.74611741 0.77376163]\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.8017011]]\n",
      "Lr que voy a aplicar en el lote: 174 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.61214501 0.63049501 0.65079802 0.67259586 0.69562924 0.7201727\n",
      "  0.74611741 0.77376163]]\n",
      "verdaderas salidas: [0.95776831]\n",
      "PERDIDAAAA antes: 0.024356968700885773\n",
      "Predicción post entrenamiento : [[0.8193638]]\n",
      "PERDIDAAAA despues: 0.019155818969011307\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "0\n",
      "[[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "ejemplar: [0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      " 0.03448276 0.04223169]\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.49619702]]\n",
      "Lr que voy a aplicar en el lote: 1 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      "  0.03448276 0.04223169]]\n",
      "verdaderas salidas: [0.04610616]\n",
      "PERDIDAAAA antes: 0.20258177816867828\n",
      "Predicción post entrenamiento : [[0.5036448]]\n",
      "PERDIDAAAA despues: 0.2093416303396225\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "[[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.49619702]]]\n",
      "ejemplar: [0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      " 0.04223169 0.49619702]\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.49034992]]\n",
      "Lr que voy a aplicar en el lote: 2 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      "  0.04223169 0.49619702]]\n",
      "verdaderas salidas: [0.10422317]\n",
      "PERDIDAAAA antes: 0.1490938663482666\n",
      "Predicción post entrenamiento : [[0.49533862]]\n",
      "PERDIDAAAA despues: 0.1529712975025177\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "[[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.49619702]\n",
      "  [0.49034992]]]\n",
      "ejemplar: [0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      " 0.49619702 0.49034992]\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.5020136]]\n",
      "Lr que voy a aplicar en el lote: 3 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      "  0.49619702 0.49034992]]\n",
      "verdaderas salidas: [0.1542038]\n",
      "PERDIDAAAA antes: 0.1209716722369194\n",
      "Predicción post entrenamiento : [[0.5050289]]\n",
      "PERDIDAAAA despues: 0.12307824939489365\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "[[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.49619702]\n",
      "  [0.49034992]\n",
      "  [0.50201362]]]\n",
      "ejemplar: [0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.49619702\n",
      " 0.49034992 0.50201362]\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.5227331]]\n",
      "Lr que voy a aplicar en el lote: 4 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.49619702\n",
      "  0.49034992 0.50201362]]\n",
      "verdaderas salidas: [0.15575358]\n",
      "PERDIDAAAA antes: 0.13467395305633545\n",
      "Predicción post entrenamiento : [[0.5233914]]\n",
      "PERDIDAAAA despues: 0.13515758514404297\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "[[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.49619702]\n",
      "  [0.49034992]\n",
      "  [0.50201362]\n",
      "  [0.52273309]]]\n",
      "ejemplar: [0.05656722 0.02595893 0.03448276 0.04223169 0.49619702 0.49034992\n",
      " 0.50201362 0.52273309]\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.5483146]]\n",
      "Lr que voy a aplicar en el lote: 5 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.05656722 0.02595893 0.03448276 0.04223169 0.49619702 0.49034992\n",
      "  0.50201362 0.52273309]]\n",
      "verdaderas salidas: [0.12553274]\n",
      "PERDIDAAAA antes: 0.17874446511268616\n",
      "Predicción post entrenamiento : [[0.5465087]]\n",
      "PERDIDAAAA despues: 0.17722077667713165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "[[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.49619702]\n",
      "  [0.49034992]\n",
      "  [0.50201362]\n",
      "  [0.52273309]\n",
      "  [0.54831457]]]\n",
      "ejemplar: [0.02595893 0.03448276 0.04223169 0.49619702 0.49034992 0.50201362\n",
      " 0.52273309 0.54831457]\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.5768406]]\n",
      "Lr que voy a aplicar en el lote: 6 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.02595893 0.03448276 0.04223169 0.49619702 0.49034992 0.50201362\n",
      "  0.52273309 0.54831457]]\n",
      "verdaderas salidas: [0.14567997]\n",
      "PERDIDAAAA antes: 0.18589948117733002\n",
      "Predicción post entrenamiento : [[0.5736843]]\n",
      "PERDIDAAAA despues: 0.18318770825862885\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "[[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.49619702]\n",
      "  [0.49034992]\n",
      "  [0.50201362]\n",
      "  [0.52273309]\n",
      "  [0.54831457]\n",
      "  [0.57684058]]]\n",
      "ejemplar: [0.03448276 0.04223169 0.49619702 0.49034992 0.50201362 0.52273309\n",
      " 0.54831457 0.57684058]\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.62403405]]\n",
      "Lr que voy a aplicar en el lote: 7 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.03448276 0.04223169 0.49619702 0.49034992 0.50201362 0.52273309\n",
      "  0.54831457 0.57684058]]\n",
      "verdaderas salidas: [0.14645486]\n",
      "PERDIDAAAA antes: 0.2280818670988083\n",
      "Predicción post entrenamiento : [[0.6184705]]\n",
      "PERDIDAAAA despues: 0.22279874980449677\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "[[[0.04223169]\n",
      "  [0.49619702]\n",
      "  [0.49034992]\n",
      "  [0.50201362]\n",
      "  [0.52273309]\n",
      "  [0.54831457]\n",
      "  [0.57684058]\n",
      "  [0.62403405]]]\n",
      "ejemplar: [0.04223169 0.49619702 0.49034992 0.50201362 0.52273309 0.54831457\n",
      " 0.57684058 0.62403405]\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.6838333]]\n",
      "Lr que voy a aplicar en el lote: 8 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.04223169 0.49619702 0.49034992 0.50201362 0.52273309 0.54831457\n",
      "  0.57684058 0.62403405]]\n",
      "verdaderas salidas: [0.19604804]\n",
      "PERDIDAAAA antes: 0.23793448507785797\n",
      "Predicción post entrenamiento : [[0.6760073]]\n",
      "PERDIDAAAA despues: 0.23036088049411774\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "[[[0.49619702]\n",
      "  [0.49034992]\n",
      "  [0.50201362]\n",
      "  [0.52273309]\n",
      "  [0.54831457]\n",
      "  [0.57684058]\n",
      "  [0.62403405]\n",
      "  [0.6838333 ]]]\n",
      "ejemplar: [0.49619702 0.49034992 0.50201362 0.52273309 0.54831457 0.57684058\n",
      " 0.62403405 0.6838333 ]\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.75734574]]\n",
      "Lr que voy a aplicar en el lote: 9 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.49619702 0.49034992 0.50201362 0.52273309 0.54831457 0.57684058\n",
      "  0.62403405 0.6838333 ]]\n",
      "verdaderas salidas: [0.2305308]\n",
      "PERDIDAAAA antes: 0.27753397822380066\n",
      "Predicción post entrenamiento : [[0.74713176]]\n",
      "PERDIDAAAA despues: 0.26687654852867126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "[[[0.49034992]\n",
      "  [0.50201362]\n",
      "  [0.52273309]\n",
      "  [0.54831457]\n",
      "  [0.57684058]\n",
      "  [0.62403405]\n",
      "  [0.6838333 ]\n",
      "  [0.75734574]]]\n",
      "ejemplar: [0.49034992 0.50201362 0.52273309 0.54831457 0.57684058 0.62403405\n",
      " 0.6838333  0.75734574]\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.7554364]]\n",
      "Lr que voy a aplicar en el lote: 10 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.49034992 0.50201362 0.52273309 0.54831457 0.57684058 0.62403405\n",
      "  0.6838333  0.75734574]]\n",
      "verdaderas salidas: [0.20844634]\n",
      "PERDIDAAAA antes: 0.299198180437088\n",
      "Predicción post entrenamiento : [[0.7416499]]\n",
      "PERDIDAAAA despues: 0.2843060791492462\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "[[[0.50201362]\n",
      "  [0.52273309]\n",
      "  [0.54831457]\n",
      "  [0.57684058]\n",
      "  [0.62403405]\n",
      "  [0.6838333 ]\n",
      "  [0.75734574]\n",
      "  [0.75543642]]]\n",
      "ejemplar: [0.50201362 0.52273309 0.54831457 0.57684058 0.62403405 0.6838333\n",
      " 0.75734574 0.75543642]\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.7557411]]\n",
      "Lr que voy a aplicar en el lote: 11 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.50201362 0.52273309 0.54831457 0.57684058 0.62403405 0.6838333\n",
      "  0.75734574 0.75543642]]\n",
      "verdaderas salidas: [0.21193336]\n",
      "PERDIDAAAA antes: 0.29572686553001404\n",
      "Predicción post entrenamiento : [[0.73865956]]\n",
      "PERDIDAAAA despues: 0.27744048833847046\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "[[[0.52273309]\n",
      "  [0.54831457]\n",
      "  [0.57684058]\n",
      "  [0.62403405]\n",
      "  [0.6838333 ]\n",
      "  [0.75734574]\n",
      "  [0.75543642]\n",
      "  [0.75574112]]]\n",
      "ejemplar: [0.52273309 0.54831457 0.57684058 0.62403405 0.6838333  0.75734574\n",
      " 0.75543642 0.75574112]\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.75620496]]\n",
      "Lr que voy a aplicar en el lote: 12 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.52273309 0.54831457 0.57684058 0.62403405 0.6838333  0.75734574\n",
      "  0.75543642 0.75574112]]\n",
      "verdaderas salidas: [0.207284]\n",
      "PERDIDAAAA antes: 0.30131426453590393\n",
      "Predicción post entrenamiento : [[0.73667437]]\n",
      "PERDIDAAAA despues: 0.2802541255950928\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "[[[0.54831457]\n",
      "  [0.57684058]\n",
      "  [0.62403405]\n",
      "  [0.6838333 ]\n",
      "  [0.75734574]\n",
      "  [0.75543642]\n",
      "  [0.75574112]\n",
      "  [0.75620496]]]\n",
      "ejemplar: [0.54831457 0.57684058 0.62403405 0.6838333  0.75734574 0.75543642\n",
      " 0.75574112 0.75620496]\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.7562853]]\n",
      "Lr que voy a aplicar en el lote: 13 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.54831457 0.57684058 0.62403405 0.6838333  0.75734574 0.75543642\n",
      "  0.75574112 0.75620496]]\n",
      "verdaderas salidas: [0.19294847]\n",
      "PERDIDAAAA antes: 0.3173483908176422\n",
      "Predicción post entrenamiento : [[0.7326137]]\n",
      "PERDIDAAAA despues: 0.29123854637145996\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "[[[0.57684058]\n",
      "  [0.62403405]\n",
      "  [0.6838333 ]\n",
      "  [0.75734574]\n",
      "  [0.75543642]\n",
      "  [0.75574112]\n",
      "  [0.75620496]\n",
      "  [0.75628531]]]\n",
      "ejemplar: [0.57684058 0.62403405 0.6838333  0.75734574 0.75543642 0.75574112\n",
      " 0.75620496 0.75628531]\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.7531459]]\n",
      "Lr que voy a aplicar en el lote: 14 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.57684058 0.62403405 0.6838333  0.75734574 0.75543642 0.75574112\n",
      "  0.75620496 0.75628531]]\n",
      "verdaderas salidas: [0.19682294]\n",
      "PERDIDAAAA antes: 0.309495210647583\n",
      "Predicción post entrenamiento : [[0.72733563]]\n",
      "PERDIDAAAA despues: 0.28144371509552\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "[[[0.62403405]\n",
      "  [0.6838333 ]\n",
      "  [0.75734574]\n",
      "  [0.75543642]\n",
      "  [0.75574112]\n",
      "  [0.75620496]\n",
      "  [0.75628531]\n",
      "  [0.75314587]]]\n",
      "ejemplar: [0.62403405 0.6838333  0.75734574 0.75543642 0.75574112 0.75620496\n",
      " 0.75628531 0.75314587]\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.74770576]]\n",
      "Lr que voy a aplicar en el lote: 15 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.62403405 0.6838333  0.75734574 0.75543642 0.75574112 0.75620496\n",
      "  0.75628531 0.75314587]]\n",
      "verdaderas salidas: [0.21425804]\n",
      "PERDIDAAAA antes: 0.2845664918422699\n",
      "Predicción post entrenamiento : [[0.72046685]]\n",
      "PERDIDAAAA despues: 0.25624731183052063\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "[[[0.6838333 ]\n",
      "  [0.75734574]\n",
      "  [0.75543642]\n",
      "  [0.75574112]\n",
      "  [0.75620496]\n",
      "  [0.75628531]\n",
      "  [0.75314587]\n",
      "  [0.74770576]]]\n",
      "ejemplar: [0.6838333  0.75734574 0.75543642 0.75574112 0.75620496 0.75628531\n",
      " 0.75314587 0.74770576]\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.73683757]]\n",
      "Lr que voy a aplicar en el lote: 16 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.6838333  0.75734574 0.75543642 0.75574112 0.75620496 0.75628531\n",
      "  0.75314587 0.74770576]]\n",
      "verdaderas salidas: [0.18132507]\n",
      "PERDIDAAAA antes: 0.30859413743019104\n",
      "Predicción post entrenamiento : [[0.7091461]]\n",
      "PERDIDAAAA despues: 0.2785950005054474\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "[[[0.75734574]\n",
      "  [0.75543642]\n",
      "  [0.75574112]\n",
      "  [0.75620496]\n",
      "  [0.75628531]\n",
      "  [0.75314587]\n",
      "  [0.74770576]\n",
      "  [0.73683757]]]\n",
      "ejemplar: [0.75734574 0.75543642 0.75574112 0.75620496 0.75628531 0.75314587\n",
      " 0.74770576 0.73683757]\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.71855456]]\n",
      "Lr que voy a aplicar en el lote: 17 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.75734574 0.75543642 0.75574112 0.75620496 0.75628531 0.75314587\n",
      "  0.74770576 0.73683757]]\n",
      "verdaderas salidas: [0.17512592]\n",
      "PERDIDAAAA antes: 0.2953146994113922\n",
      "Predicción post entrenamiento : [[0.6894418]]\n",
      "PERDIDAAAA despues: 0.2645207941532135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "[[[0.75543642]\n",
      "  [0.75574112]\n",
      "  [0.75620496]\n",
      "  [0.75628531]\n",
      "  [0.75314587]\n",
      "  [0.74770576]\n",
      "  [0.73683757]\n",
      "  [0.71855456]]]\n",
      "ejemplar: [0.75543642 0.75574112 0.75620496 0.75628531 0.75314587 0.74770576\n",
      " 0.73683757 0.71855456]\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.68887466]]\n",
      "Lr que voy a aplicar en el lote: 18 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.75543642 0.75574112 0.75620496 0.75628531 0.75314587 0.74770576\n",
      "  0.73683757 0.71855456]]\n",
      "verdaderas salidas: [0.14800465]\n",
      "PERDIDAAAA antes: 0.29254037141799927\n",
      "Predicción post entrenamiento : [[0.6591197]]\n",
      "PERDIDAAAA despues: 0.26123860478401184\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "[[[0.75574112]\n",
      "  [0.75620496]\n",
      "  [0.75628531]\n",
      "  [0.75314587]\n",
      "  [0.74770576]\n",
      "  [0.73683757]\n",
      "  [0.71855456]\n",
      "  [0.68887466]]]\n",
      "ejemplar: [0.75574112 0.75620496 0.75628531 0.75314587 0.74770576 0.73683757\n",
      " 0.71855456 0.68887466]\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.6583503]]\n",
      "Lr que voy a aplicar en el lote: 19 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.75574112 0.75620496 0.75628531 0.75314587 0.74770576 0.73683757\n",
      "  0.71855456 0.68887466]]\n",
      "verdaderas salidas: [0.15885316]\n",
      "PERDIDAAAA antes: 0.24949736893177032\n",
      "Predicción post entrenamiento : [[0.6295884]]\n",
      "PERDIDAAAA despues: 0.22159168124198914\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "[[[0.75620496]\n",
      "  [0.75628531]\n",
      "  [0.75314587]\n",
      "  [0.74770576]\n",
      "  [0.73683757]\n",
      "  [0.71855456]\n",
      "  [0.68887466]\n",
      "  [0.65835029]]]\n",
      "ejemplar: [0.75620496 0.75628531 0.75314587 0.74770576 0.73683757 0.71855456\n",
      " 0.68887466 0.65835029]\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.62803483]]\n",
      "Lr que voy a aplicar en el lote: 20 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.75620496 0.75628531 0.75314587 0.74770576 0.73683757 0.71855456\n",
      "  0.68887466 0.65835029]]\n",
      "verdaderas salidas: [0.19217358]\n",
      "PERDIDAAAA antes: 0.18997503817081451\n",
      "Predicción post entrenamiento : [[0.6001595]]\n",
      "PERDIDAAAA despues: 0.1664525419473648\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "[[[0.75628531]\n",
      "  [0.75314587]\n",
      "  [0.74770576]\n",
      "  [0.73683757]\n",
      "  [0.71855456]\n",
      "  [0.68887466]\n",
      "  [0.65835029]\n",
      "  [0.62803483]]]\n",
      "ejemplar: [0.75628531 0.75314587 0.74770576 0.73683757 0.71855456 0.68887466\n",
      " 0.65835029 0.62803483]\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.5974477]]\n",
      "Lr que voy a aplicar en el lote: 21 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.75628531 0.75314587 0.74770576 0.73683757 0.71855456 0.68887466\n",
      "  0.65835029 0.62803483]]\n",
      "verdaderas salidas: [0.18597443]\n",
      "PERDIDAAAA antes: 0.16931025683879852\n",
      "Predicción post entrenamiento : [[0.57122576]]\n",
      "PERDIDAAAA despues: 0.148418590426445\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "[[[0.75314587]\n",
      "  [0.74770576]\n",
      "  [0.73683757]\n",
      "  [0.71855456]\n",
      "  [0.68887466]\n",
      "  [0.65835029]\n",
      "  [0.62803483]\n",
      "  [0.59744769]]]\n",
      "ejemplar: [0.75314587 0.74770576 0.73683757 0.71855456 0.68887466 0.65835029\n",
      " 0.62803483 0.59744769]\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.56703186]]\n",
      "Lr que voy a aplicar en el lote: 22 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.75314587 0.74770576 0.73683757 0.71855456 0.68887466 0.65835029\n",
      "  0.62803483 0.59744769]]\n",
      "verdaderas salidas: [0.26695079]\n",
      "PERDIDAAAA antes: 0.090048648416996\n",
      "Predicción post entrenamiento : [[0.543312]]\n",
      "PERDIDAAAA despues: 0.07637552917003632\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "[[[0.74770576]\n",
      "  [0.73683757]\n",
      "  [0.71855456]\n",
      "  [0.68887466]\n",
      "  [0.65835029]\n",
      "  [0.62803483]\n",
      "  [0.59744769]\n",
      "  [0.56703186]]]\n",
      "ejemplar: [0.74770576 0.73683757 0.71855456 0.68887466 0.65835029 0.62803483\n",
      " 0.59744769 0.56703186]\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.537642]]\n",
      "Lr que voy a aplicar en el lote: 23 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.74770576 0.73683757 0.71855456 0.68887466 0.65835029 0.62803483\n",
      "  0.59744769 0.56703186]]\n",
      "verdaderas salidas: [0.29252228]\n",
      "PERDIDAAAA antes: 0.060083676129579544\n",
      "Predicción post entrenamiento : [[0.5166286]]\n",
      "PERDIDAAAA despues: 0.05022365227341652\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "[[[0.73683757]\n",
      "  [0.71855456]\n",
      "  [0.68887466]\n",
      "  [0.65835029]\n",
      "  [0.62803483]\n",
      "  [0.59744769]\n",
      "  [0.56703186]\n",
      "  [0.537642  ]]]\n",
      "ejemplar: [0.73683757 0.71855456 0.68887466 0.65835029 0.62803483 0.59744769\n",
      " 0.56703186 0.537642  ]\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.5094212]]\n",
      "Lr que voy a aplicar en el lote: 24 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.73683757 0.71855456 0.68887466 0.65835029 0.62803483 0.59744769\n",
      "  0.56703186 0.537642  ]]\n",
      "verdaderas salidas: [0.31770632]\n",
      "PERDIDAAAA antes: 0.036754608154296875\n",
      "Predicción post entrenamiento : [[0.49072254]]\n",
      "PERDIDAAAA despues: 0.029934613034129143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "[[[0.71855456]\n",
      "  [0.68887466]\n",
      "  [0.65835029]\n",
      "  [0.62803483]\n",
      "  [0.59744769]\n",
      "  [0.56703186]\n",
      "  [0.537642  ]\n",
      "  [0.50942123]]]\n",
      "ejemplar: [0.71855456 0.68887466 0.65835029 0.62803483 0.59744769 0.56703186\n",
      " 0.537642   0.50942123]\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.48228905]]\n",
      "Lr que voy a aplicar en el lote: 25 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.71855456 0.68887466 0.65835029 0.62803483 0.59744769 0.56703186\n",
      "  0.537642   0.50942123]]\n",
      "verdaderas salidas: [0.31266951]\n",
      "PERDIDAAAA antes: 0.02877078577876091\n",
      "Predicción post entrenamiento : [[0.4651478]]\n",
      "PERDIDAAAA despues: 0.02324962429702282\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "[[[0.68887466]\n",
      "  [0.65835029]\n",
      "  [0.62803483]\n",
      "  [0.59744769]\n",
      "  [0.56703186]\n",
      "  [0.537642  ]\n",
      "  [0.50942123]\n",
      "  [0.48228905]]]\n",
      "ejemplar: [0.68887466 0.65835029 0.62803483 0.59744769 0.56703186 0.537642\n",
      " 0.50942123 0.48228905]\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.45606393]]\n",
      "Lr que voy a aplicar en el lote: 26 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.68887466 0.65835029 0.62803483 0.59744769 0.56703186 0.537642\n",
      "  0.50942123 0.48228905]]\n",
      "verdaderas salidas: [0.28903526]\n",
      "PERDIDAAAA antes: 0.027898574247956276\n",
      "Predicción post entrenamiento : [[0.44079557]]\n",
      "PERDIDAAAA despues: 0.023031191900372505\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "[[[0.65835029]\n",
      "  [0.62803483]\n",
      "  [0.59744769]\n",
      "  [0.56703186]\n",
      "  [0.537642  ]\n",
      "  [0.50942123]\n",
      "  [0.48228905]\n",
      "  [0.45606393]]]\n",
      "ejemplar: [0.65835029 0.62803483 0.59744769 0.56703186 0.537642   0.50942123\n",
      " 0.48228905 0.45606393]\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.4320472]]\n",
      "Lr que voy a aplicar en el lote: 27 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.65835029 0.62803483 0.59744769 0.56703186 0.537642   0.50942123\n",
      "  0.48228905 0.45606393]]\n",
      "verdaderas salidas: [0.28283611]\n",
      "PERDIDAAAA antes: 0.022263946011662483\n",
      "Predicción post entrenamiento : [[0.41886488]]\n",
      "PERDIDAAAA despues: 0.0185038261115551\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "[[[0.62803483]\n",
      "  [0.59744769]\n",
      "  [0.56703186]\n",
      "  [0.537642  ]\n",
      "  [0.50942123]\n",
      "  [0.48228905]\n",
      "  [0.45606393]\n",
      "  [0.43204719]]]\n",
      "ejemplar: [0.62803483 0.59744769 0.56703186 0.537642   0.50942123 0.48228905\n",
      " 0.45606393 0.43204719]\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.41052324]]\n",
      "Lr que voy a aplicar en el lote: 28 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.62803483 0.59744769 0.56703186 0.537642   0.50942123 0.48228905\n",
      "  0.45606393 0.43204719]]\n",
      "verdaderas salidas: [0.29949632]\n",
      "PERDIDAAAA antes: 0.012326975353062153\n",
      "Predicción post entrenamiento : [[0.3987538]]\n",
      "PERDIDAAAA despues: 0.009852045215666294\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "[[[0.59744769]\n",
      "  [0.56703186]\n",
      "  [0.537642  ]\n",
      "  [0.50942123]\n",
      "  [0.48228905]\n",
      "  [0.45606393]\n",
      "  [0.43204719]\n",
      "  [0.41052324]]]\n",
      "ejemplar: [0.59744769 0.56703186 0.537642   0.50942123 0.48228905 0.45606393\n",
      " 0.43204719 0.41052324]\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.39083043]]\n",
      "Lr que voy a aplicar en el lote: 29 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.59744769 0.56703186 0.537642   0.50942123 0.48228905 0.45606393\n",
      "  0.43204719 0.41052324]]\n",
      "verdaderas salidas: [0.27586207]\n",
      "PERDIDAAAA antes: 0.013217723928391933\n",
      "Predicción post entrenamiento : [[0.3803504]]\n",
      "PERDIDAAAA despues: 0.010917813517153263\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "[[[0.56703186]\n",
      "  [0.537642  ]\n",
      "  [0.50942123]\n",
      "  [0.48228905]\n",
      "  [0.45606393]\n",
      "  [0.43204719]\n",
      "  [0.41052324]\n",
      "  [0.39083043]]]\n",
      "ejemplar: [0.56703186 0.537642   0.50942123 0.48228905 0.45606393 0.43204719\n",
      " 0.41052324 0.39083043]\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.37291473]]\n",
      "Lr que voy a aplicar en el lote: 30 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.56703186 0.537642   0.50942123 0.48228905 0.45606393 0.43204719\n",
      "  0.41052324 0.39083043]]\n",
      "verdaderas salidas: [0.27469973]\n",
      "PERDIDAAAA antes: 0.009646188467741013\n",
      "Predicción post entrenamiento : [[0.36372268]]\n",
      "PERDIDAAAA despues: 0.00792508851736784\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "[[[0.537642  ]\n",
      "  [0.50942123]\n",
      "  [0.48228905]\n",
      "  [0.45606393]\n",
      "  [0.43204719]\n",
      "  [0.41052324]\n",
      "  [0.39083043]\n",
      "  [0.37291473]]]\n",
      "ejemplar: [0.537642   0.50942123 0.48228905 0.45606393 0.43204719 0.41052324\n",
      " 0.39083043 0.37291473]\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.35682416]]\n",
      "Lr que voy a aplicar en el lote: 31 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.537642   0.50942123 0.48228905 0.45606393 0.43204719 0.41052324\n",
      "  0.39083043 0.37291473]]\n",
      "verdaderas salidas: [0.27547462]\n",
      "PERDIDAAAA antes: 0.006617749575525522\n",
      "Predicción post entrenamiento : [[0.34870306]]\n",
      "PERDIDAAAA despues: 0.0053624059073626995\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "[[[0.50942123]\n",
      "  [0.48228905]\n",
      "  [0.45606393]\n",
      "  [0.43204719]\n",
      "  [0.41052324]\n",
      "  [0.39083043]\n",
      "  [0.37291473]\n",
      "  [0.35682416]]]\n",
      "ejemplar: [0.50942123 0.48228905 0.45606393 0.43204719 0.41052324 0.39083043\n",
      " 0.37291473 0.35682416]\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.34234208]]\n",
      "Lr que voy a aplicar en el lote: 32 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.50942123 0.48228905 0.45606393 0.43204719 0.41052324 0.39083043\n",
      "  0.37291473 0.35682416]]\n",
      "verdaderas salidas: [0.33475397]\n",
      "PERDIDAAAA antes: 5.757953840657137e-05\n",
      "Predicción post entrenamiento : [[0.33531123]]\n",
      "PERDIDAAAA despues: 3.1055390081746737e-07\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "[[[0.48228905]\n",
      "  [0.45606393]\n",
      "  [0.43204719]\n",
      "  [0.41052324]\n",
      "  [0.39083043]\n",
      "  [0.37291473]\n",
      "  [0.35682416]\n",
      "  [0.34234208]]]\n",
      "ejemplar: [0.48228905 0.45606393 0.43204719 0.41052324 0.39083043 0.37291473\n",
      " 0.35682416 0.34234208]\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.3294858]]\n",
      "Lr que voy a aplicar en el lote: 33 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.48228905 0.45606393 0.43204719 0.41052324 0.39083043 0.37291473\n",
      "  0.35682416 0.34234208]]\n",
      "verdaderas salidas: [0.35567609]\n",
      "PERDIDAAAA antes: 0.0006859308341518044\n",
      "Predicción post entrenamiento : [[0.32347095]]\n",
      "PERDIDAAAA despues: 0.0010371706448495388\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "[[[0.45606393]\n",
      "  [0.43204719]\n",
      "  [0.41052324]\n",
      "  [0.39083043]\n",
      "  [0.37291473]\n",
      "  [0.35682416]\n",
      "  [0.34234208]\n",
      "  [0.3294858 ]]]\n",
      "ejemplar: [0.45606393 0.43204719 0.41052324 0.39083043 0.37291473 0.35682416\n",
      " 0.34234208 0.3294858 ]\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.31819415]]\n",
      "Lr que voy a aplicar en el lote: 34 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.45606393 0.43204719 0.41052324 0.39083043 0.37291473 0.35682416\n",
      "  0.34234208 0.3294858 ]]\n",
      "verdaderas salidas: [0.3366912]\n",
      "PERDIDAAAA antes: 0.00034214084735140204\n",
      "Predicción post entrenamiento : [[0.3130841]]\n",
      "PERDIDAAAA despues: 0.0005572953959926963\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "[[[0.43204719]\n",
      "  [0.41052324]\n",
      "  [0.39083043]\n",
      "  [0.37291473]\n",
      "  [0.35682416]\n",
      "  [0.34234208]\n",
      "  [0.3294858 ]\n",
      "  [0.31819415]]]\n",
      "ejemplar: [0.43204719 0.41052324 0.39083043 0.37291473 0.35682416 0.34234208\n",
      " 0.3294858  0.31819415]\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.30838954]]\n",
      "Lr que voy a aplicar en el lote: 35 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.43204719 0.41052324 0.39083043 0.37291473 0.35682416 0.34234208\n",
      "  0.3294858  0.31819415]]\n",
      "verdaderas salidas: [0.33359163]\n",
      "PERDIDAAAA antes: 0.0006351456395350397\n",
      "Predicción post entrenamiento : [[0.3039968]]\n",
      "PERDIDAAAA despues: 0.0008758544572629035\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "[[[0.41052324]\n",
      "  [0.39083043]\n",
      "  [0.37291473]\n",
      "  [0.35682416]\n",
      "  [0.34234208]\n",
      "  [0.3294858 ]\n",
      "  [0.31819415]\n",
      "  [0.30838954]]]\n",
      "ejemplar: [0.41052324 0.39083043 0.37291473 0.35682416 0.34234208 0.3294858\n",
      " 0.31819415 0.30838954]\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.2998327]]\n",
      "Lr que voy a aplicar en el lote: 36 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.41052324 0.39083043 0.37291473 0.35682416 0.34234208 0.3294858\n",
      "  0.31819415 0.30838954]]\n",
      "verdaderas salidas: [0.3847346]\n",
      "PERDIDAAAA antes: 0.007208332419395447\n",
      "Predicción post entrenamiento : [[0.29606965]]\n",
      "PERDIDAAAA despues: 0.007861473597586155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "[[[0.39083043]\n",
      "  [0.37291473]\n",
      "  [0.35682416]\n",
      "  [0.34234208]\n",
      "  [0.3294858 ]\n",
      "  [0.31819415]\n",
      "  [0.30838954]\n",
      "  [0.2998327 ]]]\n",
      "ejemplar: [0.39083043 0.37291473 0.35682416 0.34234208 0.3294858  0.31819415\n",
      " 0.30838954 0.2998327 ]\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.29236263]]\n",
      "Lr que voy a aplicar en el lote: 37 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.39083043 0.37291473 0.35682416 0.34234208 0.3294858  0.31819415\n",
      "  0.30838954 0.2998327 ]]\n",
      "verdaderas salidas: [0.57109647]\n",
      "PERDIDAAAA antes: 0.07769256085157394\n",
      "Predicción post entrenamiento : [[0.28947875]]\n",
      "PERDIDAAAA despues: 0.07930854707956314\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "[[[0.37291473]\n",
      "  [0.35682416]\n",
      "  [0.34234208]\n",
      "  [0.3294858 ]\n",
      "  [0.31819415]\n",
      "  [0.30838954]\n",
      "  [0.2998327 ]\n",
      "  [0.29236263]]]\n",
      "ejemplar: [0.37291473 0.35682416 0.34234208 0.3294858  0.31819415 0.30838954\n",
      " 0.2998327  0.29236263]\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.2861938]]\n",
      "Lr que voy a aplicar en el lote: 38 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.37291473 0.35682416 0.34234208 0.3294858  0.31819415 0.30838954\n",
      "  0.2998327  0.29236263]]\n",
      "verdaderas salidas: [0.59628051]\n",
      "PERDIDAAAA antes: 0.09615378081798553\n",
      "Predicción post entrenamiento : [[0.2840941]]\n",
      "PERDIDAAAA despues: 0.09746035933494568\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "[[[0.35682416]\n",
      "  [0.34234208]\n",
      "  [0.3294858 ]\n",
      "  [0.31819415]\n",
      "  [0.30838954]\n",
      "  [0.2998327 ]\n",
      "  [0.29236263]\n",
      "  [0.28619379]]]\n",
      "ejemplar: [0.35682416 0.34234208 0.3294858  0.31819415 0.30838954 0.2998327\n",
      " 0.29236263 0.28619379]\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.28119957]]\n",
      "Lr que voy a aplicar en el lote: 39 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.35682416 0.34234208 0.3294858  0.31819415 0.30838954 0.2998327\n",
      "  0.29236263 0.28619379]]\n",
      "verdaderas salidas: [0.57458349]\n",
      "PERDIDAAAA antes: 0.0860741138458252\n",
      "Predicción post entrenamiento : [[0.27978677]]\n",
      "PERDIDAAAA despues: 0.0869050994515419\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "[[[0.34234208]\n",
      "  [0.3294858 ]\n",
      "  [0.31819415]\n",
      "  [0.30838954]\n",
      "  [0.2998327 ]\n",
      "  [0.29236263]\n",
      "  [0.28619379]\n",
      "  [0.28119957]]]\n",
      "ejemplar: [0.34234208 0.3294858  0.31819415 0.30838954 0.2998327  0.29236263\n",
      " 0.28619379 0.28119957]\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.2772468]]\n",
      "Lr que voy a aplicar en el lote: 40 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.34234208 0.3294858  0.31819415 0.30838954 0.2998327  0.29236263\n",
      "  0.28619379 0.28119957]]\n",
      "verdaderas salidas: [0.60635413]\n",
      "PERDIDAAAA antes: 0.10831162333488464\n",
      "Predicción post entrenamiento : [[0.27646038]]\n",
      "PERDIDAAAA despues: 0.10882987827062607\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "[[[0.3294858 ]\n",
      "  [0.31819415]\n",
      "  [0.30838954]\n",
      "  [0.2998327 ]\n",
      "  [0.29236263]\n",
      "  [0.28619379]\n",
      "  [0.28119957]\n",
      "  [0.2772468 ]]]\n",
      "ejemplar: [0.3294858  0.31819415 0.30838954 0.2998327  0.29236263 0.28619379\n",
      " 0.28119957 0.2772468 ]\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.27425078]]\n",
      "Lr que voy a aplicar en el lote: 41 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.3294858  0.31819415 0.30838954 0.2998327  0.29236263 0.28619379\n",
      "  0.28119957 0.2772468 ]]\n",
      "verdaderas salidas: [0.58465711]\n",
      "PERDIDAAAA antes: 0.09635210782289505\n",
      "Predicción post entrenamiento : [[0.27400014]]\n",
      "PERDIDAAAA despues: 0.09650776535272598\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "[[[0.31819415]\n",
      "  [0.30838954]\n",
      "  [0.2998327 ]\n",
      "  [0.29236263]\n",
      "  [0.28619379]\n",
      "  [0.28119957]\n",
      "  [0.2772468 ]\n",
      "  [0.27425078]]]\n",
      "ejemplar: [0.31819415 0.30838954 0.2998327  0.29236263 0.28619379 0.28119957\n",
      " 0.2772468  0.27425078]\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.2720936]]\n",
      "Lr que voy a aplicar en el lote: 42 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.31819415 0.30838954 0.2998327  0.29236263 0.28619379 0.28119957\n",
      "  0.2772468  0.27425078]]\n",
      "verdaderas salidas: [0.56877179]\n",
      "PERDIDAAAA antes: 0.08801794797182083\n",
      "Predicción post entrenamiento : [[0.2722919]]\n",
      "PERDIDAAAA despues: 0.0879003182053566\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "[[[0.30838954]\n",
      "  [0.2998327 ]\n",
      "  [0.29236263]\n",
      "  [0.28619379]\n",
      "  [0.28119957]\n",
      "  [0.2772468 ]\n",
      "  [0.27425078]\n",
      "  [0.27209359]]]\n",
      "ejemplar: [0.30838954 0.2998327  0.29236263 0.28619379 0.28119957 0.2772468\n",
      " 0.27425078 0.27209359]\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.2706621]]\n",
      "Lr que voy a aplicar en el lote: 43 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.30838954 0.2998327  0.29236263 0.28619379 0.28119957 0.2772468\n",
      "  0.27425078 0.27209359]]\n",
      "verdaderas salidas: [0.64277412]\n",
      "PERDIDAAAA antes: 0.13846734166145325\n",
      "Predicción post entrenamiento : [[0.27133626]]\n",
      "PERDIDAAAA despues: 0.1379660815000534\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "[[[0.2998327 ]\n",
      "  [0.29236263]\n",
      "  [0.28619379]\n",
      "  [0.28119957]\n",
      "  [0.2772468 ]\n",
      "  [0.27425078]\n",
      "  [0.27209359]\n",
      "  [0.2706621 ]]]\n",
      "ejemplar: [0.2998327  0.29236263 0.28619379 0.28119957 0.2772468  0.27425078\n",
      " 0.27209359 0.2706621 ]\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.2699578]]\n",
      "Lr que voy a aplicar en el lote: 44 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.2998327  0.29236263 0.28619379 0.28119957 0.2772468  0.27425078\n",
      "  0.27209359 0.2706621 ]]\n",
      "verdaderas salidas: [0.66175901]\n",
      "PERDIDAAAA antes: 0.15350818634033203\n",
      "Predicción post entrenamiento : [[0.2710758]]\n",
      "PERDIDAAAA despues: 0.15263338387012482\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "[[[0.29236263]\n",
      "  [0.28619379]\n",
      "  [0.28119957]\n",
      "  [0.2772468 ]\n",
      "  [0.27425078]\n",
      "  [0.27209359]\n",
      "  [0.2706621 ]\n",
      "  [0.26995781]]]\n",
      "ejemplar: [0.29236263 0.28619379 0.28119957 0.2772468  0.27425078 0.27209359\n",
      " 0.2706621  0.26995781]\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.2699346]]\n",
      "Lr que voy a aplicar en el lote: 45 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.29236263 0.28619379 0.28119957 0.2772468  0.27425078 0.27209359\n",
      "  0.2706621  0.26995781]]\n",
      "verdaderas salidas: [0.67299496]\n",
      "PERDIDAAAA antes: 0.1624576598405838\n",
      "Predicción post entrenamiento : [[0.27151954]]\n",
      "PERDIDAAAA despues: 0.16118252277374268\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "[[[0.28619379]\n",
      "  [0.28119957]\n",
      "  [0.2772468 ]\n",
      "  [0.27425078]\n",
      "  [0.27209359]\n",
      "  [0.2706621 ]\n",
      "  [0.26995781]\n",
      "  [0.26993459]]]\n",
      "ejemplar: [0.28619379 0.28119957 0.2772468  0.27425078 0.27209359 0.2706621\n",
      " 0.26995781 0.26993459]\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.27060914]]\n",
      "Lr que voy a aplicar en el lote: 46 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.28619379 0.28119957 0.2772468  0.27425078 0.27209359 0.2706621\n",
      "  0.26995781 0.26993459]]\n",
      "verdaderas salidas: [0.7105773]\n",
      "PERDIDAAAA antes: 0.19357198476791382\n",
      "Predicción post entrenamiento : [[0.27265462]]\n",
      "PERDIDAAAA despues: 0.19177627563476562\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "[[[0.28119957]\n",
      "  [0.2772468 ]\n",
      "  [0.27425078]\n",
      "  [0.27209359]\n",
      "  [0.2706621 ]\n",
      "  [0.26995781]\n",
      "  [0.26993459]\n",
      "  [0.27060914]]]\n",
      "ejemplar: [0.28119957 0.2772468  0.27425078 0.27209359 0.2706621  0.26995781\n",
      " 0.26993459 0.27060914]\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.27195147]]\n",
      "Lr que voy a aplicar en el lote: 47 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.28119957 0.2772468  0.27425078 0.27209359 0.2706621  0.26995781\n",
      "  0.26993459 0.27060914]]\n",
      "verdaderas salidas: [0.7039907]\n",
      "PERDIDAAAA antes: 0.1866578906774521\n",
      "Predicción post entrenamiento : [[0.27441004]]\n",
      "PERDIDAAAA despues: 0.1845395416021347\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "[[[0.2772468 ]\n",
      "  [0.27425078]\n",
      "  [0.27209359]\n",
      "  [0.2706621 ]\n",
      "  [0.26995781]\n",
      "  [0.26993459]\n",
      "  [0.27060914]\n",
      "  [0.27195147]]]\n",
      "ejemplar: [0.2772468  0.27425078 0.27209359 0.2706621  0.26995781 0.26993459\n",
      " 0.27060914 0.27195147]\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.27389434]]\n",
      "Lr que voy a aplicar en el lote: 48 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.2772468  0.27425078 0.27209359 0.2706621  0.26995781 0.26993459\n",
      "  0.27060914 0.27195147]]\n",
      "verdaderas salidas: [0.7272375]\n",
      "PERDIDAAAA antes: 0.20552004873752594\n",
      "Predicción post entrenamiento : [[0.27675435]]\n",
      "PERDIDAAAA despues: 0.2029350847005844\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "[[[0.27425078]\n",
      "  [0.27209359]\n",
      "  [0.2706621 ]\n",
      "  [0.26995781]\n",
      "  [0.26993459]\n",
      "  [0.27060914]\n",
      "  [0.27195147]\n",
      "  [0.27389434]]]\n",
      "ejemplar: [0.27425078 0.27209359 0.2706621  0.26995781 0.26993459 0.27060914\n",
      " 0.27195147 0.27389434]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.2764108]]\n",
      "Lr que voy a aplicar en el lote: 49 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.27425078 0.27209359 0.2706621  0.26995781 0.26993459 0.27060914\n",
      "  0.27195147 0.27389434]]\n",
      "verdaderas salidas: [0.72258814]\n",
      "PERDIDAAAA antes: 0.19907420873641968\n",
      "Predicción post entrenamiento : [[0.27964365]]\n",
      "PERDIDAAAA despues: 0.19619980454444885\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "[[[0.27209359]\n",
      "  [0.2706621 ]\n",
      "  [0.26995781]\n",
      "  [0.26993459]\n",
      "  [0.27060914]\n",
      "  [0.27195147]\n",
      "  [0.27389434]\n",
      "  [0.27641079]]]\n",
      "ejemplar: [0.27209359 0.2706621  0.26995781 0.26993459 0.27060914 0.27195147\n",
      " 0.27389434 0.27641079]\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.2794596]]\n",
      "Lr que voy a aplicar en el lote: 50 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.27209359 0.2706621  0.26995781 0.26993459 0.27060914 0.27195147\n",
      "  0.27389434 0.27641079]]\n",
      "verdaderas salidas: [0.77179388]\n",
      "PERDIDAAAA antes: 0.24239307641983032\n",
      "Predicción post entrenamiento : [[0.2830502]]\n",
      "PERDIDAAAA despues: 0.23887039721012115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "[[[0.2706621 ]\n",
      "  [0.26995781]\n",
      "  [0.26993459]\n",
      "  [0.27060914]\n",
      "  [0.27195147]\n",
      "  [0.27389434]\n",
      "  [0.27641079]\n",
      "  [0.2794596 ]]]\n",
      "ejemplar: [0.2706621  0.26995781 0.26993459 0.27060914 0.27195147 0.27389434\n",
      " 0.27641079 0.2794596 ]\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.2830181]]\n",
      "Lr que voy a aplicar en el lote: 51 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.2706621  0.26995781 0.26993459 0.27060914 0.27195147 0.27389434\n",
      "  0.27641079 0.2794596 ]]\n",
      "verdaderas salidas: [0.72452538]\n",
      "PERDIDAAAA antes: 0.19492867588996887\n",
      "Predicción post entrenamiento : [[0.28692174]]\n",
      "PERDIDAAAA despues: 0.19149695336818695\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "[[[0.26995781]\n",
      "  [0.26993459]\n",
      "  [0.27060914]\n",
      "  [0.27195147]\n",
      "  [0.27389434]\n",
      "  [0.27641079]\n",
      "  [0.2794596 ]\n",
      "  [0.28301811]]]\n",
      "ejemplar: [0.26995781 0.26993459 0.27060914 0.27195147 0.27389434 0.27641079\n",
      " 0.2794596  0.28301811]\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.2870395]]\n",
      "Lr que voy a aplicar en el lote: 52 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.26995781 0.26993459 0.27060914 0.27195147 0.27389434 0.27641079\n",
      "  0.2794596  0.28301811]]\n",
      "verdaderas salidas: [0.67105773]\n",
      "PERDIDAAAA antes: 0.14746998250484467\n",
      "Predicción post entrenamiento : [[0.29115584]]\n",
      "PERDIDAAAA despues: 0.14432542026042938\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "[[[0.26993459]\n",
      "  [0.27060914]\n",
      "  [0.27195147]\n",
      "  [0.27389434]\n",
      "  [0.27641079]\n",
      "  [0.2794596 ]\n",
      "  [0.28301811]\n",
      "  [0.28703949]]]\n",
      "ejemplar: [0.26993459 0.27060914 0.27195147 0.27389434 0.27641079 0.2794596\n",
      " 0.28301811 0.28703949]\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.29141966]]\n",
      "Lr que voy a aplicar en el lote: 53 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.26993459 0.27060914 0.27195147 0.27389434 0.27641079 0.2794596\n",
      "  0.28301811 0.28703949]]\n",
      "verdaderas salidas: [0.67376986]\n",
      "PERDIDAAAA antes: 0.14619165658950806\n",
      "Predicción post entrenamiento : [[0.29573277]]\n",
      "PERDIDAAAA despues: 0.14291201531887054\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "[[[0.27060914]\n",
      "  [0.27195147]\n",
      "  [0.27389434]\n",
      "  [0.27641079]\n",
      "  [0.2794596 ]\n",
      "  [0.28301811]\n",
      "  [0.28703949]\n",
      "  [0.29141966]]]\n",
      "ejemplar: [0.27060914 0.27195147 0.27389434 0.27641079 0.2794596  0.28301811\n",
      " 0.28703949 0.29141966]\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.2961397]]\n",
      "Lr que voy a aplicar en el lote: 54 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.27060914 0.27195147 0.27389434 0.27641079 0.2794596  0.28301811\n",
      "  0.28703949 0.29141966]]\n",
      "verdaderas salidas: [0.71445176]\n",
      "PERDIDAAAA antes: 0.17498502135276794\n",
      "Predicción post entrenamiento : [[0.30064082]]\n",
      "PERDIDAAAA despues: 0.17123951017856598\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "[[[0.27195147]\n",
      "  [0.27389434]\n",
      "  [0.27641079]\n",
      "  [0.2794596 ]\n",
      "  [0.28301811]\n",
      "  [0.28703949]\n",
      "  [0.29141966]\n",
      "  [0.29613969]]]\n",
      "ejemplar: [0.27195147 0.27389434 0.27641079 0.2794596  0.28301811 0.28703949\n",
      " 0.29141966 0.29613969]\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.3011846]]\n",
      "Lr que voy a aplicar en el lote: 55 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.27195147 0.27389434 0.27641079 0.2794596  0.28301811 0.28703949\n",
      "  0.29141966 0.29613969]]\n",
      "verdaderas salidas: [0.74389771]\n",
      "PERDIDAAAA antes: 0.19599492847919464\n",
      "Predicción post entrenamiento : [[0.30598456]]\n",
      "PERDIDAAAA despues: 0.19176794588565826\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "[[[0.27389434]\n",
      "  [0.27641079]\n",
      "  [0.2794596 ]\n",
      "  [0.28301811]\n",
      "  [0.28703949]\n",
      "  [0.29141966]\n",
      "  [0.29613969]\n",
      "  [0.30118459]]]\n",
      "ejemplar: [0.27389434 0.27641079 0.2794596  0.28301811 0.28703949 0.29141966\n",
      " 0.29613969 0.30118459]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.30665752]]\n",
      "Lr que voy a aplicar en el lote: 56 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.27389434 0.27641079 0.2794596  0.28301811 0.28703949 0.29141966\n",
      "  0.29613969 0.30118459]]\n",
      "verdaderas salidas: [0.72258814]\n",
      "PERDIDAAAA antes: 0.17299826443195343\n",
      "Predicción post entrenamiento : [[0.3116948]]\n",
      "PERDIDAAAA despues: 0.16883331537246704\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "[[[0.27641079]\n",
      "  [0.2794596 ]\n",
      "  [0.28301811]\n",
      "  [0.28703949]\n",
      "  [0.29141966]\n",
      "  [0.29613969]\n",
      "  [0.30118459]\n",
      "  [0.30665752]]]\n",
      "ejemplar: [0.27641079 0.2794596  0.28301811 0.28703949 0.29141966 0.29613969\n",
      " 0.30118459 0.30665752]\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.31249177]]\n",
      "Lr que voy a aplicar en el lote: 57 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.27641079 0.2794596  0.28301811 0.28703949 0.29141966 0.29613969\n",
      "  0.30118459 0.30665752]]\n",
      "verdaderas salidas: [0.69934134]\n",
      "PERDIDAAAA antes: 0.1496526002883911\n",
      "Predicción post entrenamiento : [[0.3176725]]\n",
      "PERDIDAAAA despues: 0.14567112922668457\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "[[[0.2794596 ]\n",
      "  [0.28301811]\n",
      "  [0.28703949]\n",
      "  [0.29141966]\n",
      "  [0.29613969]\n",
      "  [0.30118459]\n",
      "  [0.30665752]\n",
      "  [0.31249177]]]\n",
      "ejemplar: [0.2794596  0.28301811 0.28703949 0.29141966 0.29613969 0.30118459\n",
      " 0.30665752 0.31249177]\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.31858695]]\n",
      "Lr que voy a aplicar en el lote: 58 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.2794596  0.28301811 0.28703949 0.29141966 0.29613969 0.30118459\n",
      "  0.30665752 0.31249177]]\n",
      "verdaderas salidas: [0.73731112]\n",
      "PERDIDAAAA antes: 0.17532993853092194\n",
      "Predicción post entrenamiento : [[0.32401496]]\n",
      "PERDIDAAAA despues: 0.17081372439861298\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "[[[0.28301811]\n",
      "  [0.28703949]\n",
      "  [0.29141966]\n",
      "  [0.29613969]\n",
      "  [0.30118459]\n",
      "  [0.30665752]\n",
      "  [0.31249177]\n",
      "  [0.31858695]]]\n",
      "ejemplar: [0.28301811 0.28703949 0.29141966 0.29613969 0.30118459 0.30665752\n",
      " 0.31249177 0.31858695]\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.32504132]]\n",
      "Lr que voy a aplicar en el lote: 59 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.28301811 0.28703949 0.29141966 0.29613969 0.30118459 0.30665752\n",
      "  0.31249177 0.31858695]]\n",
      "verdaderas salidas: [0.7214258]\n",
      "PERDIDAAAA antes: 0.15712067484855652\n",
      "Predicción post entrenamiento : [[0.33067212]]\n",
      "PERDIDAAAA despues: 0.15268847346305847\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "[[[0.28703949]\n",
      "  [0.29141966]\n",
      "  [0.29613969]\n",
      "  [0.30118459]\n",
      "  [0.30665752]\n",
      "  [0.31249177]\n",
      "  [0.31858695]\n",
      "  [0.32504132]]]\n",
      "ejemplar: [0.28703949 0.29141966 0.29613969 0.30118459 0.30665752 0.31249177\n",
      " 0.31858695 0.32504132]\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.33180436]]\n",
      "Lr que voy a aplicar en el lote: 60 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.28703949 0.29141966 0.29613969 0.30118459 0.30665752 0.31249177\n",
      "  0.31858695 0.32504132]]\n",
      "verdaderas salidas: [0.71871368]\n",
      "PERDIDAAAA antes: 0.14969883859157562\n",
      "Predicción post entrenamiento : [[0.3376274]]\n",
      "PERDIDAAAA despues: 0.14522676169872284\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "[[[0.29141966]\n",
      "  [0.29613969]\n",
      "  [0.30118459]\n",
      "  [0.30665752]\n",
      "  [0.31249177]\n",
      "  [0.31858695]\n",
      "  [0.32504132]\n",
      "  [0.33180436]]]\n",
      "ejemplar: [0.29141966 0.29613969 0.30118459 0.30665752 0.31249177 0.31858695\n",
      " 0.32504132 0.33180436]\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.33886078]]\n",
      "Lr que voy a aplicar en el lote: 61 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.29141966 0.29613969 0.30118459 0.30665752 0.31249177 0.31858695\n",
      "  0.32504132 0.33180436]]\n",
      "verdaderas salidas: [0.6741573]\n",
      "PERDIDAAAA antes: 0.11242377012968063\n",
      "Predicción post entrenamiento : [[0.34474838]]\n",
      "PERDIDAAAA despues: 0.10851025581359863\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "[[[0.29613969]\n",
      "  [0.30118459]\n",
      "  [0.30665752]\n",
      "  [0.31249177]\n",
      "  [0.31858695]\n",
      "  [0.32504132]\n",
      "  [0.33180436]\n",
      "  [0.33886078]]]\n",
      "ejemplar: [0.29613969 0.30118459 0.30665752 0.31249177 0.31858695 0.32504132\n",
      " 0.33180436 0.33886078]\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.34608433]]\n",
      "Lr que voy a aplicar en el lote: 62 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.29613969 0.30118459 0.30665752 0.31249177 0.31858695 0.32504132\n",
      "  0.33180436 0.33886078]]\n",
      "verdaderas salidas: [0.69856645]\n",
      "PERDIDAAAA antes: 0.12424363940954208\n",
      "Predicción post entrenamiento : [[0.35210767]]\n",
      "PERDIDAAAA despues: 0.12003367394208908\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "[[[0.30118459]\n",
      "  [0.30665752]\n",
      "  [0.31249177]\n",
      "  [0.31858695]\n",
      "  [0.32504132]\n",
      "  [0.33180436]\n",
      "  [0.33886078]\n",
      "  [0.34608433]]]\n",
      "ejemplar: [0.30118459 0.30665752 0.31249177 0.31858695 0.32504132 0.33180436\n",
      " 0.33886078 0.34608433]\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.35354885]]\n",
      "Lr que voy a aplicar en el lote: 63 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.30118459 0.30665752 0.31249177 0.31858695 0.32504132 0.33180436\n",
      "  0.33886078 0.34608433]]\n",
      "verdaderas salidas: [0.72103836]\n",
      "PERDIDAAAA antes: 0.1350485235452652\n",
      "Predicción post entrenamiento : [[0.35973853]]\n",
      "PERDIDAAAA despues: 0.13053755462169647\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "[[[0.30665752]\n",
      "  [0.31249177]\n",
      "  [0.31858695]\n",
      "  [0.32504132]\n",
      "  [0.33180436]\n",
      "  [0.33886078]\n",
      "  [0.34608433]\n",
      "  [0.35354885]]]\n",
      "ejemplar: [0.30665752 0.31249177 0.31858695 0.32504132 0.33180436 0.33886078\n",
      " 0.34608433 0.35354885]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.3612879]]\n",
      "Lr que voy a aplicar en el lote: 64 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.30665752 0.31249177 0.31858695 0.32504132 0.33180436 0.33886078\n",
      "  0.34608433 0.35354885]]\n",
      "verdaderas salidas: [0.72258814]\n",
      "PERDIDAAAA antes: 0.13053785264492035\n",
      "Predicción post entrenamiento : [[0.36765316]]\n",
      "PERDIDAAAA despues: 0.12597882747650146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "[[[0.31249177]\n",
      "  [0.31858695]\n",
      "  [0.32504132]\n",
      "  [0.33180436]\n",
      "  [0.33886078]\n",
      "  [0.34608433]\n",
      "  [0.35354885]\n",
      "  [0.36128789]]]\n",
      "ejemplar: [0.31249177 0.31858695 0.32504132 0.33180436 0.33886078 0.34608433\n",
      " 0.35354885 0.36128789]\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.3693045]]\n",
      "Lr que voy a aplicar en el lote: 65 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.31249177 0.31858695 0.32504132 0.33180436 0.33886078 0.34608433\n",
      "  0.35354885 0.36128789]]\n",
      "verdaderas salidas: [0.75629601]\n",
      "PERDIDAAAA antes: 0.14976245164871216\n",
      "Predicción post entrenamiento : [[0.37586594]]\n",
      "PERDIDAAAA despues: 0.14472706615924835\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "[[[0.31858695]\n",
      "  [0.32504132]\n",
      "  [0.33180436]\n",
      "  [0.33886078]\n",
      "  [0.34608433]\n",
      "  [0.35354885]\n",
      "  [0.36128789]\n",
      "  [0.36930451]]]\n",
      "ejemplar: [0.31858695 0.32504132 0.33180436 0.33886078 0.34608433 0.35354885\n",
      " 0.36128789 0.36930451]\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.37761626]]\n",
      "Lr que voy a aplicar en el lote: 66 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.31858695 0.32504132 0.33180436 0.33886078 0.34608433 0.35354885\n",
      "  0.36128789 0.36930451]]\n",
      "verdaderas salidas: [0.82758621]\n",
      "PERDIDAAAA antes: 0.202472984790802\n",
      "Predicción post entrenamiento : [[0.38451958]]\n",
      "PERDIDAAAA despues: 0.19630806148052216\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "[[[0.32504132]\n",
      "  [0.33180436]\n",
      "  [0.33886078]\n",
      "  [0.34608433]\n",
      "  [0.35354885]\n",
      "  [0.36128789]\n",
      "  [0.36930451]\n",
      "  [0.37761626]]]\n",
      "ejemplar: [0.32504132 0.33180436 0.33886078 0.34608433 0.35354885 0.36128789\n",
      " 0.36930451 0.37761626]\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.38637376]]\n",
      "Lr que voy a aplicar en el lote: 67 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.32504132 0.33180436 0.33886078 0.34608433 0.35354885 0.36128789\n",
      "  0.36930451 0.37761626]]\n",
      "verdaderas salidas: [0.83882216]\n",
      "PERDIDAAAA antes: 0.20470957458019257\n",
      "Predicción post entrenamiento : [[0.39365575]]\n",
      "PERDIDAAAA despues: 0.1981731653213501\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "[[[0.33180436]\n",
      "  [0.33886078]\n",
      "  [0.34608433]\n",
      "  [0.35354885]\n",
      "  [0.36128789]\n",
      "  [0.36930451]\n",
      "  [0.37761626]\n",
      "  [0.38637376]]]\n",
      "ejemplar: [0.33180436 0.33886078 0.34608433 0.35354885 0.36128789 0.36930451\n",
      " 0.37761626 0.38637376]\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.3956109]]\n",
      "Lr que voy a aplicar en el lote: 68 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.33180436 0.33886078 0.34608433 0.35354885 0.36128789 0.36930451\n",
      "  0.37761626 0.38637376]]\n",
      "verdaderas salidas: [0.79426579]\n",
      "PERDIDAAAA antes: 0.15892574191093445\n",
      "Predicción post entrenamiento : [[0.40317613]]\n",
      "PERDIDAAAA despues: 0.15295113623142242\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "[[[0.33886078]\n",
      "  [0.34608433]\n",
      "  [0.35354885]\n",
      "  [0.36128789]\n",
      "  [0.36930451]\n",
      "  [0.37761626]\n",
      "  [0.38637376]\n",
      "  [0.3956109 ]]]\n",
      "ejemplar: [0.33886078 0.34608433 0.35354885 0.36128789 0.36930451 0.37761626\n",
      " 0.38637376 0.3956109 ]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.4052332]]\n",
      "Lr que voy a aplicar en el lote: 69 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.33886078 0.34608433 0.35354885 0.36128789 0.36930451 0.37761626\n",
      "  0.38637376 0.3956109 ]]\n",
      "verdaderas salidas: [0.78380473]\n",
      "PERDIDAAAA antes: 0.143316388130188\n",
      "Predicción post entrenamiento : [[0.413035]]\n",
      "PERDIDAAAA despues: 0.13747017085552216\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "[[[0.34608433]\n",
      "  [0.35354885]\n",
      "  [0.36128789]\n",
      "  [0.36930451]\n",
      "  [0.37761626]\n",
      "  [0.38637376]\n",
      "  [0.3956109 ]\n",
      "  [0.4052332 ]]]\n",
      "ejemplar: [0.34608433 0.35354885 0.36128789 0.36930451 0.37761626 0.38637376\n",
      " 0.3956109  0.4052332 ]\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.415197]]\n",
      "Lr que voy a aplicar en el lote: 70 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.34608433 0.35354885 0.36128789 0.36930451 0.37761626 0.38637376\n",
      "  0.3956109  0.4052332 ]]\n",
      "verdaderas salidas: [0.76791941]\n",
      "PERDIDAAAA antes: 0.12441309541463852\n",
      "Predicción post entrenamiento : [[0.42319632]]\n",
      "PERDIDAAAA despues: 0.11883401870727539\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "[[[0.35354885]\n",
      "  [0.36128789]\n",
      "  [0.36930451]\n",
      "  [0.37761626]\n",
      "  [0.38637376]\n",
      "  [0.3956109 ]\n",
      "  [0.4052332 ]\n",
      "  [0.41519701]]]\n",
      "ejemplar: [0.35354885 0.36128789 0.36930451 0.37761626 0.38637376 0.3956109\n",
      " 0.4052332  0.41519701]\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.42547897]]\n",
      "Lr que voy a aplicar en el lote: 71 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.35354885 0.36128789 0.36930451 0.37761626 0.38637376 0.3956109\n",
      "  0.4052332  0.41519701]]\n",
      "verdaderas salidas: [0.78457962]\n",
      "PERDIDAAAA antes: 0.12895329296588898\n",
      "Predicción post entrenamiento : [[0.43371436]]\n",
      "PERDIDAAAA despues: 0.1231064423918724\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "[[[0.36128789]\n",
      "  [0.36930451]\n",
      "  [0.37761626]\n",
      "  [0.38637376]\n",
      "  [0.3956109 ]\n",
      "  [0.4052332 ]\n",
      "  [0.41519701]\n",
      "  [0.42547897]]]\n",
      "ejemplar: [0.36128789 0.36930451 0.37761626 0.38637376 0.3956109  0.4052332\n",
      " 0.41519701 0.42547897]\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.4361305]]\n",
      "Lr que voy a aplicar en el lote: 72 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.36128789 0.36930451 0.37761626 0.38637376 0.3956109  0.4052332\n",
      "  0.41519701 0.42547897]]\n",
      "verdaderas salidas: [0.87872917]\n",
      "PERDIDAAAA antes: 0.19589358568191528\n",
      "Predicción post entrenamiento : [[0.44480333]]\n",
      "PERDIDAAAA despues: 0.18829163908958435\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "[[[0.36930451]\n",
      "  [0.37761626]\n",
      "  [0.38637376]\n",
      "  [0.3956109 ]\n",
      "  [0.4052332 ]\n",
      "  [0.41519701]\n",
      "  [0.42547897]\n",
      "  [0.43613049]]]\n",
      "ejemplar: [0.36930451 0.37761626 0.38637376 0.3956109  0.4052332  0.41519701\n",
      " 0.42547897 0.43613049]\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.44736657]]\n",
      "Lr que voy a aplicar en el lote: 73 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.36930451 0.37761626 0.38637376 0.3956109  0.4052332  0.41519701\n",
      "  0.42547897 0.43613049]]\n",
      "verdaderas salidas: [0.8756296]\n",
      "PERDIDAAAA antes: 0.18340922892093658\n",
      "Predicción post entrenamiento : [[0.45647103]]\n",
      "PERDIDAAAA despues: 0.17569391429424286\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "[[[0.37761626]\n",
      "  [0.38637376]\n",
      "  [0.3956109 ]\n",
      "  [0.4052332 ]\n",
      "  [0.41519701]\n",
      "  [0.42547897]\n",
      "  [0.43613049]\n",
      "  [0.44736657]]]\n",
      "ejemplar: [0.37761626 0.38637376 0.3956109  0.4052332  0.41519701 0.42547897\n",
      " 0.43613049 0.44736657]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.4591967]]\n",
      "Lr que voy a aplicar en el lote: 74 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.37761626 0.38637376 0.3956109  0.4052332  0.41519701 0.42547897\n",
      "  0.43613049 0.44736657]]\n",
      "verdaderas salidas: [0.84889578]\n",
      "PERDIDAAAA antes: 0.1518653929233551\n",
      "Predicción post entrenamiento : [[0.46866778]]\n",
      "PERDIDAAAA despues: 0.14457334578037262\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "[[[0.38637376]\n",
      "  [0.3956109 ]\n",
      "  [0.4052332 ]\n",
      "  [0.41519701]\n",
      "  [0.42547897]\n",
      "  [0.43613049]\n",
      "  [0.44736657]\n",
      "  [0.45919669]]]\n",
      "ejemplar: [0.38637376 0.3956109  0.4052332  0.41519701 0.42547897 0.43613049\n",
      " 0.44736657 0.45919669]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.47157252]]\n",
      "Lr que voy a aplicar en el lote: 75 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.38637376 0.3956109  0.4052332  0.41519701 0.42547897 0.43613049\n",
      "  0.44736657 0.45919669]]\n",
      "verdaderas salidas: [0.81828749]\n",
      "PERDIDAAAA antes: 0.12021127343177795\n",
      "Predicción post entrenamiento : [[0.48131448]]\n",
      "PERDIDAAAA despues: 0.1135508120059967\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "[[[0.3956109 ]\n",
      "  [0.4052332 ]\n",
      "  [0.41519701]\n",
      "  [0.42547897]\n",
      "  [0.43613049]\n",
      "  [0.44736657]\n",
      "  [0.45919669]\n",
      "  [0.47157252]]]\n",
      "ejemplar: [0.3956109  0.4052332  0.41519701 0.42547897 0.43613049 0.44736657\n",
      " 0.45919669 0.47157252]\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.4844026]]\n",
      "Lr que voy a aplicar en el lote: 76 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.3956109  0.4052332  0.41519701 0.42547897 0.43613049 0.44736657\n",
      "  0.45919669 0.47157252]]\n",
      "verdaderas salidas: [0.82681131]\n",
      "PERDIDAAAA antes: 0.11724372953176498\n",
      "Predicción post entrenamiento : [[0.49444026]]\n",
      "PERDIDAAAA despues: 0.11047051846981049\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "[[[0.4052332 ]\n",
      "  [0.41519701]\n",
      "  [0.42547897]\n",
      "  [0.43613049]\n",
      "  [0.44736657]\n",
      "  [0.45919669]\n",
      "  [0.47157252]\n",
      "  [0.4844026 ]]]\n",
      "ejemplar: [0.4052332  0.41519701 0.42547897 0.43613049 0.44736657 0.45919669\n",
      " 0.47157252 0.4844026 ]\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.49771315]]\n",
      "Lr que voy a aplicar en el lote: 77 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.4052332  0.41519701 0.42547897 0.43613049 0.44736657 0.45919669\n",
      "  0.47157252 0.4844026 ]]\n",
      "verdaderas salidas: [0.78535451]\n",
      "PERDIDAAAA antes: 0.08273754268884659\n",
      "Predicción post entrenamiento : [[0.50792277]]\n",
      "PERDIDAAAA despues: 0.07696836441755295\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "[[[0.41519701]\n",
      "  [0.42547897]\n",
      "  [0.43613049]\n",
      "  [0.44736657]\n",
      "  [0.45919669]\n",
      "  [0.47157252]\n",
      "  [0.4844026 ]\n",
      "  [0.49771315]]]\n",
      "ejemplar: [0.41519701 0.42547897 0.43613049 0.44736657 0.45919669 0.47157252\n",
      " 0.4844026  0.49771315]\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.5113915]]\n",
      "Lr que voy a aplicar en el lote: 78 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.41519701 0.42547897 0.43613049 0.44736657 0.45919669 0.47157252\n",
      "  0.4844026  0.49771315]]\n",
      "verdaderas salidas: [0.78922898]\n",
      "PERDIDAAAA antes: 0.07719365507364273\n",
      "Predicción post entrenamiento : [[0.5217667]]\n",
      "PERDIDAAAA despues: 0.07153605669736862\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "[[[0.42547897]\n",
      "  [0.43613049]\n",
      "  [0.44736657]\n",
      "  [0.45919669]\n",
      "  [0.47157252]\n",
      "  [0.4844026 ]\n",
      "  [0.49771315]\n",
      "  [0.51139152]]]\n",
      "ejemplar: [0.42547897 0.43613049 0.44736657 0.45919669 0.47157252 0.4844026\n",
      " 0.49771315 0.51139152]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.52544975]]\n",
      "Lr que voy a aplicar en el lote: 79 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.42547897 0.43613049 0.44736657 0.45919669 0.47157252 0.4844026\n",
      "  0.49771315 0.51139152]]\n",
      "verdaderas salidas: [0.8341728]\n",
      "PERDIDAAAA antes: 0.09530991315841675\n",
      "Predicción post entrenamiento : [[0.5361073]]\n",
      "PERDIDAAAA despues: 0.08884303271770477\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "[[[0.43613049]\n",
      "  [0.44736657]\n",
      "  [0.45919669]\n",
      "  [0.47157252]\n",
      "  [0.4844026 ]\n",
      "  [0.49771315]\n",
      "  [0.51139152]\n",
      "  [0.52544975]]]\n",
      "ejemplar: [0.43613049 0.44736657 0.45919669 0.47157252 0.4844026  0.49771315\n",
      " 0.51139152 0.52544975]\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.5400292]]\n",
      "Lr que voy a aplicar en el lote: 80 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.43613049 0.44736657 0.45919669 0.47157252 0.4844026  0.49771315\n",
      "  0.51139152 0.52544975]]\n",
      "verdaderas salidas: [0.81247578]\n",
      "PERDIDAAAA antes: 0.07422713190317154\n",
      "Predicción post entrenamiento : [[0.55099654]]\n",
      "PERDIDAAAA despues: 0.06837140023708344\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "[[[0.44736657]\n",
      "  [0.45919669]\n",
      "  [0.47157252]\n",
      "  [0.4844026 ]\n",
      "  [0.49771315]\n",
      "  [0.51139152]\n",
      "  [0.52544975]\n",
      "  [0.54002923]]]\n",
      "ejemplar: [0.44736657 0.45919669 0.47157252 0.4844026  0.49771315 0.51139152\n",
      " 0.52544975 0.54002923]\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.55518]]\n",
      "Lr que voy a aplicar en el lote: 81 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.44736657 0.45919669 0.47157252 0.4844026  0.49771315 0.51139152\n",
      "  0.52544975 0.54002923]]\n",
      "verdaderas salidas: [0.80123983]\n",
      "PERDIDAAAA antes: 0.06054544076323509\n",
      "Predicción post entrenamiento : [[0.5661613]]\n",
      "PERDIDAAAA despues: 0.05526193603873253\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "[[[0.45919669]\n",
      "  [0.47157252]\n",
      "  [0.4844026 ]\n",
      "  [0.49771315]\n",
      "  [0.51139152]\n",
      "  [0.52544975]\n",
      "  [0.54002923]\n",
      "  [0.55518001]]]\n",
      "ejemplar: [0.45919669 0.47157252 0.4844026  0.49771315 0.51139152 0.52544975\n",
      " 0.54002923 0.55518001]\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.5706036]]\n",
      "Lr que voy a aplicar en el lote: 82 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.45919669 0.47157252 0.4844026  0.49771315 0.51139152 0.52544975\n",
      "  0.54002923 0.55518001]]\n",
      "verdaderas salidas: [0.80317706]\n",
      "PERDIDAAAA antes: 0.054090410470962524\n",
      "Predicción post entrenamiento : [[0.5816033]]\n",
      "PERDIDAAAA despues: 0.04909493401646614\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "[[[0.47157252]\n",
      "  [0.4844026 ]\n",
      "  [0.49771315]\n",
      "  [0.51139152]\n",
      "  [0.52544975]\n",
      "  [0.54002923]\n",
      "  [0.55518001]\n",
      "  [0.57060361]]]\n",
      "ejemplar: [0.47157252 0.4844026  0.49771315 0.51139152 0.52544975 0.54002923\n",
      " 0.55518001 0.57060361]\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.5862981]]\n",
      "Lr que voy a aplicar en el lote: 83 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.47157252 0.4844026  0.49771315 0.51139152 0.52544975 0.54002923\n",
      "  0.55518001 0.57060361]]\n",
      "verdaderas salidas: [0.7934909]\n",
      "PERDIDAAAA antes: 0.042928848415613174\n",
      "Predicción post entrenamiento : [[0.5972933]]\n",
      "PERDIDAAAA despues: 0.03849348798394203\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "[[[0.4844026 ]\n",
      "  [0.49771315]\n",
      "  [0.51139152]\n",
      "  [0.52544975]\n",
      "  [0.54002923]\n",
      "  [0.55518001]\n",
      "  [0.57060361]\n",
      "  [0.58629811]]]\n",
      "ejemplar: [0.4844026  0.49771315 0.51139152 0.52544975 0.54002923 0.55518001\n",
      " 0.57060361 0.58629811]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.6022353]]\n",
      "Lr que voy a aplicar en el lote: 84 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.4844026  0.49771315 0.51139152 0.52544975 0.54002923 0.55518001\n",
      "  0.57060361 0.58629811]]\n",
      "verdaderas salidas: [0.76017048]\n",
      "PERDIDAAAA antes: 0.024943510070443153\n",
      "Predicción post entrenamiento : [[0.6132388]]\n",
      "PERDIDAAAA despues: 0.02158890850841999\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "[[[0.49771315]\n",
      "  [0.51139152]\n",
      "  [0.52544975]\n",
      "  [0.54002923]\n",
      "  [0.55518001]\n",
      "  [0.57060361]\n",
      "  [0.58629811]\n",
      "  [0.60223532]]]\n",
      "ejemplar: [0.49771315 0.51139152 0.52544975 0.54002923 0.55518001 0.57060361\n",
      " 0.58629811 0.60223532]\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.61842984]]\n",
      "Lr que voy a aplicar en el lote: 85 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.49771315 0.51139152 0.52544975 0.54002923 0.55518001 0.57060361\n",
      "  0.58629811 0.60223532]]\n",
      "verdaderas salidas: [0.73537389]\n",
      "PERDIDAAAA antes: 0.013675916939973831\n",
      "Predicción post entrenamiento : [[0.6289332]]\n",
      "PERDIDAAAA despues: 0.011329627595841885\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "[[[0.51139152]\n",
      "  [0.52544975]\n",
      "  [0.54002923]\n",
      "  [0.55518001]\n",
      "  [0.57060361]\n",
      "  [0.58629811]\n",
      "  [0.60223532]\n",
      "  [0.61842984]]]\n",
      "ejemplar: [0.51139152 0.52544975 0.54002923 0.55518001 0.57060361 0.58629811\n",
      " 0.60223532 0.61842984]\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.63436484]]\n",
      "Lr que voy a aplicar en el lote: 86 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.51139152 0.52544975 0.54002923 0.55518001 0.57060361 0.58629811\n",
      "  0.60223532 0.61842984]]\n",
      "verdaderas salidas: [0.71018985]\n",
      "PERDIDAAAA antes: 0.005749426782131195\n",
      "Predicción post entrenamiento : [[0.64430785]]\n",
      "PERDIDAAAA despues: 0.004340433515608311\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "[[[0.52544975]\n",
      "  [0.54002923]\n",
      "  [0.55518001]\n",
      "  [0.57060361]\n",
      "  [0.58629811]\n",
      "  [0.60223532]\n",
      "  [0.61842984]\n",
      "  [0.63436484]]]\n",
      "ejemplar: [0.52544975 0.54002923 0.55518001 0.57060361 0.58629811 0.60223532\n",
      " 0.61842984 0.63436484]\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.6499796]]\n",
      "Lr que voy a aplicar en el lote: 87 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.52544975 0.54002923 0.55518001 0.57060361 0.58629811 0.60223532\n",
      "  0.61842984 0.63436484]]\n",
      "verdaderas salidas: [0.71212708]\n",
      "PERDIDAAAA antes: 0.0038623115979135036\n",
      "Predicción post entrenamiento : [[0.6589804]]\n",
      "PERDIDAAAA despues: 0.0028245674911886454\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "[[[0.54002923]\n",
      "  [0.55518001]\n",
      "  [0.57060361]\n",
      "  [0.58629811]\n",
      "  [0.60223532]\n",
      "  [0.61842984]\n",
      "  [0.63436484]\n",
      "  [0.64997959]]]\n",
      "ejemplar: [0.54002923 0.55518001 0.57060361 0.58629811 0.60223532 0.61842984\n",
      " 0.63436484 0.64997959]\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.6648803]]\n",
      "Lr que voy a aplicar en el lote: 88 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.54002923 0.55518001 0.57060361 0.58629811 0.60223532 0.61842984\n",
      "  0.63436484 0.64997959]]\n",
      "verdaderas salidas: [0.7396358]\n",
      "PERDIDAAAA antes: 0.00558839226141572\n",
      "Predicción post entrenamiento : [[0.67343026]]\n",
      "PERDIDAAAA despues: 0.004383176099509001\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "[[[0.55518001]\n",
      "  [0.57060361]\n",
      "  [0.58629811]\n",
      "  [0.60223532]\n",
      "  [0.61842984]\n",
      "  [0.63436484]\n",
      "  [0.64997959]\n",
      "  [0.66488028]]]\n",
      "ejemplar: [0.55518001 0.57060361 0.58629811 0.60223532 0.61842984 0.63436484\n",
      " 0.64997959 0.66488028]\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.6795229]]\n",
      "Lr que voy a aplicar en el lote: 89 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.55518001 0.57060361 0.58629811 0.60223532 0.61842984 0.63436484\n",
      "  0.64997959 0.66488028]]\n",
      "verdaderas salidas: [0.73614878]\n",
      "PERDIDAAAA antes: 0.003206492867320776\n",
      "Predicción post entrenamiento : [[0.6875173]]\n",
      "PERDIDAAAA despues: 0.0023650217335671186\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "[[[0.57060361]\n",
      "  [0.58629811]\n",
      "  [0.60223532]\n",
      "  [0.61842984]\n",
      "  [0.63436484]\n",
      "  [0.64997959]\n",
      "  [0.66488028]\n",
      "  [0.67952287]]]\n",
      "ejemplar: [0.57060361 0.58629811 0.60223532 0.61842984 0.63436484 0.64997959\n",
      " 0.66488028 0.67952287]\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.6937422]]\n",
      "Lr que voy a aplicar en el lote: 90 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.57060361 0.58629811 0.60223532 0.61842984 0.63436484 0.64997959\n",
      "  0.66488028 0.67952287]]\n",
      "verdaderas salidas: [0.66757071]\n",
      "PERDIDAAAA antes: 0.000684947706758976\n",
      "Predicción post entrenamiento : [[0.70179725]]\n",
      "PERDIDAAAA despues: 0.00117145583499223\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "[[[0.58629811]\n",
      "  [0.60223532]\n",
      "  [0.61842984]\n",
      "  [0.63436484]\n",
      "  [0.64997959]\n",
      "  [0.66488028]\n",
      "  [0.67952287]\n",
      "  [0.69374222]]]\n",
      "ejemplar: [0.58629811 0.60223532 0.61842984 0.63436484 0.64997959 0.66488028\n",
      " 0.67952287 0.69374222]\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.7081209]]\n",
      "Lr que voy a aplicar en el lote: 91 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.58629811 0.60223532 0.61842984 0.63436484 0.64997959 0.66488028\n",
      "  0.67952287 0.69374222]]\n",
      "verdaderas salidas: [0.66989539]\n",
      "PERDIDAAAA antes: 0.0014611866790801287\n",
      "Predicción post entrenamiento : [[0.71538395]]\n",
      "PERDIDAAAA despues: 0.0020692069083452225\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "[[[0.60223532]\n",
      "  [0.61842984]\n",
      "  [0.63436484]\n",
      "  [0.64997959]\n",
      "  [0.66488028]\n",
      "  [0.67952287]\n",
      "  [0.69374222]\n",
      "  [0.70812088]]]\n",
      "ejemplar: [0.60223532 0.61842984 0.63436484 0.64997959 0.66488028 0.67952287\n",
      " 0.69374222 0.70812088]\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.72175103]]\n",
      "Lr que voy a aplicar en el lote: 92 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.60223532 0.61842984 0.63436484 0.64997959 0.66488028 0.67952287\n",
      "  0.69374222 0.70812088]]\n",
      "verdaderas salidas: [0.69662921]\n",
      "PERDIDAAAA antes: 0.0006311052129603922\n",
      "Predicción post entrenamiento : [[0.72834575]]\n",
      "PERDIDAAAA despues: 0.0010059380438178778\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "[[[0.61842984]\n",
      "  [0.63436484]\n",
      "  [0.64997959]\n",
      "  [0.66488028]\n",
      "  [0.67952287]\n",
      "  [0.69374222]\n",
      "  [0.70812088]\n",
      "  [0.72175103]]]\n",
      "ejemplar: [0.61842984 0.63436484 0.64997959 0.66488028 0.67952287 0.69374222\n",
      " 0.70812088 0.72175103]\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.73469114]]\n",
      "Lr que voy a aplicar en el lote: 93 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.61842984 0.63436484 0.64997959 0.66488028 0.67952287 0.69374222\n",
      "  0.70812088 0.72175103]]\n",
      "verdaderas salidas: [0.65594731]\n",
      "PERDIDAAAA antes: 0.006200588308274746\n",
      "Predicción post entrenamiento : [[0.73997176]]\n",
      "PERDIDAAAA despues: 0.007060104515403509\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "[[[0.63436484]\n",
      "  [0.64997959]\n",
      "  [0.66488028]\n",
      "  [0.67952287]\n",
      "  [0.69374222]\n",
      "  [0.70812088]\n",
      "  [0.72175103]\n",
      "  [0.73469114]]]\n",
      "ejemplar: [0.63436484 0.64997959 0.66488028 0.67952287 0.69374222 0.70812088\n",
      " 0.72175103 0.73469114]\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.7462059]]\n",
      "Lr que voy a aplicar en el lote: 94 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.63436484 0.64997959 0.66488028 0.67952287 0.69374222 0.70812088\n",
      "  0.72175103 0.73469114]]\n",
      "verdaderas salidas: [0.67880666]\n",
      "PERDIDAAAA antes: 0.004542660899460316\n",
      "Predicción post entrenamiento : [[0.75128865]]\n",
      "PERDIDAAAA despues: 0.005253639072179794\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "[[[0.64997959]\n",
      "  [0.66488028]\n",
      "  [0.67952287]\n",
      "  [0.69374222]\n",
      "  [0.70812088]\n",
      "  [0.72175103]\n",
      "  [0.73469114]\n",
      "  [0.74620593]]]\n",
      "ejemplar: [0.64997959 0.66488028 0.67952287 0.69374222 0.70812088 0.72175103\n",
      " 0.73469114 0.74620593]\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.75738865]]\n",
      "Lr que voy a aplicar en el lote: 95 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.64997959 0.66488028 0.67952287 0.69374222 0.70812088 0.72175103\n",
      "  0.73469114 0.74620593]]\n",
      "verdaderas salidas: [0.67609454]\n",
      "PERDIDAAAA antes: 0.006608733907341957\n",
      "Predicción post entrenamiento : [[0.76113963]]\n",
      "PERDIDAAAA despues: 0.007232668809592724\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "[[[0.66488028]\n",
      "  [0.67952287]\n",
      "  [0.69374222]\n",
      "  [0.70812088]\n",
      "  [0.72175103]\n",
      "  [0.73469114]\n",
      "  [0.74620593]\n",
      "  [0.75738865]]]\n",
      "ejemplar: [0.66488028 0.67952287 0.69374222 0.70812088 0.72175103 0.73469114\n",
      " 0.74620593 0.75738865]\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.7670717]]\n",
      "Lr que voy a aplicar en el lote: 96 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.66488028 0.67952287 0.69374222 0.70812088 0.72175103 0.73469114\n",
      "  0.74620593 0.75738865]]\n",
      "verdaderas salidas: [0.72956219]\n",
      "PERDIDAAAA antes: 0.0014069671742618084\n",
      "Predicción post entrenamiento : [[0.770679]]\n",
      "PERDIDAAAA despues: 0.0016905940137803555\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "[[[0.67952287]\n",
      "  [0.69374222]\n",
      "  [0.70812088]\n",
      "  [0.72175103]\n",
      "  [0.73469114]\n",
      "  [0.74620593]\n",
      "  [0.75738865]\n",
      "  [0.76707172]]]\n",
      "ejemplar: [0.67952287 0.69374222 0.70812088 0.72175103 0.73469114 0.74620593\n",
      " 0.75738865 0.76707172]\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.7764691]]\n",
      "Lr que voy a aplicar en el lote: 97 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.67952287 0.69374222 0.70812088 0.72175103 0.73469114 0.74620593\n",
      "  0.75738865 0.76707172]]\n",
      "verdaderas salidas: [0.70127857]\n",
      "PERDIDAAAA antes: 0.005653617903590202\n",
      "Predicción post entrenamiento : [[0.7790615]]\n",
      "PERDIDAAAA despues: 0.006050183903425932\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "[[[0.69374222]\n",
      "  [0.70812088]\n",
      "  [0.72175103]\n",
      "  [0.73469114]\n",
      "  [0.74620593]\n",
      "  [0.75738865]\n",
      "  [0.76707172]\n",
      "  [0.77646911]]]\n",
      "ejemplar: [0.69374222 0.70812088 0.72175103 0.73469114 0.74620593 0.75738865\n",
      " 0.76707172 0.77646911]\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.7846604]]\n",
      "Lr que voy a aplicar en el lote: 98 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.69374222 0.70812088 0.72175103 0.73469114 0.74620593 0.75738865\n",
      "  0.76707172 0.77646911]]\n",
      "verdaderas salidas: [0.76753196]\n",
      "PERDIDAAAA antes: 0.0002933823561761528\n",
      "Predicción post entrenamiento : [[0.7869639]]\n",
      "PERDIDAAAA despues: 0.0003775983059313148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "[[[0.70812088]\n",
      "  [0.72175103]\n",
      "  [0.73469114]\n",
      "  [0.74620593]\n",
      "  [0.75738865]\n",
      "  [0.76707172]\n",
      "  [0.77646911]\n",
      "  [0.7846604 ]]]\n",
      "ejemplar: [0.70812088 0.72175103 0.73469114 0.74620593 0.75738865 0.76707172\n",
      " 0.77646911 0.7846604 ]\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.7923392]]\n",
      "Lr que voy a aplicar en el lote: 99 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.70812088 0.72175103 0.73469114 0.74620593 0.75738865 0.76707172\n",
      "  0.77646911 0.7846604 ]]\n",
      "verdaderas salidas: [0.75513367]\n",
      "PERDIDAAAA antes: 0.0013842504704371095\n",
      "Predicción post entrenamiento : [[0.79378223]]\n",
      "PERDIDAAAA despues: 0.0014937100932002068\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "[[[0.72175103]\n",
      "  [0.73469114]\n",
      "  [0.74620593]\n",
      "  [0.75738865]\n",
      "  [0.76707172]\n",
      "  [0.77646911]\n",
      "  [0.7846604 ]\n",
      "  [0.79233921]]]\n",
      "ejemplar: [0.72175103 0.73469114 0.74620593 0.75738865 0.76707172 0.77646911\n",
      " 0.7846604  0.79233921]\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.798803]]\n",
      "Lr que voy a aplicar en el lote: 100 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.72175103 0.73469114 0.74620593 0.75738865 0.76707172 0.77646911\n",
      "  0.7846604  0.79233921]]\n",
      "verdaderas salidas: [0.74506005]\n",
      "PERDIDAAAA antes: 0.002888304181396961\n",
      "Predicción post entrenamiento : [[0.7989398]]\n",
      "PERDIDAAAA despues: 0.0029030325822532177\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "[[[0.73469114]\n",
      "  [0.74620593]\n",
      "  [0.75738865]\n",
      "  [0.76707172]\n",
      "  [0.77646911]\n",
      "  [0.7846604 ]\n",
      "  [0.79233921]\n",
      "  [0.79880297]]]\n",
      "ejemplar: [0.73469114 0.74620593 0.75738865 0.76707172 0.77646911 0.7846604\n",
      " 0.79233921 0.79880297]\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.80357957]]\n",
      "Lr que voy a aplicar en el lote: 101 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.73469114 0.74620593 0.75738865 0.76707172 0.77646911 0.7846604\n",
      "  0.79233921 0.79880297]]\n",
      "verdaderas salidas: [0.7520341]\n",
      "PERDIDAAAA antes: 0.0026569387409836054\n",
      "Predicción post entrenamiento : [[0.80366087]]\n",
      "PERDIDAAAA despues: 0.0026653266977518797\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "[[[0.74620593]\n",
      "  [0.75738865]\n",
      "  [0.76707172]\n",
      "  [0.77646911]\n",
      "  [0.7846604 ]\n",
      "  [0.79233921]\n",
      "  [0.79880297]\n",
      "  [0.80357957]]]\n",
      "ejemplar: [0.74620593 0.75738865 0.76707172 0.77646911 0.7846604  0.79233921\n",
      " 0.79880297 0.80357957]\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.8078912]]\n",
      "Lr que voy a aplicar en el lote: 102 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.74620593 0.75738865 0.76707172 0.77646911 0.7846604  0.79233921\n",
      "  0.79880297 0.80357957]]\n",
      "verdaderas salidas: [0.7098024]\n",
      "PERDIDAAAA antes: 0.009621412493288517\n",
      "Predicción post entrenamiento : [[0.8067557]]\n",
      "PERDIDAAAA despues: 0.00939994864165783\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "[[[0.75738865]\n",
      "  [0.76707172]\n",
      "  [0.77646911]\n",
      "  [0.7846604 ]\n",
      "  [0.79233921]\n",
      "  [0.79880297]\n",
      "  [0.80357957]\n",
      "  [0.80789119]]]\n",
      "ejemplar: [0.75738865 0.76707172 0.77646911 0.7846604  0.79233921 0.79880297\n",
      " 0.80357957 0.80789119]\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.81064004]]\n",
      "Lr que voy a aplicar en el lote: 103 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.75738865 0.76707172 0.77646911 0.7846604  0.79233921 0.79880297\n",
      "  0.80357957 0.80789119]]\n",
      "verdaderas salidas: [0.69043007]\n",
      "PERDIDAAAA antes: 0.014450442045927048\n",
      "Predicción post entrenamiento : [[0.8093881]]\n",
      "PERDIDAAAA despues: 0.014151019044220448\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "[[[0.76707172]\n",
      "  [0.77646911]\n",
      "  [0.7846604 ]\n",
      "  [0.79233921]\n",
      "  [0.79880297]\n",
      "  [0.80357957]\n",
      "  [0.80789119]\n",
      "  [0.81064004]]]\n",
      "ejemplar: [0.76707172 0.77646911 0.7846604  0.79233921 0.79880297 0.80357957\n",
      " 0.80789119 0.81064004]\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.81284934]]\n",
      "Lr que voy a aplicar en el lote: 104 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.76707172 0.77646911 0.7846604  0.79233921 0.79880297 0.80357957\n",
      "  0.80789119 0.81064004]]\n",
      "verdaderas salidas: [0.75435878]\n",
      "PERDIDAAAA antes: 0.0034211473539471626\n",
      "Predicción post entrenamiento : [[0.80954397]]\n",
      "PERDIDAAAA despues: 0.0030454061925411224\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "[[[0.77646911]\n",
      "  [0.7846604 ]\n",
      "  [0.79233921]\n",
      "  [0.79880297]\n",
      "  [0.80357957]\n",
      "  [0.80789119]\n",
      "  [0.81064004]\n",
      "  [0.81284934]]]\n",
      "ejemplar: [0.77646911 0.7846604  0.79233921 0.79880297 0.80357957 0.80789119\n",
      " 0.81064004 0.81284934]\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.8126463]]\n",
      "Lr que voy a aplicar en el lote: 105 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.77646911 0.7846604  0.79233921 0.79880297 0.80357957 0.80789119\n",
      "  0.81064004 0.81284934]]\n",
      "verdaderas salidas: [0.7222007]\n",
      "PERDIDAAAA antes: 0.008180413395166397\n",
      "Predicción post entrenamiento : [[0.8090954]]\n",
      "PERDIDAAAA despues: 0.007550687529146671\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "[[[0.7846604 ]\n",
      "  [0.79233921]\n",
      "  [0.79880297]\n",
      "  [0.80357957]\n",
      "  [0.80789119]\n",
      "  [0.81064004]\n",
      "  [0.81284934]\n",
      "  [0.81264633]]]\n",
      "ejemplar: [0.7846604  0.79233921 0.79880297 0.80357957 0.80789119 0.81064004\n",
      " 0.81284934 0.81264633]\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.8117487]]\n",
      "Lr que voy a aplicar en el lote: 106 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.7846604  0.79233921 0.79880297 0.80357957 0.80789119 0.81064004\n",
      "  0.81284934 0.81264633]]\n",
      "verdaderas salidas: [0.84850833]\n",
      "PERDIDAAAA antes: 0.0013512736186385155\n",
      "Predicción post entrenamiento : [[0.8095413]]\n",
      "PERDIDAAAA despues: 0.0015184327494353056\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "[[[0.79233921]\n",
      "  [0.79880297]\n",
      "  [0.80357957]\n",
      "  [0.80789119]\n",
      "  [0.81064004]\n",
      "  [0.81284934]\n",
      "  [0.81264633]\n",
      "  [0.81174868]]]\n",
      "ejemplar: [0.79233921 0.79880297 0.80357957 0.80789119 0.81064004 0.81284934\n",
      " 0.81264633 0.81174868]\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.81177104]]\n",
      "Lr que voy a aplicar en el lote: 107 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.79233921 0.79880297 0.80357957 0.80789119 0.81064004 0.81284934\n",
      "  0.81264633 0.81174868]]\n",
      "verdaderas salidas: [0.905463]\n",
      "PERDIDAAAA antes: 0.008778180927038193\n",
      "Predicción post entrenamiento : [[0.8100967]]\n",
      "PERDIDAAAA despues: 0.009094730950891972\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "[[[0.79880297]\n",
      "  [0.80357957]\n",
      "  [0.80789119]\n",
      "  [0.81064004]\n",
      "  [0.81284934]\n",
      "  [0.81264633]\n",
      "  [0.81174868]\n",
      "  [0.81177104]]]\n",
      "ejemplar: [0.79880297 0.80357957 0.80789119 0.81064004 0.81284934 0.81264633\n",
      " 0.81174868 0.81177104]\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.8118308]]\n",
      "Lr que voy a aplicar en el lote: 108 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.79880297 0.80357957 0.80789119 0.81064004 0.81284934 0.81264633\n",
      "  0.81174868 0.81177104]]\n",
      "verdaderas salidas: [0.8822162]\n",
      "PERDIDAAAA antes: 0.004954103846102953\n",
      "Predicción post entrenamiento : [[0.81131315]]\n",
      "PERDIDAAAA despues: 0.005027244333177805\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "[[[0.80357957]\n",
      "  [0.80789119]\n",
      "  [0.81064004]\n",
      "  [0.81284934]\n",
      "  [0.81264633]\n",
      "  [0.81174868]\n",
      "  [0.81177104]\n",
      "  [0.81183082]]]\n",
      "ejemplar: [0.80357957 0.80789119 0.81064004 0.81284934 0.81264633 0.81174868\n",
      " 0.81177104 0.81183082]\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.8125735]]\n",
      "Lr que voy a aplicar en el lote: 109 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.80357957 0.80789119 0.81064004 0.81284934 0.81264633 0.81174868\n",
      "  0.81177104 0.81183082]]\n",
      "verdaderas salidas: [0.90778768]\n",
      "PERDIDAAAA antes: 0.009065741673111916\n",
      "Predicción post entrenamiento : [[0.8128016]]\n",
      "PERDIDAAAA despues: 0.009022356010973454\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "[[[0.80789119]\n",
      "  [0.81064004]\n",
      "  [0.81284934]\n",
      "  [0.81264633]\n",
      "  [0.81174868]\n",
      "  [0.81177104]\n",
      "  [0.81183082]\n",
      "  [0.81257349]]]\n",
      "ejemplar: [0.80789119 0.81064004 0.81284934 0.81264633 0.81174868 0.81177104\n",
      " 0.81183082 0.81257349]\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.81369066]]\n",
      "Lr que voy a aplicar en el lote: 110 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.80789119 0.81064004 0.81284934 0.81264633 0.81174868 0.81177104\n",
      "  0.81183082 0.81257349]]\n",
      "verdaderas salidas: [0.88957768]\n",
      "PERDIDAAAA antes: 0.005758840590715408\n",
      "Predicción post entrenamiento : [[0.815205]]\n",
      "PERDIDAAAA despues: 0.005531299859285355\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "[[[0.81064004]\n",
      "  [0.81284934]\n",
      "  [0.81264633]\n",
      "  [0.81174868]\n",
      "  [0.81177104]\n",
      "  [0.81183082]\n",
      "  [0.81257349]\n",
      "  [0.81369066]]]\n",
      "ejemplar: [0.81064004 0.81284934 0.81264633 0.81174868 0.81177104 0.81183082\n",
      " 0.81257349 0.81369066]\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.815688]]\n",
      "Lr que voy a aplicar en el lote: 111 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.81064004 0.81284934 0.81264633 0.81174868 0.81177104 0.81183082\n",
      "  0.81257349 0.81369066]]\n",
      "verdaderas salidas: [0.87485471]\n",
      "PERDIDAAAA antes: 0.003500694874674082\n",
      "Predicción post entrenamiento : [[0.81640345]]\n",
      "PERDIDAAAA despues: 0.003416546853259206\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "[[[0.81284934]\n",
      "  [0.81264633]\n",
      "  [0.81174868]\n",
      "  [0.81177104]\n",
      "  [0.81183082]\n",
      "  [0.81257349]\n",
      "  [0.81369066]\n",
      "  [0.81568801]]]\n",
      "ejemplar: [0.81284934 0.81264633 0.81174868 0.81177104 0.81183082 0.81257349\n",
      " 0.81369066 0.81568801]\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.81661165]]\n",
      "Lr que voy a aplicar en el lote: 112 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.81284934 0.81264633 0.81174868 0.81177104 0.81183082 0.81257349\n",
      "  0.81369066 0.81568801]]\n",
      "verdaderas salidas: [0.91321193]\n",
      "PERDIDAAAA antes: 0.009331616573035717\n",
      "Predicción post entrenamiento : [[0.8185911]]\n",
      "PERDIDAAAA despues: 0.008953100070357323\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "[[[0.81264633]\n",
      "  [0.81174868]\n",
      "  [0.81177104]\n",
      "  [0.81183082]\n",
      "  [0.81257349]\n",
      "  [0.81369066]\n",
      "  [0.81568801]\n",
      "  [0.81661165]]]\n",
      "ejemplar: [0.81264633 0.81174868 0.81177104 0.81183082 0.81257349 0.81369066\n",
      " 0.81568801 0.81661165]\n",
      "y: 1.0\n",
      "Predicción : [[0.81855375]]\n",
      "Lr que voy a aplicar en el lote: 113 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.81264633 0.81174868 0.81177104 0.81183082 0.81257349 0.81369066\n",
      "  0.81568801 0.81661165]]\n",
      "verdaderas salidas: [1.]\n",
      "PERDIDAAAA antes: 0.03292274475097656\n",
      "Predicción post entrenamiento : [[0.8210737]]\n",
      "PERDIDAAAA despues: 0.03201461583375931\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "[[[0.81174868]\n",
      "  [0.81177104]\n",
      "  [0.81183082]\n",
      "  [0.81257349]\n",
      "  [0.81369066]\n",
      "  [0.81568801]\n",
      "  [0.81661165]\n",
      "  [0.81855375]]]\n",
      "ejemplar: [0.81174868 0.81177104 0.81183082 0.81257349 0.81369066 0.81568801\n",
      " 0.81661165 0.81855375]\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.8211034]]\n",
      "Lr que voy a aplicar en el lote: 114 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.81174868 0.81177104 0.81183082 0.81257349 0.81369066 0.81568801\n",
      "  0.81661165 0.81855375]]\n",
      "verdaderas salidas: [0.97055405]\n",
      "PERDIDAAAA antes: 0.02233549952507019\n",
      "Predicción post entrenamiento : [[0.824213]]\n",
      "PERDIDAAAA despues: 0.021415695548057556\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "[[[0.81177104]\n",
      "  [0.81183082]\n",
      "  [0.81257349]\n",
      "  [0.81369066]\n",
      "  [0.81568801]\n",
      "  [0.81661165]\n",
      "  [0.81855375]\n",
      "  [0.82110339]]]\n",
      "ejemplar: [0.81177104 0.81183082 0.81257349 0.81369066 0.81568801 0.81661165\n",
      " 0.81855375 0.82110339]\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.82444566]]\n",
      "Lr que voy a aplicar en el lote: 115 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.81177104 0.81183082 0.81257349 0.81369066 0.81568801 0.81661165\n",
      "  0.81855375 0.82110339]]\n",
      "verdaderas salidas: [0.88880279]\n",
      "PERDIDAAAA antes: 0.004141836427152157\n",
      "Predicción post entrenamiento : [[0.8284181]]\n",
      "PERDIDAAAA despues: 0.0036463108845055103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "[[[0.81183082]\n",
      "  [0.81257349]\n",
      "  [0.81369066]\n",
      "  [0.81568801]\n",
      "  [0.81661165]\n",
      "  [0.81855375]\n",
      "  [0.82110339]\n",
      "  [0.82444566]]]\n",
      "ejemplar: [0.81183082 0.81257349 0.81369066 0.81568801 0.81661165 0.81855375\n",
      " 0.82110339 0.82444566]\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.8287873]]\n",
      "Lr que voy a aplicar en el lote: 116 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.81183082 0.81257349 0.81369066 0.81568801 0.81661165 0.81855375\n",
      "  0.82110339 0.82444566]]\n",
      "verdaderas salidas: [0.87795428]\n",
      "PERDIDAAAA antes: 0.0024173916317522526\n",
      "Predicción post entrenamiento : [[0.83306754]]\n",
      "PERDIDAAAA despues: 0.0020148218609392643\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "[[[0.81257349]\n",
      "  [0.81369066]\n",
      "  [0.81568801]\n",
      "  [0.81661165]\n",
      "  [0.81855375]\n",
      "  [0.82110339]\n",
      "  [0.82444566]\n",
      "  [0.82878733]]]\n",
      "ejemplar: [0.81257349 0.81369066 0.81568801 0.81661165 0.81855375 0.82110339\n",
      " 0.82444566 0.82878733]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.83362365]]\n",
      "Lr que voy a aplicar en el lote: 117 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.81257349 0.81369066 0.81568801 0.81661165 0.81855375 0.82110339\n",
      "  0.82444566 0.82878733]]\n",
      "verdaderas salidas: [0.84889578]\n",
      "PERDIDAAAA antes: 0.00023323827190324664\n",
      "Predicción post entrenamiento : [[0.8367926]]\n",
      "PERDIDAAAA despues: 0.00014648745127487928\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "[[[0.81369066]\n",
      "  [0.81568801]\n",
      "  [0.81661165]\n",
      "  [0.81855375]\n",
      "  [0.82110339]\n",
      "  [0.82444566]\n",
      "  [0.82878733]\n",
      "  [0.83362365]]]\n",
      "ejemplar: [0.81369066 0.81568801 0.81661165 0.81855375 0.82110339 0.82444566\n",
      " 0.82878733 0.83362365]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.8375039]]\n",
      "Lr que voy a aplicar en el lote: 118 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.81369066 0.81568801 0.81661165 0.81855375 0.82110339 0.82444566\n",
      "  0.82878733 0.83362365]]\n",
      "verdaderas salidas: [0.8341728]\n",
      "PERDIDAAAA antes: 1.109639197238721e-05\n",
      "Predicción post entrenamiento : [[0.84047353]]\n",
      "PERDIDAAAA despues: 3.969941826653667e-05\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "[[[0.81568801]\n",
      "  [0.81661165]\n",
      "  [0.81855375]\n",
      "  [0.82110339]\n",
      "  [0.82444566]\n",
      "  [0.82878733]\n",
      "  [0.83362365]\n",
      "  [0.83750391]]]\n",
      "ejemplar: [0.81568801 0.81661165 0.81855375 0.82110339 0.82444566 0.82878733\n",
      " 0.83362365 0.83750391]\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.841348]]\n",
      "Lr que voy a aplicar en el lote: 119 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.81568801 0.81661165 0.81855375 0.82110339 0.82444566 0.82878733\n",
      "  0.83362365 0.83750391]]\n",
      "verdaderas salidas: [0.85509492]\n",
      "PERDIDAAAA antes: 0.00018897773406933993\n",
      "Predicción post entrenamiento : [[0.8443677]]\n",
      "PERDIDAAAA despues: 0.00011507339513627812\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "[[[0.81661165]\n",
      "  [0.81855375]\n",
      "  [0.82110339]\n",
      "  [0.82444566]\n",
      "  [0.82878733]\n",
      "  [0.83362365]\n",
      "  [0.83750391]\n",
      "  [0.84134799]]]\n",
      "ejemplar: [0.81661165 0.81855375 0.82110339 0.82444566 0.82878733 0.83362365\n",
      " 0.83750391 0.84134799]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.84533924]]\n",
      "Lr que voy a aplicar en el lote: 120 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.81661165 0.81855375 0.82110339 0.82444566 0.82878733 0.83362365\n",
      "  0.83750391 0.84134799]]\n",
      "verdaderas salidas: [0.87524215]\n",
      "PERDIDAAAA antes: 0.0008941855048760772\n",
      "Predicción post entrenamiento : [[0.8475706]]\n",
      "PERDIDAAAA despues: 0.0007657160749658942\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "[[[0.81855375]\n",
      "  [0.82110339]\n",
      "  [0.82444566]\n",
      "  [0.82878733]\n",
      "  [0.83362365]\n",
      "  [0.83750391]\n",
      "  [0.84134799]\n",
      "  [0.84533924]]]\n",
      "ejemplar: [0.81855375 0.82110339 0.82444566 0.82878733 0.83362365 0.83750391\n",
      " 0.84134799 0.84533924]\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.84884197]]\n",
      "Lr que voy a aplicar en el lote: 121 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.81855375 0.82110339 0.82444566 0.82878733 0.83362365 0.83750391\n",
      "  0.84134799 0.84533924]]\n",
      "verdaderas salidas: [0.85703216]\n",
      "PERDIDAAAA antes: 6.70796143822372e-05\n",
      "Predicción post entrenamiento : [[0.8510379]]\n",
      "PERDIDAAAA despues: 3.5931156162405387e-05\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "[[[0.82110339]\n",
      "  [0.82444566]\n",
      "  [0.82878733]\n",
      "  [0.83362365]\n",
      "  [0.83750391]\n",
      "  [0.84134799]\n",
      "  [0.84533924]\n",
      "  [0.84884197]]]\n",
      "ejemplar: [0.82110339 0.82444566 0.82878733 0.83362365 0.83750391 0.84134799\n",
      " 0.84533924 0.84884197]\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.85253435]]\n",
      "Lr que voy a aplicar en el lote: 122 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.82110339 0.82444566 0.82878733 0.83362365 0.83750391 0.84134799\n",
      "  0.84533924 0.84884197]]\n",
      "verdaderas salidas: [0.85005812]\n",
      "PERDIDAAAA antes: 6.131642294349149e-06\n",
      "Predicción post entrenamiento : [[0.8552548]]\n",
      "PERDIDAAAA despues: 2.7005593437934294e-05\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "[[[0.82444566]\n",
      "  [0.82878733]\n",
      "  [0.83362365]\n",
      "  [0.83750391]\n",
      "  [0.84134799]\n",
      "  [0.84533924]\n",
      "  [0.84884197]\n",
      "  [0.85253435]]]\n",
      "ejemplar: [0.82444566 0.82878733 0.83362365 0.83750391 0.84134799 0.84533924\n",
      " 0.84884197 0.85253435]\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.85693705]]\n",
      "Lr que voy a aplicar en el lote: 123 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.82444566 0.82878733 0.83362365 0.83750391 0.84134799 0.84533924\n",
      "  0.84884197 0.85253435]]\n",
      "verdaderas salidas: [0.84269663]\n",
      "PERDIDAAAA antes: 0.000202790237381123\n",
      "Predicción post entrenamiento : [[0.8589901]]\n",
      "PERDIDAAAA despues: 0.00026547705056145787\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "[[[0.82878733]\n",
      "  [0.83362365]\n",
      "  [0.83750391]\n",
      "  [0.84134799]\n",
      "  [0.84533924]\n",
      "  [0.84884197]\n",
      "  [0.85253435]\n",
      "  [0.85693705]]]\n",
      "ejemplar: [0.82878733 0.83362365 0.83750391 0.84134799 0.84533924 0.84884197\n",
      " 0.85253435 0.85693705]\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.8607738]]\n",
      "Lr que voy a aplicar en el lote: 124 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.82878733 0.83362365 0.83750391 0.84134799 0.84533924 0.84884197\n",
      "  0.85253435 0.85693705]]\n",
      "verdaderas salidas: [0.82293685]\n",
      "PERDIDAAAA antes: 0.001431636163033545\n",
      "Predicción post entrenamiento : [[0.8615514]]\n",
      "PERDIDAAAA despues: 0.0014910850441083312\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "[[[0.83362365]\n",
      "  [0.83750391]\n",
      "  [0.84134799]\n",
      "  [0.84533924]\n",
      "  [0.84884197]\n",
      "  [0.85253435]\n",
      "  [0.85693705]\n",
      "  [0.8607738 ]]]\n",
      "ejemplar: [0.83362365 0.83750391 0.84134799 0.84533924 0.84884197 0.85253435\n",
      " 0.85693705 0.8607738 ]\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.86329854]]\n",
      "Lr que voy a aplicar en el lote: 125 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.83362365 0.83750391 0.84134799 0.84533924 0.84884197 0.85253435\n",
      "  0.85693705 0.8607738 ]]\n",
      "verdaderas salidas: [0.77450601]\n",
      "PERDIDAAAA antes: 0.00788410846143961\n",
      "Predicción post entrenamiento : [[0.8611697]]\n",
      "PERDIDAAAA despues: 0.0075105903670191765\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "[[[0.83750391]\n",
      "  [0.84134799]\n",
      "  [0.84533924]\n",
      "  [0.84884197]\n",
      "  [0.85253435]\n",
      "  [0.85693705]\n",
      "  [0.8607738 ]\n",
      "  [0.86329854]]]\n",
      "ejemplar: [0.83750391 0.84134799 0.84533924 0.84884197 0.85253435 0.85693705\n",
      " 0.8607738  0.86329854]\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.86278516]]\n",
      "Lr que voy a aplicar en el lote: 126 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.83750391 0.84134799 0.84533924 0.84884197 0.85253435 0.85693705\n",
      "  0.8607738  0.86329854]]\n",
      "verdaderas salidas: [0.78419217]\n",
      "PERDIDAAAA antes: 0.006176861934363842\n",
      "Predicción post entrenamiento : [[0.85957634]]\n",
      "PERDIDAAAA despues: 0.005682777613401413\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "[[[0.84134799]\n",
      "  [0.84533924]\n",
      "  [0.84884197]\n",
      "  [0.85253435]\n",
      "  [0.85693705]\n",
      "  [0.8607738 ]\n",
      "  [0.86329854]\n",
      "  [0.86278516]]]\n",
      "ejemplar: [0.84134799 0.84533924 0.84884197 0.85253435 0.85693705 0.8607738\n",
      " 0.86329854 0.86278516]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.86116004]]\n",
      "Lr que voy a aplicar en el lote: 127 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.84134799 0.84533924 0.84884197 0.85253435 0.85693705 0.8607738\n",
      "  0.86329854 0.86278516]]\n",
      "verdaderas salidas: [0.85974429]\n",
      "PERDIDAAAA antes: 2.0042900814587483e-06\n",
      "Predicción post entrenamiento : [[0.85798824]]\n",
      "PERDIDAAAA despues: 3.0837891245028004e-06\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "[[[0.84533924]\n",
      "  [0.84884197]\n",
      "  [0.85253435]\n",
      "  [0.85693705]\n",
      "  [0.8607738 ]\n",
      "  [0.86329854]\n",
      "  [0.86278516]\n",
      "  [0.86116004]]]\n",
      "ejemplar: [0.84533924 0.84884197 0.85253435 0.85693705 0.8607738  0.86329854\n",
      " 0.86278516 0.86116004]\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.8595094]]\n",
      "Lr que voy a aplicar en el lote: 128 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.84533924 0.84884197 0.85253435 0.85693705 0.8607738  0.86329854\n",
      "  0.86278516 0.86116004]]\n",
      "verdaderas salidas: [0.85432003]\n",
      "PERDIDAAAA antes: 2.692944872251246e-05\n",
      "Predicción post entrenamiento : [[0.85742307]]\n",
      "PERDIDAAAA despues: 9.628719453758094e-06\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "[[[0.84884197]\n",
      "  [0.85253435]\n",
      "  [0.85693705]\n",
      "  [0.8607738 ]\n",
      "  [0.86329854]\n",
      "  [0.86278516]\n",
      "  [0.86116004]\n",
      "  [0.85950941]]]\n",
      "ejemplar: [0.84884197 0.85253435 0.85693705 0.8607738  0.86329854 0.86278516\n",
      " 0.86116004 0.85950941]\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.858805]]\n",
      "Lr que voy a aplicar en el lote: 129 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.84884197 0.85253435 0.85693705 0.8607738  0.86329854 0.86278516\n",
      "  0.86116004 0.85950941]]\n",
      "verdaderas salidas: [0.83688493]\n",
      "PERDIDAAAA antes: 0.00048049012548290193\n",
      "Predicción post entrenamiento : [[0.85493714]]\n",
      "PERDIDAAAA despues: 0.00032588266185484827\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "[[[0.85253435]\n",
      "  [0.85693705]\n",
      "  [0.8607738 ]\n",
      "  [0.86329854]\n",
      "  [0.86278516]\n",
      "  [0.86116004]\n",
      "  [0.85950941]\n",
      "  [0.858805  ]]]\n",
      "ejemplar: [0.85253435 0.85693705 0.8607738  0.86329854 0.86278516 0.86116004\n",
      " 0.85950941 0.858805  ]\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.85616565]]\n",
      "Lr que voy a aplicar en el lote: 130 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.85253435 0.85693705 0.8607738  0.86329854 0.86278516 0.86116004\n",
      "  0.85950941 0.858805  ]]\n",
      "verdaderas salidas: [0.82991089]\n",
      "PERDIDAAAA antes: 0.0006893131067045033\n",
      "Predicción post entrenamiento : [[0.8527793]]\n",
      "PERDIDAAAA despues: 0.0005229662056080997\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "[[[0.85693705]\n",
      "  [0.8607738 ]\n",
      "  [0.86329854]\n",
      "  [0.86278516]\n",
      "  [0.86116004]\n",
      "  [0.85950941]\n",
      "  [0.858805  ]\n",
      "  [0.85616565]]]\n",
      "ejemplar: [0.85693705 0.8607738  0.86329854 0.86278516 0.86116004 0.85950941\n",
      " 0.858805   0.85616565]\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.85373867]]\n",
      "Lr que voy a aplicar en el lote: 131 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.85693705 0.8607738  0.86329854 0.86278516 0.86116004 0.85950941\n",
      "  0.858805   0.85616565]]\n",
      "verdaderas salidas: [0.887253]\n",
      "PERDIDAAAA antes: 0.0011232097167521715\n",
      "Predicción post entrenamiento : [[0.8501809]]\n",
      "PERDIDAAAA despues: 0.0013743378221988678\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "[[[0.8607738 ]\n",
      "  [0.86329854]\n",
      "  [0.86278516]\n",
      "  [0.86116004]\n",
      "  [0.85950941]\n",
      "  [0.858805  ]\n",
      "  [0.85616565]\n",
      "  [0.85373867]]]\n",
      "ejemplar: [0.8607738  0.86329854 0.86278516 0.86116004 0.85950941 0.858805\n",
      " 0.85616565 0.85373867]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.8506595]]\n",
      "Lr que voy a aplicar en el lote: 132 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.8607738  0.86329854 0.86278516 0.86116004 0.85950941 0.858805\n",
      "  0.85616565 0.85373867]]\n",
      "verdaderas salidas: [0.85974429]\n",
      "PERDIDAAAA antes: 8.253396663349122e-05\n",
      "Predicción post entrenamiento : [[0.8484875]]\n",
      "PERDIDAAAA despues: 0.00012671586591750383\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "[[[0.86329854]\n",
      "  [0.86278516]\n",
      "  [0.86116004]\n",
      "  [0.85950941]\n",
      "  [0.858805  ]\n",
      "  [0.85616565]\n",
      "  [0.85373867]\n",
      "  [0.85065949]]]\n",
      "ejemplar: [0.86329854 0.86278516 0.86116004 0.85950941 0.858805   0.85616565\n",
      " 0.85373867 0.85065949]\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.848428]]\n",
      "Lr que voy a aplicar en el lote: 133 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.86329854 0.86278516 0.86116004 0.85950941 0.858805   0.85616565\n",
      "  0.85373867 0.85065949]]\n",
      "verdaderas salidas: [0.83959706]\n",
      "PERDIDAAAA antes: 7.798593287589028e-05\n",
      "Predicción post entrenamiento : [[0.8462419]]\n",
      "PERDIDAAAA despues: 4.4153966882731766e-05\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "[[[0.86278516]\n",
      "  [0.86116004]\n",
      "  [0.85950941]\n",
      "  [0.858805  ]\n",
      "  [0.85616565]\n",
      "  [0.85373867]\n",
      "  [0.85065949]\n",
      "  [0.84842801]]]\n",
      "ejemplar: [0.86278516 0.86116004 0.85950941 0.858805   0.85616565 0.85373867\n",
      " 0.85065949 0.84842801]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.8456982]]\n",
      "Lr que voy a aplicar en el lote: 134 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.86278516 0.86116004 0.85950941 0.858805   0.85616565 0.85373867\n",
      "  0.85065949 0.84842801]]\n",
      "verdaderas salidas: [0.78380473]\n",
      "PERDIDAAAA antes: 0.0038308007642626762\n",
      "Predicción post entrenamiento : [[0.84231514]]\n",
      "PERDIDAAAA despues: 0.0034234696067869663\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "[[[0.86116004]\n",
      "  [0.85950941]\n",
      "  [0.858805  ]\n",
      "  [0.85616565]\n",
      "  [0.85373867]\n",
      "  [0.85065949]\n",
      "  [0.84842801]\n",
      "  [0.84569818]]]\n",
      "ejemplar: [0.86116004 0.85950941 0.858805   0.85616565 0.85373867 0.85065949\n",
      " 0.84842801 0.84569818]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.8416097]]\n",
      "Lr que voy a aplicar en el lote: 135 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.86116004 0.85950941 0.858805   0.85616565 0.85373867 0.85065949\n",
      "  0.84842801 0.84569818]]\n",
      "verdaderas salidas: [0.81828749]\n",
      "PERDIDAAAA antes: 0.0005439261440187693\n",
      "Predicción post entrenamiento : [[0.83865094]]\n",
      "PERDIDAAAA despues: 0.0004146700957790017\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "[[[0.85950941]\n",
      "  [0.858805  ]\n",
      "  [0.85616565]\n",
      "  [0.85373867]\n",
      "  [0.85065949]\n",
      "  [0.84842801]\n",
      "  [0.84569818]\n",
      "  [0.84160972]]]\n",
      "ejemplar: [0.85950941 0.858805   0.85616565 0.85373867 0.85065949 0.84842801\n",
      " 0.84569818 0.84160972]\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.83789206]]\n",
      "Lr que voy a aplicar en el lote: 136 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.85950941 0.858805   0.85616565 0.85373867 0.85065949 0.84842801\n",
      "  0.84569818 0.84160972]]\n",
      "verdaderas salidas: [0.79116621]\n",
      "PERDIDAAAA antes: 0.002183306962251663\n",
      "Predicción post entrenamiento : [[0.83454555]]\n",
      "PERDIDAAAA despues: 0.0018817693926393986\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "[[[0.858805  ]\n",
      "  [0.85616565]\n",
      "  [0.85373867]\n",
      "  [0.85065949]\n",
      "  [0.84842801]\n",
      "  [0.84569818]\n",
      "  [0.84160972]\n",
      "  [0.83789206]]]\n",
      "ejemplar: [0.858805   0.85616565 0.85373867 0.85065949 0.84842801 0.84569818\n",
      " 0.84160972 0.83789206]\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.8337083]]\n",
      "Lr que voy a aplicar en el lote: 137 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.858805   0.85616565 0.85373867 0.85065949 0.84842801 0.84569818\n",
      "  0.84160972 0.83789206]]\n",
      "verdaderas salidas: [0.76055792]\n",
      "PERDIDAAAA antes: 0.005350971594452858\n",
      "Predicción post entrenamiento : [[0.829661]]\n",
      "PERDIDAAAA despues: 0.0047752331010997295\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "[[[0.85616565]\n",
      "  [0.85373867]\n",
      "  [0.85065949]\n",
      "  [0.84842801]\n",
      "  [0.84569818]\n",
      "  [0.84160972]\n",
      "  [0.83789206]\n",
      "  [0.83370829]]]\n",
      "ejemplar: [0.85616565 0.85373867 0.85065949 0.84842801 0.84569818 0.84160972\n",
      " 0.83789206 0.83370829]\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.82857996]]\n",
      "Lr que voy a aplicar en el lote: 138 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.85616565 0.85373867 0.85065949 0.84842801 0.84569818 0.84160972\n",
      "  0.83789206 0.83370829]]\n",
      "verdaderas salidas: [0.79155366]\n",
      "PERDIDAAAA antes: 0.0013709458289667964\n",
      "Predicción post entrenamiento : [[0.82404006]]\n",
      "PERDIDAAAA despues: 0.001055364846251905\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "[[[0.85373867]\n",
      "  [0.85065949]\n",
      "  [0.84842801]\n",
      "  [0.84569818]\n",
      "  [0.84160972]\n",
      "  [0.83789206]\n",
      "  [0.83370829]\n",
      "  [0.82857996]]]\n",
      "ejemplar: [0.85373867 0.85065949 0.84842801 0.84569818 0.84160972 0.83789206\n",
      " 0.83370829 0.82857996]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.82292014]]\n",
      "Lr que voy a aplicar en el lote: 139 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.85373867 0.85065949 0.84842801 0.84569818 0.84160972 0.83789206\n",
      "  0.83370829 0.82857996]]\n",
      "verdaderas salidas: [0.7686943]\n",
      "PERDIDAAAA antes: 0.002940444042906165\n",
      "Predicción post entrenamiento : [[0.81824744]]\n",
      "PERDIDAAAA despues: 0.002455515321344137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "[[[0.85065949]\n",
      "  [0.84842801]\n",
      "  [0.84569818]\n",
      "  [0.84160972]\n",
      "  [0.83789206]\n",
      "  [0.83370829]\n",
      "  [0.82857996]\n",
      "  [0.82292014]]]\n",
      "ejemplar: [0.85065949 0.84842801 0.84569818 0.84160972 0.83789206 0.83370829\n",
      " 0.82857996 0.82292014]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.81702906]]\n",
      "Lr que voy a aplicar en el lote: 140 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.85065949 0.84842801 0.84569818 0.84160972 0.83789206 0.83370829\n",
      "  0.82857996 0.82292014]]\n",
      "verdaderas salidas: [0.7686943]\n",
      "PERDIDAAAA antes: 0.0023362506181001663\n",
      "Predicción post entrenamiento : [[0.8122539]]\n",
      "PERDIDAAAA despues: 0.0018974397098645568\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "[[[0.84842801]\n",
      "  [0.84569818]\n",
      "  [0.84160972]\n",
      "  [0.83789206]\n",
      "  [0.83370829]\n",
      "  [0.82857996]\n",
      "  [0.82292014]\n",
      "  [0.81702906]]]\n",
      "ejemplar: [0.84842801 0.84569818 0.84160972 0.83789206 0.83370829 0.82857996\n",
      " 0.82292014 0.81702906]\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.81097937]]\n",
      "Lr que voy a aplicar en el lote: 141 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.84842801 0.84569818 0.84160972 0.83789206 0.83370829 0.82857996\n",
      "  0.82292014 0.81702906]]\n",
      "verdaderas salidas: [0.79891515]\n",
      "PERDIDAAAA antes: 0.00014554537483491004\n",
      "Predicción post entrenamiento : [[0.8053412]]\n",
      "PERDIDAAAA despues: 4.1293944377684966e-05\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "[[[0.84569818]\n",
      "  [0.84160972]\n",
      "  [0.83789206]\n",
      "  [0.83370829]\n",
      "  [0.82857996]\n",
      "  [0.82292014]\n",
      "  [0.81702906]\n",
      "  [0.81097937]]]\n",
      "ejemplar: [0.84569818 0.84160972 0.83789206 0.83370829 0.82857996 0.82292014\n",
      " 0.81702906 0.81097937]\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.8038571]]\n",
      "Lr que voy a aplicar en el lote: 142 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.84569818 0.84160972 0.83789206 0.83370829 0.82857996 0.82292014\n",
      "  0.81702906 0.81097937]]\n",
      "verdaderas salidas: [0.79000387]\n",
      "PERDIDAAAA antes: 0.00019191093451809138\n",
      "Predicción post entrenamiento : [[0.798826]]\n",
      "PERDIDAAAA despues: 7.782915781717747e-05\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "[[[0.84160972]\n",
      "  [0.83789206]\n",
      "  [0.83370829]\n",
      "  [0.82857996]\n",
      "  [0.82292014]\n",
      "  [0.81702906]\n",
      "  [0.81097937]\n",
      "  [0.80385709]]]\n",
      "ejemplar: [0.84160972 0.83789206 0.83370829 0.82857996 0.82292014 0.81702906\n",
      " 0.81097937 0.80385709]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.7971304]]\n",
      "Lr que voy a aplicar en el lote: 143 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.84160972 0.83789206 0.83370829 0.82857996 0.82292014 0.81702906\n",
      "  0.81097937 0.80385709]]\n",
      "verdaderas salidas: [0.76017048]\n",
      "PERDIDAAAA antes: 0.001366037642583251\n",
      "Predicción post entrenamiento : [[0.7923526]]\n",
      "PERDIDAAAA despues: 0.0010356912389397621\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "[[[0.83789206]\n",
      "  [0.83370829]\n",
      "  [0.82857996]\n",
      "  [0.82292014]\n",
      "  [0.81702906]\n",
      "  [0.81097937]\n",
      "  [0.80385709]\n",
      "  [0.79713041]]]\n",
      "ejemplar: [0.83789206 0.83370829 0.82857996 0.82292014 0.81702906 0.81097937\n",
      " 0.80385709 0.79713041]\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.79055876]]\n",
      "Lr que voy a aplicar en el lote: 144 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.83789206 0.83370829 0.82857996 0.82292014 0.81702906 0.81097937\n",
      "  0.80385709 0.79713041]]\n",
      "verdaderas salidas: [0.68539326]\n",
      "PERDIDAAAA antes: 0.011059778742492199\n",
      "Predicción post entrenamiento : [[0.78482103]]\n",
      "PERDIDAAAA despues: 0.0098858792334795\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "[[[0.83370829]\n",
      "  [0.82857996]\n",
      "  [0.82292014]\n",
      "  [0.81702906]\n",
      "  [0.81097937]\n",
      "  [0.80385709]\n",
      "  [0.79713041]\n",
      "  [0.79055876]]]\n",
      "ejemplar: [0.83370829 0.82857996 0.82292014 0.81702906 0.81097937 0.80385709\n",
      " 0.79713041 0.79055876]\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.782839]]\n",
      "Lr que voy a aplicar en el lote: 145 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.83370829 0.82857996 0.82292014 0.81702906 0.81097937 0.80385709\n",
      "  0.79713041 0.79055876]]\n",
      "verdaderas salidas: [0.60519179]\n",
      "PERDIDAAAA antes: 0.03155853971838951\n",
      "Predicción post entrenamiento : [[0.77498776]]\n",
      "PERDIDAAAA despues: 0.02883067913353443\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "[[[0.82857996]\n",
      "  [0.82292014]\n",
      "  [0.81702906]\n",
      "  [0.81097937]\n",
      "  [0.80385709]\n",
      "  [0.79713041]\n",
      "  [0.79055876]\n",
      "  [0.782839  ]]]\n",
      "ejemplar: [0.82857996 0.82292014 0.81702906 0.81097937 0.80385709 0.79713041\n",
      " 0.79055876 0.782839  ]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.77282935]]\n",
      "Lr que voy a aplicar en el lote: 146 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.82857996 0.82292014 0.81702906 0.81097937 0.80385709 0.79713041\n",
      "  0.79055876 0.782839  ]]\n",
      "verdaderas salidas: [0.66485858]\n",
      "PERDIDAAAA antes: 0.011657687835395336\n",
      "Predicción post entrenamiento : [[0.7640453]]\n",
      "PERDIDAAAA despues: 0.009838005527853966\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "[[[0.82292014]\n",
      "  [0.81702906]\n",
      "  [0.81097937]\n",
      "  [0.80385709]\n",
      "  [0.79713041]\n",
      "  [0.79055876]\n",
      "  [0.782839  ]\n",
      "  [0.77282935]]]\n",
      "ejemplar: [0.82292014 0.81702906 0.81097937 0.80385709 0.79713041 0.79055876\n",
      " 0.782839   0.77282935]\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.7617783]]\n",
      "Lr que voy a aplicar en el lote: 147 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.82292014 0.81702906 0.81097937 0.80385709 0.79713041 0.79055876\n",
      "  0.782839   0.77282935]]\n",
      "verdaderas salidas: [0.70786517]\n",
      "PERDIDAAAA antes: 0.0029066242277622223\n",
      "Predicción post entrenamiento : [[0.75390947]]\n",
      "PERDIDAAAA despues: 0.0021200766786932945\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "[[[0.81702906]\n",
      "  [0.81097937]\n",
      "  [0.80385709]\n",
      "  [0.79713041]\n",
      "  [0.79055876]\n",
      "  [0.782839  ]\n",
      "  [0.77282935]\n",
      "  [0.7617783 ]]]\n",
      "ejemplar: [0.81702906 0.81097937 0.80385709 0.79713041 0.79055876 0.782839\n",
      " 0.77282935 0.7617783 ]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.7515442]]\n",
      "Lr que voy a aplicar en el lote: 148 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.81702906 0.81097937 0.80385709 0.79713041 0.79055876 0.782839\n",
      "  0.77282935 0.7617783 ]]\n",
      "verdaderas salidas: [0.66485858]\n",
      "PERDIDAAAA antes: 0.0075143929570913315\n",
      "Predicción post entrenamiento : [[0.7437112]]\n",
      "PERDIDAAAA despues: 0.00621773162856698\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "[[[0.81097937]\n",
      "  [0.80385709]\n",
      "  [0.79713041]\n",
      "  [0.79055876]\n",
      "  [0.782839  ]\n",
      "  [0.77282935]\n",
      "  [0.7617783 ]\n",
      "  [0.75154418]]]\n",
      "ejemplar: [0.81097937 0.80385709 0.79713041 0.79055876 0.782839   0.77282935\n",
      " 0.7617783  0.75154418]\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.7412196]]\n",
      "Lr que voy a aplicar en el lote: 149 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.81097937 0.80385709 0.79713041 0.79055876 0.782839   0.77282935\n",
      "  0.7617783  0.75154418]]\n",
      "verdaderas salidas: [0.71135219]\n",
      "PERDIDAAAA antes: 0.0008920622058212757\n",
      "Predicción post entrenamiento : [[0.733771]]\n",
      "PERDIDAAAA despues: 0.0005026051076129079\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "[[[0.80385709]\n",
      "  [0.79713041]\n",
      "  [0.79055876]\n",
      "  [0.782839  ]\n",
      "  [0.77282935]\n",
      "  [0.7617783 ]\n",
      "  [0.75154418]\n",
      "  [0.74121958]]]\n",
      "ejemplar: [0.80385709 0.79713041 0.79055876 0.782839   0.77282935 0.7617783\n",
      " 0.75154418 0.74121958]\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.73110837]]\n",
      "Lr que voy a aplicar en el lote: 150 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.80385709 0.79713041 0.79055876 0.782839   0.77282935 0.7617783\n",
      "  0.75154418 0.74121958]]\n",
      "verdaderas salidas: [0.67725688]\n",
      "PERDIDAAAA antes: 0.002899982500821352\n",
      "Predicción post entrenamiento : [[0.7237915]]\n",
      "PERDIDAAAA despues: 0.0021654688753187656\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "[[[0.79713041]\n",
      "  [0.79055876]\n",
      "  [0.782839  ]\n",
      "  [0.77282935]\n",
      "  [0.7617783 ]\n",
      "  [0.75154418]\n",
      "  [0.74121958]\n",
      "  [0.73110837]]]\n",
      "ejemplar: [0.79713041 0.79055876 0.782839   0.77282935 0.7617783  0.75154418\n",
      " 0.74121958 0.73110837]\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.7210183]]\n",
      "Lr que voy a aplicar en el lote: 151 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.79713041 0.79055876 0.782839   0.77282935 0.7617783  0.75154418\n",
      "  0.74121958 0.73110837]]\n",
      "verdaderas salidas: [0.76210771]\n",
      "PERDIDAAAA antes: 0.0016883400967344642\n",
      "Predicción post entrenamiento : [[0.7152226]]\n",
      "PERDIDAAAA despues: 0.002198215574026108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "[[[0.79055876]\n",
      "  [0.782839  ]\n",
      "  [0.77282935]\n",
      "  [0.7617783 ]\n",
      "  [0.75154418]\n",
      "  [0.74121958]\n",
      "  [0.73110837]\n",
      "  [0.72101831]]]\n",
      "ejemplar: [0.79055876 0.782839   0.77282935 0.7617783  0.75154418 0.74121958\n",
      " 0.73110837 0.72101831]\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.71223104]]\n",
      "Lr que voy a aplicar en el lote: 152 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.79055876 0.782839   0.77282935 0.7617783  0.75154418 0.74121958\n",
      "  0.73110837 0.72101831]]\n",
      "verdaderas salidas: [0.80705153]\n",
      "PERDIDAAAA antes: 0.008990926668047905\n",
      "Predicción post entrenamiento : [[0.70836395]]\n",
      "PERDIDAAAA despues: 0.009739240631461143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "[[[0.782839  ]\n",
      "  [0.77282935]\n",
      "  [0.7617783 ]\n",
      "  [0.75154418]\n",
      "  [0.74121958]\n",
      "  [0.73110837]\n",
      "  [0.72101831]\n",
      "  [0.71223104]]]\n",
      "ejemplar: [0.782839   0.77282935 0.7617783  0.75154418 0.74121958 0.73110837\n",
      " 0.72101831 0.71223104]\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.70506793]]\n",
      "Lr que voy a aplicar en el lote: 153 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.782839   0.77282935 0.7617783  0.75154418 0.74121958 0.73110837\n",
      "  0.72101831 0.71223104]]\n",
      "verdaderas salidas: [0.81518791]\n",
      "PERDIDAAAA antes: 0.012126414105296135\n",
      "Predicción post entrenamiento : [[0.702231]]\n",
      "PERDIDAAAA despues: 0.012759270146489143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "[[[0.77282935]\n",
      "  [0.7617783 ]\n",
      "  [0.75154418]\n",
      "  [0.74121958]\n",
      "  [0.73110837]\n",
      "  [0.72101831]\n",
      "  [0.71223104]\n",
      "  [0.70506793]]]\n",
      "ejemplar: [0.77282935 0.7617783  0.75154418 0.74121958 0.73110837 0.72101831\n",
      " 0.71223104 0.70506793]\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.69870716]]\n",
      "Lr que voy a aplicar en el lote: 154 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.77282935 0.7617783  0.75154418 0.74121958 0.73110837 0.72101831\n",
      "  0.71223104 0.70506793]]\n",
      "verdaderas salidas: [0.90623789]\n",
      "PERDIDAAAA antes: 0.04306900501251221\n",
      "Predicción post entrenamiento : [[0.69726175]]\n",
      "PERDIDAAAA despues: 0.043671030551195145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "[[[0.7617783 ]\n",
      "  [0.75154418]\n",
      "  [0.74121958]\n",
      "  [0.73110837]\n",
      "  [0.72101831]\n",
      "  [0.71223104]\n",
      "  [0.70506793]\n",
      "  [0.69870716]]]\n",
      "ejemplar: [0.7617783  0.75154418 0.74121958 0.73110837 0.72101831 0.71223104\n",
      " 0.70506793 0.69870716]\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.6937485]]\n",
      "Lr que voy a aplicar en el lote: 155 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.7617783  0.75154418 0.74121958 0.73110837 0.72101831 0.71223104\n",
      "  0.70506793 0.69870716]]\n",
      "verdaderas salidas: [0.95970554]\n",
      "PERDIDAAAA antes: 0.07073315978050232\n",
      "Predicción post entrenamiento : [[0.69347614]]\n",
      "PERDIDAAAA despues: 0.07087808847427368\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "[[[0.75154418]\n",
      "  [0.74121958]\n",
      "  [0.73110837]\n",
      "  [0.72101831]\n",
      "  [0.71223104]\n",
      "  [0.70506793]\n",
      "  [0.69870716]\n",
      "  [0.69374847]]]\n",
      "ejemplar: [0.75154418 0.74121958 0.73110837 0.72101831 0.71223104 0.70506793\n",
      " 0.69870716 0.69374847]\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.6901242]]\n",
      "Lr que voy a aplicar en el lote: 156 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.75154418 0.74121958 0.73110837 0.72101831 0.71223104 0.70506793\n",
      "  0.69870716 0.69374847]]\n",
      "verdaderas salidas: [0.9643549]\n",
      "PERDIDAAAA antes: 0.07520245760679245\n",
      "Predicción post entrenamiento : [[0.69119245]]\n",
      "PERDIDAAAA despues: 0.07461771368980408\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "[[[0.74121958]\n",
      "  [0.73110837]\n",
      "  [0.72101831]\n",
      "  [0.71223104]\n",
      "  [0.70506793]\n",
      "  [0.69870716]\n",
      "  [0.69374847]\n",
      "  [0.69012421]]]\n",
      "ejemplar: [0.74121958 0.73110837 0.72101831 0.71223104 0.70506793 0.69870716\n",
      " 0.69374847 0.69012421]\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.68797535]]\n",
      "Lr que voy a aplicar en el lote: 157 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.74121958 0.73110837 0.72101831 0.71223104 0.70506793 0.69870716\n",
      "  0.69374847 0.69012421]]\n",
      "verdaderas salidas: [0.8880279]\n",
      "PERDIDAAAA antes: 0.040021028369665146\n",
      "Predicción post entrenamiento : [[0.6903667]]\n",
      "PERDIDAAAA despues: 0.03906995803117752\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "[[[0.73110837]\n",
      "  [0.72101831]\n",
      "  [0.71223104]\n",
      "  [0.70506793]\n",
      "  [0.69870716]\n",
      "  [0.69374847]\n",
      "  [0.69012421]\n",
      "  [0.68797535]]]\n",
      "ejemplar: [0.73110837 0.72101831 0.71223104 0.70506793 0.69870716 0.69374847\n",
      " 0.69012421 0.68797535]\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.6873723]]\n",
      "Lr que voy a aplicar en el lote: 158 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.73110837 0.72101831 0.71223104 0.70506793 0.69870716 0.69374847\n",
      "  0.69012421 0.68797535]]\n",
      "verdaderas salidas: [0.89267726]\n",
      "PERDIDAAAA antes: 0.0421501100063324\n",
      "Predicción post entrenamiento : [[0.69077325]]\n",
      "PERDIDAAAA despues: 0.040765225887298584\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "[[[0.72101831]\n",
      "  [0.71223104]\n",
      "  [0.70506793]\n",
      "  [0.69870716]\n",
      "  [0.69374847]\n",
      "  [0.69012421]\n",
      "  [0.68797535]\n",
      "  [0.68737233]]]\n",
      "ejemplar: [0.72101831 0.71223104 0.70506793 0.69870716 0.69374847 0.69012421\n",
      " 0.68797535 0.68737233]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.68808556]]\n",
      "Lr que voy a aplicar en el lote: 159 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.72101831 0.71223104 0.70506793 0.69870716 0.69374847 0.69012421\n",
      "  0.68797535 0.68737233]]\n",
      "verdaderas salidas: [0.87524215]\n",
      "PERDIDAAAA antes: 0.035027600824832916\n",
      "Predicción post entrenamiento : [[0.6920419]]\n",
      "PERDIDAAAA despues: 0.033562351018190384\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "[[[0.71223104]\n",
      "  [0.70506793]\n",
      "  [0.69870716]\n",
      "  [0.69374847]\n",
      "  [0.69012421]\n",
      "  [0.68797535]\n",
      "  [0.68737233]\n",
      "  [0.68808556]]]\n",
      "ejemplar: [0.71223104 0.70506793 0.69870716 0.69374847 0.69012421 0.68797535\n",
      " 0.68737233 0.68808556]\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.68979335]]\n",
      "Lr que voy a aplicar en el lote: 160 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.71223104 0.70506793 0.69870716 0.69374847 0.69012421 0.68797535\n",
      "  0.68737233 0.68808556]]\n",
      "verdaderas salidas: [0.85083301]\n",
      "PERDIDAAAA antes: 0.02593376860022545\n",
      "Predicción post entrenamiento : [[0.6944759]]\n",
      "PERDIDAAAA despues: 0.024447545409202576\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "[[[0.70506793]\n",
      "  [0.69870716]\n",
      "  [0.69374847]\n",
      "  [0.69012421]\n",
      "  [0.68797535]\n",
      "  [0.68737233]\n",
      "  [0.68808556]\n",
      "  [0.68979335]]]\n",
      "ejemplar: [0.70506793 0.69870716 0.69374847 0.69012421 0.68797535 0.68737233\n",
      " 0.68808556 0.68979335]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.6926743]]\n",
      "Lr que voy a aplicar en el lote: 161 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.70506793 0.69870716 0.69374847 0.69012421 0.68797535 0.68737233\n",
      "  0.68808556 0.68979335]]\n",
      "verdaderas salidas: [0.84889578]\n",
      "PERDIDAAAA antes: 0.024405159056186676\n",
      "Predicción post entrenamiento : [[0.69805586]]\n",
      "PERDIDAAAA despues: 0.022752683609724045\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "[[[0.69870716]\n",
      "  [0.69374847]\n",
      "  [0.69012421]\n",
      "  [0.68797535]\n",
      "  [0.68737233]\n",
      "  [0.68808556]\n",
      "  [0.68979335]\n",
      "  [0.69267428]]]\n",
      "ejemplar: [0.69870716 0.69374847 0.69012421 0.68797535 0.68737233 0.68808556\n",
      " 0.68979335 0.69267428]\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.69667137]]\n",
      "Lr que voy a aplicar en el lote: 162 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.69870716 0.69374847 0.69012421 0.68797535 0.68737233 0.68808556\n",
      "  0.68979335 0.69267428]]\n",
      "verdaderas salidas: [0.96241767]\n",
      "PERDIDAAAA antes: 0.07062109559774399\n",
      "Predicción post entrenamiento : [[0.7035742]]\n",
      "PERDIDAAAA despues: 0.06699994951486588\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "[[[0.69374847]\n",
      "  [0.69012421]\n",
      "  [0.68797535]\n",
      "  [0.68737233]\n",
      "  [0.68808556]\n",
      "  [0.68979335]\n",
      "  [0.69267428]\n",
      "  [0.69667137]]]\n",
      "ejemplar: [0.69374847 0.69012421 0.68797535 0.68737233 0.68808556 0.68979335\n",
      " 0.69267428 0.69667137]\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.7026699]]\n",
      "Lr que voy a aplicar en el lote: 163 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.69374847 0.69012421 0.68797535 0.68737233 0.68808556 0.68979335\n",
      "  0.69267428 0.69667137]]\n",
      "verdaderas salidas: [0.96784192]\n",
      "PERDIDAAAA antes: 0.07031619548797607\n",
      "Predicción post entrenamiento : [[0.7109285]]\n",
      "PERDIDAAAA despues: 0.06600450724363327\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "[[[0.69012421]\n",
      "  [0.68797535]\n",
      "  [0.68737233]\n",
      "  [0.68808556]\n",
      "  [0.68979335]\n",
      "  [0.69267428]\n",
      "  [0.69667137]\n",
      "  [0.70266992]]]\n",
      "ejemplar: [0.69012421 0.68797535 0.68737233 0.68808556 0.68979335 0.69267428\n",
      " 0.69667137 0.70266992]\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.7105092]]\n",
      "Lr que voy a aplicar en el lote: 164 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.69012421 0.68797535 0.68737233 0.68808556 0.68979335 0.69267428\n",
      "  0.69667137 0.70266992]]\n",
      "verdaderas salidas: [0.94072065]\n",
      "PERDIDAAAA antes: 0.05299733206629753\n",
      "Predicción post entrenamiento : [[0.7195158]]\n",
      "PERDIDAAAA despues: 0.04893159866333008\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "[[[0.68797535]\n",
      "  [0.68737233]\n",
      "  [0.68808556]\n",
      "  [0.68979335]\n",
      "  [0.69267428]\n",
      "  [0.69667137]\n",
      "  [0.70266992]\n",
      "  [0.71050918]]]\n",
      "ejemplar: [0.68797535 0.68737233 0.68808556 0.68979335 0.69267428 0.69667137\n",
      " 0.70266992 0.71050918]\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.7195974]]\n",
      "Lr que voy a aplicar en el lote: 165 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.68797535 0.68737233 0.68808556 0.68979335 0.69267428 0.69667137\n",
      "  0.70266992 0.71050918]]\n",
      "verdaderas salidas: [0.97249128]\n",
      "PERDIDAAAA antes: 0.06395530700683594\n",
      "Predicción post entrenamiento : [[0.72993773]]\n",
      "PERDIDAAAA despues: 0.05883221700787544\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "[[[0.68737233]\n",
      "  [0.68808556]\n",
      "  [0.68979335]\n",
      "  [0.69267428]\n",
      "  [0.69667137]\n",
      "  [0.70266992]\n",
      "  [0.71050918]\n",
      "  [0.7195974 ]]]\n",
      "ejemplar: [0.68737233 0.68808556 0.68979335 0.69267428 0.69667137 0.70266992\n",
      " 0.71050918 0.7195974 ]\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.7305224]]\n",
      "Lr que voy a aplicar en el lote: 166 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.68737233 0.68808556 0.68979335 0.69267428 0.69667137 0.70266992\n",
      "  0.71050918 0.7195974 ]]\n",
      "verdaderas salidas: [0.99690043]\n",
      "PERDIDAAAA antes: 0.07095726579427719\n",
      "Predicción post entrenamiento : [[0.74124783]]\n",
      "PERDIDAAAA despues: 0.06535825878381729\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "[[[0.68808556]\n",
      "  [0.68979335]\n",
      "  [0.69267428]\n",
      "  [0.69667137]\n",
      "  [0.70266992]\n",
      "  [0.71050918]\n",
      "  [0.7195974 ]\n",
      "  [0.73052239]]]\n",
      "ejemplar: [0.68808556 0.68979335 0.69267428 0.69667137 0.70266992 0.71050918\n",
      " 0.7195974  0.73052239]\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.74233]]\n",
      "Lr que voy a aplicar en el lote: 167 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.68808556 0.68979335 0.69267428 0.69667137 0.70266992 0.71050918\n",
      "  0.7195974  0.73052239]]\n",
      "verdaderas salidas: [0.95118171]\n",
      "PERDIDAAAA antes: 0.043619029223918915\n",
      "Predicción post entrenamiento : [[0.7537788]]\n",
      "PERDIDAAAA despues: 0.03896790370345116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "[[[0.68979335]\n",
      "  [0.69267428]\n",
      "  [0.69667137]\n",
      "  [0.70266992]\n",
      "  [0.71050918]\n",
      "  [0.7195974 ]\n",
      "  [0.73052239]\n",
      "  [0.74233001]]]\n",
      "ejemplar: [0.68979335 0.69267428 0.69667137 0.70266992 0.71050918 0.7195974\n",
      " 0.73052239 0.74233001]\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.7553837]]\n",
      "Lr que voy a aplicar en el lote: 168 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.68979335 0.69267428 0.69667137 0.70266992 0.71050918 0.7195974\n",
      "  0.73052239 0.74233001]]\n",
      "verdaderas salidas: [0.89577683]\n",
      "PERDIDAAAA antes: 0.019710233435034752\n",
      "Predicción post entrenamiento : [[0.7660992]]\n",
      "PERDIDAAAA despues: 0.0168162789195776\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "[[[0.69267428]\n",
      "  [0.69667137]\n",
      "  [0.70266992]\n",
      "  [0.71050918]\n",
      "  [0.7195974 ]\n",
      "  [0.73052239]\n",
      "  [0.74233001]\n",
      "  [0.75538367]]]\n",
      "ejemplar: [0.69267428 0.69667137 0.70266992 0.71050918 0.7195974  0.73052239\n",
      " 0.74233001 0.75538367]\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.7682955]]\n",
      "Lr que voy a aplicar en el lote: 169 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.69267428 0.69667137 0.70266992 0.71050918 0.7195974  0.73052239\n",
      "  0.74233001 0.75538367]]\n",
      "verdaderas salidas: [0.8814413]\n",
      "PERDIDAAAA antes: 0.01280196476727724\n",
      "Predicción post entrenamiento : [[0.77771056]]\n",
      "PERDIDAAAA despues: 0.010760066099464893\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "[[[0.69667137]\n",
      "  [0.70266992]\n",
      "  [0.71050918]\n",
      "  [0.7195974 ]\n",
      "  [0.73052239]\n",
      "  [0.74233001]\n",
      "  [0.75538367]\n",
      "  [0.76829553]]]\n",
      "ejemplar: [0.69667137 0.70266992 0.71050918 0.7195974  0.73052239 0.74233001\n",
      " 0.75538367 0.76829553]\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.7805462]]\n",
      "Lr que voy a aplicar en el lote: 170 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.69667137 0.70266992 0.71050918 0.7195974  0.73052239 0.74233001\n",
      "  0.75538367 0.76829553]]\n",
      "verdaderas salidas: [0.9170864]\n",
      "PERDIDAAAA antes: 0.01864323578774929\n",
      "Predicción post entrenamiento : [[0.79043955]]\n",
      "PERDIDAAAA despues: 0.01603943109512329\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "[[[0.70266992]\n",
      "  [0.71050918]\n",
      "  [0.7195974 ]\n",
      "  [0.73052239]\n",
      "  [0.74233001]\n",
      "  [0.75538367]\n",
      "  [0.76829553]\n",
      "  [0.78054619]]]\n",
      "ejemplar: [0.70266992 0.71050918 0.7195974  0.73052239 0.74233001 0.75538367\n",
      " 0.76829553 0.78054619]\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.7939705]]\n",
      "Lr que voy a aplicar en el lote: 171 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.70266992 0.71050918 0.7195974  0.73052239 0.74233001 0.75538367\n",
      "  0.76829553 0.78054619]]\n",
      "verdaderas salidas: [0.91979853]\n",
      "PERDIDAAAA antes: 0.01583269238471985\n",
      "Predicción post entrenamiento : [[0.8042642]]\n",
      "PERDIDAAAA despues: 0.013348189182579517\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "[[[0.71050918]\n",
      "  [0.7195974 ]\n",
      "  [0.73052239]\n",
      "  [0.74233001]\n",
      "  [0.75538367]\n",
      "  [0.76829553]\n",
      "  [0.78054619]\n",
      "  [0.79397053]]]\n",
      "ejemplar: [0.71050918 0.7195974  0.73052239 0.74233001 0.75538367 0.76829553\n",
      " 0.78054619 0.79397053]\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.8084116]]\n",
      "Lr que voy a aplicar en el lote: 172 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.71050918 0.7195974  0.73052239 0.74233001 0.75538367 0.76829553\n",
      "  0.78054619 0.79397053]]\n",
      "verdaderas salidas: [0.96164277]\n",
      "PERDIDAAAA antes: 0.023479802533984184\n",
      "Predicción post entrenamiento : [[0.8192428]]\n",
      "PERDIDAAAA despues: 0.02027776837348938\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "[[[0.7195974 ]\n",
      "  [0.73052239]\n",
      "  [0.74233001]\n",
      "  [0.75538367]\n",
      "  [0.76829553]\n",
      "  [0.78054619]\n",
      "  [0.79397053]\n",
      "  [0.8084116 ]]]\n",
      "ejemplar: [0.7195974  0.73052239 0.74233001 0.75538367 0.76829553 0.78054619\n",
      " 0.79397053 0.8084116 ]\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.8239153]]\n",
      "Lr que voy a aplicar en el lote: 173 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.7195974  0.73052239 0.74233001 0.75538367 0.76829553 0.78054619\n",
      "  0.79397053 0.8084116 ]]\n",
      "verdaderas salidas: [0.96822937]\n",
      "PERDIDAAAA antes: 0.020826544612646103\n",
      "Predicción post entrenamiento : [[0.8358205]]\n",
      "PERDIDAAAA despues: 0.01753210462629795\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "[[[0.73052239]\n",
      "  [0.74233001]\n",
      "  [0.75538367]\n",
      "  [0.76829553]\n",
      "  [0.78054619]\n",
      "  [0.79397053]\n",
      "  [0.8084116 ]\n",
      "  [0.8239153 ]]]\n",
      "ejemplar: [0.73052239 0.74233001 0.75538367 0.76829553 0.78054619 0.79397053\n",
      " 0.8084116  0.8239153 ]\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.84098536]]\n",
      "Lr que voy a aplicar en el lote: 174 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.73052239 0.74233001 0.75538367 0.76829553 0.78054619 0.79397053\n",
      "  0.8084116  0.8239153 ]]\n",
      "verdaderas salidas: [0.95776831]\n",
      "PERDIDAAAA antes: 0.013638260774314404\n",
      "Predicción post entrenamiento : [[0.85316235]]\n",
      "PERDIDAAAA despues: 0.010942409746348858\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "0\n",
      "[[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "ejemplar: [0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      " 0.03448276 0.04223169]\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.54196185]]\n",
      "Lr que voy a aplicar en el lote: 1 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      "  0.03448276 0.04223169]]\n",
      "verdaderas salidas: [0.04610616]\n",
      "PERDIDAAAA antes: 0.2458728700876236\n",
      "Predicción post entrenamiento : [[0.5462747]]\n",
      "PERDIDAAAA despues: 0.2501685917377472\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "[[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.54196185]]]\n",
      "ejemplar: [0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      " 0.04223169 0.54196185]\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.5353646]]\n",
      "Lr que voy a aplicar en el lote: 2 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      "  0.04223169 0.54196185]]\n",
      "verdaderas salidas: [0.10422317]\n",
      "PERDIDAAAA antes: 0.18588297069072723\n",
      "Predicción post entrenamiento : [[0.53746474]]\n",
      "PERDIDAAAA despues: 0.18769825994968414\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "[[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.54196185]\n",
      "  [0.53536463]]]\n",
      "ejemplar: [0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      " 0.54196185 0.53536463]\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.54354393]]\n",
      "Lr que voy a aplicar en el lote: 3 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      "  0.54196185 0.53536463]]\n",
      "verdaderas salidas: [0.1542038]\n",
      "PERDIDAAAA antes: 0.15158574283123016\n",
      "Predicción post entrenamiento : [[0.54409903]]\n",
      "PERDIDAAAA despues: 0.15201829373836517\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "[[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.54196185]\n",
      "  [0.53536463]\n",
      "  [0.54354393]]]\n",
      "ejemplar: [0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.54196185\n",
      " 0.53536463 0.54354393]\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.5598193]]\n",
      "Lr que voy a aplicar en el lote: 4 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.54196185\n",
      "  0.53536463 0.54354393]]\n",
      "verdaderas salidas: [0.15575358]\n",
      "PERDIDAAAA antes: 0.16326908767223358\n",
      "Predicción post entrenamiento : [[0.559514]]\n",
      "PERDIDAAAA despues: 0.1630224585533142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "[[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.54196185]\n",
      "  [0.53536463]\n",
      "  [0.54354393]\n",
      "  [0.55981928]]]\n",
      "ejemplar: [0.05656722 0.02595893 0.03448276 0.04223169 0.54196185 0.53536463\n",
      " 0.54354393 0.55981928]\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.581836]]\n",
      "Lr que voy a aplicar en el lote: 5 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.05656722 0.02595893 0.03448276 0.04223169 0.54196185 0.53536463\n",
      "  0.54354393 0.55981928]]\n",
      "verdaderas salidas: [0.12553274]\n",
      "PERDIDAAAA antes: 0.20821264386177063\n",
      "Predicción post entrenamiento : [[0.5796655]]\n",
      "PERDIDAAAA despues: 0.20623654127120972\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "[[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.54196185]\n",
      "  [0.53536463]\n",
      "  [0.54354393]\n",
      "  [0.55981928]\n",
      "  [0.58183599]]]\n",
      "ejemplar: [0.02595893 0.03448276 0.04223169 0.54196185 0.53536463 0.54354393\n",
      " 0.55981928 0.58183599]\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.60716754]]\n",
      "Lr que voy a aplicar en el lote: 6 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.02595893 0.03448276 0.04223169 0.54196185 0.53536463 0.54354393\n",
      "  0.55981928 0.58183599]]\n",
      "verdaderas salidas: [0.14567997]\n",
      "PERDIDAAAA antes: 0.2129707932472229\n",
      "Predicción post entrenamiento : [[0.6033432]]\n",
      "PERDIDAAAA despues: 0.20945563912391663\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "[[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.54196185]\n",
      "  [0.53536463]\n",
      "  [0.54354393]\n",
      "  [0.55981928]\n",
      "  [0.58183599]\n",
      "  [0.60716754]]]\n",
      "ejemplar: [0.03448276 0.04223169 0.54196185 0.53536463 0.54354393 0.55981928\n",
      " 0.58183599 0.60716754]\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.647729]]\n",
      "Lr que voy a aplicar en el lote: 7 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.03448276 0.04223169 0.54196185 0.53536463 0.54354393 0.55981928\n",
      "  0.58183599 0.60716754]]\n",
      "verdaderas salidas: [0.14645486]\n",
      "PERDIDAAAA antes: 0.2512757182121277\n",
      "Predicción post entrenamiento : [[0.6411429]]\n",
      "PERDIDAAAA despues: 0.24471625685691833\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "[[[0.04223169]\n",
      "  [0.54196185]\n",
      "  [0.53536463]\n",
      "  [0.54354393]\n",
      "  [0.55981928]\n",
      "  [0.58183599]\n",
      "  [0.60716754]\n",
      "  [0.64772898]]]\n",
      "ejemplar: [0.04223169 0.54196185 0.53536463 0.54354393 0.55981928 0.58183599\n",
      " 0.60716754 0.64772898]\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.69796085]]\n",
      "Lr que voy a aplicar en el lote: 8 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.04223169 0.54196185 0.53536463 0.54354393 0.55981928 0.58183599\n",
      "  0.60716754 0.64772898]]\n",
      "verdaderas salidas: [0.19604804]\n",
      "PERDIDAAAA antes: 0.2519164979457855\n",
      "Predicción post entrenamiento : [[0.68938786]]\n",
      "PERDIDAAAA despues: 0.2433841973543167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "[[[0.54196185]\n",
      "  [0.53536463]\n",
      "  [0.54354393]\n",
      "  [0.55981928]\n",
      "  [0.58183599]\n",
      "  [0.60716754]\n",
      "  [0.64772898]\n",
      "  [0.69796085]]]\n",
      "ejemplar: [0.54196185 0.53536463 0.54354393 0.55981928 0.58183599 0.60716754\n",
      " 0.64772898 0.69796085]\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.75895864]]\n",
      "Lr que voy a aplicar en el lote: 9 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.54196185 0.53536463 0.54354393 0.55981928 0.58183599 0.60716754\n",
      "  0.64772898 0.69796085]]\n",
      "verdaderas salidas: [0.2305308]\n",
      "PERDIDAAAA antes: 0.27923598885536194\n",
      "Predicción post entrenamiento : [[0.7463281]]\n",
      "PERDIDAAAA despues: 0.2660468816757202\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "[[[0.53536463]\n",
      "  [0.54354393]\n",
      "  [0.55981928]\n",
      "  [0.58183599]\n",
      "  [0.60716754]\n",
      "  [0.64772898]\n",
      "  [0.69796085]\n",
      "  [0.75895864]]]\n",
      "ejemplar: [0.53536463 0.54354393 0.55981928 0.58183599 0.60716754 0.64772898\n",
      " 0.69796085 0.75895864]\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.7514559]]\n",
      "Lr que voy a aplicar en el lote: 10 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.53536463 0.54354393 0.55981928 0.58183599 0.60716754 0.64772898\n",
      "  0.69796085 0.75895864]]\n",
      "verdaderas salidas: [0.20844634]\n",
      "PERDIDAAAA antes: 0.2948594093322754\n",
      "Predicción post entrenamiento : [[0.7366961]]\n",
      "PERDIDAAAA despues: 0.2790478467941284\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "[[[0.54354393]\n",
      "  [0.55981928]\n",
      "  [0.58183599]\n",
      "  [0.60716754]\n",
      "  [0.64772898]\n",
      "  [0.69796085]\n",
      "  [0.75895864]\n",
      "  [0.7514559 ]]]\n",
      "ejemplar: [0.54354393 0.55981928 0.58183599 0.60716754 0.64772898 0.69796085\n",
      " 0.75895864 0.7514559 ]\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.74579746]]\n",
      "Lr que voy a aplicar en el lote: 11 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.54354393 0.55981928 0.58183599 0.60716754 0.64772898 0.69796085\n",
      "  0.75895864 0.7514559 ]]\n",
      "verdaderas salidas: [0.21193336]\n",
      "PERDIDAAAA antes: 0.28501084446907043\n",
      "Predicción post entrenamiento : [[0.7284618]]\n",
      "PERDIDAAAA despues: 0.2668016254901886\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "[[[0.55981928]\n",
      "  [0.58183599]\n",
      "  [0.60716754]\n",
      "  [0.64772898]\n",
      "  [0.69796085]\n",
      "  [0.75895864]\n",
      "  [0.7514559 ]\n",
      "  [0.74579746]]]\n",
      "ejemplar: [0.55981928 0.58183599 0.60716754 0.64772898 0.69796085 0.75895864\n",
      " 0.7514559  0.74579746]\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.7399687]]\n",
      "Lr que voy a aplicar en el lote: 12 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.55981928 0.58183599 0.60716754 0.64772898 0.69796085 0.75895864\n",
      "  0.7514559  0.74579746]]\n",
      "verdaderas salidas: [0.207284]\n",
      "PERDIDAAAA antes: 0.283752977848053\n",
      "Predicción post entrenamiento : [[0.72109646]]\n",
      "PERDIDAAAA despues: 0.2640032172203064\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "[[[0.58183599]\n",
      "  [0.60716754]\n",
      "  [0.64772898]\n",
      "  [0.69796085]\n",
      "  [0.75895864]\n",
      "  [0.7514559 ]\n",
      "  [0.74579746]\n",
      "  [0.73996872]]]\n",
      "ejemplar: [0.58183599 0.60716754 0.64772898 0.69796085 0.75895864 0.7514559\n",
      " 0.74579746 0.73996872]\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.7339813]]\n",
      "Lr que voy a aplicar en el lote: 13 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.58183599 0.60716754 0.64772898 0.69796085 0.75895864 0.7514559\n",
      "  0.74579746 0.73996872]]\n",
      "verdaderas salidas: [0.19294847]\n",
      "PERDIDAAAA antes: 0.29271653294563293\n",
      "Predicción post entrenamiento : [[0.71474326]]\n",
      "PERDIDAAAA despues: 0.2722698152065277\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "[[[0.60716754]\n",
      "  [0.64772898]\n",
      "  [0.69796085]\n",
      "  [0.75895864]\n",
      "  [0.7514559 ]\n",
      "  [0.74579746]\n",
      "  [0.73996872]\n",
      "  [0.73398131]]]\n",
      "ejemplar: [0.60716754 0.64772898 0.69796085 0.75895864 0.7514559  0.74579746\n",
      " 0.73996872 0.73398131]\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.7280221]]\n",
      "Lr que voy a aplicar en el lote: 14 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.60716754 0.64772898 0.69796085 0.75895864 0.7514559  0.74579746\n",
      "  0.73996872 0.73398131]]\n",
      "verdaderas salidas: [0.19682294]\n",
      "PERDIDAAAA antes: 0.2821725308895111\n",
      "Predicción post entrenamiento : [[0.70727456]]\n",
      "PERDIDAAAA despues: 0.2605608403682709\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "[[[0.64772898]\n",
      "  [0.69796085]\n",
      "  [0.75895864]\n",
      "  [0.7514559 ]\n",
      "  [0.74579746]\n",
      "  [0.73996872]\n",
      "  [0.73398131]\n",
      "  [0.7280221 ]]]\n",
      "ejemplar: [0.64772898 0.69796085 0.75895864 0.7514559  0.74579746 0.73996872\n",
      " 0.73398131 0.7280221 ]\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.7200388]]\n",
      "Lr que voy a aplicar en el lote: 15 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.64772898 0.69796085 0.75895864 0.7514559  0.74579746 0.73996872\n",
      "  0.73398131 0.7280221 ]]\n",
      "verdaderas salidas: [0.21425804]\n",
      "PERDIDAAAA antes: 0.2558141052722931\n",
      "Predicción post entrenamiento : [[0.69869757]]\n",
      "PERDIDAAAA despues: 0.2346816509962082\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "[[[0.69796085]\n",
      "  [0.75895864]\n",
      "  [0.7514559 ]\n",
      "  [0.74579746]\n",
      "  [0.73996872]\n",
      "  [0.73398131]\n",
      "  [0.7280221 ]\n",
      "  [0.72003877]]]\n",
      "ejemplar: [0.69796085 0.75895864 0.7514559  0.74579746 0.73996872 0.73398131\n",
      " 0.7280221  0.72003877]\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.7084]]\n",
      "Lr que voy a aplicar en el lote: 16 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.69796085 0.75895864 0.7514559  0.74579746 0.73996872 0.73398131\n",
      "  0.7280221  0.72003877]]\n",
      "verdaderas salidas: [0.18132507]\n",
      "PERDIDAAAA antes: 0.27780798077583313\n",
      "Predicción post entrenamiento : [[0.6856559]]\n",
      "PERDIDAAAA despues: 0.25434955954551697\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "[[[0.75895864]\n",
      "  [0.7514559 ]\n",
      "  [0.74579746]\n",
      "  [0.73996872]\n",
      "  [0.73398131]\n",
      "  [0.7280221 ]\n",
      "  [0.72003877]\n",
      "  [0.70840001]]]\n",
      "ejemplar: [0.75895864 0.7514559  0.74579746 0.73996872 0.73398131 0.7280221\n",
      " 0.72003877 0.70840001]\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.6903434]]\n",
      "Lr que voy a aplicar en el lote: 17 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.75895864 0.7514559  0.74579746 0.73996872 0.73398131 0.7280221\n",
      "  0.72003877 0.70840001]]\n",
      "verdaderas salidas: [0.17512592]\n",
      "PERDIDAAAA antes: 0.26544898748397827\n",
      "Predicción post entrenamiento : [[0.66735345]]\n",
      "PERDIDAAAA despues: 0.24228793382644653\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "[[[0.7514559 ]\n",
      "  [0.74579746]\n",
      "  [0.73996872]\n",
      "  [0.73398131]\n",
      "  [0.7280221 ]\n",
      "  [0.72003877]\n",
      "  [0.70840001]\n",
      "  [0.69034338]]]\n",
      "ejemplar: [0.7514559  0.74579746 0.73996872 0.73398131 0.7280221  0.72003877\n",
      " 0.70840001 0.69034338]\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.66503525]]\n",
      "Lr que voy a aplicar en el lote: 18 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.7514559  0.74579746 0.73996872 0.73398131 0.7280221  0.72003877\n",
      "  0.70840001 0.69034338]]\n",
      "verdaderas salidas: [0.14800465]\n",
      "PERDIDAAAA antes: 0.2673206329345703\n",
      "Predicción post entrenamiento : [[0.64175975]]\n",
      "PERDIDAAAA despues: 0.24379409849643707\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "[[[0.74579746]\n",
      "  [0.73996872]\n",
      "  [0.73398131]\n",
      "  [0.7280221 ]\n",
      "  [0.72003877]\n",
      "  [0.70840001]\n",
      "  [0.69034338]\n",
      "  [0.66503525]]]\n",
      "ejemplar: [0.74579746 0.73996872 0.73398131 0.7280221  0.72003877 0.70840001\n",
      " 0.69034338 0.66503525]\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.63949805]]\n",
      "Lr que voy a aplicar en el lote: 19 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.74579746 0.73996872 0.73398131 0.7280221  0.72003877 0.70840001\n",
      "  0.69034338 0.66503525]]\n",
      "verdaderas salidas: [0.15885316]\n",
      "PERDIDAAAA antes: 0.2310194969177246\n",
      "Predicción post entrenamiento : [[0.61748946]]\n",
      "PERDIDAAAA despues: 0.2103472352027893\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "[[[0.73996872]\n",
      "  [0.73398131]\n",
      "  [0.7280221 ]\n",
      "  [0.72003877]\n",
      "  [0.70840001]\n",
      "  [0.69034338]\n",
      "  [0.66503525]\n",
      "  [0.63949805]]]\n",
      "ejemplar: [0.73996872 0.73398131 0.7280221  0.72003877 0.70840001 0.69034338\n",
      " 0.66503525 0.63949805]\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.6149359]]\n",
      "Lr que voy a aplicar en el lote: 20 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.73996872 0.73398131 0.7280221  0.72003877 0.70840001 0.69034338\n",
      "  0.66503525 0.63949805]]\n",
      "verdaderas salidas: [0.19217358]\n",
      "PERDIDAAAA antes: 0.17872796952724457\n",
      "Predicción post entrenamiento : [[0.5939064]]\n",
      "PERDIDAAAA despues: 0.16138926148414612\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "[[[0.73398131]\n",
      "  [0.7280221 ]\n",
      "  [0.72003877]\n",
      "  [0.70840001]\n",
      "  [0.69034338]\n",
      "  [0.66503525]\n",
      "  [0.63949805]\n",
      "  [0.61493587]]]\n",
      "ejemplar: [0.73398131 0.7280221  0.72003877 0.70840001 0.69034338 0.66503525\n",
      " 0.63949805 0.61493587]\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.5908814]]\n",
      "Lr que voy a aplicar en el lote: 21 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.73398131 0.7280221  0.72003877 0.70840001 0.69034338 0.66503525\n",
      "  0.63949805 0.61493587]]\n",
      "verdaderas salidas: [0.18597443]\n",
      "PERDIDAAAA antes: 0.16394966840744019\n",
      "Predicción post entrenamiento : [[0.5707947]]\n",
      "PERDIDAAAA despues: 0.14808665215969086\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "[[[0.7280221 ]\n",
      "  [0.72003877]\n",
      "  [0.70840001]\n",
      "  [0.69034338]\n",
      "  [0.66503525]\n",
      "  [0.63949805]\n",
      "  [0.61493587]\n",
      "  [0.59088141]]]\n",
      "ejemplar: [0.7280221  0.72003877 0.70840001 0.69034338 0.66503525 0.63949805\n",
      " 0.61493587 0.59088141]\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.5671038]]\n",
      "Lr que voy a aplicar en el lote: 22 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.7280221  0.72003877 0.70840001 0.69034338 0.66503525 0.63949805\n",
      "  0.61493587 0.59088141]]\n",
      "verdaderas salidas: [0.26695079]\n",
      "PERDIDAAAA antes: 0.09009183198213577\n",
      "Predicción post entrenamiento : [[0.5483554]]\n",
      "PERDIDAAAA despues: 0.07918855547904968\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "[[[0.72003877]\n",
      "  [0.70840001]\n",
      "  [0.69034338]\n",
      "  [0.66503525]\n",
      "  [0.63949805]\n",
      "  [0.61493587]\n",
      "  [0.59088141]\n",
      "  [0.5671038 ]]]\n",
      "ejemplar: [0.72003877 0.70840001 0.69034338 0.66503525 0.63949805 0.61493587\n",
      " 0.59088141 0.5671038 ]\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.5437911]]\n",
      "Lr que voy a aplicar en el lote: 23 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.72003877 0.70840001 0.69034338 0.66503525 0.63949805 0.61493587\n",
      "  0.59088141 0.5671038 ]]\n",
      "verdaderas salidas: [0.29252228]\n",
      "PERDIDAAAA antes: 0.063136026263237\n",
      "Predicción post entrenamiento : [[0.5265425]]\n",
      "PERDIDAAAA despues: 0.054765455424785614\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "[[[0.70840001]\n",
      "  [0.69034338]\n",
      "  [0.66503525]\n",
      "  [0.63949805]\n",
      "  [0.61493587]\n",
      "  [0.59088141]\n",
      "  [0.5671038 ]\n",
      "  [0.54379112]]]\n",
      "ejemplar: [0.70840001 0.69034338 0.66503525 0.63949805 0.61493587 0.59088141\n",
      " 0.5671038  0.54379112]\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.52110344]]\n",
      "Lr que voy a aplicar en el lote: 24 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.70840001 0.69034338 0.66503525 0.63949805 0.61493587 0.59088141\n",
      "  0.5671038  0.54379112]]\n",
      "verdaderas salidas: [0.31770632]\n",
      "PERDIDAAAA antes: 0.041370391845703125\n",
      "Predicción post entrenamiento : [[0.5056423]]\n",
      "PERDIDAAAA despues: 0.03531993180513382\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "[[[0.69034338]\n",
      "  [0.66503525]\n",
      "  [0.63949805]\n",
      "  [0.61493587]\n",
      "  [0.59088141]\n",
      "  [0.5671038 ]\n",
      "  [0.54379112]\n",
      "  [0.52110344]]]\n",
      "ejemplar: [0.69034338 0.66503525 0.63949805 0.61493587 0.59088141 0.5671038\n",
      " 0.54379112 0.52110344]\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.49949947]]\n",
      "Lr que voy a aplicar en el lote: 25 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.69034338 0.66503525 0.63949805 0.61493587 0.59088141 0.5671038\n",
      "  0.54379112 0.52110344]]\n",
      "verdaderas salidas: [0.31266951]\n",
      "PERDIDAAAA antes: 0.034905433654785156\n",
      "Predicción post entrenamiento : [[0.48573664]]\n",
      "PERDIDAAAA despues: 0.02995222806930542\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "[[[0.66503525]\n",
      "  [0.63949805]\n",
      "  [0.61493587]\n",
      "  [0.59088141]\n",
      "  [0.5671038 ]\n",
      "  [0.54379112]\n",
      "  [0.52110344]\n",
      "  [0.49949947]]]\n",
      "ejemplar: [0.66503525 0.63949805 0.61493587 0.59088141 0.5671038  0.54379112\n",
      " 0.52110344 0.49949947]\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.47933084]]\n",
      "Lr que voy a aplicar en el lote: 26 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.66503525 0.63949805 0.61493587 0.59088141 0.5671038  0.54379112\n",
      "  0.52110344 0.49949947]]\n",
      "verdaderas salidas: [0.28903526]\n",
      "PERDIDAAAA antes: 0.03621240705251694\n",
      "Predicción post entrenamiento : [[0.46647415]]\n",
      "PERDIDAAAA despues: 0.031484559178352356\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "[[[0.63949805]\n",
      "  [0.61493587]\n",
      "  [0.59088141]\n",
      "  [0.5671038 ]\n",
      "  [0.54379112]\n",
      "  [0.52110344]\n",
      "  [0.49949947]\n",
      "  [0.47933084]]]\n",
      "ejemplar: [0.63949805 0.61493587 0.59088141 0.5671038  0.54379112 0.52110344\n",
      " 0.49949947 0.47933084]\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.4603658]]\n",
      "Lr que voy a aplicar en el lote: 27 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.63949805 0.61493587 0.59088141 0.5671038  0.54379112 0.52110344\n",
      "  0.49949947 0.47933084]]\n",
      "verdaderas salidas: [0.28283611]\n",
      "PERDIDAAAA antes: 0.03151679039001465\n",
      "Predicción post entrenamiento : [[0.4488309]]\n",
      "PERDIDAAAA despues: 0.02755427174270153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "[[[0.61493587]\n",
      "  [0.59088141]\n",
      "  [0.5671038 ]\n",
      "  [0.54379112]\n",
      "  [0.52110344]\n",
      "  [0.49949947]\n",
      "  [0.47933084]\n",
      "  [0.4603658 ]]]\n",
      "ejemplar: [0.61493587 0.59088141 0.5671038  0.54379112 0.52110344 0.49949947\n",
      " 0.47933084 0.4603658 ]\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.44305927]]\n",
      "Lr que voy a aplicar en el lote: 28 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.61493587 0.59088141 0.5671038  0.54379112 0.52110344 0.49949947\n",
      "  0.47933084 0.4603658 ]]\n",
      "verdaderas salidas: [0.29949632]\n",
      "PERDIDAAAA antes: 0.020610319450497627\n",
      "Predicción post entrenamiento : [[0.43258336]]\n",
      "PERDIDAAAA despues: 0.01771215908229351\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "[[[0.59088141]\n",
      "  [0.5671038 ]\n",
      "  [0.54379112]\n",
      "  [0.52110344]\n",
      "  [0.49949947]\n",
      "  [0.47933084]\n",
      "  [0.4603658 ]\n",
      "  [0.44305927]]]\n",
      "ejemplar: [0.59088141 0.5671038  0.54379112 0.52110344 0.49949947 0.47933084\n",
      " 0.4603658  0.44305927]\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.42710972]]\n",
      "Lr que voy a aplicar en el lote: 29 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.59088141 0.5671038  0.54379112 0.52110344 0.49949947 0.47933084\n",
      "  0.4603658  0.44305927]]\n",
      "verdaderas salidas: [0.27586207]\n",
      "PERDIDAAAA antes: 0.022875851020216942\n",
      "Predicción post entrenamiento : [[0.41765392]]\n",
      "PERDIDAAAA despues: 0.02010492794215679\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "[[[0.5671038 ]\n",
      "  [0.54379112]\n",
      "  [0.52110344]\n",
      "  [0.49949947]\n",
      "  [0.47933084]\n",
      "  [0.4603658 ]\n",
      "  [0.44305927]\n",
      "  [0.42710972]]]\n",
      "ejemplar: [0.5671038  0.54379112 0.52110344 0.49949947 0.47933084 0.4603658\n",
      " 0.44305927 0.42710972]\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.41248065]]\n",
      "Lr que voy a aplicar en el lote: 30 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.5671038  0.54379112 0.52110344 0.49949947 0.47933084 0.4603658\n",
      "  0.44305927 0.42710972]]\n",
      "verdaderas salidas: [0.27469973]\n",
      "PERDIDAAAA antes: 0.018983585759997368\n",
      "Predicción post entrenamiento : [[0.40389588]]\n",
      "PERDIDAAAA despues: 0.016691649332642555\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "[[[0.54379112]\n",
      "  [0.52110344]\n",
      "  [0.49949947]\n",
      "  [0.47933084]\n",
      "  [0.4603658 ]\n",
      "  [0.44305927]\n",
      "  [0.42710972]\n",
      "  [0.41248065]]]\n",
      "ejemplar: [0.54379112 0.52110344 0.49949947 0.47933084 0.4603658  0.44305927\n",
      " 0.42710972 0.41248065]\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.39905283]]\n",
      "Lr que voy a aplicar en el lote: 31 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.54379112 0.52110344 0.49949947 0.47933084 0.4603658  0.44305927\n",
      "  0.42710972 0.41248065]]\n",
      "verdaderas salidas: [0.27547462]\n",
      "PERDIDAAAA antes: 0.015271577052772045\n",
      "Predicción post entrenamiento : [[0.3913356]]\n",
      "PERDIDAAAA despues: 0.013423770666122437\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "[[[0.52110344]\n",
      "  [0.49949947]\n",
      "  [0.47933084]\n",
      "  [0.4603658 ]\n",
      "  [0.44305927]\n",
      "  [0.42710972]\n",
      "  [0.41248065]\n",
      "  [0.39905283]]]\n",
      "ejemplar: [0.52110344 0.49949947 0.47933084 0.4603658  0.44305927 0.42710972\n",
      " 0.41248065 0.39905283]\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.38684773]]\n",
      "Lr que voy a aplicar en el lote: 32 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.52110344 0.49949947 0.47933084 0.4603658  0.44305927 0.42710972\n",
      "  0.41248065 0.39905283]]\n",
      "verdaderas salidas: [0.33475397]\n",
      "PERDIDAAAA antes: 0.002713761292397976\n",
      "Predicción post entrenamiento : [[0.37974566]]\n",
      "PERDIDAAAA despues: 0.0020242531318217516\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "[[[0.49949947]\n",
      "  [0.47933084]\n",
      "  [0.4603658 ]\n",
      "  [0.44305927]\n",
      "  [0.42710972]\n",
      "  [0.41248065]\n",
      "  [0.39905283]\n",
      "  [0.38684773]]]\n",
      "ejemplar: [0.49949947 0.47933084 0.4603658  0.44305927 0.42710972 0.41248065\n",
      " 0.39905283 0.38684773]\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.37563676]]\n",
      "Lr que voy a aplicar en el lote: 33 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.49949947 0.47933084 0.4603658  0.44305927 0.42710972 0.41248065\n",
      "  0.39905283 0.38684773]]\n",
      "verdaderas salidas: [0.35567609]\n",
      "PERDIDAAAA antes: 0.0003984284121543169\n",
      "Predicción post entrenamiento : [[0.36939958]]\n",
      "PERDIDAAAA despues: 0.00018833424837794155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "[[[0.47933084]\n",
      "  [0.4603658 ]\n",
      "  [0.44305927]\n",
      "  [0.42710972]\n",
      "  [0.41248065]\n",
      "  [0.39905283]\n",
      "  [0.38684773]\n",
      "  [0.37563676]]]\n",
      "ejemplar: [0.47933084 0.4603658  0.44305927 0.42710972 0.41248065 0.39905283\n",
      " 0.38684773 0.37563676]\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.3656636]]\n",
      "Lr que voy a aplicar en el lote: 34 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.47933084 0.4603658  0.44305927 0.42710972 0.41248065 0.39905283\n",
      "  0.38684773 0.37563676]]\n",
      "verdaderas salidas: [0.3366912]\n",
      "PERDIDAAAA antes: 0.0008393992320634425\n",
      "Predicción post entrenamiento : [[0.36021635]]\n",
      "PERDIDAAAA despues: 0.0005534326191991568\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "[[[0.4603658 ]\n",
      "  [0.44305927]\n",
      "  [0.42710972]\n",
      "  [0.41248065]\n",
      "  [0.39905283]\n",
      "  [0.38684773]\n",
      "  [0.37563676]\n",
      "  [0.36566359]]]\n",
      "ejemplar: [0.4603658  0.44305927 0.42710972 0.41248065 0.39905283 0.38684773\n",
      " 0.37563676 0.36566359]\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.3568268]]\n",
      "Lr que voy a aplicar en el lote: 35 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.4603658  0.44305927 0.42710972 0.41248065 0.39905283 0.38684773\n",
      "  0.37563676 0.36566359]]\n",
      "verdaderas salidas: [0.33359163]\n",
      "PERDIDAAAA antes: 0.0005398732027970254\n",
      "Predicción post entrenamiento : [[0.35199487]]\n",
      "PERDIDAAAA despues: 0.00033867894671857357\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "[[[0.44305927]\n",
      "  [0.42710972]\n",
      "  [0.41248065]\n",
      "  [0.39905283]\n",
      "  [0.38684773]\n",
      "  [0.37563676]\n",
      "  [0.36566359]\n",
      "  [0.35682681]]]\n",
      "ejemplar: [0.44305927 0.42710972 0.41248065 0.39905283 0.38684773 0.37563676\n",
      " 0.36566359 0.35682681]\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.34894153]]\n",
      "Lr que voy a aplicar en el lote: 36 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.44305927 0.42710972 0.41248065 0.39905283 0.38684773 0.37563676\n",
      "  0.36566359 0.35682681]]\n",
      "verdaderas salidas: [0.3847346]\n",
      "PERDIDAAAA antes: 0.001281143631786108\n",
      "Predicción post entrenamiento : [[0.34477615]]\n",
      "PERDIDAAAA despues: 0.0015966774662956595\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "[[[0.42710972]\n",
      "  [0.41248065]\n",
      "  [0.39905283]\n",
      "  [0.38684773]\n",
      "  [0.37563676]\n",
      "  [0.36566359]\n",
      "  [0.35682681]\n",
      "  [0.34894153]]]\n",
      "ejemplar: [0.42710972 0.41248065 0.39905283 0.38684773 0.37563676 0.36566359\n",
      " 0.35682681 0.34894153]\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.34201968]]\n",
      "Lr que voy a aplicar en el lote: 37 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.42710972 0.41248065 0.39905283 0.38684773 0.37563676 0.36566359\n",
      "  0.35682681 0.34894153]]\n",
      "verdaderas salidas: [0.57109647]\n",
      "PERDIDAAAA antes: 0.0524761825799942\n",
      "Predicción post entrenamiento : [[0.3387003]]\n",
      "PERDIDAAAA despues: 0.054007988423109055\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "[[[0.41248065]\n",
      "  [0.39905283]\n",
      "  [0.38684773]\n",
      "  [0.37563676]\n",
      "  [0.36566359]\n",
      "  [0.35682681]\n",
      "  [0.34894153]\n",
      "  [0.34201968]]]\n",
      "ejemplar: [0.41248065 0.39905283 0.38684773 0.37563676 0.36566359 0.35682681\n",
      " 0.34894153 0.34201968]\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.33621633]]\n",
      "Lr que voy a aplicar en el lote: 38 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.41248065 0.39905283 0.38684773 0.37563676 0.36566359 0.35682681\n",
      "  0.34894153 0.34201968]]\n",
      "verdaderas salidas: [0.59628051]\n",
      "PERDIDAAAA antes: 0.06763338297605515\n",
      "Predicción post entrenamiento : [[0.33369204]]\n",
      "PERDIDAAAA despues: 0.06895270198583603\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "[[[0.39905283]\n",
      "  [0.38684773]\n",
      "  [0.37563676]\n",
      "  [0.36566359]\n",
      "  [0.35682681]\n",
      "  [0.34894153]\n",
      "  [0.34201968]\n",
      "  [0.33621633]]]\n",
      "ejemplar: [0.39905283 0.38684773 0.37563676 0.36566359 0.35682681 0.34894153\n",
      " 0.34201968 0.33621633]\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.33145878]]\n",
      "Lr que voy a aplicar en el lote: 39 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.39905283 0.38684773 0.37563676 0.36566359 0.35682681 0.34894153\n",
      "  0.34201968 0.33621633]]\n",
      "verdaderas salidas: [0.57458349]\n",
      "PERDIDAAAA antes: 0.05910961702466011\n",
      "Predicción post entrenamiento : [[0.32961127]]\n",
      "PERDIDAAAA despues: 0.060011379420757294\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "[[[0.38684773]\n",
      "  [0.37563676]\n",
      "  [0.36566359]\n",
      "  [0.35682681]\n",
      "  [0.34894153]\n",
      "  [0.34201968]\n",
      "  [0.33621633]\n",
      "  [0.33145878]]]\n",
      "ejemplar: [0.38684773 0.37563676 0.36566359 0.35682681 0.34894153 0.34201968\n",
      " 0.33621633 0.33145878]\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.32761458]]\n",
      "Lr que voy a aplicar en el lote: 40 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.38684773 0.37563676 0.36566359 0.35682681 0.34894153 0.34201968\n",
      "  0.33621633 0.33145878]]\n",
      "verdaderas salidas: [0.60635413]\n",
      "PERDIDAAAA antes: 0.07769573479890823\n",
      "Predicción post entrenamiento : [[0.3263938]]\n",
      "PERDIDAAAA despues: 0.07837776839733124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "[[[0.37563676]\n",
      "  [0.36566359]\n",
      "  [0.35682681]\n",
      "  [0.34894153]\n",
      "  [0.34201968]\n",
      "  [0.33621633]\n",
      "  [0.33145878]\n",
      "  [0.32761458]]]\n",
      "ejemplar: [0.37563676 0.36566359 0.35682681 0.34894153 0.34201968 0.33621633\n",
      " 0.33145878 0.32761458]\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.32461825]]\n",
      "Lr que voy a aplicar en el lote: 41 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.37563676 0.36566359 0.35682681 0.34894153 0.34201968 0.33621633\n",
      "  0.33145878 0.32761458]]\n",
      "verdaderas salidas: [0.58465711]\n",
      "PERDIDAAAA antes: 0.06762021780014038\n",
      "Predicción post entrenamiento : [[0.32391638]]\n",
      "PERDIDAAAA despues: 0.06798574328422546\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "[[[0.36566359]\n",
      "  [0.35682681]\n",
      "  [0.34894153]\n",
      "  [0.34201968]\n",
      "  [0.33621633]\n",
      "  [0.33145878]\n",
      "  [0.32761458]\n",
      "  [0.32461825]]]\n",
      "ejemplar: [0.36566359 0.35682681 0.34894153 0.34201968 0.33621633 0.33145878\n",
      " 0.32761458 0.32461825]\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.32236007]]\n",
      "Lr que voy a aplicar en el lote: 42 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.36566359 0.35682681 0.34894153 0.34201968 0.33621633 0.33145878\n",
      "  0.32761458 0.32461825]]\n",
      "verdaderas salidas: [0.56877179]\n",
      "PERDIDAAAA antes: 0.060718730092048645\n",
      "Predicción post entrenamiento : [[0.32206395]]\n",
      "PERDIDAAAA despues: 0.06086475029587746\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "[[[0.35682681]\n",
      "  [0.34894153]\n",
      "  [0.34201968]\n",
      "  [0.33621633]\n",
      "  [0.33145878]\n",
      "  [0.32761458]\n",
      "  [0.32461825]\n",
      "  [0.32236007]]]\n",
      "ejemplar: [0.35682681 0.34894153 0.34201968 0.33621633 0.33145878 0.32761458\n",
      " 0.32461825 0.32236007]\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.3207111]]\n",
      "Lr que voy a aplicar en el lote: 43 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.35682681 0.34894153 0.34201968 0.33621633 0.33145878 0.32761458\n",
      "  0.32461825 0.32236007]]\n",
      "verdaderas salidas: [0.64277412]\n",
      "PERDIDAAAA antes: 0.10372457653284073\n",
      "Predicción post entrenamiento : [[0.3209133]]\n",
      "PERDIDAAAA despues: 0.10359437018632889\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "[[[0.34894153]\n",
      "  [0.34201968]\n",
      "  [0.33621633]\n",
      "  [0.33145878]\n",
      "  [0.32761458]\n",
      "  [0.32461825]\n",
      "  [0.32236007]\n",
      "  [0.32071111]]]\n",
      "ejemplar: [0.34894153 0.34201968 0.33621633 0.33145878 0.32761458 0.32461825\n",
      " 0.32236007 0.32071111]\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.3197514]]\n",
      "Lr que voy a aplicar en el lote: 44 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.34894153 0.34201968 0.33621633 0.33145878 0.32761458 0.32461825\n",
      "  0.32236007 0.32071111]]\n",
      "verdaderas salidas: [0.66175901]\n",
      "PERDIDAAAA antes: 0.11696920543909073\n",
      "Predicción post entrenamiento : [[0.32043356]]\n",
      "PERDIDAAAA despues: 0.11650306731462479\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "[[[0.34201968]\n",
      "  [0.33621633]\n",
      "  [0.33145878]\n",
      "  [0.32761458]\n",
      "  [0.32461825]\n",
      "  [0.32236007]\n",
      "  [0.32071111]\n",
      "  [0.31975141]]]\n",
      "ejemplar: [0.34201968 0.33621633 0.33145878 0.32761458 0.32461825 0.32236007\n",
      " 0.32071111 0.31975141]\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.31945935]]\n",
      "Lr que voy a aplicar en el lote: 45 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.34201968 0.33621633 0.33145878 0.32761458 0.32461825 0.32236007\n",
      "  0.32071111 0.31975141]]\n",
      "verdaderas salidas: [0.67299496]\n",
      "PERDIDAAAA antes: 0.12498743832111359\n",
      "Predicción post entrenamiento : [[0.3205893]]\n",
      "PERDIDAAAA despues: 0.12418975681066513\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "[[[0.33621633]\n",
      "  [0.33145878]\n",
      "  [0.32761458]\n",
      "  [0.32461825]\n",
      "  [0.32236007]\n",
      "  [0.32071111]\n",
      "  [0.31975141]\n",
      "  [0.31945935]]]\n",
      "ejemplar: [0.33621633 0.33145878 0.32761458 0.32461825 0.32236007 0.32071111\n",
      " 0.31975141 0.31945935]\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.31979728]]\n",
      "Lr que voy a aplicar en el lote: 46 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.33621633 0.33145878 0.32761458 0.32461825 0.32236007 0.32071111\n",
      "  0.31975141 0.31945935]]\n",
      "verdaderas salidas: [0.7105773]\n",
      "PERDIDAAAA antes: 0.15270903706550598\n",
      "Predicción post entrenamiento : [[0.32135436]]\n",
      "PERDIDAAAA despues: 0.15149450302124023\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "[[[0.33145878]\n",
      "  [0.32761458]\n",
      "  [0.32461825]\n",
      "  [0.32236007]\n",
      "  [0.32071111]\n",
      "  [0.31975141]\n",
      "  [0.31945935]\n",
      "  [0.31979728]]]\n",
      "ejemplar: [0.33145878 0.32761458 0.32461825 0.32236007 0.32071111 0.31975141\n",
      " 0.31945935 0.31979728]\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.32072774]]\n",
      "Lr que voy a aplicar en el lote: 47 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.33145878 0.32761458 0.32461825 0.32236007 0.32071111 0.31975141\n",
      "  0.31945935 0.31979728]]\n",
      "verdaderas salidas: [0.7039907]\n",
      "PERDIDAAAA antes: 0.14689049124717712\n",
      "Predicción post entrenamiento : [[0.32267806]]\n",
      "PERDIDAAAA despues: 0.1453993320465088\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "[[[0.32761458]\n",
      "  [0.32461825]\n",
      "  [0.32236007]\n",
      "  [0.32071111]\n",
      "  [0.31975141]\n",
      "  [0.31945935]\n",
      "  [0.31979728]\n",
      "  [0.32072774]]]\n",
      "ejemplar: [0.32761458 0.32461825 0.32236007 0.32071111 0.31975141 0.31945935\n",
      " 0.31979728 0.32072774]\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.32220083]]\n",
      "Lr que voy a aplicar en el lote: 48 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.32761458 0.32461825 0.32236007 0.32071111 0.31975141 0.31945935\n",
      "  0.31979728 0.32072774]]\n",
      "verdaderas salidas: [0.7272375]\n",
      "PERDIDAAAA antes: 0.1640547215938568\n",
      "Predicción post entrenamiento : [[0.32455954]]\n",
      "PERDIDAAAA despues: 0.1621495634317398\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "[[[0.32461825]\n",
      "  [0.32236007]\n",
      "  [0.32071111]\n",
      "  [0.31975141]\n",
      "  [0.31945935]\n",
      "  [0.31979728]\n",
      "  [0.32072774]\n",
      "  [0.32220083]]]\n",
      "ejemplar: [0.32461825 0.32236007 0.32071111 0.31975141 0.31945935 0.31979728\n",
      " 0.32072774 0.32220083]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.32422057]]\n",
      "Lr que voy a aplicar en el lote: 49 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.32461825 0.32236007 0.32071111 0.31975141 0.31945935 0.31979728\n",
      "  0.32072774 0.32220083]]\n",
      "verdaderas salidas: [0.72258814]\n",
      "PERDIDAAAA antes: 0.158696711063385\n",
      "Predicción post entrenamiento : [[0.32691953]]\n",
      "PERDIDAAAA despues: 0.15655364096164703\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "[[[0.32236007]\n",
      "  [0.32071111]\n",
      "  [0.31975141]\n",
      "  [0.31945935]\n",
      "  [0.31979728]\n",
      "  [0.32072774]\n",
      "  [0.32220083]\n",
      "  [0.32422057]]]\n",
      "ejemplar: [0.32236007 0.32071111 0.31975141 0.31945935 0.31979728 0.32072774\n",
      " 0.32220083 0.32422057]\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.32670927]]\n",
      "Lr que voy a aplicar en el lote: 50 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.32236007 0.32071111 0.31975141 0.31945935 0.31979728 0.32072774\n",
      "  0.32220083 0.32422057]]\n",
      "verdaderas salidas: [0.77179388]\n",
      "PERDIDAAAA antes: 0.19810032844543457\n",
      "Predicción post entrenamiento : [[0.32981214]]\n",
      "PERDIDAAAA despues: 0.1953478753566742\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "[[[0.32071111]\n",
      "  [0.31975141]\n",
      "  [0.31945935]\n",
      "  [0.31979728]\n",
      "  [0.32072774]\n",
      "  [0.32220083]\n",
      "  [0.32422057]\n",
      "  [0.32670927]]]\n",
      "ejemplar: [0.32071111 0.31975141 0.31945935 0.31979728 0.32072774 0.32220083\n",
      " 0.32422057 0.32670927]\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.32972553]]\n",
      "Lr que voy a aplicar en el lote: 51 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.32071111 0.31975141 0.31945935 0.31979728 0.32072774 0.32220083\n",
      "  0.32422057 0.32670927]]\n",
      "verdaderas salidas: [0.72452538]\n",
      "PERDIDAAAA antes: 0.15586692094802856\n",
      "Predicción post entrenamiento : [[0.33313584]]\n",
      "PERDIDAAAA despues: 0.15318578481674194\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "[[[0.31975141]\n",
      "  [0.31945935]\n",
      "  [0.31979728]\n",
      "  [0.32072774]\n",
      "  [0.32220083]\n",
      "  [0.32422057]\n",
      "  [0.32670927]\n",
      "  [0.32972553]]]\n",
      "ejemplar: [0.31975141 0.31945935 0.31979728 0.32072774 0.32220083 0.32422057\n",
      " 0.32670927 0.32972553]\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.3331745]]\n",
      "Lr que voy a aplicar en el lote: 52 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.31975141 0.31945935 0.31979728 0.32072774 0.32220083 0.32422057\n",
      "  0.32670927 0.32972553]]\n",
      "verdaderas salidas: [0.67105773]\n",
      "PERDIDAAAA antes: 0.1141650602221489\n",
      "Predicción post entrenamiento : [[0.33677673]]\n",
      "PERDIDAAAA despues: 0.11174376308917999\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "[[[0.31945935]\n",
      "  [0.31979728]\n",
      "  [0.32072774]\n",
      "  [0.32220083]\n",
      "  [0.32422057]\n",
      "  [0.32670927]\n",
      "  [0.32972553]\n",
      "  [0.3331745 ]]]\n",
      "ejemplar: [0.31945935 0.31979728 0.32072774 0.32220083 0.32422057 0.32670927\n",
      " 0.32972553 0.3331745 ]\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.3369366]]\n",
      "Lr que voy a aplicar en el lote: 53 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.31945935 0.31979728 0.32072774 0.32220083 0.32422057 0.32670927\n",
      "  0.32972553 0.3331745 ]]\n",
      "verdaderas salidas: [0.67376986]\n",
      "PERDIDAAAA antes: 0.11345662921667099\n",
      "Predicción post entrenamiento : [[0.34072018]]\n",
      "PERDIDAAAA despues: 0.11092207580804825\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "[[[0.31979728]\n",
      "  [0.32072774]\n",
      "  [0.32220083]\n",
      "  [0.32422057]\n",
      "  [0.32670927]\n",
      "  [0.32972553]\n",
      "  [0.3331745 ]\n",
      "  [0.33693659]]]\n",
      "ejemplar: [0.31979728 0.32072774 0.32220083 0.32422057 0.32670927 0.32972553\n",
      " 0.3331745  0.33693659]\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.34099615]]\n",
      "Lr que voy a aplicar en el lote: 54 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.31979728 0.32072774 0.32220083 0.32422057 0.32670927 0.32972553\n",
      "  0.3331745  0.33693659]]\n",
      "verdaderas salidas: [0.71445176]\n",
      "PERDIDAAAA antes: 0.13946911692619324\n",
      "Predicción post entrenamiento : [[0.3450249]]\n",
      "PERDIDAAAA despues: 0.13647621870040894\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "[[[0.32072774]\n",
      "  [0.32220083]\n",
      "  [0.32422057]\n",
      "  [0.32670927]\n",
      "  [0.32972553]\n",
      "  [0.3331745 ]\n",
      "  [0.33693659]\n",
      "  [0.34099615]]]\n",
      "ejemplar: [0.32072774 0.32220083 0.32422057 0.32670927 0.32972553 0.3331745\n",
      " 0.33693659 0.34099615]\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.34541234]]\n",
      "Lr que voy a aplicar en el lote: 55 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.32072774 0.32220083 0.32422057 0.32670927 0.32972553 0.3331745\n",
      "  0.33693659 0.34099615]]\n",
      "verdaderas salidas: [0.74389771]\n",
      "PERDIDAAAA antes: 0.15879060328006744\n",
      "Predicción post entrenamiento : [[0.34971377]]\n",
      "PERDIDAAAA despues: 0.1553809940814972\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "[[[0.32220083]\n",
      "  [0.32422057]\n",
      "  [0.32670927]\n",
      "  [0.32972553]\n",
      "  [0.3331745 ]\n",
      "  [0.33693659]\n",
      "  [0.34099615]\n",
      "  [0.34541234]]]\n",
      "ejemplar: [0.32220083 0.32422057 0.32670927 0.32972553 0.3331745  0.33693659\n",
      " 0.34099615 0.34541234]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.35020813]]\n",
      "Lr que voy a aplicar en el lote: 56 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.32220083 0.32422057 0.32670927 0.32972553 0.3331745  0.33693659\n",
      "  0.34099615 0.34541234]]\n",
      "verdaderas salidas: [0.72258814]\n",
      "PERDIDAAAA antes: 0.13866685330867767\n",
      "Predicción post entrenamiento : [[0.35471535]]\n",
      "PERDIDAAAA despues: 0.13533037900924683\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "[[[0.32422057]\n",
      "  [0.32670927]\n",
      "  [0.32972553]\n",
      "  [0.3331745 ]\n",
      "  [0.33693659]\n",
      "  [0.34099615]\n",
      "  [0.34541234]\n",
      "  [0.35020813]]]\n",
      "ejemplar: [0.32422057 0.32670927 0.32972553 0.3331745  0.33693659 0.34099615\n",
      " 0.34541234 0.35020813]\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.3553128]]\n",
      "Lr que voy a aplicar en el lote: 57 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.32422057 0.32670927 0.32972553 0.3331745  0.33693659 0.34099615\n",
      "  0.34541234 0.35020813]]\n",
      "verdaderas salidas: [0.69934134]\n",
      "PERDIDAAAA antes: 0.1183556541800499\n",
      "Predicción post entrenamiento : [[0.3599833]]\n",
      "PERDIDAAAA despues: 0.1151638925075531\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "[[[0.32670927]\n",
      "  [0.32972553]\n",
      "  [0.3331745 ]\n",
      "  [0.33693659]\n",
      "  [0.34099615]\n",
      "  [0.34541234]\n",
      "  [0.35020813]\n",
      "  [0.35531279]]]\n",
      "ejemplar: [0.32670927 0.32972553 0.3331745  0.33693659 0.34099615 0.34541234\n",
      " 0.35020813 0.35531279]\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.36067808]]\n",
      "Lr que voy a aplicar en el lote: 58 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.32670927 0.32972553 0.3331745  0.33693659 0.34099615 0.34541234\n",
      "  0.35020813 0.35531279]]\n",
      "verdaderas salidas: [0.73731112]\n",
      "PERDIDAAAA antes: 0.1418524533510208\n",
      "Predicción post entrenamiento : [[0.36557367]]\n",
      "PERDIDAAAA despues: 0.13818873465061188\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "[[[0.32972553]\n",
      "  [0.3331745 ]\n",
      "  [0.33693659]\n",
      "  [0.34099615]\n",
      "  [0.34541234]\n",
      "  [0.35020813]\n",
      "  [0.35531279]\n",
      "  [0.36067808]]]\n",
      "ejemplar: [0.32972553 0.3331745  0.33693659 0.34099615 0.34541234 0.35020813\n",
      " 0.35531279 0.36067808]\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.3663626]]\n",
      "Lr que voy a aplicar en el lote: 59 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.32972553 0.3331745  0.33693659 0.34099615 0.34541234 0.35020813\n",
      "  0.35531279 0.36067808]]\n",
      "verdaderas salidas: [0.7214258]\n",
      "PERDIDAAAA antes: 0.12606990337371826\n",
      "Predicción post entrenamiento : [[0.37143478]]\n",
      "PERDIDAAAA despues: 0.12249373644590378\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "[[[0.3331745 ]\n",
      "  [0.33693659]\n",
      "  [0.34099615]\n",
      "  [0.34541234]\n",
      "  [0.35020813]\n",
      "  [0.35531279]\n",
      "  [0.36067808]\n",
      "  [0.3663626 ]]]\n",
      "ejemplar: [0.3331745  0.33693659 0.34099615 0.34541234 0.35020813 0.35531279\n",
      " 0.36067808 0.3663626 ]\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.37230948]]\n",
      "Lr que voy a aplicar en el lote: 60 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.3331745  0.33693659 0.34099615 0.34541234 0.35020813 0.35531279\n",
      "  0.36067808 0.3663626 ]]\n",
      "verdaderas salidas: [0.71871368]\n",
      "PERDIDAAAA antes: 0.11999588459730148\n",
      "Predicción post entrenamiento : [[0.37753743]]\n",
      "PERDIDAAAA despues: 0.11640124768018723\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "[[[0.33693659]\n",
      "  [0.34099615]\n",
      "  [0.34541234]\n",
      "  [0.35020813]\n",
      "  [0.35531279]\n",
      "  [0.36067808]\n",
      "  [0.3663626 ]\n",
      "  [0.37230948]]]\n",
      "ejemplar: [0.33693659 0.34099615 0.34541234 0.35020813 0.35531279 0.36067808\n",
      " 0.3663626  0.37230948]\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.37849307]]\n",
      "Lr que voy a aplicar en el lote: 61 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.33693659 0.34099615 0.34541234 0.35020813 0.35531279 0.36067808\n",
      "  0.3663626  0.37230948]]\n",
      "verdaderas salidas: [0.6741573]\n",
      "PERDIDAAAA antes: 0.0874173492193222\n",
      "Predicción post entrenamiento : [[0.38380378]]\n",
      "PERDIDAAAA despues: 0.08430517464876175\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "[[[0.34099615]\n",
      "  [0.34541234]\n",
      "  [0.35020813]\n",
      "  [0.35531279]\n",
      "  [0.36067808]\n",
      "  [0.3663626 ]\n",
      "  [0.37230948]\n",
      "  [0.37849307]]]\n",
      "ejemplar: [0.34099615 0.34541234 0.35020813 0.35531279 0.36067808 0.3663626\n",
      " 0.37230948 0.37849307]\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.3848427]]\n",
      "Lr que voy a aplicar en el lote: 62 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.34099615 0.34541234 0.35020813 0.35531279 0.36067808 0.3663626\n",
      "  0.37230948 0.37849307]]\n",
      "verdaderas salidas: [0.69856645]\n",
      "PERDIDAAAA antes: 0.0984225869178772\n",
      "Predicción post entrenamiento : [[0.390268]]\n",
      "PERDIDAAAA despues: 0.09504792839288712\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "[[[0.34541234]\n",
      "  [0.35020813]\n",
      "  [0.35531279]\n",
      "  [0.36067808]\n",
      "  [0.3663626 ]\n",
      "  [0.37230948]\n",
      "  [0.37849307]\n",
      "  [0.38484269]]]\n",
      "ejemplar: [0.34541234 0.35020813 0.35531279 0.36067808 0.3663626  0.37230948\n",
      " 0.37849307 0.38484269]\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.39139283]]\n",
      "Lr que voy a aplicar en el lote: 63 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.34541234 0.35020813 0.35531279 0.36067808 0.3663626  0.37230948\n",
      "  0.37849307 0.38484269]]\n",
      "verdaderas salidas: [0.72103836]\n",
      "PERDIDAAAA antes: 0.10866616666316986\n",
      "Predicción post entrenamiento : [[0.39697018]]\n",
      "PERDIDAAAA despues: 0.10502017289400101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "[[[0.35020813]\n",
      "  [0.35531279]\n",
      "  [0.36067808]\n",
      "  [0.3663626 ]\n",
      "  [0.37230948]\n",
      "  [0.37849307]\n",
      "  [0.38484269]\n",
      "  [0.39139283]]]\n",
      "ejemplar: [0.35020813 0.35531279 0.36067808 0.3663626  0.37230948 0.37849307\n",
      " 0.38484269 0.39139283]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.398179]]\n",
      "Lr que voy a aplicar en el lote: 64 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.35020813 0.35531279 0.36067808 0.3663626  0.37230948 0.37849307\n",
      "  0.38484269 0.39139283]]\n",
      "verdaderas salidas: [0.72258814]\n",
      "PERDIDAAAA antes: 0.10524128377437592\n",
      "Predicción post entrenamiento : [[0.40390876]]\n",
      "PERDIDAAAA despues: 0.10155653953552246\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "[[[0.35531279]\n",
      "  [0.36067808]\n",
      "  [0.3663626 ]\n",
      "  [0.37230948]\n",
      "  [0.37849307]\n",
      "  [0.38484269]\n",
      "  [0.39139283]\n",
      "  [0.39817899]]]\n",
      "ejemplar: [0.35531279 0.36067808 0.3663626  0.37230948 0.37849307 0.38484269\n",
      " 0.39139283 0.39817899]\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.4051962]]\n",
      "Lr que voy a aplicar en el lote: 65 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.35531279 0.36067808 0.3663626  0.37230948 0.37849307 0.38484269\n",
      "  0.39139283 0.39817899]]\n",
      "verdaderas salidas: [0.75629601]\n",
      "PERDIDAAAA antes: 0.12327110022306442\n",
      "Predicción post entrenamiento : [[0.4111281]]\n",
      "PERDIDAAAA despues: 0.11914090067148209\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "[[[0.36067808]\n",
      "  [0.3663626 ]\n",
      "  [0.37230948]\n",
      "  [0.37849307]\n",
      "  [0.38484269]\n",
      "  [0.39139283]\n",
      "  [0.39817899]\n",
      "  [0.40519619]]]\n",
      "ejemplar: [0.36067808 0.3663626  0.37230948 0.37849307 0.38484269 0.39139283\n",
      " 0.39817899 0.40519619]\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.41249236]]\n",
      "Lr que voy a aplicar en el lote: 66 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.36067808 0.3663626  0.37230948 0.37849307 0.38484269 0.39139283\n",
      "  0.39817899 0.40519619]]\n",
      "verdaderas salidas: [0.82758621]\n",
      "PERDIDAAAA antes: 0.17230291664600372\n",
      "Predicción post entrenamiento : [[0.41875288]]\n",
      "PERDIDAAAA despues: 0.16714471578598022\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "[[[0.3663626 ]\n",
      "  [0.37230948]\n",
      "  [0.37849307]\n",
      "  [0.38484269]\n",
      "  [0.39139283]\n",
      "  [0.39817899]\n",
      "  [0.40519619]\n",
      "  [0.41249236]]]\n",
      "ejemplar: [0.3663626  0.37230948 0.37849307 0.38484269 0.39139283 0.39817899\n",
      " 0.40519619 0.41249236]\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.42019528]]\n",
      "Lr que voy a aplicar en el lote: 67 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.3663626  0.37230948 0.37849307 0.38484269 0.39139283 0.39817899\n",
      "  0.40519619 0.41249236]]\n",
      "verdaderas salidas: [0.83882216]\n",
      "PERDIDAAAA antes: 0.17524848878383636\n",
      "Predicción post entrenamiento : [[0.42681432]]\n",
      "PERDIDAAAA despues: 0.16975048184394836\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "[[[0.37230948]\n",
      "  [0.37849307]\n",
      "  [0.38484269]\n",
      "  [0.39139283]\n",
      "  [0.39817899]\n",
      "  [0.40519619]\n",
      "  [0.41249236]\n",
      "  [0.42019528]]]\n",
      "ejemplar: [0.37230948 0.37849307 0.38484269 0.39139283 0.39817899 0.40519619\n",
      " 0.41249236 0.42019528]\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.42833203]]\n",
      "Lr que voy a aplicar en el lote: 68 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.37230948 0.37849307 0.38484269 0.39139283 0.39817899 0.40519619\n",
      "  0.41249236 0.42019528]]\n",
      "verdaderas salidas: [0.79426579]\n",
      "PERDIDAAAA antes: 0.1339075267314911\n",
      "Predicción post entrenamiento : [[0.43517855]]\n",
      "PERDIDAAAA despues: 0.12894365191459656\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "[[[0.37849307]\n",
      "  [0.38484269]\n",
      "  [0.39139283]\n",
      "  [0.39817899]\n",
      "  [0.40519619]\n",
      "  [0.41249236]\n",
      "  [0.42019528]\n",
      "  [0.42833203]]]\n",
      "ejemplar: [0.37849307 0.38484269 0.39139283 0.39817899 0.40519619 0.41249236\n",
      " 0.42019528 0.42833203]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.43677217]]\n",
      "Lr que voy a aplicar en el lote: 69 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.37849307 0.38484269 0.39139283 0.39817899 0.40519619 0.41249236\n",
      "  0.42019528 0.42833203]]\n",
      "verdaderas salidas: [0.78380473]\n",
      "PERDIDAAAA antes: 0.12043158710002899\n",
      "Predicción post entrenamiento : [[0.44380936]]\n",
      "PERDIDAAAA despues: 0.11559683829545975\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "[[[0.38484269]\n",
      "  [0.39139283]\n",
      "  [0.39817899]\n",
      "  [0.40519619]\n",
      "  [0.41249236]\n",
      "  [0.42019528]\n",
      "  [0.42833203]\n",
      "  [0.43677217]]]\n",
      "ejemplar: [0.38484269 0.39139283 0.39817899 0.40519619 0.41249236 0.42019528\n",
      " 0.42833203 0.43677217]\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.4454823]]\n",
      "Lr que voy a aplicar en el lote: 70 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.38484269 0.39139283 0.39817899 0.40519619 0.41249236 0.42019528\n",
      "  0.42833203 0.43677217]]\n",
      "verdaderas salidas: [0.76791941]\n",
      "PERDIDAAAA antes: 0.10396568477153778\n",
      "Predicción post entrenamiento : [[0.4526637]]\n",
      "PERDIDAAAA despues: 0.09938617795705795\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "[[[0.39139283]\n",
      "  [0.39817899]\n",
      "  [0.40519619]\n",
      "  [0.41249236]\n",
      "  [0.42019528]\n",
      "  [0.42833203]\n",
      "  [0.43677217]\n",
      "  [0.44548231]]]\n",
      "ejemplar: [0.39139283 0.39817899 0.40519619 0.41249236 0.42019528 0.42833203\n",
      " 0.43677217 0.44548231]\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.45442638]]\n",
      "Lr que voy a aplicar en el lote: 71 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.39139283 0.39817899 0.40519619 0.41249236 0.42019528 0.42833203\n",
      "  0.43677217 0.44548231]]\n",
      "verdaderas salidas: [0.78457962]\n",
      "PERDIDAAAA antes: 0.10900117456912994\n",
      "Predicción post entrenamiento : [[0.4617682]]\n",
      "PERDIDAAAA despues: 0.10420721769332886\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "[[[0.39817899]\n",
      "  [0.40519619]\n",
      "  [0.41249236]\n",
      "  [0.42019528]\n",
      "  [0.42833203]\n",
      "  [0.43677217]\n",
      "  [0.44548231]\n",
      "  [0.45442638]]]\n",
      "ejemplar: [0.39817899 0.40519619 0.41249236 0.42019528 0.42833203 0.43677217\n",
      " 0.44548231 0.45442638]\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.46363062]]\n",
      "Lr que voy a aplicar en el lote: 72 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.39817899 0.40519619 0.41249236 0.42019528 0.42833203 0.43677217\n",
      "  0.44548231 0.45442638]]\n",
      "verdaderas salidas: [0.87872917]\n",
      "PERDIDAAAA antes: 0.17230680584907532\n",
      "Predicción post entrenamiento : [[0.471374]]\n",
      "PERDIDAAAA despues: 0.16593822836875916\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "[[[0.40519619]\n",
      "  [0.41249236]\n",
      "  [0.42019528]\n",
      "  [0.42833203]\n",
      "  [0.43677217]\n",
      "  [0.44548231]\n",
      "  [0.45442638]\n",
      "  [0.46363062]]]\n",
      "ejemplar: [0.40519619 0.41249236 0.42019528 0.42833203 0.43677217 0.44548231\n",
      " 0.45442638 0.46363062]\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.47334585]]\n",
      "Lr que voy a aplicar en el lote: 73 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.40519619 0.41249236 0.42019528 0.42833203 0.43677217 0.44548231\n",
      "  0.45442638 0.46363062]]\n",
      "verdaderas salidas: [0.8756296]\n",
      "PERDIDAAAA antes: 0.16183222830295563\n",
      "Predicción post entrenamiento : [[0.48148838]]\n",
      "PERDIDAAAA despues: 0.1553473025560379\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "[[[0.41249236]\n",
      "  [0.42019528]\n",
      "  [0.42833203]\n",
      "  [0.43677217]\n",
      "  [0.44548231]\n",
      "  [0.45442638]\n",
      "  [0.46363062]\n",
      "  [0.47334585]]]\n",
      "ejemplar: [0.41249236 0.42019528 0.42833203 0.43677217 0.44548231 0.45442638\n",
      " 0.46363062 0.47334585]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.48358127]]\n",
      "Lr que voy a aplicar en el lote: 74 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.41249236 0.42019528 0.42833203 0.43677217 0.44548231 0.45442638\n",
      "  0.46363062 0.47334585]]\n",
      "verdaderas salidas: [0.84889578]\n",
      "PERDIDAAAA antes: 0.13345469534397125\n",
      "Predicción post entrenamiento : [[0.49201182]]\n",
      "PERDIDAAAA despues: 0.12736617028713226\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "[[[0.42019528]\n",
      "  [0.42833203]\n",
      "  [0.43677217]\n",
      "  [0.44548231]\n",
      "  [0.45442638]\n",
      "  [0.46363062]\n",
      "  [0.47334585]\n",
      "  [0.48358127]]]\n",
      "ejemplar: [0.42019528 0.42833203 0.43677217 0.44548231 0.45442638 0.46363062\n",
      " 0.47334585 0.48358127]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.49423495]]\n",
      "Lr que voy a aplicar en el lote: 75 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.42019528 0.42833203 0.43677217 0.44548231 0.45442638 0.46363062\n",
      "  0.47334585 0.48358127]]\n",
      "verdaderas salidas: [0.81828749]\n",
      "PERDIDAAAA antes: 0.10501004755496979\n",
      "Predicción post entrenamiento : [[0.50288314]]\n",
      "PERDIDAAAA despues: 0.09947990626096725\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "[[[0.42833203]\n",
      "  [0.43677217]\n",
      "  [0.44548231]\n",
      "  [0.45442638]\n",
      "  [0.46363062]\n",
      "  [0.47334585]\n",
      "  [0.48358127]\n",
      "  [0.49423495]]]\n",
      "ejemplar: [0.42833203 0.43677217 0.44548231 0.45442638 0.46363062 0.47334585\n",
      " 0.48358127 0.49423495]\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.50523555]]\n",
      "Lr que voy a aplicar en el lote: 76 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.42833203 0.43677217 0.44548231 0.45442638 0.46363062 0.47334585\n",
      "  0.48358127 0.49423495]]\n",
      "verdaderas salidas: [0.82681131]\n",
      "PERDIDAAAA antes: 0.10341096669435501\n",
      "Predicción post entrenamiento : [[0.5140857]]\n",
      "PERDIDAAAA despues: 0.09779730439186096\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "[[[0.43677217]\n",
      "  [0.44548231]\n",
      "  [0.45442638]\n",
      "  [0.46363062]\n",
      "  [0.47334585]\n",
      "  [0.48358127]\n",
      "  [0.49423495]\n",
      "  [0.50523555]]]\n",
      "ejemplar: [0.43677217 0.44548231 0.45442638 0.46363062 0.47334585 0.48358127\n",
      " 0.49423495 0.50523555]\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.51656383]]\n",
      "Lr que voy a aplicar en el lote: 77 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.43677217 0.44548231 0.45442638 0.46363062 0.47334585 0.48358127\n",
      "  0.49423495 0.50523555]]\n",
      "verdaderas salidas: [0.78535451]\n",
      "PERDIDAAAA antes: 0.0722484216094017\n",
      "Predicción post entrenamiento : [[0.5254922]]\n",
      "PERDIDAAAA despues: 0.06752841919660568\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "[[[0.44548231]\n",
      "  [0.45442638]\n",
      "  [0.46363062]\n",
      "  [0.47334585]\n",
      "  [0.48358127]\n",
      "  [0.49423495]\n",
      "  [0.50523555]\n",
      "  [0.51656383]]]\n",
      "ejemplar: [0.44548231 0.45442638 0.46363062 0.47334585 0.48358127 0.49423495\n",
      " 0.50523555 0.51656383]\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.5281031]]\n",
      "Lr que voy a aplicar en el lote: 78 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.44548231 0.45442638 0.46363062 0.47334585 0.48358127 0.49423495\n",
      "  0.50523555 0.51656383]]\n",
      "verdaderas salidas: [0.78922898]\n",
      "PERDIDAAAA antes: 0.06818671524524689\n",
      "Predicción post entrenamiento : [[0.537205]]\n",
      "PERDIDAAAA despues: 0.06351609528064728\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "[[[0.45442638]\n",
      "  [0.46363062]\n",
      "  [0.47334585]\n",
      "  [0.48358127]\n",
      "  [0.49423495]\n",
      "  [0.50523555]\n",
      "  [0.51656383]\n",
      "  [0.52810311]]]\n",
      "ejemplar: [0.45442638 0.46363062 0.47334585 0.48358127 0.49423495 0.50523555\n",
      " 0.51656383 0.52810311]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.539961]]\n",
      "Lr que voy a aplicar en el lote: 79 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.45442638 0.46363062 0.47334585 0.48358127 0.49423495 0.50523555\n",
      "  0.51656383 0.52810311]]\n",
      "verdaderas salidas: [0.8341728]\n",
      "PERDIDAAAA antes: 0.08656058460474014\n",
      "Predicción post entrenamiento : [[0.54926413]]\n",
      "PERDIDAAAA despues: 0.08117294311523438\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "[[[0.46363062]\n",
      "  [0.47334585]\n",
      "  [0.48358127]\n",
      "  [0.49423495]\n",
      "  [0.50523555]\n",
      "  [0.51656383]\n",
      "  [0.52810311]\n",
      "  [0.53996098]]]\n",
      "ejemplar: [0.46363062 0.47334585 0.48358127 0.49423495 0.50523555 0.51656383\n",
      " 0.52810311 0.53996098]\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.55218226]]\n",
      "Lr que voy a aplicar en el lote: 80 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.46363062 0.47334585 0.48358127 0.49423495 0.50523555 0.51656383\n",
      "  0.52810311 0.53996098]]\n",
      "verdaderas salidas: [0.81247578]\n",
      "PERDIDAAAA antes: 0.06775272637605667\n",
      "Predicción post entrenamiento : [[0.5616752]]\n",
      "PERDIDAAAA despues: 0.06290094554424286\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "[[[0.47334585]\n",
      "  [0.48358127]\n",
      "  [0.49423495]\n",
      "  [0.50523555]\n",
      "  [0.51656383]\n",
      "  [0.52810311]\n",
      "  [0.53996098]\n",
      "  [0.55218226]]]\n",
      "ejemplar: [0.47334585 0.48358127 0.49423495 0.50523555 0.51656383 0.52810311\n",
      " 0.53996098 0.55218226]\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.5647724]]\n",
      "Lr que voy a aplicar en el lote: 81 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.47334585 0.48358127 0.49423495 0.50523555 0.51656383 0.52810311\n",
      "  0.53996098 0.55218226]]\n",
      "verdaderas salidas: [0.80123983]\n",
      "PERDIDAAAA antes: 0.05591684207320213\n",
      "Predicción post entrenamiento : [[0.57443553]]\n",
      "PERDIDAAAA despues: 0.051440197974443436\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "[[[0.48358127]\n",
      "  [0.49423495]\n",
      "  [0.50523555]\n",
      "  [0.51656383]\n",
      "  [0.52810311]\n",
      "  [0.53996098]\n",
      "  [0.55218226]\n",
      "  [0.56477243]]]\n",
      "ejemplar: [0.48358127 0.49423495 0.50523555 0.51656383 0.52810311 0.53996098\n",
      " 0.55218226 0.56477243]\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.57770485]]\n",
      "Lr que voy a aplicar en el lote: 82 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.48358127 0.49423495 0.50523555 0.51656383 0.52810311 0.53996098\n",
      "  0.55218226 0.56477243]]\n",
      "verdaderas salidas: [0.80317706]\n",
      "PERDIDAAAA antes: 0.050837717950344086\n",
      "Predicción post entrenamiento : [[0.58749133]]\n",
      "PERDIDAAAA despues: 0.046520333737134933\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "[[[0.49423495]\n",
      "  [0.50523555]\n",
      "  [0.51656383]\n",
      "  [0.52810311]\n",
      "  [0.53996098]\n",
      "  [0.55218226]\n",
      "  [0.56477243]\n",
      "  [0.57770485]]]\n",
      "ejemplar: [0.49423495 0.50523555 0.51656383 0.52810311 0.53996098 0.55218226\n",
      " 0.56477243 0.57770485]\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.59092146]]\n",
      "Lr que voy a aplicar en el lote: 83 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.49423495 0.50523555 0.51656383 0.52810311 0.53996098 0.55218226\n",
      "  0.56477243 0.57770485]]\n",
      "verdaderas salidas: [0.7934909]\n",
      "PERDIDAAAA antes: 0.04103437066078186\n",
      "Predicción post entrenamiento : [[0.60070455]]\n",
      "PERDIDAAAA despues: 0.037166573107242584\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "[[[0.50523555]\n",
      "  [0.51656383]\n",
      "  [0.52810311]\n",
      "  [0.53996098]\n",
      "  [0.55218226]\n",
      "  [0.56477243]\n",
      "  [0.57770485]\n",
      "  [0.59092146]]]\n",
      "ejemplar: [0.50523555 0.51656383 0.52810311 0.53996098 0.55218226 0.56477243\n",
      " 0.57770485 0.59092146]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.60429007]]\n",
      "Lr que voy a aplicar en el lote: 84 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.50523555 0.51656383 0.52810311 0.53996098 0.55218226 0.56477243\n",
      "  0.57770485 0.59092146]]\n",
      "verdaderas salidas: [0.76017048]\n",
      "PERDIDAAAA antes: 0.024298695847392082\n",
      "Predicción post entrenamiento : [[0.61372524]]\n",
      "PERDIDAAAA despues: 0.02144620008766651\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "[[[0.51656383]\n",
      "  [0.52810311]\n",
      "  [0.53996098]\n",
      "  [0.55218226]\n",
      "  [0.56477243]\n",
      "  [0.57770485]\n",
      "  [0.59092146]\n",
      "  [0.60429007]]]\n",
      "ejemplar: [0.51656383 0.52810311 0.53996098 0.55218226 0.56477243 0.57770485\n",
      " 0.59092146 0.60429007]\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.61746347]]\n",
      "Lr que voy a aplicar en el lote: 85 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.51656383 0.52810311 0.53996098 0.55218226 0.56477243 0.57770485\n",
      "  0.59092146 0.60429007]]\n",
      "verdaderas salidas: [0.73537389]\n",
      "PERDIDAAAA antes: 0.013902872800827026\n",
      "Predicción post entrenamiento : [[0.6268124]]\n",
      "PERDIDAAAA despues: 0.011785603128373623\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "[[[0.52810311]\n",
      "  [0.53996098]\n",
      "  [0.55218226]\n",
      "  [0.56477243]\n",
      "  [0.57770485]\n",
      "  [0.59092146]\n",
      "  [0.60429007]\n",
      "  [0.61746347]]]\n",
      "ejemplar: [0.52810311 0.53996098 0.55218226 0.56477243 0.57770485 0.59092146\n",
      " 0.60429007 0.61746347]\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.6307019]]\n",
      "Lr que voy a aplicar en el lote: 86 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.52810311 0.53996098 0.55218226 0.56477243 0.57770485 0.59092146\n",
      "  0.60429007 0.61746347]]\n",
      "verdaderas salidas: [0.71018985]\n",
      "PERDIDAAAA antes: 0.006318329367786646\n",
      "Predicción post entrenamiento : [[0.63957953]]\n",
      "PERDIDAAAA despues: 0.004985812120139599\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "[[[0.53996098]\n",
      "  [0.55218226]\n",
      "  [0.56477243]\n",
      "  [0.57770485]\n",
      "  [0.59092146]\n",
      "  [0.60429007]\n",
      "  [0.61746347]\n",
      "  [0.6307019 ]]]\n",
      "ejemplar: [0.53996098 0.55218226 0.56477243 0.57770485 0.59092146 0.60429007\n",
      " 0.61746347 0.6307019 ]\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.6436264]]\n",
      "Lr que voy a aplicar en el lote: 87 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.53996098 0.55218226 0.56477243 0.57770485 0.59092146 0.60429007\n",
      "  0.61746347 0.6307019 ]]\n",
      "verdaderas salidas: [0.71212708]\n",
      "PERDIDAAAA antes: 0.004692345391958952\n",
      "Predicción post entrenamiento : [[0.65207094]]\n",
      "PERDIDAAAA despues: 0.0036067410837858915\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "[[[0.55218226]\n",
      "  [0.56477243]\n",
      "  [0.57770485]\n",
      "  [0.59092146]\n",
      "  [0.60429007]\n",
      "  [0.61746347]\n",
      "  [0.6307019 ]\n",
      "  [0.64362639]]]\n",
      "ejemplar: [0.55218226 0.56477243 0.57770485 0.59092146 0.60429007 0.61746347\n",
      " 0.6307019  0.64362639]\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.65626615]]\n",
      "Lr que voy a aplicar en el lote: 88 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.55218226 0.56477243 0.57770485 0.59092146 0.60429007 0.61746347\n",
      "  0.6307019  0.64362639]]\n",
      "verdaderas salidas: [0.7396358]\n",
      "PERDIDAAAA antes: 0.006950502283871174\n",
      "Predicción post entrenamiento : [[0.664057]]\n",
      "PERDIDAAAA despues: 0.005712156184017658\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "[[[0.56477243]\n",
      "  [0.57770485]\n",
      "  [0.59092146]\n",
      "  [0.60429007]\n",
      "  [0.61746347]\n",
      "  [0.6307019 ]\n",
      "  [0.64362639]\n",
      "  [0.65626615]]]\n",
      "ejemplar: [0.56477243 0.57770485 0.59092146 0.60429007 0.61746347 0.6307019\n",
      " 0.64362639 0.65626615]\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.66837865]]\n",
      "Lr que voy a aplicar en el lote: 89 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.56477243 0.57770485 0.59092146 0.60429007 0.61746347 0.6307019\n",
      "  0.64362639 0.65626615]]\n",
      "verdaderas salidas: [0.73614878]\n",
      "PERDIDAAAA antes: 0.004592789802700281\n",
      "Predicción post entrenamiento : [[0.67593634]]\n",
      "PERDIDAAAA despues: 0.003625537035986781\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "[[[0.57770485]\n",
      "  [0.59092146]\n",
      "  [0.60429007]\n",
      "  [0.61746347]\n",
      "  [0.6307019 ]\n",
      "  [0.64362639]\n",
      "  [0.65626615]\n",
      "  [0.66837865]]]\n",
      "ejemplar: [0.57770485 0.59092146 0.60429007 0.61746347 0.6307019  0.64362639\n",
      " 0.65626615 0.66837865]\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.6803543]]\n",
      "Lr que voy a aplicar en el lote: 90 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.57770485 0.59092146 0.60429007 0.61746347 0.6307019  0.64362639\n",
      "  0.65626615 0.66837865]]\n",
      "verdaderas salidas: [0.66757071]\n",
      "PERDIDAAAA antes: 0.0001634200889384374\n",
      "Predicción post entrenamiento : [[0.6869384]]\n",
      "PERDIDAAAA despues: 0.00037510760012082756\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "[[[0.59092146]\n",
      "  [0.60429007]\n",
      "  [0.61746347]\n",
      "  [0.6307019 ]\n",
      "  [0.64362639]\n",
      "  [0.65626615]\n",
      "  [0.66837865]\n",
      "  [0.6803543 ]]]\n",
      "ejemplar: [0.59092146 0.60429007 0.61746347 0.6307019  0.64362639 0.65626615\n",
      " 0.66837865 0.6803543 ]\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.69140834]]\n",
      "Lr que voy a aplicar en el lote: 91 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.59092146 0.60429007 0.61746347 0.6307019  0.64362639 0.65626615\n",
      "  0.66837865 0.6803543 ]]\n",
      "verdaderas salidas: [0.66989539]\n",
      "PERDIDAAAA antes: 0.00046280596870929003\n",
      "Predicción post entrenamiento : [[0.69714785]]\n",
      "PERDIDAAAA despues: 0.0007426952361129224\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "[[[0.60429007]\n",
      "  [0.61746347]\n",
      "  [0.6307019 ]\n",
      "  [0.64362639]\n",
      "  [0.65626615]\n",
      "  [0.66837865]\n",
      "  [0.6803543 ]\n",
      "  [0.69140834]]]\n",
      "ejemplar: [0.60429007 0.61746347 0.6307019  0.64362639 0.65626615 0.66837865\n",
      " 0.6803543  0.69140834]\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.7016196]]\n",
      "Lr que voy a aplicar en el lote: 92 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.60429007 0.61746347 0.6307019  0.64362639 0.65626615 0.66837865\n",
      "  0.6803543  0.69140834]]\n",
      "verdaderas salidas: [0.69662921]\n",
      "PERDIDAAAA antes: 2.49040804192191e-05\n",
      "Predicción post entrenamiento : [[0.7063376]]\n",
      "PERDIDAAAA despues: 9.425196185475215e-05\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "[[[0.61746347]\n",
      "  [0.6307019 ]\n",
      "  [0.64362639]\n",
      "  [0.65626615]\n",
      "  [0.66837865]\n",
      "  [0.6803543 ]\n",
      "  [0.69140834]\n",
      "  [0.70161963]]]\n",
      "ejemplar: [0.61746347 0.6307019  0.64362639 0.65626615 0.66837865 0.6803543\n",
      " 0.69140834 0.70161963]\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.7107606]]\n",
      "Lr que voy a aplicar en el lote: 93 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.61746347 0.6307019  0.64362639 0.65626615 0.66837865 0.6803543\n",
      "  0.69140834 0.70161963]]\n",
      "verdaderas salidas: [0.65594731]\n",
      "PERDIDAAAA antes: 0.003004494123160839\n",
      "Predicción post entrenamiento : [[0.7149909]]\n",
      "PERDIDAAAA despues: 0.003486145054921508\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "[[[0.6307019 ]\n",
      "  [0.64362639]\n",
      "  [0.65626615]\n",
      "  [0.66837865]\n",
      "  [0.6803543 ]\n",
      "  [0.69140834]\n",
      "  [0.70161963]\n",
      "  [0.71076059]]]\n",
      "ejemplar: [0.6307019  0.64362639 0.65626615 0.66837865 0.6803543  0.69140834\n",
      " 0.70161963 0.71076059]\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.71934503]]\n",
      "Lr que voy a aplicar en el lote: 94 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.6307019  0.64362639 0.65626615 0.66837865 0.6803543  0.69140834\n",
      "  0.70161963 0.71076059]]\n",
      "verdaderas salidas: [0.67880666]\n",
      "PERDIDAAAA antes: 0.001643359544686973\n",
      "Predicción post entrenamiento : [[0.7231316]]\n",
      "PERDIDAAAA despues: 0.001964699709787965\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "[[[0.64362639]\n",
      "  [0.65626615]\n",
      "  [0.66837865]\n",
      "  [0.6803543 ]\n",
      "  [0.69140834]\n",
      "  [0.70161963]\n",
      "  [0.71076059]\n",
      "  [0.71934503]]]\n",
      "ejemplar: [0.64362639 0.65626615 0.66837865 0.6803543  0.69140834 0.70161963\n",
      " 0.71076059 0.71934503]\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.72735727]]\n",
      "Lr que voy a aplicar en el lote: 95 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.64362639 0.65626615 0.66837865 0.6803543  0.69140834 0.70161963\n",
      "  0.71076059 0.71934503]]\n",
      "verdaderas salidas: [0.67609454]\n",
      "PERDIDAAAA antes: 0.002627868205308914\n",
      "Predicción post entrenamiento : [[0.7305924]]\n",
      "PERDIDAAAA despues: 0.00297002075240016\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "[[[0.65626615]\n",
      "  [0.66837865]\n",
      "  [0.6803543 ]\n",
      "  [0.69140834]\n",
      "  [0.70161963]\n",
      "  [0.71076059]\n",
      "  [0.71934503]\n",
      "  [0.72735727]]]\n",
      "ejemplar: [0.65626615 0.66837865 0.6803543  0.69140834 0.70161963 0.71076059\n",
      " 0.71934503 0.72735727]\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.73465973]]\n",
      "Lr que voy a aplicar en el lote: 96 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.65626615 0.66837865 0.6803543  0.69140834 0.70161963 0.71076059\n",
      "  0.71934503 0.72735727]]\n",
      "verdaderas salidas: [0.72956219]\n",
      "PERDIDAAAA antes: 2.5985200409195386e-05\n",
      "Predicción post entrenamiento : [[0.7377801]]\n",
      "PERDIDAAAA despues: 6.75343835609965e-05\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "[[[0.66837865]\n",
      "  [0.6803543 ]\n",
      "  [0.69140834]\n",
      "  [0.70161963]\n",
      "  [0.71076059]\n",
      "  [0.71934503]\n",
      "  [0.72735727]\n",
      "  [0.73465973]]]\n",
      "ejemplar: [0.66837865 0.6803543  0.69140834 0.70161963 0.71076059 0.71934503\n",
      " 0.72735727 0.73465973]\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.7416504]]\n",
      "Lr que voy a aplicar en el lote: 97 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.66837865 0.6803543  0.69140834 0.70161963 0.71076059 0.71934503\n",
      "  0.72735727 0.73465973]]\n",
      "verdaderas salidas: [0.70127857]\n",
      "PERDIDAAAA antes: 0.0016298850532621145\n",
      "Predicción post entrenamiento : [[0.74354583]]\n",
      "PERDIDAAAA despues: 0.0017865215195342898\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "[[[0.6803543 ]\n",
      "  [0.69140834]\n",
      "  [0.70161963]\n",
      "  [0.71076059]\n",
      "  [0.71934503]\n",
      "  [0.72735727]\n",
      "  [0.73465973]\n",
      "  [0.7416504 ]]]\n",
      "ejemplar: [0.6803543  0.69140834 0.70161963 0.71076059 0.71934503 0.72735727\n",
      " 0.73465973 0.7416504 ]\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.74719536]]\n",
      "Lr que voy a aplicar en el lote: 98 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.6803543  0.69140834 0.70161963 0.71076059 0.71934503 0.72735727\n",
      "  0.73465973 0.7416504 ]]\n",
      "verdaderas salidas: [0.76753196]\n",
      "PERDIDAAAA antes: 0.0004135784402024001\n",
      "Predicción post entrenamiento : [[0.7487282]]\n",
      "PERDIDAAAA despues: 0.00035358197055757046\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "[[[0.69140834]\n",
      "  [0.70161963]\n",
      "  [0.71076059]\n",
      "  [0.71934503]\n",
      "  [0.72735727]\n",
      "  [0.73465973]\n",
      "  [0.7416504 ]\n",
      "  [0.74719536]]]\n",
      "ejemplar: [0.69140834 0.70161963 0.71076059 0.71934503 0.72735727 0.73465973\n",
      " 0.7416504  0.74719536]\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.7520887]]\n",
      "Lr que voy a aplicar en el lote: 99 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.69140834 0.70161963 0.71076059 0.71934503 0.72735727 0.73465973\n",
      "  0.7416504  0.74719536]]\n",
      "verdaderas salidas: [0.75513367]\n",
      "PERDIDAAAA antes: 9.27179917198373e-06\n",
      "Predicción post entrenamiento : [[0.7537122]]\n",
      "PERDIDAAAA despues: 2.0206939552736003e-06\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "[[[0.70161963]\n",
      "  [0.71076059]\n",
      "  [0.71934503]\n",
      "  [0.72735727]\n",
      "  [0.73465973]\n",
      "  [0.7416504 ]\n",
      "  [0.74719536]\n",
      "  [0.75208873]]]\n",
      "ejemplar: [0.70161963 0.71076059 0.71934503 0.72735727 0.73465973 0.7416504\n",
      " 0.74719536 0.75208873]\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.75680107]]\n",
      "Lr que voy a aplicar en el lote: 100 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.70161963 0.71076059 0.71934503 0.72735727 0.73465973 0.7416504\n",
      "  0.74719536 0.75208873]]\n",
      "verdaderas salidas: [0.74506005]\n",
      "PERDIDAAAA antes: 0.00013785206829197705\n",
      "Predicción post entrenamiento : [[0.758903]]\n",
      "PERDIDAAAA despues: 0.0001916286419145763\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "[[[0.71076059]\n",
      "  [0.71934503]\n",
      "  [0.72735727]\n",
      "  [0.73465973]\n",
      "  [0.7416504 ]\n",
      "  [0.74719536]\n",
      "  [0.75208873]\n",
      "  [0.75680107]]]\n",
      "ejemplar: [0.71076059 0.71934503 0.72735727 0.73465973 0.7416504  0.74719536\n",
      " 0.75208873 0.75680107]\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.76173395]]\n",
      "Lr que voy a aplicar en el lote: 101 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.71076059 0.71934503 0.72735727 0.73465973 0.7416504  0.74719536\n",
      "  0.75208873 0.75680107]]\n",
      "verdaderas salidas: [0.7520341]\n",
      "PERDIDAAAA antes: 9.408769255969673e-05\n",
      "Predicción post entrenamiento : [[0.76367533]]\n",
      "PERDIDAAAA despues: 0.00013551903248298913\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "[[[0.71934503]\n",
      "  [0.72735727]\n",
      "  [0.73465973]\n",
      "  [0.7416504 ]\n",
      "  [0.74719536]\n",
      "  [0.75208873]\n",
      "  [0.75680107]\n",
      "  [0.76173395]]]\n",
      "ejemplar: [0.71934503 0.72735727 0.73465973 0.7416504  0.74719536 0.75208873\n",
      " 0.75680107 0.76173395]\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.76629233]]\n",
      "Lr que voy a aplicar en el lote: 102 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.71934503 0.72735727 0.73465973 0.7416504  0.74719536 0.75208873\n",
      "  0.75680107 0.76173395]]\n",
      "verdaderas salidas: [0.7098024]\n",
      "PERDIDAAAA antes: 0.0031911139376461506\n",
      "Predicción post entrenamiento : [[0.7670235]]\n",
      "PERDIDAAAA despues: 0.003274255897849798\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "[[[0.72735727]\n",
      "  [0.73465973]\n",
      "  [0.7416504 ]\n",
      "  [0.74719536]\n",
      "  [0.75208873]\n",
      "  [0.75680107]\n",
      "  [0.76173395]\n",
      "  [0.76629233]]]\n",
      "ejemplar: [0.72735727 0.73465973 0.7416504  0.74719536 0.75208873 0.75680107\n",
      " 0.76173395 0.76629233]\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.7694151]]\n",
      "Lr que voy a aplicar en el lote: 103 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.72735727 0.73465973 0.7416504  0.74719536 0.75208873 0.75680107\n",
      "  0.76173395 0.76629233]]\n",
      "verdaderas salidas: [0.69043007]\n",
      "PERDIDAAAA antes: 0.006238635629415512\n",
      "Predicción post entrenamiento : [[0.76954836]]\n",
      "PERDIDAAAA despues: 0.006259707268327475\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "[[[0.73465973]\n",
      "  [0.7416504 ]\n",
      "  [0.74719536]\n",
      "  [0.75208873]\n",
      "  [0.75680107]\n",
      "  [0.76173395]\n",
      "  [0.76629233]\n",
      "  [0.76941508]]]\n",
      "ejemplar: [0.73465973 0.7416504  0.74719536 0.75208873 0.75680107 0.76173395\n",
      " 0.76629233 0.76941508]\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.7717099]]\n",
      "Lr que voy a aplicar en el lote: 104 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.73465973 0.7416504  0.74719536 0.75208873 0.75680107 0.76173395\n",
      "  0.76629233 0.76941508]]\n",
      "verdaderas salidas: [0.75435878]\n",
      "PERDIDAAAA antes: 0.000301062420476228\n",
      "Predicción post entrenamiento : [[0.7723734]]\n",
      "PERDIDAAAA despues: 0.00032452616142109036\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "[[[0.7416504 ]\n",
      "  [0.74719536]\n",
      "  [0.75208873]\n",
      "  [0.75680107]\n",
      "  [0.76173395]\n",
      "  [0.76629233]\n",
      "  [0.76941508]\n",
      "  [0.77170992]]]\n",
      "ejemplar: [0.7416504  0.74719536 0.75208873 0.75680107 0.76173395 0.76629233\n",
      " 0.76941508 0.77170992]\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.7743211]]\n",
      "Lr que voy a aplicar en el lote: 105 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.7416504  0.74719536 0.75208873 0.75680107 0.76173395 0.76629233\n",
      "  0.76941508 0.77170992]]\n",
      "verdaderas salidas: [0.7222007]\n",
      "PERDIDAAAA antes: 0.002716534771025181\n",
      "Predicción post entrenamiento : [[0.77478963]]\n",
      "PERDIDAAAA despues: 0.0027655966114252806\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "[[[0.74719536]\n",
      "  [0.75208873]\n",
      "  [0.75680107]\n",
      "  [0.76173395]\n",
      "  [0.76629233]\n",
      "  [0.76941508]\n",
      "  [0.77170992]\n",
      "  [0.77432108]]]\n",
      "ejemplar: [0.74719536 0.75208873 0.75680107 0.76173395 0.76629233 0.76941508\n",
      " 0.77170992 0.77432108]\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.7764926]]\n",
      "Lr que voy a aplicar en el lote: 106 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.74719536 0.75208873 0.75680107 0.76173395 0.76629233 0.76941508\n",
      "  0.77170992 0.77432108]]\n",
      "verdaderas salidas: [0.84850833]\n",
      "PERDIDAAAA antes: 0.0051862699910998344\n",
      "Predicción post entrenamiento : [[0.7772875]]\n",
      "PERDIDAAAA despues: 0.005072413012385368\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "[[[0.75208873]\n",
      "  [0.75680107]\n",
      "  [0.76173395]\n",
      "  [0.76629233]\n",
      "  [0.76941508]\n",
      "  [0.77170992]\n",
      "  [0.77432108]\n",
      "  [0.7764926 ]]]\n",
      "ejemplar: [0.75208873 0.75680107 0.76173395 0.76629233 0.76941508 0.77170992\n",
      " 0.77432108 0.7764926 ]\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.7788512]]\n",
      "Lr que voy a aplicar en el lote: 107 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.75208873 0.75680107 0.76173395 0.76629233 0.76941508 0.77170992\n",
      "  0.77432108 0.7764926 ]]\n",
      "verdaderas salidas: [0.905463]\n",
      "PERDIDAAAA antes: 0.01603054068982601\n",
      "Predicción post entrenamiento : [[0.78040296]]\n",
      "PERDIDAAAA despues: 0.015640009194612503\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "[[[0.75680107]\n",
      "  [0.76173395]\n",
      "  [0.76629233]\n",
      "  [0.76941508]\n",
      "  [0.77170992]\n",
      "  [0.77432108]\n",
      "  [0.7764926 ]\n",
      "  [0.77885121]]]\n",
      "ejemplar: [0.75680107 0.76173395 0.76629233 0.76941508 0.77170992 0.77432108\n",
      " 0.7764926  0.77885121]\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.7818576]]\n",
      "Lr que voy a aplicar en el lote: 108 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.75680107 0.76173395 0.76629233 0.76941508 0.77170992 0.77432108\n",
      "  0.7764926  0.77885121]]\n",
      "verdaderas salidas: [0.8822162]\n",
      "PERDIDAAAA antes: 0.010071849450469017\n",
      "Predicción post entrenamiento : [[0.7840993]]\n",
      "PERDIDAAAA despues: 0.009626932442188263\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "[[[0.76173395]\n",
      "  [0.76629233]\n",
      "  [0.76941508]\n",
      "  [0.77170992]\n",
      "  [0.77432108]\n",
      "  [0.7764926 ]\n",
      "  [0.77885121]\n",
      "  [0.78185761]]]\n",
      "ejemplar: [0.76173395 0.76629233 0.76941508 0.77170992 0.77432108 0.7764926\n",
      " 0.77885121 0.78185761]\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.7854253]]\n",
      "Lr que voy a aplicar en el lote: 109 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.76173395 0.76629233 0.76941508 0.77170992 0.77432108 0.7764926\n",
      "  0.77885121 0.78185761]]\n",
      "verdaderas salidas: [0.90778768]\n",
      "PERDIDAAAA antes: 0.014972550794482231\n",
      "Predicción post entrenamiento : [[0.7877841]]\n",
      "PERDIDAAAA despues: 0.014400859363377094\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "[[[0.76629233]\n",
      "  [0.76941508]\n",
      "  [0.77170992]\n",
      "  [0.77432108]\n",
      "  [0.7764926 ]\n",
      "  [0.77885121]\n",
      "  [0.78185761]\n",
      "  [0.78542531]]]\n",
      "ejemplar: [0.76629233 0.76941508 0.77170992 0.77432108 0.7764926  0.77885121\n",
      " 0.78185761 0.78542531]\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.78891486]]\n",
      "Lr que voy a aplicar en el lote: 110 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.76629233 0.76941508 0.77170992 0.77432108 0.7764926  0.77885121\n",
      "  0.78185761 0.78542531]]\n",
      "verdaderas salidas: [0.88957768]\n",
      "PERDIDAAAA antes: 0.010133004747331142\n",
      "Predicción post entrenamiento : [[0.791889]]\n",
      "PERDIDAAAA despues: 0.00954307708889246\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "[[[0.76941508]\n",
      "  [0.77170992]\n",
      "  [0.77432108]\n",
      "  [0.7764926 ]\n",
      "  [0.77885121]\n",
      "  [0.78185761]\n",
      "  [0.78542531]\n",
      "  [0.78891486]]]\n",
      "ejemplar: [0.76941508 0.77170992 0.77432108 0.7764926  0.77885121 0.78185761\n",
      " 0.78542531 0.78891486]\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.7928284]]\n",
      "Lr que voy a aplicar en el lote: 111 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.76941508 0.77170992 0.77432108 0.7764926  0.77885121 0.78185761\n",
      "  0.78542531 0.78891486]]\n",
      "verdaderas salidas: [0.87485471]\n",
      "PERDIDAAAA antes: 0.006728314328938723\n",
      "Predicción post entrenamiento : [[0.79471]]\n",
      "PERDIDAAAA despues: 0.006423173472285271\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "[[[0.77170992]\n",
      "  [0.77432108]\n",
      "  [0.7764926 ]\n",
      "  [0.77885121]\n",
      "  [0.78185761]\n",
      "  [0.78542531]\n",
      "  [0.78891486]\n",
      "  [0.79282838]]]\n",
      "ejemplar: [0.77170992 0.77432108 0.7764926  0.77885121 0.78185761 0.78542531\n",
      " 0.78891486 0.79282838]\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.79560226]]\n",
      "Lr que voy a aplicar en el lote: 112 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.77170992 0.77432108 0.7764926  0.77885121 0.78185761 0.78542531\n",
      "  0.78891486 0.79282838]]\n",
      "verdaderas salidas: [0.91321193]\n",
      "PERDIDAAAA antes: 0.013832036405801773\n",
      "Predicción post entrenamiento : [[0.79753697]]\n",
      "PERDIDAAAA despues: 0.01338069885969162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "[[[0.77432108]\n",
      "  [0.7764926 ]\n",
      "  [0.77885121]\n",
      "  [0.78185761]\n",
      "  [0.78542531]\n",
      "  [0.78891486]\n",
      "  [0.79282838]\n",
      "  [0.79560226]]]\n",
      "ejemplar: [0.77432108 0.7764926  0.77885121 0.78185761 0.78542531 0.78891486\n",
      " 0.79282838 0.79560226]\n",
      "y: 1.0\n",
      "Predicción : [[0.79848546]]\n",
      "Lr que voy a aplicar en el lote: 113 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.77432108 0.7764926  0.77885121 0.78185761 0.78542531 0.78891486\n",
      "  0.79282838 0.79560226]]\n",
      "verdaderas salidas: [1.]\n",
      "PERDIDAAAA antes: 0.04060811176896095\n",
      "Predicción post entrenamiento : [[0.80191904]]\n",
      "PERDIDAAAA despues: 0.03923606500029564\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "[[[0.7764926 ]\n",
      "  [0.77885121]\n",
      "  [0.78185761]\n",
      "  [0.78542531]\n",
      "  [0.78891486]\n",
      "  [0.79282838]\n",
      "  [0.79560226]\n",
      "  [0.79848546]]]\n",
      "ejemplar: [0.7764926  0.77885121 0.78185761 0.78542531 0.78891486 0.79282838\n",
      " 0.79560226 0.79848546]\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.80290616]]\n",
      "Lr que voy a aplicar en el lote: 114 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.7764926  0.77885121 0.78185761 0.78542531 0.78891486 0.79282838\n",
      "  0.79560226 0.79848546]]\n",
      "verdaderas salidas: [0.97055405]\n",
      "PERDIDAAAA antes: 0.02810581773519516\n",
      "Predicción post entrenamiento : [[0.8075995]]\n",
      "PERDIDAAAA despues: 0.02655419148504734\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "[[[0.77885121]\n",
      "  [0.78185761]\n",
      "  [0.78542531]\n",
      "  [0.78891486]\n",
      "  [0.79282838]\n",
      "  [0.79560226]\n",
      "  [0.79848546]\n",
      "  [0.80290616]]]\n",
      "ejemplar: [0.77885121 0.78185761 0.78542531 0.78891486 0.79282838 0.79560226\n",
      " 0.79848546 0.80290616]\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.8086978]]\n",
      "Lr que voy a aplicar en el lote: 115 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.77885121 0.78185761 0.78542531 0.78891486 0.79282838 0.79560226\n",
      "  0.79848546 0.80290616]]\n",
      "verdaderas salidas: [0.88880279]\n",
      "PERDIDAAAA antes: 0.0064168027602136135\n",
      "Predicción post entrenamiento : [[0.8135766]]\n",
      "PERDIDAAAA despues: 0.005658979527652264\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "[[[0.78185761]\n",
      "  [0.78542531]\n",
      "  [0.78891486]\n",
      "  [0.79282838]\n",
      "  [0.79560226]\n",
      "  [0.79848546]\n",
      "  [0.80290616]\n",
      "  [0.80869782]]]\n",
      "ejemplar: [0.78185761 0.78542531 0.78891486 0.79282838 0.79560226 0.79848546\n",
      " 0.80290616 0.80869782]\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.81479645]]\n",
      "Lr que voy a aplicar en el lote: 116 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.78185761 0.78542531 0.78891486 0.79282838 0.79560226 0.79848546\n",
      "  0.80290616 0.80869782]]\n",
      "verdaderas salidas: [0.87795428]\n",
      "PERDIDAAAA antes: 0.003988914657384157\n",
      "Predicción post entrenamiento : [[0.81977355]]\n",
      "PERDIDAAAA despues: 0.0033849996980279684\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "[[[0.78542531]\n",
      "  [0.78891486]\n",
      "  [0.79282838]\n",
      "  [0.79560226]\n",
      "  [0.79848546]\n",
      "  [0.80290616]\n",
      "  [0.80869782]\n",
      "  [0.81479645]]]\n",
      "ejemplar: [0.78542531 0.78891486 0.79282838 0.79560226 0.79848546 0.80290616\n",
      " 0.80869782 0.81479645]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.8210717]]\n",
      "Lr que voy a aplicar en el lote: 117 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.78542531 0.78891486 0.79282838 0.79560226 0.79848546 0.80290616\n",
      "  0.80869782 0.81479645]]\n",
      "verdaderas salidas: [0.84889578]\n",
      "PERDIDAAAA antes: 0.0007741807494312525\n",
      "Predicción post entrenamiento : [[0.82542837]]\n",
      "PERDIDAAAA despues: 0.0005507198511622846\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "[[[0.78891486]\n",
      "  [0.79282838]\n",
      "  [0.79560226]\n",
      "  [0.79848546]\n",
      "  [0.80290616]\n",
      "  [0.80869782]\n",
      "  [0.81479645]\n",
      "  [0.82107168]]]\n",
      "ejemplar: [0.78891486 0.79282838 0.79560226 0.79848546 0.80290616 0.80869782\n",
      " 0.81479645 0.82107168]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.82676715]]\n",
      "Lr que voy a aplicar en el lote: 118 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.78891486 0.79282838 0.79560226 0.79848546 0.80290616 0.80869782\n",
      "  0.81479645 0.82107168]]\n",
      "verdaderas salidas: [0.8341728]\n",
      "PERDIDAAAA antes: 5.484348366735503e-05\n",
      "Predicción post entrenamiento : [[0.8310279]]\n",
      "PERDIDAAAA despues: 9.890146429825108e-06\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "[[[0.79282838]\n",
      "  [0.79560226]\n",
      "  [0.79848546]\n",
      "  [0.80290616]\n",
      "  [0.80869782]\n",
      "  [0.81479645]\n",
      "  [0.82107168]\n",
      "  [0.82676715]]]\n",
      "ejemplar: [0.79282838 0.79560226 0.79848546 0.80290616 0.80869782 0.81479645\n",
      " 0.82107168 0.82676715]\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.8324492]]\n",
      "Lr que voy a aplicar en el lote: 119 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.79282838 0.79560226 0.79848546 0.80290616 0.80869782 0.81479645\n",
      "  0.82107168 0.82676715]]\n",
      "verdaderas salidas: [0.85509492]\n",
      "PERDIDAAAA antes: 0.0005128282937221229\n",
      "Predicción post entrenamiento : [[0.8358328]]\n",
      "PERDIDAAAA despues: 0.00037102983333170414\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "[[[0.79560226]\n",
      "  [0.79848546]\n",
      "  [0.80290616]\n",
      "  [0.80869782]\n",
      "  [0.81479645]\n",
      "  [0.82107168]\n",
      "  [0.82676715]\n",
      "  [0.8324492 ]]]\n",
      "ejemplar: [0.79560226 0.79848546 0.80290616 0.80869782 0.81479645 0.82107168\n",
      " 0.82676715 0.8324492 ]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.8373227]]\n",
      "Lr que voy a aplicar en el lote: 120 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.79560226 0.79848546 0.80290616 0.80869782 0.81479645 0.82107168\n",
      "  0.82676715 0.8324492 ]]\n",
      "verdaderas salidas: [0.87524215]\n",
      "PERDIDAAAA antes: 0.0014378855703398585\n",
      "Predicción post entrenamiento : [[0.84069836]]\n",
      "PERDIDAAAA despues: 0.0011932749766856432\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "[[[0.79848546]\n",
      "  [0.80290616]\n",
      "  [0.80869782]\n",
      "  [0.81479645]\n",
      "  [0.82107168]\n",
      "  [0.82676715]\n",
      "  [0.8324492 ]\n",
      "  [0.83732271]]]\n",
      "ejemplar: [0.79848546 0.80290616 0.80869782 0.81479645 0.82107168 0.82676715\n",
      " 0.8324492  0.83732271]\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.8424415]]\n",
      "Lr que voy a aplicar en el lote: 121 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.79848546 0.80290616 0.80869782 0.81479645 0.82107168 0.82676715\n",
      "  0.8324492  0.83732271]]\n",
      "verdaderas salidas: [0.85703216]\n",
      "PERDIDAAAA antes: 0.00021288795687723905\n",
      "Predicción post entrenamiento : [[0.84553677]]\n",
      "PERDIDAAAA despues: 0.00013214448699727654\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "[[[0.80290616]\n",
      "  [0.80869782]\n",
      "  [0.81479645]\n",
      "  [0.82107168]\n",
      "  [0.82676715]\n",
      "  [0.8324492 ]\n",
      "  [0.83732271]\n",
      "  [0.8424415 ]]]\n",
      "ejemplar: [0.80290616 0.80869782 0.81479645 0.82107168 0.82676715 0.8324492\n",
      " 0.83732271 0.8424415 ]\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.84758085]]\n",
      "Lr que voy a aplicar en el lote: 122 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.80290616 0.80869782 0.81479645 0.82107168 0.82676715 0.8324492\n",
      "  0.83732271 0.8424415 ]]\n",
      "verdaderas salidas: [0.85005812]\n",
      "PERDIDAAAA antes: 6.136956926638959e-06\n",
      "Predicción post entrenamiento : [[0.85140145]]\n",
      "PERDIDAAAA despues: 1.8044814851236879e-06\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "[[[0.80869782]\n",
      "  [0.81479645]\n",
      "  [0.82107168]\n",
      "  [0.82676715]\n",
      "  [0.8324492 ]\n",
      "  [0.83732271]\n",
      "  [0.8424415 ]\n",
      "  [0.84758085]]]\n",
      "ejemplar: [0.80869782 0.81479645 0.82107168 0.82676715 0.8324492  0.83732271\n",
      " 0.8424415  0.84758085]\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.85360414]]\n",
      "Lr que voy a aplicar en el lote: 123 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.80869782 0.81479645 0.82107168 0.82676715 0.8324492  0.83732271\n",
      "  0.8424415  0.84758085]]\n",
      "verdaderas salidas: [0.84269663]\n",
      "PERDIDAAAA antes: 0.00011897422518813983\n",
      "Predicción post entrenamiento : [[0.8576765]]\n",
      "PERDIDAAAA despues: 0.0002243973722215742\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "[[[0.81479645]\n",
      "  [0.82107168]\n",
      "  [0.82676715]\n",
      "  [0.8324492 ]\n",
      "  [0.83732271]\n",
      "  [0.8424415 ]\n",
      "  [0.84758085]\n",
      "  [0.85360414]]]\n",
      "ejemplar: [0.81479645 0.82107168 0.82676715 0.8324492  0.83732271 0.8424415\n",
      " 0.84758085 0.85360414]\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.8598808]]\n",
      "Lr que voy a aplicar en el lote: 124 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.81479645 0.82107168 0.82676715 0.8324492  0.83732271 0.8424415\n",
      "  0.84758085 0.85360414]]\n",
      "verdaderas salidas: [0.82293685]\n",
      "PERDIDAAAA antes: 0.001364857074804604\n",
      "Predicción post entrenamiento : [[0.8635801]]\n",
      "PERDIDAAAA despues: 0.0016518757911399007\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "[[[0.82107168]\n",
      "  [0.82676715]\n",
      "  [0.8324492 ]\n",
      "  [0.83732271]\n",
      "  [0.8424415 ]\n",
      "  [0.84758085]\n",
      "  [0.85360414]\n",
      "  [0.85988081]]]\n",
      "ejemplar: [0.82107168 0.82676715 0.8324492  0.83732271 0.8424415  0.84758085\n",
      " 0.85360414 0.85988081]\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.86573744]]\n",
      "Lr que voy a aplicar en el lote: 125 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.82107168 0.82676715 0.8324492  0.83732271 0.8424415  0.84758085\n",
      "  0.85360414 0.85988081]]\n",
      "verdaderas salidas: [0.77450601]\n",
      "PERDIDAAAA antes: 0.008323169313371181\n",
      "Predicción post entrenamiento : [[0.86885065]]\n",
      "PERDIDAAAA despues: 0.008900906890630722\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "[[[0.82676715]\n",
      "  [0.8324492 ]\n",
      "  [0.83732271]\n",
      "  [0.8424415 ]\n",
      "  [0.84758085]\n",
      "  [0.85360414]\n",
      "  [0.85988081]\n",
      "  [0.86573744]]]\n",
      "ejemplar: [0.82676715 0.8324492  0.83732271 0.8424415  0.84758085 0.85360414\n",
      " 0.85988081 0.86573744]\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.87092376]]\n",
      "Lr que voy a aplicar en el lote: 126 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.82676715 0.8324492  0.83732271 0.8424415  0.84758085 0.85360414\n",
      "  0.85988081 0.86573744]]\n",
      "verdaderas salidas: [0.78419217]\n",
      "PERDIDAAAA antes: 0.007522372528910637\n",
      "Predicción post entrenamiento : [[0.8732221]]\n",
      "PERDIDAAAA despues: 0.00792633555829525\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "[[[0.8324492 ]\n",
      "  [0.83732271]\n",
      "  [0.8424415 ]\n",
      "  [0.84758085]\n",
      "  [0.85360414]\n",
      "  [0.85988081]\n",
      "  [0.86573744]\n",
      "  [0.87092376]]]\n",
      "ejemplar: [0.8324492  0.83732271 0.8424415  0.84758085 0.85360414 0.85988081\n",
      " 0.86573744 0.87092376]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.8752711]]\n",
      "Lr que voy a aplicar en el lote: 127 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.8324492  0.83732271 0.8424415  0.84758085 0.85360414 0.85988081\n",
      "  0.86573744 0.87092376]]\n",
      "verdaderas salidas: [0.85974429]\n",
      "PERDIDAAAA antes: 0.0002410806337138638\n",
      "Predicción post entrenamiento : [[0.87713045]]\n",
      "PERDIDAAAA despues: 0.0003022777964361012\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "[[[0.83732271]\n",
      "  [0.8424415 ]\n",
      "  [0.84758085]\n",
      "  [0.85360414]\n",
      "  [0.85988081]\n",
      "  [0.86573744]\n",
      "  [0.87092376]\n",
      "  [0.87527108]]]\n",
      "ejemplar: [0.83732271 0.8424415  0.84758085 0.85360414 0.85988081 0.86573744\n",
      " 0.87092376 0.87527108]\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.87915194]]\n",
      "Lr que voy a aplicar en el lote: 128 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.83732271 0.8424415  0.84758085 0.85360414 0.85988081 0.86573744\n",
      "  0.87092376 0.87527108]]\n",
      "verdaderas salidas: [0.85432003]\n",
      "PERDIDAAAA antes: 0.0006166227976791561\n",
      "Predicción post entrenamiento : [[0.8806287]]\n",
      "PERDIDAAAA despues: 0.0006921453750692308\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "[[[0.8424415 ]\n",
      "  [0.84758085]\n",
      "  [0.85360414]\n",
      "  [0.85988081]\n",
      "  [0.86573744]\n",
      "  [0.87092376]\n",
      "  [0.87527108]\n",
      "  [0.87915194]]]\n",
      "ejemplar: [0.8424415  0.84758085 0.85360414 0.85988081 0.86573744 0.87092376\n",
      " 0.87527108 0.87915194]\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.88272125]]\n",
      "Lr que voy a aplicar en el lote: 129 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.8424415  0.84758085 0.85360414 0.85988081 0.86573744 0.87092376\n",
      "  0.87527108 0.87915194]]\n",
      "verdaderas salidas: [0.83688493]\n",
      "PERDIDAAAA antes: 0.002100969199091196\n",
      "Predicción post entrenamiento : [[0.8841039]]\n",
      "PERDIDAAAA despues: 0.0022296318784356117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "[[[0.84758085]\n",
      "  [0.85360414]\n",
      "  [0.85988081]\n",
      "  [0.86573744]\n",
      "  [0.87092376]\n",
      "  [0.87527108]\n",
      "  [0.87915194]\n",
      "  [0.88272125]]]\n",
      "ejemplar: [0.84758085 0.85360414 0.85988081 0.86573744 0.87092376 0.87527108\n",
      " 0.87915194 0.88272125]\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.8862361]]\n",
      "Lr que voy a aplicar en el lote: 130 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.84758085 0.85360414 0.85988081 0.86573744 0.87092376 0.87527108\n",
      "  0.87915194 0.88272125]]\n",
      "verdaderas salidas: [0.82991089]\n",
      "PERDIDAAAA antes: 0.003172527765855193\n",
      "Predicción post entrenamiento : [[0.8860657]]\n",
      "PERDIDAAAA despues: 0.003153366968035698\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "[[[0.85360414]\n",
      "  [0.85988081]\n",
      "  [0.86573744]\n",
      "  [0.87092376]\n",
      "  [0.87527108]\n",
      "  [0.87915194]\n",
      "  [0.88272125]\n",
      "  [0.88623607]]]\n",
      "ejemplar: [0.85360414 0.85988081 0.86573744 0.87092376 0.87527108 0.87915194\n",
      " 0.88272125 0.88623607]\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.8882176]]\n",
      "Lr que voy a aplicar en el lote: 131 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.85360414 0.85988081 0.86573744 0.87092376 0.87527108 0.87915194\n",
      "  0.88272125 0.88623607]]\n",
      "verdaderas salidas: [0.887253]\n",
      "PERDIDAAAA antes: 9.305333605880151e-07\n",
      "Predicción post entrenamiento : [[0.88879603]]\n",
      "PERDIDAAAA despues: 2.3809880076441914e-06\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "[[[0.85988081]\n",
      "  [0.86573744]\n",
      "  [0.87092376]\n",
      "  [0.87527108]\n",
      "  [0.87915194]\n",
      "  [0.88272125]\n",
      "  [0.88623607]\n",
      "  [0.88821763]]]\n",
      "ejemplar: [0.85988081 0.86573744 0.87092376 0.87527108 0.87915194 0.88272125\n",
      " 0.88623607 0.88821763]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.89082557]]\n",
      "Lr que voy a aplicar en el lote: 132 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.85988081 0.86573744 0.87092376 0.87527108 0.87915194 0.88272125\n",
      "  0.88623607 0.88821763]]\n",
      "verdaderas salidas: [0.85974429]\n",
      "PERDIDAAAA antes: 0.000966044666711241\n",
      "Predicción post entrenamiento : [[0.8914774]]\n",
      "PERDIDAAAA despues: 0.0010069893905892968\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "[[[0.86573744]\n",
      "  [0.87092376]\n",
      "  [0.87527108]\n",
      "  [0.87915194]\n",
      "  [0.88272125]\n",
      "  [0.88623607]\n",
      "  [0.88821763]\n",
      "  [0.89082557]]]\n",
      "ejemplar: [0.86573744 0.87092376 0.87527108 0.87915194 0.88272125 0.88623607\n",
      " 0.88821763 0.89082557]\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.8932961]]\n",
      "Lr que voy a aplicar en el lote: 133 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.86573744 0.87092376 0.87527108 0.87915194 0.88272125 0.88623607\n",
      "  0.88821763 0.89082557]]\n",
      "verdaderas salidas: [0.83959706]\n",
      "PERDIDAAAA antes: 0.0028835907578468323\n",
      "Predicción post entrenamiento : [[0.89327633]]\n",
      "PERDIDAAAA despues: 0.002881465945392847\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "[[[0.87092376]\n",
      "  [0.87527108]\n",
      "  [0.87915194]\n",
      "  [0.88272125]\n",
      "  [0.88623607]\n",
      "  [0.88821763]\n",
      "  [0.89082557]\n",
      "  [0.89329612]]]\n",
      "ejemplar: [0.87092376 0.87527108 0.87915194 0.88272125 0.88623607 0.88821763\n",
      " 0.89082557 0.89329612]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.89486986]]\n",
      "Lr que voy a aplicar en el lote: 134 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.87092376 0.87527108 0.87915194 0.88272125 0.88623607 0.88821763\n",
      "  0.89082557 0.89329612]]\n",
      "verdaderas salidas: [0.78380473]\n",
      "PERDIDAAAA antes: 0.012335467152297497\n",
      "Predicción post entrenamiento : [[0.89294815]]\n",
      "PERDIDAAAA despues: 0.011912290006875992\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "[[[0.87527108]\n",
      "  [0.87915194]\n",
      "  [0.88272125]\n",
      "  [0.88623607]\n",
      "  [0.88821763]\n",
      "  [0.89082557]\n",
      "  [0.89329612]\n",
      "  [0.89486986]]]\n",
      "ejemplar: [0.87527108 0.87915194 0.88272125 0.88623607 0.88821763 0.89082557\n",
      " 0.89329612 0.89486986]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.89433503]]\n",
      "Lr que voy a aplicar en el lote: 135 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.87527108 0.87915194 0.88272125 0.88623607 0.88821763 0.89082557\n",
      "  0.89329612 0.89486986]]\n",
      "verdaderas salidas: [0.81828749]\n",
      "PERDIDAAAA antes: 0.005783228203654289\n",
      "Predicción post entrenamiento : [[0.89276063]]\n",
      "PERDIDAAAA despues: 0.005546248983591795\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "[[[0.87915194]\n",
      "  [0.88272125]\n",
      "  [0.88623607]\n",
      "  [0.88821763]\n",
      "  [0.89082557]\n",
      "  [0.89329612]\n",
      "  [0.89486986]\n",
      "  [0.89433503]]]\n",
      "ejemplar: [0.87915194 0.88272125 0.88623607 0.88821763 0.89082557 0.89329612\n",
      " 0.89486986 0.89433503]\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.89398974]]\n",
      "Lr que voy a aplicar en el lote: 136 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.87915194 0.88272125 0.88623607 0.88821763 0.89082557 0.89329612\n",
      "  0.89486986 0.89433503]]\n",
      "verdaderas salidas: [0.79116621]\n",
      "PERDIDAAAA antes: 0.010572683997452259\n",
      "Predicción post entrenamiento : [[0.89255214]]\n",
      "PERDIDAAAA despues: 0.010279110632836819\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "[[[0.88272125]\n",
      "  [0.88623607]\n",
      "  [0.88821763]\n",
      "  [0.89082557]\n",
      "  [0.89329612]\n",
      "  [0.89486986]\n",
      "  [0.89433503]\n",
      "  [0.89398974]]]\n",
      "ejemplar: [0.88272125 0.88623607 0.88821763 0.89082557 0.89329612 0.89486986\n",
      " 0.89433503 0.89398974]\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.8936269]]\n",
      "Lr que voy a aplicar en el lote: 137 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.88272125 0.88623607 0.88821763 0.89082557 0.89329612 0.89486986\n",
      "  0.89433503 0.89398974]]\n",
      "verdaderas salidas: [0.76055792]\n",
      "PERDIDAAAA antes: 0.017707353457808495\n",
      "Predicción post entrenamiento : [[0.89220965]]\n",
      "PERDIDAAAA despues: 0.01733217015862465\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "[[[0.88623607]\n",
      "  [0.88821763]\n",
      "  [0.89082557]\n",
      "  [0.89329612]\n",
      "  [0.89486986]\n",
      "  [0.89433503]\n",
      "  [0.89398974]\n",
      "  [0.89362693]]]\n",
      "ejemplar: [0.88623607 0.88821763 0.89082557 0.89329612 0.89486986 0.89433503\n",
      " 0.89398974 0.89362693]\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.8931099]]\n",
      "Lr que voy a aplicar en el lote: 138 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.88623607 0.88821763 0.89082557 0.89329612 0.89486986 0.89433503\n",
      "  0.89398974 0.89362693]]\n",
      "verdaderas salidas: [0.79155366]\n",
      "PERDIDAAAA antes: 0.01031367015093565\n",
      "Predicción post entrenamiento : [[0.89179003]]\n",
      "PERDIDAAAA despues: 0.010047326795756817\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "[[[0.88821763]\n",
      "  [0.89082557]\n",
      "  [0.89329612]\n",
      "  [0.89486986]\n",
      "  [0.89433503]\n",
      "  [0.89398974]\n",
      "  [0.89362693]\n",
      "  [0.89310992]]]\n",
      "ejemplar: [0.88821763 0.89082557 0.89329612 0.89486986 0.89433503 0.89398974\n",
      " 0.89362693 0.89310992]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.8924583]]\n",
      "Lr que voy a aplicar en el lote: 139 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.88821763 0.89082557 0.89329612 0.89486986 0.89433503 0.89398974\n",
      "  0.89362693 0.89310992]]\n",
      "verdaderas salidas: [0.7686943]\n",
      "PERDIDAAAA antes: 0.015317536890506744\n",
      "Predicción post entrenamiento : [[0.8914041]]\n",
      "PERDIDAAAA despues: 0.015057697892189026\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "[[[0.89082557]\n",
      "  [0.89329612]\n",
      "  [0.89486986]\n",
      "  [0.89433503]\n",
      "  [0.89398974]\n",
      "  [0.89362693]\n",
      "  [0.89310992]\n",
      "  [0.89245832]]]\n",
      "ejemplar: [0.89082557 0.89329612 0.89486986 0.89433503 0.89398974 0.89362693\n",
      " 0.89310992 0.89245832]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.89196986]]\n",
      "Lr que voy a aplicar en el lote: 140 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.89082557 0.89329612 0.89486986 0.89433503 0.89398974 0.89362693\n",
      "  0.89310992 0.89245832]]\n",
      "verdaderas salidas: [0.7686943]\n",
      "PERDIDAAAA antes: 0.01519686821848154\n",
      "Predicción post entrenamiento : [[0.88949317]]\n",
      "PERDIDAAAA despues: 0.014592370949685574\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "[[[0.89329612]\n",
      "  [0.89486986]\n",
      "  [0.89433503]\n",
      "  [0.89398974]\n",
      "  [0.89362693]\n",
      "  [0.89310992]\n",
      "  [0.89245832]\n",
      "  [0.89196986]]]\n",
      "ejemplar: [0.89329612 0.89486986 0.89433503 0.89398974 0.89362693 0.89310992\n",
      " 0.89245832 0.89196986]\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.8898248]]\n",
      "Lr que voy a aplicar en el lote: 141 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.89329612 0.89486986 0.89433503 0.89398974 0.89362693 0.89310992\n",
      "  0.89245832 0.89196986]]\n",
      "verdaderas salidas: [0.79891515]\n",
      "PERDIDAAAA antes: 0.008264565840363503\n",
      "Predicción post entrenamiento : [[0.88609964]]\n",
      "PERDIDAAAA despues: 0.007601134944707155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "[[[0.89486986]\n",
      "  [0.89433503]\n",
      "  [0.89398974]\n",
      "  [0.89362693]\n",
      "  [0.89310992]\n",
      "  [0.89245832]\n",
      "  [0.89196986]\n",
      "  [0.88982481]]]\n",
      "ejemplar: [0.89486986 0.89433503 0.89398974 0.89362693 0.89310992 0.89245832\n",
      " 0.89196986 0.88982481]\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.88614786]]\n",
      "Lr que voy a aplicar en el lote: 142 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.89486986 0.89433503 0.89398974 0.89362693 0.89310992 0.89245832\n",
      "  0.89196986 0.88982481]]\n",
      "verdaderas salidas: [0.79000387]\n",
      "PERDIDAAAA antes: 0.009243661537766457\n",
      "Predicción post entrenamiento : [[0.8805731]]\n",
      "PERDIDAAAA despues: 0.008202780038118362\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "[[[0.89433503]\n",
      "  [0.89398974]\n",
      "  [0.89362693]\n",
      "  [0.89310992]\n",
      "  [0.89245832]\n",
      "  [0.89196986]\n",
      "  [0.88982481]\n",
      "  [0.88614786]]]\n",
      "ejemplar: [0.89433503 0.89398974 0.89362693 0.89310992 0.89245832 0.89196986\n",
      " 0.88982481 0.88614786]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.8803822]]\n",
      "Lr que voy a aplicar en el lote: 143 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.89433503 0.89398974 0.89362693 0.89310992 0.89245832 0.89196986\n",
      "  0.88982481 0.88614786]]\n",
      "verdaderas salidas: [0.76017048]\n",
      "PERDIDAAAA antes: 0.014450857415795326\n",
      "Predicción post entrenamiento : [[0.874792]]\n",
      "PERDIDAAAA despues: 0.013138093054294586\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "[[[0.89398974]\n",
      "  [0.89362693]\n",
      "  [0.89310992]\n",
      "  [0.89245832]\n",
      "  [0.89196986]\n",
      "  [0.88982481]\n",
      "  [0.88614786]\n",
      "  [0.88038218]]]\n",
      "ejemplar: [0.89398974 0.89362693 0.89310992 0.89245832 0.89196986 0.88982481\n",
      " 0.88614786 0.88038218]\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.8745639]]\n",
      "Lr que voy a aplicar en el lote: 144 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.89398974 0.89362693 0.89310992 0.89245832 0.89196986 0.88982481\n",
      "  0.88614786 0.88038218]]\n",
      "verdaderas salidas: [0.68539326]\n",
      "PERDIDAAAA antes: 0.03578551486134529\n",
      "Predicción post entrenamiento : [[0.8664825]]\n",
      "PERDIDAAAA despues: 0.032793305814266205\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "[[[0.89362693]\n",
      "  [0.89310992]\n",
      "  [0.89245832]\n",
      "  [0.89196986]\n",
      "  [0.88982481]\n",
      "  [0.88614786]\n",
      "  [0.88038218]\n",
      "  [0.87456387]]]\n",
      "ejemplar: [0.89362693 0.89310992 0.89245832 0.89196986 0.88982481 0.88614786\n",
      " 0.88038218 0.87456387]\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.86614764]]\n",
      "Lr que voy a aplicar en el lote: 145 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.89362693 0.89310992 0.89245832 0.89196986 0.88982481 0.88614786\n",
      "  0.88038218 0.87456387]]\n",
      "verdaderas salidas: [0.60519179]\n",
      "PERDIDAAAA antes: 0.06809796392917633\n",
      "Predicción post entrenamiento : [[0.8567665]]\n",
      "PERDIDAAAA despues: 0.06328985840082169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "[[[0.89310992]\n",
      "  [0.89245832]\n",
      "  [0.89196986]\n",
      "  [0.88982481]\n",
      "  [0.88614786]\n",
      "  [0.88038218]\n",
      "  [0.87456387]\n",
      "  [0.86614764]]]\n",
      "ejemplar: [0.89310992 0.89245832 0.89196986 0.88982481 0.88614786 0.88038218\n",
      " 0.87456387 0.86614764]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.8562555]]\n",
      "Lr que voy a aplicar en el lote: 146 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.89310992 0.89245832 0.89196986 0.88982481 0.88614786 0.88038218\n",
      "  0.87456387 0.86614764]]\n",
      "verdaderas salidas: [0.66485858]\n",
      "PERDIDAAAA antes: 0.03663276880979538\n",
      "Predicción post entrenamiento : [[0.8436018]]\n",
      "PERDIDAAAA despues: 0.03194914758205414\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "[[[0.89245832]\n",
      "  [0.89196986]\n",
      "  [0.88982481]\n",
      "  [0.88614786]\n",
      "  [0.88038218]\n",
      "  [0.87456387]\n",
      "  [0.86614764]\n",
      "  [0.85625547]]]\n",
      "ejemplar: [0.89245832 0.89196986 0.88982481 0.88614786 0.88038218 0.87456387\n",
      " 0.86614764 0.85625547]\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.8428406]]\n",
      "Lr que voy a aplicar en el lote: 147 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.89245832 0.89196986 0.88982481 0.88614786 0.88038218 0.87456387\n",
      "  0.86614764 0.85625547]]\n",
      "verdaderas salidas: [0.70786517]\n",
      "PERDIDAAAA antes: 0.01821836829185486\n",
      "Predicción post entrenamiento : [[0.8296964]]\n",
      "PERDIDAAAA despues: 0.014842850156128407\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "[[[0.89196986]\n",
      "  [0.88982481]\n",
      "  [0.88614786]\n",
      "  [0.88038218]\n",
      "  [0.87456387]\n",
      "  [0.86614764]\n",
      "  [0.85625547]\n",
      "  [0.84284061]]]\n",
      "ejemplar: [0.89196986 0.88982481 0.88614786 0.88038218 0.87456387 0.86614764\n",
      " 0.85625547 0.84284061]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.8285819]]\n",
      "Lr que voy a aplicar en el lote: 148 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.89196986 0.88982481 0.88614786 0.88038218 0.87456387 0.86614764\n",
      "  0.85625547 0.84284061]]\n",
      "verdaderas salidas: [0.66485858]\n",
      "PERDIDAAAA antes: 0.02680533565580845\n",
      "Predicción post entrenamiento : [[0.81578195]]\n",
      "PERDIDAAAA despues: 0.022777864709496498\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "[[[0.88982481]\n",
      "  [0.88614786]\n",
      "  [0.88038218]\n",
      "  [0.87456387]\n",
      "  [0.86614764]\n",
      "  [0.85625547]\n",
      "  [0.84284061]\n",
      "  [0.82858193]]]\n",
      "ejemplar: [0.88982481 0.88614786 0.88038218 0.87456387 0.86614764 0.85625547\n",
      " 0.84284061 0.82858193]\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.81415045]]\n",
      "Lr que voy a aplicar en el lote: 149 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.88982481 0.88614786 0.88038218 0.87456387 0.86614764 0.85625547\n",
      "  0.84284061 0.82858193]]\n",
      "verdaderas salidas: [0.71135219]\n",
      "PERDIDAAAA antes: 0.010567487217485905\n",
      "Predicción post entrenamiento : [[0.80309284]]\n",
      "PERDIDAAAA despues: 0.00841634999960661\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "[[[0.88614786]\n",
      "  [0.88038218]\n",
      "  [0.87456387]\n",
      "  [0.86614764]\n",
      "  [0.85625547]\n",
      "  [0.84284061]\n",
      "  [0.82858193]\n",
      "  [0.81415045]]]\n",
      "ejemplar: [0.88614786 0.88038218 0.87456387 0.86614764 0.85625547 0.84284061\n",
      " 0.82858193 0.81415045]\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.80096036]]\n",
      "Lr que voy a aplicar en el lote: 150 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.88614786 0.88038218 0.87456387 0.86614764 0.85625547 0.84284061\n",
      "  0.82858193 0.81415045]]\n",
      "verdaderas salidas: [0.67725688]\n",
      "PERDIDAAAA antes: 0.015302550978958607\n",
      "Predicción post entrenamiento : [[0.7907218]]\n",
      "PERDIDAAAA despues: 0.012874281965196133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "[[[0.88038218]\n",
      "  [0.87456387]\n",
      "  [0.86614764]\n",
      "  [0.85625547]\n",
      "  [0.84284061]\n",
      "  [0.82858193]\n",
      "  [0.81415045]\n",
      "  [0.80096036]]]\n",
      "ejemplar: [0.88038218 0.87456387 0.86614764 0.85625547 0.84284061 0.82858193\n",
      " 0.81415045 0.80096036]\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.78809696]]\n",
      "Lr que voy a aplicar en el lote: 151 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.88038218 0.87456387 0.86614764 0.85625547 0.84284061 0.82858193\n",
      "  0.81415045 0.80096036]]\n",
      "verdaderas salidas: [0.76210771]\n",
      "PERDIDAAAA antes: 0.0006754403002560139\n",
      "Predicción post entrenamiento : [[0.7790374]]\n",
      "PERDIDAAAA despues: 0.0002866142604034394\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "[[[0.87456387]\n",
      "  [0.86614764]\n",
      "  [0.85625547]\n",
      "  [0.84284061]\n",
      "  [0.82858193]\n",
      "  [0.81415045]\n",
      "  [0.80096036]\n",
      "  [0.78809696]]]\n",
      "ejemplar: [0.87456387 0.86614764 0.85625547 0.84284061 0.82858193 0.81415045\n",
      " 0.80096036 0.78809696]\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.7759996]]\n",
      "Lr que voy a aplicar en el lote: 152 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.87456387 0.86614764 0.85625547 0.84284061 0.82858193 0.81415045\n",
      "  0.80096036 0.78809696]]\n",
      "verdaderas salidas: [0.80705153]\n",
      "PERDIDAAAA antes: 0.0009642225923016667\n",
      "Predicción post entrenamiento : [[0.76758045]]\n",
      "PERDIDAAAA despues: 0.0015579669270664454\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "[[[0.86614764]\n",
      "  [0.85625547]\n",
      "  [0.84284061]\n",
      "  [0.82858193]\n",
      "  [0.81415045]\n",
      "  [0.80096036]\n",
      "  [0.78809696]\n",
      "  [0.77599961]]]\n",
      "ejemplar: [0.86614764 0.85625547 0.84284061 0.82858193 0.81415045 0.80096036\n",
      " 0.78809696 0.77599961]\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.7640157]]\n",
      "Lr que voy a aplicar en el lote: 153 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.86614764 0.85625547 0.84284061 0.82858193 0.81415045 0.80096036\n",
      "  0.78809696 0.77599961]]\n",
      "verdaderas salidas: [0.81518791]\n",
      "PERDIDAAAA antes: 0.0026185999158769846\n",
      "Predicción post entrenamiento : [[0.75718147]]\n",
      "PERDIDAAAA despues: 0.003364749951288104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "[[[0.85625547]\n",
      "  [0.84284061]\n",
      "  [0.82858193]\n",
      "  [0.81415045]\n",
      "  [0.80096036]\n",
      "  [0.78809696]\n",
      "  [0.77599961]\n",
      "  [0.76401567]]]\n",
      "ejemplar: [0.85625547 0.84284061 0.82858193 0.81415045 0.80096036 0.78809696\n",
      " 0.77599961 0.76401567]\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.75324875]]\n",
      "Lr que voy a aplicar en el lote: 154 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.85625547 0.84284061 0.82858193 0.81415045 0.80096036 0.78809696\n",
      "  0.77599961 0.76401567]]\n",
      "verdaderas salidas: [0.90623789]\n",
      "PERDIDAAAA antes: 0.023405680432915688\n",
      "Predicción post entrenamiento : [[0.7483839]]\n",
      "PERDIDAAAA despues: 0.02491789124906063\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "[[[0.84284061]\n",
      "  [0.82858193]\n",
      "  [0.81415045]\n",
      "  [0.80096036]\n",
      "  [0.78809696]\n",
      "  [0.77599961]\n",
      "  [0.76401567]\n",
      "  [0.75324875]]]\n",
      "ejemplar: [0.84284061 0.82858193 0.81415045 0.80096036 0.78809696 0.77599961\n",
      " 0.76401567 0.75324875]\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.7441632]]\n",
      "Lr que voy a aplicar en el lote: 155 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.84284061 0.82858193 0.81415045 0.80096036 0.78809696 0.77599961\n",
      "  0.76401567 0.75324875]]\n",
      "verdaderas salidas: [0.95970554]\n",
      "PERDIDAAAA antes: 0.04645849019289017\n",
      "Predicción post entrenamiento : [[0.7417865]]\n",
      "PERDIDAAAA despues: 0.04748871177434921\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "[[[0.82858193]\n",
      "  [0.81415045]\n",
      "  [0.80096036]\n",
      "  [0.78809696]\n",
      "  [0.77599961]\n",
      "  [0.76401567]\n",
      "  [0.75324875]\n",
      "  [0.74416322]]]\n",
      "ejemplar: [0.82858193 0.81415045 0.80096036 0.78809696 0.77599961 0.76401567\n",
      " 0.75324875 0.74416322]\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.7376048]]\n",
      "Lr que voy a aplicar en el lote: 156 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.82858193 0.81415045 0.80096036 0.78809696 0.77599961 0.76401567\n",
      "  0.75324875 0.74416322]]\n",
      "verdaderas salidas: [0.9643549]\n",
      "PERDIDAAAA antes: 0.05141559615731239\n",
      "Predicción post entrenamiento : [[0.7367986]]\n",
      "PERDIDAAAA despues: 0.05178186297416687\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "[[[0.81415045]\n",
      "  [0.80096036]\n",
      "  [0.78809696]\n",
      "  [0.77599961]\n",
      "  [0.76401567]\n",
      "  [0.75324875]\n",
      "  [0.74416322]\n",
      "  [0.7376048 ]]]\n",
      "ejemplar: [0.81415045 0.80096036 0.78809696 0.77599961 0.76401567 0.75324875\n",
      " 0.74416322 0.7376048 ]\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.73277885]]\n",
      "Lr que voy a aplicar en el lote: 157 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.81415045 0.80096036 0.78809696 0.77599961 0.76401567 0.75324875\n",
      "  0.74416322 0.7376048 ]]\n",
      "verdaderas salidas: [0.8880279]\n",
      "PERDIDAAAA antes: 0.02410227060317993\n",
      "Predicción post entrenamiento : [[0.7330146]]\n",
      "PERDIDAAAA despues: 0.02402913011610508\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "[[[0.80096036]\n",
      "  [0.78809696]\n",
      "  [0.77599961]\n",
      "  [0.76401567]\n",
      "  [0.75324875]\n",
      "  [0.74416322]\n",
      "  [0.7376048 ]\n",
      "  [0.73277885]]]\n",
      "ejemplar: [0.80096036 0.78809696 0.77599961 0.76401567 0.75324875 0.74416322\n",
      " 0.7376048  0.73277885]\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.729249]]\n",
      "Lr que voy a aplicar en el lote: 158 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.80096036 0.78809696 0.77599961 0.76401567 0.75324875 0.74416322\n",
      "  0.7376048  0.73277885]]\n",
      "verdaderas salidas: [0.89267726]\n",
      "PERDIDAAAA antes: 0.02670879103243351\n",
      "Predicción post entrenamiento : [[0.7306698]]\n",
      "PERDIDAAAA despues: 0.026246413588523865\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "[[[0.78809696]\n",
      "  [0.77599961]\n",
      "  [0.76401567]\n",
      "  [0.75324875]\n",
      "  [0.74416322]\n",
      "  [0.7376048 ]\n",
      "  [0.73277885]\n",
      "  [0.729249  ]]]\n",
      "ejemplar: [0.78809696 0.77599961 0.76401567 0.75324875 0.74416322 0.7376048\n",
      " 0.73277885 0.729249  ]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.7271296]]\n",
      "Lr que voy a aplicar en el lote: 159 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.78809696 0.77599961 0.76401567 0.75324875 0.74416322 0.7376048\n",
      "  0.73277885 0.729249  ]]\n",
      "verdaderas salidas: [0.87524215]\n",
      "PERDIDAAAA antes: 0.02193734049797058\n",
      "Predicción post entrenamiento : [[0.7296956]]\n",
      "PERDIDAAAA despues: 0.0211837999522686\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "[[[0.77599961]\n",
      "  [0.76401567]\n",
      "  [0.75324875]\n",
      "  [0.74416322]\n",
      "  [0.7376048 ]\n",
      "  [0.73277885]\n",
      "  [0.729249  ]\n",
      "  [0.72712958]]]\n",
      "ejemplar: [0.77599961 0.76401567 0.75324875 0.74416322 0.7376048  0.73277885\n",
      " 0.729249   0.72712958]\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.726457]]\n",
      "Lr que voy a aplicar en el lote: 160 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.77599961 0.76401567 0.75324875 0.74416322 0.7376048  0.73277885\n",
      "  0.729249   0.72712958]]\n",
      "verdaderas salidas: [0.85083301]\n",
      "PERDIDAAAA antes: 0.015469389036297798\n",
      "Predicción post entrenamiento : [[0.7290075]]\n",
      "PERDIDAAAA despues: 0.014841455966234207\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "[[[0.76401567]\n",
      "  [0.75324875]\n",
      "  [0.74416322]\n",
      "  [0.7376048 ]\n",
      "  [0.73277885]\n",
      "  [0.729249  ]\n",
      "  [0.72712958]\n",
      "  [0.726457  ]]]\n",
      "ejemplar: [0.76401567 0.75324875 0.74416322 0.7376048  0.73277885 0.729249\n",
      " 0.72712958 0.726457  ]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.72613066]]\n",
      "Lr que voy a aplicar en el lote: 161 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.76401567 0.75324875 0.74416322 0.7376048  0.73277885 0.729249\n",
      "  0.72712958 0.726457  ]]\n",
      "verdaderas salidas: [0.84889578]\n",
      "PERDIDAAAA antes: 0.015071275644004345\n",
      "Predicción post entrenamiento : [[0.7293357]]\n",
      "PERDIDAAAA despues: 0.014294608496129513\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "[[[0.75324875]\n",
      "  [0.74416322]\n",
      "  [0.7376048 ]\n",
      "  [0.73277885]\n",
      "  [0.729249  ]\n",
      "  [0.72712958]\n",
      "  [0.726457  ]\n",
      "  [0.72613066]]]\n",
      "ejemplar: [0.75324875 0.74416322 0.7376048  0.73277885 0.729249   0.72712958\n",
      " 0.726457   0.72613066]\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.72696143]]\n",
      "Lr que voy a aplicar en el lote: 162 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.75324875 0.74416322 0.7376048  0.73277885 0.729249   0.72712958\n",
      "  0.726457   0.72613066]]\n",
      "verdaderas salidas: [0.96241767]\n",
      "PERDIDAAAA antes: 0.05543963611125946\n",
      "Predicción post entrenamiento : [[0.73122966]]\n",
      "PERDIDAAAA despues: 0.053447891026735306\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "[[[0.74416322]\n",
      "  [0.7376048 ]\n",
      "  [0.73277885]\n",
      "  [0.729249  ]\n",
      "  [0.72712958]\n",
      "  [0.726457  ]\n",
      "  [0.72613066]\n",
      "  [0.72696143]]]\n",
      "ejemplar: [0.74416322 0.7376048  0.73277885 0.729249   0.72712958 0.726457\n",
      " 0.72613066 0.72696143]\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.7294014]]\n",
      "Lr que voy a aplicar en el lote: 163 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.74416322 0.7376048  0.73277885 0.729249   0.72712958 0.726457\n",
      "  0.72613066 0.72696143]]\n",
      "verdaderas salidas: [0.96784192]\n",
      "PERDIDAAAA antes: 0.05685387924313545\n",
      "Predicción post entrenamiento : [[0.7348886]]\n",
      "PERDIDAAAA despues: 0.05426724627614021\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "[[[0.7376048 ]\n",
      "  [0.73277885]\n",
      "  [0.729249  ]\n",
      "  [0.72712958]\n",
      "  [0.726457  ]\n",
      "  [0.72613066]\n",
      "  [0.72696143]\n",
      "  [0.72940141]]]\n",
      "ejemplar: [0.7376048  0.73277885 0.729249   0.72712958 0.726457   0.72613066\n",
      " 0.72696143 0.72940141]\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.7336014]]\n",
      "Lr que voy a aplicar en el lote: 164 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.7376048  0.73277885 0.729249   0.72712958 0.726457   0.72613066\n",
      "  0.72696143 0.72940141]]\n",
      "verdaderas salidas: [0.94072065]\n",
      "PERDIDAAAA antes: 0.04289839789271355\n",
      "Predicción post entrenamiento : [[0.73998106]]\n",
      "PERDIDAAAA despues: 0.040296394377946854\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "[[[0.73277885]\n",
      "  [0.729249  ]\n",
      "  [0.72712958]\n",
      "  [0.726457  ]\n",
      "  [0.72613066]\n",
      "  [0.72696143]\n",
      "  [0.72940141]\n",
      "  [0.73360139]]]\n",
      "ejemplar: [0.73277885 0.729249   0.72712958 0.726457   0.72613066 0.72696143\n",
      " 0.72940141 0.73360139]\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.73913085]]\n",
      "Lr que voy a aplicar en el lote: 165 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.73277885 0.729249   0.72712958 0.726457   0.72613066 0.72696143\n",
      "  0.72940141 0.73360139]]\n",
      "verdaderas salidas: [0.97249128]\n",
      "PERDIDAAAA antes: 0.054457079619169235\n",
      "Predicción post entrenamiento : [[0.7463034]]\n",
      "PERDIDAAAA despues: 0.05116095766425133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "[[[0.729249  ]\n",
      "  [0.72712958]\n",
      "  [0.726457  ]\n",
      "  [0.72613066]\n",
      "  [0.72696143]\n",
      "  [0.72940141]\n",
      "  [0.73360139]\n",
      "  [0.73913085]]]\n",
      "ejemplar: [0.729249   0.72712958 0.726457   0.72613066 0.72696143 0.72940141\n",
      " 0.73360139 0.73913085]\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.7458521]]\n",
      "Lr que voy a aplicar en el lote: 166 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.729249   0.72712958 0.726457   0.72613066 0.72696143 0.72940141\n",
      "  0.73360139 0.73913085]]\n",
      "verdaderas salidas: [0.99690043]\n",
      "PERDIDAAAA antes: 0.06302526593208313\n",
      "Predicción post entrenamiento : [[0.7541058]]\n",
      "PERDIDAAAA despues: 0.05894923210144043\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "[[[0.72712958]\n",
      "  [0.726457  ]\n",
      "  [0.72613066]\n",
      "  [0.72696143]\n",
      "  [0.72940141]\n",
      "  [0.73360139]\n",
      "  [0.73913085]\n",
      "  [0.74585211]]]\n",
      "ejemplar: [0.72712958 0.726457   0.72613066 0.72696143 0.72940141 0.73360139\n",
      " 0.73913085 0.74585211]\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.75405794]]\n",
      "Lr que voy a aplicar en el lote: 167 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.72712958 0.726457   0.72613066 0.72696143 0.72940141 0.73360139\n",
      "  0.73913085 0.74585211]]\n",
      "verdaderas salidas: [0.95118171]\n",
      "PERDIDAAAA antes: 0.038857780396938324\n",
      "Predicción post entrenamiento : [[0.76291627]]\n",
      "PERDIDAAAA despues: 0.035443875938653946\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "[[[0.726457  ]\n",
      "  [0.72613066]\n",
      "  [0.72696143]\n",
      "  [0.72940141]\n",
      "  [0.73360139]\n",
      "  [0.73913085]\n",
      "  [0.74585211]\n",
      "  [0.75405794]]]\n",
      "ejemplar: [0.726457   0.72613066 0.72696143 0.72940141 0.73360139 0.73913085\n",
      " 0.74585211 0.75405794]\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.76326555]]\n",
      "Lr que voy a aplicar en el lote: 168 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.726457   0.72613066 0.72696143 0.72940141 0.73360139 0.73913085\n",
      "  0.74585211 0.75405794]]\n",
      "verdaderas salidas: [0.89577683]\n",
      "PERDIDAAAA antes: 0.0175592340528965\n",
      "Predicción post entrenamiento : [[0.7710202]]\n",
      "PERDIDAAAA despues: 0.015564218163490295\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "[[[0.72613066]\n",
      "  [0.72696143]\n",
      "  [0.72940141]\n",
      "  [0.73360139]\n",
      "  [0.73913085]\n",
      "  [0.74585211]\n",
      "  [0.75405794]\n",
      "  [0.76326555]]]\n",
      "ejemplar: [0.72613066 0.72696143 0.72940141 0.73360139 0.73913085 0.74585211\n",
      " 0.75405794 0.76326555]\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.7717531]]\n",
      "Lr que voy a aplicar en el lote: 169 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.72613066 0.72696143 0.72940141 0.73360139 0.73913085 0.74585211\n",
      "  0.75405794 0.76326555]]\n",
      "verdaderas salidas: [0.8814413]\n",
      "PERDIDAAAA antes: 0.012031505815684795\n",
      "Predicción post entrenamiento : [[0.77937263]]\n",
      "PERDIDAAAA despues: 0.01041801180690527\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "[[[0.72696143]\n",
      "  [0.72940141]\n",
      "  [0.73360139]\n",
      "  [0.73913085]\n",
      "  [0.74585211]\n",
      "  [0.75405794]\n",
      "  [0.76326555]\n",
      "  [0.77175307]]]\n",
      "ejemplar: [0.72696143 0.72940141 0.73360139 0.73913085 0.74585211 0.75405794\n",
      " 0.76326555 0.77175307]\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.7806007]]\n",
      "Lr que voy a aplicar en el lote: 170 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.72696143 0.72940141 0.73360139 0.73913085 0.74585211 0.75405794\n",
      "  0.76326555 0.77175307]]\n",
      "verdaderas salidas: [0.9170864]\n",
      "PERDIDAAAA antes: 0.018628345802426338\n",
      "Predicción post entrenamiento : [[0.7883483]]\n",
      "PERDIDAAAA despues: 0.016573499888181686\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "[[[0.72940141]\n",
      "  [0.73360139]\n",
      "  [0.73913085]\n",
      "  [0.74585211]\n",
      "  [0.75405794]\n",
      "  [0.76326555]\n",
      "  [0.77175307]\n",
      "  [0.78060073]]]\n",
      "ejemplar: [0.72940141 0.73360139 0.73913085 0.74585211 0.75405794 0.76326555\n",
      " 0.77175307 0.78060073]\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.7900981]]\n",
      "Lr que voy a aplicar en el lote: 171 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.72940141 0.73360139 0.73913085 0.74585211 0.75405794 0.76326555\n",
      "  0.77175307 0.78060073]]\n",
      "verdaderas salidas: [0.91979853]\n",
      "PERDIDAAAA antes: 0.016822215169668198\n",
      "Predicción post entrenamiento : [[0.7985844]]\n",
      "PERDIDAAAA despues: 0.014692870900034904\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "[[[0.73360139]\n",
      "  [0.73913085]\n",
      "  [0.74585211]\n",
      "  [0.75405794]\n",
      "  [0.76326555]\n",
      "  [0.77175307]\n",
      "  [0.78060073]\n",
      "  [0.79009807]]]\n",
      "ejemplar: [0.73360139 0.73913085 0.74585211 0.75405794 0.76326555 0.77175307\n",
      " 0.78060073 0.79009807]\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.80081856]]\n",
      "Lr que voy a aplicar en el lote: 172 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.73360139 0.73913085 0.74585211 0.75405794 0.76326555 0.77175307\n",
      "  0.78060073 0.79009807]]\n",
      "verdaderas salidas: [0.96164277]\n",
      "PERDIDAAAA antes: 0.025864435359835625\n",
      "Predicción post entrenamiento : [[0.8097021]]\n",
      "PERDIDAAAA despues: 0.023085977882146835\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "[[[0.73913085]\n",
      "  [0.74585211]\n",
      "  [0.75405794]\n",
      "  [0.76326555]\n",
      "  [0.77175307]\n",
      "  [0.78060073]\n",
      "  [0.79009807]\n",
      "  [0.80081856]]]\n",
      "ejemplar: [0.73913085 0.74585211 0.75405794 0.76326555 0.77175307 0.78060073\n",
      " 0.79009807 0.80081856]\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.81234306]]\n",
      "Lr que voy a aplicar en el lote: 173 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.73913085 0.74585211 0.75405794 0.76326555 0.77175307 0.78060073\n",
      "  0.79009807 0.80081856]]\n",
      "verdaderas salidas: [0.96822937]\n",
      "PERDIDAAAA antes: 0.024300536140799522\n",
      "Predicción post entrenamiento : [[0.82228255]]\n",
      "PERDIDAAAA despues: 0.02130046859383583\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "[[[0.74585211]\n",
      "  [0.75405794]\n",
      "  [0.76326555]\n",
      "  [0.77175307]\n",
      "  [0.78060073]\n",
      "  [0.79009807]\n",
      "  [0.80081856]\n",
      "  [0.81234306]]]\n",
      "ejemplar: [0.74585211 0.75405794 0.76326555 0.77175307 0.78060073 0.79009807\n",
      " 0.80081856 0.81234306]\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.82528377]]\n",
      "Lr que voy a aplicar en el lote: 174 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.74585211 0.75405794 0.76326555 0.77175307 0.78060073 0.79009807\n",
      "  0.80081856 0.81234306]]\n",
      "verdaderas salidas: [0.95776831]\n",
      "PERDIDAAAA antes: 0.01755215786397457\n",
      "Predicción post entrenamiento : [[0.8355937]]\n",
      "PERDIDAAAA despues: 0.014926637522876263\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "0\n",
      "[[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "ejemplar: [0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      " 0.03448276 0.04223169]\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.5605535]]\n",
      "Lr que voy a aplicar en el lote: 1 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      "  0.03448276 0.04223169]]\n",
      "verdaderas salidas: [0.04610616]\n",
      "PERDIDAAAA antes: 0.26465606689453125\n",
      "Predicción post entrenamiento : [[0.5643436]]\n",
      "PERDIDAAAA despues: 0.2685700058937073\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "[[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.56055349]]]\n",
      "ejemplar: [0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      " 0.04223169 0.56055349]\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.5547882]]\n",
      "Lr que voy a aplicar en el lote: 2 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      "  0.04223169 0.56055349]]\n",
      "verdaderas salidas: [0.10422317]\n",
      "PERDIDAAAA antes: 0.20300883054733276\n",
      "Predicción post entrenamiento : [[0.5562076]]\n",
      "PERDIDAAAA despues: 0.20428992807865143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "[[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.56055349]\n",
      "  [0.55478817]]]\n",
      "ejemplar: [0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      " 0.56055349 0.55478817]\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.5618332]]\n",
      "Lr que voy a aplicar en el lote: 3 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      "  0.56055349 0.55478817]]\n",
      "verdaderas salidas: [0.1542038]\n",
      "PERDIDAAAA antes: 0.16616173088550568\n",
      "Predicción post entrenamiento : [[0.56189704]]\n",
      "PERDIDAAAA despues: 0.1662137806415558\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "[[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.56055349]\n",
      "  [0.55478817]\n",
      "  [0.5618332 ]]]\n",
      "ejemplar: [0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.56055349\n",
      " 0.55478817 0.5618332 ]\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.5762552]]\n",
      "Lr que voy a aplicar en el lote: 4 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.56055349\n",
      "  0.55478817 0.5618332 ]]\n",
      "verdaderas salidas: [0.15575358]\n",
      "PERDIDAAAA antes: 0.17682161927223206\n",
      "Predicción post entrenamiento : [[0.5749467]]\n",
      "PERDIDAAAA despues: 0.1757228672504425\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "[[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.56055349]\n",
      "  [0.55478817]\n",
      "  [0.5618332 ]\n",
      "  [0.5762552 ]]]\n",
      "ejemplar: [0.05656722 0.02595893 0.03448276 0.04223169 0.56055349 0.55478817\n",
      " 0.5618332  0.5762552 ]\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.59536105]]\n",
      "Lr que voy a aplicar en el lote: 5 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.05656722 0.02595893 0.03448276 0.04223169 0.56055349 0.55478817\n",
      "  0.5618332  0.5762552 ]]\n",
      "verdaderas salidas: [0.12553274]\n",
      "PERDIDAAAA antes: 0.22073863446712494\n",
      "Predicción post entrenamiento : [[0.5929078]]\n",
      "PERDIDAAAA despues: 0.21843942999839783\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "[[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.56055349]\n",
      "  [0.55478817]\n",
      "  [0.5618332 ]\n",
      "  [0.5762552 ]\n",
      "  [0.59536105]]]\n",
      "ejemplar: [0.02595893 0.03448276 0.04223169 0.56055349 0.55478817 0.5618332\n",
      " 0.5762552  0.59536105]\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.61812013]]\n",
      "Lr que voy a aplicar en el lote: 6 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.02595893 0.03448276 0.04223169 0.56055349 0.55478817 0.5618332\n",
      "  0.5762552  0.59536105]]\n",
      "verdaderas salidas: [0.14567997]\n",
      "PERDIDAAAA antes: 0.223199725151062\n",
      "Predicción post entrenamiento : [[0.61422336]]\n",
      "PERDIDAAAA despues: 0.21953292191028595\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "[[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.56055349]\n",
      "  [0.55478817]\n",
      "  [0.5618332 ]\n",
      "  [0.5762552 ]\n",
      "  [0.59536105]\n",
      "  [0.61812013]]]\n",
      "ejemplar: [0.03448276 0.04223169 0.56055349 0.55478817 0.5618332  0.5762552\n",
      " 0.59536105 0.61812013]\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.654348]]\n",
      "Lr que voy a aplicar en el lote: 7 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.03448276 0.04223169 0.56055349 0.55478817 0.5618332  0.5762552\n",
      "  0.59536105 0.61812013]]\n",
      "verdaderas salidas: [0.14645486]\n",
      "PERDIDAAAA antes: 0.2579554319381714\n",
      "Predicción post entrenamiento : [[0.6474652]]\n",
      "PERDIDAAAA despues: 0.25101137161254883\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "[[[0.04223169]\n",
      "  [0.56055349]\n",
      "  [0.55478817]\n",
      "  [0.5618332 ]\n",
      "  [0.5762552 ]\n",
      "  [0.59536105]\n",
      "  [0.61812013]\n",
      "  [0.65434802]]]\n",
      "ejemplar: [0.04223169 0.56055349 0.55478817 0.5618332  0.5762552  0.59536105\n",
      " 0.61812013 0.65434802]\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.69836223]]\n",
      "Lr que voy a aplicar en el lote: 8 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.04223169 0.56055349 0.55478817 0.5618332  0.5762552  0.59536105\n",
      "  0.61812013 0.65434802]]\n",
      "verdaderas salidas: [0.19604804]\n",
      "PERDIDAAAA antes: 0.2523195743560791\n",
      "Predicción post entrenamiento : [[0.68876785]]\n",
      "PERDIDAAAA despues: 0.24277283251285553\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "[[[0.56055349]\n",
      "  [0.55478817]\n",
      "  [0.5618332 ]\n",
      "  [0.5762552 ]\n",
      "  [0.59536105]\n",
      "  [0.61812013]\n",
      "  [0.65434802]\n",
      "  [0.69836223]]]\n",
      "ejemplar: [0.56055349 0.55478817 0.5618332  0.5762552  0.59536105 0.61812013\n",
      " 0.65434802 0.69836223]\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.7503545]]\n",
      "Lr que voy a aplicar en el lote: 9 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.56055349 0.55478817 0.5618332  0.5762552  0.59536105 0.61812013\n",
      "  0.65434802 0.69836223]]\n",
      "verdaderas salidas: [0.2305308]\n",
      "PERDIDAAAA antes: 0.270216703414917\n",
      "Predicción post entrenamiento : [[0.73872644]]\n",
      "PERDIDAAAA despues: 0.2582628130912781\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "[[[0.55478817]\n",
      "  [0.5618332 ]\n",
      "  [0.5762552 ]\n",
      "  [0.59536105]\n",
      "  [0.61812013]\n",
      "  [0.65434802]\n",
      "  [0.69836223]\n",
      "  [0.75035453]]]\n",
      "ejemplar: [0.55478817 0.5618332  0.5762552  0.59536105 0.61812013 0.65434802\n",
      " 0.69836223 0.75035453]\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.74262065]]\n",
      "Lr que voy a aplicar en el lote: 10 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.55478817 0.5618332  0.5762552  0.59536105 0.61812013 0.65434802\n",
      "  0.69836223 0.75035453]]\n",
      "verdaderas salidas: [0.20844634]\n",
      "PERDIDAAAA antes: 0.2853422164916992\n",
      "Predicción post entrenamiento : [[0.729418]]\n",
      "PERDIDAAAA despues: 0.2714114785194397\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "[[[0.5618332 ]\n",
      "  [0.5762552 ]\n",
      "  [0.59536105]\n",
      "  [0.61812013]\n",
      "  [0.65434802]\n",
      "  [0.69836223]\n",
      "  [0.75035453]\n",
      "  [0.74262065]]]\n",
      "ejemplar: [0.5618332  0.5762552  0.59536105 0.61812013 0.65434802 0.69836223\n",
      " 0.75035453 0.74262065]\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.7363088]]\n",
      "Lr que voy a aplicar en el lote: 11 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.5618332  0.5762552  0.59536105 0.61812013 0.65434802 0.69836223\n",
      "  0.75035453 0.74262065]]\n",
      "verdaderas salidas: [0.21193336]\n",
      "PERDIDAAAA antes: 0.27496960759162903\n",
      "Predicción post entrenamiento : [[0.7208696]]\n",
      "PERDIDAAAA despues: 0.25901609659194946\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "[[[0.5762552 ]\n",
      "  [0.59536105]\n",
      "  [0.61812013]\n",
      "  [0.65434802]\n",
      "  [0.69836223]\n",
      "  [0.75035453]\n",
      "  [0.74262065]\n",
      "  [0.73630881]]]\n",
      "ejemplar: [0.5762552  0.59536105 0.61812013 0.65434802 0.69836223 0.75035453\n",
      " 0.74262065 0.73630881]\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.7295886]]\n",
      "Lr que voy a aplicar en el lote: 12 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.5762552  0.59536105 0.61812013 0.65434802 0.69836223 0.75035453\n",
      "  0.74262065 0.73630881]]\n",
      "verdaderas salidas: [0.207284]\n",
      "PERDIDAAAA antes: 0.2728021442890167\n",
      "Predicción post entrenamiento : [[0.7128453]]\n",
      "PERDIDAAAA despues: 0.2555922865867615\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "[[[0.59536105]\n",
      "  [0.61812013]\n",
      "  [0.65434802]\n",
      "  [0.69836223]\n",
      "  [0.75035453]\n",
      "  [0.74262065]\n",
      "  [0.73630881]\n",
      "  [0.72958863]]]\n",
      "ejemplar: [0.59536105 0.61812013 0.65434802 0.69836223 0.75035453 0.74262065\n",
      " 0.73630881 0.72958863]\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.72257125]]\n",
      "Lr que voy a aplicar en el lote: 13 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.59536105 0.61812013 0.65434802 0.69836223 0.75035453 0.74262065\n",
      "  0.73630881 0.72958863]]\n",
      "verdaderas salidas: [0.19294847]\n",
      "PERDIDAAAA antes: 0.28050029277801514\n",
      "Predicción post entrenamiento : [[0.7046118]]\n",
      "PERDIDAAAA despues: 0.2617993652820587\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "[[[0.61812013]\n",
      "  [0.65434802]\n",
      "  [0.69836223]\n",
      "  [0.75035453]\n",
      "  [0.74262065]\n",
      "  [0.73630881]\n",
      "  [0.72958863]\n",
      "  [0.72257125]]]\n",
      "ejemplar: [0.61812013 0.65434802 0.69836223 0.75035453 0.74262065 0.73630881\n",
      " 0.72958863 0.72257125]\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.7146052]]\n",
      "Lr que voy a aplicar en el lote: 14 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.61812013 0.65434802 0.69836223 0.75035453 0.74262065 0.73630881\n",
      "  0.72958863 0.72257125]]\n",
      "verdaderas salidas: [0.19682294]\n",
      "PERDIDAAAA antes: 0.26809847354888916\n",
      "Predicción post entrenamiento : [[0.6937343]]\n",
      "PERDIDAAAA despues: 0.2469208836555481\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "[[[0.65434802]\n",
      "  [0.69836223]\n",
      "  [0.75035453]\n",
      "  [0.74262065]\n",
      "  [0.73630881]\n",
      "  [0.72958863]\n",
      "  [0.72257125]\n",
      "  [0.71460521]]]\n",
      "ejemplar: [0.65434802 0.69836223 0.75035453 0.74262065 0.73630881 0.72958863\n",
      " 0.72257125 0.71460521]\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.7031698]]\n",
      "Lr que voy a aplicar en el lote: 15 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.65434802 0.69836223 0.75035453 0.74262065 0.73630881 0.72958863\n",
      "  0.72257125 0.71460521]]\n",
      "verdaderas salidas: [0.21425804]\n",
      "PERDIDAAAA antes: 0.2390347272157669\n",
      "Predicción post entrenamiento : [[0.6828209]]\n",
      "PERDIDAAAA despues: 0.21955116093158722\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "[[[0.69836223]\n",
      "  [0.75035453]\n",
      "  [0.74262065]\n",
      "  [0.73630881]\n",
      "  [0.72958863]\n",
      "  [0.72257125]\n",
      "  [0.71460521]\n",
      "  [0.70316982]]]\n",
      "ejemplar: [0.69836223 0.75035453 0.74262065 0.73630881 0.72958863 0.72257125\n",
      " 0.71460521 0.70316982]\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.6897581]]\n",
      "Lr que voy a aplicar en el lote: 16 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.69836223 0.75035453 0.74262065 0.73630881 0.72958863 0.72257125\n",
      "  0.71460521 0.70316982]]\n",
      "verdaderas salidas: [0.18132507]\n",
      "PERDIDAAAA antes: 0.25850415229797363\n",
      "Predicción post entrenamiento : [[0.6687594]]\n",
      "PERDIDAAAA despues: 0.23759222030639648\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "[[[0.75035453]\n",
      "  [0.74262065]\n",
      "  [0.73630881]\n",
      "  [0.72958863]\n",
      "  [0.72257125]\n",
      "  [0.71460521]\n",
      "  [0.70316982]\n",
      "  [0.68975812]]]\n",
      "ejemplar: [0.75035453 0.74262065 0.73630881 0.72958863 0.72257125 0.71460521\n",
      " 0.70316982 0.68975812]\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.6717833]]\n",
      "Lr que voy a aplicar en el lote: 17 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.75035453 0.74262065 0.73630881 0.72958863 0.72257125 0.71460521\n",
      "  0.70316982 0.68975812]]\n",
      "verdaderas salidas: [0.17512592]\n",
      "PERDIDAAAA antes: 0.24666857719421387\n",
      "Predicción post entrenamiento : [[0.65118206]]\n",
      "PERDIDAAAA despues: 0.22662943601608276\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "[[[0.74262065]\n",
      "  [0.73630881]\n",
      "  [0.72958863]\n",
      "  [0.72257125]\n",
      "  [0.71460521]\n",
      "  [0.70316982]\n",
      "  [0.68975812]\n",
      "  [0.67178333]]]\n",
      "ejemplar: [0.74262065 0.73630881 0.72958863 0.72257125 0.71460521 0.70316982\n",
      " 0.68975812 0.67178333]\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.6489138]]\n",
      "Lr que voy a aplicar en el lote: 18 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.74262065 0.73630881 0.72958863 0.72257125 0.71460521 0.70316982\n",
      "  0.68975812 0.67178333]]\n",
      "verdaderas salidas: [0.14800465]\n",
      "PERDIDAAAA antes: 0.2509099841117859\n",
      "Predicción post entrenamiento : [[0.62965417]]\n",
      "PERDIDAAAA despues: 0.23198625445365906\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "[[[0.73630881]\n",
      "  [0.72958863]\n",
      "  [0.72257125]\n",
      "  [0.71460521]\n",
      "  [0.70316982]\n",
      "  [0.68975812]\n",
      "  [0.67178333]\n",
      "  [0.6489138 ]]]\n",
      "ejemplar: [0.73630881 0.72958863 0.72257125 0.71460521 0.70316982 0.68975812\n",
      " 0.67178333 0.6489138 ]\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.62734044]]\n",
      "Lr que voy a aplicar en el lote: 19 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.73630881 0.72958863 0.72257125 0.71460521 0.70316982 0.68975812\n",
      "  0.67178333 0.6489138 ]]\n",
      "verdaderas salidas: [0.15885316]\n",
      "PERDIDAAAA antes: 0.21948032081127167\n",
      "Predicción post entrenamiento : [[0.60907197]]\n",
      "PERDIDAAAA despues: 0.20269696414470673\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "[[[0.72958863]\n",
      "  [0.72257125]\n",
      "  [0.71460521]\n",
      "  [0.70316982]\n",
      "  [0.68975812]\n",
      "  [0.67178333]\n",
      "  [0.6489138 ]\n",
      "  [0.62734044]]]\n",
      "ejemplar: [0.72958863 0.72257125 0.71460521 0.70316982 0.68975812 0.67178333\n",
      " 0.6489138  0.62734044]\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.60645837]]\n",
      "Lr que voy a aplicar en el lote: 20 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.72958863 0.72257125 0.71460521 0.70316982 0.68975812 0.67178333\n",
      "  0.6489138  0.62734044]]\n",
      "verdaderas salidas: [0.19217358]\n",
      "PERDIDAAAA antes: 0.17163188755512238\n",
      "Predicción post entrenamiento : [[0.5888159]]\n",
      "PERDIDAAAA despues: 0.1573251634836197\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "[[[0.72257125]\n",
      "  [0.71460521]\n",
      "  [0.70316982]\n",
      "  [0.68975812]\n",
      "  [0.67178333]\n",
      "  [0.6489138 ]\n",
      "  [0.62734044]\n",
      "  [0.60645837]]]\n",
      "ejemplar: [0.72257125 0.71460521 0.70316982 0.68975812 0.67178333 0.6489138\n",
      " 0.62734044 0.60645837]\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.58579284]]\n",
      "Lr que voy a aplicar en el lote: 21 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.72257125 0.71460521 0.70316982 0.68975812 0.67178333 0.6489138\n",
      "  0.62734044 0.60645837]]\n",
      "verdaderas salidas: [0.18597443]\n",
      "PERDIDAAAA antes: 0.15985476970672607\n",
      "Predicción post entrenamiento : [[0.56902426]]\n",
      "PERDIDAAAA despues: 0.14672718942165375\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "[[[0.71460521]\n",
      "  [0.70316982]\n",
      "  [0.68975812]\n",
      "  [0.67178333]\n",
      "  [0.6489138 ]\n",
      "  [0.62734044]\n",
      "  [0.60645837]\n",
      "  [0.58579284]]]\n",
      "ejemplar: [0.71460521 0.70316982 0.68975812 0.67178333 0.6489138  0.62734044\n",
      " 0.60645837 0.58579284]\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.5654692]]\n",
      "Lr que voy a aplicar en el lote: 22 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.71460521 0.70316982 0.68975812 0.67178333 0.6489138  0.62734044\n",
      "  0.60645837 0.58579284]]\n",
      "verdaderas salidas: [0.26695079]\n",
      "PERDIDAAAA antes: 0.08911324292421341\n",
      "Predicción post entrenamiento : [[0.54978454]]\n",
      "PERDIDAAAA despues: 0.07999493181705475\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "[[[0.70316982]\n",
      "  [0.68975812]\n",
      "  [0.67178333]\n",
      "  [0.6489138 ]\n",
      "  [0.62734044]\n",
      "  [0.60645837]\n",
      "  [0.58579284]\n",
      "  [0.56546921]]]\n",
      "ejemplar: [0.70316982 0.68975812 0.67178333 0.6489138  0.62734044 0.60645837\n",
      " 0.58579284 0.56546921]\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.545638]]\n",
      "Lr que voy a aplicar en el lote: 23 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.70316982 0.68975812 0.67178333 0.6489138  0.62734044 0.60645837\n",
      "  0.58579284 0.56546921]]\n",
      "verdaderas salidas: [0.29252228]\n",
      "PERDIDAAAA antes: 0.06406757980585098\n",
      "Predicción post entrenamiento : [[0.5314788]]\n",
      "PERDIDAAAA despues: 0.05710022896528244\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "[[[0.68975812]\n",
      "  [0.67178333]\n",
      "  [0.6489138 ]\n",
      "  [0.62734044]\n",
      "  [0.60645837]\n",
      "  [0.58579284]\n",
      "  [0.56546921]\n",
      "  [0.54563802]]]\n",
      "ejemplar: [0.68975812 0.67178333 0.6489138  0.62734044 0.60645837 0.58579284\n",
      " 0.56546921 0.54563802]\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.5268989]]\n",
      "Lr que voy a aplicar en el lote: 24 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.68975812 0.67178333 0.6489138  0.62734044 0.60645837 0.58579284\n",
      "  0.56546921 0.54563802]]\n",
      "verdaderas salidas: [0.31770632]\n",
      "PERDIDAAAA antes: 0.043761543929576874\n",
      "Predicción post entrenamiento : [[0.51355976]]\n",
      "PERDIDAAAA despues: 0.03835856914520264\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "[[[0.67178333]\n",
      "  [0.6489138 ]\n",
      "  [0.62734044]\n",
      "  [0.60645837]\n",
      "  [0.58579284]\n",
      "  [0.56546921]\n",
      "  [0.54563802]\n",
      "  [0.52689892]]]\n",
      "ejemplar: [0.67178333 0.6489138  0.62734044 0.60645837 0.58579284 0.56546921\n",
      " 0.54563802 0.52689892]\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.5086267]]\n",
      "Lr que voy a aplicar en el lote: 25 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.67178333 0.6489138  0.62734044 0.60645837 0.58579284 0.56546921\n",
      "  0.54563802 0.52689892]]\n",
      "verdaderas salidas: [0.31266951]\n",
      "PERDIDAAAA antes: 0.03839921951293945\n",
      "Predicción post entrenamiento : [[0.4967149]]\n",
      "PERDIDAAAA despues: 0.03387270122766495\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "[[[0.6489138 ]\n",
      "  [0.62734044]\n",
      "  [0.60645837]\n",
      "  [0.58579284]\n",
      "  [0.56546921]\n",
      "  [0.54563802]\n",
      "  [0.52689892]\n",
      "  [0.5086267 ]]]\n",
      "ejemplar: [0.6489138  0.62734044 0.60645837 0.58579284 0.56546921 0.54563802\n",
      " 0.52689892 0.5086267 ]\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.49172184]]\n",
      "Lr que voy a aplicar en el lote: 26 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.6489138  0.62734044 0.60645837 0.58579284 0.56546921 0.54563802\n",
      "  0.52689892 0.5086267 ]]\n",
      "verdaderas salidas: [0.28903526]\n",
      "PERDIDAAAA antes: 0.04108184948563576\n",
      "Predicción post entrenamiento : [[0.48080793]]\n",
      "PERDIDAAAA despues: 0.03677675500512123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "[[[0.62734044]\n",
      "  [0.60645837]\n",
      "  [0.58579284]\n",
      "  [0.56546921]\n",
      "  [0.54563802]\n",
      "  [0.52689892]\n",
      "  [0.5086267 ]\n",
      "  [0.49172184]]]\n",
      "ejemplar: [0.62734044 0.60645837 0.58579284 0.56546921 0.54563802 0.52689892\n",
      " 0.5086267  0.49172184]\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.47610784]]\n",
      "Lr que voy a aplicar en el lote: 27 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.62734044 0.60645837 0.58579284 0.56546921 0.54563802 0.52689892\n",
      "  0.5086267  0.49172184]]\n",
      "verdaderas salidas: [0.28283611]\n",
      "PERDIDAAAA antes: 0.03735395893454552\n",
      "Predicción post entrenamiento : [[0.46614742]]\n",
      "PERDIDAAAA despues: 0.033603038638830185\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "[[[0.60645837]\n",
      "  [0.58579284]\n",
      "  [0.56546921]\n",
      "  [0.54563802]\n",
      "  [0.52689892]\n",
      "  [0.5086267 ]\n",
      "  [0.49172184]\n",
      "  [0.47610784]]]\n",
      "ejemplar: [0.60645837 0.58579284 0.56546921 0.54563802 0.52689892 0.5086267\n",
      " 0.49172184 0.47610784]\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.46167994]]\n",
      "Lr que voy a aplicar en el lote: 28 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.60645837 0.58579284 0.56546921 0.54563802 0.52689892 0.5086267\n",
      "  0.49172184 0.47610784]]\n",
      "verdaderas salidas: [0.29949632]\n",
      "PERDIDAAAA antes: 0.026303524151444435\n",
      "Predicción post entrenamiento : [[0.45263234]]\n",
      "PERDIDAAAA despues: 0.023450639098882675\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "[[[0.58579284]\n",
      "  [0.56546921]\n",
      "  [0.54563802]\n",
      "  [0.52689892]\n",
      "  [0.5086267 ]\n",
      "  [0.49172184]\n",
      "  [0.47610784]\n",
      "  [0.46167994]]]\n",
      "ejemplar: [0.58579284 0.56546921 0.54563802 0.52689892 0.5086267  0.49172184\n",
      " 0.47610784 0.46167994]\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.4483817]]\n",
      "Lr que voy a aplicar en el lote: 29 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.58579284 0.56546921 0.54563802 0.52689892 0.5086267  0.49172184\n",
      "  0.47610784 0.46167994]]\n",
      "verdaderas salidas: [0.27586207]\n",
      "PERDIDAAAA antes: 0.02976302057504654\n",
      "Predicción post entrenamiento : [[0.44004995]]\n",
      "PERDIDAAAA despues: 0.026957659050822258\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "[[[0.56546921]\n",
      "  [0.54563802]\n",
      "  [0.52689892]\n",
      "  [0.5086267 ]\n",
      "  [0.49172184]\n",
      "  [0.47610784]\n",
      "  [0.46167994]\n",
      "  [0.44838169]]]\n",
      "ejemplar: [0.56546921 0.54563802 0.52689892 0.5086267  0.49172184 0.47610784\n",
      " 0.46167994 0.44838169]\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.4360401]]\n",
      "Lr que voy a aplicar en el lote: 30 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.56546921 0.54563802 0.52689892 0.5086267  0.49172184 0.47610784\n",
      "  0.46167994 0.44838169]]\n",
      "verdaderas salidas: [0.27469973]\n",
      "PERDIDAAAA antes: 0.02603071928024292\n",
      "Predicción post entrenamiento : [[0.4282098]]\n",
      "PERDIDAAAA despues: 0.023565348237752914\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "[[[0.54563802]\n",
      "  [0.52689892]\n",
      "  [0.5086267 ]\n",
      "  [0.49172184]\n",
      "  [0.47610784]\n",
      "  [0.46167994]\n",
      "  [0.44838169]\n",
      "  [0.4360401 ]]]\n",
      "ejemplar: [0.54563802 0.52689892 0.5086267  0.49172184 0.47610784 0.46167994\n",
      " 0.44838169 0.4360401 ]\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.42446604]]\n",
      "Lr que voy a aplicar en el lote: 31 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.54563802 0.52689892 0.5086267  0.49172184 0.47610784 0.46167994\n",
      "  0.44838169 0.4360401 ]]\n",
      "verdaderas salidas: [0.27547462]\n",
      "PERDIDAAAA antes: 0.022198447957634926\n",
      "Predicción post entrenamiento : [[0.41738224]]\n",
      "PERDIDAAAA despues: 0.02013777568936348\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "[[[0.52689892]\n",
      "  [0.5086267 ]\n",
      "  [0.49172184]\n",
      "  [0.47610784]\n",
      "  [0.46167994]\n",
      "  [0.44838169]\n",
      "  [0.4360401 ]\n",
      "  [0.42446604]]]\n",
      "ejemplar: [0.52689892 0.5086267  0.49172184 0.47610784 0.46167994 0.44838169\n",
      " 0.4360401  0.42446604]\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.41392195]]\n",
      "Lr que voy a aplicar en el lote: 32 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.52689892 0.5086267  0.49172184 0.47610784 0.46167994 0.44838169\n",
      "  0.4360401  0.42446604]]\n",
      "verdaderas salidas: [0.33475397]\n",
      "PERDIDAAAA antes: 0.00626757089048624\n",
      "Predicción post entrenamiento : [[0.40756953]]\n",
      "PERDIDAAAA despues: 0.005302106961607933\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "[[[0.5086267 ]\n",
      "  [0.49172184]\n",
      "  [0.47610784]\n",
      "  [0.46167994]\n",
      "  [0.44838169]\n",
      "  [0.4360401 ]\n",
      "  [0.42446604]\n",
      "  [0.41392195]]]\n",
      "ejemplar: [0.5086267  0.49172184 0.47610784 0.46167994 0.44838169 0.4360401\n",
      " 0.42446604 0.41392195]\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.40437603]]\n",
      "Lr que voy a aplicar en el lote: 33 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.5086267  0.49172184 0.47610784 0.46167994 0.44838169 0.4360401\n",
      "  0.42446604 0.41392195]]\n",
      "verdaderas salidas: [0.35567609]\n",
      "PERDIDAAAA antes: 0.0023716846480965614\n",
      "Predicción post entrenamiento : [[0.3987428]]\n",
      "PERDIDAAAA despues: 0.0018547414802014828\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "[[[0.49172184]\n",
      "  [0.47610784]\n",
      "  [0.46167994]\n",
      "  [0.44838169]\n",
      "  [0.4360401 ]\n",
      "  [0.42446604]\n",
      "  [0.41392195]\n",
      "  [0.40437603]]]\n",
      "ejemplar: [0.49172184 0.47610784 0.46167994 0.44838169 0.4360401  0.42446604\n",
      " 0.41392195 0.40437603]\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.39583892]]\n",
      "Lr que voy a aplicar en el lote: 34 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.49172184 0.47610784 0.46167994 0.44838169 0.4360401  0.42446604\n",
      "  0.41392195 0.40437603]]\n",
      "verdaderas salidas: [0.3366912]\n",
      "PERDIDAAAA antes: 0.0034984522499144077\n",
      "Predicción post entrenamiento : [[0.39081177]]\n",
      "PERDIDAAAA despues: 0.0029290360398590565\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "[[[0.47610784]\n",
      "  [0.46167994]\n",
      "  [0.44838169]\n",
      "  [0.4360401 ]\n",
      "  [0.42446604]\n",
      "  [0.41392195]\n",
      "  [0.40437603]\n",
      "  [0.39583892]]]\n",
      "ejemplar: [0.47610784 0.46167994 0.44838169 0.4360401  0.42446604 0.41392195\n",
      " 0.40437603 0.39583892]\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.38816917]]\n",
      "Lr que voy a aplicar en el lote: 35 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.47610784 0.46167994 0.44838169 0.4360401  0.42446604 0.41392195\n",
      "  0.40437603 0.39583892]]\n",
      "verdaderas salidas: [0.33359163]\n",
      "PERDIDAAAA antes: 0.002978706732392311\n",
      "Predicción post entrenamiento : [[0.38359416]]\n",
      "PERDIDAAAA despues: 0.0025002516340464354\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "[[[0.46167994]\n",
      "  [0.44838169]\n",
      "  [0.4360401 ]\n",
      "  [0.42446604]\n",
      "  [0.41392195]\n",
      "  [0.40437603]\n",
      "  [0.39583892]\n",
      "  [0.38816917]]]\n",
      "ejemplar: [0.46167994 0.44838169 0.4360401  0.42446604 0.41392195 0.40437603\n",
      " 0.39583892 0.38816917]\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.381188]]\n",
      "Lr que voy a aplicar en el lote: 36 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.46167994 0.44838169 0.4360401  0.42446604 0.41392195 0.40437603\n",
      "  0.39583892 0.38816917]]\n",
      "verdaderas salidas: [0.3847346]\n",
      "PERDIDAAAA antes: 1.2578339919855352e-05\n",
      "Predicción post entrenamiento : [[0.37708712]]\n",
      "PERDIDAAAA despues: 5.848401997354813e-05\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "[[[0.44838169]\n",
      "  [0.4360401 ]\n",
      "  [0.42446604]\n",
      "  [0.41392195]\n",
      "  [0.40437603]\n",
      "  [0.39583892]\n",
      "  [0.38816917]\n",
      "  [0.38118801]]]\n",
      "ejemplar: [0.44838169 0.4360401  0.42446604 0.41392195 0.40437603 0.39583892\n",
      " 0.38816917 0.38118801]\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.37489724]]\n",
      "Lr que voy a aplicar en el lote: 37 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.44838169 0.4360401  0.42446604 0.41392195 0.40437603 0.39583892\n",
      "  0.38816917 0.38118801]]\n",
      "verdaderas salidas: [0.57109647]\n",
      "PERDIDAAAA antes: 0.03849413990974426\n",
      "Predicción post entrenamiento : [[0.37156686]]\n",
      "PERDIDAAAA despues: 0.03981206938624382\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "[[[0.4360401 ]\n",
      "  [0.42446604]\n",
      "  [0.41392195]\n",
      "  [0.40437603]\n",
      "  [0.39583892]\n",
      "  [0.38816917]\n",
      "  [0.38118801]\n",
      "  [0.37489724]]]\n",
      "ejemplar: [0.4360401  0.42446604 0.41392195 0.40437603 0.39583892 0.38816917\n",
      " 0.38118801 0.37489724]\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.36957324]]\n",
      "Lr que voy a aplicar en el lote: 38 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.4360401  0.42446604 0.41392195 0.40437603 0.39583892 0.38816917\n",
      "  0.38118801 0.37489724]]\n",
      "verdaderas salidas: [0.59628051]\n",
      "PERDIDAAAA antes: 0.051396191120147705\n",
      "Predicción post entrenamiento : [[0.3669438]]\n",
      "PERDIDAAAA despues: 0.05259532481431961\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "[[[0.42446604]\n",
      "  [0.41392195]\n",
      "  [0.40437603]\n",
      "  [0.39583892]\n",
      "  [0.38816917]\n",
      "  [0.38118801]\n",
      "  [0.37489724]\n",
      "  [0.36957324]]]\n",
      "ejemplar: [0.42446604 0.41392195 0.40437603 0.39583892 0.38816917 0.38118801\n",
      " 0.37489724 0.36957324]\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.36513594]]\n",
      "Lr que voy a aplicar en el lote: 39 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.42446604 0.41392195 0.40437603 0.39583892 0.38816917 0.38118801\n",
      "  0.37489724 0.36957324]]\n",
      "verdaderas salidas: [0.57458349]\n",
      "PERDIDAAAA antes: 0.04386826977133751\n",
      "Predicción post entrenamiento : [[0.3631266]]\n",
      "PERDIDAAAA despues: 0.044714007526636124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "[[[0.41392195]\n",
      "  [0.40437603]\n",
      "  [0.39583892]\n",
      "  [0.38816917]\n",
      "  [0.38118801]\n",
      "  [0.37489724]\n",
      "  [0.36957324]\n",
      "  [0.36513594]]]\n",
      "ejemplar: [0.41392195 0.40437603 0.39583892 0.38816917 0.38118801 0.37489724\n",
      " 0.36957324 0.36513594]\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.3615052]]\n",
      "Lr que voy a aplicar en el lote: 40 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.41392195 0.40437603 0.39583892 0.38816917 0.38118801 0.37489724\n",
      "  0.36957324 0.36513594]]\n",
      "verdaderas salidas: [0.60635413]\n",
      "PERDIDAAAA antes: 0.05995098873972893\n",
      "Predicción post entrenamiento : [[0.36009502]]\n",
      "PERDIDAAAA despues: 0.06064354255795479\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "[[[0.40437603]\n",
      "  [0.39583892]\n",
      "  [0.38816917]\n",
      "  [0.38118801]\n",
      "  [0.37489724]\n",
      "  [0.36957324]\n",
      "  [0.36513594]\n",
      "  [0.36150521]]]\n",
      "ejemplar: [0.40437603 0.39583892 0.38816917 0.38118801 0.37489724 0.36957324\n",
      " 0.36513594 0.36150521]\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.35864708]]\n",
      "Lr que voy a aplicar en el lote: 41 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.40437603 0.39583892 0.38816917 0.38118801 0.37489724 0.36957324\n",
      "  0.36513594 0.36150521]]\n",
      "verdaderas salidas: [0.58465711]\n",
      "PERDIDAAAA antes: 0.05108054354786873\n",
      "Predicción post entrenamiento : [[0.3577368]]\n",
      "PERDIDAAAA despues: 0.051492840051651\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "[[[0.39583892]\n",
      "  [0.38816917]\n",
      "  [0.38118801]\n",
      "  [0.37489724]\n",
      "  [0.36957324]\n",
      "  [0.36513594]\n",
      "  [0.36150521]\n",
      "  [0.35864708]]]\n",
      "ejemplar: [0.39583892 0.38816917 0.38118801 0.37489724 0.36957324 0.36513594\n",
      " 0.36150521 0.35864708]\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.3564509]]\n",
      "Lr que voy a aplicar en el lote: 42 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.39583892 0.38816917 0.38118801 0.37489724 0.36957324 0.36513594\n",
      "  0.36150521 0.35864708]]\n",
      "verdaderas salidas: [0.56877179]\n",
      "PERDIDAAAA antes: 0.04508016258478165\n",
      "Predicción post entrenamiento : [[0.35591152]]\n",
      "PERDIDAAAA despues: 0.045309487730264664\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "[[[0.38816917]\n",
      "  [0.38118801]\n",
      "  [0.37489724]\n",
      "  [0.36957324]\n",
      "  [0.36513594]\n",
      "  [0.36150521]\n",
      "  [0.35864708]\n",
      "  [0.35645089]]]\n",
      "ejemplar: [0.38816917 0.38118801 0.37489724 0.36957324 0.36513594 0.36150521\n",
      " 0.35864708 0.35645089]\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.35477495]]\n",
      "Lr que voy a aplicar en el lote: 43 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.38816917 0.38118801 0.37489724 0.36957324 0.36513594 0.36150521\n",
      "  0.35864708 0.35645089]]\n",
      "verdaderas salidas: [0.64277412]\n",
      "PERDIDAAAA antes: 0.08294351398944855\n",
      "Predicción post entrenamiento : [[0.35472375]]\n",
      "PERDIDAAAA despues: 0.08297300338745117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "[[[0.38118801]\n",
      "  [0.37489724]\n",
      "  [0.36957324]\n",
      "  [0.36513594]\n",
      "  [0.36150521]\n",
      "  [0.35864708]\n",
      "  [0.35645089]\n",
      "  [0.35477495]]]\n",
      "ejemplar: [0.38118801 0.37489724 0.36957324 0.36513594 0.36150521 0.35864708\n",
      " 0.35645089 0.35477495]\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.35373044]]\n",
      "Lr que voy a aplicar en el lote: 44 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.38118801 0.37489724 0.36957324 0.36513594 0.36150521 0.35864708\n",
      "  0.35645089 0.35477495]]\n",
      "verdaderas salidas: [0.66175901]\n",
      "PERDIDAAAA antes: 0.09488160163164139\n",
      "Predicción post entrenamiento : [[0.35415393]]\n",
      "PERDIDAAAA despues: 0.09462089091539383\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "[[[0.37489724]\n",
      "  [0.36957324]\n",
      "  [0.36513594]\n",
      "  [0.36150521]\n",
      "  [0.35864708]\n",
      "  [0.35645089]\n",
      "  [0.35477495]\n",
      "  [0.35373044]]]\n",
      "ejemplar: [0.37489724 0.36957324 0.36513594 0.36150521 0.35864708 0.35645089\n",
      " 0.35477495 0.35373044]\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.35330695]]\n",
      "Lr que voy a aplicar en el lote: 45 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.37489724 0.36957324 0.36513594 0.36150521 0.35864708 0.35645089\n",
      "  0.35477495 0.35373044]]\n",
      "verdaderas salidas: [0.67299496]\n",
      "PERDIDAAAA antes: 0.10220043361186981\n",
      "Predicción post entrenamiento : [[0.35416707]]\n",
      "PERDIDAAAA despues: 0.10165122896432877\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "[[[0.36957324]\n",
      "  [0.36513594]\n",
      "  [0.36150521]\n",
      "  [0.35864708]\n",
      "  [0.35645089]\n",
      "  [0.35477495]\n",
      "  [0.35373044]\n",
      "  [0.35330695]]]\n",
      "ejemplar: [0.36957324 0.36513594 0.36150521 0.35864708 0.35645089 0.35477495\n",
      " 0.35373044 0.35330695]\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.35346964]]\n",
      "Lr que voy a aplicar en el lote: 46 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.36957324 0.36513594 0.36150521 0.35864708 0.35645089 0.35477495\n",
      "  0.35373044 0.35330695]]\n",
      "verdaderas salidas: [0.7105773]\n",
      "PERDIDAAAA antes: 0.12752588093280792\n",
      "Predicción post entrenamiento : [[0.3547822]]\n",
      "PERDIDAAAA despues: 0.12659016251564026\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "[[[0.36513594]\n",
      "  [0.36150521]\n",
      "  [0.35864708]\n",
      "  [0.35645089]\n",
      "  [0.35477495]\n",
      "  [0.35373044]\n",
      "  [0.35330695]\n",
      "  [0.35346964]]]\n",
      "ejemplar: [0.36513594 0.36150521 0.35864708 0.35645089 0.35477495 0.35373044\n",
      " 0.35330695 0.35346964]\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.35422143]]\n",
      "Lr que voy a aplicar en el lote: 47 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.36513594 0.36150521 0.35864708 0.35645089 0.35477495 0.35373044\n",
      "  0.35330695 0.35346964]]\n",
      "verdaderas salidas: [0.7039907]\n",
      "PERDIDAAAA antes: 0.12233854085206985\n",
      "Predicción post entrenamiento : [[0.35591698]]\n",
      "PERDIDAAAA despues: 0.12115531414747238\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "[[[0.36150521]\n",
      "  [0.35864708]\n",
      "  [0.35645089]\n",
      "  [0.35477495]\n",
      "  [0.35373044]\n",
      "  [0.35330695]\n",
      "  [0.35346964]\n",
      "  [0.35422143]]]\n",
      "ejemplar: [0.36150521 0.35864708 0.35645089 0.35477495 0.35373044 0.35330695\n",
      " 0.35346964 0.35422143]\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.355482]]\n",
      "Lr que voy a aplicar en el lote: 48 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.36150521 0.35864708 0.35645089 0.35477495 0.35373044 0.35330695\n",
      "  0.35346964 0.35422143]]\n",
      "verdaderas salidas: [0.7272375]\n",
      "PERDIDAAAA antes: 0.13820216059684753\n",
      "Predicción post entrenamiento : [[0.35757318]]\n",
      "PERDIDAAAA despues: 0.13665172457695007\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "[[[0.35864708]\n",
      "  [0.35645089]\n",
      "  [0.35477495]\n",
      "  [0.35373044]\n",
      "  [0.35330695]\n",
      "  [0.35346964]\n",
      "  [0.35422143]\n",
      "  [0.35548201]]]\n",
      "ejemplar: [0.35864708 0.35645089 0.35477495 0.35373044 0.35330695 0.35346964\n",
      " 0.35422143 0.35548201]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.35725573]]\n",
      "Lr que voy a aplicar en el lote: 49 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.35864708 0.35645089 0.35477495 0.35373044 0.35330695 0.35346964\n",
      "  0.35422143 0.35548201]]\n",
      "verdaderas salidas: [0.72258814]\n",
      "PERDIDAAAA antes: 0.13346776366233826\n",
      "Predicción post entrenamiento : [[0.35970208]]\n",
      "PERDIDAAAA despues: 0.1316862851381302\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "[[[0.35645089]\n",
      "  [0.35477495]\n",
      "  [0.35373044]\n",
      "  [0.35330695]\n",
      "  [0.35346964]\n",
      "  [0.35422143]\n",
      "  [0.35548201]\n",
      "  [0.35725573]]]\n",
      "ejemplar: [0.35645089 0.35477495 0.35373044 0.35330695 0.35346964 0.35422143\n",
      " 0.35548201 0.35725573]\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.35949394]]\n",
      "Lr que voy a aplicar en el lote: 50 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.35645089 0.35477495 0.35373044 0.35330695 0.35346964 0.35422143\n",
      "  0.35548201 0.35725573]]\n",
      "verdaderas salidas: [0.77179388]\n",
      "PERDIDAAAA antes: 0.16999125480651855\n",
      "Predicción post entrenamiento : [[0.36233652]]\n",
      "PERDIDAAAA despues: 0.167655348777771\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "[[[0.35477495]\n",
      "  [0.35373044]\n",
      "  [0.35330695]\n",
      "  [0.35346964]\n",
      "  [0.35422143]\n",
      "  [0.35548201]\n",
      "  [0.35725573]\n",
      "  [0.35949394]]]\n",
      "ejemplar: [0.35477495 0.35373044 0.35330695 0.35346964 0.35422143 0.35548201\n",
      " 0.35725573 0.35949394]\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.36223453]]\n",
      "Lr que voy a aplicar en el lote: 51 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.35477495 0.35373044 0.35330695 0.35346964 0.35422143 0.35548201\n",
      "  0.35725573 0.35949394]]\n",
      "verdaderas salidas: [0.72452538]\n",
      "PERDIDAAAA antes: 0.1312546730041504\n",
      "Predicción post entrenamiento : [[0.36536202]]\n",
      "PERDIDAAAA despues: 0.12899832427501678\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "[[[0.35373044]\n",
      "  [0.35330695]\n",
      "  [0.35346964]\n",
      "  [0.35422143]\n",
      "  [0.35548201]\n",
      "  [0.35725573]\n",
      "  [0.35949394]\n",
      "  [0.36223453]]]\n",
      "ejemplar: [0.35373044 0.35330695 0.35346964 0.35422143 0.35548201 0.35725573\n",
      " 0.35949394 0.36223453]\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.36537]]\n",
      "Lr que voy a aplicar en el lote: 52 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.35373044 0.35330695 0.35346964 0.35422143 0.35548201 0.35725573\n",
      "  0.35949394 0.36223453]]\n",
      "verdaderas salidas: [0.67105773]\n",
      "PERDIDAAAA antes: 0.09344496577978134\n",
      "Predicción post entrenamiento : [[0.36866996]]\n",
      "PERDIDAAAA despues: 0.09143834561109543\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "[[[0.35330695]\n",
      "  [0.35346964]\n",
      "  [0.35422143]\n",
      "  [0.35548201]\n",
      "  [0.35725573]\n",
      "  [0.35949394]\n",
      "  [0.36223453]\n",
      "  [0.36537001]]]\n",
      "ejemplar: [0.35330695 0.35346964 0.35422143 0.35548201 0.35725573 0.35949394\n",
      " 0.36223453 0.36537001]\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.36878502]]\n",
      "Lr que voy a aplicar en el lote: 53 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.35330695 0.35346964 0.35422143 0.35548201 0.35725573 0.35949394\n",
      "  0.36223453 0.36537001]]\n",
      "verdaderas salidas: [0.67376986]\n",
      "PERDIDAAAA antes: 0.09301573038101196\n",
      "Predicción post entrenamiento : [[0.3722546]]\n",
      "PERDIDAAAA despues: 0.09091142565011978\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "[[[0.35346964]\n",
      "  [0.35422143]\n",
      "  [0.35548201]\n",
      "  [0.35725573]\n",
      "  [0.35949394]\n",
      "  [0.36223453]\n",
      "  [0.36537001]\n",
      "  [0.36878502]]]\n",
      "ejemplar: [0.35346964 0.35422143 0.35548201 0.35725573 0.35949394 0.36223453\n",
      " 0.36537001 0.36878502]\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.37247318]]\n",
      "Lr que voy a aplicar en el lote: 54 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.35346964 0.35422143 0.35548201 0.35725573 0.35949394 0.36223453\n",
      "  0.36537001 0.36878502]]\n",
      "verdaderas salidas: [0.71445176]\n",
      "PERDIDAAAA antes: 0.11694937199354172\n",
      "Predicción post entrenamiento : [[0.37616733]]\n",
      "PERDIDAAAA despues: 0.11443638056516647\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "[[[0.35422143]\n",
      "  [0.35548201]\n",
      "  [0.35725573]\n",
      "  [0.35949394]\n",
      "  [0.36223453]\n",
      "  [0.36537001]\n",
      "  [0.36878502]\n",
      "  [0.37247318]]]\n",
      "ejemplar: [0.35422143 0.35548201 0.35725573 0.35949394 0.36223453 0.36537001\n",
      " 0.36878502 0.37247318]\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.37648568]]\n",
      "Lr que voy a aplicar en el lote: 55 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.35422143 0.35548201 0.35725573 0.35949394 0.36223453 0.36537001\n",
      "  0.36878502 0.37247318]]\n",
      "verdaderas salidas: [0.74389771]\n",
      "PERDIDAAAA antes: 0.1349916160106659\n",
      "Predicción post entrenamiento : [[0.3804045]]\n",
      "PERDIDAAAA despues: 0.1321273297071457\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "[[[0.35548201]\n",
      "  [0.35725573]\n",
      "  [0.35949394]\n",
      "  [0.36223453]\n",
      "  [0.36537001]\n",
      "  [0.36878502]\n",
      "  [0.37247318]\n",
      "  [0.37648568]]]\n",
      "ejemplar: [0.35548201 0.35725573 0.35949394 0.36223453 0.36537001 0.36878502\n",
      " 0.37247318 0.37648568]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.3808167]]\n",
      "Lr que voy a aplicar en el lote: 56 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.35548201 0.35725573 0.35949394 0.36223453 0.36537001 0.36878502\n",
      "  0.37247318 0.37648568]]\n",
      "verdaderas salidas: [0.72258814]\n",
      "PERDIDAAAA antes: 0.11680770665407181\n",
      "Predicción post entrenamiento : [[0.3849472]]\n",
      "PERDIDAAAA despues: 0.11400138586759567\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "[[[0.35725573]\n",
      "  [0.35949394]\n",
      "  [0.36223453]\n",
      "  [0.36537001]\n",
      "  [0.36878502]\n",
      "  [0.37247318]\n",
      "  [0.37648568]\n",
      "  [0.3808167 ]]]\n",
      "ejemplar: [0.35725573 0.35949394 0.36223453 0.36537001 0.36878502 0.37247318\n",
      " 0.37648568 0.3808167 ]\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.38544983]]\n",
      "Lr que voy a aplicar en el lote: 57 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.35725573 0.35949394 0.36223453 0.36537001 0.36878502 0.37247318\n",
      "  0.37648568 0.3808167 ]]\n",
      "verdaderas salidas: [0.69934134]\n",
      "PERDIDAAAA antes: 0.09852789342403412\n",
      "Predicción post entrenamiento : [[0.3897265]]\n",
      "PERDIDAAAA despues: 0.09586136788129807\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "[[[0.35949394]\n",
      "  [0.36223453]\n",
      "  [0.36537001]\n",
      "  [0.36878502]\n",
      "  [0.37247318]\n",
      "  [0.37648568]\n",
      "  [0.3808167 ]\n",
      "  [0.38544983]]]\n",
      "ejemplar: [0.35949394 0.36223453 0.36537001 0.36878502 0.37247318 0.37648568\n",
      " 0.3808167  0.38544983]\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.39031395]]\n",
      "Lr que voy a aplicar en el lote: 58 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.35949394 0.36223453 0.36537001 0.36878502 0.37247318 0.37648568\n",
      "  0.3808167  0.38544983]]\n",
      "verdaderas salidas: [0.73731112]\n",
      "PERDIDAAAA antes: 0.12040703743696213\n",
      "Predicción post entrenamiento : [[0.39480567]]\n",
      "PERDIDAAAA despues: 0.11730998754501343\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "[[[0.36223453]\n",
      "  [0.36537001]\n",
      "  [0.36878502]\n",
      "  [0.37247318]\n",
      "  [0.37648568]\n",
      "  [0.3808167 ]\n",
      "  [0.38544983]\n",
      "  [0.39031395]]]\n",
      "ejemplar: [0.36223453 0.36537001 0.36878502 0.37247318 0.37648568 0.3808167\n",
      " 0.38544983 0.39031395]\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.39547345]]\n",
      "Lr que voy a aplicar en el lote: 59 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.36223453 0.36537001 0.36878502 0.37247318 0.37648568 0.3808167\n",
      "  0.38544983 0.39031395]]\n",
      "verdaderas salidas: [0.7214258]\n",
      "PERDIDAAAA antes: 0.10624495148658752\n",
      "Predicción post entrenamiento : [[0.40013587]]\n",
      "PERDIDAAAA despues: 0.10322723537683487\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "[[[0.36537001]\n",
      "  [0.36878502]\n",
      "  [0.37247318]\n",
      "  [0.37648568]\n",
      "  [0.3808167 ]\n",
      "  [0.38544983]\n",
      "  [0.39031395]\n",
      "  [0.39547345]]]\n",
      "ejemplar: [0.36537001 0.36878502 0.37247318 0.37648568 0.3808167  0.38544983\n",
      " 0.39031395 0.39547345]\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.40087515]]\n",
      "Lr que voy a aplicar en el lote: 60 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.36537001 0.36878502 0.37247318 0.37648568 0.3808167  0.38544983\n",
      "  0.39031395 0.39547345]]\n",
      "verdaderas salidas: [0.71871368]\n",
      "PERDIDAAAA antes: 0.10102134197950363\n",
      "Predicción post entrenamiento : [[0.40569347]]\n",
      "PERDIDAAAA despues: 0.09798166155815125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "[[[0.36878502]\n",
      "  [0.37247318]\n",
      "  [0.37648568]\n",
      "  [0.3808167 ]\n",
      "  [0.38544983]\n",
      "  [0.39031395]\n",
      "  [0.39547345]\n",
      "  [0.40087515]]]\n",
      "ejemplar: [0.36878502 0.37247318 0.37648568 0.3808167  0.38544983 0.39031395\n",
      " 0.39547345 0.40087515]\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.40650016]]\n",
      "Lr que voy a aplicar en el lote: 61 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.36878502 0.37247318 0.37648568 0.3808167  0.38544983 0.39031395\n",
      "  0.39547345 0.40087515]]\n",
      "verdaderas salidas: [0.6741573]\n",
      "PERDIDAAAA antes: 0.07164035737514496\n",
      "Predicción post entrenamiento : [[0.4113847]]\n",
      "PERDIDAAAA despues: 0.06904944777488708\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "[[[0.37247318]\n",
      "  [0.37648568]\n",
      "  [0.3808167 ]\n",
      "  [0.38544983]\n",
      "  [0.39031395]\n",
      "  [0.39547345]\n",
      "  [0.40087515]\n",
      "  [0.40650016]]]\n",
      "ejemplar: [0.37247318 0.37648568 0.3808167  0.38544983 0.39031395 0.39547345\n",
      " 0.40087515 0.40650016]\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.41226065]]\n",
      "Lr que voy a aplicar en el lote: 62 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.37247318 0.37648568 0.3808167  0.38544983 0.39031395 0.39547345\n",
      "  0.40087515 0.40650016]]\n",
      "verdaderas salidas: [0.69856645]\n",
      "PERDIDAAAA antes: 0.08197100460529327\n",
      "Predicción post entrenamiento : [[0.41726243]]\n",
      "PERDIDAAAA despues: 0.07913193851709366\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "[[[0.37648568]\n",
      "  [0.3808167 ]\n",
      "  [0.38544983]\n",
      "  [0.39031395]\n",
      "  [0.39547345]\n",
      "  [0.40087515]\n",
      "  [0.40650016]\n",
      "  [0.41226065]]]\n",
      "ejemplar: [0.37648568 0.3808167  0.38544983 0.39031395 0.39547345 0.40087515\n",
      " 0.40650016 0.41226065]\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.41820946]]\n",
      "Lr que voy a aplicar en el lote: 63 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.37648568 0.3808167  0.38544983 0.39031395 0.39547345 0.40087515\n",
      "  0.40650016 0.41226065]]\n",
      "verdaderas salidas: [0.72103836]\n",
      "PERDIDAAAA antes: 0.0917053297162056\n",
      "Predicción post entrenamiento : [[0.42336023]]\n",
      "PERDIDAAAA despues: 0.08861225843429565\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "[[[0.3808167 ]\n",
      "  [0.38544983]\n",
      "  [0.39031395]\n",
      "  [0.39547345]\n",
      "  [0.40087515]\n",
      "  [0.40650016]\n",
      "  [0.41226065]\n",
      "  [0.41820946]]]\n",
      "ejemplar: [0.3808167  0.38544983 0.39031395 0.39547345 0.40087515 0.40650016\n",
      " 0.41226065 0.41820946]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.42437676]]\n",
      "Lr que voy a aplicar en el lote: 64 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.3808167  0.38544983 0.39031395 0.39547345 0.40087515 0.40650016\n",
      "  0.41226065 0.41820946]]\n",
      "verdaderas salidas: [0.72258814]\n",
      "PERDIDAAAA antes: 0.08893001824617386\n",
      "Predicción post entrenamiento : [[0.42964408]]\n",
      "PERDIDAAAA despues: 0.08581621199846268\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "[[[0.38544983]\n",
      "  [0.39031395]\n",
      "  [0.39547345]\n",
      "  [0.40087515]\n",
      "  [0.40650016]\n",
      "  [0.41226065]\n",
      "  [0.41820946]\n",
      "  [0.42437676]]]\n",
      "ejemplar: [0.38544983 0.39031395 0.39547345 0.40087515 0.40650016 0.41226065\n",
      " 0.41820946 0.42437676]\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.43072698]]\n",
      "Lr que voy a aplicar en el lote: 65 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.38544983 0.39031395 0.39547345 0.40087515 0.40650016 0.41226065\n",
      "  0.41820946 0.42437676]]\n",
      "verdaderas salidas: [0.75629601]\n",
      "PERDIDAAAA antes: 0.10599521547555923\n",
      "Predicción post entrenamiento : [[0.43620005]]\n",
      "PERDIDAAAA despues: 0.10246144235134125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "[[[0.39031395]\n",
      "  [0.39547345]\n",
      "  [0.40087515]\n",
      "  [0.40650016]\n",
      "  [0.41226065]\n",
      "  [0.41820946]\n",
      "  [0.42437676]\n",
      "  [0.43072698]]]\n",
      "ejemplar: [0.39031395 0.39547345 0.40087515 0.40650016 0.41226065 0.41820946\n",
      " 0.42437676 0.43072698]\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.4373468]]\n",
      "Lr que voy a aplicar en el lote: 66 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.39031395 0.39547345 0.40087515 0.40650016 0.41226065 0.41820946\n",
      "  0.42437676 0.43072698]]\n",
      "verdaderas salidas: [0.82758621]\n",
      "PERDIDAAAA antes: 0.1522868275642395\n",
      "Predicción post entrenamiento : [[0.4431438]]\n",
      "PERDIDAAAA despues: 0.14779597520828247\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "[[[0.39547345]\n",
      "  [0.40087515]\n",
      "  [0.40650016]\n",
      "  [0.41226065]\n",
      "  [0.41820946]\n",
      "  [0.42437676]\n",
      "  [0.43072698]\n",
      "  [0.43734679]]]\n",
      "ejemplar: [0.39547345 0.40087515 0.40650016 0.41226065 0.41820946 0.42437676\n",
      " 0.43072698 0.43734679]\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.44435567]]\n",
      "Lr que voy a aplicar en el lote: 67 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.39547345 0.40087515 0.40650016 0.41226065 0.41820946 0.42437676\n",
      "  0.43072698 0.43734679]]\n",
      "verdaderas salidas: [0.83882216]\n",
      "PERDIDAAAA antes: 0.15560384094715118\n",
      "Predicción post entrenamiento : [[0.45046943]]\n",
      "PERDIDAAAA despues: 0.1508178561925888\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "[[[0.40087515]\n",
      "  [0.40650016]\n",
      "  [0.41226065]\n",
      "  [0.41820946]\n",
      "  [0.42437676]\n",
      "  [0.43072698]\n",
      "  [0.43734679]\n",
      "  [0.44435567]]]\n",
      "ejemplar: [0.40087515 0.40650016 0.41226065 0.41820946 0.42437676 0.43072698\n",
      " 0.43734679 0.44435567]\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.45174354]]\n",
      "Lr que voy a aplicar en el lote: 68 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.40087515 0.40650016 0.41226065 0.41820946 0.42437676 0.43072698\n",
      "  0.43734679 0.44435567]]\n",
      "verdaderas salidas: [0.79426579]\n",
      "PERDIDAAAA antes: 0.11732149869203568\n",
      "Predicción post entrenamiento : [[0.4580732]]\n",
      "PERDIDAAAA despues: 0.1130254715681076\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "[[[0.40650016]\n",
      "  [0.41226065]\n",
      "  [0.41820946]\n",
      "  [0.42437676]\n",
      "  [0.43072698]\n",
      "  [0.43734679]\n",
      "  [0.44435567]\n",
      "  [0.45174354]]]\n",
      "ejemplar: [0.40650016 0.41226065 0.41820946 0.42437676 0.43072698 0.43734679\n",
      " 0.44435567 0.45174354]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.45940953]]\n",
      "Lr que voy a aplicar en el lote: 69 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.40650016 0.41226065 0.41820946 0.42437676 0.43072698 0.43734679\n",
      "  0.44435567 0.45174354]]\n",
      "verdaderas salidas: [0.78380473]\n",
      "PERDIDAAAA antes: 0.10523223131895065\n",
      "Predicción post entrenamiento : [[0.46592116]]\n",
      "PERDIDAAAA despues: 0.10104995220899582\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "[[[0.41226065]\n",
      "  [0.41820946]\n",
      "  [0.42437676]\n",
      "  [0.43072698]\n",
      "  [0.43734679]\n",
      "  [0.44435567]\n",
      "  [0.45174354]\n",
      "  [0.45940953]]]\n",
      "ejemplar: [0.41226065 0.41820946 0.42437676 0.43072698 0.43734679 0.44435567\n",
      " 0.45174354 0.45940953]\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.467322]]\n",
      "Lr que voy a aplicar en el lote: 70 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.41226065 0.41820946 0.42437676 0.43072698 0.43734679 0.44435567\n",
      "  0.45174354 0.45940953]]\n",
      "verdaderas salidas: [0.76791941]\n",
      "PERDIDAAAA antes: 0.09035881608724594\n",
      "Predicción post entrenamiento : [[0.47394443]]\n",
      "PERDIDAAAA despues: 0.08642129600048065\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "[[[0.41820946]\n",
      "  [0.42437676]\n",
      "  [0.43072698]\n",
      "  [0.43734679]\n",
      "  [0.44435567]\n",
      "  [0.45174354]\n",
      "  [0.45940953]\n",
      "  [0.46732199]]]\n",
      "ejemplar: [0.41820946 0.42437676 0.43072698 0.43734679 0.44435567 0.45174354\n",
      " 0.45940953 0.46732199]\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.47541943]]\n",
      "Lr que voy a aplicar en el lote: 71 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.41820946 0.42437676 0.43072698 0.43734679 0.44435567 0.45174354\n",
      "  0.45940953 0.46732199]]\n",
      "verdaderas salidas: [0.78457962]\n",
      "PERDIDAAAA antes: 0.09558003395795822\n",
      "Predicción post entrenamiento : [[0.4821723]]\n",
      "PERDIDAAAA despues: 0.09145019203424454\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "[[[0.42437676]\n",
      "  [0.43072698]\n",
      "  [0.43734679]\n",
      "  [0.44435567]\n",
      "  [0.45174354]\n",
      "  [0.45940953]\n",
      "  [0.46732199]\n",
      "  [0.47541943]]]\n",
      "ejemplar: [0.42437676 0.43072698 0.43734679 0.44435567 0.45174354 0.45940953\n",
      " 0.46732199 0.47541943]\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.483729]]\n",
      "Lr que voy a aplicar en el lote: 72 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.42437676 0.43072698 0.43734679 0.44435567 0.45174354 0.45940953\n",
      "  0.46732199 0.47541943]]\n",
      "verdaderas salidas: [0.87872917]\n",
      "PERDIDAAAA antes: 0.15602512657642365\n",
      "Predicción post entrenamiento : [[0.49088642]]\n",
      "PERDIDAAAA despues: 0.15042199194431305\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "[[[0.43072698]\n",
      "  [0.43734679]\n",
      "  [0.44435567]\n",
      "  [0.45174354]\n",
      "  [0.45940953]\n",
      "  [0.46732199]\n",
      "  [0.47541943]\n",
      "  [0.483729  ]]]\n",
      "ejemplar: [0.43072698 0.43734679 0.44435567 0.45174354 0.45940953 0.46732199\n",
      " 0.47541943 0.483729  ]\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.4925323]]\n",
      "Lr que voy a aplicar en el lote: 73 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.43072698 0.43734679 0.44435567 0.45174354 0.45940953 0.46732199\n",
      "  0.47541943 0.483729  ]]\n",
      "verdaderas salidas: [0.8756296]\n",
      "PERDIDAAAA antes: 0.14676353335380554\n",
      "Predicción post entrenamiento : [[0.5000302]]\n",
      "PERDIDAAAA despues: 0.14107489585876465\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "[[[0.43734679]\n",
      "  [0.44435567]\n",
      "  [0.45174354]\n",
      "  [0.45940953]\n",
      "  [0.46732199]\n",
      "  [0.47541943]\n",
      "  [0.483729  ]\n",
      "  [0.49253231]]]\n",
      "ejemplar: [0.43734679 0.44435567 0.45174354 0.45940953 0.46732199 0.47541943\n",
      " 0.483729   0.49253231]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.5017764]]\n",
      "Lr que voy a aplicar en el lote: 74 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.43734679 0.44435567 0.45174354 0.45940953 0.46732199 0.47541943\n",
      "  0.483729   0.49253231]]\n",
      "verdaderas salidas: [0.84889578]\n",
      "PERDIDAAAA antes: 0.1204918697476387\n",
      "Predicción post entrenamiento : [[0.5095174]]\n",
      "PERDIDAAAA despues: 0.1151777133345604\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "[[[0.44435567]\n",
      "  [0.45174354]\n",
      "  [0.45940953]\n",
      "  [0.46732199]\n",
      "  [0.47541943]\n",
      "  [0.483729  ]\n",
      "  [0.49253231]\n",
      "  [0.5017764 ]]]\n",
      "ejemplar: [0.44435567 0.45174354 0.45940953 0.46732199 0.47541943 0.483729\n",
      " 0.49253231 0.5017764 ]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.5113697]]\n",
      "Lr que voy a aplicar en el lote: 75 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.44435567 0.45174354 0.45940953 0.46732199 0.47541943 0.483729\n",
      "  0.49253231 0.5017764 ]]\n",
      "verdaderas salidas: [0.81828749]\n",
      "PERDIDAAAA antes: 0.09419852495193481\n",
      "Predicción post entrenamiento : [[0.5192748]]\n",
      "PERDIDAAAA despues: 0.08940860629081726\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "[[[0.45174354]\n",
      "  [0.45940953]\n",
      "  [0.46732199]\n",
      "  [0.47541943]\n",
      "  [0.483729  ]\n",
      "  [0.49253231]\n",
      "  [0.5017764 ]\n",
      "  [0.51136971]]]\n",
      "ejemplar: [0.45174354 0.45940953 0.46732199 0.47541943 0.483729   0.49253231\n",
      " 0.5017764  0.51136971]\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.52123034]]\n",
      "Lr que voy a aplicar en el lote: 76 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.45174354 0.45940953 0.46732199 0.47541943 0.483729   0.49253231\n",
      "  0.5017764  0.51136971]]\n",
      "verdaderas salidas: [0.82681131]\n",
      "PERDIDAAAA antes: 0.09337972849607468\n",
      "Predicción post entrenamiento : [[0.5293161]]\n",
      "PERDIDAAAA despues: 0.0885033831000328\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "[[[0.45940953]\n",
      "  [0.46732199]\n",
      "  [0.47541943]\n",
      "  [0.483729  ]\n",
      "  [0.49253231]\n",
      "  [0.5017764 ]\n",
      "  [0.51136971]\n",
      "  [0.52123034]]]\n",
      "ejemplar: [0.45940953 0.46732199 0.47541943 0.483729   0.49253231 0.5017764\n",
      " 0.51136971 0.52123034]\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.53137195]]\n",
      "Lr que voy a aplicar en el lote: 77 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.45940953 0.46732199 0.47541943 0.483729   0.49253231 0.5017764\n",
      "  0.51136971 0.52123034]]\n",
      "verdaderas salidas: [0.78535451]\n",
      "PERDIDAAAA antes: 0.0645071342587471\n",
      "Predicción post entrenamiento : [[0.5395017]]\n",
      "PERDIDAAAA despues: 0.060443583875894547\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "[[[0.46732199]\n",
      "  [0.47541943]\n",
      "  [0.483729  ]\n",
      "  [0.49253231]\n",
      "  [0.5017764 ]\n",
      "  [0.51136971]\n",
      "  [0.52123034]\n",
      "  [0.53137195]]]\n",
      "ejemplar: [0.46732199 0.47541943 0.483729   0.49253231 0.5017764  0.51136971\n",
      " 0.52123034 0.53137195]\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.5416621]]\n",
      "Lr que voy a aplicar en el lote: 78 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.46732199 0.47541943 0.483729   0.49253231 0.5017764  0.51136971\n",
      "  0.52123034 0.53137195]]\n",
      "verdaderas salidas: [0.78922898]\n",
      "PERDIDAAAA antes: 0.061289358884096146\n",
      "Predicción post entrenamiento : [[0.5498795]]\n",
      "PERDIDAAAA despues: 0.05728817731142044\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "[[[0.47541943]\n",
      "  [0.483729  ]\n",
      "  [0.49253231]\n",
      "  [0.5017764 ]\n",
      "  [0.51136971]\n",
      "  [0.52123034]\n",
      "  [0.53137195]\n",
      "  [0.5416621 ]]]\n",
      "ejemplar: [0.47541943 0.483729   0.49253231 0.5017764  0.51136971 0.52123034\n",
      " 0.53137195 0.5416621 ]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.5521521]]\n",
      "Lr que voy a aplicar en el lote: 79 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.47541943 0.483729   0.49253231 0.5017764  0.51136971 0.52123034\n",
      "  0.53137195 0.5416621 ]]\n",
      "verdaderas salidas: [0.8341728]\n",
      "PERDIDAAAA antes: 0.07953567057847977\n",
      "Predicción post entrenamiento : [[0.56055033]]\n",
      "PERDIDAAAA despues: 0.07486924529075623\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "[[[0.483729  ]\n",
      "  [0.49253231]\n",
      "  [0.5017764 ]\n",
      "  [0.51136971]\n",
      "  [0.52123034]\n",
      "  [0.53137195]\n",
      "  [0.5416621 ]\n",
      "  [0.5521521 ]]]\n",
      "ejemplar: [0.483729   0.49253231 0.5017764  0.51136971 0.52123034 0.53137195\n",
      " 0.5416621  0.5521521 ]\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.5629497]]\n",
      "Lr que voy a aplicar en el lote: 80 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.483729   0.49253231 0.5017764  0.51136971 0.52123034 0.53137195\n",
      "  0.5416621  0.5521521 ]]\n",
      "verdaderas salidas: [0.81247578]\n",
      "PERDIDAAAA antes: 0.06226326525211334\n",
      "Predicción post entrenamiento : [[0.57155615]]\n",
      "PERDIDAAAA despues: 0.05804227665066719\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "[[[0.49253231]\n",
      "  [0.5017764 ]\n",
      "  [0.51136971]\n",
      "  [0.52123034]\n",
      "  [0.53137195]\n",
      "  [0.5416621 ]\n",
      "  [0.5521521 ]\n",
      "  [0.56294972]]]\n",
      "ejemplar: [0.49253231 0.5017764  0.51136971 0.52123034 0.53137195 0.5416621\n",
      " 0.5521521  0.56294972]\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.57409585]]\n",
      "Lr que voy a aplicar en el lote: 81 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.49253231 0.5017764  0.51136971 0.52123034 0.53137195 0.5416621\n",
      "  0.5521521  0.56294972]]\n",
      "verdaderas salidas: [0.80123983]\n",
      "PERDIDAAAA antes: 0.05159439891576767\n",
      "Predicción post entrenamiento : [[0.5826652]]\n",
      "PERDIDAAAA despues: 0.04777487367391586\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "[[[0.5017764 ]\n",
      "  [0.51136971]\n",
      "  [0.52123034]\n",
      "  [0.53137195]\n",
      "  [0.5416621 ]\n",
      "  [0.5521521 ]\n",
      "  [0.56294972]\n",
      "  [0.57409585]]]\n",
      "ejemplar: [0.5017764  0.51136971 0.52123034 0.53137195 0.5416621  0.5521521\n",
      " 0.56294972 0.57409585]\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.58533293]]\n",
      "Lr que voy a aplicar en el lote: 82 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.5017764  0.51136971 0.52123034 0.53137195 0.5416621  0.5521521\n",
      "  0.56294972 0.57409585]]\n",
      "verdaderas salidas: [0.80317706]\n",
      "PERDIDAAAA antes: 0.04745606333017349\n",
      "Predicción post entrenamiento : [[0.5939132]]\n",
      "PERDIDAAAA despues: 0.04379136487841606\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "[[[0.51136971]\n",
      "  [0.52123034]\n",
      "  [0.53137195]\n",
      "  [0.5416621 ]\n",
      "  [0.5521521 ]\n",
      "  [0.56294972]\n",
      "  [0.57409585]\n",
      "  [0.58533293]]]\n",
      "ejemplar: [0.51136971 0.52123034 0.53137195 0.5416621  0.5521521  0.56294972\n",
      " 0.57409585 0.58533293]\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.5966974]]\n",
      "Lr que voy a aplicar en el lote: 83 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.51136971 0.52123034 0.53137195 0.5416621  0.5521521  0.56294972\n",
      "  0.57409585 0.58533293]]\n",
      "verdaderas salidas: [0.7934909]\n",
      "PERDIDAAAA antes: 0.03872768208384514\n",
      "Predicción post entrenamiento : [[0.6053638]]\n",
      "PERDIDAAAA despues: 0.035391807556152344\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "[[[0.52123034]\n",
      "  [0.53137195]\n",
      "  [0.5416621 ]\n",
      "  [0.5521521 ]\n",
      "  [0.56294972]\n",
      "  [0.57409585]\n",
      "  [0.58533293]\n",
      "  [0.59669739]]]\n",
      "ejemplar: [0.52123034 0.53137195 0.5416621  0.5521521  0.56294972 0.57409585\n",
      " 0.58533293 0.59669739]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.6082581]]\n",
      "Lr que voy a aplicar en el lote: 84 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.52123034 0.53137195 0.5416621  0.5521521  0.56294972 0.57409585\n",
      "  0.58533293 0.59669739]]\n",
      "verdaderas salidas: [0.76017048]\n",
      "PERDIDAAAA antes: 0.023077355697751045\n",
      "Predicción post entrenamiento : [[0.61690235]]\n",
      "PERDIDAAAA despues: 0.020525751635432243\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "[[[0.53137195]\n",
      "  [0.5416621 ]\n",
      "  [0.5521521 ]\n",
      "  [0.56294972]\n",
      "  [0.57409585]\n",
      "  [0.58533293]\n",
      "  [0.59669739]\n",
      "  [0.60825813]]]\n",
      "ejemplar: [0.53137195 0.5416621  0.5521521  0.56294972 0.57409585 0.58533293\n",
      " 0.59669739 0.60825813]\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.6199057]]\n",
      "Lr que voy a aplicar en el lote: 85 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.53137195 0.5416621  0.5521521  0.56294972 0.57409585 0.58533293\n",
      "  0.59669739 0.60825813]]\n",
      "verdaderas salidas: [0.73537389]\n",
      "PERDIDAAAA antes: 0.013332906179130077\n",
      "Predicción post entrenamiento : [[0.62799877]]\n",
      "PERDIDAAAA despues: 0.01152942143380642\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "[[[0.5416621 ]\n",
      "  [0.5521521 ]\n",
      "  [0.56294972]\n",
      "  [0.57409585]\n",
      "  [0.58533293]\n",
      "  [0.59669739]\n",
      "  [0.60825813]\n",
      "  [0.61990571]]]\n",
      "ejemplar: [0.5416621  0.5521521  0.56294972 0.57409585 0.58533293 0.59669739\n",
      " 0.60825813 0.61990571]\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.6311029]]\n",
      "Lr que voy a aplicar en el lote: 86 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.5416621  0.5521521  0.56294972 0.57409585 0.58533293 0.59669739\n",
      "  0.60825813 0.61990571]]\n",
      "verdaderas salidas: [0.71018985]\n",
      "PERDIDAAAA antes: 0.006254737731069326\n",
      "Predicción post entrenamiento : [[0.63882214]]\n",
      "PERDIDAAAA despues: 0.005093345884233713\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "[[[0.5521521 ]\n",
      "  [0.56294972]\n",
      "  [0.57409585]\n",
      "  [0.58533293]\n",
      "  [0.59669739]\n",
      "  [0.60825813]\n",
      "  [0.61990571]\n",
      "  [0.63110292]]]\n",
      "ejemplar: [0.5521521  0.56294972 0.57409585 0.58533293 0.59669739 0.60825813\n",
      " 0.61990571 0.63110292]\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.6420306]]\n",
      "Lr que voy a aplicar en el lote: 87 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.5521521  0.56294972 0.57409585 0.58533293 0.59669739 0.60825813\n",
      "  0.61990571 0.63110292]]\n",
      "verdaderas salidas: [0.71212708]\n",
      "PERDIDAAAA antes: 0.004913518205285072\n",
      "Predicción post entrenamiento : [[0.64934087]]\n",
      "PERDIDAAAA despues: 0.003942109644412994\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "[[[0.56294972]\n",
      "  [0.57409585]\n",
      "  [0.58533293]\n",
      "  [0.59669739]\n",
      "  [0.60825813]\n",
      "  [0.61990571]\n",
      "  [0.63110292]\n",
      "  [0.6420306 ]]]\n",
      "ejemplar: [0.56294972 0.57409585 0.58533293 0.59669739 0.60825813 0.61990571\n",
      " 0.63110292 0.6420306 ]\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.65264904]]\n",
      "Lr que voy a aplicar en el lote: 88 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.56294972 0.57409585 0.58533293 0.59669739 0.60825813 0.61990571\n",
      "  0.63110292 0.6420306 ]]\n",
      "verdaderas salidas: [0.7396358]\n",
      "PERDIDAAAA antes: 0.007566699758172035\n",
      "Predicción post entrenamiento : [[0.6597113]]\n",
      "PERDIDAAAA despues: 0.006387929432094097\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "[[[0.57409585]\n",
      "  [0.58533293]\n",
      "  [0.59669739]\n",
      "  [0.60825813]\n",
      "  [0.61990571]\n",
      "  [0.63110292]\n",
      "  [0.6420306 ]\n",
      "  [0.65264904]]]\n",
      "ejemplar: [0.57409585 0.58533293 0.59669739 0.60825813 0.61990571 0.63110292\n",
      " 0.6420306  0.65264904]\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.6630991]]\n",
      "Lr que voy a aplicar en el lote: 89 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.57409585 0.58533293 0.59669739 0.60825813 0.61990571 0.63110292\n",
      "  0.6420306  0.65264904]]\n",
      "verdaderas salidas: [0.73614878]\n",
      "PERDIDAAAA antes: 0.005336253438144922\n",
      "Predicción post entrenamiento : [[0.6696047]]\n",
      "PERDIDAAAA despues: 0.004428111482411623\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "[[[0.58533293]\n",
      "  [0.59669739]\n",
      "  [0.60825813]\n",
      "  [0.61990571]\n",
      "  [0.63110292]\n",
      "  [0.6420306 ]\n",
      "  [0.65264904]\n",
      "  [0.66309911]]]\n",
      "ejemplar: [0.58533293 0.59669739 0.60825813 0.61990571 0.63110292 0.6420306\n",
      " 0.65264904 0.66309911]\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.673038]]\n",
      "Lr que voy a aplicar en el lote: 90 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.58533293 0.59669739 0.60825813 0.61990571 0.63110292 0.6420306\n",
      "  0.65264904 0.66309911]]\n",
      "verdaderas salidas: [0.66757071]\n",
      "PERDIDAAAA antes: 2.9891321901232004e-05\n",
      "Predicción post entrenamiento : [[0.6790892]]\n",
      "PERDIDAAAA despues: 0.00013267534086480737\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "[[[0.59669739]\n",
      "  [0.60825813]\n",
      "  [0.61990571]\n",
      "  [0.63110292]\n",
      "  [0.6420306 ]\n",
      "  [0.65264904]\n",
      "  [0.66309911]\n",
      "  [0.67303801]]]\n",
      "ejemplar: [0.59669739 0.60825813 0.61990571 0.63110292 0.6420306  0.65264904\n",
      " 0.66309911 0.67303801]\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.68255013]]\n",
      "Lr que voy a aplicar en el lote: 91 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.59669739 0.60825813 0.61990571 0.63110292 0.6420306  0.65264904\n",
      "  0.66309911 0.67303801]]\n",
      "verdaderas salidas: [0.66989539]\n",
      "PERDIDAAAA antes: 0.0001601419789949432\n",
      "Predicción post entrenamiento : [[0.6878429]]\n",
      "PERDIDAAAA despues: 0.00032211258076131344\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "[[[0.60825813]\n",
      "  [0.61990571]\n",
      "  [0.63110292]\n",
      "  [0.6420306 ]\n",
      "  [0.65264904]\n",
      "  [0.66309911]\n",
      "  [0.67303801]\n",
      "  [0.68255013]]]\n",
      "ejemplar: [0.60825813 0.61990571 0.63110292 0.6420306  0.65264904 0.66309911\n",
      " 0.67303801 0.68255013]\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.691301]]\n",
      "Lr que voy a aplicar en el lote: 92 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.60825813 0.61990571 0.63110292 0.6420306  0.65264904 0.66309911\n",
      "  0.67303801 0.68255013]]\n",
      "verdaderas salidas: [0.69662921]\n",
      "PERDIDAAAA antes: 2.839012086042203e-05\n",
      "Predicción post entrenamiento : [[0.6961739]]\n",
      "PERDIDAAAA despues: 2.0731619088110165e-07\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "[[[0.61990571]\n",
      "  [0.63110292]\n",
      "  [0.6420306 ]\n",
      "  [0.65264904]\n",
      "  [0.66309911]\n",
      "  [0.67303801]\n",
      "  [0.68255013]\n",
      "  [0.69130099]]]\n",
      "ejemplar: [0.61990571 0.63110292 0.6420306  0.65264904 0.66309911 0.67303801\n",
      " 0.68255013 0.69130099]\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.6995845]]\n",
      "Lr que voy a aplicar en el lote: 93 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.61990571 0.63110292 0.6420306  0.65264904 0.66309911 0.67303801\n",
      "  0.68255013 0.69130099]]\n",
      "verdaderas salidas: [0.65594731]\n",
      "PERDIDAAAA antes: 0.0019042014610022306\n",
      "Predicción post entrenamiento : [[0.70358413]]\n",
      "PERDIDAAAA despues: 0.0022692654747515917\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "[[[0.63110292]\n",
      "  [0.6420306 ]\n",
      "  [0.65264904]\n",
      "  [0.66309911]\n",
      "  [0.67303801]\n",
      "  [0.68255013]\n",
      "  [0.69130099]\n",
      "  [0.69958448]]]\n",
      "ejemplar: [0.63110292 0.6420306  0.65264904 0.66309911 0.67303801 0.68255013\n",
      " 0.69130099 0.69958448]\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.70689994]]\n",
      "Lr que voy a aplicar en el lote: 94 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.63110292 0.6420306  0.65264904 0.66309911 0.67303801 0.68255013\n",
      "  0.69130099 0.69958448]]\n",
      "verdaderas salidas: [0.67880666]\n",
      "PERDIDAAAA antes: 0.0007892323192209005\n",
      "Predicción post entrenamiento : [[0.7099965]]\n",
      "PERDIDAAAA despues: 0.0009728072909638286\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "[[[0.6420306 ]\n",
      "  [0.65264904]\n",
      "  [0.66309911]\n",
      "  [0.67303801]\n",
      "  [0.68255013]\n",
      "  [0.69130099]\n",
      "  [0.69958448]\n",
      "  [0.70689994]]]\n",
      "ejemplar: [0.6420306  0.65264904 0.66309911 0.67303801 0.68255013 0.69130099\n",
      " 0.69958448 0.70689994]\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.71321696]]\n",
      "Lr que voy a aplicar en el lote: 95 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.6420306  0.65264904 0.66309911 0.67303801 0.68255013 0.69130099\n",
      "  0.69958448 0.70689994]]\n",
      "verdaderas salidas: [0.67609454]\n",
      "PERDIDAAAA antes: 0.0013780746376141906\n",
      "Predicción post entrenamiento : [[0.7157227]]\n",
      "PERDIDAAAA despues: 0.0015703900717198849\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "[[[0.65264904]\n",
      "  [0.66309911]\n",
      "  [0.67303801]\n",
      "  [0.68255013]\n",
      "  [0.69130099]\n",
      "  [0.69958448]\n",
      "  [0.70689994]\n",
      "  [0.71321696]]]\n",
      "ejemplar: [0.65264904 0.66309911 0.67303801 0.68255013 0.69130099 0.69958448\n",
      " 0.70689994 0.71321696]\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.7188268]]\n",
      "Lr que voy a aplicar en el lote: 96 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.65264904 0.66309911 0.67303801 0.68255013 0.69130099 0.69958448\n",
      "  0.70689994 0.71321696]]\n",
      "verdaderas salidas: [0.72956219]\n",
      "PERDIDAAAA antes: 0.00011524865112733096\n",
      "Predicción post entrenamiento : [[0.72098905]]\n",
      "PERDIDAAAA despues: 7.349829684244469e-05\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "[[[0.66309911]\n",
      "  [0.67303801]\n",
      "  [0.68255013]\n",
      "  [0.69130099]\n",
      "  [0.69958448]\n",
      "  [0.70689994]\n",
      "  [0.71321696]\n",
      "  [0.71882677]]]\n",
      "ejemplar: [0.66309911 0.67303801 0.68255013 0.69130099 0.69958448 0.70689994\n",
      " 0.71321696 0.71882677]\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.7239539]]\n",
      "Lr que voy a aplicar en el lote: 97 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.66309911 0.67303801 0.68255013 0.69130099 0.69958448 0.70689994\n",
      "  0.71321696 0.71882677]]\n",
      "verdaderas salidas: [0.70127857]\n",
      "PERDIDAAAA antes: 0.000514170853421092\n",
      "Predicción post entrenamiento : [[0.7263764]]\n",
      "PERDIDAAAA despues: 0.000629901944193989\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "[[[0.67303801]\n",
      "  [0.68255013]\n",
      "  [0.69130099]\n",
      "  [0.69958448]\n",
      "  [0.70689994]\n",
      "  [0.71321696]\n",
      "  [0.71882677]\n",
      "  [0.7239539 ]]]\n",
      "ejemplar: [0.67303801 0.68255013 0.69130099 0.69958448 0.70689994 0.71321696\n",
      " 0.71882677 0.7239539 ]\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.72916013]]\n",
      "Lr que voy a aplicar en el lote: 98 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.67303801 0.68255013 0.69130099 0.69958448 0.70689994 0.71321696\n",
      "  0.71882677 0.7239539 ]]\n",
      "verdaderas salidas: [0.76753196]\n",
      "PERDIDAAAA antes: 0.0014723996864631772\n",
      "Predicción post entrenamiento : [[0.7317295]]\n",
      "PERDIDAAAA despues: 0.0012818177929148078\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "[[[0.68255013]\n",
      "  [0.69130099]\n",
      "  [0.69958448]\n",
      "  [0.70689994]\n",
      "  [0.71321696]\n",
      "  [0.71882677]\n",
      "  [0.7239539 ]\n",
      "  [0.72916013]]]\n",
      "ejemplar: [0.68255013 0.69130099 0.69958448 0.70689994 0.71321696 0.71882677\n",
      " 0.7239539  0.72916013]\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.73431796]]\n",
      "Lr que voy a aplicar en el lote: 99 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.68255013 0.69130099 0.69958448 0.70689994 0.71321696 0.71882677\n",
      "  0.7239539  0.72916013]]\n",
      "verdaderas salidas: [0.75513367]\n",
      "PERDIDAAAA antes: 0.00043329462641850114\n",
      "Predicción post entrenamiento : [[0.7367391]]\n",
      "PERDIDAAAA despues: 0.00033836092916317284\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "[[[0.69130099]\n",
      "  [0.69958448]\n",
      "  [0.70689994]\n",
      "  [0.71321696]\n",
      "  [0.71882677]\n",
      "  [0.7239539 ]\n",
      "  [0.72916013]\n",
      "  [0.73431796]]]\n",
      "ejemplar: [0.69130099 0.69958448 0.70689994 0.71321696 0.71882677 0.7239539\n",
      " 0.72916013 0.73431796]\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.7391074]]\n",
      "Lr que voy a aplicar en el lote: 100 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.69130099 0.69958448 0.70689994 0.71321696 0.71882677 0.7239539\n",
      "  0.72916013 0.73431796]]\n",
      "verdaderas salidas: [0.74506005]\n",
      "PERDIDAAAA antes: 3.543411730788648e-05\n",
      "Predicción post entrenamiento : [[0.7410635]]\n",
      "PERDIDAAAA despues: 1.597242044226732e-05\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "[[[0.69958448]\n",
      "  [0.70689994]\n",
      "  [0.71321696]\n",
      "  [0.71882677]\n",
      "  [0.7239539 ]\n",
      "  [0.72916013]\n",
      "  [0.73431796]\n",
      "  [0.73910737]]]\n",
      "ejemplar: [0.69958448 0.70689994 0.71321696 0.71882677 0.7239539  0.72916013\n",
      " 0.73431796 0.73910737]\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.7432221]]\n",
      "Lr que voy a aplicar en el lote: 101 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.69958448 0.70689994 0.71321696 0.71882677 0.7239539  0.72916013\n",
      "  0.73431796 0.73910737]]\n",
      "verdaderas salidas: [0.7520341]\n",
      "PERDIDAAAA antes: 7.765047485008836e-05\n",
      "Predicción post entrenamiento : [[0.7457638]]\n",
      "PERDIDAAAA despues: 3.931652827304788e-05\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "[[[0.70689994]\n",
      "  [0.71321696]\n",
      "  [0.71882677]\n",
      "  [0.7239539 ]\n",
      "  [0.72916013]\n",
      "  [0.73431796]\n",
      "  [0.73910737]\n",
      "  [0.74322212]]]\n",
      "ejemplar: [0.70689994 0.71321696 0.71882677 0.7239539  0.72916013 0.73431796\n",
      " 0.73910737 0.74322212]\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.7477027]]\n",
      "Lr que voy a aplicar en el lote: 102 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.70689994 0.71321696 0.71882677 0.7239539  0.72916013 0.73431796\n",
      "  0.73910737 0.74322212]]\n",
      "verdaderas salidas: [0.7098024]\n",
      "PERDIDAAAA antes: 0.001436434919014573\n",
      "Predicción post entrenamiento : [[0.7505015]]\n",
      "PERDIDAAAA despues: 0.0016564186662435532\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "[[[0.71321696]\n",
      "  [0.71882677]\n",
      "  [0.7239539 ]\n",
      "  [0.72916013]\n",
      "  [0.73431796]\n",
      "  [0.73910737]\n",
      "  [0.74322212]\n",
      "  [0.74770272]]]\n",
      "ejemplar: [0.71321696 0.71882677 0.7239539  0.72916013 0.73431796 0.73910737\n",
      " 0.74322212 0.74770272]\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.75226665]]\n",
      "Lr que voy a aplicar en el lote: 103 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.71321696 0.71882677 0.7239539  0.72916013 0.73431796 0.73910737\n",
      "  0.74322212 0.74770272]]\n",
      "verdaderas salidas: [0.69043007]\n",
      "PERDIDAAAA antes: 0.0038237650878727436\n",
      "Predicción post entrenamiento : [[0.7541537]]\n",
      "PERDIDAAAA despues: 0.004060707986354828\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "[[[0.71882677]\n",
      "  [0.7239539 ]\n",
      "  [0.72916013]\n",
      "  [0.73431796]\n",
      "  [0.73910737]\n",
      "  [0.74322212]\n",
      "  [0.74770272]\n",
      "  [0.75226665]]]\n",
      "ejemplar: [0.71882677 0.7239539  0.72916013 0.73431796 0.73910737 0.74322212\n",
      " 0.74770272 0.75226665]\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.7558052]]\n",
      "Lr que voy a aplicar en el lote: 104 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.71882677 0.7239539  0.72916013 0.73431796 0.73910737 0.74322212\n",
      "  0.74770272 0.75226665]]\n",
      "verdaderas salidas: [0.75435878]\n",
      "PERDIDAAAA antes: 2.0921479517710395e-06\n",
      "Predicción post entrenamiento : [[0.75681955]]\n",
      "PERDIDAAAA despues: 6.055427093087928e-06\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "[[[0.7239539 ]\n",
      "  [0.72916013]\n",
      "  [0.73431796]\n",
      "  [0.73910737]\n",
      "  [0.74322212]\n",
      "  [0.74770272]\n",
      "  [0.75226665]\n",
      "  [0.75580519]]]\n",
      "ejemplar: [0.7239539  0.72916013 0.73431796 0.73910737 0.74322212 0.74770272\n",
      " 0.75226665 0.75580519]\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.75840104]]\n",
      "Lr que voy a aplicar en el lote: 105 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.7239539  0.72916013 0.73431796 0.73910737 0.74322212 0.74770272\n",
      "  0.75226665 0.75580519]]\n",
      "verdaderas salidas: [0.7222007]\n",
      "PERDIDAAAA antes: 0.0013104649260640144\n",
      "Predicción post entrenamiento : [[0.7591805]]\n",
      "PERDIDAAAA despues: 0.0013675051741302013\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "[[[0.72916013]\n",
      "  [0.73431796]\n",
      "  [0.73910737]\n",
      "  [0.74322212]\n",
      "  [0.74770272]\n",
      "  [0.75226665]\n",
      "  [0.75580519]\n",
      "  [0.75840104]]]\n",
      "ejemplar: [0.72916013 0.73431796 0.73910737 0.74322212 0.74770272 0.75226665\n",
      " 0.75580519 0.75840104]\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.7607186]]\n",
      "Lr que voy a aplicar en el lote: 106 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.72916013 0.73431796 0.73910737 0.74322212 0.74770272 0.75226665\n",
      "  0.75580519 0.75840104]]\n",
      "verdaderas salidas: [0.84850833]\n",
      "PERDIDAAAA antes: 0.00770704448223114\n",
      "Predicción post entrenamiento : [[0.7621799]]\n",
      "PERDIDAAAA despues: 0.007452600635588169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "[[[0.73431796]\n",
      "  [0.73910737]\n",
      "  [0.74322212]\n",
      "  [0.74770272]\n",
      "  [0.75226665]\n",
      "  [0.75580519]\n",
      "  [0.75840104]\n",
      "  [0.76071858]]]\n",
      "ejemplar: [0.73431796 0.73910737 0.74322212 0.74770272 0.75226665 0.75580519\n",
      " 0.75840104 0.76071858]\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.7636432]]\n",
      "Lr que voy a aplicar en el lote: 107 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.73431796 0.73910737 0.74322212 0.74770272 0.75226665 0.75580519\n",
      "  0.75840104 0.76071858]]\n",
      "verdaderas salidas: [0.905463]\n",
      "PERDIDAAAA antes: 0.02011284790933132\n",
      "Predicción post entrenamiento : [[0.7662074]]\n",
      "PERDIDAAAA despues: 0.019392117857933044\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "[[[0.73910737]\n",
      "  [0.74322212]\n",
      "  [0.74770272]\n",
      "  [0.75226665]\n",
      "  [0.75580519]\n",
      "  [0.75840104]\n",
      "  [0.76071858]\n",
      "  [0.76364321]]]\n",
      "ejemplar: [0.73910737 0.74322212 0.74770272 0.75226665 0.75580519 0.75840104\n",
      " 0.76071858 0.76364321]\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.7675716]]\n",
      "Lr que voy a aplicar en el lote: 108 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.73910737 0.74322212 0.74770272 0.75226665 0.75580519 0.75840104\n",
      "  0.76071858 0.76364321]]\n",
      "verdaderas salidas: [0.8822162]\n",
      "PERDIDAAAA antes: 0.013143381103873253\n",
      "Predicción post entrenamiento : [[0.770372]]\n",
      "PERDIDAAAA despues: 0.012509134598076344\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "[[[0.74322212]\n",
      "  [0.74770272]\n",
      "  [0.75226665]\n",
      "  [0.75580519]\n",
      "  [0.75840104]\n",
      "  [0.76071858]\n",
      "  [0.76364321]\n",
      "  [0.76757163]]]\n",
      "ejemplar: [0.74322212 0.74770272 0.75226665 0.75580519 0.75840104 0.76071858\n",
      " 0.76364321 0.76757163]\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.77164465]]\n",
      "Lr que voy a aplicar en el lote: 109 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.74322212 0.74770272 0.75226665 0.75580519 0.75840104 0.76071858\n",
      "  0.76364321 0.76757163]]\n",
      "verdaderas salidas: [0.90778768]\n",
      "PERDIDAAAA antes: 0.01853492483496666\n",
      "Predicción post entrenamiento : [[0.7753518]]\n",
      "PERDIDAAAA despues: 0.017539257183670998\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "[[[0.74770272]\n",
      "  [0.75226665]\n",
      "  [0.75580519]\n",
      "  [0.75840104]\n",
      "  [0.76071858]\n",
      "  [0.76364321]\n",
      "  [0.76757163]\n",
      "  [0.77164465]]]\n",
      "ejemplar: [0.74770272 0.75226665 0.75580519 0.75840104 0.76071858 0.76364321\n",
      " 0.76757163 0.77164465]\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.7765825]]\n",
      "Lr que voy a aplicar en el lote: 110 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.74770272 0.75226665 0.75580519 0.75840104 0.76071858 0.76364321\n",
      "  0.76757163 0.77164465]]\n",
      "verdaderas salidas: [0.88957768]\n",
      "PERDIDAAAA antes: 0.012767916545271873\n",
      "Predicción post entrenamiento : [[0.7808448]]\n",
      "PERDIDAAAA despues: 0.011822839267551899\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "[[[0.75226665]\n",
      "  [0.75580519]\n",
      "  [0.75840104]\n",
      "  [0.76071858]\n",
      "  [0.76364321]\n",
      "  [0.76757163]\n",
      "  [0.77164465]\n",
      "  [0.77658248]]]\n",
      "ejemplar: [0.75226665 0.75580519 0.75840104 0.76071858 0.76364321 0.76757163\n",
      " 0.77164465 0.77658248]\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.781981]]\n",
      "Lr que voy a aplicar en el lote: 111 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.75226665 0.75580519 0.75840104 0.76071858 0.76364321 0.76757163\n",
      "  0.77164465 0.77658248]]\n",
      "verdaderas salidas: [0.87485471]\n",
      "PERDIDAAAA antes: 0.008625523187220097\n",
      "Predicción post entrenamiento : [[0.7866248]]\n",
      "PERDIDAAAA despues: 0.007784514222294092\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "[[[0.75580519]\n",
      "  [0.75840104]\n",
      "  [0.76071858]\n",
      "  [0.76364321]\n",
      "  [0.76757163]\n",
      "  [0.77164465]\n",
      "  [0.77658248]\n",
      "  [0.78198099]]]\n",
      "ejemplar: [0.75580519 0.75840104 0.76071858 0.76364321 0.76757163 0.77164465\n",
      " 0.77658248 0.78198099]\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.7876454]]\n",
      "Lr que voy a aplicar en el lote: 112 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.75580519 0.75840104 0.76071858 0.76364321 0.76757163 0.77164465\n",
      "  0.77658248 0.78198099]]\n",
      "verdaderas salidas: [0.91321193]\n",
      "PERDIDAAAA antes: 0.01576695591211319\n",
      "Predicción post entrenamiento : [[0.7931407]]\n",
      "PERDIDAAAA despues: 0.014417100697755814\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "[[[0.75840104]\n",
      "  [0.76071858]\n",
      "  [0.76364321]\n",
      "  [0.76757163]\n",
      "  [0.77164465]\n",
      "  [0.77658248]\n",
      "  [0.78198099]\n",
      "  [0.7876454 ]]]\n",
      "ejemplar: [0.75840104 0.76071858 0.76364321 0.76757163 0.77164465 0.77658248\n",
      " 0.78198099 0.7876454 ]\n",
      "y: 1.0\n",
      "Predicción : [[0.79415846]]\n",
      "Lr que voy a aplicar en el lote: 113 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.75840104 0.76071858 0.76364321 0.76757163 0.77164465 0.77658248\n",
      "  0.78198099 0.7876454 ]]\n",
      "verdaderas salidas: [1.]\n",
      "PERDIDAAAA antes: 0.042370740324258804\n",
      "Predicción post entrenamiento : [[0.80066544]]\n",
      "PERDIDAAAA despues: 0.03973426669836044\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "[[[0.76071858]\n",
      "  [0.76364321]\n",
      "  [0.76757163]\n",
      "  [0.77164465]\n",
      "  [0.77658248]\n",
      "  [0.78198099]\n",
      "  [0.7876454 ]\n",
      "  [0.79415846]]]\n",
      "ejemplar: [0.76071858 0.76364321 0.76757163 0.77164465 0.77658248 0.78198099\n",
      " 0.7876454  0.79415846]\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.80181634]]\n",
      "Lr que voy a aplicar en el lote: 114 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.76071858 0.76364321 0.76757163 0.77164465 0.77658248 0.78198099\n",
      "  0.7876454  0.79415846]]\n",
      "verdaderas salidas: [0.97055405]\n",
      "PERDIDAAAA antes: 0.02847241424024105\n",
      "Predicción post entrenamiento : [[0.80878985]]\n",
      "PERDIDAAAA despues: 0.02616765722632408\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "[[[0.76364321]\n",
      "  [0.76757163]\n",
      "  [0.77164465]\n",
      "  [0.77658248]\n",
      "  [0.78198099]\n",
      "  [0.7876454 ]\n",
      "  [0.79415846]\n",
      "  [0.80181634]]]\n",
      "ejemplar: [0.76364321 0.76757163 0.77164465 0.77658248 0.78198099 0.7876454\n",
      " 0.79415846 0.80181634]\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.8101647]]\n",
      "Lr que voy a aplicar en el lote: 115 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.76364321 0.76757163 0.77164465 0.77658248 0.78198099 0.7876454\n",
      "  0.79415846 0.80181634]]\n",
      "verdaderas salidas: [0.88880279]\n",
      "PERDIDAAAA antes: 0.006183946970850229\n",
      "Predicción post entrenamiento : [[0.81725943]]\n",
      "PERDIDAAAA despues: 0.005118448752909899\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "[[[0.76757163]\n",
      "  [0.77164465]\n",
      "  [0.77658248]\n",
      "  [0.78198099]\n",
      "  [0.7876454 ]\n",
      "  [0.79415846]\n",
      "  [0.80181634]\n",
      "  [0.81016469]]]\n",
      "ejemplar: [0.76757163 0.77164465 0.77658248 0.78198099 0.7876454  0.79415846\n",
      " 0.80181634 0.81016469]\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.81886506]]\n",
      "Lr que voy a aplicar en el lote: 116 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.76757163 0.77164465 0.77658248 0.78198099 0.7876454  0.79415846\n",
      "  0.80181634 0.81016469]]\n",
      "verdaderas salidas: [0.87795428]\n",
      "PERDIDAAAA antes: 0.0034915385767817497\n",
      "Predicción post entrenamiento : [[0.82679725]]\n",
      "PERDIDAAAA despues: 0.0026170446071773767\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "[[[0.77164465]\n",
      "  [0.77658248]\n",
      "  [0.78198099]\n",
      "  [0.7876454 ]\n",
      "  [0.79415846]\n",
      "  [0.80181634]\n",
      "  [0.81016469]\n",
      "  [0.81886506]]]\n",
      "ejemplar: [0.77164465 0.77658248 0.78198099 0.7876454  0.79415846 0.80181634\n",
      " 0.81016469 0.81886506]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.82859635]]\n",
      "Lr que voy a aplicar en el lote: 117 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.77164465 0.77658248 0.78198099 0.7876454  0.79415846 0.80181634\n",
      "  0.81016469 0.81886506]]\n",
      "verdaderas salidas: [0.84889578]\n",
      "PERDIDAAAA antes: 0.00041206704918295145\n",
      "Predicción post entrenamiento : [[0.835851]]\n",
      "PERDIDAAAA despues: 0.00017016613855957985\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "[[[0.77658248]\n",
      "  [0.78198099]\n",
      "  [0.7876454 ]\n",
      "  [0.79415846]\n",
      "  [0.80181634]\n",
      "  [0.81016469]\n",
      "  [0.81886506]\n",
      "  [0.82859635]]]\n",
      "ejemplar: [0.77658248 0.78198099 0.7876454  0.79415846 0.80181634 0.81016469\n",
      " 0.81886506 0.82859635]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.8378994]]\n",
      "Lr que voy a aplicar en el lote: 118 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.77658248 0.78198099 0.7876454  0.79415846 0.80181634 0.81016469\n",
      "  0.81886506 0.82859635]]\n",
      "verdaderas salidas: [0.8341728]\n",
      "PERDIDAAAA antes: 1.3887559362046886e-05\n",
      "Predicción post entrenamiento : [[0.8433693]]\n",
      "PERDIDAAAA despues: 8.457597868982702e-05\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "[[[0.78198099]\n",
      "  [0.7876454 ]\n",
      "  [0.79415846]\n",
      "  [0.80181634]\n",
      "  [0.81016469]\n",
      "  [0.81886506]\n",
      "  [0.82859635]\n",
      "  [0.83789939]]]\n",
      "ejemplar: [0.78198099 0.7876454  0.79415846 0.80181634 0.81016469 0.81886506\n",
      " 0.82859635 0.83789939]\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.8456402]]\n",
      "Lr que voy a aplicar en el lote: 119 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.78198099 0.7876454  0.79415846 0.80181634 0.81016469 0.81886506\n",
      "  0.82859635 0.83789939]]\n",
      "verdaderas salidas: [0.85509492]\n",
      "PERDIDAAAA antes: 8.939186227507889e-05\n",
      "Predicción post entrenamiento : [[0.85016847]]\n",
      "PERDIDAAAA despues: 2.4269842469948344e-05\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "[[[0.7876454 ]\n",
      "  [0.79415846]\n",
      "  [0.80181634]\n",
      "  [0.81016469]\n",
      "  [0.81886506]\n",
      "  [0.82859635]\n",
      "  [0.83789939]\n",
      "  [0.84564018]]]\n",
      "ejemplar: [0.7876454  0.79415846 0.80181634 0.81016469 0.81886506 0.82859635\n",
      " 0.83789939 0.84564018]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.85267466]]\n",
      "Lr que voy a aplicar en el lote: 120 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.7876454  0.79415846 0.80181634 0.81016469 0.81886506 0.82859635\n",
      "  0.83789939 0.84564018]]\n",
      "verdaderas salidas: [0.87524215]\n",
      "PERDIDAAAA antes: 0.0005092925275675952\n",
      "Predicción post entrenamiento : [[0.8571798]]\n",
      "PERDIDAAAA despues: 0.00032624861341901124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "[[[0.79415846]\n",
      "  [0.80181634]\n",
      "  [0.81016469]\n",
      "  [0.81886506]\n",
      "  [0.82859635]\n",
      "  [0.83789939]\n",
      "  [0.84564018]\n",
      "  [0.85267466]]]\n",
      "ejemplar: [0.79415846 0.80181634 0.81016469 0.81886506 0.82859635 0.83789939\n",
      " 0.84564018 0.85267466]\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.85995305]]\n",
      "Lr que voy a aplicar en el lote: 121 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.79415846 0.80181634 0.81016469 0.81886506 0.82859635 0.83789939\n",
      "  0.84564018 0.85267466]]\n",
      "verdaderas salidas: [0.85703216]\n",
      "PERDIDAAAA antes: 8.531458661309443e-06\n",
      "Predicción post entrenamiento : [[0.8650942]]\n",
      "PERDIDAAAA despues: 6.499592564068735e-05\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "[[[0.80181634]\n",
      "  [0.81016469]\n",
      "  [0.81886506]\n",
      "  [0.82859635]\n",
      "  [0.83789939]\n",
      "  [0.84564018]\n",
      "  [0.85267466]\n",
      "  [0.85995305]]]\n",
      "ejemplar: [0.80181634 0.81016469 0.81886506 0.82859635 0.83789939 0.84564018\n",
      " 0.85267466 0.85995305]\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.8680878]]\n",
      "Lr que voy a aplicar en el lote: 122 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.80181634 0.81016469 0.81886506 0.82859635 0.83789939 0.84564018\n",
      "  0.85267466 0.85995305]]\n",
      "verdaderas salidas: [0.85005812]\n",
      "PERDIDAAAA antes: 0.0003250697045587003\n",
      "Predicción post entrenamiento : [[0.8711678]]\n",
      "PERDIDAAAA despues: 0.0004456169262994081\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "[[[0.81016469]\n",
      "  [0.81886506]\n",
      "  [0.82859635]\n",
      "  [0.83789939]\n",
      "  [0.84564018]\n",
      "  [0.85267466]\n",
      "  [0.85995305]\n",
      "  [0.86808783]]]\n",
      "ejemplar: [0.81016469 0.81886506 0.82859635 0.83789939 0.84564018 0.85267466\n",
      " 0.85995305 0.86808783]\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.874264]]\n",
      "Lr que voy a aplicar en el lote: 123 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.81016469 0.81886506 0.82859635 0.83789939 0.84564018 0.85267466\n",
      "  0.85995305 0.86808783]]\n",
      "verdaderas salidas: [0.84269663]\n",
      "PERDIDAAAA antes: 0.00099650037009269\n",
      "Predicción post entrenamiento : [[0.8769306]]\n",
      "PERDIDAAAA despues: 0.0011719658505171537\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "[[[0.81886506]\n",
      "  [0.82859635]\n",
      "  [0.83789939]\n",
      "  [0.84564018]\n",
      "  [0.85267466]\n",
      "  [0.85995305]\n",
      "  [0.86808783]\n",
      "  [0.874264  ]]]\n",
      "ejemplar: [0.81886506 0.82859635 0.83789939 0.84564018 0.85267466 0.85995305\n",
      " 0.86808783 0.874264  ]\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.8800435]]\n",
      "Lr que voy a aplicar en el lote: 124 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.81886506 0.82859635 0.83789939 0.84564018 0.85267466 0.85995305\n",
      "  0.86808783 0.874264  ]]\n",
      "verdaderas salidas: [0.82293685]\n",
      "PERDIDAAAA antes: 0.0032611722126603127\n",
      "Predicción post entrenamiento : [[0.88235503]]\n",
      "PERDIDAAAA despues: 0.0035305225756019354\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "[[[0.82859635]\n",
      "  [0.83789939]\n",
      "  [0.84564018]\n",
      "  [0.85267466]\n",
      "  [0.85995305]\n",
      "  [0.86808783]\n",
      "  [0.874264  ]\n",
      "  [0.88004351]]]\n",
      "ejemplar: [0.82859635 0.83789939 0.84564018 0.85267466 0.85995305 0.86808783\n",
      " 0.874264   0.88004351]\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.88541746]]\n",
      "Lr que voy a aplicar en el lote: 125 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.82859635 0.83789939 0.84564018 0.85267466 0.85995305 0.86808783\n",
      "  0.874264   0.88004351]]\n",
      "verdaderas salidas: [0.77450601]\n",
      "PERDIDAAAA antes: 0.012301345355808735\n",
      "Predicción post entrenamiento : [[0.8855559]]\n",
      "PERDIDAAAA despues: 0.012332078069448471\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "[[[0.83789939]\n",
      "  [0.84564018]\n",
      "  [0.85267466]\n",
      "  [0.85995305]\n",
      "  [0.86808783]\n",
      "  [0.874264  ]\n",
      "  [0.88004351]\n",
      "  [0.88541746]]]\n",
      "ejemplar: [0.83789939 0.84564018 0.85267466 0.85995305 0.86808783 0.874264\n",
      " 0.88004351 0.88541746]\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.8883892]]\n",
      "Lr que voy a aplicar en el lote: 126 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.83789939 0.84564018 0.85267466 0.85995305 0.86808783 0.874264\n",
      "  0.88004351 0.88541746]]\n",
      "verdaderas salidas: [0.78419217]\n",
      "PERDIDAAAA antes: 0.010857032611966133\n",
      "Predicción post entrenamiento : [[0.88546395]]\n",
      "PERDIDAAAA despues: 0.010255979374051094\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "[[[0.84564018]\n",
      "  [0.85267466]\n",
      "  [0.85995305]\n",
      "  [0.86808783]\n",
      "  [0.874264  ]\n",
      "  [0.88004351]\n",
      "  [0.88541746]\n",
      "  [0.88838923]]]\n",
      "ejemplar: [0.84564018 0.85267466 0.85995305 0.86808783 0.874264   0.88004351\n",
      " 0.88541746 0.88838923]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.8880372]]\n",
      "Lr que voy a aplicar en el lote: 127 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.84564018 0.85267466 0.85995305 0.86808783 0.874264   0.88004351\n",
      "  0.88541746 0.88838923]]\n",
      "verdaderas salidas: [0.85974429]\n",
      "PERDIDAAAA antes: 0.0008004878764040768\n",
      "Predicción post entrenamiento : [[0.88504124]]\n",
      "PERDIDAAAA despues: 0.0006399345002137125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "[[[0.85267466]\n",
      "  [0.85995305]\n",
      "  [0.86808783]\n",
      "  [0.874264  ]\n",
      "  [0.88004351]\n",
      "  [0.88541746]\n",
      "  [0.88838923]\n",
      "  [0.8880372 ]]]\n",
      "ejemplar: [0.85267466 0.85995305 0.86808783 0.874264   0.88004351 0.88541746\n",
      " 0.88838923 0.8880372 ]\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.88746655]]\n",
      "Lr que voy a aplicar en el lote: 128 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.85267466 0.85995305 0.86808783 0.874264   0.88004351 0.88541746\n",
      "  0.88838923 0.8880372 ]]\n",
      "verdaderas salidas: [0.85432003]\n",
      "PERDIDAAAA antes: 0.0010986905544996262\n",
      "Predicción post entrenamiento : [[0.88401246]]\n",
      "PERDIDAAAA despues: 0.0008816393092274666\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "[[[0.85995305]\n",
      "  [0.86808783]\n",
      "  [0.874264  ]\n",
      "  [0.88004351]\n",
      "  [0.88541746]\n",
      "  [0.88838923]\n",
      "  [0.8880372 ]\n",
      "  [0.88746655]]]\n",
      "ejemplar: [0.85995305 0.86808783 0.874264   0.88004351 0.88541746 0.88838923\n",
      " 0.8880372  0.88746655]\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.8862978]]\n",
      "Lr que voy a aplicar en el lote: 129 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.85995305 0.86808783 0.874264   0.88004351 0.88541746 0.88838923\n",
      "  0.8880372  0.88746655]]\n",
      "verdaderas salidas: [0.83688493]\n",
      "PERDIDAAAA antes: 0.0024416353553533554\n",
      "Predicción post entrenamiento : [[0.88212633]]\n",
      "PERDIDAAAA despues: 0.002046785783022642\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "[[[0.86808783]\n",
      "  [0.874264  ]\n",
      "  [0.88004351]\n",
      "  [0.88541746]\n",
      "  [0.88838923]\n",
      "  [0.8880372 ]\n",
      "  [0.88746655]\n",
      "  [0.88629782]]]\n",
      "ejemplar: [0.86808783 0.874264   0.88004351 0.88541746 0.88838923 0.8880372\n",
      " 0.88746655 0.88629782]\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.8841493]]\n",
      "Lr que voy a aplicar en el lote: 130 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.86808783 0.874264   0.88004351 0.88541746 0.88838923 0.8880372\n",
      "  0.88746655 0.88629782]]\n",
      "verdaderas salidas: [0.82991089]\n",
      "PERDIDAAAA antes: 0.002941808197647333\n",
      "Predicción post entrenamiento : [[0.87942314]]\n",
      "PERDIDAAAA despues: 0.002451464533805847\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "[[[0.874264  ]\n",
      "  [0.88004351]\n",
      "  [0.88541746]\n",
      "  [0.88838923]\n",
      "  [0.8880372 ]\n",
      "  [0.88746655]\n",
      "  [0.88629782]\n",
      "  [0.88414931]]]\n",
      "ejemplar: [0.874264   0.88004351 0.88541746 0.88838923 0.8880372  0.88746655\n",
      " 0.88629782 0.88414931]\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.8809586]]\n",
      "Lr que voy a aplicar en el lote: 131 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.874264   0.88004351 0.88541746 0.88838923 0.8880372  0.88746655\n",
      "  0.88629782 0.88414931]]\n",
      "verdaderas salidas: [0.887253]\n",
      "PERDIDAAAA antes: 3.961909169447608e-05\n",
      "Predicción post entrenamiento : [[0.8761355]]\n",
      "PERDIDAAAA despues: 0.00012359788524918258\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "[[[0.88004351]\n",
      "  [0.88541746]\n",
      "  [0.88838923]\n",
      "  [0.8880372 ]\n",
      "  [0.88746655]\n",
      "  [0.88629782]\n",
      "  [0.88414931]\n",
      "  [0.88095862]]]\n",
      "ejemplar: [0.88004351 0.88541746 0.88838923 0.8880372  0.88746655 0.88629782\n",
      " 0.88414931 0.88095862]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.87726486]]\n",
      "Lr que voy a aplicar en el lote: 132 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.88004351 0.88541746 0.88838923 0.8880372  0.88746655 0.88629782\n",
      "  0.88414931 0.88095862]]\n",
      "verdaderas salidas: [0.85974429]\n",
      "PERDIDAAAA antes: 0.0003069695667363703\n",
      "Predicción post entrenamiento : [[0.87261623]]\n",
      "PERDIDAAAA despues: 0.00016568634600844234\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "[[[0.88541746]\n",
      "  [0.88838923]\n",
      "  [0.8880372 ]\n",
      "  [0.88746655]\n",
      "  [0.88629782]\n",
      "  [0.88414931]\n",
      "  [0.88095862]\n",
      "  [0.87726486]]]\n",
      "ejemplar: [0.88541746 0.88838923 0.8880372  0.88746655 0.88629782 0.88414931\n",
      " 0.88095862 0.87726486]\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.8732476]]\n",
      "Lr que voy a aplicar en el lote: 133 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.88541746 0.88838923 0.8880372  0.88746655 0.88629782 0.88414931\n",
      "  0.88095862 0.87726486]]\n",
      "verdaderas salidas: [0.83959706]\n",
      "PERDIDAAAA antes: 0.0011323613580316305\n",
      "Predicción post entrenamiento : [[0.869077]]\n",
      "PERDIDAAAA despues: 0.0008690692484378815\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "[[[0.88838923]\n",
      "  [0.8880372 ]\n",
      "  [0.88746655]\n",
      "  [0.88629782]\n",
      "  [0.88414931]\n",
      "  [0.88095862]\n",
      "  [0.87726486]\n",
      "  [0.87324762]]]\n",
      "ejemplar: [0.88838923 0.8880372  0.88746655 0.88629782 0.88414931 0.88095862\n",
      " 0.87726486 0.87324762]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.86911106]]\n",
      "Lr que voy a aplicar en el lote: 134 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.88838923 0.8880372  0.88746655 0.88629782 0.88414931 0.88095862\n",
      "  0.87726486 0.87324762]]\n",
      "verdaderas salidas: [0.78380473]\n",
      "PERDIDAAAA antes: 0.007277172524482012\n",
      "Predicción post entrenamiento : [[0.86476326]]\n",
      "PERDIDAAAA despues: 0.006554285995662212\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "[[[0.8880372 ]\n",
      "  [0.88746655]\n",
      "  [0.88629782]\n",
      "  [0.88414931]\n",
      "  [0.88095862]\n",
      "  [0.87726486]\n",
      "  [0.87324762]\n",
      "  [0.86911106]]]\n",
      "ejemplar: [0.8880372  0.88746655 0.88629782 0.88414931 0.88095862 0.87726486\n",
      " 0.87324762 0.86911106]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.8643328]]\n",
      "Lr que voy a aplicar en el lote: 135 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.8880372  0.88746655 0.88629782 0.88414931 0.88095862 0.87726486\n",
      "  0.87324762 0.86911106]]\n",
      "verdaderas salidas: [0.81828749]\n",
      "PERDIDAAAA antes: 0.0021201700437813997\n",
      "Predicción post entrenamiento : [[0.8608062]]\n",
      "PERDIDAAAA despues: 0.0018078428693115711\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "[[[0.88746655]\n",
      "  [0.88629782]\n",
      "  [0.88414931]\n",
      "  [0.88095862]\n",
      "  [0.87726486]\n",
      "  [0.87324762]\n",
      "  [0.86911106]\n",
      "  [0.8643328 ]]]\n",
      "ejemplar: [0.88746655 0.88629782 0.88414931 0.88095862 0.87726486 0.87324762\n",
      " 0.86911106 0.8643328 ]\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.86018413]]\n",
      "Lr que voy a aplicar en el lote: 136 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.88746655 0.88629782 0.88414931 0.88095862 0.87726486 0.87324762\n",
      "  0.86911106 0.8643328 ]]\n",
      "verdaderas salidas: [0.79116621]\n",
      "PERDIDAAAA antes: 0.004763477016240358\n",
      "Predicción post entrenamiento : [[0.8565812]]\n",
      "PERDIDAAAA despues: 0.004279125481843948\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "[[[0.88629782]\n",
      "  [0.88414931]\n",
      "  [0.88095862]\n",
      "  [0.87726486]\n",
      "  [0.87324762]\n",
      "  [0.86911106]\n",
      "  [0.8643328 ]\n",
      "  [0.86018413]]]\n",
      "ejemplar: [0.88629782 0.88414931 0.88095862 0.87726486 0.87324762 0.86911106\n",
      " 0.8643328  0.86018413]\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.85572916]]\n",
      "Lr que voy a aplicar en el lote: 137 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.88629782 0.88414931 0.88095862 0.87726486 0.87324762 0.86911106\n",
      "  0.8643328  0.86018413]]\n",
      "verdaderas salidas: [0.76055792]\n",
      "PERDIDAAAA antes: 0.009057560004293919\n",
      "Predicción post entrenamiento : [[0.8536789]]\n",
      "PERDIDAAAA despues: 0.00867150817066431\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "[[[0.88414931]\n",
      "  [0.88095862]\n",
      "  [0.87726486]\n",
      "  [0.87324762]\n",
      "  [0.86911106]\n",
      "  [0.8643328 ]\n",
      "  [0.86018413]\n",
      "  [0.85572916]]]\n",
      "ejemplar: [0.88414931 0.88095862 0.87726486 0.87324762 0.86911106 0.8643328\n",
      " 0.86018413 0.85572916]\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.8525986]]\n",
      "Lr que voy a aplicar en el lote: 138 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.88414931 0.88095862 0.87726486 0.87324762 0.86911106 0.8643328\n",
      "  0.86018413 0.85572916]]\n",
      "verdaderas salidas: [0.79155366]\n",
      "PERDIDAAAA antes: 0.00372648355551064\n",
      "Predicción post entrenamiento : [[0.84831667]]\n",
      "PERDIDAAAA despues: 0.0032220373395830393\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "[[[0.88095862]\n",
      "  [0.87726486]\n",
      "  [0.87324762]\n",
      "  [0.86911106]\n",
      "  [0.8643328 ]\n",
      "  [0.86018413]\n",
      "  [0.85572916]\n",
      "  [0.85259861]]]\n",
      "ejemplar: [0.88095862 0.87726486 0.87324762 0.86911106 0.8643328  0.86018413\n",
      " 0.85572916 0.85259861]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.84707195]]\n",
      "Lr que voy a aplicar en el lote: 139 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.88095862 0.87726486 0.87324762 0.86911106 0.8643328  0.86018413\n",
      "  0.85572916 0.85259861]]\n",
      "verdaderas salidas: [0.7686943]\n",
      "PERDIDAAAA antes: 0.006143058184534311\n",
      "Predicción post entrenamiento : [[0.84185046]]\n",
      "PERDIDAAAA despues: 0.005351826548576355\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "[[[0.87726486]\n",
      "  [0.87324762]\n",
      "  [0.86911106]\n",
      "  [0.8643328 ]\n",
      "  [0.86018413]\n",
      "  [0.85572916]\n",
      "  [0.85259861]\n",
      "  [0.84707195]]]\n",
      "ejemplar: [0.87726486 0.87324762 0.86911106 0.8643328  0.86018413 0.85572916\n",
      " 0.85259861 0.84707195]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.84052527]]\n",
      "Lr que voy a aplicar en el lote: 140 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.87726486 0.87324762 0.86911106 0.8643328  0.86018413 0.85572916\n",
      "  0.85259861 0.84707195]]\n",
      "verdaderas salidas: [0.7686943]\n",
      "PERDIDAAAA antes: 0.005159690976142883\n",
      "Predicción post entrenamiento : [[0.8351497]]\n",
      "PERDIDAAAA despues: 0.004416323266923428\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "[[[0.87324762]\n",
      "  [0.86911106]\n",
      "  [0.8643328 ]\n",
      "  [0.86018413]\n",
      "  [0.85572916]\n",
      "  [0.85259861]\n",
      "  [0.84707195]\n",
      "  [0.84052527]]]\n",
      "ejemplar: [0.87324762 0.86911106 0.8643328  0.86018413 0.85572916 0.85259861\n",
      " 0.84707195 0.84052527]\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.83377707]]\n",
      "Lr que voy a aplicar en el lote: 141 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.87324762 0.86911106 0.8643328  0.86018413 0.85572916 0.85259861\n",
      "  0.84707195 0.84052527]]\n",
      "verdaderas salidas: [0.79891515]\n",
      "PERDIDAAAA antes: 0.0012153536081314087\n",
      "Predicción post entrenamiento : [[0.8289546]]\n",
      "PERDIDAAAA despues: 0.0009023673483170569\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "[[[0.86911106]\n",
      "  [0.8643328 ]\n",
      "  [0.86018413]\n",
      "  [0.85572916]\n",
      "  [0.85259861]\n",
      "  [0.84707195]\n",
      "  [0.84052527]\n",
      "  [0.83377707]]]\n",
      "ejemplar: [0.86911106 0.8643328  0.86018413 0.85572916 0.85259861 0.84707195\n",
      " 0.84052527 0.83377707]\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.8275467]]\n",
      "Lr que voy a aplicar en el lote: 142 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.86911106 0.8643328  0.86018413 0.85572916 0.85259861 0.84707195\n",
      "  0.84052527 0.83377707]]\n",
      "verdaderas salidas: [0.79000387]\n",
      "PERDIDAAAA antes: 0.0014094633515924215\n",
      "Predicción post entrenamiento : [[0.82345366]]\n",
      "PERDIDAAAA despues: 0.0011188870994374156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "[[[0.8643328 ]\n",
      "  [0.86018413]\n",
      "  [0.85572916]\n",
      "  [0.85259861]\n",
      "  [0.84707195]\n",
      "  [0.84052527]\n",
      "  [0.83377707]\n",
      "  [0.82754672]]]\n",
      "ejemplar: [0.8643328  0.86018413 0.85572916 0.85259861 0.84707195 0.84052527\n",
      " 0.83377707 0.82754672]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.8219981]]\n",
      "Lr que voy a aplicar en el lote: 143 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.8643328  0.86018413 0.85572916 0.85259861 0.84707195 0.84052527\n",
      "  0.83377707 0.82754672]]\n",
      "verdaderas salidas: [0.76017048]\n",
      "PERDIDAAAA antes: 0.003822659607976675\n",
      "Predicción post entrenamiento : [[0.8166541]]\n",
      "PERDIDAAAA despues: 0.003190400078892708\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "[[[0.86018413]\n",
      "  [0.85572916]\n",
      "  [0.85259861]\n",
      "  [0.84707195]\n",
      "  [0.84052527]\n",
      "  [0.83377707]\n",
      "  [0.82754672]\n",
      "  [0.82199812]]]\n",
      "ejemplar: [0.86018413 0.85572916 0.85259861 0.84707195 0.84052527 0.83377707\n",
      " 0.82754672 0.82199812]\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.81519806]]\n",
      "Lr que voy a aplicar en el lote: 144 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.86018413 0.85572916 0.85259861 0.84707195 0.84052527 0.83377707\n",
      "  0.82754672 0.82199812]]\n",
      "verdaderas salidas: [0.68539326]\n",
      "PERDIDAAAA antes: 0.016849283128976822\n",
      "Predicción post entrenamiento : [[0.80959773]]\n",
      "PERDIDAAAA despues: 0.015426747500896454\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "[[[0.85572916]\n",
      "  [0.85259861]\n",
      "  [0.84707195]\n",
      "  [0.84052527]\n",
      "  [0.83377707]\n",
      "  [0.82754672]\n",
      "  [0.82199812]\n",
      "  [0.81519806]]]\n",
      "ejemplar: [0.85572916 0.85259861 0.84707195 0.84052527 0.83377707 0.82754672\n",
      " 0.82199812 0.81519806]\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.8080511]]\n",
      "Lr que voy a aplicar en el lote: 145 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.85572916 0.85259861 0.84707195 0.84052527 0.83377707 0.82754672\n",
      "  0.82199812 0.81519806]]\n",
      "verdaderas salidas: [0.60519179]\n",
      "PERDIDAAAA antes: 0.04115191102027893\n",
      "Predicción post entrenamiento : [[0.8019032]]\n",
      "PERDIDAAAA despues: 0.038695383816957474\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "[[[0.85259861]\n",
      "  [0.84707195]\n",
      "  [0.84052527]\n",
      "  [0.83377707]\n",
      "  [0.82754672]\n",
      "  [0.82199812]\n",
      "  [0.81519806]\n",
      "  [0.80805111]]]\n",
      "ejemplar: [0.85259861 0.84707195 0.84052527 0.83377707 0.82754672 0.82199812\n",
      " 0.81519806 0.80805111]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.8002648]]\n",
      "Lr que voy a aplicar en el lote: 146 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.85259861 0.84707195 0.84052527 0.83377707 0.82754672 0.82199812\n",
      "  0.81519806 0.80805111]]\n",
      "verdaderas salidas: [0.66485858]\n",
      "PERDIDAAAA antes: 0.01833483763039112\n",
      "Predicción post entrenamiento : [[0.7939449]]\n",
      "PERDIDAAAA despues: 0.01666327752172947\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "[[[0.84707195]\n",
      "  [0.84052527]\n",
      "  [0.83377707]\n",
      "  [0.82754672]\n",
      "  [0.82199812]\n",
      "  [0.81519806]\n",
      "  [0.80805111]\n",
      "  [0.80026478]]]\n",
      "ejemplar: [0.84707195 0.84052527 0.83377707 0.82754672 0.82199812 0.81519806\n",
      " 0.80805111 0.80026478]\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.7920378]]\n",
      "Lr que voy a aplicar en el lote: 147 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.84707195 0.84052527 0.83377707 0.82754672 0.82199812 0.81519806\n",
      "  0.80805111 0.80026478]]\n",
      "verdaderas salidas: [0.70786517]\n",
      "PERDIDAAAA antes: 0.007085027638822794\n",
      "Predicción post entrenamiento : [[0.78691417]]\n",
      "PERDIDAAAA despues: 0.0062487428076565266\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "[[[0.84052527]\n",
      "  [0.83377707]\n",
      "  [0.82754672]\n",
      "  [0.82199812]\n",
      "  [0.81519806]\n",
      "  [0.80805111]\n",
      "  [0.80026478]\n",
      "  [0.79203779]]]\n",
      "ejemplar: [0.84052527 0.83377707 0.82754672 0.82199812 0.81519806 0.80805111\n",
      " 0.80026478 0.79203779]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.7849289]]\n",
      "Lr que voy a aplicar en el lote: 148 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.84052527 0.83377707 0.82754672 0.82199812 0.81519806 0.80805111\n",
      "  0.80026478 0.79203779]]\n",
      "verdaderas salidas: [0.66485858]\n",
      "PERDIDAAAA antes: 0.014416886493563652\n",
      "Predicción post entrenamiento : [[0.7808348]]\n",
      "PERDIDAAAA despues: 0.013450481928884983\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "[[[0.83377707]\n",
      "  [0.82754672]\n",
      "  [0.82199812]\n",
      "  [0.81519806]\n",
      "  [0.80805111]\n",
      "  [0.80026478]\n",
      "  [0.79203779]\n",
      "  [0.78492892]]]\n",
      "ejemplar: [0.83377707 0.82754672 0.82199812 0.81519806 0.80805111 0.80026478\n",
      " 0.79203779 0.78492892]\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.7788495]]\n",
      "Lr que voy a aplicar en el lote: 149 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.83377707 0.82754672 0.82199812 0.81519806 0.80805111 0.80026478\n",
      "  0.79203779 0.78492892]]\n",
      "verdaderas salidas: [0.71135219]\n",
      "PERDIDAAAA antes: 0.004555887077003717\n",
      "Predicción post entrenamiento : [[0.77493125]]\n",
      "PERDIDAAAA despues: 0.004042299930006266\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "[[[0.82754672]\n",
      "  [0.82199812]\n",
      "  [0.81519806]\n",
      "  [0.80805111]\n",
      "  [0.80026478]\n",
      "  [0.79203779]\n",
      "  [0.78492892]\n",
      "  [0.77884948]]]\n",
      "ejemplar: [0.82754672 0.82199812 0.81519806 0.80805111 0.80026478 0.79203779\n",
      " 0.78492892 0.77884948]\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.7729561]]\n",
      "Lr que voy a aplicar en el lote: 150 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.82754672 0.82199812 0.81519806 0.80805111 0.80026478 0.79203779\n",
      "  0.78492892 0.77884948]]\n",
      "verdaderas salidas: [0.67725688]\n",
      "PERDIDAAAA antes: 0.009158335626125336\n",
      "Predicción post entrenamiento : [[0.76892453]]\n",
      "PERDIDAAAA despues: 0.008402958512306213\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "[[[0.82199812]\n",
      "  [0.81519806]\n",
      "  [0.80805111]\n",
      "  [0.80026478]\n",
      "  [0.79203779]\n",
      "  [0.78492892]\n",
      "  [0.77884948]\n",
      "  [0.77295607]]]\n",
      "ejemplar: [0.82199812 0.81519806 0.80805111 0.80026478 0.79203779 0.78492892\n",
      " 0.77884948 0.77295607]\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.76690084]]\n",
      "Lr que voy a aplicar en el lote: 151 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.82199812 0.81519806 0.80805111 0.80026478 0.79203779 0.78492892\n",
      "  0.77884948 0.77295607]]\n",
      "verdaderas salidas: [0.76210771]\n",
      "PERDIDAAAA antes: 2.2973879822529852e-05\n",
      "Predicción post entrenamiento : [[0.76288253]]\n",
      "PERDIDAAAA despues: 6.003162411616358e-07\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "[[[0.81519806]\n",
      "  [0.80805111]\n",
      "  [0.80026478]\n",
      "  [0.79203779]\n",
      "  [0.78492892]\n",
      "  [0.77884948]\n",
      "  [0.77295607]\n",
      "  [0.76690084]]]\n",
      "ejemplar: [0.81519806 0.80805111 0.80026478 0.79203779 0.78492892 0.77884948\n",
      " 0.77295607 0.76690084]\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.7607308]]\n",
      "Lr que voy a aplicar en el lote: 152 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.81519806 0.80805111 0.80026478 0.79203779 0.78492892 0.77884948\n",
      "  0.77295607 0.76690084]]\n",
      "verdaderas salidas: [0.80705153]\n",
      "PERDIDAAAA antes: 0.0021456105168908834\n",
      "Predicción post entrenamiento : [[0.7578792]]\n",
      "PERDIDAAAA despues: 0.0024179192259907722\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "[[[0.80805111]\n",
      "  [0.80026478]\n",
      "  [0.79203779]\n",
      "  [0.78492892]\n",
      "  [0.77884948]\n",
      "  [0.77295607]\n",
      "  [0.76690084]\n",
      "  [0.7607308 ]]]\n",
      "ejemplar: [0.80805111 0.80026478 0.79203779 0.78492892 0.77884948 0.77295607\n",
      " 0.76690084 0.7607308 ]\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.75570863]]\n",
      "Lr que voy a aplicar en el lote: 153 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.80805111 0.80026478 0.79203779 0.78492892 0.77884948 0.77295607\n",
      "  0.76690084 0.7607308 ]]\n",
      "verdaderas salidas: [0.81518791]\n",
      "PERDIDAAAA antes: 0.0035377866588532925\n",
      "Predicción post entrenamiento : [[0.7529473]]\n",
      "PERDIDAAAA despues: 0.0038738998118788004\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "[[[0.80026478]\n",
      "  [0.79203779]\n",
      "  [0.78492892]\n",
      "  [0.77884948]\n",
      "  [0.77295607]\n",
      "  [0.76690084]\n",
      "  [0.7607308 ]\n",
      "  [0.75570863]]]\n",
      "ejemplar: [0.80026478 0.79203779 0.78492892 0.77884948 0.77295607 0.76690084\n",
      " 0.7607308  0.75570863]\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.75080264]]\n",
      "Lr que voy a aplicar en el lote: 154 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.80026478 0.79203779 0.78492892 0.77884948 0.77295607 0.76690084\n",
      "  0.7607308  0.75570863]]\n",
      "verdaderas salidas: [0.90623789]\n",
      "PERDIDAAAA antes: 0.024160120636224747\n",
      "Predicción post entrenamiento : [[0.7493003]]\n",
      "PERDIDAAAA despues: 0.024629410356283188\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "[[[0.79203779]\n",
      "  [0.78492892]\n",
      "  [0.77884948]\n",
      "  [0.77295607]\n",
      "  [0.76690084]\n",
      "  [0.7607308 ]\n",
      "  [0.75570863]\n",
      "  [0.75080264]]]\n",
      "ejemplar: [0.79203779 0.78492892 0.77884948 0.77295607 0.76690084 0.7607308\n",
      " 0.75570863 0.75080264]\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.74726367]]\n",
      "Lr que voy a aplicar en el lote: 155 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.79203779 0.78492892 0.77884948 0.77295607 0.76690084 0.7607308\n",
      "  0.75570863 0.75080264]]\n",
      "verdaderas salidas: [0.95970554]\n",
      "PERDIDAAAA antes: 0.04513154551386833\n",
      "Predicción post entrenamiento : [[0.7467159]]\n",
      "PERDIDAAAA despues: 0.04536458104848862\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "[[[0.78492892]\n",
      "  [0.77884948]\n",
      "  [0.77295607]\n",
      "  [0.76690084]\n",
      "  [0.7607308 ]\n",
      "  [0.75570863]\n",
      "  [0.75080264]\n",
      "  [0.74726367]]]\n",
      "ejemplar: [0.78492892 0.77884948 0.77295607 0.76690084 0.7607308  0.75570863\n",
      " 0.75080264 0.74726367]\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.74486744]]\n",
      "Lr que voy a aplicar en el lote: 156 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.78492892 0.77884948 0.77295607 0.76690084 0.7607308  0.75570863\n",
      "  0.75080264 0.74726367]]\n",
      "verdaderas salidas: [0.9643549]\n",
      "PERDIDAAAA antes: 0.04817473143339157\n",
      "Predicción post entrenamiento : [[0.7458422]]\n",
      "PERDIDAAAA despues: 0.04774777963757515\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "[[[0.77884948]\n",
      "  [0.77295607]\n",
      "  [0.76690084]\n",
      "  [0.7607308 ]\n",
      "  [0.75570863]\n",
      "  [0.75080264]\n",
      "  [0.74726367]\n",
      "  [0.74486744]]]\n",
      "ejemplar: [0.77884948 0.77295607 0.76690084 0.7607308  0.75570863 0.75080264\n",
      " 0.74726367 0.74486744]\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.7441194]]\n",
      "Lr que voy a aplicar en el lote: 157 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.77884948 0.77295607 0.76690084 0.7607308  0.75570863 0.75080264\n",
      "  0.74726367 0.74486744]]\n",
      "verdaderas salidas: [0.8880279]\n",
      "PERDIDAAAA antes: 0.020709656178951263\n",
      "Predicción post entrenamiento : [[0.7456278]]\n",
      "PERDIDAAAA despues: 0.020277785137295723\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "[[[0.77295607]\n",
      "  [0.76690084]\n",
      "  [0.7607308 ]\n",
      "  [0.75570863]\n",
      "  [0.75080264]\n",
      "  [0.74726367]\n",
      "  [0.74486744]\n",
      "  [0.74411941]]]\n",
      "ejemplar: [0.77295607 0.76690084 0.7607308  0.75570863 0.75080264 0.74726367\n",
      " 0.74486744 0.74411941]\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.7439759]]\n",
      "Lr que voy a aplicar en el lote: 158 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.77295607 0.76690084 0.7607308  0.75570863 0.75080264 0.74726367\n",
      "  0.74486744 0.74411941]]\n",
      "verdaderas salidas: [0.89267726]\n",
      "PERDIDAAAA antes: 0.022112097591161728\n",
      "Predicción post entrenamiento : [[0.745878]]\n",
      "PERDIDAAAA despues: 0.021550023928284645\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "[[[0.76690084]\n",
      "  [0.7607308 ]\n",
      "  [0.75570863]\n",
      "  [0.75080264]\n",
      "  [0.74726367]\n",
      "  [0.74486744]\n",
      "  [0.74411941]\n",
      "  [0.74397588]]]\n",
      "ejemplar: [0.76690084 0.7607308  0.75570863 0.75080264 0.74726367 0.74486744\n",
      " 0.74411941 0.74397588]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.7443278]]\n",
      "Lr que voy a aplicar en el lote: 159 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.76690084 0.7607308  0.75570863 0.75080264 0.74726367 0.74486744\n",
      "  0.74411941 0.74397588]]\n",
      "verdaderas salidas: [0.87524215]\n",
      "PERDIDAAAA antes: 0.01713857799768448\n",
      "Predicción post entrenamiento : [[0.74699205]]\n",
      "PERDIDAAAA despues: 0.016448093578219414\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "[[[0.7607308 ]\n",
      "  [0.75570863]\n",
      "  [0.75080264]\n",
      "  [0.74726367]\n",
      "  [0.74486744]\n",
      "  [0.74411941]\n",
      "  [0.74397588]\n",
      "  [0.74432778]]]\n",
      "ejemplar: [0.7607308  0.75570863 0.75080264 0.74726367 0.74486744 0.74411941\n",
      " 0.74397588 0.74432778]\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.74562263]]\n",
      "Lr que voy a aplicar en el lote: 160 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.7607308  0.75570863 0.75080264 0.74726367 0.74486744 0.74411941\n",
      "  0.74397588 0.74432778]]\n",
      "verdaderas salidas: [0.85083301]\n",
      "PERDIDAAAA antes: 0.01106922049075365\n",
      "Predicción post entrenamiento : [[0.74831235]]\n",
      "PERDIDAAAA despues: 0.01051048282533884\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "[[[0.75570863]\n",
      "  [0.75080264]\n",
      "  [0.74726367]\n",
      "  [0.74486744]\n",
      "  [0.74411941]\n",
      "  [0.74397588]\n",
      "  [0.74432778]\n",
      "  [0.74562263]]]\n",
      "ejemplar: [0.75570863 0.75080264 0.74726367 0.74486744 0.74411941 0.74397588\n",
      " 0.74432778 0.74562263]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.7472205]]\n",
      "Lr que voy a aplicar en el lote: 161 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.75570863 0.75080264 0.74726367 0.74486744 0.74411941 0.74397588\n",
      "  0.74432778 0.74562263]]\n",
      "verdaderas salidas: [0.84889578]\n",
      "PERDIDAAAA antes: 0.010337861254811287\n",
      "Predicción post entrenamiento : [[0.7508523]]\n",
      "PERDIDAAAA despues: 0.00961252860724926\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "[[[0.75080264]\n",
      "  [0.74726367]\n",
      "  [0.74486744]\n",
      "  [0.74411941]\n",
      "  [0.74397588]\n",
      "  [0.74432778]\n",
      "  [0.74562263]\n",
      "  [0.74722052]]]\n",
      "ejemplar: [0.75080264 0.74726367 0.74486744 0.74411941 0.74397588 0.74432778\n",
      " 0.74562263 0.74722052]\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.750019]]\n",
      "Lr que voy a aplicar en el lote: 162 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.75080264 0.74726367 0.74486744 0.74411941 0.74397588 0.74432778\n",
      "  0.74562263 0.74722052]]\n",
      "verdaderas salidas: [0.96241767]\n",
      "PERDIDAAAA antes: 0.04511318728327751\n",
      "Predicción post entrenamiento : [[0.7543541]]\n",
      "PERDIDAAAA despues: 0.04329043626785278\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "[[[0.74726367]\n",
      "  [0.74486744]\n",
      "  [0.74411941]\n",
      "  [0.74397588]\n",
      "  [0.74432778]\n",
      "  [0.74562263]\n",
      "  [0.74722052]\n",
      "  [0.75001901]]]\n",
      "ejemplar: [0.74726367 0.74486744 0.74411941 0.74397588 0.74432778 0.74562263\n",
      " 0.74722052 0.75001901]\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.75386506]]\n",
      "Lr que voy a aplicar en el lote: 163 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.74726367 0.74486744 0.74411941 0.74397588 0.74432778 0.74562263\n",
      "  0.74722052 0.75001901]]\n",
      "verdaderas salidas: [0.96784192]\n",
      "PERDIDAAAA antes: 0.04578609764575958\n",
      "Predicción post entrenamiento : [[0.75880915]]\n",
      "PERDIDAAAA despues: 0.04369470104575157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "[[[0.74486744]\n",
      "  [0.74411941]\n",
      "  [0.74397588]\n",
      "  [0.74432778]\n",
      "  [0.74562263]\n",
      "  [0.74722052]\n",
      "  [0.75001901]\n",
      "  [0.75386506]]]\n",
      "ejemplar: [0.74486744 0.74411941 0.74397588 0.74432778 0.74562263 0.74722052\n",
      " 0.75001901 0.75386506]\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.7586312]]\n",
      "Lr que voy a aplicar en el lote: 164 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.74486744 0.74411941 0.74397588 0.74432778 0.74562263 0.74722052\n",
      "  0.75001901 0.75386506]]\n",
      "verdaderas salidas: [0.94072065]\n",
      "PERDIDAAAA antes: 0.03315656632184982\n",
      "Predicción post entrenamiento : [[0.76416844]]\n",
      "PERDIDAAAA despues: 0.031170692294836044\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "[[[0.74411941]\n",
      "  [0.74397588]\n",
      "  [0.74432778]\n",
      "  [0.74562263]\n",
      "  [0.74722052]\n",
      "  [0.75001901]\n",
      "  [0.75386506]\n",
      "  [0.75863123]]]\n",
      "ejemplar: [0.74411941 0.74397588 0.74432778 0.74562263 0.74722052 0.75001901\n",
      " 0.75386506 0.75863123]\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.7642844]]\n",
      "Lr que voy a aplicar en el lote: 165 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.74411941 0.74397588 0.74432778 0.74562263 0.74722052 0.75001901\n",
      "  0.75386506 0.75863123]]\n",
      "verdaderas salidas: [0.97249128]\n",
      "PERDIDAAAA antes: 0.043350111693143845\n",
      "Predicción post entrenamiento : [[0.77023023]]\n",
      "PERDIDAAAA despues: 0.040909525007009506\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "[[[0.74397588]\n",
      "  [0.74432778]\n",
      "  [0.74562263]\n",
      "  [0.74722052]\n",
      "  [0.75001901]\n",
      "  [0.75386506]\n",
      "  [0.75863123]\n",
      "  [0.76428437]]]\n",
      "ejemplar: [0.74397588 0.74432778 0.74562263 0.74722052 0.75001901 0.75386506\n",
      " 0.75863123 0.76428437]\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.7705619]]\n",
      "Lr que voy a aplicar en el lote: 166 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.74397588 0.74432778 0.74562263 0.74722052 0.75001901 0.75386506\n",
      "  0.75863123 0.76428437]]\n",
      "verdaderas salidas: [0.99690043]\n",
      "PERDIDAAAA antes: 0.051229145377874374\n",
      "Predicción post entrenamiento : [[0.7773321]]\n",
      "PERDIDAAAA despues: 0.04821024462580681\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "[[[0.74432778]\n",
      "  [0.74562263]\n",
      "  [0.74722052]\n",
      "  [0.75001901]\n",
      "  [0.75386506]\n",
      "  [0.75863123]\n",
      "  [0.76428437]\n",
      "  [0.77056187]]]\n",
      "ejemplar: [0.74432778 0.74562263 0.74722052 0.75001901 0.75386506 0.75863123\n",
      " 0.76428437 0.77056187]\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.7779011]]\n",
      "Lr que voy a aplicar en el lote: 167 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.74432778 0.74562263 0.74722052 0.75001901 0.75386506 0.75863123\n",
      "  0.76428437 0.77056187]]\n",
      "verdaderas salidas: [0.95118171]\n",
      "PERDIDAAAA antes: 0.030026165768504143\n",
      "Predicción post entrenamiento : [[0.78420115]]\n",
      "PERDIDAAAA despues: 0.02788250893354416\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "[[[0.74562263]\n",
      "  [0.74722052]\n",
      "  [0.75001901]\n",
      "  [0.75386506]\n",
      "  [0.75863123]\n",
      "  [0.76428437]\n",
      "  [0.77056187]\n",
      "  [0.77790111]]]\n",
      "ejemplar: [0.74562263 0.74722052 0.75001901 0.75386506 0.75863123 0.76428437\n",
      " 0.77056187 0.77790111]\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.7850465]]\n",
      "Lr que voy a aplicar en el lote: 168 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.74562263 0.74722052 0.75001901 0.75386506 0.75863123 0.76428437\n",
      "  0.77056187 0.77790111]]\n",
      "verdaderas salidas: [0.89577683]\n",
      "PERDIDAAAA antes: 0.012261196970939636\n",
      "Predicción post entrenamiento : [[0.79125667]]\n",
      "PERDIDAAAA despues: 0.010924460366368294\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "[[[0.74722052]\n",
      "  [0.75001901]\n",
      "  [0.75386506]\n",
      "  [0.75863123]\n",
      "  [0.76428437]\n",
      "  [0.77056187]\n",
      "  [0.77790111]\n",
      "  [0.78504652]]]\n",
      "ejemplar: [0.74722052 0.75001901 0.75386506 0.75863123 0.76428437 0.77056187\n",
      " 0.77790111 0.78504652]\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.79237247]]\n",
      "Lr que voy a aplicar en el lote: 169 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.74722052 0.75001901 0.75386506 0.75863123 0.76428437 0.77056187\n",
      "  0.77790111 0.78504652]]\n",
      "verdaderas salidas: [0.8814413]\n",
      "PERDIDAAAA antes: 0.007933256216347218\n",
      "Predicción post entrenamiento : [[0.7986098]]\n",
      "PERDIDAAAA despues: 0.006861057598143816\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "[[[0.75001901]\n",
      "  [0.75386506]\n",
      "  [0.75863123]\n",
      "  [0.76428437]\n",
      "  [0.77056187]\n",
      "  [0.77790111]\n",
      "  [0.78504652]\n",
      "  [0.79237247]]]\n",
      "ejemplar: [0.75001901 0.75386506 0.75863123 0.76428437 0.77056187 0.77790111\n",
      " 0.78504652 0.79237247]\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.8000574]]\n",
      "Lr que voy a aplicar en el lote: 170 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.75001901 0.75386506 0.75863123 0.76428437 0.77056187 0.77790111\n",
      "  0.78504652 0.79237247]]\n",
      "verdaderas salidas: [0.9170864]\n",
      "PERDIDAAAA antes: 0.013695789501070976\n",
      "Predicción post entrenamiento : [[0.80696666]]\n",
      "PERDIDAAAA despues: 0.012126361951231956\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "[[[0.75386506]\n",
      "  [0.75863123]\n",
      "  [0.76428437]\n",
      "  [0.77056187]\n",
      "  [0.77790111]\n",
      "  [0.78504652]\n",
      "  [0.79237247]\n",
      "  [0.80005741]]]\n",
      "ejemplar: [0.75386506 0.75863123 0.76428437 0.77056187 0.77790111 0.78504652\n",
      " 0.79237247 0.80005741]\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.80871093]]\n",
      "Lr que voy a aplicar en el lote: 171 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.75386506 0.75863123 0.76428437 0.77056187 0.77790111 0.78504652\n",
      "  0.79237247 0.80005741]]\n",
      "verdaderas salidas: [0.91979853]\n",
      "PERDIDAAAA antes: 0.012340459041297436\n",
      "Predicción post entrenamiento : [[0.81594723]]\n",
      "PERDIDAAAA despues: 0.010785096324980259\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "[[[0.75863123]\n",
      "  [0.76428437]\n",
      "  [0.77056187]\n",
      "  [0.77790111]\n",
      "  [0.78504652]\n",
      "  [0.79237247]\n",
      "  [0.80005741]\n",
      "  [0.80871093]]]\n",
      "ejemplar: [0.75863123 0.76428437 0.77056187 0.77790111 0.78504652 0.79237247\n",
      " 0.80005741 0.80871093]\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.81795573]]\n",
      "Lr que voy a aplicar en el lote: 172 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.75863123 0.76428437 0.77056187 0.77790111 0.78504652 0.79237247\n",
      "  0.80005741 0.80871093]]\n",
      "verdaderas salidas: [0.96164277]\n",
      "PERDIDAAAA antes: 0.020645974203944206\n",
      "Predicción post entrenamiento : [[0.82589656]]\n",
      "PERDIDAAAA despues: 0.018427042290568352\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "[[[0.76428437]\n",
      "  [0.77056187]\n",
      "  [0.77790111]\n",
      "  [0.78504652]\n",
      "  [0.79237247]\n",
      "  [0.80005741]\n",
      "  [0.80871093]\n",
      "  [0.81795573]]]\n",
      "ejemplar: [0.76428437 0.77056187 0.77790111 0.78504652 0.79237247 0.80005741\n",
      " 0.80871093 0.81795573]\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.82814187]]\n",
      "Lr que voy a aplicar en el lote: 173 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.76428437 0.77056187 0.77790111 0.78504652 0.79237247 0.80005741\n",
      "  0.80871093 0.81795573]]\n",
      "verdaderas salidas: [0.96822937]\n",
      "PERDIDAAAA antes: 0.019624503329396248\n",
      "Predicción post entrenamiento : [[0.83698815]]\n",
      "PERDIDAAAA despues: 0.017224254086613655\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "[[[0.77056187]\n",
      "  [0.77790111]\n",
      "  [0.78504652]\n",
      "  [0.79237247]\n",
      "  [0.80005741]\n",
      "  [0.80871093]\n",
      "  [0.81795573]\n",
      "  [0.82814187]]]\n",
      "ejemplar: [0.77056187 0.77790111 0.78504652 0.79237247 0.80005741 0.80871093\n",
      " 0.81795573 0.82814187]\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.8394396]]\n",
      "Lr que voy a aplicar en el lote: 174 es 9.999999747378752e-05\n",
      "lote que voy a entrenar: [[0.77056187 0.77790111 0.78504652 0.79237247 0.80005741 0.80871093\n",
      "  0.81795573 0.82814187]]\n",
      "verdaderas salidas: [0.95776831]\n",
      "PERDIDAAAA antes: 0.014001692645251751\n",
      "Predicción post entrenamiento : [[0.8483696]]\n",
      "PERDIDAAAA despues: 0.011968080885708332\n",
      ">>>>>>>>>>>>>>>Fin lote \n"
     ]
    }
   ],
   "source": [
    "#red.compile(optimizer='sgd',loss='mean_squared_error')#SGD(learning_rate=1e-3)\n",
    "\n",
    "# Definir el callback con la función de la tasa de aprendizaje\n",
    "# lr_callback = CustomLearningRateScheduler(initial_lr=0.001, decay_factor=0.9)#\n",
    "# lr_callback.reset()\n",
    "ts_cierre_s_pred = c_entrenamiento_n\n",
    "sub_epocas = 1\n",
    "t_lote = 1\n",
    "\n",
    "loss_m = []\n",
    "print(f\"y_entrenamiento: {y_entrenamiento}\")\n",
    "for epoca in range(4):  # Número de épocas\n",
    "    ts_cierre_s_pred = c_entrenamiento_n[:time_steps] #:8 se toman los primeros 8 elementos del conjunto de entrenamiendo predictivo \n",
    "    ts_cierre_s_pred_post_entreno = c_entrenamiento_n[:time_steps]\n",
    "    loss = []\n",
    "    n_ejemplar = 1\n",
    "    n_lote = 1\n",
    "    x_lote = []\n",
    "    # print(f\"grtrt: {ts_cierre_s_pred}\")\n",
    "    for i in range(0,len(y_entrenamiento)):#time_steps+1\n",
    "        print(i)\n",
    "        # Obtener las características y la etiqueta actual\n",
    "        ejemplar = ts_cierre_s_pred[i:i+time_steps,0]\n",
    "        print(ejemplar.reshape(1,time_steps,1))\n",
    "\n",
    "        x_lote.append(ejemplar)\n",
    "\n",
    "        # Predicción del modelo \n",
    "        #prediccion = red.predict(x_actual)#.reshape(1,1,1)\n",
    "        prediccion = red(ejemplar.reshape(1,time_steps,1))\n",
    "        \n",
    "        # Agregar la predicción a las características para el siguiente paso\n",
    "        # print(ts_cierre_s_pred)\n",
    "        print(f\"ejemplar: {ejemplar}\")\n",
    "        print(f\"y: {np.array( y_entrenamiento[i])}\")\n",
    "        print(f\"Predicción : { prediccion}\")\n",
    "        ts_cierre_s_pred = np.concatenate([ts_cierre_s_pred, prediccion])\n",
    "        \n",
    "\n",
    "        if(n_ejemplar == t_lote):\n",
    "            \n",
    "            #print(f\"y: {np.array( y_entrenamiento[i-t_lote+1:i+1]).reshape(t_lote,1)}\")\n",
    "            \n",
    "            #print(f\"x_lote: {x_lote}\")\n",
    "            lr = float(red.optimizer.lr)\n",
    "            print(f\"Lr que voy a aplicar en el lote: {n_lote} es {lr}\")\n",
    "            print(f\"lote que voy a entrenar: {np.array(x_lote)}\")\n",
    "            print(f\"verdaderas salidas: {np.array( y_entrenamiento[i-t_lote+1:i+1])}\")\n",
    "            print(f\"PERDIDAAAA antes: {red.test_on_batch(np.array(x_lote),np.array( y_entrenamiento[i-t_lote+1:i+1]))}\")\n",
    "            train = red.train_on_batch(np.array(x_lote), np.array( y_entrenamiento[i-t_lote+1:i+1]))\n",
    "            \n",
    "            # print(f\"train: {train}\")\n",
    "            loss.append(train)#np.array(y_entrenamiento[i:i+t_lote])\n",
    "            prediccion_post_entrenamiento = red(ejemplar.reshape(1,time_steps,1))\n",
    "            print(f\"Predicción post entrenamiento : { prediccion_post_entrenamiento}\")\n",
    "            print(f\"PERDIDAAAA despues: {red.test_on_batch(np.array(x_lote),np.array( y_entrenamiento[i-t_lote+1:i+1]))}\")\n",
    "            #ts_cierre_s_pred_post_entreno = np.concatenate([ts_cierre_s_pred_post_entreno, prediccion])\n",
    "            # lr_callback.on_batch_begin(n_lote, logs={'loss': loss, 'epoca': epoca+1})  # Llamada al callback en cada lote\n",
    "            #red.optimizer.lr =\n",
    "            x_lote = []\n",
    "            n_ejemplar = 0\n",
    "            \n",
    "            n_lote = n_lote + 1\n",
    "            \n",
    "        n_ejemplar = n_ejemplar+1\n",
    "        print(\">>>>>>>>>>>>>>>Fin lote \")\n",
    "\n",
    "        # Entrenar el modelo con las nuevas características y la etiqueta real\n",
    "        # for sub_epoca in range(sub_epocas):\n",
    "        #     red.train_on_batch(x_actual, y_actual)\n",
    "        #     if(sub_epoca == sub_epocas - 1):\n",
    "        #         loss.append(red.train_on_batch(x_actual, y_actual))\n",
    "        \n",
    "\n",
    "        \n",
    "    #print(f\"mean: {np.mean(np.array(loss))}\")\n",
    "    #loss_m.append(np.mean(np.array(loss)))\n",
    "    mse = np.mean(np.array(mean_squared_error(c_entrenamiento_n,ts_cierre_s_pred[:,0])))\n",
    "    loss_m.append(mse)\n",
    "    writer.add_scalar(f'Perdida de entrenamiento predictivo de la red: ', mse, epoca+1)\n",
    "    \n",
    "    \n",
    "    plot_buf = utls.gen_plot(c_entrenamiento_n,ts_cierre_s_pred,mse)\n",
    "\n",
    "    image = PIL.Image.open(plot_buf)\n",
    "    image = ToTensor()(image).unsqueeze(0)\n",
    "    writer.add_image(f'Comportamiento de la serie de tiempo para la red: {0} durante el entrenamiento predictivo', image, epoca+1,dataformats='NCHW')\n",
    "    #lr_callback.reset()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18193908502334455, 0.1310213680893403, 0.12601600447779537, 0.12038880445235148]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(loss_m)\n",
    "plt.plot(range(len(loss_m)),loss_m)\n",
    "plt.show()\n",
    "# losses = history.history['loss']\n",
    "# print(losses)\n",
    "# plt.plot(range(len(losses)),losses)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "shape: (78, 1)\n",
      "[0.54539295 0.44850949 0.42344173 0.48577236 0.49051491 0.56368564\n",
      " 0.57520325 0.55691057]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "shape: (86,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# for i in range(time_steps, N):\n",
    "#     X_entrenamiento.append(c_entrenamiento_n[i-time_steps:i, 0])#toma paquetes de 8 en 8\n",
    "#     y_entrenamiento.append(c_entrenamiento_n[i, 0])#se toma el elemento 8+1\n",
    "\n",
    "# Ahora, el modelo ha sido entrenado de manera iterativa\n",
    "\n",
    "# print(X_entrenamiento.shape)\n",
    "# print(X_entrenamiento[0,:].shape)\n",
    "f_X_test_cierre = np.reshape(X_entrenamiento[0,:], (1, X_entrenamiento[0,:].shape[0], 1))\n",
    "# print(f_X_test_cierre)\n",
    "f_predicted_sp_cierre = red.predict(f_X_test_cierre)\n",
    "print(f\"shape: {precios_predichos.shape}\")\n",
    "f_predicted_sp_cierre = m_m_s.inverse_transform(f_predicted_sp_cierre)\n",
    "print(f_X_test_cierre.reshape(8))\n",
    "\n",
    "# Predice el conjunto de prueba usando la prediccion predictiva (ñps datos que va prediciendo)\n",
    "\n",
    "predicted_stock_price_cierre_pred = utls.genera_prediccion_predictiva(f_X_test_cierre.reshape(8),8,78,red)\n",
    "print(f\"shape: {predicted_stock_price_cierre_pred.shape}\")\n",
    "temp = predicted_stock_price_cierre_pred\n",
    "predicted_stock_price_cierre_pred = m_m_s.inverse_transform(predicted_stock_price_cierre_pred.reshape(86,1))\n",
    "# input_shape_primera_capa = red.layers[0].input_shape\n",
    "# print(input_shape_primera_capa[1:])\n",
    "\n",
    "# arreglo_una_dimension = np.random.rand(8)  # Completa con tus valores reales\n",
    "\n",
    "# # Utilizar input_shape_primera_capa en la función reshape\n",
    "# arreglo_reshape = arreglo_una_dimension.reshape(1, *input_shape_primera_capa[1:])\n",
    "# print(arreglo_reshape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predice el conjunto de entrenamiento usando la prediccion predictiva (usando los datos que predice)\n",
    "\n",
    "#f_X_train_cierre = np.reshape(X_entrenamiento[0,:], (1, X_entrenamiento[0,:].shape[0], 1))\n",
    "f_X_train_cierre = c_entrenamiento_n[:time_steps].reshape(8)\n",
    "# # print(f_X_test_cierre)\n",
    "# f_predicted_t_sp_cierre = red.predict(f_X_train_cierre)\n",
    "# print(f\"shape: {precios_predichos.shape}\")\n",
    "# f_predicted_sp_cierre = m_m_s.inverse_transform(f_predicted_t_sp_cierre)\n",
    "# print(f_X_test_cierre.reshape(8))\n",
    "\n",
    "predicted_stock_price_cierre_pred_t = utls.genera_prediccion_predictiva(f_X_train_cierre,8,182,red)\n",
    "# print(f\"shape: {predicted_stock_price_cierre_pred_t.shape}\")\n",
    "# temp_t = predicted_stock_price_cierre_pred_t\n",
    "# predicted_stock_price_cierre_pred = m_m_s.inverse_transform(predicted_stock_price_cierre_pred.reshape(86,1))\n",
    "\n",
    "#Sin normalizar\n",
    "plt.plot(c_entrenamiento_n, color = 'black', label = 'COMI original Stock prices')\n",
    "plt.plot(predicted_stock_price_cierre_pred_t, color = 'green', label = 'Predicted COMI closing Stock prices') #ts_cierre_s_pred[:,0]\n",
    "plt.title('COMI Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('COMI Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Sin normalizar\n",
    "plt.plot(inputs_cierre, color = 'black', label = 'COMI original Stock prices')\n",
    "plt.plot(temp, color = 'green', label = 'Predicted COMI closing Stock prices')\n",
    "plt.title('COMI Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('COMI Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Sin normalizar\n",
    "# plt.plot(inputs_cierre, color = 'black', label = 'COMI original Stock prices')\n",
    "# plt.plot(temp, color = 'green', label = 'Predicted COMI closing Stock prices')\n",
    "# plt.title('COMI Stock Price Prediction')\n",
    "# plt.xlabel('Time')\n",
    "# plt.ylabel('COMI Stock Price')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.plot(precios_reales, color = 'black', label = 'COMI original Stock prices')\n",
    "# plt.plot(predicted_stock_price_cierre_pred, color = 'green', label = 'Predicted COMI closing Stock prices')\n",
    "# plt.title('COMI Stock Price Prediction')\n",
    "# plt.xlabel('Time')\n",
    "# plt.ylabel('COMI Stock Price')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.9232, dtype=torch.float64)\n",
      "tensor(36.7176, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "criterion = nn.MSELoss()\n",
    "perdida = criterion(torch.tensor(precios_reales),torch.tensor(precios_predichos))\n",
    "print(perdida)\n",
    "perdida = criterion(torch.tensor(precios_reales),torch.tensor(predicted_stock_price_cierre_pred[:78]))\n",
    "print(perdida)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
