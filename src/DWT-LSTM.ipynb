{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import reader1 as rd\n",
    "import utilerias as utls\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import PIL.Image\n",
    "# Llamamos a la función antes de ejecutar el script\n",
    "utls.eliminar_archivos_registro(\"logs/lstm\")\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('logs/lstm')\n",
    "DATOS = 'Datos históricos COMI 3ene16-31dic2020 semanal.csv'\n",
    "cierre = rd.leer_archivo(DATOS).astype(float)\n",
    "c_entrenamiento = np.array(cierre[:int(len(cierre) * 0.7)])\n",
    "\n",
    "#Se convierte en un arreglo bidimensional\n",
    "c_entrenamiento = np.reshape(c_entrenamiento, (c_entrenamiento.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "m_m_s = MinMaxScaler(feature_range=(0,1))\n",
    "c_entrenamiento_n = m_m_s.fit_transform(c_entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 8\n",
    "N = len(c_entrenamiento_n) #182\n",
    "X_entrenamiento = []\n",
    "y_entrenamiento = []\n",
    "for i in range(time_steps, N):\n",
    "    X_entrenamiento.append(c_entrenamiento_n[i-time_steps:i, 0])#toma paquetes de 8 en 8\n",
    "    y_entrenamiento.append(c_entrenamiento_n[i, 0])#se toma el elemento 8+1\n",
    "X_entrenamiento, y_entrenamiento = np.array(X_entrenamiento), np.array(y_entrenamiento)\n",
    "#Se le da una tercera dimension al conjunto de entradas de entrenamiento\n",
    "X_entrenamiento = np.reshape(X_entrenamiento, (X_entrenamiento.shape[0], X_entrenamiento.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.models import load_model\n",
    "\n",
    "red = load_model('models/LSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04610616 0.10422317 0.1542038  0.15575358 0.12553274 0.14567997\n",
      " 0.14645486 0.19604804 0.2305308  0.20844634 0.21193336 0.207284\n",
      " 0.19294847 0.19682294 0.21425804 0.18132507 0.17512592 0.14800465\n",
      " 0.15885316 0.19217358 0.18597443 0.26695079 0.29252228 0.31770632\n",
      " 0.31266951 0.28903526 0.28283611 0.29949632 0.27586207 0.27469973\n",
      " 0.27547462 0.33475397 0.35567609 0.3366912  0.33359163 0.3847346\n",
      " 0.57109647 0.59628051 0.57458349 0.60635413 0.58465711 0.56877179\n",
      " 0.64277412 0.66175901 0.67299496 0.7105773  0.7039907  0.7272375\n",
      " 0.72258814 0.77179388 0.72452538 0.67105773 0.67376986 0.71445176\n",
      " 0.74389771 0.72258814 0.69934134 0.73731112 0.7214258  0.71871368\n",
      " 0.6741573  0.69856645 0.72103836 0.72258814 0.75629601 0.82758621\n",
      " 0.83882216 0.79426579 0.78380473 0.76791941 0.78457962 0.87872917\n",
      " 0.8756296  0.84889578 0.81828749 0.82681131 0.78535451 0.78922898\n",
      " 0.8341728  0.81247578 0.80123983 0.80317706 0.7934909  0.76017048\n",
      " 0.73537389 0.71018985 0.71212708 0.7396358  0.73614878 0.66757071\n",
      " 0.66989539 0.69662921 0.65594731 0.67880666 0.67609454 0.72956219\n",
      " 0.70127857 0.76753196 0.75513367 0.74506005 0.7520341  0.7098024\n",
      " 0.69043007 0.75435878 0.7222007  0.84850833 0.905463   0.8822162\n",
      " 0.90778768 0.88957768 0.87485471 0.91321193 1.         0.97055405\n",
      " 0.88880279 0.87795428 0.84889578 0.8341728  0.85509492 0.87524215\n",
      " 0.85703216 0.85005812 0.84269663 0.82293685 0.77450601 0.78419217\n",
      " 0.85974429 0.85432003 0.83688493 0.82991089 0.887253   0.85974429\n",
      " 0.83959706 0.78380473 0.81828749 0.79116621 0.76055792 0.79155366\n",
      " 0.7686943  0.7686943  0.79891515 0.79000387 0.76017048 0.68539326\n",
      " 0.60519179 0.66485858 0.70786517 0.66485858 0.71135219 0.67725688\n",
      " 0.76210771 0.80705153 0.81518791 0.90623789 0.95970554 0.9643549\n",
      " 0.8880279  0.89267726 0.87524215 0.85083301 0.84889578 0.96241767\n",
      " 0.96784192 0.94072065 0.97249128 0.99690043 0.95118171 0.89577683\n",
      " 0.8814413  0.9170864  0.91979853 0.96164277 0.96822937 0.95776831]\n"
     ]
    }
   ],
   "source": [
    "print(y_entrenamiento)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#Se entrena con un aprendizaje por reforzamiento del profesor\\nred = Sequential()\\nred.add(LSTM(units=50,return_sequences=True,input_shape=(X_entrenamiento.shape[1], 1)))#tiene un tamaño de entrada de 8 y de salida 1, input_shape = (8, 1)\\nred.add(Dropout(0.2))#Se apagan aleatoriamente el 20% de las neuronas de la capa anterior\\nred.add(LSTM(units=50,return_sequences=True))\\nred.add(Dropout(0.2))\\nred.add(LSTM(units=50,return_sequences=True))\\nred.add(Dropout(0.2))\\nred.add(LSTM(units=50))\\nred.add(Dropout(0.2))\\nred.add(Dense(units=1))\\nred.compile(optimizer=Adam(learning_rate=0.0001),loss='mean_squared_error')# mejor, , SGD(learning_rate=0.1)\\nhistory = red.fit(X_entrenamiento,y_entrenamiento,epochs=60,batch_size=32)#batch_size=32\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#Se entrena con un aprendizaje por reforzamiento del profesor\n",
    "red = Sequential()\n",
    "red.add(LSTM(units=50,return_sequences=True,input_shape=(X_entrenamiento.shape[1], 1)))#tiene un tamaño de entrada de 8 y de salida 1, input_shape = (8, 1)\n",
    "red.add(Dropout(0.2))#Se apagan aleatoriamente el 20% de las neuronas de la capa anterior\n",
    "red.add(LSTM(units=50,return_sequences=True))\n",
    "red.add(Dropout(0.2))\n",
    "red.add(LSTM(units=50,return_sequences=True))\n",
    "red.add(Dropout(0.2))\n",
    "red.add(LSTM(units=50))\n",
    "red.add(Dropout(0.2))\n",
    "red.add(Dense(units=1))\n",
    "red.compile(optimizer=Adam(learning_rate=0.0001),loss='mean_squared_error')# mejor, , SGD(learning_rate=0.1)\n",
    "history = red.fit(X_entrenamiento,y_entrenamiento,epochs=60,batch_size=32)#batch_size=32\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"losses = history.history['loss']\\nprint(losses)\\nplt.plot(range(len(losses)),losses)\\nplt.show()\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtener la pérdida durante el entrenamiento\n",
    "\"\"\"losses = history.history['loss']\n",
    "print(losses)\n",
    "plt.plot(range(len(losses)),losses)\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "precios_reales = cierre[int(len(cierre) * 0.7):] #verdaderos valores del conjunto de prueba\n",
    "precios_reales = np.reshape(precios_reales, (precios_reales.shape[0], 1)) #se le da una dimension mas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0)\n",
    "# inputs = dataset_total[len(dataset_total) - len(dataset_test) - time_steps:].values\n",
    "\n",
    "inputs_cierre = cierre[len(cierre) - len(precios_reales) - time_steps:]#toma los ultimos 86 elementos, los ultimos 8 de entrenamiento y todos los de prueba  \n",
    "#print(len(cierre) - len(precios_reales) - time_steps)\n",
    "inputs_cierre = np.array(inputs_cierre).reshape(-1,1)\n",
    "#print(len(inputs_cierre))\n",
    "#print(inputs_cierre.shape)\n",
    "m_m_s_entrenamiento = MinMaxScaler(feature_range=(0,1))\n",
    "inputs_cierre = m_m_s_entrenamiento.fit_transform(inputs_cierre)# se normalizan los datos usandlo los parametros que se le dieron a m_m_s\n",
    "#inputs_cierre = m_m_s.transform(inputs_cierre) \n",
    "X_entrenamiento = []\n",
    "for i in range(time_steps, len(inputs_cierre)):\n",
    "    X_entrenamiento.append(inputs_cierre[i-time_steps:i, 0]) # setoman en paquetes de 8 \n",
    "X_entrenamiento = np.array(X_entrenamiento)\n",
    "X_entrenamiento = np.reshape(X_entrenamiento, (X_entrenamiento.shape[0], X_entrenamiento.shape[1], 1))#(78, 8, 1)\n",
    "\n",
    "precios_predichos = red.predict(X_entrenamiento)\n",
    "s_normalizar = precios_predichos\n",
    "precios_predichos = m_m_s_entrenamiento.inverse_transform(precios_predichos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#La normalización funciona correctamente\n",
    "plt.plot(precios_reales, color = 'black', label = 'COMI original Stock prices')\n",
    "plt.plot(precios_predichos, color = 'green', label = 'Predicted COMI closing Stock prices')\n",
    "plt.title('COMI Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('COMI Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo entrenado\n",
    "# red.save('models/LSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y_entrenamiento.size)\n",
    "# plt.plot(y_entrenamiento)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_cierre_s_pred = c_entrenamiento_n\n",
    "\n",
    "# loss_m = []\n",
    "# for epoch in range(100):  # Número de épocas\n",
    "#     ts_cierre_s_pred = c_entrenamiento_n[:time_steps]#se obtienen los primeros time_steps(8) elementos del trainig set\n",
    "#     loss = []\n",
    "#     X_train_c_pred = []\n",
    "#     # print(f\"grtrt: {ts_cierre_s_pred}\")\n",
    "#     for i in range(time_steps, N):\n",
    "#         # Obtener las características y la etiqueta actual\n",
    "#         x_actual = ts_cierre_s_pred[i-time_steps:i,0]\n",
    "#         X_train_c_pred.append(x_actual)\n",
    "#         x_actual = x_actual.reshape(1,time_steps,1)\n",
    "\n",
    "#         y_actual = np.array([y_entrenamiento[i-time_steps]])\n",
    "\n",
    "#         print(f\"x_actual: {x_actual}\")\n",
    "#         print(f\"y_actual: {y_actual}\")\n",
    "        \n",
    "#         # Entrenar el modelo con las nuevas características y la etiqueta real\n",
    "#         #loss.append(red.train_on_batch(x_actual, y_actual))\n",
    "\n",
    "#         # Predicción del modelo\n",
    "#         #prediccion = red.predict(x_actual)#.reshape(1,1,1)\n",
    "#         prediccion = red(x_actual)\n",
    "        \n",
    "#         # Agregar la predicción a las características para el siguiente paso\n",
    "#         # print(ts_cierre_s_pred)\n",
    "#         print(f\"prediccion: {prediccion}\")\n",
    "#         ts_cierre_s_pred = np.concatenate([ts_cierre_s_pred, prediccion])\n",
    "\n",
    "\n",
    "\n",
    "#     # print(f\"mean: {np.mean(np.array(loss))}\")\n",
    "#     # loss_m.append(np.mean(np.array(loss)))\n",
    "#     X_train_c_pred = np.array(X_train_c_pred)\n",
    "#     X_train_c_pred = np.reshape(X_train_c_pred, (X_train_c_pred.shape[0], X_train_c_pred.shape[1], 1))\n",
    "#     history = red.fit(X_train_c_pred, y_entrenamiento, epochs=1, batch_size=32)\n",
    "#     loss = history.history['loss']\n",
    "#     loss_m.append(loss)\n",
    "#     loss_m.append(mean_squared_error(c_entrenamiento_n,ts_cierre_s_pred[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "from keras import backend as K\n",
    "\n",
    "class CustomLearningRateScheduler(Callback):\n",
    "    def __init__(self, initial_lr, decay_factor):\n",
    "        super(CustomLearningRateScheduler, self).__init__()\n",
    "        self.initial_lr = initial_lr\n",
    "        self.decay_factor = decay_factor\n",
    "        self.iteration = 0  # Contador de iteraciones\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        #lr = self.initial_lr * (self.decay_factor ** self.iteration)\n",
    "        lr = self.initial_lr / (1 + self.decay_factor * self.iteration)\n",
    "        print(f\"lr: {lr}, batch: {batch}\")\n",
    "        if (logs['epoca'] == 1):\n",
    "            writer.add_scalar(\"Learning Rate en cada batch: \",lr,batch)\n",
    "        #print(red.summary())\n",
    "        K.set_value(red.optimizer.lr, lr)\n",
    "        self.iteration += 1\n",
    "    \n",
    "    def reset(self):\n",
    "        K.set_value(red.optimizer.lr, self.initial_lr)\n",
    "        self.iteration = 0\n",
    "        print(\"Se resetea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se resetea\n",
      "y_entrenamiento: [0.04610616 0.10422317 0.1542038  0.15575358 0.12553274 0.14567997\n",
      " 0.14645486 0.19604804 0.2305308  0.20844634 0.21193336 0.207284\n",
      " 0.19294847 0.19682294 0.21425804 0.18132507 0.17512592 0.14800465\n",
      " 0.15885316 0.19217358 0.18597443 0.26695079 0.29252228 0.31770632\n",
      " 0.31266951 0.28903526 0.28283611 0.29949632 0.27586207 0.27469973\n",
      " 0.27547462 0.33475397 0.35567609 0.3366912  0.33359163 0.3847346\n",
      " 0.57109647 0.59628051 0.57458349 0.60635413 0.58465711 0.56877179\n",
      " 0.64277412 0.66175901 0.67299496 0.7105773  0.7039907  0.7272375\n",
      " 0.72258814 0.77179388 0.72452538 0.67105773 0.67376986 0.71445176\n",
      " 0.74389771 0.72258814 0.69934134 0.73731112 0.7214258  0.71871368\n",
      " 0.6741573  0.69856645 0.72103836 0.72258814 0.75629601 0.82758621\n",
      " 0.83882216 0.79426579 0.78380473 0.76791941 0.78457962 0.87872917\n",
      " 0.8756296  0.84889578 0.81828749 0.82681131 0.78535451 0.78922898\n",
      " 0.8341728  0.81247578 0.80123983 0.80317706 0.7934909  0.76017048\n",
      " 0.73537389 0.71018985 0.71212708 0.7396358  0.73614878 0.66757071\n",
      " 0.66989539 0.69662921 0.65594731 0.67880666 0.67609454 0.72956219\n",
      " 0.70127857 0.76753196 0.75513367 0.74506005 0.7520341  0.7098024\n",
      " 0.69043007 0.75435878 0.7222007  0.84850833 0.905463   0.8822162\n",
      " 0.90778768 0.88957768 0.87485471 0.91321193 1.         0.97055405\n",
      " 0.88880279 0.87795428 0.84889578 0.8341728  0.85509492 0.87524215\n",
      " 0.85703216 0.85005812 0.84269663 0.82293685 0.77450601 0.78419217\n",
      " 0.85974429 0.85432003 0.83688493 0.82991089 0.887253   0.85974429\n",
      " 0.83959706 0.78380473 0.81828749 0.79116621 0.76055792 0.79155366\n",
      " 0.7686943  0.7686943  0.79891515 0.79000387 0.76017048 0.68539326\n",
      " 0.60519179 0.66485858 0.70786517 0.66485858 0.71135219 0.67725688\n",
      " 0.76210771 0.80705153 0.81518791 0.90623789 0.95970554 0.9643549\n",
      " 0.8880279  0.89267726 0.87524215 0.85083301 0.84889578 0.96241767\n",
      " 0.96784192 0.94072065 0.97249128 0.99690043 0.95118171 0.89577683\n",
      " 0.8814413  0.9170864  0.91979853 0.96164277 0.96822937 0.95776831]\n",
      "0\n",
      "[[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "ejemplar: [0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      " 0.03448276 0.04223169]\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.24278472]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      "  0.03448276 0.04223169]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03868245705962181\n",
      "Predicción post entrenamiento : [[0.21255413]]\n",
      "PERDIDAAAA despues: 0.02770492620766163\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "[[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24278472]]]\n",
      "ejemplar: [0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      " 0.04223169 0.24278472]\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.19715632]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      "  0.04223169 0.24278472]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00863657146692276\n",
      "Predicción post entrenamiento : [[0.17470233]]\n",
      "PERDIDAAAA despues: 0.004967312328517437\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "[[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24278472]\n",
      "  [0.19715632]]]\n",
      "ejemplar: [0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      " 0.24278472 0.19715632]\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.17860867]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      "  0.24278472 0.19715632]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005955976084806025\n",
      "Predicción post entrenamiento : [[0.17443852]]\n",
      "PERDIDAAAA despues: 0.00040944386273622513\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "[[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24278472]\n",
      "  [0.19715632]\n",
      "  [0.17860867]]]\n",
      "ejemplar: [0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.24278472\n",
      " 0.19715632 0.17860867]\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.18559977]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.24278472\n",
      "  0.19715632 0.17860867]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008907951414585114\n",
      "Predicción post entrenamiento : [[0.18170433]]\n",
      "PERDIDAAAA despues: 0.0006734411581419408\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "[[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24278472]\n",
      "  [0.19715632]\n",
      "  [0.17860867]\n",
      "  [0.18559977]]]\n",
      "ejemplar: [0.05656722 0.02595893 0.03448276 0.04223169 0.24278472 0.19715632\n",
      " 0.17860867 0.18559977]\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.19400132]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[0.05656722 0.02595893 0.03448276 0.04223169 0.24278472 0.19715632\n",
      "  0.17860867 0.18559977]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004687945358455181\n",
      "Predicción post entrenamiento : [[0.18391134]]\n",
      "PERDIDAAAA despues: 0.0034080599434673786\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "[[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24278472]\n",
      "  [0.19715632]\n",
      "  [0.17860867]\n",
      "  [0.18559977]\n",
      "  [0.19400132]]]\n",
      "ejemplar: [0.02595893 0.03448276 0.04223169 0.24278472 0.19715632 0.17860867\n",
      " 0.18559977 0.19400132]\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.19345982]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[0.02595893 0.03448276 0.04223169 0.24278472 0.19715632 0.17860867\n",
      "  0.18559977 0.19400132]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002282914938405156\n",
      "Predicción post entrenamiento : [[0.1876435]]\n",
      "PERDIDAAAA despues: 0.0017609380884096026\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "[[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24278472]\n",
      "  [0.19715632]\n",
      "  [0.17860867]\n",
      "  [0.18559977]\n",
      "  [0.19400132]\n",
      "  [0.19345982]]]\n",
      "ejemplar: [0.03448276 0.04223169 0.24278472 0.19715632 0.17860867 0.18559977\n",
      " 0.19400132 0.19345982]\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.20782712]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[0.03448276 0.04223169 0.24278472 0.19715632 0.17860867 0.18559977\n",
      "  0.19400132 0.19345982]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0037665548734366894\n",
      "Predicción post entrenamiento : [[0.20265839]]\n",
      "PERDIDAAAA despues: 0.0031588366255164146\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "[[[0.04223169]\n",
      "  [0.24278472]\n",
      "  [0.19715632]\n",
      "  [0.17860867]\n",
      "  [0.18559977]\n",
      "  [0.19400132]\n",
      "  [0.19345982]\n",
      "  [0.20782712]]]\n",
      "ejemplar: [0.04223169 0.24278472 0.19715632 0.17860867 0.18559977 0.19400132\n",
      " 0.19345982 0.20782712]\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.22701366]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[0.04223169 0.24278472 0.19715632 0.17860867 0.18559977 0.19400132\n",
      "  0.19345982 0.20782712]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000958869990427047\n",
      "Predicción post entrenamiento : [[0.22544122]]\n",
      "PERDIDAAAA despues: 0.0008639590814709663\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "[[[0.24278472]\n",
      "  [0.19715632]\n",
      "  [0.17860867]\n",
      "  [0.18559977]\n",
      "  [0.19400132]\n",
      "  [0.19345982]\n",
      "  [0.20782712]\n",
      "  [0.22701366]]]\n",
      "ejemplar: [0.24278472 0.19715632 0.17860867 0.18559977 0.19400132 0.19345982\n",
      " 0.20782712 0.22701366]\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.2542528]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[0.24278472 0.19715632 0.17860867 0.18559977 0.19400132 0.19345982\n",
      "  0.20782712 0.22701366]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005627329228445888\n",
      "Predicción post entrenamiento : [[0.25306112]]\n",
      "PERDIDAAAA despues: 0.0005076152156107128\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "[[[0.19715632]\n",
      "  [0.17860867]\n",
      "  [0.18559977]\n",
      "  [0.19400132]\n",
      "  [0.19345982]\n",
      "  [0.20782712]\n",
      "  [0.22701366]\n",
      "  [0.25425279]]]\n",
      "ejemplar: [0.19715632 0.17860867 0.18559977 0.19400132 0.19345982 0.20782712\n",
      " 0.22701366 0.25425279]\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.24427629]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[0.19715632 0.17860867 0.18559977 0.19400132 0.19345982 0.20782712\n",
      "  0.22701366 0.25425279]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012837850954383612\n",
      "Predicción post entrenamiento : [[0.24334219]]\n",
      "PERDIDAAAA despues: 0.001217720448039472\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "[[[0.17860867]\n",
      "  [0.18559977]\n",
      "  [0.19400132]\n",
      "  [0.19345982]\n",
      "  [0.20782712]\n",
      "  [0.22701366]\n",
      "  [0.25425279]\n",
      "  [0.24427629]]]\n",
      "ejemplar: [0.17860867 0.18559977 0.19400132 0.19345982 0.20782712 0.22701366\n",
      " 0.25425279 0.24427629]\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.24366067]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[0.17860867 0.18559977 0.19400132 0.19345982 0.20782712 0.22701366\n",
      "  0.25425279 0.24427629]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010066224494948983\n",
      "Predicción post entrenamiento : [[0.24294524]]\n",
      "PERDIDAAAA despues: 0.0009617366595193744\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "[[[0.18559977]\n",
      "  [0.19400132]\n",
      "  [0.19345982]\n",
      "  [0.20782712]\n",
      "  [0.22701366]\n",
      "  [0.25425279]\n",
      "  [0.24427629]\n",
      "  [0.24366067]]]\n",
      "ejemplar: [0.18559977 0.19400132 0.19345982 0.20782712 0.22701366 0.25425279\n",
      " 0.24427629 0.24366067]\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.24836661]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[0.18559977 0.19400132 0.19345982 0.20782712 0.22701366 0.25425279\n",
      "  0.24427629 0.24366067]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001687780488282442\n",
      "Predicción post entrenamiento : [[0.24725081]]\n",
      "PERDIDAAAA despues: 0.0015973456902429461\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "[[[0.19400132]\n",
      "  [0.19345982]\n",
      "  [0.20782712]\n",
      "  [0.22701366]\n",
      "  [0.25425279]\n",
      "  [0.24427629]\n",
      "  [0.24366067]\n",
      "  [0.24836661]]]\n",
      "ejemplar: [0.19400132 0.19345982 0.20782712 0.22701366 0.25425279 0.24427629\n",
      " 0.24366067 0.24836661]\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.2531736]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[0.19400132 0.19345982 0.20782712 0.22701366 0.25425279 0.24427629\n",
      "  0.24366067 0.24836661]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0036270644050091505\n",
      "Predicción post entrenamiento : [[0.25167045]]\n",
      "PERDIDAAAA despues: 0.003448270261287689\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "[[[0.19345982]\n",
      "  [0.20782712]\n",
      "  [0.22701366]\n",
      "  [0.25425279]\n",
      "  [0.24427629]\n",
      "  [0.24366067]\n",
      "  [0.24836661]\n",
      "  [0.25317359]]]\n",
      "ejemplar: [0.19345982 0.20782712 0.22701366 0.25425279 0.24427629 0.24366067\n",
      " 0.24836661 0.25317359]\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.25776872]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[0.19345982 0.20782712 0.22701366 0.25425279 0.24427629 0.24366067\n",
      "  0.24836661 0.25317359]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0037143880035728216\n",
      "Predicción post entrenamiento : [[0.25631812]]\n",
      "PERDIDAAAA despues: 0.003539676545187831\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "[[[0.20782712]\n",
      "  [0.22701366]\n",
      "  [0.25425279]\n",
      "  [0.24427629]\n",
      "  [0.24366067]\n",
      "  [0.24836661]\n",
      "  [0.25317359]\n",
      "  [0.25776872]]]\n",
      "ejemplar: [0.20782712 0.22701366 0.25425279 0.24427629 0.24366067 0.24836661\n",
      " 0.25317359 0.25776872]\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.26442772]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[0.20782712 0.22701366 0.25425279 0.24427629 0.24366067 0.24836661\n",
      "  0.25317359 0.25776872]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0025169963482767344\n",
      "Predicción post entrenamiento : [[0.2620473]]\n",
      "PERDIDAAAA despues: 0.0022838120348751545\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "[[[0.22701366]\n",
      "  [0.25425279]\n",
      "  [0.24427629]\n",
      "  [0.24366067]\n",
      "  [0.24836661]\n",
      "  [0.25317359]\n",
      "  [0.25776872]\n",
      "  [0.26442772]]]\n",
      "ejemplar: [0.22701366 0.25425279 0.24427629 0.24366067 0.24836661 0.25317359\n",
      " 0.25776872 0.26442772]\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.26904806]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[0.22701366 0.25425279 0.24427629 0.24366067 0.24836661 0.25317359\n",
      "  0.25776872 0.26442772]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007695325184613466\n",
      "Predicción post entrenamiento : [[0.26658383]]\n",
      "PERDIDAAAA despues: 0.0072690574452281\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "[[[0.25425279]\n",
      "  [0.24427629]\n",
      "  [0.24366067]\n",
      "  [0.24836661]\n",
      "  [0.25317359]\n",
      "  [0.25776872]\n",
      "  [0.26442772]\n",
      "  [0.26904806]]]\n",
      "ejemplar: [0.25425279 0.24427629 0.24366067 0.24836661 0.25317359 0.25776872\n",
      " 0.26442772 0.26904806]\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.27102053]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[0.25425279 0.24427629 0.24366067 0.24836661 0.25317359 0.25776872\n",
      "  0.26442772 0.26904806]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009195774793624878\n",
      "Predicción post entrenamiento : [[0.27028435]]\n",
      "PERDIDAAAA despues: 0.009055126458406448\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "[[[0.24427629]\n",
      "  [0.24366067]\n",
      "  [0.24836661]\n",
      "  [0.25317359]\n",
      "  [0.25776872]\n",
      "  [0.26442772]\n",
      "  [0.26904806]\n",
      "  [0.27102053]]]\n",
      "ejemplar: [0.24427629 0.24366067 0.24836661 0.25317359 0.25776872 0.26442772\n",
      " 0.26904806 0.27102053]\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.2698473]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[0.24427629 0.24366067 0.24836661 0.25317359 0.25776872 0.26442772\n",
      "  0.26904806 0.27102053]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014845632016658783\n",
      "Predicción post entrenamiento : [[0.26506102]]\n",
      "PERDIDAAAA despues: 0.013702193275094032\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "[[[0.24366067]\n",
      "  [0.24836661]\n",
      "  [0.25317359]\n",
      "  [0.25776872]\n",
      "  [0.26442772]\n",
      "  [0.26904806]\n",
      "  [0.27102053]\n",
      "  [0.2698473 ]]]\n",
      "ejemplar: [0.24366067 0.24836661 0.25317359 0.25776872 0.26442772 0.26904806\n",
      " 0.27102053 0.2698473 ]\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.26717573]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[0.24366067 0.24836661 0.25317359 0.25776872 0.26442772 0.26904806\n",
      "  0.27102053 0.2698473 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01173378061503172\n",
      "Predicción post entrenamiento : [[0.2652874]]\n",
      "PERDIDAAAA despues: 0.011328247375786304\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "[[[0.24836661]\n",
      "  [0.25317359]\n",
      "  [0.25776872]\n",
      "  [0.26442772]\n",
      "  [0.26904806]\n",
      "  [0.27102053]\n",
      "  [0.2698473 ]\n",
      "  [0.26717573]]]\n",
      "ejemplar: [0.24836661 0.25317359 0.25776872 0.26442772 0.26904806 0.27102053\n",
      " 0.2698473  0.26717573]\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.2683125]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[0.24836661 0.25317359 0.25776872 0.26442772 0.26904806 0.27102053\n",
      "  0.2698473  0.26717573]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005797138903290033\n",
      "Predicción post entrenamiento : [[0.2665165]]\n",
      "PERDIDAAAA despues: 0.005526872351765633\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "[[[0.25317359]\n",
      "  [0.25776872]\n",
      "  [0.26442772]\n",
      "  [0.26904806]\n",
      "  [0.27102053]\n",
      "  [0.2698473 ]\n",
      "  [0.26717573]\n",
      "  [0.26831251]]]\n",
      "ejemplar: [0.25317359 0.25776872 0.26442772 0.26904806 0.27102053 0.2698473\n",
      " 0.26717573 0.26831251]\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.26934445]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[0.25317359 0.25776872 0.26442772 0.26904806 0.27102053 0.2698473\n",
      "  0.26717573 0.26831251]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006950559560209513\n",
      "Predicción post entrenamiento : [[0.26748702]]\n",
      "PERDIDAAAA despues: 0.0066443015821278095\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "[[[0.25776872]\n",
      "  [0.26442772]\n",
      "  [0.26904806]\n",
      "  [0.27102053]\n",
      "  [0.2698473 ]\n",
      "  [0.26717573]\n",
      "  [0.26831251]\n",
      "  [0.26934445]]]\n",
      "ejemplar: [0.25776872 0.26442772 0.26904806 0.27102053 0.2698473  0.26717573\n",
      " 0.26831251 0.26934445]\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.26995495]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[0.25776872 0.26442772 0.26904806 0.27102053 0.2698473  0.26717573\n",
      "  0.26831251 0.26934445]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 9.024998689710628e-06\n",
      "Predicción post entrenamiento : [[0.26922268]]\n",
      "PERDIDAAAA despues: 5.161487024452072e-06\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "[[[0.26442772]\n",
      "  [0.26904806]\n",
      "  [0.27102053]\n",
      "  [0.2698473 ]\n",
      "  [0.26717573]\n",
      "  [0.26831251]\n",
      "  [0.26934445]\n",
      "  [0.26995495]]]\n",
      "ejemplar: [0.26442772 0.26904806 0.27102053 0.2698473  0.26717573 0.26831251\n",
      " 0.26934445 0.26995495]\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.2712194]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[0.26442772 0.26904806 0.27102053 0.2698473  0.26717573 0.26831251\n",
      "  0.26934445 0.26995495]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00045381265226751566\n",
      "Predicción post entrenamiento : [[0.27062765]]\n",
      "PERDIDAAAA despues: 0.0004793749831151217\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "[[[0.26904806]\n",
      "  [0.27102053]\n",
      "  [0.2698473 ]\n",
      "  [0.26717573]\n",
      "  [0.26831251]\n",
      "  [0.26934445]\n",
      "  [0.26995495]\n",
      "  [0.2712194 ]]]\n",
      "ejemplar: [0.26904806 0.27102053 0.2698473  0.26717573 0.26831251 0.26934445\n",
      " 0.26995495 0.2712194 ]\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.27154228]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[0.26904806 0.27102053 0.2698473  0.26717573 0.26831251 0.26934445\n",
      "  0.26995495 0.2712194 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002131118206307292\n",
      "Predicción post entrenamiento : [[0.27265054]]\n",
      "PERDIDAAAA despues: 0.002030023140832782\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "[[[0.27102053]\n",
      "  [0.2698473 ]\n",
      "  [0.26717573]\n",
      "  [0.26831251]\n",
      "  [0.26934445]\n",
      "  [0.26995495]\n",
      "  [0.2712194 ]\n",
      "  [0.27154228]]]\n",
      "ejemplar: [0.27102053 0.2698473  0.26717573 0.26831251 0.26934445 0.26995495\n",
      " 0.2712194  0.27154228]\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.2727202]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[0.27102053 0.2698473  0.26717573 0.26831251 0.26934445 0.26995495\n",
      "  0.2712194  0.27154228]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015959488227963448\n",
      "Predicción post entrenamiento : [[0.27359042]]\n",
      "PERDIDAAAA despues: 0.0015271760057657957\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "[[[0.2698473 ]\n",
      "  [0.26717573]\n",
      "  [0.26831251]\n",
      "  [0.26934445]\n",
      "  [0.26995495]\n",
      "  [0.2712194 ]\n",
      "  [0.27154228]\n",
      "  [0.27272019]]]\n",
      "ejemplar: [0.2698473  0.26717573 0.26831251 0.26934445 0.26995495 0.2712194\n",
      " 0.27154228 0.27272019]\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.27326965]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[0.2698473  0.26717573 0.26831251 0.26934445 0.26995495 0.2712194\n",
      "  0.27154228 0.27272019]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00024855436640791595\n",
      "Predicción post entrenamiento : [[0.27337214]]\n",
      "PERDIDAAAA despues: 0.00024533324176445603\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "[[[0.26717573]\n",
      "  [0.26831251]\n",
      "  [0.26934445]\n",
      "  [0.26995495]\n",
      "  [0.2712194 ]\n",
      "  [0.27154228]\n",
      "  [0.27272019]\n",
      "  [0.27326965]]]\n",
      "ejemplar: [0.26717573 0.26831251 0.26934445 0.26995495 0.2712194  0.27154228\n",
      " 0.27272019 0.27326965]\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.27332285]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[0.26717573 0.26831251 0.26934445 0.26995495 0.2712194  0.27154228\n",
      "  0.27272019 0.27326965]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 9.050209337146953e-05\n",
      "Predicción post entrenamiento : [[0.273648]]\n",
      "PERDIDAAAA despues: 8.442146645393223e-05\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "[[[0.26831251]\n",
      "  [0.26934445]\n",
      "  [0.26995495]\n",
      "  [0.2712194 ]\n",
      "  [0.27154228]\n",
      "  [0.27272019]\n",
      "  [0.27326965]\n",
      "  [0.27332285]]]\n",
      "ejemplar: [0.26831251 0.26934445 0.26995495 0.2712194  0.27154228 0.27272019\n",
      " 0.27326965 0.27332285]\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.27426848]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[0.26831251 0.26934445 0.26995495 0.2712194  0.27154228 0.27272019\n",
      "  0.27326965 0.27332285]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006364441360346973\n",
      "Predicción post entrenamiento : [[0.27428663]]\n",
      "PERDIDAAAA despues: 0.0006355287041515112\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "[[[0.26934445]\n",
      "  [0.26995495]\n",
      "  [0.2712194 ]\n",
      "  [0.27154228]\n",
      "  [0.27272019]\n",
      "  [0.27326965]\n",
      "  [0.27332285]\n",
      "  [0.27426848]]]\n",
      "ejemplar: [0.26934445 0.26995495 0.2712194  0.27154228 0.27272019 0.27326965\n",
      " 0.27332285 0.27426848]\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.2748439]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[0.26934445 0.26995495 0.2712194  0.27154228 0.27272019 0.27326965\n",
      "  0.27332285 0.27426848]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.036663093145762e-06\n",
      "Predicción post entrenamiento : [[0.27484423]]\n",
      "PERDIDAAAA despues: 1.0359956377214985e-06\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "[[[0.26995495]\n",
      "  [0.2712194 ]\n",
      "  [0.27154228]\n",
      "  [0.27272019]\n",
      "  [0.27326965]\n",
      "  [0.27332285]\n",
      "  [0.27426848]\n",
      "  [0.2748439 ]]]\n",
      "ejemplar: [0.26995495 0.2712194  0.27154228 0.27272019 0.27326965 0.27332285\n",
      " 0.27426848 0.2748439 ]\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.2753443]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[0.26995495 0.2712194  0.27154228 0.27272019 0.27326965 0.27332285\n",
      "  0.27426848 0.2748439 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.1550197238393594e-07\n",
      "Predicción post entrenamiento : [[0.27528796]]\n",
      "PERDIDAAAA despues: 3.46024222608321e-07\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "[[[0.2712194 ]\n",
      "  [0.27154228]\n",
      "  [0.27272019]\n",
      "  [0.27326965]\n",
      "  [0.27332285]\n",
      "  [0.27426848]\n",
      "  [0.2748439 ]\n",
      "  [0.27534431]]]\n",
      "ejemplar: [0.2712194  0.27154228 0.27272019 0.27326965 0.27332285 0.27426848\n",
      " 0.2748439  0.27534431]\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.27580926]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[0.2712194  0.27154228 0.27272019 0.27326965 0.27332285 0.27426848\n",
      "  0.2748439  0.27534431]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.1199080773849346e-07\n",
      "Predicción post entrenamiento : [[0.275779]]\n",
      "PERDIDAAAA despues: 9.265991707252397e-08\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "[[[0.27154228]\n",
      "  [0.27272019]\n",
      "  [0.27326965]\n",
      "  [0.27332285]\n",
      "  [0.27426848]\n",
      "  [0.2748439 ]\n",
      "  [0.27534431]\n",
      "  [0.27580926]]]\n",
      "ejemplar: [0.27154228 0.27272019 0.27326965 0.27332285 0.27426848 0.2748439\n",
      " 0.27534431 0.27580926]\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.27617428]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[0.27154228 0.27272019 0.27326965 0.27332285 0.27426848 0.2748439\n",
      "  0.27534431 0.27580926]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0034315793309360743\n",
      "Predicción post entrenamiento : [[0.27720842]]\n",
      "PERDIDAAAA despues: 0.003311489475890994\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "[[[0.27272019]\n",
      "  [0.27326965]\n",
      "  [0.27332285]\n",
      "  [0.27426848]\n",
      "  [0.2748439 ]\n",
      "  [0.27534431]\n",
      "  [0.27580926]\n",
      "  [0.27617428]]]\n",
      "ejemplar: [0.27272019 0.27326965 0.27332285 0.27426848 0.2748439  0.27534431\n",
      " 0.27580926 0.27617428]\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.27766192]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[0.27272019 0.27326965 0.27332285 0.27426848 0.2748439  0.27534431\n",
      "  0.27580926 0.27617428]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006086209788918495\n",
      "Predicción post entrenamiento : [[0.27862808]]\n",
      "PERDIDAAAA despues: 0.005936394911259413\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "[[[0.27326965]\n",
      "  [0.27332285]\n",
      "  [0.27426848]\n",
      "  [0.2748439 ]\n",
      "  [0.27534431]\n",
      "  [0.27580926]\n",
      "  [0.27617428]\n",
      "  [0.27766192]]]\n",
      "ejemplar: [0.27326965 0.27332285 0.27426848 0.2748439  0.27534431 0.27580926\n",
      " 0.27617428 0.27766192]\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.27895933]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[0.27326965 0.27332285 0.27426848 0.2748439  0.27534431 0.27580926\n",
      "  0.27617428 0.27766192]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003332968335598707\n",
      "Predicción post entrenamiento : [[0.279887]]\n",
      "PERDIDAAAA despues: 0.0032267181668430567\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "[[[0.27332285]\n",
      "  [0.27426848]\n",
      "  [0.2748439 ]\n",
      "  [0.27534431]\n",
      "  [0.27580926]\n",
      "  [0.27617428]\n",
      "  [0.27766192]\n",
      "  [0.27895933]]]\n",
      "ejemplar: [0.27332285 0.27426848 0.2748439  0.27534431 0.27580926 0.27617428\n",
      " 0.27766192 0.27895933]\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.28022256]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[0.27332285 0.27426848 0.2748439  0.27534431 0.27580926 0.27617428\n",
      "  0.27766192 0.27895933]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0028482582420110703\n",
      "Predicción post entrenamiento : [[0.2812328]]\n",
      "PERDIDAAAA despues: 0.002741447649896145\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "[[[0.27426848]\n",
      "  [0.2748439 ]\n",
      "  [0.27534431]\n",
      "  [0.27580926]\n",
      "  [0.27617428]\n",
      "  [0.27766192]\n",
      "  [0.27895933]\n",
      "  [0.28022256]]]\n",
      "ejemplar: [0.27426848 0.2748439  0.27534431 0.27580926 0.27617428 0.27766192\n",
      " 0.27895933 0.28022256]\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.28169638]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[0.27426848 0.2748439  0.27534431 0.27580926 0.27617428 0.27766192\n",
      "  0.27895933 0.28022256]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010616875253617764\n",
      "Predicción post entrenamiento : [[0.2829736]]\n",
      "PERDIDAAAA despues: 0.01035530399531126\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "[[[0.2748439 ]\n",
      "  [0.27534431]\n",
      "  [0.27580926]\n",
      "  [0.27617428]\n",
      "  [0.27766192]\n",
      "  [0.27895933]\n",
      "  [0.28022256]\n",
      "  [0.28169638]]]\n",
      "ejemplar: [0.2748439  0.27534431 0.27580926 0.27617428 0.27766192 0.27895933\n",
      " 0.28022256 0.28169638]\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.2834016]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[0.2748439  0.27534431 0.27580926 0.27617428 0.27766192 0.27895933\n",
      "  0.28022256 0.28169638]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08276833593845367\n",
      "Predicción post entrenamiento : [[0.28720698]]\n",
      "PERDIDAAAA despues: 0.08059325069189072\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "[[[0.27534431]\n",
      "  [0.27580926]\n",
      "  [0.27617428]\n",
      "  [0.27766192]\n",
      "  [0.27895933]\n",
      "  [0.28022256]\n",
      "  [0.28169638]\n",
      "  [0.28340161]]]\n",
      "ejemplar: [0.27534431 0.27580926 0.27617428 0.27766192 0.27895933 0.28022256\n",
      " 0.28169638 0.28340161]\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.2876943]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[0.27534431 0.27580926 0.27617428 0.27766192 0.27895933 0.28022256\n",
      "  0.28169638 0.28340161]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09522544592618942\n",
      "Predicción post entrenamiento : [[0.29177392]]\n",
      "PERDIDAAAA despues: 0.0927242711186409\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "[[[0.27580926]\n",
      "  [0.27617428]\n",
      "  [0.27766192]\n",
      "  [0.27895933]\n",
      "  [0.28022256]\n",
      "  [0.28169638]\n",
      "  [0.28340161]\n",
      "  [0.28769431]]]\n",
      "ejemplar: [0.27580926 0.27617428 0.27766192 0.27895933 0.28022256 0.28169638\n",
      " 0.28340161 0.28769431]\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.2923791]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[0.27580926 0.27617428 0.27766192 0.27895933 0.28022256 0.28169638\n",
      "  0.28340161 0.28769431]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07963930070400238\n",
      "Predicción post entrenamiento : [[0.29600587]]\n",
      "PERDIDAAAA despues: 0.0776054784655571\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "[[[0.27617428]\n",
      "  [0.27766192]\n",
      "  [0.27895933]\n",
      "  [0.28022256]\n",
      "  [0.28169638]\n",
      "  [0.28340161]\n",
      "  [0.28769431]\n",
      "  [0.29237911]]]\n",
      "ejemplar: [0.27617428 0.27766192 0.27895933 0.28022256 0.28169638 0.28340161\n",
      " 0.28769431 0.29237911]\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.29680392]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[0.27617428 0.27766192 0.27895933 0.28022256 0.28169638 0.28340161\n",
      "  0.28769431 0.29237911]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0958213210105896\n",
      "Predicción post entrenamiento : [[0.3005404]]\n",
      "PERDIDAAAA despues: 0.09352203458547592\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "[[[0.27766192]\n",
      "  [0.27895933]\n",
      "  [0.28022256]\n",
      "  [0.28169638]\n",
      "  [0.28340161]\n",
      "  [0.28769431]\n",
      "  [0.29237911]\n",
      "  [0.29680392]]]\n",
      "ejemplar: [0.27766192 0.27895933 0.28022256 0.28169638 0.28340161 0.28769431\n",
      " 0.29237911 0.29680392]\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.30164477]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[0.27766192 0.27895933 0.28022256 0.28169638 0.28340161 0.28769431\n",
      "  0.29237911 0.29680392]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08009599894285202\n",
      "Predicción post entrenamiento : [[0.305025]]\n",
      "PERDIDAAAA despues: 0.07819412648677826\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "[[[0.27895933]\n",
      "  [0.28022256]\n",
      "  [0.28169638]\n",
      "  [0.28340161]\n",
      "  [0.28769431]\n",
      "  [0.29237911]\n",
      "  [0.29680392]\n",
      "  [0.30164477]]]\n",
      "ejemplar: [0.27895933 0.28022256 0.28169638 0.28340161 0.28769431 0.29237911\n",
      " 0.29680392 0.30164477]\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.3062985]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[0.27895933 0.28022256 0.28169638 0.28340161 0.28769431 0.29237911\n",
      "  0.29680392 0.30164477]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0688922256231308\n",
      "Predicción post entrenamiento : [[0.30939528]]\n",
      "PERDIDAAAA despues: 0.06727616488933563\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "[[[0.28022256]\n",
      "  [0.28169638]\n",
      "  [0.28340161]\n",
      "  [0.28769431]\n",
      "  [0.29237911]\n",
      "  [0.29680392]\n",
      "  [0.30164477]\n",
      "  [0.30629849]]]\n",
      "ejemplar: [0.28022256 0.28169638 0.28340161 0.28769431 0.29237911 0.29680392\n",
      " 0.30164477 0.30629849]\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.3109759]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[0.28022256 0.28169638 0.28340161 0.28769431 0.29237911 0.29680392\n",
      "  0.30164477 0.30629849]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11009003967046738\n",
      "Predicción post entrenamiento : [[0.31493437]]\n",
      "PERDIDAAAA despues: 0.10747888684272766\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "[[[0.28169638]\n",
      "  [0.28340161]\n",
      "  [0.28769431]\n",
      "  [0.29237911]\n",
      "  [0.29680392]\n",
      "  [0.30164477]\n",
      "  [0.30629849]\n",
      "  [0.31097591]]]\n",
      "ejemplar: [0.28169638 0.28340161 0.28769431 0.29237911 0.29680392 0.30164477\n",
      " 0.30629849 0.31097591]\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.31694564]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[0.28169638 0.28340161 0.28769431 0.29237911 0.29680392 0.30164477\n",
      "  0.30629849 0.31097591]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11889626830816269\n",
      "Predicción post entrenamiento : [[0.32101172]]\n",
      "PERDIDAAAA despues: 0.1161087229847908\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "[[[0.28340161]\n",
      "  [0.28769431]\n",
      "  [0.29237911]\n",
      "  [0.29680392]\n",
      "  [0.30164477]\n",
      "  [0.30629849]\n",
      "  [0.31097591]\n",
      "  [0.31694564]]]\n",
      "ejemplar: [0.28340161 0.28769431 0.29237911 0.29680392 0.30164477 0.30629849\n",
      " 0.31097591 0.31694564]\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.32353556]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[0.28340161 0.28769431 0.29237911 0.29680392 0.30164477 0.30629849\n",
      "  0.31097591 0.31694564]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12212187796831131\n",
      "Predicción post entrenamiento : [[0.32749027]]\n",
      "PERDIDAAAA despues: 0.11937350034713745\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "[[[0.28769431]\n",
      "  [0.29237911]\n",
      "  [0.29680392]\n",
      "  [0.30164477]\n",
      "  [0.30629849]\n",
      "  [0.31097591]\n",
      "  [0.31694564]\n",
      "  [0.32353556]]]\n",
      "ejemplar: [0.28769431 0.29237911 0.29680392 0.30164477 0.30629849 0.31097591\n",
      " 0.31694564 0.32353556]\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.3306091]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[0.28769431 0.29237911 0.29680392 0.30164477 0.30629849 0.31097591\n",
      "  0.31694564 0.32353556]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14437583088874817\n",
      "Predicción post entrenamiento : [[0.3347668]]\n",
      "PERDIDAAAA despues: 0.14123353362083435\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "[[[0.29237911]\n",
      "  [0.29680392]\n",
      "  [0.30164477]\n",
      "  [0.30629849]\n",
      "  [0.31097591]\n",
      "  [0.31694564]\n",
      "  [0.32353556]\n",
      "  [0.33060911]]]\n",
      "ejemplar: [0.29237911 0.29680392 0.30164477 0.30629849 0.31097591 0.31694564\n",
      " 0.32353556 0.33060911]\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.3380283]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[0.29237911 0.29680392 0.30164477 0.30629849 0.31097591 0.31694564\n",
      "  0.32353556 0.33060911]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13392846286296844\n",
      "Predicción post entrenamiento : [[0.34205174]]\n",
      "PERDIDAAAA despues: 0.13099980354309082\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "[[[0.29680392]\n",
      "  [0.30164477]\n",
      "  [0.30629849]\n",
      "  [0.31097591]\n",
      "  [0.31694564]\n",
      "  [0.32353556]\n",
      "  [0.33060911]\n",
      "  [0.33802831]]]\n",
      "ejemplar: [0.29680392 0.30164477 0.30629849 0.31097591 0.31694564 0.32353556\n",
      " 0.33060911 0.33802831]\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.3454318]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[0.29680392 0.30164477 0.30629849 0.31097591 0.31694564 0.32353556\n",
      "  0.33060911 0.33802831]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14577560126781464\n",
      "Predicción post entrenamiento : [[0.34926012]]\n",
      "PERDIDAAAA despues: 0.14286690950393677\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "[[[0.30164477]\n",
      "  [0.30629849]\n",
      "  [0.31097591]\n",
      "  [0.31694564]\n",
      "  [0.32353556]\n",
      "  [0.33060911]\n",
      "  [0.33802831]\n",
      "  [0.3454318 ]]]\n",
      "ejemplar: [0.30164477 0.30629849 0.31097591 0.31694564 0.32353556 0.33060911\n",
      " 0.33802831 0.3454318 ]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.35288906]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[0.30164477 0.30629849 0.31097591 0.31694564 0.32353556 0.33060911\n",
      "  0.33802831 0.3454318 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13667739927768707\n",
      "Predicción post entrenamiento : [[0.35672346]]\n",
      "PERDIDAAAA despues: 0.13385695219039917\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "[[[0.30629849]\n",
      "  [0.31097591]\n",
      "  [0.31694564]\n",
      "  [0.32353556]\n",
      "  [0.33060911]\n",
      "  [0.33802831]\n",
      "  [0.3454318 ]\n",
      "  [0.35288906]]]\n",
      "ejemplar: [0.30629849 0.31097591 0.31694564 0.32353556 0.33060911 0.33802831\n",
      " 0.3454318  0.35288906]\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.36059868]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[0.30629849 0.31097591 0.31694564 0.32353556 0.33060911 0.33802831\n",
      "  0.3454318  0.35288906]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.16908150911331177\n",
      "Predicción post entrenamiento : [[0.36503005]]\n",
      "PERDIDAAAA despues: 0.1654568314552307\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "[[[0.31097591]\n",
      "  [0.31694564]\n",
      "  [0.32353556]\n",
      "  [0.33060911]\n",
      "  [0.33802831]\n",
      "  [0.3454318 ]\n",
      "  [0.35288906]\n",
      "  [0.36059868]]]\n",
      "ejemplar: [0.31097591 0.31694564 0.32353556 0.33060911 0.33802831 0.3454318\n",
      " 0.35288906 0.36059868]\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.36928836]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[0.31097591 0.31694564 0.32353556 0.33060911 0.33802831 0.3454318\n",
      "  0.35288906 0.36059868]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1261933594942093\n",
      "Predicción post entrenamiento : [[0.37270835]]\n",
      "PERDIDAAAA despues: 0.12377522885799408\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "[[[0.31694564]\n",
      "  [0.32353556]\n",
      "  [0.33060911]\n",
      "  [0.33802831]\n",
      "  [0.3454318 ]\n",
      "  [0.35288906]\n",
      "  [0.36059868]\n",
      "  [0.36928836]]]\n",
      "ejemplar: [0.31694564 0.32353556 0.33060911 0.33802831 0.3454318  0.35288906\n",
      " 0.36059868 0.36928836]\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.37745357]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[0.31694564 0.32353556 0.33060911 0.33802831 0.3454318  0.35288906\n",
      "  0.36059868 0.36928836]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08620338886976242\n",
      "Predicción post entrenamiento : [[0.38025072]]\n",
      "PERDIDAAAA despues: 0.08456870168447495\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "[[[0.32353556]\n",
      "  [0.33060911]\n",
      "  [0.33802831]\n",
      "  [0.3454318 ]\n",
      "  [0.35288906]\n",
      "  [0.36059868]\n",
      "  [0.36928836]\n",
      "  [0.37745357]]]\n",
      "ejemplar: [0.32353556 0.33060911 0.33802831 0.3454318  0.35288906 0.36059868\n",
      " 0.36928836 0.37745357]\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.3852949]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[0.32353556 0.33060911 0.33802831 0.3454318  0.35288906 0.36059868\n",
      "  0.36928836 0.37745357]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08321777731180191\n",
      "Predicción post entrenamiento : [[0.38823023]]\n",
      "PERDIDAAAA despues: 0.08153285831212997\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "[[[0.33060911]\n",
      "  [0.33802831]\n",
      "  [0.3454318 ]\n",
      "  [0.35288906]\n",
      "  [0.36059868]\n",
      "  [0.36928836]\n",
      "  [0.37745357]\n",
      "  [0.38529491]]]\n",
      "ejemplar: [0.33060911 0.33802831 0.3454318  0.35288906 0.36059868 0.36928836\n",
      " 0.37745357 0.38529491]\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.3935008]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[0.33060911 0.33802831 0.3454318  0.35288906 0.36059868 0.36928836\n",
      "  0.37745357 0.38529491]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10300953686237335\n",
      "Predicción post entrenamiento : [[0.39665985]]\n",
      "PERDIDAAAA despues: 0.10099171847105026\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "[[[0.33802831]\n",
      "  [0.3454318 ]\n",
      "  [0.35288906]\n",
      "  [0.36059868]\n",
      "  [0.36928836]\n",
      "  [0.37745357]\n",
      "  [0.38529491]\n",
      "  [0.3935008 ]]]\n",
      "ejemplar: [0.33802831 0.3454318  0.35288906 0.36059868 0.36928836 0.37745357\n",
      " 0.38529491 0.3935008 ]\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.40209773]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[0.33802831 0.3454318  0.35288906 0.36059868 0.36928836 0.37745357\n",
      "  0.38529491 0.3935008 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11682724207639694\n",
      "Predicción post entrenamiento : [[0.40544567]]\n",
      "PERDIDAAAA despues: 0.11454980075359344\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "[[[0.3454318 ]\n",
      "  [0.35288906]\n",
      "  [0.36059868]\n",
      "  [0.36928836]\n",
      "  [0.37745357]\n",
      "  [0.38529491]\n",
      "  [0.3935008 ]\n",
      "  [0.40209773]]]\n",
      "ejemplar: [0.3454318  0.35288906 0.36059868 0.36928836 0.37745357 0.38529491\n",
      " 0.3935008  0.40209773]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.4110105]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[0.3454318  0.35288906 0.36059868 0.36928836 0.37745357 0.38529491\n",
      "  0.3935008  0.40209773]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09708061069250107\n",
      "Predicción post entrenamiento : [[0.41419974]]\n",
      "PERDIDAAAA despues: 0.09510339796543121\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "[[[0.35288906]\n",
      "  [0.36059868]\n",
      "  [0.36928836]\n",
      "  [0.37745357]\n",
      "  [0.38529491]\n",
      "  [0.3935008 ]\n",
      "  [0.40209773]\n",
      "  [0.4110105 ]]]\n",
      "ejemplar: [0.35288906 0.36059868 0.36928836 0.37745357 0.38529491 0.3935008\n",
      " 0.40209773 0.4110105 ]\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.41992995]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[0.35288906 0.36059868 0.36928836 0.37745357 0.38529491 0.3935008\n",
      "  0.40209773 0.4110105 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.078070729970932\n",
      "Predicción post entrenamiento : [[0.42234522]]\n",
      "PERDIDAAAA despues: 0.07672686129808426\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "[[[0.36059868]\n",
      "  [0.36928836]\n",
      "  [0.37745357]\n",
      "  [0.38529491]\n",
      "  [0.3935008 ]\n",
      "  [0.40209773]\n",
      "  [0.4110105 ]\n",
      "  [0.41992995]]]\n",
      "ejemplar: [0.36059868 0.36928836 0.37745357 0.38529491 0.3935008  0.40209773\n",
      " 0.4110105  0.41992995]\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.42826825]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[0.36059868 0.36928836 0.37745357 0.38529491 0.3935008  0.40209773\n",
      "  0.4110105  0.41992995]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09550749510526657\n",
      "Predicción post entrenamiento : [[0.4309442]]\n",
      "PERDIDAAAA despues: 0.0938606932759285\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "[[[0.36928836]\n",
      "  [0.37745357]\n",
      "  [0.38529491]\n",
      "  [0.3935008 ]\n",
      "  [0.40209773]\n",
      "  [0.4110105 ]\n",
      "  [0.41992995]\n",
      "  [0.42826825]]]\n",
      "ejemplar: [0.36928836 0.37745357 0.38529491 0.3935008  0.40209773 0.4110105\n",
      " 0.41992995 0.42826825]\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.43704134]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[0.36928836 0.37745357 0.38529491 0.3935008  0.40209773 0.4110105\n",
      "  0.41992995 0.42826825]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08087453991174698\n",
      "Predicción post entrenamiento : [[0.4394034]]\n",
      "PERDIDAAAA despues: 0.07953664660453796\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "[[[0.37745357]\n",
      "  [0.38529491]\n",
      "  [0.3935008 ]\n",
      "  [0.40209773]\n",
      "  [0.4110105 ]\n",
      "  [0.41992995]\n",
      "  [0.42826825]\n",
      "  [0.43704134]]]\n",
      "ejemplar: [0.37745357 0.38529491 0.3935008  0.40209773 0.4110105  0.41992995\n",
      " 0.42826825 0.43704134]\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.44546887]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[0.37745357 0.38529491 0.3935008  0.40209773 0.4110105  0.41992995\n",
      "  0.42826825 0.43704134]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07466273754835129\n",
      "Predicción post entrenamiento : [[0.44821975]]\n",
      "PERDIDAAAA despues: 0.07316698133945465\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "[[[0.38529491]\n",
      "  [0.3935008 ]\n",
      "  [0.40209773]\n",
      "  [0.4110105 ]\n",
      "  [0.41992995]\n",
      "  [0.42826825]\n",
      "  [0.43704134]\n",
      "  [0.44546887]]]\n",
      "ejemplar: [0.38529491 0.3935008  0.40209773 0.4110105  0.41992995 0.42826825\n",
      " 0.43704134 0.44546887]\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.454382]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[0.38529491 0.3935008  0.40209773 0.4110105  0.41992995 0.42826825\n",
      "  0.43704134 0.44546887]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04830119013786316\n",
      "Predicción post entrenamiento : [[0.45676506]]\n",
      "PERDIDAAAA despues: 0.04725939780473709\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "[[[0.3935008 ]\n",
      "  [0.40209773]\n",
      "  [0.4110105 ]\n",
      "  [0.41992995]\n",
      "  [0.42826825]\n",
      "  [0.43704134]\n",
      "  [0.44546887]\n",
      "  [0.454382  ]]]\n",
      "ejemplar: [0.3935008  0.40209773 0.4110105  0.41992995 0.42826825 0.43704134\n",
      " 0.44546887 0.454382  ]\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.46312413]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[0.3935008  0.40209773 0.4110105  0.41992995 0.42826825 0.43704134\n",
      "  0.44546887 0.454382  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.055433083325624466\n",
      "Predicción post entrenamiento : [[0.46535796]]\n",
      "PERDIDAAAA despues: 0.0543861947953701\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "[[[0.40209773]\n",
      "  [0.4110105 ]\n",
      "  [0.41992995]\n",
      "  [0.42826825]\n",
      "  [0.43704134]\n",
      "  [0.44546887]\n",
      "  [0.454382  ]\n",
      "  [0.46312413]]]\n",
      "ejemplar: [0.40209773 0.4110105  0.41992995 0.42826825 0.43704134 0.44546887\n",
      " 0.454382   0.46312413]\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.47185645]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[0.40209773 0.4110105  0.41992995 0.42826825 0.43704134 0.44546887\n",
      "  0.454382   0.46312413]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06209161877632141\n",
      "Predicción post entrenamiento : [[0.47431865]]\n",
      "PERDIDAAAA despues: 0.06087060272693634\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "[[[0.4110105 ]\n",
      "  [0.41992995]\n",
      "  [0.42826825]\n",
      "  [0.43704134]\n",
      "  [0.44546887]\n",
      "  [0.454382  ]\n",
      "  [0.46312413]\n",
      "  [0.47185645]]]\n",
      "ejemplar: [0.4110105  0.41992995 0.42826825 0.43704134 0.44546887 0.454382\n",
      " 0.46312413 0.47185645]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.4808783]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[0.4110105  0.41992995 0.42826825 0.43704134 0.44546887 0.454382\n",
      "  0.46312413 0.47185645]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.058423642069101334\n",
      "Predicción post entrenamiento : [[0.4831069]]\n",
      "PERDIDAAAA despues: 0.0573512502014637\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "[[[0.41992995]\n",
      "  [0.42826825]\n",
      "  [0.43704134]\n",
      "  [0.44546887]\n",
      "  [0.454382  ]\n",
      "  [0.46312413]\n",
      "  [0.47185645]\n",
      "  [0.48087829]]]\n",
      "ejemplar: [0.41992995 0.42826825 0.43704134 0.44546887 0.454382   0.46312413\n",
      " 0.47185645 0.48087829]\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.4896532]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[0.41992995 0.42826825 0.43704134 0.44546887 0.454382   0.46312413\n",
      "  0.47185645 0.48087829]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07109840214252472\n",
      "Predicción post entrenamiento : [[0.491914]]\n",
      "PERDIDAAAA despues: 0.06989786028862\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "[[[0.42826825]\n",
      "  [0.43704134]\n",
      "  [0.44546887]\n",
      "  [0.454382  ]\n",
      "  [0.46312413]\n",
      "  [0.47185645]\n",
      "  [0.48087829]\n",
      "  [0.4896532 ]]]\n",
      "ejemplar: [0.42826825 0.43704134 0.44546887 0.454382   0.46312413 0.47185645\n",
      " 0.48087829 0.4896532 ]\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.49844047]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[0.42826825 0.43704134 0.44546887 0.454382   0.46312413 0.47185645\n",
      "  0.48087829 0.4896532 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1083369329571724\n",
      "Predicción post entrenamiento : [[0.50106966]]\n",
      "PERDIDAAAA despues: 0.10661306977272034\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "[[[0.43704134]\n",
      "  [0.44546887]\n",
      "  [0.454382  ]\n",
      "  [0.46312413]\n",
      "  [0.47185645]\n",
      "  [0.48087829]\n",
      "  [0.4896532 ]\n",
      "  [0.49844047]]]\n",
      "ejemplar: [0.43704134 0.44546887 0.454382   0.46312413 0.47185645 0.48087829\n",
      " 0.4896532  0.49844047]\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.50772095]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[0.43704134 0.44546887 0.454382   0.46312413 0.47185645 0.48087829\n",
      "  0.4896532  0.49844047]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10962802916765213\n",
      "Predicción post entrenamiento : [[0.51078254]]\n",
      "PERDIDAAAA despues: 0.10761000961065292\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "[[[0.44546887]\n",
      "  [0.454382  ]\n",
      "  [0.46312413]\n",
      "  [0.47185645]\n",
      "  [0.48087829]\n",
      "  [0.4896532 ]\n",
      "  [0.49844047]\n",
      "  [0.50772095]]]\n",
      "ejemplar: [0.44546887 0.454382   0.46312413 0.47185645 0.48087829 0.4896532\n",
      " 0.49844047 0.50772095]\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.5174709]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[0.44546887 0.454382   0.46312413 0.47185645 0.48087829 0.4896532\n",
      "  0.49844047 0.50772095]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07661542296409607\n",
      "Predicción post entrenamiento : [[0.52016586]]\n",
      "PERDIDAAAA despues: 0.07513078302145004\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "[[[0.454382  ]\n",
      "  [0.46312413]\n",
      "  [0.47185645]\n",
      "  [0.48087829]\n",
      "  [0.4896532 ]\n",
      "  [0.49844047]\n",
      "  [0.50772095]\n",
      "  [0.5174709 ]]]\n",
      "ejemplar: [0.454382   0.46312413 0.47185645 0.48087829 0.4896532  0.49844047\n",
      " 0.50772095 0.5174709 ]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.52698904]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[0.454382   0.46312413 0.47185645 0.48087829 0.4896532  0.49844047\n",
      "  0.50772095 0.5174709 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06595429033041\n",
      "Predicción post entrenamiento : [[0.52915806]]\n",
      "PERDIDAAAA despues: 0.06484492123126984\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "[[[0.46312413]\n",
      "  [0.47185645]\n",
      "  [0.48087829]\n",
      "  [0.4896532 ]\n",
      "  [0.49844047]\n",
      "  [0.50772095]\n",
      "  [0.5174709 ]\n",
      "  [0.52698904]]]\n",
      "ejemplar: [0.46312413 0.47185645 0.48087829 0.4896532  0.49844047 0.50772095\n",
      " 0.5174709  0.52698904]\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.5360203]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[0.46312413 0.47185645 0.48087829 0.4896532  0.49844047 0.50772095\n",
      "  0.5174709  0.52698904]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05377721041440964\n",
      "Predicción post entrenamiento : [[0.5385109]]\n",
      "PERDIDAAAA despues: 0.05262826010584831\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "[[[0.47185645]\n",
      "  [0.48087829]\n",
      "  [0.4896532 ]\n",
      "  [0.49844047]\n",
      "  [0.50772095]\n",
      "  [0.5174709 ]\n",
      "  [0.52698904]\n",
      "  [0.53602028]]]\n",
      "ejemplar: [0.47185645 0.48087829 0.4896532  0.49844047 0.50772095 0.5174709\n",
      " 0.52698904 0.53602028]\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.5454708]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[0.47185645 0.48087829 0.4896532  0.49844047 0.50772095 0.5174709\n",
      "  0.52698904 0.53602028]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.057173047214746475\n",
      "Predicción post entrenamiento : [[0.5479032]]\n",
      "PERDIDAAAA despues: 0.056015744805336\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "[[[0.48087829]\n",
      "  [0.4896532 ]\n",
      "  [0.49844047]\n",
      "  [0.50772095]\n",
      "  [0.5174709 ]\n",
      "  [0.52698904]\n",
      "  [0.53602028]\n",
      "  [0.54547077]]]\n",
      "ejemplar: [0.48087829 0.4896532  0.49844047 0.50772095 0.5174709  0.52698904\n",
      " 0.53602028 0.54547077]\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.55498767]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[0.48087829 0.4896532  0.49844047 0.50772095 0.5174709  0.52698904\n",
      "  0.53602028 0.54547077]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10480855405330658\n",
      "Predicción post entrenamiento : [[0.5572564]]\n",
      "PERDIDAAAA despues: 0.10334473848342896\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "[[[0.4896532 ]\n",
      "  [0.49844047]\n",
      "  [0.50772095]\n",
      "  [0.5174709 ]\n",
      "  [0.52698904]\n",
      "  [0.53602028]\n",
      "  [0.54547077]\n",
      "  [0.55498767]]]\n",
      "ejemplar: [0.4896532  0.49844047 0.50772095 0.5174709  0.52698904 0.53602028\n",
      " 0.54547077 0.55498767]\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.5644165]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[0.4896532  0.49844047 0.50772095 0.5174709  0.52698904 0.53602028\n",
      "  0.54547077 0.55498767]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0968535766005516\n",
      "Predicción post entrenamiento : [[0.56676984]]\n",
      "PERDIDAAAA despues: 0.09539435803890228\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "[[[0.49844047]\n",
      "  [0.50772095]\n",
      "  [0.5174709 ]\n",
      "  [0.52698904]\n",
      "  [0.53602028]\n",
      "  [0.54547077]\n",
      "  [0.55498767]\n",
      "  [0.56441653]]]\n",
      "ejemplar: [0.49844047 0.50772095 0.5174709  0.52698904 0.53602028 0.54547077\n",
      " 0.55498767 0.56441653]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.5740876]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[0.49844047 0.50772095 0.5174709  0.52698904 0.53602028 0.54547077\n",
      "  0.55498767 0.56441653]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07551953196525574\n",
      "Predicción post entrenamiento : [[0.57657474]]\n",
      "PERDIDAAAA despues: 0.07415875047445297\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "[[[0.50772095]\n",
      "  [0.5174709 ]\n",
      "  [0.52698904]\n",
      "  [0.53602028]\n",
      "  [0.54547077]\n",
      "  [0.55498767]\n",
      "  [0.56441653]\n",
      "  [0.57408762]]]\n",
      "ejemplar: [0.50772095 0.5174709  0.52698904 0.53602028 0.54547077 0.55498767\n",
      " 0.56441653 0.57408762]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.5840752]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[0.50772095 0.5174709  0.52698904 0.53602028 0.54547077 0.55498767\n",
      "  0.56441653 0.57408762]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05485539138317108\n",
      "Predicción post entrenamiento : [[0.5853668]]\n",
      "PERDIDAAAA despues: 0.054252054542303085\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "[[[0.5174709 ]\n",
      "  [0.52698904]\n",
      "  [0.53602028]\n",
      "  [0.54547077]\n",
      "  [0.55498767]\n",
      "  [0.56441653]\n",
      "  [0.57408762]\n",
      "  [0.58407521]]]\n",
      "ejemplar: [0.5174709  0.52698904 0.53602028 0.54547077 0.55498767 0.56441653\n",
      " 0.57408762 0.58407521]\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.59294575]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[0.5174709  0.52698904 0.53602028 0.54547077 0.55498767 0.56441653\n",
      "  0.57408762 0.58407521]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05469309911131859\n",
      "Predicción post entrenamiento : [[0.59480125]]\n",
      "PERDIDAAAA despues: 0.05382867157459259\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "[[[0.52698904]\n",
      "  [0.53602028]\n",
      "  [0.54547077]\n",
      "  [0.55498767]\n",
      "  [0.56441653]\n",
      "  [0.57408762]\n",
      "  [0.58407521]\n",
      "  [0.59294575]]]\n",
      "ejemplar: [0.52698904 0.53602028 0.54547077 0.55498767 0.56441653 0.57408762\n",
      " 0.58407521 0.59294575]\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.6023444]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[0.52698904 0.53602028 0.54547077 0.55498767 0.56441653 0.57408762\n",
      "  0.58407521 0.59294575]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03349269554018974\n",
      "Predicción post entrenamiento : [[0.6038621]]\n",
      "PERDIDAAAA despues: 0.03293948620557785\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "[[[0.53602028]\n",
      "  [0.54547077]\n",
      "  [0.55498767]\n",
      "  [0.56441653]\n",
      "  [0.57408762]\n",
      "  [0.58407521]\n",
      "  [0.59294575]\n",
      "  [0.60234439]]]\n",
      "ejemplar: [0.53602028 0.54547077 0.55498767 0.56441653 0.57408762 0.58407521\n",
      " 0.59294575 0.60234439]\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.6114193]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[0.53602028 0.54547077 0.55498767 0.56441653 0.57408762 0.58407521\n",
      "  0.59294575 0.60234439]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.031616274267435074\n",
      "Predicción post entrenamiento : [[0.61281824]]\n",
      "PERDIDAAAA despues: 0.031120747327804565\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "[[[0.54547077]\n",
      "  [0.55498767]\n",
      "  [0.56441653]\n",
      "  [0.57408762]\n",
      "  [0.58407521]\n",
      "  [0.59294575]\n",
      "  [0.60234439]\n",
      "  [0.61141932]]]\n",
      "ejemplar: [0.54547077 0.55498767 0.56441653 0.57408762 0.58407521 0.59294575\n",
      " 0.60234439 0.61141932]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.6205154]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[0.54547077 0.55498767 0.56441653 0.57408762 0.58407521 0.59294575\n",
      "  0.60234439 0.61141932]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04564947634935379\n",
      "Predicción post entrenamiento : [[0.6222678]]\n",
      "PERDIDAAAA despues: 0.04490372911095619\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "[[[0.55498767]\n",
      "  [0.56441653]\n",
      "  [0.57408762]\n",
      "  [0.58407521]\n",
      "  [0.59294575]\n",
      "  [0.60234439]\n",
      "  [0.61141932]\n",
      "  [0.62051541]]]\n",
      "ejemplar: [0.55498767 0.56441653 0.57408762 0.58407521 0.59294575 0.60234439\n",
      " 0.61141932 0.62051541]\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.63000464]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[0.55498767 0.56441653 0.57408762 0.58407521 0.59294575 0.60234439\n",
      "  0.61141932 0.62051541]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03329572454094887\n",
      "Predicción post entrenamiento : [[0.63189644]]\n",
      "PERDIDAAAA despues: 0.03260890766978264\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "[[[0.56441653]\n",
      "  [0.57408762]\n",
      "  [0.58407521]\n",
      "  [0.59294575]\n",
      "  [0.60234439]\n",
      "  [0.61141932]\n",
      "  [0.62051541]\n",
      "  [0.63000464]]]\n",
      "ejemplar: [0.56441653 0.57408762 0.58407521 0.59294575 0.60234439 0.61141932\n",
      " 0.62051541 0.63000464]\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.6396475]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[0.56441653 0.57408762 0.58407521 0.59294575 0.60234439 0.61141932\n",
      "  0.62051541 0.63000464]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.026112092658877373\n",
      "Predicción post entrenamiento : [[0.6413281]]\n",
      "PERDIDAAAA despues: 0.02557176910340786\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "[[[0.57408762]\n",
      "  [0.58407521]\n",
      "  [0.59294575]\n",
      "  [0.60234439]\n",
      "  [0.61141932]\n",
      "  [0.62051541]\n",
      "  [0.63000464]\n",
      "  [0.63964748]]]\n",
      "ejemplar: [0.57408762 0.58407521 0.59294575 0.60234439 0.61141932 0.62051541\n",
      " 0.63000464 0.63964748]\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.64910597]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[0.57408762 0.58407521 0.59294575 0.60234439 0.61141932 0.62051541\n",
      "  0.63000464 0.63964748]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02373790182173252\n",
      "Predicción post entrenamiento : [[0.6507602]]\n",
      "PERDIDAAAA despues: 0.023230906575918198\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "[[[0.58407521]\n",
      "  [0.59294575]\n",
      "  [0.60234439]\n",
      "  [0.61141932]\n",
      "  [0.62051541]\n",
      "  [0.63000464]\n",
      "  [0.63964748]\n",
      "  [0.64910597]]]\n",
      "ejemplar: [0.58407521 0.59294575 0.60234439 0.61141932 0.62051541 0.63000464\n",
      " 0.63964748 0.64910597]\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.65849423]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[0.58407521 0.59294575 0.60234439 0.61141932 0.62051541 0.63000464\n",
      "  0.63964748 0.64910597]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018224095925688744\n",
      "Predicción post entrenamiento : [[0.659099]]\n",
      "PERDIDAAAA despues: 0.018061183393001556\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "[[[0.59294575]\n",
      "  [0.60234439]\n",
      "  [0.61141932]\n",
      "  [0.62051541]\n",
      "  [0.63000464]\n",
      "  [0.63964748]\n",
      "  [0.64910597]\n",
      "  [0.65849423]]]\n",
      "ejemplar: [0.59294575 0.60234439 0.61141932 0.62051541 0.63000464 0.63964748\n",
      " 0.64910597 0.65849423]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.66668624]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[0.59294575 0.60234439 0.61141932 0.62051541 0.63000464 0.63964748\n",
      "  0.64910597 0.65849423]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008739300072193146\n",
      "Predicción post entrenamiento : [[0.66808033]]\n",
      "PERDIDAAAA despues: 0.00848059169948101\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "[[[0.60234439]\n",
      "  [0.61141932]\n",
      "  [0.62051541]\n",
      "  [0.63000464]\n",
      "  [0.63964748]\n",
      "  [0.64910597]\n",
      "  [0.65849423]\n",
      "  [0.66668624]]]\n",
      "ejemplar: [0.60234439 0.61141932 0.62051541 0.63000464 0.63964748 0.64910597\n",
      " 0.65849423 0.66668624]\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.6758005]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[0.60234439 0.61141932 0.62051541 0.63000464 0.63964748 0.64910597\n",
      "  0.65849423 0.66668624]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0035489914007484913\n",
      "Predicción post entrenamiento : [[0.6745077]]\n",
      "PERDIDAAAA despues: 0.003704698756337166\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "[[[0.61141932]\n",
      "  [0.62051541]\n",
      "  [0.63000464]\n",
      "  [0.63964748]\n",
      "  [0.64910597]\n",
      "  [0.65849423]\n",
      "  [0.66668624]\n",
      "  [0.6758005 ]]]\n",
      "ejemplar: [0.61141932 0.62051541 0.63000464 0.63964748 0.64910597 0.65849423\n",
      " 0.66668624 0.6758005 ]\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.68221796]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[0.61141932 0.62051541 0.63000464 0.63964748 0.64910597 0.65849423\n",
      "  0.66668624 0.6758005 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007824251661077142\n",
      "Predicción post entrenamiento : [[0.68186903]]\n",
      "PERDIDAAAA despues: 0.0008020671084523201\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "[[[0.62051541]\n",
      "  [0.63000464]\n",
      "  [0.63964748]\n",
      "  [0.64910597]\n",
      "  [0.65849423]\n",
      "  [0.66668624]\n",
      "  [0.6758005 ]\n",
      "  [0.68221796]]]\n",
      "ejemplar: [0.62051541 0.63000464 0.63964748 0.64910597 0.65849423 0.66668624\n",
      " 0.6758005  0.68221796]\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.6896343]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[0.62051541 0.63000464 0.63964748 0.64910597 0.65849423 0.66668624\n",
      "  0.6758005  0.68221796]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005059245158918202\n",
      "Predicción post entrenamiento : [[0.6893136]]\n",
      "PERDIDAAAA despues: 0.0005204557091929018\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "[[[0.63000464]\n",
      "  [0.63964748]\n",
      "  [0.64910597]\n",
      "  [0.65849423]\n",
      "  [0.66668624]\n",
      "  [0.6758005 ]\n",
      "  [0.68221796]\n",
      "  [0.68963432]]]\n",
      "ejemplar: [0.63000464 0.63964748 0.64910597 0.65849423 0.66668624 0.6758005\n",
      " 0.68221796 0.68963432]\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.69709355]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[0.63000464 0.63964748 0.64910597 0.65849423 0.66668624 0.6758005\n",
      "  0.68221796 0.68963432]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001809845445677638\n",
      "Predicción post entrenamiento : [[0.6973913]]\n",
      "PERDIDAAAA despues: 0.001784602296538651\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "[[[0.63964748]\n",
      "  [0.64910597]\n",
      "  [0.65849423]\n",
      "  [0.66668624]\n",
      "  [0.6758005 ]\n",
      "  [0.68221796]\n",
      "  [0.68963432]\n",
      "  [0.69709355]]]\n",
      "ejemplar: [0.63964748 0.64910597 0.65849423 0.66668624 0.6758005  0.68221796\n",
      " 0.68963432 0.69709355]\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.7050254]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[0.63964748 0.64910597 0.65849423 0.66668624 0.6758005  0.68221796\n",
      "  0.68963432 0.69709355]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009686659905128181\n",
      "Predicción post entrenamiento : [[0.70553344]]\n",
      "PERDIDAAAA despues: 0.0009372984059154987\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "[[[0.64910597]\n",
      "  [0.65849423]\n",
      "  [0.66668624]\n",
      "  [0.6758005 ]\n",
      "  [0.68221796]\n",
      "  [0.68963432]\n",
      "  [0.69709355]\n",
      "  [0.70502537]]]\n",
      "ejemplar: [0.64910597 0.65849423 0.66668624 0.6758005  0.68221796 0.68963432\n",
      " 0.69709355 0.70502537]\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.71289986]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[0.64910597 0.65849423 0.66668624 0.6758005  0.68221796 0.68963432\n",
      "  0.69709355 0.70502537]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002054732060059905\n",
      "Predicción post entrenamiento : [[0.7123738]]\n",
      "PERDIDAAAA despues: 0.002007316332310438\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "[[[0.65849423]\n",
      "  [0.66668624]\n",
      "  [0.6758005 ]\n",
      "  [0.68221796]\n",
      "  [0.68963432]\n",
      "  [0.69709355]\n",
      "  [0.70502537]\n",
      "  [0.71289986]]]\n",
      "ejemplar: [0.65849423 0.66668624 0.6758005  0.68221796 0.68963432 0.69709355\n",
      " 0.70502537 0.71289986]\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.7194308]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[0.65849423 0.66668624 0.6758005  0.68221796 0.68963432 0.69709355\n",
      "  0.70502537 0.71289986]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002453755121678114\n",
      "Predicción post entrenamiento : [[0.7190029]]\n",
      "PERDIDAAAA despues: 0.0024115457199513912\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "[[[0.66668624]\n",
      "  [0.6758005 ]\n",
      "  [0.68221796]\n",
      "  [0.68963432]\n",
      "  [0.69709355]\n",
      "  [0.70502537]\n",
      "  [0.71289986]\n",
      "  [0.7194308 ]]]\n",
      "ejemplar: [0.66668624 0.6758005  0.68221796 0.68963432 0.69709355 0.70502537\n",
      " 0.71289986 0.7194308 ]\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.72568214]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[0.66668624 0.6758005  0.68221796 0.68963432 0.69709355 0.70502537\n",
      "  0.71289986 0.7194308 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008440717938356102\n",
      "Predicción post entrenamiento : [[0.7250765]]\n",
      "PERDIDAAAA despues: 0.000809247198048979\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "[[[0.6758005 ]\n",
      "  [0.68221796]\n",
      "  [0.68963432]\n",
      "  [0.69709355]\n",
      "  [0.70502537]\n",
      "  [0.71289986]\n",
      "  [0.7194308 ]\n",
      "  [0.72568214]]]\n",
      "ejemplar: [0.6758005  0.68221796 0.68963432 0.69709355 0.70502537 0.71289986\n",
      " 0.7194308  0.72568214]\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.7316204]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[0.6758005  0.68221796 0.68963432 0.69709355 0.70502537 0.71289986\n",
      "  0.7194308  0.72568214]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005726409610360861\n",
      "Predicción post entrenamiento : [[0.73194605]]\n",
      "PERDIDAAAA despues: 0.005775806028395891\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "[[[0.68221796]\n",
      "  [0.68963432]\n",
      "  [0.69709355]\n",
      "  [0.70502537]\n",
      "  [0.71289986]\n",
      "  [0.7194308 ]\n",
      "  [0.72568214]\n",
      "  [0.73162037]]]\n",
      "ejemplar: [0.68221796 0.68963432 0.69709355 0.70502537 0.71289986 0.7194308\n",
      " 0.72568214 0.73162037]\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.7380449]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[0.68221796 0.68963432 0.69709355 0.70502537 0.71289986 0.7194308\n",
      "  0.72568214 0.73162037]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0035091708414256573\n",
      "Predicción post entrenamiento : [[0.737088]]\n",
      "PERDIDAAAA despues: 0.003396717133000493\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "[[[0.68963432]\n",
      "  [0.69709355]\n",
      "  [0.70502537]\n",
      "  [0.71289986]\n",
      "  [0.7194308 ]\n",
      "  [0.72568214]\n",
      "  [0.73162037]\n",
      "  [0.73804492]]]\n",
      "ejemplar: [0.68963432 0.69709355 0.70502537 0.71289986 0.7194308  0.72568214\n",
      " 0.73162037 0.73804492]\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.7433984]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[0.68963432 0.69709355 0.70502537 0.71289986 0.7194308  0.72568214\n",
      "  0.73162037 0.73804492]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00452981423586607\n",
      "Predicción post entrenamiento : [[0.743476]]\n",
      "PERDIDAAAA despues: 0.004540258552879095\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "[[[0.69709355]\n",
      "  [0.70502537]\n",
      "  [0.71289986]\n",
      "  [0.7194308 ]\n",
      "  [0.72568214]\n",
      "  [0.73162037]\n",
      "  [0.73804492]\n",
      "  [0.74339843]]]\n",
      "ejemplar: [0.69709355 0.70502537 0.71289986 0.7194308  0.72568214 0.73162037\n",
      " 0.73804492 0.74339843]\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.74971247]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[0.69709355 0.70502537 0.71289986 0.7194308  0.72568214 0.73162037\n",
      "  0.73804492 0.74339843]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00040603475645184517\n",
      "Predicción post entrenamiento : [[0.75031483]]\n",
      "PERDIDAAAA despues: 0.00043067324440926313\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "[[[0.70502537]\n",
      "  [0.71289986]\n",
      "  [0.7194308 ]\n",
      "  [0.72568214]\n",
      "  [0.73162037]\n",
      "  [0.73804492]\n",
      "  [0.74339843]\n",
      "  [0.74971247]]]\n",
      "ejemplar: [0.70502537 0.71289986 0.7194308  0.72568214 0.73162037 0.73804492\n",
      " 0.74339843 0.74971247]\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.75640976]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[0.70502537 0.71289986 0.7194308  0.72568214 0.73162037 0.73804492\n",
      "  0.74339843 0.74971247]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0030394489876925945\n",
      "Predicción post entrenamiento : [[0.7558584]]\n",
      "PERDIDAAAA despues: 0.002978960517793894\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "[[[0.71289986]\n",
      "  [0.7194308 ]\n",
      "  [0.72568214]\n",
      "  [0.73162037]\n",
      "  [0.73804492]\n",
      "  [0.74339843]\n",
      "  [0.74971247]\n",
      "  [0.75640976]]]\n",
      "ejemplar: [0.71289986 0.7194308  0.72568214 0.73162037 0.73804492 0.74339843\n",
      " 0.74971247 0.75640976]\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.76161253]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[0.71289986 0.7194308  0.72568214 0.73162037 0.73804492 0.74339843\n",
      "  0.74971247 0.75640976]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.503996413201094e-05\n",
      "Predicción post entrenamiento : [[0.76263064]]\n",
      "PERDIDAAAA despues: 2.4023227524594404e-05\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "[[[0.7194308 ]\n",
      "  [0.72568214]\n",
      "  [0.73162037]\n",
      "  [0.73804492]\n",
      "  [0.74339843]\n",
      "  [0.74971247]\n",
      "  [0.75640976]\n",
      "  [0.76161253]]]\n",
      "ejemplar: [0.7194308  0.72568214 0.73162037 0.73804492 0.74339843 0.74971247\n",
      " 0.75640976 0.76161253]\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.7679806]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[0.7194308  0.72568214 0.73162037 0.73804492 0.74339843 0.74971247\n",
      "  0.75640976 0.76161253]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00016504251107107848\n",
      "Predicción post entrenamiento : [[0.76768893]]\n",
      "PERDIDAAAA despues: 0.00015763408737257123\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "[[[0.72568214]\n",
      "  [0.73162037]\n",
      "  [0.73804492]\n",
      "  [0.74339843]\n",
      "  [0.74971247]\n",
      "  [0.75640976]\n",
      "  [0.76161253]\n",
      "  [0.76798058]]]\n",
      "ejemplar: [0.72568214 0.73162037 0.73804492 0.74339843 0.74971247 0.75640976\n",
      " 0.76161253 0.76798058]\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.77293587]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[0.72568214 0.73162037 0.73804492 0.74339843 0.74971247 0.75640976\n",
      "  0.76161253 0.76798058]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007770624943077564\n",
      "Predicción post entrenamiento : [[0.77329576]]\n",
      "PERDIDAAAA despues: 0.0007972566527314484\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "[[[0.73162037]\n",
      "  [0.73804492]\n",
      "  [0.74339843]\n",
      "  [0.74971247]\n",
      "  [0.75640976]\n",
      "  [0.76161253]\n",
      "  [0.76798058]\n",
      "  [0.77293587]]]\n",
      "ejemplar: [0.73162037 0.73804492 0.74339843 0.74971247 0.75640976 0.76161253\n",
      " 0.76798058 0.77293587]\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.7784941]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[0.73162037 0.73804492 0.74339843 0.74971247 0.75640976 0.76161253\n",
      "  0.76798058 0.77293587]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007001343183219433\n",
      "Predicción post entrenamiento : [[0.77815247]]\n",
      "PERDIDAAAA despues: 0.0006821706774644554\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "[[[0.73804492]\n",
      "  [0.74339843]\n",
      "  [0.74971247]\n",
      "  [0.75640976]\n",
      "  [0.76161253]\n",
      "  [0.76798058]\n",
      "  [0.77293587]\n",
      "  [0.77849412]]]\n",
      "ejemplar: [0.73804492 0.74339843 0.74971247 0.75640976 0.76161253 0.76798058\n",
      " 0.77293587 0.77849412]\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.78336877]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[0.73804492 0.74339843 0.74971247 0.75640976 0.76161253 0.76798058\n",
      "  0.77293587 0.77849412]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005412011872977018\n",
      "Predicción post entrenamiento : [[0.78181696]]\n",
      "PERDIDAAAA despues: 0.005186098162084818\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "[[[0.74339843]\n",
      "  [0.74971247]\n",
      "  [0.75640976]\n",
      "  [0.76161253]\n",
      "  [0.76798058]\n",
      "  [0.77293587]\n",
      "  [0.77849412]\n",
      "  [0.78336877]]]\n",
      "ejemplar: [0.74339843 0.74971247 0.75640976 0.76161253 0.76798058 0.77293587\n",
      " 0.77849412 0.78336877]\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.7868935]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[0.74339843 0.74971247 0.75640976 0.76161253 0.76798058 0.77293587\n",
      "  0.77849412 0.78336877]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00930519588291645\n",
      "Predicción post entrenamiento : [[0.78600574]]\n",
      "PERDIDAAAA despues: 0.009134712629020214\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "[[[0.74971247]\n",
      "  [0.75640976]\n",
      "  [0.76161253]\n",
      "  [0.76798058]\n",
      "  [0.77293587]\n",
      "  [0.77849412]\n",
      "  [0.78336877]\n",
      "  [0.78689349]]]\n",
      "ejemplar: [0.74971247 0.75640976 0.76161253 0.76798058 0.77293587 0.77849412\n",
      " 0.78336877 0.78689349]\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.79119635]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[0.74971247 0.75640976 0.76161253 0.76798058 0.77293587 0.77849412\n",
      "  0.78336877 0.78689349]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013570071896538138\n",
      "Predicción post entrenamiento : [[0.7904344]]\n",
      "PERDIDAAAA despues: 0.0013014526339247823\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "[[[0.75640976]\n",
      "  [0.76161253]\n",
      "  [0.76798058]\n",
      "  [0.77293587]\n",
      "  [0.77849412]\n",
      "  [0.78336877]\n",
      "  [0.78689349]\n",
      "  [0.79119635]]]\n",
      "ejemplar: [0.75640976 0.76161253 0.76798058 0.77293587 0.77849412 0.78336877\n",
      " 0.78689349 0.79119635]\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.79543746]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[0.75640976 0.76161253 0.76798058 0.77293587 0.77849412 0.78336877\n",
      "  0.78689349 0.79119635]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005363623611629009\n",
      "Predicción post entrenamiento : [[0.79488504]]\n",
      "PERDIDAAAA despues: 0.005283014383167028\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "[[[0.76161253]\n",
      "  [0.76798058]\n",
      "  [0.77293587]\n",
      "  [0.77849412]\n",
      "  [0.78336877]\n",
      "  [0.78689349]\n",
      "  [0.79119635]\n",
      "  [0.79543746]]]\n",
      "ejemplar: [0.76161253 0.76798058 0.77293587 0.77849412 0.78336877 0.78689349\n",
      " 0.79119635 0.79543746]\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.79951304]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[0.76161253 0.76798058 0.77293587 0.77849412 0.78336877 0.78689349\n",
      "  0.79119635 0.79543746]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002400540979579091\n",
      "Predicción post entrenamiento : [[0.79963547]]\n",
      "PERDIDAAAA despues: 0.0023885592818260193\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "[[[0.76798058]\n",
      "  [0.77293587]\n",
      "  [0.77849412]\n",
      "  [0.78336877]\n",
      "  [0.78689349]\n",
      "  [0.79119635]\n",
      "  [0.79543746]\n",
      "  [0.79951304]]]\n",
      "ejemplar: [0.76798058 0.77293587 0.77849412 0.78336877 0.78689349 0.79119635\n",
      " 0.79543746 0.79951304]\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.8042164]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[0.76798058 0.77293587 0.77849412 0.78336877 0.78689349 0.79119635\n",
      "  0.79543746 0.79951304]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010250872932374477\n",
      "Predicción post entrenamiento : [[0.8047024]]\n",
      "PERDIDAAAA despues: 0.010152693837881088\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "[[[0.77293587]\n",
      "  [0.77849412]\n",
      "  [0.78336877]\n",
      "  [0.78689349]\n",
      "  [0.79119635]\n",
      "  [0.79543746]\n",
      "  [0.79951304]\n",
      "  [0.80421638]]]\n",
      "ejemplar: [0.77293587 0.77849412 0.78336877 0.78689349 0.79119635 0.79543746\n",
      " 0.79951304 0.80421638]\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.8088572]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[0.77293587 0.77849412 0.78336877 0.78689349 0.79119635 0.79543746\n",
      "  0.79951304 0.80421638]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005381544586271048\n",
      "Predicción post entrenamiento : [[0.80906355]]\n",
      "PERDIDAAAA despues: 0.00535131199285388\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "[[[0.77849412]\n",
      "  [0.78336877]\n",
      "  [0.78689349]\n",
      "  [0.79119635]\n",
      "  [0.79543746]\n",
      "  [0.79951304]\n",
      "  [0.80421638]\n",
      "  [0.8088572 ]]]\n",
      "ejemplar: [0.77849412 0.78336877 0.78689349 0.79119635 0.79543746 0.79951304\n",
      " 0.80421638 0.8088572 ]\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.81310815]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[0.77849412 0.78336877 0.78689349 0.79119635 0.79543746 0.79951304\n",
      "  0.80421638 0.8088572 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008964214473962784\n",
      "Predicción post entrenamiento : [[0.8141646]]\n",
      "PERDIDAAAA despues: 0.008765284903347492\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "[[[0.78336877]\n",
      "  [0.78689349]\n",
      "  [0.79119635]\n",
      "  [0.79543746]\n",
      "  [0.79951304]\n",
      "  [0.80421638]\n",
      "  [0.8088572 ]\n",
      "  [0.81310815]]]\n",
      "ejemplar: [0.78336877 0.78689349 0.79119635 0.79543746 0.79951304 0.80421638\n",
      " 0.8088572  0.81310815]\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.8178988]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[0.78336877 0.78689349 0.79119635 0.79543746 0.79951304 0.80421638\n",
      "  0.8088572  0.81310815]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005137861240655184\n",
      "Predicción post entrenamiento : [[0.81896514]]\n",
      "PERDIDAAAA despues: 0.004986132029443979\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "[[[0.78689349]\n",
      "  [0.79119635]\n",
      "  [0.79543746]\n",
      "  [0.79951304]\n",
      "  [0.80421638]\n",
      "  [0.8088572 ]\n",
      "  [0.81310815]\n",
      "  [0.81789881]]]\n",
      "ejemplar: [0.78689349 0.79119635 0.79543746 0.79951304 0.80421638 0.8088572\n",
      " 0.81310815 0.81789881]\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.82254064]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[0.78689349 0.79119635 0.79543746 0.79951304 0.80421638 0.8088572\n",
      "  0.81310815 0.81789881]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002736759139224887\n",
      "Predicción post entrenamiento : [[0.8228647]]\n",
      "PERDIDAAAA despues: 0.0027029572520405054\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "[[[0.79119635]\n",
      "  [0.79543746]\n",
      "  [0.79951304]\n",
      "  [0.80421638]\n",
      "  [0.8088572 ]\n",
      "  [0.81310815]\n",
      "  [0.81789881]\n",
      "  [0.82254064]]]\n",
      "ejemplar: [0.79119635 0.79543746 0.79951304 0.80421638 0.8088572  0.81310815\n",
      " 0.81789881 0.82254064]\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.8266587]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[0.79119635 0.79543746 0.79951304 0.80421638 0.8088572  0.81310815\n",
      "  0.81789881 0.82254064]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007491459138691425\n",
      "Predicción post entrenamiento : [[0.82694346]]\n",
      "PERDIDAAAA despues: 0.007442251313477755\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "[[[0.79543746]\n",
      "  [0.79951304]\n",
      "  [0.80421638]\n",
      "  [0.8088572 ]\n",
      "  [0.81310815]\n",
      "  [0.81789881]\n",
      "  [0.82254064]\n",
      "  [0.82665873]]]\n",
      "ejemplar: [0.79543746 0.79951304 0.80421638 0.8088572  0.81310815 0.81789881\n",
      " 0.82254064 0.82665873]\n",
      "y: 1.0\n",
      "Predicción : [[0.83077323]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[0.79543746 0.79951304 0.80421638 0.8088572  0.81310815 0.81789881\n",
      "  0.82254064 0.82665873]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02863769792020321\n",
      "Predicción post entrenamiento : [[0.83159256]]\n",
      "PERDIDAAAA despues: 0.028361065313220024\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "[[[0.79951304]\n",
      "  [0.80421638]\n",
      "  [0.8088572 ]\n",
      "  [0.81310815]\n",
      "  [0.81789881]\n",
      "  [0.82254064]\n",
      "  [0.82665873]\n",
      "  [0.83077323]]]\n",
      "ejemplar: [0.79951304 0.80421638 0.8088572  0.81310815 0.81789881 0.82254064\n",
      " 0.82665873 0.83077323]\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.8354835]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[0.79951304 0.80421638 0.8088572  0.81310815 0.81789881 0.82254064\n",
      "  0.82665873 0.83077323]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018244056031107903\n",
      "Predicción post entrenamiento : [[0.8371409]]\n",
      "PERDIDAAAA despues: 0.01779906451702118\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "[[[0.80421638]\n",
      "  [0.8088572 ]\n",
      "  [0.81310815]\n",
      "  [0.81789881]\n",
      "  [0.82254064]\n",
      "  [0.82665873]\n",
      "  [0.83077323]\n",
      "  [0.83548349]]]\n",
      "ejemplar: [0.80421638 0.8088572  0.81310815 0.81789881 0.82254064 0.82665873\n",
      " 0.83077323 0.83548349]\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.84115124]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[0.80421638 0.8088572  0.81310815 0.81789881 0.82254064 0.82665873\n",
      "  0.83077323 0.83548349]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0022706682793796062\n",
      "Predicción post entrenamiento : [[0.84119487]]\n",
      "PERDIDAAAA despues: 0.002266512019559741\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "[[[0.8088572 ]\n",
      "  [0.81310815]\n",
      "  [0.81789881]\n",
      "  [0.82254064]\n",
      "  [0.82665873]\n",
      "  [0.83077323]\n",
      "  [0.83548349]\n",
      "  [0.84115124]]]\n",
      "ejemplar: [0.8088572  0.81310815 0.81789881 0.82254064 0.82665873 0.83077323\n",
      " 0.83548349 0.84115124]\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.8451601]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[0.8088572  0.81310815 0.81789881 0.82254064 0.82665873 0.83077323\n",
      "  0.83548349 0.84115124]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001075458130799234\n",
      "Predicción post entrenamiento : [[0.8450215]]\n",
      "PERDIDAAAA despues: 0.0010845705401152372\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "[[[0.81310815]\n",
      "  [0.81789881]\n",
      "  [0.82254064]\n",
      "  [0.82665873]\n",
      "  [0.83077323]\n",
      "  [0.83548349]\n",
      "  [0.84115124]\n",
      "  [0.84516013]]]\n",
      "ejemplar: [0.81310815 0.81789881 0.82254064 0.82665873 0.83077323 0.83548349\n",
      " 0.84115124 0.84516013]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.8489546]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[0.81310815 0.81789881 0.82254064 0.82665873 0.83077323 0.83548349\n",
      "  0.84115124 0.84516013]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.460943531763405e-09\n",
      "Predicción post entrenamiento : [[0.8496374]]\n",
      "PERDIDAAAA despues: 5.499720145962783e-07\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "[[[0.81789881]\n",
      "  [0.82254064]\n",
      "  [0.82665873]\n",
      "  [0.83077323]\n",
      "  [0.83548349]\n",
      "  [0.84115124]\n",
      "  [0.84516013]\n",
      "  [0.84895462]]]\n",
      "ejemplar: [0.81789881 0.82254064 0.82665873 0.83077323 0.83548349 0.84115124\n",
      " 0.84516013 0.84895462]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.85364777]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[0.81789881 0.82254064 0.82665873 0.83077323 0.83548349 0.84115124\n",
      "  0.84516013 0.84895462]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00037927497760392725\n",
      "Predicción post entrenamiento : [[0.85337466]]\n",
      "PERDIDAAAA despues: 0.00036871200427412987\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "[[[0.82254064]\n",
      "  [0.82665873]\n",
      "  [0.83077323]\n",
      "  [0.83548349]\n",
      "  [0.84115124]\n",
      "  [0.84516013]\n",
      "  [0.84895462]\n",
      "  [0.85364777]]]\n",
      "ejemplar: [0.82254064 0.82665873 0.83077323 0.83548349 0.84115124 0.84516013\n",
      " 0.84895462 0.85364777]\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.8573129]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[0.82254064 0.82665873 0.83077323 0.83548349 0.84115124 0.84516013\n",
      "  0.84895462 0.85364777]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.919559614791069e-06\n",
      "Predicción post entrenamiento : [[0.85731167]]\n",
      "PERDIDAAAA despues: 4.914008513878798e-06\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "[[[0.82665873]\n",
      "  [0.83077323]\n",
      "  [0.83548349]\n",
      "  [0.84115124]\n",
      "  [0.84516013]\n",
      "  [0.84895462]\n",
      "  [0.85364777]\n",
      "  [0.85731292]]]\n",
      "ejemplar: [0.82665873 0.83077323 0.83548349 0.84115124 0.84516013 0.84895462\n",
      " 0.85364777 0.85731292]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.86120445]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[0.82665873 0.83077323 0.83548349 0.84115124 0.84516013 0.84895462\n",
      "  0.85364777 0.85731292]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00019705781596712768\n",
      "Predicción post entrenamiento : [[0.86145127]]\n",
      "PERDIDAAAA despues: 0.00019018907914869487\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "[[[0.83077323]\n",
      "  [0.83548349]\n",
      "  [0.84115124]\n",
      "  [0.84516013]\n",
      "  [0.84895462]\n",
      "  [0.85364777]\n",
      "  [0.85731292]\n",
      "  [0.86120445]]]\n",
      "ejemplar: [0.83077323 0.83548349 0.84115124 0.84516013 0.84895462 0.85364777\n",
      " 0.85731292 0.86120445]\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.8654342]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[0.83077323 0.83548349 0.84115124 0.84516013 0.84895462 0.85364777\n",
      "  0.85731292 0.86120445]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.059443305479363e-05\n",
      "Predicción post entrenamiento : [[0.8641622]]\n",
      "PERDIDAAAA despues: 5.083728319732472e-05\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "[[[0.83548349]\n",
      "  [0.84115124]\n",
      "  [0.84516013]\n",
      "  [0.84895462]\n",
      "  [0.85364777]\n",
      "  [0.85731292]\n",
      "  [0.86120445]\n",
      "  [0.86543423]]]\n",
      "ejemplar: [0.83548349 0.84115124 0.84516013 0.84895462 0.85364777 0.85731292\n",
      " 0.86120445 0.86543423]\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.86823213]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[0.83548349 0.84115124 0.84516013 0.84895462 0.85364777 0.85731292\n",
      "  0.86120445 0.86543423]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00033029401674866676\n",
      "Predicción post entrenamiento : [[0.8684164]]\n",
      "PERDIDAAAA despues: 0.00033702680957503617\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "[[[0.84115124]\n",
      "  [0.84516013]\n",
      "  [0.84895462]\n",
      "  [0.85364777]\n",
      "  [0.85731292]\n",
      "  [0.86120445]\n",
      "  [0.86543423]\n",
      "  [0.86823213]]]\n",
      "ejemplar: [0.84115124 0.84516013 0.84895462 0.85364777 0.85731292 0.86120445\n",
      " 0.86543423 0.86823213]\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.8723865]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[0.84115124 0.84516013 0.84895462 0.85364777 0.85731292 0.86120445\n",
      "  0.86543423 0.86823213]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008814906468614936\n",
      "Predicción post entrenamiento : [[0.87146914]]\n",
      "PERDIDAAAA despues: 0.0008278586319647729\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "[[[0.84516013]\n",
      "  [0.84895462]\n",
      "  [0.85364777]\n",
      "  [0.85731292]\n",
      "  [0.86120445]\n",
      "  [0.86543423]\n",
      "  [0.86823213]\n",
      "  [0.87238652]]]\n",
      "ejemplar: [0.84516013 0.84895462 0.85364777 0.85731292 0.86120445 0.86543423\n",
      " 0.86823213 0.87238652]\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.87501585]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[0.84516013 0.84895462 0.85364777 0.85731292 0.86120445 0.86543423\n",
      "  0.86823213 0.87238652]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0027122246101498604\n",
      "Predicción post entrenamiento : [[0.8736213]]\n",
      "PERDIDAAAA despues: 0.002568913623690605\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "[[[0.84895462]\n",
      "  [0.85364777]\n",
      "  [0.85731292]\n",
      "  [0.86120445]\n",
      "  [0.86543423]\n",
      "  [0.86823213]\n",
      "  [0.87238652]\n",
      "  [0.87501585]]]\n",
      "ejemplar: [0.84895462 0.85364777 0.85731292 0.86120445 0.86543423 0.86823213\n",
      " 0.87238652 0.87501585]\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.87714285]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[0.84895462 0.85364777 0.85731292 0.86120445 0.86543423 0.86823213\n",
      "  0.87238652 0.87501585]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01053431537002325\n",
      "Predicción post entrenamiento : [[0.8779306]]\n",
      "PERDIDAAAA despues: 0.010696637444198132\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "[[[0.85364777]\n",
      "  [0.85731292]\n",
      "  [0.86120445]\n",
      "  [0.86543423]\n",
      "  [0.86823213]\n",
      "  [0.87238652]\n",
      "  [0.87501585]\n",
      "  [0.87714285]]]\n",
      "ejemplar: [0.85364777 0.85731292 0.86120445 0.86543423 0.86823213 0.87238652\n",
      " 0.87501585 0.87714285]\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.88146025]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[0.85364777 0.85731292 0.86120445 0.86543423 0.86823213 0.87238652\n",
      "  0.87501585 0.87714285]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009461084380745888\n",
      "Predicción post entrenamiento : [[0.87847]]\n",
      "PERDIDAAAA despues: 0.008888314478099346\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "[[[0.85731292]\n",
      "  [0.86120445]\n",
      "  [0.86543423]\n",
      "  [0.86823213]\n",
      "  [0.87238652]\n",
      "  [0.87501585]\n",
      "  [0.87714285]\n",
      "  [0.88146025]]]\n",
      "ejemplar: [0.85731292 0.86120445 0.86543423 0.86823213 0.87238652 0.87501585\n",
      " 0.87714285 0.88146025]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.8817133]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[0.85731292 0.86120445 0.86543423 0.86823213 0.87238652 0.87501585\n",
      "  0.87714285 0.88146025]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004826352233067155\n",
      "Predicción post entrenamiento : [[0.8814156]]\n",
      "PERDIDAAAA despues: 0.00046964501962065697\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "[[[0.86120445]\n",
      "  [0.86543423]\n",
      "  [0.86823213]\n",
      "  [0.87238652]\n",
      "  [0.87501585]\n",
      "  [0.87714285]\n",
      "  [0.88146025]\n",
      "  [0.88171327]]]\n",
      "ejemplar: [0.86120445 0.86543423 0.86823213 0.87238652 0.87501585 0.87714285\n",
      " 0.88146025 0.88171327]\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.88459575]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[0.86120445 0.86543423 0.86823213 0.87238652 0.87501585 0.87714285\n",
      "  0.88146025 0.88171327]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009166181553155184\n",
      "Predicción post entrenamiento : [[0.8850924]]\n",
      "PERDIDAAAA despues: 0.000946936197578907\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "[[[0.86543423]\n",
      "  [0.86823213]\n",
      "  [0.87238652]\n",
      "  [0.87501585]\n",
      "  [0.87714285]\n",
      "  [0.88146025]\n",
      "  [0.88171327]\n",
      "  [0.88459575]]]\n",
      "ejemplar: [0.86543423 0.86823213 0.87238652 0.87501585 0.87714285 0.88146025\n",
      " 0.88171327 0.88459575]\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.8880945]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[0.86543423 0.86823213 0.87238652 0.87501585 0.87714285 0.88146025\n",
      "  0.88171327 0.88459575]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0026224199682474136\n",
      "Predicción post entrenamiento : [[0.8867948]]\n",
      "PERDIDAAAA despues: 0.0024909970816224813\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "[[[0.86823213]\n",
      "  [0.87238652]\n",
      "  [0.87501585]\n",
      "  [0.87714285]\n",
      "  [0.88146025]\n",
      "  [0.88171327]\n",
      "  [0.88459575]\n",
      "  [0.88809448]]]\n",
      "ejemplar: [0.86823213 0.87238652 0.87501585 0.87714285 0.88146025 0.88171327\n",
      " 0.88459575 0.88809448]\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.88945955]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[0.86823213 0.87238652 0.87501585 0.87714285 0.88146025 0.88171327\n",
      "  0.88459575 0.88809448]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0035460449289530516\n",
      "Predicción post entrenamiento : [[0.8887055]]\n",
      "PERDIDAAAA despues: 0.0034568069968372583\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "[[[0.87238652]\n",
      "  [0.87501585]\n",
      "  [0.87714285]\n",
      "  [0.88146025]\n",
      "  [0.88171327]\n",
      "  [0.88459575]\n",
      "  [0.88809448]\n",
      "  [0.88945955]]]\n",
      "ejemplar: [0.87238652 0.87501585 0.87714285 0.88146025 0.88171327 0.88459575\n",
      " 0.88809448 0.88945955]\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.89137363]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[0.87238652 0.87501585 0.87714285 0.88146025 0.88171327 0.88459575\n",
      "  0.88809448 0.88945955]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.6979738575173542e-05\n",
      "Predicción post entrenamiento : [[0.89136666]]\n",
      "PERDIDAAAA despues: 1.6922314898693003e-05\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "[[[0.87501585]\n",
      "  [0.87714285]\n",
      "  [0.88146025]\n",
      "  [0.88171327]\n",
      "  [0.88459575]\n",
      "  [0.88809448]\n",
      "  [0.88945955]\n",
      "  [0.89137363]]]\n",
      "ejemplar: [0.87501585 0.87714285 0.88146025 0.88171327 0.88459575 0.88809448\n",
      " 0.88945955 0.89137363]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.89361537]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[0.87501585 0.87714285 0.88146025 0.88171327 0.88459575 0.88809448\n",
      "  0.88945955 0.89137363]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011472483165562153\n",
      "Predicción post entrenamiento : [[0.8934602]]\n",
      "PERDIDAAAA despues: 0.0011367622064426541\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "[[[0.87714285]\n",
      "  [0.88146025]\n",
      "  [0.88171327]\n",
      "  [0.88459575]\n",
      "  [0.88809448]\n",
      "  [0.88945955]\n",
      "  [0.89137363]\n",
      "  [0.89361537]]]\n",
      "ejemplar: [0.87714285 0.88146025 0.88171327 0.88459575 0.88809448 0.88945955\n",
      " 0.89137363 0.89361537]\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.8956552]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[0.87714285 0.88146025 0.88171327 0.88459575 0.88809448 0.88945955\n",
      "  0.89137363 0.89361537]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003142518224194646\n",
      "Predicción post entrenamiento : [[0.8949153]]\n",
      "PERDIDAAAA despues: 0.0030601073522120714\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "[[[0.88146025]\n",
      "  [0.88171327]\n",
      "  [0.88459575]\n",
      "  [0.88809448]\n",
      "  [0.88945955]\n",
      "  [0.89137363]\n",
      "  [0.89361537]\n",
      "  [0.89565521]]]\n",
      "ejemplar: [0.88146025 0.88171327 0.88459575 0.88809448 0.88945955 0.89137363\n",
      " 0.89361537 0.89565521]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.89718026]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[0.88146025 0.88171327 0.88459575 0.88809448 0.88945955 0.89137363\n",
      "  0.89361537 0.89565521]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01285401452332735\n",
      "Predicción post entrenamiento : [[0.89618117]]\n",
      "PERDIDAAAA despues: 0.012628466822206974\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "[[[0.88171327]\n",
      "  [0.88459575]\n",
      "  [0.88809448]\n",
      "  [0.88945955]\n",
      "  [0.89137363]\n",
      "  [0.89361537]\n",
      "  [0.89565521]\n",
      "  [0.89718026]]]\n",
      "ejemplar: [0.88171327 0.88459575 0.88809448 0.88945955 0.89137363 0.89361537\n",
      " 0.89565521 0.89718026]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.8978675]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[0.88171327 0.88459575 0.88809448 0.88945955 0.89137363 0.89361537\n",
      "  0.89565521 0.89718026]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0063329776749014854\n",
      "Predicción post entrenamiento : [[0.8974656]]\n",
      "PERDIDAAAA despues: 0.00626917090266943\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "[[[0.88459575]\n",
      "  [0.88809448]\n",
      "  [0.88945955]\n",
      "  [0.89137363]\n",
      "  [0.89361537]\n",
      "  [0.89565521]\n",
      "  [0.89718026]\n",
      "  [0.8978675 ]]]\n",
      "ejemplar: [0.88459575 0.88809448 0.88945955 0.89137363 0.89361537 0.89565521\n",
      " 0.89718026 0.8978675 ]\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.89966375]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[0.88459575 0.88809448 0.88945955 0.89137363 0.89361537 0.89565521\n",
      "  0.89718026 0.8978675 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011771720834076405\n",
      "Predicción post entrenamiento : [[0.89801073]]\n",
      "PERDIDAAAA despues: 0.011415756307542324\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "[[[0.88809448]\n",
      "  [0.88945955]\n",
      "  [0.89137363]\n",
      "  [0.89361537]\n",
      "  [0.89565521]\n",
      "  [0.89718026]\n",
      "  [0.8978675 ]\n",
      "  [0.89966375]]]\n",
      "ejemplar: [0.88809448 0.88945955 0.89137363 0.89361537 0.89565521 0.89718026\n",
      " 0.8978675  0.89966375]\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.8999982]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[0.88809448 0.88945955 0.89137363 0.89361537 0.89565521 0.89718026\n",
      "  0.8978675  0.89966375]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019443580880761147\n",
      "Predicción post entrenamiento : [[0.8984973]]\n",
      "PERDIDAAAA despues: 0.019027259200811386\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "[[[0.88945955]\n",
      "  [0.89137363]\n",
      "  [0.89361537]\n",
      "  [0.89565521]\n",
      "  [0.89718026]\n",
      "  [0.8978675 ]\n",
      "  [0.89966375]\n",
      "  [0.89999819]]]\n",
      "ejemplar: [0.88945955 0.89137363 0.89361537 0.89565521 0.89718026 0.8978675\n",
      " 0.89966375 0.89999819]\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.90002704]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[0.88945955 0.89137363 0.89361537 0.89565521 0.89718026 0.8978675\n",
      "  0.89966375 0.89999819]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011766470037400723\n",
      "Predicción post entrenamiento : [[0.89974225]]\n",
      "PERDIDAAAA despues: 0.011704766191542149\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "[[[0.89137363]\n",
      "  [0.89361537]\n",
      "  [0.89565521]\n",
      "  [0.89718026]\n",
      "  [0.8978675 ]\n",
      "  [0.89966375]\n",
      "  [0.89999819]\n",
      "  [0.90002704]]]\n",
      "ejemplar: [0.89137363 0.89361537 0.89565521 0.89718026 0.8978675  0.89966375\n",
      " 0.89999819 0.90002704]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9013387]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[0.89137363 0.89361537 0.89565521 0.89718026 0.8978675  0.89966375\n",
      "  0.89999819 0.90002704]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017594540491700172\n",
      "Predicción post entrenamiento : [[0.90013766]]\n",
      "PERDIDAAAA despues: 0.017277361825108528\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "[[[0.89361537]\n",
      "  [0.89565521]\n",
      "  [0.89718026]\n",
      "  [0.8978675 ]\n",
      "  [0.89966375]\n",
      "  [0.89999819]\n",
      "  [0.90002704]\n",
      "  [0.9013387 ]]]\n",
      "ejemplar: [0.89361537 0.89565521 0.89718026 0.8978675  0.89966375 0.89999819\n",
      " 0.90002704 0.9013387 ]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.90161556]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[0.89361537 0.89565521 0.89718026 0.8978675  0.89966375 0.89999819\n",
      "  0.90002704 0.9013387 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017668066546320915\n",
      "Predicción post entrenamiento : [[0.9006778]]\n",
      "PERDIDAAAA despues: 0.01741964928805828\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "[[[0.89565521]\n",
      "  [0.89718026]\n",
      "  [0.8978675 ]\n",
      "  [0.89966375]\n",
      "  [0.89999819]\n",
      "  [0.90002704]\n",
      "  [0.9013387 ]\n",
      "  [0.90161556]]]\n",
      "ejemplar: [0.89565521 0.89718026 0.8978675  0.89966375 0.89999819 0.90002704\n",
      " 0.9013387  0.90161556]\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.9018856]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[0.89565521 0.89718026 0.8978675  0.89966375 0.89999819 0.90002704\n",
      "  0.9013387  0.90161556]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010602920316159725\n",
      "Predicción post entrenamiento : [[0.9016002]]\n",
      "PERDIDAAAA despues: 0.010544216260313988\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "[[[0.89718026]\n",
      "  [0.8978675 ]\n",
      "  [0.89966375]\n",
      "  [0.89999819]\n",
      "  [0.90002704]\n",
      "  [0.9013387 ]\n",
      "  [0.90161556]\n",
      "  [0.90188563]]]\n",
      "ejemplar: [0.89718026 0.8978675  0.89966375 0.89999819 0.90002704 0.9013387\n",
      " 0.90161556 0.90188563]\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.90252477]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[0.89718026 0.8978675  0.89966375 0.89999819 0.90002704 0.9013387\n",
      "  0.90161556 0.90188563]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012660946696996689\n",
      "Predicción post entrenamiento : [[0.9025499]]\n",
      "PERDIDAAAA despues: 0.012666608206927776\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "[[[0.8978675 ]\n",
      "  [0.89966375]\n",
      "  [0.89999819]\n",
      "  [0.90002704]\n",
      "  [0.9013387 ]\n",
      "  [0.90161556]\n",
      "  [0.90188563]\n",
      "  [0.90252477]]]\n",
      "ejemplar: [0.8978675  0.89966375 0.89999819 0.90002704 0.9013387  0.90161556\n",
      " 0.90188563 0.90252477]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.9032766]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[0.8978675  0.89966375 0.89999819 0.90002704 0.9013387  0.90161556\n",
      "  0.90188563 0.90252477]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.020479373633861542\n",
      "Predicción post entrenamiento : [[0.90252584]]\n",
      "PERDIDAAAA despues: 0.02026505582034588\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "[[[0.89966375]\n",
      "  [0.89999819]\n",
      "  [0.90002704]\n",
      "  [0.9013387 ]\n",
      "  [0.90161556]\n",
      "  [0.90188563]\n",
      "  [0.90252477]\n",
      "  [0.90327662]]]\n",
      "ejemplar: [0.89966375 0.89999819 0.90002704 0.9013387  0.90161556 0.90188563\n",
      " 0.90252477 0.90327662]\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.90325713]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[0.89966375 0.89999819 0.90002704 0.9013387  0.90161556 0.90188563\n",
      "  0.90252477 0.90327662]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04746466130018234\n",
      "Predicción post entrenamiento : [[0.90110147]]\n",
      "PERDIDAAAA despues: 0.04653002694249153\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "[[[0.89999819]\n",
      "  [0.90002704]\n",
      "  [0.9013387 ]\n",
      "  [0.90161556]\n",
      "  [0.90188563]\n",
      "  [0.90252477]\n",
      "  [0.90327662]\n",
      "  [0.90325713]]]\n",
      "ejemplar: [0.89999819 0.90002704 0.9013387  0.90161556 0.90188563 0.90252477\n",
      " 0.90327662 0.90325713]\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.9015001]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[0.89999819 0.90002704 0.9013387  0.90161556 0.90188563 0.90252477\n",
      "  0.90327662 0.90325713]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08779863268136978\n",
      "Predicción post entrenamiento : [[0.898888]]\n",
      "PERDIDAAAA despues: 0.08625747263431549\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "[[[0.90002704]\n",
      "  [0.9013387 ]\n",
      "  [0.90161556]\n",
      "  [0.90188563]\n",
      "  [0.90252477]\n",
      "  [0.90327662]\n",
      "  [0.90325713]\n",
      "  [0.90150011]]]\n",
      "ejemplar: [0.90002704 0.9013387  0.90161556 0.90188563 0.90252477 0.90327662\n",
      " 0.90325713 0.90150011]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.8993152]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[0.90002704 0.9013387  0.90161556 0.90188563 0.90252477 0.90327662\n",
      "  0.90325713 0.90150011]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.054969895631074905\n",
      "Predicción post entrenamiento : [[0.8984678]]\n",
      "PERDIDAAAA despues: 0.05457325652241707\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "[[[0.9013387 ]\n",
      "  [0.90161556]\n",
      "  [0.90188563]\n",
      "  [0.90252477]\n",
      "  [0.90327662]\n",
      "  [0.90325713]\n",
      "  [0.90150011]\n",
      "  [0.89931518]]]\n",
      "ejemplar: [0.9013387  0.90161556 0.90188563 0.90252477 0.90327662 0.90325713\n",
      " 0.90150011 0.89931518]\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.89898175]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[0.9013387  0.90161556 0.90188563 0.90252477 0.90327662 0.90325713\n",
      "  0.90150011 0.89931518]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03652554377913475\n",
      "Predicción post entrenamiento : [[0.8984294]]\n",
      "PERDIDAAAA despues: 0.036314718425273895\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "[[[0.90161556]\n",
      "  [0.90188563]\n",
      "  [0.90252477]\n",
      "  [0.90327662]\n",
      "  [0.90325713]\n",
      "  [0.90150011]\n",
      "  [0.89931518]\n",
      "  [0.89898175]]]\n",
      "ejemplar: [0.90161556 0.90188563 0.90252477 0.90327662 0.90325713 0.90150011\n",
      " 0.89931518 0.89898175]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.8986209]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[0.90161556 0.90188563 0.90252477 0.90327662 0.90325713 0.90150011\n",
      "  0.89931518 0.89898175]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05464482307434082\n",
      "Predicción post entrenamiento : [[0.8973735]]\n",
      "PERDIDAAAA despues: 0.054063186049461365\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "[[[0.90188563]\n",
      "  [0.90252477]\n",
      "  [0.90327662]\n",
      "  [0.90325713]\n",
      "  [0.90150011]\n",
      "  [0.89931518]\n",
      "  [0.89898175]\n",
      "  [0.8986209 ]]]\n",
      "ejemplar: [0.90188563 0.90252477 0.90327662 0.90325713 0.90150011 0.89931518\n",
      " 0.89898175 0.8986209 ]\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.89745325]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[0.90188563 0.90252477 0.90327662 0.90325713 0.90150011 0.89931518\n",
      "  0.89898175 0.8986209 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.034633610397577286\n",
      "Predicción post entrenamiento : [[0.89623296]]\n",
      "PERDIDAAAA despues: 0.034180909395217896\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "[[[0.90252477]\n",
      "  [0.90327662]\n",
      "  [0.90325713]\n",
      "  [0.90150011]\n",
      "  [0.89931518]\n",
      "  [0.89898175]\n",
      "  [0.8986209 ]\n",
      "  [0.89745325]]]\n",
      "ejemplar: [0.90252477 0.90327662 0.90325713 0.90150011 0.89931518 0.89898175\n",
      " 0.8986209  0.89745325]\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.8961451]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[0.90252477 0.90327662 0.90325713 0.90150011 0.89931518 0.89898175\n",
      "  0.8986209  0.89745325]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.047912053763866425\n",
      "Predicción post entrenamiento : [[0.89360124]]\n",
      "PERDIDAAAA despues: 0.04680487886071205\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "[[[0.90327662]\n",
      "  [0.90325713]\n",
      "  [0.90150011]\n",
      "  [0.89931518]\n",
      "  [0.89898175]\n",
      "  [0.8986209 ]\n",
      "  [0.89745325]\n",
      "  [0.89614511]]]\n",
      "ejemplar: [0.90327662 0.90325713 0.90150011 0.89931518 0.89898175 0.8986209\n",
      " 0.89745325 0.89614511]\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.89317566]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[0.90327662 0.90325713 0.90150011 0.89931518 0.89898175 0.8986209\n",
      "  0.89745325 0.89614511]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01717880181968212\n",
      "Predicción post entrenamiento : [[0.8920625]]\n",
      "PERDIDAAAA despues: 0.016888238489627838\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "[[[0.90325713]\n",
      "  [0.90150011]\n",
      "  [0.89931518]\n",
      "  [0.89898175]\n",
      "  [0.8986209 ]\n",
      "  [0.89745325]\n",
      "  [0.89614511]\n",
      "  [0.89317566]]]\n",
      "ejemplar: [0.90325713 0.90150011 0.89931518 0.89898175 0.8986209  0.89745325\n",
      " 0.89614511 0.89317566]\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.8911808]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[0.90325713 0.90150011 0.89931518 0.89898175 0.8986209  0.89745325\n",
      "  0.89614511 0.89317566]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0070777349174022675\n",
      "Predicción post entrenamiento : [[0.8913829]]\n",
      "PERDIDAAAA despues: 0.007111773826181889\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "[[[0.90150011]\n",
      "  [0.89931518]\n",
      "  [0.89898175]\n",
      "  [0.8986209 ]\n",
      "  [0.89745325]\n",
      "  [0.89614511]\n",
      "  [0.89317566]\n",
      "  [0.89118081]]]\n",
      "ejemplar: [0.90150011 0.89931518 0.89898175 0.8986209  0.89745325 0.89614511\n",
      " 0.89317566 0.89118081]\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.8901754]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[0.90150011 0.89931518 0.89898175 0.8986209  0.89745325 0.89614511\n",
      "  0.89317566 0.89118081]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005623120814561844\n",
      "Predicción post entrenamiento : [[0.88971585]]\n",
      "PERDIDAAAA despues: 0.005554410628974438\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "[[[0.89931518]\n",
      "  [0.89898175]\n",
      "  [0.8986209 ]\n",
      "  [0.89745325]\n",
      "  [0.89614511]\n",
      "  [0.89317566]\n",
      "  [0.89118081]\n",
      "  [0.8901754 ]]]\n",
      "ejemplar: [0.89931518 0.89898175 0.8986209  0.89745325 0.89614511 0.89317566\n",
      " 0.89118081 0.8901754 ]\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.88862836]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[0.89931518 0.89898175 0.8986209  0.89745325 0.89614511 0.89317566\n",
      "  0.89118081 0.8901754 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00031009578378871083\n",
      "Predicción post entrenamiento : [[0.8891421]]\n",
      "PERDIDAAAA despues: 0.00029226651531644166\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "[[[0.89898175]\n",
      "  [0.8986209 ]\n",
      "  [0.89745325]\n",
      "  [0.89614511]\n",
      "  [0.89317566]\n",
      "  [0.89118081]\n",
      "  [0.8901754 ]\n",
      "  [0.88862836]]]\n",
      "ejemplar: [0.89898175 0.8986209  0.89745325 0.89614511 0.89317566 0.89118081\n",
      " 0.8901754  0.88862836]\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.8882994]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[0.89898175 0.8986209  0.89745325 0.89614511 0.89317566 0.89118081\n",
      "  0.8901754  0.88862836]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0050988346338272095\n",
      "Predicción post entrenamiento : [[0.88805157]]\n",
      "PERDIDAAAA despues: 0.005134290084242821\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "[[[0.8986209 ]\n",
      "  [0.89745325]\n",
      "  [0.89614511]\n",
      "  [0.89317566]\n",
      "  [0.89118081]\n",
      "  [0.8901754 ]\n",
      "  [0.88862836]\n",
      "  [0.88829941]]]\n",
      "ejemplar: [0.8986209  0.89745325 0.89614511 0.89317566 0.89118081 0.8901754\n",
      " 0.88862836 0.88829941]\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.8869338]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[0.8986209  0.89745325 0.89614511 0.89317566 0.89118081 0.8901754\n",
      "  0.88862836 0.88829941]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005994021892547607\n",
      "Predicción post entrenamiento : [[0.88805646]]\n",
      "PERDIDAAAA despues: 0.0058214482851326466\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "[[[0.89745325]\n",
      "  [0.89614511]\n",
      "  [0.89317566]\n",
      "  [0.89118081]\n",
      "  [0.8901754 ]\n",
      "  [0.88862836]\n",
      "  [0.88829941]\n",
      "  [0.8869338 ]]]\n",
      "ejemplar: [0.89745325 0.89614511 0.89317566 0.89118081 0.8901754  0.88862836\n",
      " 0.88829941 0.8869338 ]\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.8866236]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[0.89745325 0.89614511 0.89317566 0.89118081 0.8901754  0.88862836\n",
      "  0.88829941 0.8869338 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.9720175714610377e-06\n",
      "Predicción post entrenamiento : [[0.8864975]]\n",
      "PERDIDAAAA despues: 2.3421512196364347e-06\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "[[[0.89614511]\n",
      "  [0.89317566]\n",
      "  [0.89118081]\n",
      "  [0.8901754 ]\n",
      "  [0.88862836]\n",
      "  [0.88829941]\n",
      "  [0.8869338 ]\n",
      "  [0.88662362]]]\n",
      "ejemplar: [0.89614511 0.89317566 0.89118081 0.8901754  0.88862836 0.88829941\n",
      " 0.8869338  0.88662362]\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.88495547]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[0.89614511 0.89317566 0.89118081 0.8901754  0.88862836 0.88829941\n",
      "  0.8869338  0.88662362]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.962591239949688e-05\n",
      "Predicción post entrenamiento : [[0.8845619]]\n",
      "PERDIDAAAA despues: 6.585892697330564e-05\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "[[[0.89317566]\n",
      "  [0.89118081]\n",
      "  [0.8901754 ]\n",
      "  [0.88862836]\n",
      "  [0.88829941]\n",
      "  [0.8869338 ]\n",
      "  [0.88662362]\n",
      "  [0.88495547]]]\n",
      "ejemplar: [0.89317566 0.89118081 0.8901754  0.88862836 0.88829941 0.8869338\n",
      " 0.88662362 0.88495547]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.88296294]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[0.89317566 0.89118081 0.8901754  0.88862836 0.88829941 0.8869338\n",
      "  0.88662362 0.88495547]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.961026545264758e-05\n",
      "Predicción post entrenamiento : [[0.88324565]]\n",
      "PERDIDAAAA despues: 6.40555881545879e-05\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "[[[0.89118081]\n",
      "  [0.8901754 ]\n",
      "  [0.88862836]\n",
      "  [0.88829941]\n",
      "  [0.8869338 ]\n",
      "  [0.88662362]\n",
      "  [0.88495547]\n",
      "  [0.88296294]]]\n",
      "ejemplar: [0.89118081 0.8901754  0.88862836 0.88829941 0.8869338  0.88662362\n",
      " 0.88495547 0.88296294]\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.8820875]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[0.89118081 0.8901754  0.88862836 0.88829941 0.8869338  0.88662362\n",
      "  0.88495547 0.88296294]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000976845622062683\n",
      "Predicción post entrenamiento : [[0.8812298]]\n",
      "PERDIDAAAA despues: 0.0009239666396752\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "[[[0.8901754 ]\n",
      "  [0.88862836]\n",
      "  [0.88829941]\n",
      "  [0.8869338 ]\n",
      "  [0.88662362]\n",
      "  [0.88495547]\n",
      "  [0.88296294]\n",
      "  [0.88208753]]]\n",
      "ejemplar: [0.8901754  0.88862836 0.88829941 0.8869338  0.88662362 0.88495547\n",
      " 0.88296294 0.88208753]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.88030475]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[0.8901754  0.88862836 0.88829941 0.8869338  0.88662362 0.88495547\n",
      "  0.88296294 0.88208753]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009865231113508344\n",
      "Predicción post entrenamiento : [[0.8797183]]\n",
      "PERDIDAAAA despues: 0.0009500274900346994\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "[[[0.88862836]\n",
      "  [0.88829941]\n",
      "  [0.8869338 ]\n",
      "  [0.88662362]\n",
      "  [0.88495547]\n",
      "  [0.88296294]\n",
      "  [0.88208753]\n",
      "  [0.88030475]]]\n",
      "ejemplar: [0.88862836 0.88829941 0.8869338  0.88662362 0.88495547 0.88296294\n",
      " 0.88208753 0.88030475]\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.87876487]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[0.88862836 0.88829941 0.8869338  0.88662362 0.88495547 0.88296294\n",
      "  0.88208753 0.88030475]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006997790187597275\n",
      "Predicción post entrenamiento : [[0.8796301]]\n",
      "PERDIDAAAA despues: 0.00685378210619092\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "[[[0.88829941]\n",
      "  [0.8869338 ]\n",
      "  [0.88662362]\n",
      "  [0.88495547]\n",
      "  [0.88296294]\n",
      "  [0.88208753]\n",
      "  [0.88030475]\n",
      "  [0.87876487]]]\n",
      "ejemplar: [0.88829941 0.8869338  0.88662362 0.88495547 0.88296294 0.88208753\n",
      " 0.88030475 0.87876487]\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.87878644]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[0.88829941 0.8869338  0.88662362 0.88495547 0.88296294 0.88208753\n",
      "  0.88030475 0.87876487]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007930878549814224\n",
      "Predicción post entrenamiento : [[0.87886924]]\n",
      "PERDIDAAAA despues: 0.00791613943874836\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "[[[0.8869338 ]\n",
      "  [0.88662362]\n",
      "  [0.88495547]\n",
      "  [0.88296294]\n",
      "  [0.88208753]\n",
      "  [0.88030475]\n",
      "  [0.87876487]\n",
      "  [0.87878644]]]\n",
      "ejemplar: [0.8869338  0.88662362 0.88495547 0.88296294 0.88208753 0.88030475\n",
      " 0.87876487 0.87878644]\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.87778807]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[0.8869338  0.88662362 0.88495547 0.88296294 0.88208753 0.88030475\n",
      "  0.87876487 0.87878644]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003960513509809971\n",
      "Predicción post entrenamiento : [[0.877942]]\n",
      "PERDIDAAAA despues: 0.003941159229725599\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "[[[0.88662362]\n",
      "  [0.88495547]\n",
      "  [0.88296294]\n",
      "  [0.88208753]\n",
      "  [0.88030475]\n",
      "  [0.87876487]\n",
      "  [0.87878644]\n",
      "  [0.87778807]]]\n",
      "ejemplar: [0.88662362 0.88495547 0.88296294 0.88208753 0.88030475 0.87876487\n",
      " 0.87878644 0.87778807]\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.87688935]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[0.88662362 0.88495547 0.88296294 0.88208753 0.88030475 0.87876487\n",
      "  0.87878644 0.87778807]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00913972593843937\n",
      "Predicción post entrenamiento : [[0.8774487]]\n",
      "PERDIDAAAA despues: 0.009033093228936195\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "[[[0.88495547]\n",
      "  [0.88296294]\n",
      "  [0.88208753]\n",
      "  [0.88030475]\n",
      "  [0.87876487]\n",
      "  [0.87878644]\n",
      "  [0.87778807]\n",
      "  [0.87688935]]]\n",
      "ejemplar: [0.88495547 0.88296294 0.88208753 0.88030475 0.87876487 0.87878644\n",
      " 0.87778807 0.87688935]\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.87613034]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[0.88495547 0.88296294 0.88208753 0.88030475 0.87876487 0.87878644\n",
      "  0.87778807 0.87688935]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014585415832698345\n",
      "Predicción post entrenamiento : [[0.8762564]]\n",
      "PERDIDAAAA despues: 0.014554983004927635\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "[[[0.88296294]\n",
      "  [0.88208753]\n",
      "  [0.88030475]\n",
      "  [0.87876487]\n",
      "  [0.87878644]\n",
      "  [0.87778807]\n",
      "  [0.87688935]\n",
      "  [0.87613034]]]\n",
      "ejemplar: [0.88296294 0.88208753 0.88030475 0.87876487 0.87878644 0.87778807\n",
      " 0.87688935 0.87613034]\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.8750474]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[0.88296294 0.88208753 0.88030475 0.87876487 0.87878644 0.87778807\n",
      "  0.87688935 0.87613034]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005796435289084911\n",
      "Predicción post entrenamiento : [[0.875628]]\n",
      "PERDIDAAAA despues: 0.005708363838493824\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "[[[0.88208753]\n",
      "  [0.88030475]\n",
      "  [0.87876487]\n",
      "  [0.87878644]\n",
      "  [0.87778807]\n",
      "  [0.87688935]\n",
      "  [0.87613034]\n",
      "  [0.87504739]]]\n",
      "ejemplar: [0.88208753 0.88030475 0.87876487 0.87878644 0.87778807 0.87688935\n",
      " 0.87613034 0.87504739]\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.8746591]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[0.88208753 0.88030475 0.87876487 0.87878644 0.87778807 0.87688935\n",
      "  0.87613034 0.87504739]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00044595671351999044\n",
      "Predicción post entrenamiento : [[0.87396455]]\n",
      "PERDIDAAAA despues: 0.0004757746937684715\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "[[[0.88030475]\n",
      "  [0.87876487]\n",
      "  [0.87878644]\n",
      "  [0.87778807]\n",
      "  [0.87688935]\n",
      "  [0.87613034]\n",
      "  [0.87504739]\n",
      "  [0.87465912]]]\n",
      "ejemplar: [0.88030475 0.87876487 0.87878644 0.87778807 0.87688935 0.87613034\n",
      " 0.87504739 0.87465912]\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.872963]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[0.88030475 0.87876487 0.87878644 0.87778807 0.87688935 0.87613034\n",
      "  0.87504739 0.87465912]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.188129529822618e-05\n",
      "Predicción post entrenamiento : [[0.873217]]\n",
      "PERDIDAAAA despues: 6.763925193808973e-05\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "[[[0.87876487]\n",
      "  [0.87878644]\n",
      "  [0.87778807]\n",
      "  [0.87688935]\n",
      "  [0.87613034]\n",
      "  [0.87504739]\n",
      "  [0.87465912]\n",
      "  [0.87296301]]]\n",
      "ejemplar: [0.87876487 0.87878644 0.87778807 0.87688935 0.87613034 0.87504739\n",
      " 0.87465912 0.87296301]\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.87244844]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[0.87876487 0.87878644 0.87778807 0.87688935 0.87613034 0.87504739\n",
      "  0.87465912 0.87296301]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0019925490487366915\n",
      "Predicción post entrenamiento : [[0.8728921]]\n",
      "PERDIDAAAA despues: 0.00195313966833055\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "[[[0.87878644]\n",
      "  [0.87778807]\n",
      "  [0.87688935]\n",
      "  [0.87613034]\n",
      "  [0.87504739]\n",
      "  [0.87465912]\n",
      "  [0.87296301]\n",
      "  [0.87244844]]]\n",
      "ejemplar: [0.87878644 0.87778807 0.87688935 0.87613034 0.87504739 0.87465912\n",
      " 0.87296301 0.87244844]\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.872322]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[0.87878644 0.87778807 0.87688935 0.87613034 0.87504739 0.87465912\n",
      "  0.87296301 0.87244844]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0022540208883583546\n",
      "Predicción post entrenamiento : [[0.87290204]]\n",
      "PERDIDAAAA despues: 0.0021992833353579044\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "[[[0.87778807]\n",
      "  [0.87688935]\n",
      "  [0.87613034]\n",
      "  [0.87504739]\n",
      "  [0.87465912]\n",
      "  [0.87296301]\n",
      "  [0.87244844]\n",
      "  [0.87232202]]]\n",
      "ejemplar: [0.87778807 0.87688935 0.87613034 0.87504739 0.87465912 0.87296301\n",
      " 0.87244844 0.87232202]\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.8721044]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[0.87778807 0.87688935 0.87613034 0.87504739 0.87465912 0.87296301\n",
      "  0.87244844 0.87232202]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008017124608159065\n",
      "Predicción post entrenamiento : [[0.8720988]]\n",
      "PERDIDAAAA despues: 0.008018127642571926\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "[[[0.87688935]\n",
      "  [0.87613034]\n",
      "  [0.87504739]\n",
      "  [0.87465912]\n",
      "  [0.87296301]\n",
      "  [0.87244844]\n",
      "  [0.87232202]\n",
      "  [0.87210441]]]\n",
      "ejemplar: [0.87688935 0.87613034 0.87504739 0.87465912 0.87296301 0.87244844\n",
      " 0.87232202 0.87210441]\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.87134296]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[0.87688935 0.87613034 0.87504739 0.87465912 0.87296301 0.87244844\n",
      "  0.87232202 0.87210441]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009386973455548286\n",
      "Predicción post entrenamiento : [[0.87166977]]\n",
      "PERDIDAAAA despues: 0.009323753416538239\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "[[[0.87613034]\n",
      "  [0.87504739]\n",
      "  [0.87465912]\n",
      "  [0.87296301]\n",
      "  [0.87244844]\n",
      "  [0.87232202]\n",
      "  [0.87210441]\n",
      "  [0.87134296]]]\n",
      "ejemplar: [0.87613034 0.87504739 0.87465912 0.87296301 0.87244844 0.87232202\n",
      " 0.87210441 0.87134296]\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.8709439]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[0.87613034 0.87504739 0.87465912 0.87296301 0.87244844 0.87232202\n",
      "  0.87210441 0.87134296]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007538479287177324\n",
      "Predicción post entrenamiento : [[0.87154156]]\n",
      "PERDIDAAAA despues: 0.0074350545182824135\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "[[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "ejemplar: [0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      " 0.03448276 0.04223169]\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.24402258]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      "  0.03448276 0.04223169]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03917090967297554\n",
      "Predicción post entrenamiento : [[0.21109259]]\n",
      "PERDIDAAAA despues: 0.027220522984862328\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "[[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24402258]]]\n",
      "ejemplar: [0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      " 0.04223169 0.24402258]\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.19556016]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      "  0.04223169 0.24402258]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008342444896697998\n",
      "Predicción post entrenamiento : [[0.18319695]]\n",
      "PERDIDAAAA despues: 0.006236857734620571\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "[[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24402258]\n",
      "  [0.19556016]]]\n",
      "ejemplar: [0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      " 0.24402258 0.19556016]\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.18716338]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      "  0.24402258 0.19556016]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010863339994102716\n",
      "Predicción post entrenamiento : [[0.17940761]]\n",
      "PERDIDAAAA despues: 0.0006352320197038352\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "[[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24402258]\n",
      "  [0.19556016]\n",
      "  [0.18716338]]]\n",
      "ejemplar: [0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.24402258\n",
      " 0.19556016 0.18716338]\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.19074029]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.24402258\n",
      "  0.19556016 0.18716338]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012240695068612695\n",
      "Predicción post entrenamiento : [[0.18587807]]\n",
      "PERDIDAAAA despues: 0.0009074846166186035\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "[[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24402258]\n",
      "  [0.19556016]\n",
      "  [0.18716338]\n",
      "  [0.19074029]]]\n",
      "ejemplar: [0.05656722 0.02595893 0.03448276 0.04223169 0.24402258 0.19556016\n",
      " 0.18716338 0.19074029]\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.19842322]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[0.05656722 0.02595893 0.03448276 0.04223169 0.24402258 0.19556016\n",
      "  0.18716338 0.19074029]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005313021596521139\n",
      "Predicción post entrenamiento : [[0.18934892]]\n",
      "PERDIDAAAA despues: 0.0040725041180849075\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "[[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24402258]\n",
      "  [0.19556016]\n",
      "  [0.18716338]\n",
      "  [0.19074029]\n",
      "  [0.19842322]]]\n",
      "ejemplar: [0.02595893 0.03448276 0.04223169 0.24402258 0.19556016 0.18716338\n",
      " 0.19074029 0.19842322]\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.19922183]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[0.02595893 0.03448276 0.04223169 0.24402258 0.19556016 0.18716338\n",
      "  0.19074029 0.19842322]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0028667317237704992\n",
      "Predicción post entrenamiento : [[0.19422974]]\n",
      "PERDIDAAAA despues: 0.0023570803459733725\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "[[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24402258]\n",
      "  [0.19556016]\n",
      "  [0.18716338]\n",
      "  [0.19074029]\n",
      "  [0.19842322]\n",
      "  [0.19922183]]]\n",
      "ejemplar: [0.03448276 0.04223169 0.24402258 0.19556016 0.18716338 0.19074029\n",
      " 0.19842322 0.19922183]\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.21501657]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[0.03448276 0.04223169 0.24402258 0.19556016 0.18716338 0.19074029\n",
      "  0.19842322 0.19922183]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004700709134340286\n",
      "Predicción post entrenamiento : [[0.2108899]]\n",
      "PERDIDAAAA despues: 0.004151875618845224\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "[[[0.04223169]\n",
      "  [0.24402258]\n",
      "  [0.19556016]\n",
      "  [0.18716338]\n",
      "  [0.19074029]\n",
      "  [0.19842322]\n",
      "  [0.19922183]\n",
      "  [0.21501657]]]\n",
      "ejemplar: [0.04223169 0.24402258 0.19556016 0.18716338 0.19074029 0.19842322\n",
      " 0.19922183 0.21501657]\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.23609532]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[0.04223169 0.24402258 0.19556016 0.18716338 0.19074029 0.19842322\n",
      "  0.19922183 0.21501657]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016037853201851249\n",
      "Predicción post entrenamiento : [[0.2344728]]\n",
      "PERDIDAAAA despues: 0.0014764622319489717\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "[[[0.24402258]\n",
      "  [0.19556016]\n",
      "  [0.18716338]\n",
      "  [0.19074029]\n",
      "  [0.19842322]\n",
      "  [0.19922183]\n",
      "  [0.21501657]\n",
      "  [0.23609532]]]\n",
      "ejemplar: [0.24402258 0.19556016 0.18716338 0.19074029 0.19842322 0.19922183\n",
      " 0.21501657 0.23609532]\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.26442474]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[0.24402258 0.19556016 0.18716338 0.19074029 0.19842322 0.19922183\n",
      "  0.21501657 0.23609532]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011487993178889155\n",
      "Predicción post entrenamiento : [[0.26346603]]\n",
      "PERDIDAAAA despues: 0.001084729447029531\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "[[[0.19556016]\n",
      "  [0.18716338]\n",
      "  [0.19074029]\n",
      "  [0.19842322]\n",
      "  [0.19922183]\n",
      "  [0.21501657]\n",
      "  [0.23609532]\n",
      "  [0.26442474]]]\n",
      "ejemplar: [0.19556016 0.18716338 0.19074029 0.19842322 0.19922183 0.21501657\n",
      " 0.23609532 0.26442474]\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.25525105]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[0.19556016 0.18716338 0.19074029 0.19842322 0.19922183 0.21501657\n",
      "  0.23609532 0.26442474]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002190680941566825\n",
      "Predicción post entrenamiento : [[0.25282544]]\n",
      "PERDIDAAAA despues: 0.0019695046357810497\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "[[[0.18716338]\n",
      "  [0.19074029]\n",
      "  [0.19842322]\n",
      "  [0.19922183]\n",
      "  [0.21501657]\n",
      "  [0.23609532]\n",
      "  [0.26442474]\n",
      "  [0.25525105]]]\n",
      "ejemplar: [0.18716338 0.19074029 0.19842322 0.19922183 0.21501657 0.23609532\n",
      " 0.26442474 0.25525105]\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.25470218]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[0.18716338 0.19074029 0.19842322 0.19922183 0.21501657 0.23609532\n",
      "  0.26442474 0.25525105]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018291720189154148\n",
      "Predicción post entrenamiento : [[0.2516815]]\n",
      "PERDIDAAAA despues: 0.0015799151733517647\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "[[[0.19074029]\n",
      "  [0.19842322]\n",
      "  [0.19922183]\n",
      "  [0.21501657]\n",
      "  [0.23609532]\n",
      "  [0.26442474]\n",
      "  [0.25525105]\n",
      "  [0.25470218]]]\n",
      "ejemplar: [0.19074029 0.19842322 0.19922183 0.21501657 0.23609532 0.26442474\n",
      " 0.25525105 0.25470218]\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.25687605]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[0.19074029 0.19842322 0.19922183 0.21501657 0.23609532 0.26442474\n",
      "  0.25525105 0.25470218]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002459371229633689\n",
      "Predicción post entrenamiento : [[0.25588077]]\n",
      "PERDIDAAAA despues: 0.002361645922064781\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "[[[0.19842322]\n",
      "  [0.19922183]\n",
      "  [0.21501657]\n",
      "  [0.23609532]\n",
      "  [0.26442474]\n",
      "  [0.25525105]\n",
      "  [0.25470218]\n",
      "  [0.25687605]]]\n",
      "ejemplar: [0.19842322 0.19922183 0.21501657 0.23609532 0.26442474 0.25525105\n",
      " 0.25470218 0.25687605]\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.2623719]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[0.19842322 0.19922183 0.21501657 0.23609532 0.26442474 0.25525105\n",
      "  0.25470218 0.25687605]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004819611553102732\n",
      "Predicción post entrenamiento : [[0.2609418]]\n",
      "PERDIDAAAA despues: 0.004623092710971832\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "[[[0.19922183]\n",
      "  [0.21501657]\n",
      "  [0.23609532]\n",
      "  [0.26442474]\n",
      "  [0.25525105]\n",
      "  [0.25470218]\n",
      "  [0.25687605]\n",
      "  [0.2623719 ]]]\n",
      "ejemplar: [0.19922183 0.21501657 0.23609532 0.26442474 0.25525105 0.25470218\n",
      " 0.25687605 0.2623719 ]\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.26793763]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[0.19922183 0.21501657 0.23609532 0.26442474 0.25525105 0.25470218\n",
      "  0.25687605 0.2623719 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005057299043983221\n",
      "Predicción post entrenamiento : [[0.26542267]]\n",
      "PERDIDAAAA despues: 0.004705923143774271\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "[[[0.21501657]\n",
      "  [0.23609532]\n",
      "  [0.26442474]\n",
      "  [0.25525105]\n",
      "  [0.25470218]\n",
      "  [0.25687605]\n",
      "  [0.2623719 ]\n",
      "  [0.26793763]]]\n",
      "ejemplar: [0.21501657 0.23609532 0.26442474 0.25525105 0.25470218 0.25687605\n",
      " 0.2623719  0.26793763]\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.27435654]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[0.21501657 0.23609532 0.26442474 0.25525105 0.25470218 0.25687605\n",
      "  0.2623719  0.26793763]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003611829597502947\n",
      "Predicción post entrenamiento : [[0.27140653]]\n",
      "PERDIDAAAA despues: 0.0032659494318068027\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "[[[0.23609532]\n",
      "  [0.26442474]\n",
      "  [0.25525105]\n",
      "  [0.25470218]\n",
      "  [0.25687605]\n",
      "  [0.2623719 ]\n",
      "  [0.26793763]\n",
      "  [0.27435654]]]\n",
      "ejemplar: [0.23609532 0.26442474 0.25525105 0.25470218 0.25687605 0.2623719\n",
      " 0.26793763 0.27435654]\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.27904013]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[0.23609532 0.26442474 0.25525105 0.25470218 0.25687605 0.2623719\n",
      "  0.26793763 0.27435654]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009548233821988106\n",
      "Predicción post entrenamiento : [[0.2755469]]\n",
      "PERDIDAAAA despues: 0.00887775607407093\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "[[[0.26442474]\n",
      "  [0.25525105]\n",
      "  [0.25470218]\n",
      "  [0.25687605]\n",
      "  [0.2623719 ]\n",
      "  [0.26793763]\n",
      "  [0.27435654]\n",
      "  [0.27904013]]]\n",
      "ejemplar: [0.26442474 0.25525105 0.25470218 0.25687605 0.2623719  0.26793763\n",
      " 0.27435654 0.27904013]\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.28024125]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[0.26442474 0.25525105 0.25470218 0.25687605 0.2623719  0.26793763\n",
      "  0.27435654 0.27904013]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011049231514334679\n",
      "Predicción post entrenamiento : [[0.27696943]]\n",
      "PERDIDAAAA despues: 0.010372099466621876\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "[[[0.25525105]\n",
      "  [0.25470218]\n",
      "  [0.25687605]\n",
      "  [0.2623719 ]\n",
      "  [0.26793763]\n",
      "  [0.27435654]\n",
      "  [0.27904013]\n",
      "  [0.28024125]]]\n",
      "ejemplar: [0.25525105 0.25470218 0.25687605 0.2623719  0.26793763 0.27435654\n",
      " 0.27904013 0.28024125]\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.27649125]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[0.25525105 0.25470218 0.25687605 0.2623719  0.26793763 0.27435654\n",
      "  0.27904013 0.28024125]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016508806496858597\n",
      "Predicción post entrenamiento : [[0.27074763]]\n",
      "PERDIDAAAA despues: 0.015065839514136314\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "[[[0.25470218]\n",
      "  [0.25687605]\n",
      "  [0.2623719 ]\n",
      "  [0.26793763]\n",
      "  [0.27435654]\n",
      "  [0.27904013]\n",
      "  [0.28024125]\n",
      "  [0.27649125]]]\n",
      "ejemplar: [0.25470218 0.25687605 0.2623719  0.26793763 0.27435654 0.27904013\n",
      " 0.28024125 0.27649125]\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.27264637]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[0.25470218 0.25687605 0.2623719  0.26793763 0.27435654 0.27904013\n",
      "  0.28024125 0.27649125]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012948894873261452\n",
      "Predicción post entrenamiento : [[0.2673404]]\n",
      "PERDIDAAAA despues: 0.01176948007196188\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "[[[0.25687605]\n",
      "  [0.2623719 ]\n",
      "  [0.26793763]\n",
      "  [0.27435654]\n",
      "  [0.27904013]\n",
      "  [0.28024125]\n",
      "  [0.27649125]\n",
      "  [0.27264637]]]\n",
      "ejemplar: [0.25687605 0.2623719  0.26793763 0.27435654 0.27904013 0.28024125\n",
      " 0.27649125 0.27264637]\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.27005944]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[0.25687605 0.2623719  0.26793763 0.27435654 0.27904013 0.28024125\n",
      "  0.27649125 0.27264637]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006066208239644766\n",
      "Predicción post entrenamiento : [[0.26761174]]\n",
      "PERDIDAAAA despues: 0.0056909178383648396\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "[[[0.2623719 ]\n",
      "  [0.26793763]\n",
      "  [0.27435654]\n",
      "  [0.27904013]\n",
      "  [0.28024125]\n",
      "  [0.27649125]\n",
      "  [0.27264637]\n",
      "  [0.27005944]]]\n",
      "ejemplar: [0.2623719  0.26793763 0.27435654 0.27904013 0.28024125 0.27649125\n",
      " 0.27264637 0.27005944]\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.2705666]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[0.2623719  0.26793763 0.27435654 0.27904013 0.28024125 0.27649125\n",
      "  0.27264637 0.27005944]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007155836559832096\n",
      "Predicción post entrenamiento : [[0.26789817]]\n",
      "PERDIDAAAA despues: 0.006711498834192753\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "[[[0.26793763]\n",
      "  [0.27435654]\n",
      "  [0.27904013]\n",
      "  [0.28024125]\n",
      "  [0.27649125]\n",
      "  [0.27264637]\n",
      "  [0.27005944]\n",
      "  [0.27056661]]]\n",
      "ejemplar: [0.26793763 0.27435654 0.27904013 0.28024125 0.27649125 0.27264637\n",
      " 0.27005944 0.27056661]\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.2702353]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[0.26793763 0.27435654 0.27904013 0.28024125 0.27649125 0.27264637\n",
      "  0.27005944 0.27056661]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.0788032341224607e-05\n",
      "Predicción post entrenamiento : [[0.26879284]]\n",
      "PERDIDAAAA despues: 3.3931546568055637e-06\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "[[[0.27435654]\n",
      "  [0.27904013]\n",
      "  [0.28024125]\n",
      "  [0.27649125]\n",
      "  [0.27264637]\n",
      "  [0.27005944]\n",
      "  [0.27056661]\n",
      "  [0.2702353 ]]]\n",
      "ejemplar: [0.27435654 0.27904013 0.28024125 0.27649125 0.27264637 0.27005944\n",
      " 0.27056661 0.2702353 ]\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.2702546]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[0.27435654 0.27904013 0.28024125 0.27649125 0.27264637 0.27005944\n",
      "  0.27056661 0.2702353 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004958491190336645\n",
      "Predicción post entrenamiento : [[0.27122837]]\n",
      "PERDIDAAAA despues: 0.00045343051897361875\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "[[[0.27904013]\n",
      "  [0.28024125]\n",
      "  [0.27649125]\n",
      "  [0.27264637]\n",
      "  [0.27005944]\n",
      "  [0.27056661]\n",
      "  [0.2702353 ]\n",
      "  [0.27025461]]]\n",
      "ejemplar: [0.27904013 0.28024125 0.27649125 0.27264637 0.27005944 0.27056661\n",
      " 0.2702353  0.27025461]\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.27138102]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[0.27904013 0.28024125 0.27649125 0.27264637 0.27005944 0.27056661\n",
      "  0.2702353  0.27025461]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0021460331045091152\n",
      "Predicción post entrenamiento : [[0.27185825]]\n",
      "PERDIDAAAA despues: 0.002102045575156808\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "[[[0.28024125]\n",
      "  [0.27649125]\n",
      "  [0.27264637]\n",
      "  [0.27005944]\n",
      "  [0.27056661]\n",
      "  [0.2702353 ]\n",
      "  [0.27025461]\n",
      "  [0.27138102]]]\n",
      "ejemplar: [0.28024125 0.27649125 0.27264637 0.27005944 0.27056661 0.2702353\n",
      " 0.27025461 0.27138102]\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.27083966]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[0.28024125 0.27649125 0.27264637 0.27005944 0.27056661 0.2702353\n",
      "  0.27025461 0.27138102]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017497367225587368\n",
      "Predicción post entrenamiento : [[0.27174246]]\n",
      "PERDIDAAAA despues: 0.0016750235809013247\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "[[[0.27649125]\n",
      "  [0.27264637]\n",
      "  [0.27005944]\n",
      "  [0.27056661]\n",
      "  [0.2702353 ]\n",
      "  [0.27025461]\n",
      "  [0.27138102]\n",
      "  [0.27083966]]]\n",
      "ejemplar: [0.27649125 0.27264637 0.27005944 0.27056661 0.2702353  0.27025461\n",
      " 0.27138102 0.27083966]\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.27016377]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[0.27649125 0.27264637 0.27005944 0.27056661 0.2702353  0.27025461\n",
      "  0.27138102 0.27083966]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003561329795047641\n",
      "Predicción post entrenamiento : [[0.26983002]]\n",
      "PERDIDAAAA despues: 0.0003688413416966796\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "[[[0.27264637]\n",
      "  [0.27005944]\n",
      "  [0.27056661]\n",
      "  [0.2702353 ]\n",
      "  [0.27025461]\n",
      "  [0.27138102]\n",
      "  [0.27083966]\n",
      "  [0.27016377]]]\n",
      "ejemplar: [0.27264637 0.27005944 0.27056661 0.2702353  0.27025461 0.27138102\n",
      " 0.27083966 0.27016377]\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.2687597]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[0.27264637 0.27005944 0.27056661 0.2702353  0.27025461 0.27138102\n",
      "  0.27083966 0.27016377]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001981453679036349\n",
      "Predicción post entrenamiento : [[0.2695143]]\n",
      "PERDIDAAAA despues: 0.00017747080710250884\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "[[[0.27005944]\n",
      "  [0.27056661]\n",
      "  [0.2702353 ]\n",
      "  [0.27025461]\n",
      "  [0.27138102]\n",
      "  [0.27083966]\n",
      "  [0.27016377]\n",
      "  [0.2687597 ]]]\n",
      "ejemplar: [0.27005944 0.27056661 0.2702353  0.27025461 0.27138102 0.27083966\n",
      " 0.27016377 0.2687597 ]\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.26909474]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[0.27005944 0.27056661 0.2702353  0.27025461 0.27138102 0.27083966\n",
      "  0.27016377 0.2687597 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000924256513826549\n",
      "Predicción post entrenamiento : [[0.2685293]]\n",
      "PERDIDAAAA despues: 0.000958956778049469\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "[[[0.27056661]\n",
      "  [0.2702353 ]\n",
      "  [0.27025461]\n",
      "  [0.27138102]\n",
      "  [0.27083966]\n",
      "  [0.27016377]\n",
      "  [0.2687597 ]\n",
      "  [0.26909474]]]\n",
      "ejemplar: [0.27056661 0.2702353  0.27025461 0.27138102 0.27083966 0.27016377\n",
      " 0.2687597  0.26909474]\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.26860106]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[0.27056661 0.2702353  0.27025461 0.27138102 0.27083966 0.27016377\n",
      "  0.2687597  0.26909474]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.2722236432600766e-05\n",
      "Predicción post entrenamiento : [[0.26878676]]\n",
      "PERDIDAAAA despues: 5.0060007197316736e-05\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "[[[0.2702353 ]\n",
      "  [0.27025461]\n",
      "  [0.27138102]\n",
      "  [0.27083966]\n",
      "  [0.27016377]\n",
      "  [0.2687597 ]\n",
      "  [0.26909474]\n",
      "  [0.26860106]]]\n",
      "ejemplar: [0.2702353  0.27025461 0.27138102 0.27083966 0.27016377 0.2687597\n",
      " 0.26909474 0.26860106]\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.2687329]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[0.2702353  0.27025461 0.27138102 0.27083966 0.27016377 0.2687597\n",
      "  0.26909474 0.26860106]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.56028504029382e-05\n",
      "Predicción post entrenamiento : [[0.26930648]]\n",
      "PERDIDAAAA despues: 2.9087004804750904e-05\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "[[[0.27025461]\n",
      "  [0.27138102]\n",
      "  [0.27083966]\n",
      "  [0.27016377]\n",
      "  [0.2687597 ]\n",
      "  [0.26909474]\n",
      "  [0.26860106]\n",
      "  [0.26873291]]]\n",
      "ejemplar: [0.27025461 0.27138102 0.27083966 0.27016377 0.2687597  0.26909474\n",
      " 0.26860106 0.26873291]\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.26928446]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[0.27025461 0.27138102 0.27083966 0.27016377 0.2687597  0.26909474\n",
      "  0.26860106 0.26873291]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.831796857411973e-05\n",
      "Predicción post entrenamiento : [[0.26988506]]\n",
      "PERDIDAAAA despues: 3.124300928902812e-05\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "[[[0.27138102]\n",
      "  [0.27083966]\n",
      "  [0.27016377]\n",
      "  [0.2687597 ]\n",
      "  [0.26909474]\n",
      "  [0.26860106]\n",
      "  [0.26873291]\n",
      "  [0.26928446]]]\n",
      "ejemplar: [0.27138102 0.27083966 0.27016377 0.2687597  0.26909474 0.26860106\n",
      " 0.26873291 0.26928446]\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.2698188]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[0.27138102 0.27083966 0.27016377 0.2687597  0.26909474 0.26860106\n",
      "  0.26873291 0.26928446]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0042165732011199\n",
      "Predicción post entrenamiento : [[0.27090898]]\n",
      "PERDIDAAAA despues: 0.004076181445270777\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "[[[0.27083966]\n",
      "  [0.27016377]\n",
      "  [0.2687597 ]\n",
      "  [0.26909474]\n",
      "  [0.26860106]\n",
      "  [0.26873291]\n",
      "  [0.26928446]\n",
      "  [0.26981881]]]\n",
      "ejemplar: [0.27083966 0.27016377 0.2687597  0.26909474 0.26860106 0.26873291\n",
      " 0.26928446 0.26981881]\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.27054888]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[0.27083966 0.27016377 0.2687597  0.26909474 0.26860106 0.26873291\n",
      "  0.26928446 0.26981881]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0072466409765183926\n",
      "Predicción post entrenamiento : [[0.2718198]]\n",
      "PERDIDAAAA despues: 0.007031876593828201\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "[[[0.27016377]\n",
      "  [0.2687597 ]\n",
      "  [0.26909474]\n",
      "  [0.26860106]\n",
      "  [0.26873291]\n",
      "  [0.26928446]\n",
      "  [0.26981881]\n",
      "  [0.27054888]]]\n",
      "ejemplar: [0.27016377 0.2687597  0.26909474 0.26860106 0.26873291 0.26928446\n",
      " 0.26981881 0.27054888]\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.27150843]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[0.27016377 0.2687597  0.26909474 0.26860106 0.26873291 0.26928446\n",
      "  0.26981881 0.27054888]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0042487941682338715\n",
      "Predicción post entrenamiento : [[0.27162197]]\n",
      "PERDIDAAAA despues: 0.00423400430008769\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "[[[0.2687597 ]\n",
      "  [0.26909474]\n",
      "  [0.26860106]\n",
      "  [0.26873291]\n",
      "  [0.26928446]\n",
      "  [0.26981881]\n",
      "  [0.27054888]\n",
      "  [0.27150843]]]\n",
      "ejemplar: [0.2687597  0.26909474 0.26860106 0.26873291 0.26928446 0.26981881\n",
      " 0.27054888 0.27150843]\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.27142444]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[0.2687597  0.26909474 0.26860106 0.26873291 0.26928446 0.26981881\n",
      "  0.27054888 0.27150843]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003864760510623455\n",
      "Predicción post entrenamiento : [[0.2727536]]\n",
      "PERDIDAAAA despues: 0.0037012675311416388\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "[[[0.26909474]\n",
      "  [0.26860106]\n",
      "  [0.26873291]\n",
      "  [0.26928446]\n",
      "  [0.26981881]\n",
      "  [0.27054888]\n",
      "  [0.27150843]\n",
      "  [0.27142444]]]\n",
      "ejemplar: [0.26909474 0.26860106 0.26873291 0.26928446 0.26981881 0.27054888\n",
      " 0.27150843 0.27142444]\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.27287352]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[0.26909474 0.26860106 0.26873291 0.26928446 0.26981881 0.27054888\n",
      "  0.27150843 0.27142444]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012512900866568089\n",
      "Predicción post entrenamiento : [[0.27447578]]\n",
      "PERDIDAAAA despues: 0.012157007120549679\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "[[[0.26860106]\n",
      "  [0.26873291]\n",
      "  [0.26928446]\n",
      "  [0.26981881]\n",
      "  [0.27054888]\n",
      "  [0.27150843]\n",
      "  [0.27142444]\n",
      "  [0.27287352]]]\n",
      "ejemplar: [0.26860106 0.26873291 0.26928446 0.26981881 0.27054888 0.27150843\n",
      " 0.27142444 0.27287352]\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.27459422]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[0.26860106 0.26873291 0.26928446 0.26981881 0.27054888 0.27150843\n",
      "  0.27142444 0.27287352]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08791359513998032\n",
      "Predicción post entrenamiento : [[0.2785843]]\n",
      "PERDIDAAAA despues: 0.08556337654590607\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "[[[0.26873291]\n",
      "  [0.26928446]\n",
      "  [0.26981881]\n",
      "  [0.27054888]\n",
      "  [0.27150843]\n",
      "  [0.27142444]\n",
      "  [0.27287352]\n",
      "  [0.27459422]]]\n",
      "ejemplar: [0.26873291 0.26928446 0.26981881 0.27054888 0.27150843 0.27142444\n",
      " 0.27287352 0.27459422]\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.2789056]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[0.26873291 0.26928446 0.26981881 0.27054888 0.27150843 0.27142444\n",
      "  0.27287352 0.27459422]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10072683542966843\n",
      "Predicción post entrenamiento : [[0.28287515]]\n",
      "PERDIDAAAA despues: 0.09822292625904083\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "[[[0.26928446]\n",
      "  [0.26981881]\n",
      "  [0.27054888]\n",
      "  [0.27150843]\n",
      "  [0.27142444]\n",
      "  [0.27287352]\n",
      "  [0.27459422]\n",
      "  [0.2789056 ]]]\n",
      "ejemplar: [0.26928446 0.26981881 0.27054888 0.27150843 0.27142444 0.27287352\n",
      " 0.27459422 0.2789056 ]\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.28332472]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[0.26928446 0.26981881 0.27054888 0.27150843 0.27142444 0.27287352\n",
      "  0.27459422 0.2789056 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08483166247606277\n",
      "Predicción post entrenamiento : [[0.28707474]]\n",
      "PERDIDAAAA despues: 0.08266127109527588\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "[[[0.26981881]\n",
      "  [0.27054888]\n",
      "  [0.27150843]\n",
      "  [0.27142444]\n",
      "  [0.27287352]\n",
      "  [0.27459422]\n",
      "  [0.2789056 ]\n",
      "  [0.28332472]]]\n",
      "ejemplar: [0.26981881 0.27054888 0.27150843 0.27142444 0.27287352 0.27459422\n",
      " 0.2789056  0.28332472]\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.28762713]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[0.26981881 0.27054888 0.27150843 0.27142444 0.27287352 0.27459422\n",
      "  0.2789056  0.28332472]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10158689320087433\n",
      "Predicción post entrenamiento : [[0.29164046]]\n",
      "PERDIDAAAA despues: 0.09904468804597855\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "[[[0.27054888]\n",
      "  [0.27150843]\n",
      "  [0.27142444]\n",
      "  [0.27287352]\n",
      "  [0.27459422]\n",
      "  [0.2789056 ]\n",
      "  [0.28332472]\n",
      "  [0.28762713]]]\n",
      "ejemplar: [0.27054888 0.27150843 0.27142444 0.27287352 0.27459422 0.2789056\n",
      " 0.28332472 0.28762713]\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.29237956]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[0.27054888 0.27150843 0.27142444 0.27287352 0.27459422 0.2789056\n",
      "  0.28332472 0.28762713]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08542618155479431\n",
      "Predicción post entrenamiento : [[0.29600322]]\n",
      "PERDIDAAAA despues: 0.08332107961177826\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "[[[0.27150843]\n",
      "  [0.27142444]\n",
      "  [0.27287352]\n",
      "  [0.27459422]\n",
      "  [0.2789056 ]\n",
      "  [0.28332472]\n",
      "  [0.28762713]\n",
      "  [0.29237956]]]\n",
      "ejemplar: [0.27150843 0.27142444 0.27287352 0.27459422 0.2789056  0.28332472\n",
      " 0.28762713 0.29237956]\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.2969901]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[0.27150843 0.27142444 0.27287352 0.27459422 0.2789056  0.28332472\n",
      "  0.28762713 0.29237956]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07386527955532074\n",
      "Predicción post entrenamiento : [[0.3001429]]\n",
      "PERDIDAAAA despues: 0.072161465883255\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "[[[0.27142444]\n",
      "  [0.27287352]\n",
      "  [0.27459422]\n",
      "  [0.2789056 ]\n",
      "  [0.28332472]\n",
      "  [0.28762713]\n",
      "  [0.29237956]\n",
      "  [0.2969901 ]]]\n",
      "ejemplar: [0.27142444 0.27287352 0.27459422 0.2789056  0.28332472 0.28762713\n",
      " 0.29237956 0.2969901 ]\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.30144417]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[0.27142444 0.27287352 0.27459422 0.2789056  0.28332472 0.28762713\n",
      "  0.29237956 0.2969901 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11650612205266953\n",
      "Predicción post entrenamiento : [[0.30561805]]\n",
      "PERDIDAAAA despues: 0.11367420852184296\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "[[[0.27287352]\n",
      "  [0.27459422]\n",
      "  [0.2789056 ]\n",
      "  [0.28332472]\n",
      "  [0.28762713]\n",
      "  [0.29237956]\n",
      "  [0.2969901 ]\n",
      "  [0.30144417]]]\n",
      "ejemplar: [0.27287352 0.27459422 0.2789056  0.28332472 0.28762713 0.29237956\n",
      " 0.2969901  0.30144417]\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.30759627]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[0.27287352 0.27459422 0.2789056  0.28332472 0.28762713 0.29237956\n",
      "  0.2969901  0.30144417]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12543125450611115\n",
      "Predicción post entrenamiento : [[0.31162223]]\n",
      "PERDIDAAAA despues: 0.12259577214717865\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "[[[0.27459422]\n",
      "  [0.2789056 ]\n",
      "  [0.28332472]\n",
      "  [0.28762713]\n",
      "  [0.29237956]\n",
      "  [0.2969901 ]\n",
      "  [0.30144417]\n",
      "  [0.30759627]]]\n",
      "ejemplar: [0.27459422 0.2789056  0.28332472 0.28762713 0.29237956 0.2969901\n",
      " 0.30144417 0.30759627]\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.3141024]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[0.27459422 0.2789056  0.28332472 0.28762713 0.29237956 0.2969901\n",
      "  0.30144417 0.30759627]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12880386412143707\n",
      "Predicción post entrenamiento : [[0.31816682]]\n",
      "PERDIDAAAA despues: 0.12590301036834717\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "[[[0.2789056 ]\n",
      "  [0.28332472]\n",
      "  [0.28762713]\n",
      "  [0.29237956]\n",
      "  [0.2969901 ]\n",
      "  [0.30144417]\n",
      "  [0.30759627]\n",
      "  [0.31410241]]]\n",
      "ejemplar: [0.2789056  0.28332472 0.28762713 0.29237956 0.2969901  0.30144417\n",
      " 0.30759627 0.31410241]\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.32122082]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[0.2789056  0.28332472 0.28762713 0.29237956 0.2969901  0.30144417\n",
      "  0.30759627 0.31410241]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1515984833240509\n",
      "Predicción post entrenamiento : [[0.32551676]]\n",
      "PERDIDAAAA despues: 0.1482716202735901\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "[[[0.28332472]\n",
      "  [0.28762713]\n",
      "  [0.29237956]\n",
      "  [0.2969901 ]\n",
      "  [0.30144417]\n",
      "  [0.30759627]\n",
      "  [0.31410241]\n",
      "  [0.32122082]]]\n",
      "ejemplar: [0.28332472 0.28762713 0.29237956 0.2969901  0.30144417 0.30759627\n",
      " 0.31410241 0.32122082]\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.32868877]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[0.28332472 0.28762713 0.29237956 0.2969901  0.30144417 0.30759627\n",
      "  0.31410241 0.32122082]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14085154235363007\n",
      "Predicción post entrenamiento : [[0.33296254]]\n",
      "PERDIDAAAA despues: 0.1376618891954422\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "[[[0.28762713]\n",
      "  [0.29237956]\n",
      "  [0.2969901 ]\n",
      "  [0.30144417]\n",
      "  [0.30759627]\n",
      "  [0.31410241]\n",
      "  [0.32122082]\n",
      "  [0.32868877]]]\n",
      "ejemplar: [0.28762713 0.29237956 0.2969901  0.30144417 0.30759627 0.31410241\n",
      " 0.32122082 0.32868877]\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.33629265]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[0.28762713 0.29237956 0.2969901  0.30144417 0.30759627 0.31410241\n",
      "  0.32122082 0.32868877]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.15283788740634918\n",
      "Predicción post entrenamiento : [[0.34045932]]\n",
      "PERDIDAAAA despues: 0.1495973765850067\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "[[[0.29237956]\n",
      "  [0.2969901 ]\n",
      "  [0.30144417]\n",
      "  [0.30759627]\n",
      "  [0.31410241]\n",
      "  [0.32122082]\n",
      "  [0.32868877]\n",
      "  [0.33629265]]]\n",
      "ejemplar: [0.29237956 0.2969901  0.30144417 0.30759627 0.31410241 0.32122082\n",
      " 0.32868877 0.33629265]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.34405595]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[0.29237956 0.2969901  0.30144417 0.30759627 0.31410241 0.32122082\n",
      "  0.32868877 0.33629265]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1432866007089615\n",
      "Predicción post entrenamiento : [[0.34785205]]\n",
      "PERDIDAAAA despues: 0.1404271274805069\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "[[[0.2969901 ]\n",
      "  [0.30144417]\n",
      "  [0.30759627]\n",
      "  [0.31410241]\n",
      "  [0.32122082]\n",
      "  [0.32868877]\n",
      "  [0.33629265]\n",
      "  [0.34405595]]]\n",
      "ejemplar: [0.2969901  0.30144417 0.30759627 0.31410241 0.32122082 0.32868877\n",
      " 0.33629265 0.34405595]\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.3517126]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[0.2969901  0.30144417 0.30759627 0.31410241 0.32122082 0.32868877\n",
      "  0.33629265 0.34405595]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.17646828293800354\n",
      "Predicción post entrenamiento : [[0.35592467]]\n",
      "PERDIDAAAA despues: 0.1729472279548645\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "[[[0.30144417]\n",
      "  [0.30759627]\n",
      "  [0.31410241]\n",
      "  [0.32122082]\n",
      "  [0.32868877]\n",
      "  [0.33629265]\n",
      "  [0.34405595]\n",
      "  [0.35171261]]]\n",
      "ejemplar: [0.30144417 0.30759627 0.31410241 0.32122082 0.32868877 0.33629265\n",
      " 0.34405595 0.35171261]\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.36018232]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[0.30144417 0.30759627 0.31410241 0.32122082 0.32868877 0.33629265\n",
      "  0.34405595 0.35171261]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1327458769083023\n",
      "Predicción post entrenamiento : [[0.3639253]]\n",
      "PERDIDAAAA despues: 0.13003242015838623\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "[[[0.30759627]\n",
      "  [0.31410241]\n",
      "  [0.32122082]\n",
      "  [0.32868877]\n",
      "  [0.33629265]\n",
      "  [0.34405595]\n",
      "  [0.35171261]\n",
      "  [0.36018232]]]\n",
      "ejemplar: [0.30759627 0.31410241 0.32122082 0.32868877 0.33629265 0.34405595\n",
      " 0.35171261 0.36018232]\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.36873254]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[0.30759627 0.31410241 0.32122082 0.32868877 0.33629265 0.34405595\n",
      "  0.35171261 0.36018232]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09140050411224365\n",
      "Predicción post entrenamiento : [[0.37182164]]\n",
      "PERDIDAAAA despues: 0.0895422175526619\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "[[[0.31410241]\n",
      "  [0.32122082]\n",
      "  [0.32868877]\n",
      "  [0.33629265]\n",
      "  [0.34405595]\n",
      "  [0.35171261]\n",
      "  [0.36018232]\n",
      "  [0.36873254]]]\n",
      "ejemplar: [0.31410241 0.32122082 0.32868877 0.33629265 0.34405595 0.35171261\n",
      " 0.36018232 0.36873254]\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.37690553]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[0.31410241 0.32122082 0.32868877 0.33629265 0.34405595 0.35171261\n",
      "  0.36018232 0.36873254]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08812841027975082\n",
      "Predicción post entrenamiento : [[0.37957972]]\n",
      "PERDIDAAAA despues: 0.08654782176017761\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "[[[0.32122082]\n",
      "  [0.32868877]\n",
      "  [0.33629265]\n",
      "  [0.34405595]\n",
      "  [0.35171261]\n",
      "  [0.36018232]\n",
      "  [0.36873254]\n",
      "  [0.37690553]]]\n",
      "ejemplar: [0.32122082 0.32868877 0.33629265 0.34405595 0.35171261 0.36018232\n",
      " 0.36873254 0.37690553]\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.38492846]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[0.32122082 0.32868877 0.33629265 0.34405595 0.35171261 0.36018232\n",
      "  0.36873254 0.37690553]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10858561843633652\n",
      "Predicción post entrenamiento : [[0.38815796]]\n",
      "PERDIDAAAA despues: 0.10646766424179077\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "[[[0.32868877]\n",
      "  [0.33629265]\n",
      "  [0.34405595]\n",
      "  [0.35171261]\n",
      "  [0.36018232]\n",
      "  [0.36873254]\n",
      "  [0.37690553]\n",
      "  [0.38492846]]]\n",
      "ejemplar: [0.32868877 0.33629265 0.34405595 0.35171261 0.36018232 0.36873254\n",
      " 0.37690553 0.38492846]\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.39368957]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[0.32868877 0.33629265 0.34405595 0.35171261 0.36018232 0.36873254\n",
      "  0.37690553 0.38492846]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12264575809240341\n",
      "Predicción post entrenamiento : [[0.39710888]]\n",
      "PERDIDAAAA despues: 0.120262511074543\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "[[[0.33629265]\n",
      "  [0.34405595]\n",
      "  [0.35171261]\n",
      "  [0.36018232]\n",
      "  [0.36873254]\n",
      "  [0.37690553]\n",
      "  [0.38492846]\n",
      "  [0.39368957]]]\n",
      "ejemplar: [0.33629265 0.34405595 0.35171261 0.36018232 0.36873254 0.37690553\n",
      " 0.38492846 0.39368957]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.40278426]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[0.33629265 0.34405595 0.35171261 0.36018232 0.36873254 0.37690553\n",
      "  0.38492846 0.39368957]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10227451473474503\n",
      "Predicción post entrenamiento : [[0.40548703]]\n",
      "PERDIDAAAA despues: 0.10055310279130936\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "[[[0.34405595]\n",
      "  [0.35171261]\n",
      "  [0.36018232]\n",
      "  [0.36873254]\n",
      "  [0.37690553]\n",
      "  [0.38492846]\n",
      "  [0.39368957]\n",
      "  [0.40278426]]]\n",
      "ejemplar: [0.34405595 0.35171261 0.36018232 0.36873254 0.37690553 0.38492846\n",
      " 0.39368957 0.40278426]\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.41130957]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[0.34405595 0.35171261 0.36018232 0.36873254 0.37690553 0.38492846\n",
      "  0.39368957 0.40278426]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08296231180429459\n",
      "Predicción post entrenamiento : [[0.41412684]]\n",
      "PERDIDAAAA despues: 0.08134731650352478\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "[[[0.35171261]\n",
      "  [0.36018232]\n",
      "  [0.36873254]\n",
      "  [0.37690553]\n",
      "  [0.38492846]\n",
      "  [0.39368957]\n",
      "  [0.40278426]\n",
      "  [0.41130957]]]\n",
      "ejemplar: [0.35171261 0.36018232 0.36873254 0.37690553 0.38492846 0.39368957\n",
      " 0.40278426 0.41130957]\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.42009416]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[0.35171261 0.36018232 0.36873254 0.37690553 0.38492846 0.39368957\n",
      "  0.40278426 0.41130957]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10062660276889801\n",
      "Predicción post entrenamiento : [[0.42299968]]\n",
      "PERDIDAAAA despues: 0.0987916812300682\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "[[[0.36018232]\n",
      "  [0.36873254]\n",
      "  [0.37690553]\n",
      "  [0.38492846]\n",
      "  [0.39368957]\n",
      "  [0.40278426]\n",
      "  [0.41130957]\n",
      "  [0.42009416]]]\n",
      "ejemplar: [0.36018232 0.36873254 0.37690553 0.38492846 0.39368957 0.40278426\n",
      " 0.41130957 0.42009416]\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.42917243]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[0.36018232 0.36873254 0.37690553 0.38492846 0.39368957 0.40278426\n",
      "  0.41130957 0.42009416]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08541205525398254\n",
      "Predicción post entrenamiento : [[0.43192154]]\n",
      "PERDIDAAAA despues: 0.08381273597478867\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "[[[0.36873254]\n",
      "  [0.37690553]\n",
      "  [0.38492846]\n",
      "  [0.39368957]\n",
      "  [0.40278426]\n",
      "  [0.41130957]\n",
      "  [0.42009416]\n",
      "  [0.42917243]]]\n",
      "ejemplar: [0.36873254 0.37690553 0.38492846 0.39368957 0.40278426 0.41130957\n",
      " 0.42009416 0.42917243]\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.4381406]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[0.36873254 0.37690553 0.38492846 0.39368957 0.40278426 0.41130957\n",
      "  0.42009416 0.42917243]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07872126251459122\n",
      "Predicción post entrenamiento : [[0.44088402]]\n",
      "PERDIDAAAA despues: 0.07718932628631592\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "[[[0.37690553]\n",
      "  [0.38492846]\n",
      "  [0.39368957]\n",
      "  [0.40278426]\n",
      "  [0.41130957]\n",
      "  [0.42009416]\n",
      "  [0.42917243]\n",
      "  [0.4381406 ]]]\n",
      "ejemplar: [0.37690553 0.38492846 0.39368957 0.40278426 0.41130957 0.42009416\n",
      " 0.42917243 0.4381406 ]\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.44714305]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[0.37690553 0.38492846 0.39368957 0.40278426 0.41130957 0.42009416\n",
      "  0.42917243 0.4381406 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.051535479724407196\n",
      "Predicción post entrenamiento : [[0.44922203]]\n",
      "PERDIDAAAA despues: 0.05059588700532913\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "[[[0.38492846]\n",
      "  [0.39368957]\n",
      "  [0.40278426]\n",
      "  [0.41130957]\n",
      "  [0.42009416]\n",
      "  [0.42917243]\n",
      "  [0.4381406 ]\n",
      "  [0.44714305]]]\n",
      "ejemplar: [0.38492846 0.39368957 0.40278426 0.41130957 0.42009416 0.42917243\n",
      " 0.4381406  0.44714305]\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.45562696]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[0.38492846 0.39368957 0.40278426 0.41130957 0.42009416 0.42917243\n",
      "  0.4381406  0.44714305]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05901958793401718\n",
      "Predicción post entrenamiento : [[0.4579033]]\n",
      "PERDIDAAAA despues: 0.057918746024370193\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "[[[0.39368957]\n",
      "  [0.40278426]\n",
      "  [0.41130957]\n",
      "  [0.42009416]\n",
      "  [0.42917243]\n",
      "  [0.4381406 ]\n",
      "  [0.44714305]\n",
      "  [0.45562696]]]\n",
      "ejemplar: [0.39368957 0.40278426 0.41130957 0.42009416 0.42917243 0.4381406\n",
      " 0.44714305 0.45562696]\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.46452096]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[0.39368957 0.40278426 0.41130957 0.42009416 0.42917243 0.4381406\n",
      "  0.44714305 0.45562696]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06580116599798203\n",
      "Predicción post entrenamiento : [[0.4666383]]\n",
      "PERDIDAAAA despues: 0.06471938639879227\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "[[[0.40278426]\n",
      "  [0.41130957]\n",
      "  [0.42009416]\n",
      "  [0.42917243]\n",
      "  [0.4381406 ]\n",
      "  [0.44714305]\n",
      "  [0.45562696]\n",
      "  [0.46452096]]]\n",
      "ejemplar: [0.40278426 0.41130957 0.42009416 0.42917243 0.4381406  0.44714305\n",
      " 0.45562696 0.46452096]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.4733155]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[0.40278426 0.41130957 0.42009416 0.42917243 0.4381406  0.44714305\n",
      "  0.45562696 0.46452096]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06213683634996414\n",
      "Predicción post entrenamiento : [[0.47520626]]\n",
      "PERDIDAAAA despues: 0.06119778752326965\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "[[[0.41130957]\n",
      "  [0.42009416]\n",
      "  [0.42917243]\n",
      "  [0.4381406 ]\n",
      "  [0.44714305]\n",
      "  [0.45562696]\n",
      "  [0.46452096]\n",
      "  [0.47331551]]]\n",
      "ejemplar: [0.41130957 0.42009416 0.42917243 0.4381406  0.44714305 0.45562696\n",
      " 0.46452096 0.47331551]\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.4818617]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[0.41130957 0.42009416 0.42917243 0.4381406  0.44714305 0.45562696\n",
      "  0.46452096 0.47331551]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07531420141458511\n",
      "Predicción post entrenamiento : [[0.48411343]]\n",
      "PERDIDAAAA despues: 0.0740833729505539\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "[[[0.42009416]\n",
      "  [0.42917243]\n",
      "  [0.4381406 ]\n",
      "  [0.44714305]\n",
      "  [0.45562696]\n",
      "  [0.46452096]\n",
      "  [0.47331551]\n",
      "  [0.48186171]]]\n",
      "ejemplar: [0.42009416 0.42917243 0.4381406  0.44714305 0.45562696 0.46452096\n",
      " 0.47331551 0.48186171]\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.49088007]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[0.42009416 0.42917243 0.4381406  0.44714305 0.45562696 0.46452096\n",
      "  0.47331551 0.48186171]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11337103694677353\n",
      "Predicción post entrenamiento : [[0.49380803]]\n",
      "PERDIDAAAA despues: 0.11140789091587067\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "[[[0.42917243]\n",
      "  [0.4381406 ]\n",
      "  [0.44714305]\n",
      "  [0.45562696]\n",
      "  [0.46452096]\n",
      "  [0.47331551]\n",
      "  [0.48186171]\n",
      "  [0.49088007]]]\n",
      "ejemplar: [0.42917243 0.4381406  0.44714305 0.45562696 0.46452096 0.47331551\n",
      " 0.48186171 0.49088007]\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.5006315]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[0.42917243 0.4381406  0.44714305 0.45562696 0.46452096 0.47331551\n",
      "  0.48186171 0.49088007]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11437293142080307\n",
      "Predicción post entrenamiento : [[0.5032822]]\n",
      "PERDIDAAAA despues: 0.1125870868563652\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "[[[0.4381406 ]\n",
      "  [0.44714305]\n",
      "  [0.45562696]\n",
      "  [0.46452096]\n",
      "  [0.47331551]\n",
      "  [0.48186171]\n",
      "  [0.49088007]\n",
      "  [0.50063151]]]\n",
      "ejemplar: [0.4381406  0.44714305 0.45562696 0.46452096 0.47331551 0.48186171\n",
      " 0.49088007 0.50063151]\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.5100912]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[0.4381406  0.44714305 0.45562696 0.46452096 0.47331551 0.48186171\n",
      "  0.49088007 0.50063151]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08075521886348724\n",
      "Predicción post entrenamiento : [[0.5124356]]\n",
      "PERDIDAAAA despues: 0.07942825555801392\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "[[[0.44714305]\n",
      "  [0.45562696]\n",
      "  [0.46452096]\n",
      "  [0.47331551]\n",
      "  [0.48186171]\n",
      "  [0.49088007]\n",
      "  [0.50063151]\n",
      "  [0.51009119]]]\n",
      "ejemplar: [0.44714305 0.45562696 0.46452096 0.47331551 0.48186171 0.49088007\n",
      " 0.50063151 0.51009119]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.5192558]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[0.44714305 0.45562696 0.46452096 0.47331551 0.48186171 0.49088007\n",
      "  0.50063151 0.51009119]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06998611986637115\n",
      "Predicción post entrenamiento : [[0.5218618]]\n",
      "PERDIDAAAA despues: 0.06861409544944763\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "[[[0.45562696]\n",
      "  [0.46452096]\n",
      "  [0.47331551]\n",
      "  [0.48186171]\n",
      "  [0.49088007]\n",
      "  [0.50063151]\n",
      "  [0.51009119]\n",
      "  [0.51925582]]]\n",
      "ejemplar: [0.45562696 0.46452096 0.47331551 0.48186171 0.49088007 0.50063151\n",
      " 0.51009119 0.51925582]\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.52869284]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[0.45562696 0.46452096 0.47331551 0.48186171 0.49088007 0.50063151\n",
      "  0.51009119 0.51925582]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05722935497760773\n",
      "Predicción post entrenamiento : [[0.5304728]]\n",
      "PERDIDAAAA despues: 0.05638089030981064\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "[[[0.46452096]\n",
      "  [0.47331551]\n",
      "  [0.48186171]\n",
      "  [0.49088007]\n",
      "  [0.50063151]\n",
      "  [0.51009119]\n",
      "  [0.51925582]\n",
      "  [0.52869284]]]\n",
      "ejemplar: [0.46452096 0.47331551 0.48186171 0.49088007 0.50063151 0.51009119\n",
      " 0.51925582 0.52869284]\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.5374589]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[0.46452096 0.47331551 0.48186171 0.49088007 0.50063151 0.51009119\n",
      "  0.51925582 0.52869284]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06106865778565407\n",
      "Predicción post entrenamiento : [[0.53966236]]\n",
      "PERDIDAAAA despues: 0.0599844716489315\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "[[[0.47331551]\n",
      "  [0.48186171]\n",
      "  [0.49088007]\n",
      "  [0.50063151]\n",
      "  [0.51009119]\n",
      "  [0.51925582]\n",
      "  [0.52869284]\n",
      "  [0.5374589 ]]]\n",
      "ejemplar: [0.47331551 0.48186171 0.49088007 0.50063151 0.51009119 0.51925582\n",
      " 0.52869284 0.5374589 ]\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.5467302]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[0.47331551 0.48186171 0.49088007 0.50063151 0.51009119 0.51925582\n",
      "  0.52869284 0.5374589 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11022330075502396\n",
      "Predicción post entrenamiento : [[0.5496299]]\n",
      "PERDIDAAAA despues: 0.10830631107091904\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "[[[0.48186171]\n",
      "  [0.49088007]\n",
      "  [0.50063151]\n",
      "  [0.51009119]\n",
      "  [0.51925582]\n",
      "  [0.52869284]\n",
      "  [0.5374589 ]\n",
      "  [0.54673022]]]\n",
      "ejemplar: [0.48186171 0.49088007 0.50063151 0.51009119 0.51925582 0.52869284\n",
      " 0.5374589  0.54673022]\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.55682325]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[0.48186171 0.49088007 0.50063151 0.51009119 0.51925582 0.52869284\n",
      "  0.5374589  0.54673022]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10163749009370804\n",
      "Predicción post entrenamiento : [[0.5591086]]\n",
      "PERDIDAAAA despues: 0.10018553584814072\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "[[[0.49088007]\n",
      "  [0.50063151]\n",
      "  [0.51009119]\n",
      "  [0.51925582]\n",
      "  [0.52869284]\n",
      "  [0.5374589 ]\n",
      "  [0.54673022]\n",
      "  [0.55682325]]]\n",
      "ejemplar: [0.49088007 0.50063151 0.51009119 0.51925582 0.52869284 0.5374589\n",
      " 0.54673022 0.55682325]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.5665141]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[0.49088007 0.50063151 0.51009119 0.51925582 0.52869284 0.5374589\n",
      "  0.54673022 0.55682325]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07973942905664444\n",
      "Predicción post entrenamiento : [[0.56874937]]\n",
      "PERDIDAAAA despues: 0.0784820169210434\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "[[[0.50063151]\n",
      "  [0.51009119]\n",
      "  [0.51925582]\n",
      "  [0.52869284]\n",
      "  [0.5374589 ]\n",
      "  [0.54673022]\n",
      "  [0.55682325]\n",
      "  [0.56651407]]]\n",
      "ejemplar: [0.50063151 0.51009119 0.51925582 0.52869284 0.5374589  0.54673022\n",
      " 0.55682325 0.56651407]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.5762769]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[0.50063151 0.51009119 0.51925582 0.52869284 0.5374589  0.54673022\n",
      "  0.55682325 0.56651407]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05856912583112717\n",
      "Predicción post entrenamiento : [[0.57798]]\n",
      "PERDIDAAAA despues: 0.057747699320316315\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "[[[0.51009119]\n",
      "  [0.51925582]\n",
      "  [0.52869284]\n",
      "  [0.5374589 ]\n",
      "  [0.54673022]\n",
      "  [0.55682325]\n",
      "  [0.56651407]\n",
      "  [0.5762769 ]]]\n",
      "ejemplar: [0.51009119 0.51925582 0.52869284 0.5374589  0.54673022 0.55682325\n",
      " 0.56651407 0.5762769 ]\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.58545256]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[0.51009119 0.51925582 0.52869284 0.5374589  0.54673022 0.55682325\n",
      "  0.56651407 0.5762769 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.058254048228263855\n",
      "Predicción post entrenamiento : [[0.58686703]]\n",
      "PERDIDAAAA despues: 0.05757325887680054\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "[[[0.51925582]\n",
      "  [0.52869284]\n",
      "  [0.5374589 ]\n",
      "  [0.54673022]\n",
      "  [0.55682325]\n",
      "  [0.56651407]\n",
      "  [0.5762769 ]\n",
      "  [0.58545256]]]\n",
      "ejemplar: [0.51925582 0.52869284 0.5374589  0.54673022 0.55682325 0.56651407\n",
      " 0.5762769  0.58545256]\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.5943532]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[0.51925582 0.52869284 0.5374589  0.54673022 0.55682325 0.56651407\n",
      "  0.5762769  0.58545256]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03648149594664574\n",
      "Predicción post entrenamiento : [[0.5957476]]\n",
      "PERDIDAAAA despues: 0.03595077991485596\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "[[[0.52869284]\n",
      "  [0.5374589 ]\n",
      "  [0.54673022]\n",
      "  [0.55682325]\n",
      "  [0.56651407]\n",
      "  [0.5762769 ]\n",
      "  [0.58545256]\n",
      "  [0.5943532 ]]]\n",
      "ejemplar: [0.52869284 0.5374589  0.54673022 0.55682325 0.56651407 0.5762769\n",
      " 0.58545256 0.5943532 ]\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.6033276]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[0.52869284 0.5374589  0.54673022 0.55682325 0.56651407 0.5762769\n",
      "  0.58545256 0.5943532 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.034559331834316254\n",
      "Predicción post entrenamiento : [[0.60448706]]\n",
      "PERDIDAAAA despues: 0.03412957489490509\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "[[[0.5374589 ]\n",
      "  [0.54673022]\n",
      "  [0.55682325]\n",
      "  [0.56651407]\n",
      "  [0.5762769 ]\n",
      "  [0.58545256]\n",
      "  [0.5943532 ]\n",
      "  [0.60332757]]]\n",
      "ejemplar: [0.5374589  0.54673022 0.55682325 0.56651407 0.5762769  0.58545256\n",
      " 0.5943532  0.60332757]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.6120962]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[0.5374589  0.54673022 0.55682325 0.56651407 0.5762769  0.58545256\n",
      "  0.5943532  0.60332757]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.049318015575408936\n",
      "Predicción post entrenamiento : [[0.6139756]]\n",
      "PERDIDAAAA despues: 0.04848680645227432\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "[[[0.54673022]\n",
      "  [0.55682325]\n",
      "  [0.56651407]\n",
      "  [0.5762769 ]\n",
      "  [0.58545256]\n",
      "  [0.5943532 ]\n",
      "  [0.60332757]\n",
      "  [0.61209619]]]\n",
      "ejemplar: [0.54673022 0.55682325 0.56651407 0.5762769  0.58545256 0.5943532\n",
      " 0.60332757 0.61209619]\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.6217886]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[0.54673022 0.55682325 0.56651407 0.5762769  0.58545256 0.5943532\n",
      "  0.60332757 0.61209619]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03636160120368004\n",
      "Predicción post entrenamiento : [[0.6229061]]\n",
      "PERDIDAAAA despues: 0.03593667596578598\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "[[[0.55682325]\n",
      "  [0.56651407]\n",
      "  [0.5762769 ]\n",
      "  [0.58545256]\n",
      "  [0.5943532 ]\n",
      "  [0.60332757]\n",
      "  [0.61209619]\n",
      "  [0.62178862]]]\n",
      "ejemplar: [0.55682325 0.56651407 0.5762769  0.58545256 0.5943532  0.60332757\n",
      " 0.61209619 0.62178862]\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.63079786]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[0.55682325 0.56651407 0.5762769  0.58545256 0.5943532  0.60332757\n",
      "  0.61209619 0.62178862]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.029050469398498535\n",
      "Predicción post entrenamiento : [[0.63297415]]\n",
      "PERDIDAAAA despues: 0.028313346207141876\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "[[[0.56651407]\n",
      "  [0.5762769 ]\n",
      "  [0.58545256]\n",
      "  [0.5943532 ]\n",
      "  [0.60332757]\n",
      "  [0.61209619]\n",
      "  [0.62178862]\n",
      "  [0.63079786]]]\n",
      "ejemplar: [0.56651407 0.5762769  0.58545256 0.5943532  0.60332757 0.61209619\n",
      " 0.62178862 0.63079786]\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.64071476]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[0.56651407 0.5762769  0.58545256 0.5943532  0.60332757 0.61209619\n",
      "  0.62178862 0.63079786]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02639399655163288\n",
      "Predicción post entrenamiento : [[0.6420126]]\n",
      "PERDIDAAAA despues: 0.025973983108997345\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "[[[0.5762769 ]\n",
      "  [0.58545256]\n",
      "  [0.5943532 ]\n",
      "  [0.60332757]\n",
      "  [0.61209619]\n",
      "  [0.62178862]\n",
      "  [0.63079786]\n",
      "  [0.64071476]]]\n",
      "ejemplar: [0.5762769  0.58545256 0.5943532  0.60332757 0.61209619 0.62178862\n",
      " 0.63079786 0.64071476]\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.64967114]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[0.5762769  0.58545256 0.5943532  0.60332757 0.61209619 0.62178862\n",
      "  0.63079786 0.64071476]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.020684121176600456\n",
      "Predicción post entrenamiento : [[0.65057623]]\n",
      "PERDIDAAAA despues: 0.020424598827958107\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "[[[0.58545256]\n",
      "  [0.5943532 ]\n",
      "  [0.60332757]\n",
      "  [0.61209619]\n",
      "  [0.62178862]\n",
      "  [0.63079786]\n",
      "  [0.64071476]\n",
      "  [0.64967114]]]\n",
      "ejemplar: [0.58545256 0.5943532  0.60332757 0.61209619 0.62178862 0.63079786\n",
      " 0.64071476 0.64967114]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.65811193]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[0.58545256 0.5943532  0.60332757 0.61209619 0.62178862 0.63079786\n",
      "  0.64071476 0.64967114]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010415943339467049\n",
      "Predicción post entrenamiento : [[0.6588309]]\n",
      "PERDIDAAAA despues: 0.01026970986276865\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "[[[0.5943532 ]\n",
      "  [0.60332757]\n",
      "  [0.61209619]\n",
      "  [0.62178862]\n",
      "  [0.63079786]\n",
      "  [0.64071476]\n",
      "  [0.64967114]\n",
      "  [0.65811193]]]\n",
      "ejemplar: [0.5943532  0.60332757 0.61209619 0.62178862 0.63079786 0.64071476\n",
      " 0.64967114 0.65811193]\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.6663807]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[0.5943532  0.60332757 0.61209619 0.62178862 0.63079786 0.64071476\n",
      "  0.64967114 0.65811193]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004760063253343105\n",
      "Predicción post entrenamiento : [[0.66672915]]\n",
      "PERDIDAAAA despues: 0.004712103400379419\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "[[[0.60332757]\n",
      "  [0.61209619]\n",
      "  [0.62178862]\n",
      "  [0.63079786]\n",
      "  [0.64071476]\n",
      "  [0.64967114]\n",
      "  [0.65811193]\n",
      "  [0.6663807 ]]]\n",
      "ejemplar: [0.60332757 0.61209619 0.62178862 0.63079786 0.64071476 0.64967114\n",
      " 0.65811193 0.6663807 ]\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.67436194]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[0.60332757 0.61209619 0.62178862 0.63079786 0.64071476 0.64967114\n",
      "  0.65811193 0.6663807 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012836366659030318\n",
      "Predicción post entrenamiento : [[0.67439246]]\n",
      "PERDIDAAAA despues: 0.0012814508518204093\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "[[[0.61209619]\n",
      "  [0.62178862]\n",
      "  [0.63079786]\n",
      "  [0.64071476]\n",
      "  [0.64967114]\n",
      "  [0.65811193]\n",
      "  [0.6663807 ]\n",
      "  [0.67436194]]]\n",
      "ejemplar: [0.61209619 0.62178862 0.63079786 0.64071476 0.64967114 0.65811193\n",
      " 0.6663807  0.67436194]\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.6820807]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[0.61209619 0.62178862 0.63079786 0.64071476 0.64967114 0.65811193\n",
      "  0.6663807  0.67436194]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000902786385267973\n",
      "Predicción post entrenamiento : [[0.68303967]]\n",
      "PERDIDAAAA despues: 0.0008460782701149583\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "[[[0.62178862]\n",
      "  [0.63079786]\n",
      "  [0.64071476]\n",
      "  [0.64967114]\n",
      "  [0.65811193]\n",
      "  [0.6663807 ]\n",
      "  [0.67436194]\n",
      "  [0.68208069]]]\n",
      "ejemplar: [0.62178862 0.63079786 0.64071476 0.64967114 0.65811193 0.6663807\n",
      " 0.67436194 0.68208069]\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.69082123]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[0.62178862 0.63079786 0.64071476 0.64967114 0.65811193 0.6663807\n",
      "  0.67436194 0.68208069]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002382864709943533\n",
      "Predicción post entrenamiento : [[0.69149804]]\n",
      "PERDIDAAAA despues: 0.0023172462824732065\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "[[[0.63079786]\n",
      "  [0.64071476]\n",
      "  [0.64967114]\n",
      "  [0.65811193]\n",
      "  [0.6663807 ]\n",
      "  [0.67436194]\n",
      "  [0.68208069]\n",
      "  [0.69082123]]]\n",
      "ejemplar: [0.63079786 0.64071476 0.64967114 0.65811193 0.6663807  0.67436194\n",
      " 0.68208069 0.69082123]\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.69909155]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[0.63079786 0.64071476 0.64967114 0.65811193 0.6663807  0.67436194\n",
      "  0.68208069 0.69082123]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013732375809922814\n",
      "Predicción post entrenamiento : [[0.69918966]]\n",
      "PERDIDAAAA despues: 0.0013659759424626827\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "[[[0.64071476]\n",
      "  [0.64967114]\n",
      "  [0.65811193]\n",
      "  [0.6663807 ]\n",
      "  [0.67436194]\n",
      "  [0.68208069]\n",
      "  [0.69082123]\n",
      "  [0.69909155]]]\n",
      "ejemplar: [0.64071476 0.64967114 0.65811193 0.6663807  0.67436194 0.68208069\n",
      " 0.69082123 0.69909155]\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.70671964]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[0.64071476 0.64967114 0.65811193 0.6663807  0.67436194 0.68208069\n",
      "  0.69082123 0.69909155]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015326384454965591\n",
      "Predicción post entrenamiento : [[0.7067601]]\n",
      "PERDIDAAAA despues: 0.0015358089003711939\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "[[[0.64967114]\n",
      "  [0.65811193]\n",
      "  [0.6663807 ]\n",
      "  [0.67436194]\n",
      "  [0.68208069]\n",
      "  [0.69082123]\n",
      "  [0.69909155]\n",
      "  [0.70671964]]]\n",
      "ejemplar: [0.64967114 0.65811193 0.6663807  0.67436194 0.68208069 0.69082123\n",
      " 0.69909155 0.70671964]\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.71393025]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[0.64967114 0.65811193 0.6663807  0.67436194 0.68208069 0.69082123\n",
      "  0.69909155 0.70671964]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0019390670349821448\n",
      "Predicción post entrenamiento : [[0.7131111]]\n",
      "PERDIDAAAA despues: 0.001867596060037613\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "[[[0.65811193]\n",
      "  [0.6663807 ]\n",
      "  [0.67436194]\n",
      "  [0.68208069]\n",
      "  [0.69082123]\n",
      "  [0.69909155]\n",
      "  [0.70671964]\n",
      "  [0.71393025]]]\n",
      "ejemplar: [0.65811193 0.6663807  0.67436194 0.68208069 0.69082123 0.69909155\n",
      " 0.70671964 0.71393025]\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.7201053]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[0.65811193 0.6663807  0.67436194 0.68208069 0.69082123 0.69909155\n",
      "  0.70671964 0.71393025]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005511256167665124\n",
      "Predicción post entrenamiento : [[0.7192613]]\n",
      "PERDIDAAAA despues: 0.0005122102447785437\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "[[[0.6663807 ]\n",
      "  [0.67436194]\n",
      "  [0.68208069]\n",
      "  [0.69082123]\n",
      "  [0.69909155]\n",
      "  [0.70671964]\n",
      "  [0.71393025]\n",
      "  [0.72010529]]]\n",
      "ejemplar: [0.6663807  0.67436194 0.68208069 0.69082123 0.69909155 0.70671964\n",
      " 0.71393025 0.72010529]\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.72616917]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[0.6663807  0.67436194 0.68208069 0.69082123 0.69909155 0.70671964\n",
      "  0.71393025 0.72010529]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00493110716342926\n",
      "Predicción post entrenamiento : [[0.7267141]]\n",
      "PERDIDAAAA despues: 0.005007932428270578\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "[[[0.67436194]\n",
      "  [0.68208069]\n",
      "  [0.69082123]\n",
      "  [0.69909155]\n",
      "  [0.70671964]\n",
      "  [0.71393025]\n",
      "  [0.72010529]\n",
      "  [0.72616917]]]\n",
      "ejemplar: [0.67436194 0.68208069 0.69082123 0.69909155 0.70671964 0.71393025\n",
      " 0.72010529 0.72616917]\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.7335368]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[0.67436194 0.68208069 0.69082123 0.69909155 0.70671964 0.71393025\n",
      "  0.72010529 0.72616917]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029953857883810997\n",
      "Predicción post entrenamiento : [[0.7327163]]\n",
      "PERDIDAAAA despues: 0.0029062514659017324\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "[[[0.68208069]\n",
      "  [0.69082123]\n",
      "  [0.69909155]\n",
      "  [0.70671964]\n",
      "  [0.71393025]\n",
      "  [0.72010529]\n",
      "  [0.72616917]\n",
      "  [0.73353678]]]\n",
      "ejemplar: [0.68208069 0.69082123 0.69909155 0.70671964 0.71393025 0.72010529\n",
      " 0.72616917 0.73353678]\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.7394767]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[0.68208069 0.69082123 0.69909155 0.70671964 0.71393025 0.72010529\n",
      "  0.72616917 0.73353678]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004017296712845564\n",
      "Predicción post entrenamiento : [[0.7395692]]\n",
      "PERDIDAAAA despues: 0.004029031842947006\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "[[[0.69082123]\n",
      "  [0.69909155]\n",
      "  [0.70671964]\n",
      "  [0.71393025]\n",
      "  [0.72010529]\n",
      "  [0.72616917]\n",
      "  [0.73353678]\n",
      "  [0.73947668]]]\n",
      "ejemplar: [0.69082123 0.69909155 0.70671964 0.71393025 0.72010529 0.72616917\n",
      " 0.73353678 0.73947668]\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.74628675]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[0.69082123 0.69909155 0.70671964 0.71393025 0.72010529 0.72616917\n",
      "  0.73353678 0.73947668]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00027971179224550724\n",
      "Predicción post entrenamiento : [[0.7458049]]\n",
      "PERDIDAAAA despues: 0.00026382668875157833\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "[[[0.69909155]\n",
      "  [0.70671964]\n",
      "  [0.71393025]\n",
      "  [0.72010529]\n",
      "  [0.72616917]\n",
      "  [0.73353678]\n",
      "  [0.73947668]\n",
      "  [0.74628675]]]\n",
      "ejemplar: [0.69909155 0.70671964 0.71393025 0.72010529 0.72616917 0.73353678\n",
      " 0.73947668 0.74628675]\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.7521327]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[0.69909155 0.70671964 0.71393025 0.72010529 0.72616917 0.73353678\n",
      "  0.73947668 0.74628675]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00258614425547421\n",
      "Predicción post entrenamiento : [[0.7519119]]\n",
      "PERDIDAAAA despues: 0.002563732210546732\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "[[[0.70671964]\n",
      "  [0.71393025]\n",
      "  [0.72010529]\n",
      "  [0.72616917]\n",
      "  [0.73353678]\n",
      "  [0.73947668]\n",
      "  [0.74628675]\n",
      "  [0.75213271]]]\n",
      "ejemplar: [0.70671964 0.71393025 0.72010529 0.72616917 0.73353678 0.73947668\n",
      " 0.74628675 0.75213271]\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.75788313]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[0.70671964 0.71393025 0.72010529 0.72616917 0.73353678 0.73947668\n",
      "  0.74628675 0.75213271]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 9.310049063060433e-05\n",
      "Predicción post entrenamiento : [[0.75867903]]\n",
      "PERDIDAAAA despues: 7.837487646611407e-05\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "[[[0.71393025]\n",
      "  [0.72010529]\n",
      "  [0.72616917]\n",
      "  [0.73353678]\n",
      "  [0.73947668]\n",
      "  [0.74628675]\n",
      "  [0.75213271]\n",
      "  [0.75788313]]]\n",
      "ejemplar: [0.71393025 0.72010529 0.72616917 0.73353678 0.73947668 0.74628675\n",
      " 0.75213271 0.75788313]\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.7643937]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[0.71393025 0.72010529 0.72616917 0.73353678 0.73947668 0.74628675\n",
      "  0.75213271 0.75788313]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.574757521273568e-05\n",
      "Predicción post entrenamiento : [[0.7629128]]\n",
      "PERDIDAAAA despues: 6.05147288297303e-05\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "[[[0.72010529]\n",
      "  [0.72616917]\n",
      "  [0.73353678]\n",
      "  [0.73947668]\n",
      "  [0.74628675]\n",
      "  [0.75213271]\n",
      "  [0.75788313]\n",
      "  [0.76439369]]]\n",
      "ejemplar: [0.72010529 0.72616917 0.73353678 0.73947668 0.74628675 0.75213271\n",
      " 0.75788313 0.76439369]\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.7684257]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[0.72010529 0.72616917 0.73353678 0.73947668 0.74628675 0.75213271\n",
      "  0.75788313 0.76439369]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005459548556245863\n",
      "Predicción post entrenamiento : [[0.76770884]]\n",
      "PERDIDAAAA despues: 0.0005129686323925853\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "[[[0.72616917]\n",
      "  [0.73353678]\n",
      "  [0.73947668]\n",
      "  [0.74628675]\n",
      "  [0.75213271]\n",
      "  [0.75788313]\n",
      "  [0.76439369]\n",
      "  [0.7684257 ]]]\n",
      "ejemplar: [0.72616917 0.73353678 0.73947668 0.74628675 0.75213271 0.75788313\n",
      " 0.76439369 0.7684257 ]\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.77326405]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[0.72616917 0.73353678 0.73947668 0.74628675 0.75213271 0.75788313\n",
      "  0.76439369 0.7684257 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004507121630012989\n",
      "Predicción post entrenamiento : [[0.77403975]]\n",
      "PERDIDAAAA despues: 0.0004842498165089637\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "[[[0.73353678]\n",
      "  [0.73947668]\n",
      "  [0.74628675]\n",
      "  [0.75213271]\n",
      "  [0.75788313]\n",
      "  [0.76439369]\n",
      "  [0.7684257 ]\n",
      "  [0.77326405]]]\n",
      "ejemplar: [0.73353678 0.73947668 0.74628675 0.75213271 0.75788313 0.76439369\n",
      " 0.7684257  0.77326405]\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.7796451]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[0.73353678 0.73947668 0.74628675 0.75213271 0.75788313 0.76439369\n",
      "  0.7684257  0.77326405]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004878002218902111\n",
      "Predicción post entrenamiento : [[0.778267]]\n",
      "PERDIDAAAA despues: 0.004687406588345766\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "[[[0.73947668]\n",
      "  [0.74628675]\n",
      "  [0.75213271]\n",
      "  [0.75788313]\n",
      "  [0.76439369]\n",
      "  [0.7684257 ]\n",
      "  [0.77326405]\n",
      "  [0.77964509]]]\n",
      "ejemplar: [0.73947668 0.74628675 0.75213271 0.75788313 0.76439369 0.7684257\n",
      " 0.77326405 0.77964509]\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.78351396]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[0.73947668 0.74628675 0.75213271 0.75788313 0.76439369 0.7684257\n",
      "  0.77326405 0.77964509]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008664615452289581\n",
      "Predicción post entrenamiento : [[0.7836173]]\n",
      "PERDIDAAAA despues: 0.008683867752552032\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "[[[0.74628675]\n",
      "  [0.75213271]\n",
      "  [0.75788313]\n",
      "  [0.76439369]\n",
      "  [0.7684257 ]\n",
      "  [0.77326405]\n",
      "  [0.77964509]\n",
      "  [0.78351396]]]\n",
      "ejemplar: [0.74628675 0.75213271 0.75788313 0.76439369 0.7684257  0.77326405\n",
      " 0.77964509 0.78351396]\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.7888265]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[0.74628675 0.75213271 0.75788313 0.76439369 0.7684257  0.77326405\n",
      "  0.77964509 0.78351396]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001188026275485754\n",
      "Predicción post entrenamiento : [[0.7895496]]\n",
      "PERDIDAAAA despues: 0.0012383938301354647\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "[[[0.75213271]\n",
      "  [0.75788313]\n",
      "  [0.76439369]\n",
      "  [0.7684257 ]\n",
      "  [0.77326405]\n",
      "  [0.77964509]\n",
      "  [0.78351396]\n",
      "  [0.78882653]]]\n",
      "ejemplar: [0.75213271 0.75788313 0.76439369 0.7684257  0.77326405 0.77964509\n",
      " 0.78351396 0.78882653]\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.7944315]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[0.75213271 0.75788313 0.76439369 0.7684257  0.77326405 0.77964509\n",
      "  0.78351396 0.78882653]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005217290949076414\n",
      "Predicción post entrenamiento : [[0.79460275]]\n",
      "PERDIDAAAA despues: 0.005242058075964451\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "[[[0.75788313]\n",
      "  [0.76439369]\n",
      "  [0.7684257 ]\n",
      "  [0.77326405]\n",
      "  [0.77964509]\n",
      "  [0.78351396]\n",
      "  [0.78882653]\n",
      "  [0.79443151]]]\n",
      "ejemplar: [0.75788313 0.76439369 0.7684257  0.77326405 0.77964509 0.78351396\n",
      " 0.78882653 0.79443151]\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.79936]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[0.75788313 0.76439369 0.7684257  0.77326405 0.77964509 0.78351396\n",
      "  0.78882653 0.79443151]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0024155634455382824\n",
      "Predicción post entrenamiento : [[0.80008525]]\n",
      "PERDIDAAAA despues: 0.0023447978310287\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "[[[0.76439369]\n",
      "  [0.7684257 ]\n",
      "  [0.77326405]\n",
      "  [0.77964509]\n",
      "  [0.78351396]\n",
      "  [0.78882653]\n",
      "  [0.79443151]\n",
      "  [0.79935998]]]\n",
      "ejemplar: [0.76439369 0.7684257  0.77326405 0.77964509 0.78351396 0.78882653\n",
      " 0.79443151 0.79935998]\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.80471194]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[0.76439369 0.7684257  0.77326405 0.77964509 0.78351396 0.78882653\n",
      "  0.79443151 0.79935998]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010150772519409657\n",
      "Predicción post entrenamiento : [[0.8050576]]\n",
      "PERDIDAAAA despues: 0.010081243701279163\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "[[[0.7684257 ]\n",
      "  [0.77326405]\n",
      "  [0.77964509]\n",
      "  [0.78351396]\n",
      "  [0.78882653]\n",
      "  [0.79443151]\n",
      "  [0.79935998]\n",
      "  [0.80471194]]]\n",
      "ejemplar: [0.7684257  0.77326405 0.77964509 0.78351396 0.78882653 0.79443151\n",
      " 0.79935998 0.80471194]\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.80930704]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[0.7684257  0.77326405 0.77964509 0.78351396 0.78882653 0.79443151\n",
      "  0.79935998 0.80471194]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005315748043358326\n",
      "Predicción post entrenamiento : [[0.8098889]]\n",
      "PERDIDAAAA despues: 0.005231240764260292\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "[[[0.77326405]\n",
      "  [0.77964509]\n",
      "  [0.78351396]\n",
      "  [0.78882653]\n",
      "  [0.79443151]\n",
      "  [0.79935998]\n",
      "  [0.80471194]\n",
      "  [0.80930704]]]\n",
      "ejemplar: [0.77326405 0.77964509 0.78351396 0.78882653 0.79443151 0.79935998\n",
      " 0.80471194 0.80930704]\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.8144244]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[0.77326405 0.77964509 0.78351396 0.78882653 0.79443151 0.79935998\n",
      "  0.80471194 0.80930704]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00871670339256525\n",
      "Predicción post entrenamiento : [[0.81476766]]\n",
      "PERDIDAAAA despues: 0.008652724325656891\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "[[[0.77964509]\n",
      "  [0.78351396]\n",
      "  [0.78882653]\n",
      "  [0.79443151]\n",
      "  [0.79935998]\n",
      "  [0.80471194]\n",
      "  [0.80930704]\n",
      "  [0.8144244 ]]]\n",
      "ejemplar: [0.77964509 0.78351396 0.78882653 0.79443151 0.79935998 0.80471194\n",
      " 0.80930704 0.8144244 ]\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.8193969]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[0.77964509 0.78351396 0.78882653 0.79443151 0.79935998 0.80471194\n",
      "  0.80930704 0.8144244 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0049253408797085285\n",
      "Predicción post entrenamiento : [[0.8204416]]\n",
      "PERDIDAAAA despues: 0.004779797978699207\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "[[[0.78351396]\n",
      "  [0.78882653]\n",
      "  [0.79443151]\n",
      "  [0.79935998]\n",
      "  [0.80471194]\n",
      "  [0.80930704]\n",
      "  [0.8144244 ]\n",
      "  [0.81939691]]]\n",
      "ejemplar: [0.78351396 0.78882653 0.79443151 0.79935998 0.80471194 0.80930704\n",
      " 0.8144244  0.81939691]\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.82472545]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[0.78351396 0.78882653 0.79443151 0.79935998 0.80471194 0.80930704\n",
      "  0.8144244  0.81939691]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0025129402056336403\n",
      "Predicción post entrenamiento : [[0.82522875]]\n",
      "PERDIDAAAA despues: 0.002462733304128051\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "[[[0.78882653]\n",
      "  [0.79443151]\n",
      "  [0.79935998]\n",
      "  [0.80471194]\n",
      "  [0.80930704]\n",
      "  [0.8144244 ]\n",
      "  [0.81939691]\n",
      "  [0.82472545]]]\n",
      "ejemplar: [0.78882653 0.79443151 0.79935998 0.80471194 0.80930704 0.8144244\n",
      " 0.81939691 0.82472545]\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.8298446]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[0.78882653 0.79443151 0.79935998 0.80471194 0.80930704 0.8144244\n",
      "  0.81939691 0.82472545]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006950114853680134\n",
      "Predicción post entrenamiento : [[0.82972455]]\n",
      "PERDIDAAAA despues: 0.006970144342631102\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "[[[0.79443151]\n",
      "  [0.79935998]\n",
      "  [0.80471194]\n",
      "  [0.80930704]\n",
      "  [0.8144244 ]\n",
      "  [0.81939691]\n",
      "  [0.82472545]\n",
      "  [0.82984459]]]\n",
      "ejemplar: [0.79443151 0.79935998 0.80471194 0.80930704 0.8144244  0.81939691\n",
      " 0.82472545 0.82984459]\n",
      "y: 1.0\n",
      "Predicción : [[0.83429843]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[0.79443151 0.79935998 0.80471194 0.80930704 0.8144244  0.81939691\n",
      "  0.82472545 0.82984459]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.027457010000944138\n",
      "Predicción post entrenamiento : [[0.8361462]]\n",
      "PERDIDAAAA despues: 0.026848075911402702\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "[[[0.79935998]\n",
      "  [0.80471194]\n",
      "  [0.80930704]\n",
      "  [0.8144244 ]\n",
      "  [0.81939691]\n",
      "  [0.82472545]\n",
      "  [0.82984459]\n",
      "  [0.83429843]]]\n",
      "ejemplar: [0.79935998 0.80471194 0.80930704 0.8144244  0.81939691 0.82472545\n",
      " 0.82984459 0.83429843]\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.8405818]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[0.79935998 0.80471194 0.80930704 0.8144244  0.81939691 0.82472545\n",
      "  0.82984459 0.83429843]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016892792657017708\n",
      "Predicción post entrenamiento : [[0.8416884]]\n",
      "PERDIDAAAA despues: 0.01660635881125927\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "[[[0.80471194]\n",
      "  [0.80930704]\n",
      "  [0.8144244 ]\n",
      "  [0.81939691]\n",
      "  [0.82472545]\n",
      "  [0.82984459]\n",
      "  [0.83429843]\n",
      "  [0.84058177]]]\n",
      "ejemplar: [0.80471194 0.80930704 0.8144244  0.81939691 0.82472545 0.82984459\n",
      " 0.83429843 0.84058177]\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.8461631]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[0.80471194 0.80930704 0.8144244  0.81939691 0.82472545 0.82984459\n",
      "  0.83429843 0.84058177]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018181416671723127\n",
      "Predicción post entrenamiento : [[0.84734666]]\n",
      "PERDIDAAAA despues: 0.0017186085460707545\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "[[[0.80930704]\n",
      "  [0.8144244 ]\n",
      "  [0.81939691]\n",
      "  [0.82472545]\n",
      "  [0.82984459]\n",
      "  [0.83429843]\n",
      "  [0.84058177]\n",
      "  [0.84616309]]]\n",
      "ejemplar: [0.80930704 0.8144244  0.81939691 0.82472545 0.82984459 0.83429843\n",
      " 0.84058177 0.84616309]\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.8517521]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[0.80930704 0.8144244  0.81939691 0.82472545 0.82984459 0.83429843\n",
      "  0.84058177 0.84616309]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000686555402353406\n",
      "Predicción post entrenamiento : [[0.85172445]]\n",
      "PERDIDAAAA despues: 0.0006880054716020823\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "[[[0.8144244 ]\n",
      "  [0.81939691]\n",
      "  [0.82472545]\n",
      "  [0.82984459]\n",
      "  [0.83429843]\n",
      "  [0.84058177]\n",
      "  [0.84616309]\n",
      "  [0.8517521 ]]]\n",
      "ejemplar: [0.8144244  0.81939691 0.82472545 0.82984459 0.83429843 0.84058177\n",
      " 0.84616309 0.8517521 ]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.8562843]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[0.8144244  0.81939691 0.82472545 0.82984459 0.83429843 0.84058177\n",
      "  0.84616309 0.8517521 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.4590407671639696e-05\n",
      "Predicción post entrenamiento : [[0.85704243]]\n",
      "PERDIDAAAA despues: 6.636780017288402e-05\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "[[[0.81939691]\n",
      "  [0.82472545]\n",
      "  [0.82984459]\n",
      "  [0.83429843]\n",
      "  [0.84058177]\n",
      "  [0.84616309]\n",
      "  [0.8517521 ]\n",
      "  [0.85628432]]]\n",
      "ejemplar: [0.81939691 0.82472545 0.82984459 0.83429843 0.84058177 0.84616309\n",
      " 0.8517521  0.85628432]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.86163795]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[0.81939691 0.82472545 0.82984459 0.83429843 0.84058177 0.84616309\n",
      "  0.8517521  0.85628432]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007543352548964322\n",
      "Predicción post entrenamiento : [[0.8611583]]\n",
      "PERDIDAAAA despues: 0.0007282186415977776\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "[[[0.82472545]\n",
      "  [0.82984459]\n",
      "  [0.83429843]\n",
      "  [0.84058177]\n",
      "  [0.84616309]\n",
      "  [0.8517521 ]\n",
      "  [0.85628432]\n",
      "  [0.86163795]]]\n",
      "ejemplar: [0.82472545 0.82984459 0.83429843 0.84058177 0.84616309 0.8517521\n",
      " 0.85628432 0.86163795]\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.86584014]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[0.82472545 0.82984459 0.83429843 0.84058177 0.84616309 0.8517521\n",
      "  0.85628432 0.86163795]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00011545990855665877\n",
      "Predicción post entrenamiento : [[0.8654119]]\n",
      "PERDIDAAAA despues: 0.00010643983114277944\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "[[[0.82984459]\n",
      "  [0.83429843]\n",
      "  [0.84058177]\n",
      "  [0.84616309]\n",
      "  [0.8517521 ]\n",
      "  [0.85628432]\n",
      "  [0.86163795]\n",
      "  [0.86584014]]]\n",
      "ejemplar: [0.82984459 0.83429843 0.84058177 0.84616309 0.8517521  0.85628432\n",
      " 0.86163795 0.86584014]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.87008387]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[0.82984459 0.83429843 0.84058177 0.84616309 0.8517521  0.85628432\n",
      "  0.86163795 0.86584014]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.660811151145026e-05\n",
      "Predicción post entrenamiento : [[0.8702557]]\n",
      "PERDIDAAAA despues: 2.486483208485879e-05\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "[[[0.83429843]\n",
      "  [0.84058177]\n",
      "  [0.84616309]\n",
      "  [0.8517521 ]\n",
      "  [0.85628432]\n",
      "  [0.86163795]\n",
      "  [0.86584014]\n",
      "  [0.87008387]]]\n",
      "ejemplar: [0.83429843 0.84058177 0.84616309 0.8517521  0.85628432 0.86163795\n",
      " 0.86584014 0.87008387]\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.87496436]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[0.83429843 0.84058177 0.84616309 0.8517521  0.85628432 0.86163795\n",
      "  0.86584014 0.87008387]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000321562954923138\n",
      "Predicción post entrenamiento : [[0.8749751]]\n",
      "PERDIDAAAA despues: 0.0003219478530809283\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "[[[0.84058177]\n",
      "  [0.84616309]\n",
      "  [0.8517521 ]\n",
      "  [0.85628432]\n",
      "  [0.86163795]\n",
      "  [0.86584014]\n",
      "  [0.87008387]\n",
      "  [0.87496436]]]\n",
      "ejemplar: [0.84058177 0.84616309 0.8517521  0.85628432 0.86163795 0.86584014\n",
      " 0.87008387 0.87496436]\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.87989956]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[0.84058177 0.84616309 0.8517521  0.85628432 0.86163795 0.86584014\n",
      "  0.87008387 0.87496436]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008905105059966445\n",
      "Predicción post entrenamiento : [[0.87784576]]\n",
      "PERDIDAAAA despues: 0.0007721521542407572\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "[[[0.84616309]\n",
      "  [0.8517521 ]\n",
      "  [0.85628432]\n",
      "  [0.86163795]\n",
      "  [0.86584014]\n",
      "  [0.87008387]\n",
      "  [0.87496436]\n",
      "  [0.87989956]]]\n",
      "ejemplar: [0.84616309 0.8517521  0.85628432 0.86163795 0.86584014 0.87008387\n",
      " 0.87496436 0.87989956]\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.88244474]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[0.84616309 0.8517521  0.85628432 0.86163795 0.86584014 0.87008387\n",
      "  0.87496436 0.87989956]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015799140091985464\n",
      "Predicción post entrenamiento : [[0.8822542]]\n",
      "PERDIDAAAA despues: 0.0015648017870262265\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "[[[0.8517521 ]\n",
      "  [0.85628432]\n",
      "  [0.86163795]\n",
      "  [0.86584014]\n",
      "  [0.87008387]\n",
      "  [0.87496436]\n",
      "  [0.87989956]\n",
      "  [0.88244474]]]\n",
      "ejemplar: [0.8517521  0.85628432 0.86163795 0.86584014 0.87008387 0.87496436\n",
      " 0.87989956 0.88244474]\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.886654]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[0.8517521  0.85628432 0.86163795 0.86584014 0.87008387 0.87496436\n",
      "  0.87989956 0.88244474]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004059880040585995\n",
      "Predicción post entrenamiento : [[0.88615906]]\n",
      "PERDIDAAAA despues: 0.003997050225734711\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "[[[0.85628432]\n",
      "  [0.86163795]\n",
      "  [0.86584014]\n",
      "  [0.87008387]\n",
      "  [0.87496436]\n",
      "  [0.87989956]\n",
      "  [0.88244474]\n",
      "  [0.88665402]]]\n",
      "ejemplar: [0.85628432 0.86163795 0.86584014 0.87008387 0.87496436 0.87989956\n",
      " 0.88244474 0.88665402]\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.89029545]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[0.85628432 0.86163795 0.86584014 0.87008387 0.87496436 0.87989956\n",
      "  0.88244474 0.88665402]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013407188467681408\n",
      "Predicción post entrenamiento : [[0.8885781]]\n",
      "PERDIDAAAA despues: 0.013012440875172615\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "[[[0.86163795]\n",
      "  [0.86584014]\n",
      "  [0.87008387]\n",
      "  [0.87496436]\n",
      "  [0.87989956]\n",
      "  [0.88244474]\n",
      "  [0.88665402]\n",
      "  [0.89029545]]]\n",
      "ejemplar: [0.86163795 0.86584014 0.87008387 0.87496436 0.87989956 0.88244474\n",
      " 0.88665402 0.89029545]\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.89269257]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[0.86163795 0.86584014 0.87008387 0.87496436 0.87989956 0.88244474\n",
      "  0.88665402 0.89029545]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011772341094911098\n",
      "Predicción post entrenamiento : [[0.8913359]]\n",
      "PERDIDAAAA despues: 0.011479785665869713\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "[[[0.86584014]\n",
      "  [0.87008387]\n",
      "  [0.87496436]\n",
      "  [0.87989956]\n",
      "  [0.88244474]\n",
      "  [0.88665402]\n",
      "  [0.89029545]\n",
      "  [0.89269257]]]\n",
      "ejemplar: [0.86584014 0.87008387 0.87496436 0.87989956 0.88244474 0.88665402\n",
      " 0.89029545 0.89269257]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.8951468]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[0.86584014 0.87008387 0.87496436 0.87989956 0.88244474 0.88665402\n",
      "  0.89029545 0.89269257]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012533353874459863\n",
      "Predicción post entrenamiento : [[0.89483553]]\n",
      "PERDIDAAAA despues: 0.001231393776834011\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "[[[0.87008387]\n",
      "  [0.87496436]\n",
      "  [0.87989956]\n",
      "  [0.88244474]\n",
      "  [0.88665402]\n",
      "  [0.89029545]\n",
      "  [0.89269257]\n",
      "  [0.89514679]]]\n",
      "ejemplar: [0.87008387 0.87496436 0.87989956 0.88244474 0.88665402 0.89029545\n",
      " 0.89269257 0.89514679]\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.8985983]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[0.87008387 0.87496436 0.87989956 0.88244474 0.88665402 0.89029545\n",
      "  0.89269257 0.89514679]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001960564637556672\n",
      "Predicción post entrenamiento : [[0.8971137]]\n",
      "PERDIDAAAA despues: 0.001831294852308929\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "[[[0.87496436]\n",
      "  [0.87989956]\n",
      "  [0.88244474]\n",
      "  [0.88665402]\n",
      "  [0.89029545]\n",
      "  [0.89269257]\n",
      "  [0.89514679]\n",
      "  [0.89859831]]]\n",
      "ejemplar: [0.87496436 0.87989956 0.88244474 0.88665402 0.89029545 0.89269257\n",
      " 0.89514679 0.89859831]\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.9007644]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[0.87496436 0.87989956 0.88244474 0.88665402 0.89029545 0.89269257\n",
      "  0.89514679 0.89859831]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004080589395016432\n",
      "Predicción post entrenamiento : [[0.8998155]]\n",
      "PERDIDAAAA despues: 0.003960258327424526\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "[[[0.87989956]\n",
      "  [0.88244474]\n",
      "  [0.88665402]\n",
      "  [0.89029545]\n",
      "  [0.89269257]\n",
      "  [0.89514679]\n",
      "  [0.89859831]\n",
      "  [0.90076441]]]\n",
      "ejemplar: [0.87989956 0.88244474 0.88665402 0.89029545 0.89269257 0.89514679\n",
      " 0.89859831 0.90076441]\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.90310276]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[0.87989956 0.88244474 0.88665402 0.89029545 0.89269257 0.89514679\n",
      "  0.89859831 0.90076441]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005357051268219948\n",
      "Predicción post entrenamiento : [[0.90270853]]\n",
      "PERDIDAAAA despues: 0.005299498792737722\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "[[[0.88244474]\n",
      "  [0.88665402]\n",
      "  [0.89029545]\n",
      "  [0.89269257]\n",
      "  [0.89514679]\n",
      "  [0.89859831]\n",
      "  [0.90076441]\n",
      "  [0.90310276]]]\n",
      "ejemplar: [0.88244474 0.88665402 0.89029545 0.89269257 0.89514679 0.89859831\n",
      " 0.90076441 0.90310276]\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.9055214]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[0.88244474 0.88665402 0.89029545 0.89269257 0.89514679 0.89859831\n",
      "  0.90076441 0.90310276]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003337346715852618\n",
      "Predicción post entrenamiento : [[0.90408546]]\n",
      "PERDIDAAAA despues: 0.00028333207592368126\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "[[[0.88665402]\n",
      "  [0.89029545]\n",
      "  [0.89269257]\n",
      "  [0.89514679]\n",
      "  [0.89859831]\n",
      "  [0.90076441]\n",
      "  [0.90310276]\n",
      "  [0.90552139]]]\n",
      "ejemplar: [0.88665402 0.89029545 0.89269257 0.89514679 0.89859831 0.90076441\n",
      " 0.90310276 0.90552139]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.9070306]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[0.88665402 0.89029545 0.89269257 0.89514679 0.89859831 0.90076441\n",
      "  0.90310276 0.90552139]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0022359914146363735\n",
      "Predicción post entrenamiento : [[0.9060166]]\n",
      "PERDIDAAAA despues: 0.0021411236375570297\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "[[[0.89029545]\n",
      "  [0.89269257]\n",
      "  [0.89514679]\n",
      "  [0.89859831]\n",
      "  [0.90076441]\n",
      "  [0.90310276]\n",
      "  [0.90552139]\n",
      "  [0.90703058]]]\n",
      "ejemplar: [0.89029545 0.89269257 0.89514679 0.89859831 0.90076441 0.90310276\n",
      " 0.90552139 0.90703058]\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.9085868]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[0.89029545 0.89269257 0.89514679 0.89859831 0.90076441 0.90310276\n",
      "  0.90552139 0.90703058]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004759585950523615\n",
      "Predicción post entrenamiento : [[0.90914834]]\n",
      "PERDIDAAAA despues: 0.004837381653487682\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "[[[0.89269257]\n",
      "  [0.89514679]\n",
      "  [0.89859831]\n",
      "  [0.90076441]\n",
      "  [0.90310276]\n",
      "  [0.90552139]\n",
      "  [0.90703058]\n",
      "  [0.9085868 ]]]\n",
      "ejemplar: [0.89269257 0.89514679 0.89859831 0.90076441 0.90310276 0.90552139\n",
      " 0.90703058 0.9085868 ]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.9114248]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[0.89269257 0.89514679 0.89859831 0.90076441 0.90310276 0.90552139\n",
      "  0.90703058 0.9085868 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01628689095377922\n",
      "Predicción post entrenamiento : [[0.91043013]]\n",
      "PERDIDAAAA despues: 0.016033995896577835\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "[[[0.89514679]\n",
      "  [0.89859831]\n",
      "  [0.90076441]\n",
      "  [0.90310276]\n",
      "  [0.90552139]\n",
      "  [0.90703058]\n",
      "  [0.9085868 ]\n",
      "  [0.91142482]]]\n",
      "ejemplar: [0.89514679 0.89859831 0.90076441 0.90310276 0.90552139 0.90703058\n",
      " 0.9085868  0.91142482]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.9127154]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[0.89514679 0.89859831 0.90076441 0.90310276 0.90552139 0.90703058\n",
      "  0.9085868  0.91142482]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008916624821722507\n",
      "Predicción post entrenamiento : [[0.9123911]]\n",
      "PERDIDAAAA despues: 0.008855493739247322\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "[[[0.89859831]\n",
      "  [0.90076441]\n",
      "  [0.90310276]\n",
      "  [0.90552139]\n",
      "  [0.90703058]\n",
      "  [0.9085868 ]\n",
      "  [0.91142482]\n",
      "  [0.91271538]]]\n",
      "ejemplar: [0.89859831 0.90076441 0.90310276 0.90552139 0.90703058 0.9085868\n",
      " 0.91142482 0.91271538]\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.9146473]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[0.89859831 0.90076441 0.90310276 0.90552139 0.90703058 0.9085868\n",
      "  0.91142482 0.91271538]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015247580595314503\n",
      "Predicción post entrenamiento : [[0.91412175]]\n",
      "PERDIDAAAA despues: 0.0151180699467659\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "[[[0.90076441]\n",
      "  [0.90310276]\n",
      "  [0.90552139]\n",
      "  [0.90703058]\n",
      "  [0.9085868 ]\n",
      "  [0.91142482]\n",
      "  [0.91271538]\n",
      "  [0.91464728]]]\n",
      "ejemplar: [0.90076441 0.90310276 0.90552139 0.90703058 0.9085868  0.91142482\n",
      " 0.91271538 0.91464728]\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.91602504]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[0.90076441 0.90310276 0.90552139 0.90703058 0.9085868  0.91142482\n",
      "  0.91271538 0.91464728]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02417001686990261\n",
      "Predicción post entrenamiento : [[0.91552603]]\n",
      "PERDIDAAAA despues: 0.02401510626077652\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "[[[0.90310276]\n",
      "  [0.90552139]\n",
      "  [0.90703058]\n",
      "  [0.9085868 ]\n",
      "  [0.91142482]\n",
      "  [0.91271538]\n",
      "  [0.91464728]\n",
      "  [0.91602504]]]\n",
      "ejemplar: [0.90310276 0.90552139 0.90703058 0.9085868  0.91142482 0.91271538\n",
      " 0.91464728 0.91602504]\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.91738784]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[0.90310276 0.90552139 0.90703058 0.9085868  0.91142482 0.91271538\n",
      "  0.91464728 0.91602504]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01583423838019371\n",
      "Predicción post entrenamiento : [[0.91657037]]\n",
      "PERDIDAAAA despues: 0.015629172325134277\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "[[[0.90552139]\n",
      "  [0.90703058]\n",
      "  [0.9085868 ]\n",
      "  [0.91142482]\n",
      "  [0.91271538]\n",
      "  [0.91464728]\n",
      "  [0.91602504]\n",
      "  [0.91738784]]]\n",
      "ejemplar: [0.90552139 0.90703058 0.9085868  0.91142482 0.91271538 0.91464728\n",
      " 0.91602504 0.91738784]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.91831726]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[0.90552139 0.90703058 0.9085868  0.91142482 0.91271538 0.91464728\n",
      "  0.91602504 0.91738784]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022387035191059113\n",
      "Predicción post entrenamiento : [[0.9172956]]\n",
      "PERDIDAAAA despues: 0.022082343697547913\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "[[[0.90703058]\n",
      "  [0.9085868 ]\n",
      "  [0.91142482]\n",
      "  [0.91271538]\n",
      "  [0.91464728]\n",
      "  [0.91602504]\n",
      "  [0.91738784]\n",
      "  [0.91831726]]]\n",
      "ejemplar: [0.90703058 0.9085868  0.91142482 0.91271538 0.91464728 0.91602504\n",
      " 0.91738784 0.91831726]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.91886914]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[0.90703058 0.9085868  0.91142482 0.91271538 0.91464728 0.91602504\n",
      "  0.91738784 0.91831726]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0225524865090847\n",
      "Predicción post entrenamiento : [[0.9185517]]\n",
      "PERDIDAAAA despues: 0.022457240149378777\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "[[[0.9085868 ]\n",
      "  [0.91142482]\n",
      "  [0.91271538]\n",
      "  [0.91464728]\n",
      "  [0.91602504]\n",
      "  [0.91738784]\n",
      "  [0.91831726]\n",
      "  [0.91886914]]]\n",
      "ejemplar: [0.9085868  0.91142482 0.91271538 0.91464728 0.91602504 0.91738784\n",
      " 0.91831726 0.91886914]\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.92017484]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[0.9085868  0.91142482 0.91271538 0.91464728 0.91602504 0.91738784\n",
      "  0.91831726 0.91886914]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014703912660479546\n",
      "Predicción post entrenamiento : [[0.91948664]]\n",
      "PERDIDAAAA despues: 0.01453748531639576\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "[[[0.91142482]\n",
      "  [0.91271538]\n",
      "  [0.91464728]\n",
      "  [0.91602504]\n",
      "  [0.91738784]\n",
      "  [0.91831726]\n",
      "  [0.91886914]\n",
      "  [0.92017484]]]\n",
      "ejemplar: [0.91142482 0.91271538 0.91464728 0.91602504 0.91738784 0.91831726\n",
      " 0.91886914 0.92017484]\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.9211273]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[0.91142482 0.91271538 0.91464728 0.91602504 0.91738784 0.91831726\n",
      "  0.91886914 0.92017484]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017193352803587914\n",
      "Predicción post entrenamiento : [[0.91907805]]\n",
      "PERDIDAAAA despues: 0.016660137102007866\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "[[[0.91271538]\n",
      "  [0.91464728]\n",
      "  [0.91602504]\n",
      "  [0.91738784]\n",
      "  [0.91831726]\n",
      "  [0.91886914]\n",
      "  [0.92017484]\n",
      "  [0.92112732]]]\n",
      "ejemplar: [0.91271538 0.91464728 0.91602504 0.91738784 0.91831726 0.91886914\n",
      " 0.92017484 0.92112732]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.9203286]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[0.91271538 0.91464728 0.91602504 0.91738784 0.91831726 0.91886914\n",
      "  0.92017484 0.92112732]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.025650635361671448\n",
      "Predicción post entrenamiento : [[0.9200432]]\n",
      "PERDIDAAAA despues: 0.025559283792972565\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "[[[0.91464728]\n",
      "  [0.91602504]\n",
      "  [0.91738784]\n",
      "  [0.91831726]\n",
      "  [0.91886914]\n",
      "  [0.92017484]\n",
      "  [0.92112732]\n",
      "  [0.92032862]]]\n",
      "ejemplar: [0.91464728 0.91602504 0.91738784 0.91831726 0.91886914 0.92017484\n",
      " 0.92112732 0.92032862]\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.9212738]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[0.91464728 0.91602504 0.91738784 0.91831726 0.91886914 0.92017484\n",
      "  0.92112732 0.92032862]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.055639635771512985\n",
      "Predicción post entrenamiento : [[0.9196369]]\n",
      "PERDIDAAAA despues: 0.05487008020281792\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "[[[0.91602504]\n",
      "  [0.91738784]\n",
      "  [0.91831726]\n",
      "  [0.91886914]\n",
      "  [0.92017484]\n",
      "  [0.92112732]\n",
      "  [0.92032862]\n",
      "  [0.92127383]]]\n",
      "ejemplar: [0.91602504 0.91738784 0.91831726 0.91886914 0.92017484 0.92112732\n",
      " 0.92032862 0.92127383]\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.92062443]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[0.91602504 0.91738784 0.91831726 0.91886914 0.92017484 0.92112732\n",
      "  0.92032862 0.92127383]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09949776530265808\n",
      "Predicción post entrenamiento : [[0.91835034]]\n",
      "PERDIDAAAA despues: 0.09806828945875168\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "[[[0.91738784]\n",
      "  [0.91831726]\n",
      "  [0.91886914]\n",
      "  [0.92017484]\n",
      "  [0.92112732]\n",
      "  [0.92032862]\n",
      "  [0.92127383]\n",
      "  [0.92062443]]]\n",
      "ejemplar: [0.91738784 0.91831726 0.91886914 0.92017484 0.92112732 0.92032862\n",
      " 0.92127383 0.92062443]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9191903]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[0.91738784 0.91831726 0.91886914 0.92017484 0.92112732 0.92032862\n",
      "  0.92127383 0.92062443]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06468461453914642\n",
      "Predicción post entrenamiento : [[0.91873056]]\n",
      "PERDIDAAAA despues: 0.06445097923278809\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "[[[0.91831726]\n",
      "  [0.91886914]\n",
      "  [0.92017484]\n",
      "  [0.92112732]\n",
      "  [0.92032862]\n",
      "  [0.92127383]\n",
      "  [0.92062443]\n",
      "  [0.91919029]]]\n",
      "ejemplar: [0.91831726 0.91886914 0.92017484 0.92112732 0.92032862 0.92127383\n",
      " 0.92062443 0.91919029]\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.9193672]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[0.91831726 0.91886914 0.92017484 0.92112732 0.92032862 0.92127383\n",
      "  0.92062443 0.91919029]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04473310336470604\n",
      "Predicción post entrenamiento : [[0.9174796]]\n",
      "PERDIDAAAA despues: 0.04393819347023964\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "[[[0.91886914]\n",
      "  [0.92017484]\n",
      "  [0.92112732]\n",
      "  [0.92032862]\n",
      "  [0.92127383]\n",
      "  [0.92062443]\n",
      "  [0.91919029]\n",
      "  [0.91936719]]]\n",
      "ejemplar: [0.91886914 0.92017484 0.92112732 0.92032862 0.92127383 0.92062443\n",
      " 0.91919029 0.91936719]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9179716]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[0.91886914 0.92017484 0.92112732 0.92032862 0.92127383 0.92062443\n",
      "  0.91919029 0.91936719]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06406620889902115\n",
      "Predicción post entrenamiento : [[0.91495186]]\n",
      "PERDIDAAAA despues: 0.06254664808511734\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "[[[0.92017484]\n",
      "  [0.92112732]\n",
      "  [0.92032862]\n",
      "  [0.92127383]\n",
      "  [0.92062443]\n",
      "  [0.91919029]\n",
      "  [0.91936719]\n",
      "  [0.91797161]]]\n",
      "ejemplar: [0.92017484 0.92112732 0.92032862 0.92127383 0.92062443 0.91919029\n",
      " 0.91936719 0.91797161]\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.91534626]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[0.92017484 0.92112732 0.92032862 0.92127383 0.92062443 0.91919029\n",
      "  0.91936719 0.91797161]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.041613589972257614\n",
      "Predicción post entrenamiento : [[0.91413313]]\n",
      "PERDIDAAAA despues: 0.04112011939287186\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "[[[0.92112732]\n",
      "  [0.92032862]\n",
      "  [0.92127383]\n",
      "  [0.92062443]\n",
      "  [0.91919029]\n",
      "  [0.91936719]\n",
      "  [0.91797161]\n",
      "  [0.91534626]]]\n",
      "ejemplar: [0.92112732 0.92032862 0.92127383 0.92062443 0.91919029 0.91936719\n",
      " 0.91797161 0.91534626]\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.9141383]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[0.92112732 0.92032862 0.92127383 0.92062443 0.91919029 0.91936719\n",
      "  0.91797161 0.91534626]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05611281469464302\n",
      "Predicción post entrenamiento : [[0.91335505]]\n",
      "PERDIDAAAA despues: 0.05574234575033188\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "[[[0.92032862]\n",
      "  [0.92127383]\n",
      "  [0.92062443]\n",
      "  [0.91919029]\n",
      "  [0.91936719]\n",
      "  [0.91797161]\n",
      "  [0.91534626]\n",
      "  [0.91413832]]]\n",
      "ejemplar: [0.92032862 0.92127383 0.92062443 0.91919029 0.91936719 0.91797161\n",
      " 0.91534626 0.91413832]\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.91296667]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[0.92032862 0.92127383 0.92062443 0.91919029 0.91936719 0.91797161\n",
      "  0.91534626 0.91413832]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022758418694138527\n",
      "Predicción post entrenamiento : [[0.9119604]]\n",
      "PERDIDAAAA despues: 0.02245583012700081\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "[[[0.92127383]\n",
      "  [0.92062443]\n",
      "  [0.91919029]\n",
      "  [0.91936719]\n",
      "  [0.91797161]\n",
      "  [0.91534626]\n",
      "  [0.91413832]\n",
      "  [0.91296667]]]\n",
      "ejemplar: [0.92127383 0.92062443 0.91919029 0.91936719 0.91797161 0.91534626\n",
      " 0.91413832 0.91296667]\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.9115963]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[0.92127383 0.92062443 0.91919029 0.91936719 0.91797161 0.91534626\n",
      "  0.91413832 0.91296667]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010929606854915619\n",
      "Predicción post entrenamiento : [[0.91097105]]\n",
      "PERDIDAAAA despues: 0.01079926360398531\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "[[[0.92062443]\n",
      "  [0.91919029]\n",
      "  [0.91936719]\n",
      "  [0.91797161]\n",
      "  [0.91534626]\n",
      "  [0.91413832]\n",
      "  [0.91296667]\n",
      "  [0.9115963 ]]]\n",
      "ejemplar: [0.92062443 0.91919029 0.91936719 0.91797161 0.91534626 0.91413832\n",
      " 0.91296667 0.9115963 ]\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.910083]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[0.92062443 0.91919029 0.91936719 0.91797161 0.91534626 0.91413832\n",
      "  0.91296667 0.9115963 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009005073457956314\n",
      "Predicción post entrenamiento : [[0.9086208]]\n",
      "PERDIDAAAA despues: 0.008729696273803711\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "[[[0.91919029]\n",
      "  [0.91936719]\n",
      "  [0.91797161]\n",
      "  [0.91534626]\n",
      "  [0.91413832]\n",
      "  [0.91296667]\n",
      "  [0.9115963 ]\n",
      "  [0.910083  ]]]\n",
      "ejemplar: [0.91919029 0.91936719 0.91797161 0.91534626 0.91413832 0.91296667\n",
      " 0.9115963  0.910083  ]\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.907577]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[0.91919029 0.91936719 0.91797161 0.91534626 0.91413832 0.91296667\n",
      "  0.9115963  0.910083  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.7931297406903468e-06\n",
      "Predicción post entrenamiento : [[0.9079189]]\n",
      "PERDIDAAAA despues: 2.8256608857191168e-06\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "[[[0.91936719]\n",
      "  [0.91797161]\n",
      "  [0.91534626]\n",
      "  [0.91413832]\n",
      "  [0.91296667]\n",
      "  [0.9115963 ]\n",
      "  [0.910083  ]\n",
      "  [0.90757698]]]\n",
      "ejemplar: [0.91936719 0.91797161 0.91534626 0.91413832 0.91296667 0.9115963\n",
      " 0.910083   0.90757698]\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.9069065]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[0.91936719 0.91797161 0.91534626 0.91413832 0.91296667 0.9115963\n",
      "  0.910083   0.90757698]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002787739271298051\n",
      "Predicción post entrenamiento : [[0.9069176]]\n",
      "PERDIDAAAA despues: 0.0027865685988217592\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "[[[0.91797161]\n",
      "  [0.91534626]\n",
      "  [0.91413832]\n",
      "  [0.91296667]\n",
      "  [0.9115963 ]\n",
      "  [0.910083  ]\n",
      "  [0.90757698]\n",
      "  [0.90690649]]]\n",
      "ejemplar: [0.91797161 0.91534626 0.91413832 0.91296667 0.9115963  0.910083\n",
      " 0.90757698 0.90690649]\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.905453]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[0.91797161 0.91534626 0.91413832 0.91296667 0.9115963  0.910083\n",
      "  0.90757698 0.90690649]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0034694275818765163\n",
      "Predicción post entrenamiento : [[0.904297]]\n",
      "PERDIDAAAA despues: 0.003606948768720031\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "[[[0.91534626]\n",
      "  [0.91413832]\n",
      "  [0.91296667]\n",
      "  [0.9115963 ]\n",
      "  [0.910083  ]\n",
      "  [0.90757698]\n",
      "  [0.90690649]\n",
      "  [0.90545303]]]\n",
      "ejemplar: [0.91534626 0.91413832 0.91296667 0.9115963  0.910083   0.90757698\n",
      " 0.90690649 0.90545303]\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.90277874]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[0.91534626 0.91413832 0.91296667 0.9115963  0.910083   0.90757698\n",
      "  0.90690649 0.90545303]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000217587235965766\n",
      "Predicción post entrenamiento : [[0.9025454]]\n",
      "PERDIDAAAA despues: 0.00021075739641673863\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "[[[0.91413832]\n",
      "  [0.91296667]\n",
      "  [0.9115963 ]\n",
      "  [0.910083  ]\n",
      "  [0.90757698]\n",
      "  [0.90690649]\n",
      "  [0.90545303]\n",
      "  [0.90277874]]]\n",
      "ejemplar: [0.91413832 0.91296667 0.9115963  0.910083   0.90757698 0.90690649\n",
      " 0.90545303 0.90277874]\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.90132636]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[0.91413832 0.91296667 0.9115963  0.910083   0.90757698 0.90690649\n",
      "  0.90545303 0.90277874]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.480711792595685e-05\n",
      "Predicción post entrenamiento : [[0.9019516]]\n",
      "PERDIDAAAA despues: 8.601381705375388e-05\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "[[[0.91296667]\n",
      "  [0.9115963 ]\n",
      "  [0.910083  ]\n",
      "  [0.90757698]\n",
      "  [0.90690649]\n",
      "  [0.90545303]\n",
      "  [0.90277874]\n",
      "  [0.90132636]]]\n",
      "ejemplar: [0.91296667 0.9115963  0.910083   0.90757698 0.90690649 0.90545303\n",
      " 0.90277874 0.90132636]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.9006499]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[0.91296667 0.9115963  0.910083   0.90757698 0.90690649 0.90545303\n",
      "  0.90277874 0.90132636]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006455528200604022\n",
      "Predicción post entrenamiento : [[0.90024525]]\n",
      "PERDIDAAAA despues: 0.0006251537706702948\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "[[[0.9115963 ]\n",
      "  [0.910083  ]\n",
      "  [0.90757698]\n",
      "  [0.90690649]\n",
      "  [0.90545303]\n",
      "  [0.90277874]\n",
      "  [0.90132636]\n",
      "  [0.90064991]]]\n",
      "ejemplar: [0.9115963  0.910083   0.90757698 0.90690649 0.90545303 0.90277874\n",
      " 0.90132636 0.90064991]\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.8988334]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[0.9115963  0.910083   0.90757698 0.90690649 0.90545303 0.90277874\n",
      "  0.90132636 0.90064991]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002304038032889366\n",
      "Predicción post entrenamiento : [[0.89836127]]\n",
      "PERDIDAAAA despues: 0.0022589361760765314\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "[[[0.910083  ]\n",
      "  [0.90757698]\n",
      "  [0.90690649]\n",
      "  [0.90545303]\n",
      "  [0.90277874]\n",
      "  [0.90132636]\n",
      "  [0.90064991]\n",
      "  [0.89883339]]]\n",
      "ejemplar: [0.910083   0.90757698 0.90690649 0.90545303 0.90277874 0.90132636\n",
      " 0.90064991 0.89883339]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.89688146]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[0.910083   0.90757698 0.90690649 0.90545303 0.90277874 0.90132636\n",
      "  0.90064991 0.89883339]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002302624750882387\n",
      "Predicción post entrenamiento : [[0.8975315]]\n",
      "PERDIDAAAA despues: 0.0023654333781450987\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "[[[0.90757698]\n",
      "  [0.90690649]\n",
      "  [0.90545303]\n",
      "  [0.90277874]\n",
      "  [0.90132636]\n",
      "  [0.90064991]\n",
      "  [0.89883339]\n",
      "  [0.89688146]]]\n",
      "ejemplar: [0.90757698 0.90690649 0.90545303 0.90277874 0.90132636 0.90064991\n",
      " 0.89883339 0.89688146]\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.8960179]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[0.90757698 0.90690649 0.90545303 0.90277874 0.90132636 0.90064991\n",
      "  0.89883339 0.89688146]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004408927168697119\n",
      "Predicción post entrenamiento : [[0.89699864]]\n",
      "PERDIDAAAA despues: 0.004279647953808308\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "[[[0.90690649]\n",
      "  [0.90545303]\n",
      "  [0.90277874]\n",
      "  [0.90132636]\n",
      "  [0.90064991]\n",
      "  [0.89883339]\n",
      "  [0.89688146]\n",
      "  [0.89601791]]]\n",
      "ejemplar: [0.90690649 0.90545303 0.90277874 0.90132636 0.90064991 0.89883339\n",
      " 0.89688146 0.89601791]\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.8957444]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[0.90690649 0.90545303 0.90277874 0.90132636 0.90064991 0.89883339\n",
      "  0.89688146 0.89601791]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005198055412620306\n",
      "Predicción post entrenamiento : [[0.8959868]]\n",
      "PERDIDAAAA despues: 0.005163159221410751\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "[[[0.90545303]\n",
      "  [0.90277874]\n",
      "  [0.90132636]\n",
      "  [0.90064991]\n",
      "  [0.89883339]\n",
      "  [0.89688146]\n",
      "  [0.89601791]\n",
      "  [0.89574438]]]\n",
      "ejemplar: [0.90545303 0.90277874 0.90132636 0.90064991 0.89883339 0.89688146\n",
      " 0.89601791 0.89574438]\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.89450085]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[0.90545303 0.90277874 0.90132636 0.90064991 0.89883339 0.89688146\n",
      "  0.89601791 0.89574438]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0021362723782658577\n",
      "Predicción post entrenamiento : [[0.8952246]]\n",
      "PERDIDAAAA despues: 0.0020698956213891506\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "[[[0.90277874]\n",
      "  [0.90132636]\n",
      "  [0.90064991]\n",
      "  [0.89883339]\n",
      "  [0.89688146]\n",
      "  [0.89601791]\n",
      "  [0.89574438]\n",
      "  [0.89450085]]]\n",
      "ejemplar: [0.90277874 0.90132636 0.90064991 0.89883339 0.89688146 0.89601791\n",
      " 0.89574438 0.89450085]\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.8937206]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[0.90277874 0.90132636 0.90064991 0.89883339 0.89688146 0.89601791\n",
      "  0.89574438 0.89450085]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006204813253134489\n",
      "Predicción post entrenamiento : [[0.893914]]\n",
      "PERDIDAAAA despues: 0.006174388807266951\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "[[[0.90132636]\n",
      "  [0.90064991]\n",
      "  [0.89883339]\n",
      "  [0.89688146]\n",
      "  [0.89601791]\n",
      "  [0.89574438]\n",
      "  [0.89450085]\n",
      "  [0.89372063]]]\n",
      "ejemplar: [0.90132636 0.90064991 0.89883339 0.89688146 0.89601791 0.89574438\n",
      " 0.89450085 0.89372063]\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.89277345]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[0.90132636 0.90064991 0.89883339 0.89688146 0.89601791 0.89574438\n",
      "  0.89450085 0.89372063]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010842430405318737\n",
      "Predicción post entrenamiento : [[0.8929874]]\n",
      "PERDIDAAAA despues: 0.010797926224768162\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "[[[0.90064991]\n",
      "  [0.89883339]\n",
      "  [0.89688146]\n",
      "  [0.89601791]\n",
      "  [0.89574438]\n",
      "  [0.89450085]\n",
      "  [0.89372063]\n",
      "  [0.89277345]]]\n",
      "ejemplar: [0.90064991 0.89883339 0.89688146 0.89601791 0.89574438 0.89450085\n",
      " 0.89372063 0.89277345]\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.89192194]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[0.90064991 0.89883339 0.89688146 0.89601791 0.89574438 0.89450085\n",
      "  0.89372063 0.89277345]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003511720569804311\n",
      "Predicción post entrenamiento : [[0.8924834]]\n",
      "PERDIDAAAA despues: 0.0034454900305718184\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "[[[0.89883339]\n",
      "  [0.89688146]\n",
      "  [0.89601791]\n",
      "  [0.89574438]\n",
      "  [0.89450085]\n",
      "  [0.89372063]\n",
      "  [0.89277345]\n",
      "  [0.89192194]]]\n",
      "ejemplar: [0.89883339 0.89688146 0.89601791 0.89574438 0.89450085 0.89372063\n",
      " 0.89277345 0.89192194]\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.8912902]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[0.89883339 0.89688146 0.89601791 0.89574438 0.89450085 0.89372063\n",
      "  0.89277345 0.89192194]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.0129762560827658e-05\n",
      "Predicción post entrenamiento : [[0.89028573]]\n",
      "PERDIDAAAA despues: 3.0151935789035633e-05\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "[[[0.89688146]\n",
      "  [0.89601791]\n",
      "  [0.89574438]\n",
      "  [0.89450085]\n",
      "  [0.89372063]\n",
      "  [0.89277345]\n",
      "  [0.89192194]\n",
      "  [0.89129019]]]\n",
      "ejemplar: [0.89688146 0.89601791 0.89574438 0.89450085 0.89372063 0.89277345\n",
      " 0.89192194 0.89129019]\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.8892993]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[0.89688146 0.89601791 0.89574438 0.89450085 0.89372063 0.89277345\n",
      "  0.89192194 0.89129019]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.174782174639404e-05\n",
      "Predicción post entrenamiento : [[0.8899846]]\n",
      "PERDIDAAAA despues: 7.29881867300719e-05\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "[[[0.89601791]\n",
      "  [0.89574438]\n",
      "  [0.89450085]\n",
      "  [0.89372063]\n",
      "  [0.89277345]\n",
      "  [0.89192194]\n",
      "  [0.89129019]\n",
      "  [0.88929927]]]\n",
      "ejemplar: [0.89601791 0.89574438 0.89450085 0.89372063 0.89277345 0.89192194\n",
      " 0.89129019 0.88929927]\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.8892809]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[0.89601791 0.89574438 0.89450085 0.89372063 0.89277345 0.89192194\n",
      "  0.89129019 0.88929927]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007731462246738374\n",
      "Predicción post entrenamiento : [[0.8889878]]\n",
      "PERDIDAAAA despues: 0.0007895337184891105\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "[[[0.89574438]\n",
      "  [0.89450085]\n",
      "  [0.89372063]\n",
      "  [0.89277345]\n",
      "  [0.89192194]\n",
      "  [0.89129019]\n",
      "  [0.88929927]\n",
      "  [0.88928092]]]\n",
      "ejemplar: [0.89574438 0.89450085 0.89372063 0.89277345 0.89192194 0.89129019\n",
      " 0.88929927 0.88928092]\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.888288]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[0.89574438 0.89450085 0.89372063 0.89277345 0.89192194 0.89129019\n",
      "  0.88929927 0.88928092]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009929136140272021\n",
      "Predicción post entrenamiento : [[0.88833624]]\n",
      "PERDIDAAAA despues: 0.0009898770367726684\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "[[[0.89450085]\n",
      "  [0.89372063]\n",
      "  [0.89277345]\n",
      "  [0.89192194]\n",
      "  [0.89129019]\n",
      "  [0.88929927]\n",
      "  [0.88928092]\n",
      "  [0.88828802]]]\n",
      "ejemplar: [0.89450085 0.89372063 0.89277345 0.89192194 0.89129019 0.88929927\n",
      " 0.88928092 0.88828802]\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.8874636]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[0.89450085 0.89372063 0.89277345 0.89192194 0.89129019 0.88929927\n",
      "  0.88928092 0.88828802]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0055025494657456875\n",
      "Predicción post entrenamiento : [[0.8878639]]\n",
      "PERDIDAAAA despues: 0.0054433299228549\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "[[[0.89372063]\n",
      "  [0.89277345]\n",
      "  [0.89192194]\n",
      "  [0.89129019]\n",
      "  [0.88929927]\n",
      "  [0.88928092]\n",
      "  [0.88828802]\n",
      "  [0.88746363]]]\n",
      "ejemplar: [0.89372063 0.89277345 0.89192194 0.89129019 0.88929927 0.88928092\n",
      " 0.88828802 0.88746363]\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.8870782]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[0.89372063 0.89277345 0.89192194 0.89129019 0.88929927 0.88928092\n",
      "  0.88828802 0.88746363]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006585505325347185\n",
      "Predicción post entrenamiento : [[0.887727]]\n",
      "PERDIDAAAA despues: 0.006480625364929438\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "[[[0.89277345]\n",
      "  [0.89192194]\n",
      "  [0.89129019]\n",
      "  [0.88929927]\n",
      "  [0.88928092]\n",
      "  [0.88828802]\n",
      "  [0.88746363]\n",
      "  [0.88707823]]]\n",
      "ejemplar: [0.89277345 0.89192194 0.89129019 0.88929927 0.88928092 0.88828802\n",
      " 0.88746363 0.88707823]\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.8869103]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[0.89277345 0.89192194 0.89129019 0.88929927 0.88928092 0.88828802\n",
      "  0.88746363 0.88707823]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005020856391638517\n",
      "Predicción post entrenamiento : [[0.886615]]\n",
      "PERDIDAAAA despues: 0.005062798038125038\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "[[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "ejemplar: [0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      " 0.03448276 0.04223169]\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.24022761]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      "  0.03448276 0.04223169]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03768313676118851\n",
      "Predicción post entrenamiento : [[0.19527513]]\n",
      "PERDIDAAAA despues: 0.02225138060748577\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "[[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24022761]]]\n",
      "ejemplar: [0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      " 0.04223169 0.24022761]\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.17972137]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      "  0.04223169 0.24022761]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005699978210031986\n",
      "Predicción post entrenamiento : [[0.16348211]]\n",
      "PERDIDAAAA despues: 0.0035116225481033325\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "[[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24022761]\n",
      "  [0.17972137]]]\n",
      "ejemplar: [0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      " 0.24022761 0.17972137]\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.1673434]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      "  0.24022761 0.17972137]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00017264884081669152\n",
      "Predicción post entrenamiento : [[0.16616048]]\n",
      "PERDIDAAAA despues: 0.00014296211884357035\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "[[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24022761]\n",
      "  [0.17972137]\n",
      "  [0.16734339]]]\n",
      "ejemplar: [0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.24022761\n",
      " 0.17972137 0.16734339]\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.1772206]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.24022761\n",
      "  0.17972137 0.16734339]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004608327290043235\n",
      "Predicción post entrenamiento : [[0.17619051]]\n",
      "PERDIDAAAA despues: 0.00041766802314668894\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "[[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24022761]\n",
      "  [0.17972137]\n",
      "  [0.16734339]\n",
      "  [0.1772206 ]]]\n",
      "ejemplar: [0.05656722 0.02595893 0.03448276 0.04223169 0.24022761 0.17972137\n",
      " 0.16734339 0.1772206 ]\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.18818755]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[0.05656722 0.02595893 0.03448276 0.04223169 0.24022761 0.17972137\n",
      "  0.16734339 0.1772206 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003925624769181013\n",
      "Predicción post entrenamiento : [[0.18173328]]\n",
      "PERDIDAAAA despues: 0.003158499952405691\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "[[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24022761]\n",
      "  [0.17972137]\n",
      "  [0.16734339]\n",
      "  [0.1772206 ]\n",
      "  [0.18818755]]]\n",
      "ejemplar: [0.02595893 0.03448276 0.04223169 0.24022761 0.17972137 0.16734339\n",
      " 0.1772206  0.18818755]\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.1906873]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[0.02595893 0.03448276 0.04223169 0.24022761 0.17972137 0.16734339\n",
      "  0.1772206  0.18818755]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002025660127401352\n",
      "Predicción post entrenamiento : [[0.18372136]]\n",
      "PERDIDAAAA despues: 0.001447147922590375\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "[[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.24022761]\n",
      "  [0.17972137]\n",
      "  [0.16734339]\n",
      "  [0.1772206 ]\n",
      "  [0.18818755]\n",
      "  [0.1906873 ]]]\n",
      "ejemplar: [0.03448276 0.04223169 0.24022761 0.17972137 0.16734339 0.1772206\n",
      " 0.18818755 0.1906873 ]\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.20317683]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[0.03448276 0.04223169 0.24022761 0.17972137 0.16734339 0.1772206\n",
      "  0.18818755 0.1906873 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00321738189086318\n",
      "Predicción post entrenamiento : [[0.20163998]]\n",
      "PERDIDAAAA despues: 0.0030453980434685946\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "[[[0.04223169]\n",
      "  [0.24022761]\n",
      "  [0.17972137]\n",
      "  [0.16734339]\n",
      "  [0.1772206 ]\n",
      "  [0.18818755]\n",
      "  [0.1906873 ]\n",
      "  [0.20317683]]]\n",
      "ejemplar: [0.04223169 0.24022761 0.17972137 0.16734339 0.1772206  0.18818755\n",
      " 0.1906873  0.20317683]\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.22508004]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[0.04223169 0.24022761 0.17972137 0.16734339 0.1772206  0.18818755\n",
      "  0.1906873  0.20317683]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008428574074059725\n",
      "Predicción post entrenamiento : [[0.22176144]]\n",
      "PERDIDAAAA despues: 0.0006611788994632661\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "[[[0.24022761]\n",
      "  [0.17972137]\n",
      "  [0.16734339]\n",
      "  [0.1772206 ]\n",
      "  [0.18818755]\n",
      "  [0.1906873 ]\n",
      "  [0.20317683]\n",
      "  [0.22508004]]]\n",
      "ejemplar: [0.24022761 0.17972137 0.16734339 0.1772206  0.18818755 0.1906873\n",
      " 0.20317683 0.22508004]\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.24943806]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[0.24022761 0.17972137 0.16734339 0.1772206  0.18818755 0.1906873\n",
      "  0.20317683 0.22508004]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003574846195988357\n",
      "Predicción post entrenamiento : [[0.2454399]]\n",
      "PERDIDAAAA despues: 0.00022228136367630213\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "[[[0.17972137]\n",
      "  [0.16734339]\n",
      "  [0.1772206 ]\n",
      "  [0.18818755]\n",
      "  [0.1906873 ]\n",
      "  [0.20317683]\n",
      "  [0.22508004]\n",
      "  [0.24943806]]]\n",
      "ejemplar: [0.17972137 0.16734339 0.1772206  0.18818755 0.1906873  0.20317683\n",
      " 0.22508004 0.24943806]\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.23542687]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[0.17972137 0.16734339 0.1772206  0.18818755 0.1906873  0.20317683\n",
      "  0.22508004 0.24943806]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007279491983354092\n",
      "Predicción post entrenamiento : [[0.2338695]]\n",
      "PERDIDAAAA despues: 0.0006463367608375847\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "[[[0.16734339]\n",
      "  [0.1772206 ]\n",
      "  [0.18818755]\n",
      "  [0.1906873 ]\n",
      "  [0.20317683]\n",
      "  [0.22508004]\n",
      "  [0.24943806]\n",
      "  [0.23542687]]]\n",
      "ejemplar: [0.16734339 0.1772206  0.18818755 0.1906873  0.20317683 0.22508004\n",
      " 0.24943806 0.23542687]\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.23623152]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[0.16734339 0.1772206  0.18818755 0.1906873  0.20317683 0.22508004\n",
      "  0.24943806 0.23542687]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005904006538912654\n",
      "Predicción post entrenamiento : [[0.23587078]]\n",
      "PERDIDAAAA despues: 0.0005730000557377934\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "[[[0.1772206 ]\n",
      "  [0.18818755]\n",
      "  [0.1906873 ]\n",
      "  [0.20317683]\n",
      "  [0.22508004]\n",
      "  [0.24943806]\n",
      "  [0.23542687]\n",
      "  [0.23623152]]]\n",
      "ejemplar: [0.1772206  0.18818755 0.1906873  0.20317683 0.22508004 0.24943806\n",
      " 0.23542687 0.23623152]\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.24247724]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[0.1772206  0.18818755 0.1906873  0.20317683 0.22508004 0.24943806\n",
      "  0.23542687 0.23623152]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001238563796505332\n",
      "Predicción post entrenamiento : [[0.24308826]]\n",
      "PERDIDAAAA despues: 0.001281944802030921\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "[[[0.18818755]\n",
      "  [0.1906873 ]\n",
      "  [0.20317683]\n",
      "  [0.22508004]\n",
      "  [0.24943806]\n",
      "  [0.23542687]\n",
      "  [0.23623152]\n",
      "  [0.24247724]]]\n",
      "ejemplar: [0.18818755 0.1906873  0.20317683 0.22508004 0.24943806 0.23542687\n",
      " 0.23623152 0.24247724]\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.24977635]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[0.18818755 0.1906873  0.20317683 0.22508004 0.24943806 0.23542687\n",
      "  0.23623152 0.24247724]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0032294071279466152\n",
      "Predicción post entrenamiento : [[0.24829455]]\n",
      "PERDIDAAAA despues: 0.003063187701627612\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "[[[0.1906873 ]\n",
      "  [0.20317683]\n",
      "  [0.22508004]\n",
      "  [0.24943806]\n",
      "  [0.23542687]\n",
      "  [0.23623152]\n",
      "  [0.24247724]\n",
      "  [0.24977635]]]\n",
      "ejemplar: [0.1906873  0.20317683 0.22508004 0.24943806 0.23542687 0.23623152\n",
      " 0.24247724 0.24977635]\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.2546884]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[0.1906873  0.20317683 0.22508004 0.24943806 0.23542687 0.23623152\n",
      "  0.24247724 0.24977635]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0033484126906841993\n",
      "Predicción post entrenamiento : [[0.2526559]]\n",
      "PERDIDAAAA despues: 0.0031173184979707003\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "[[[0.20317683]\n",
      "  [0.22508004]\n",
      "  [0.24943806]\n",
      "  [0.23542687]\n",
      "  [0.23623152]\n",
      "  [0.24247724]\n",
      "  [0.24977635]\n",
      "  [0.25468841]]]\n",
      "ejemplar: [0.20317683 0.22508004 0.24943806 0.23542687 0.23623152 0.24247724\n",
      " 0.24977635 0.25468841]\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.2604239]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[0.20317683 0.22508004 0.24943806 0.23542687 0.23623152 0.24247724\n",
      "  0.24977635 0.25468841]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0021312860772013664\n",
      "Predicción post entrenamiento : [[0.2590648]]\n",
      "PERDIDAAAA despues: 0.00200764462351799\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "[[[0.22508004]\n",
      "  [0.24943806]\n",
      "  [0.23542687]\n",
      "  [0.23623152]\n",
      "  [0.24247724]\n",
      "  [0.24977635]\n",
      "  [0.25468841]\n",
      "  [0.2604239 ]]]\n",
      "ejemplar: [0.22508004 0.24943806 0.23542687 0.23623152 0.24247724 0.24977635\n",
      " 0.25468841 0.2604239 ]\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.26604667]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[0.22508004 0.24943806 0.23542687 0.23623152 0.24247724 0.24977635\n",
      "  0.25468841 0.2604239 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007177751045674086\n",
      "Predicción post entrenamiento : [[0.26120263]]\n",
      "PERDIDAAAA despues: 0.0063804262317717075\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "[[[0.24943806]\n",
      "  [0.23542687]\n",
      "  [0.23623152]\n",
      "  [0.24247724]\n",
      "  [0.24977635]\n",
      "  [0.25468841]\n",
      "  [0.2604239 ]\n",
      "  [0.26604667]]]\n",
      "ejemplar: [0.24943806 0.23542687 0.23623152 0.24247724 0.24977635 0.25468841\n",
      " 0.2604239  0.26604667]\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.2649744]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[0.24943806 0.23542687 0.23623152 0.24247724 0.24977635 0.25468841\n",
      "  0.2604239  0.26604667]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008072745986282825\n",
      "Predicción post entrenamiento : [[0.2617276]]\n",
      "PERDIDAAAA despues: 0.0074998498894274235\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "[[[0.23542687]\n",
      "  [0.23623152]\n",
      "  [0.24247724]\n",
      "  [0.24977635]\n",
      "  [0.25468841]\n",
      "  [0.2604239 ]\n",
      "  [0.26604667]\n",
      "  [0.26497439]]]\n",
      "ejemplar: [0.23542687 0.23623152 0.24247724 0.24977635 0.25468841 0.2604239\n",
      " 0.26604667 0.26497439]\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.2611302]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[0.23542687 0.23623152 0.24247724 0.24977635 0.25468841 0.2604239\n",
      "  0.26604667 0.26497439]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012797392904758453\n",
      "Predicción post entrenamiento : [[0.25882715]]\n",
      "PERDIDAAAA despues: 0.012281626462936401\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "[[[0.23623152]\n",
      "  [0.24247724]\n",
      "  [0.24977635]\n",
      "  [0.25468841]\n",
      "  [0.2604239 ]\n",
      "  [0.26604667]\n",
      "  [0.26497439]\n",
      "  [0.26113021]]]\n",
      "ejemplar: [0.23623152 0.24247724 0.24977635 0.25468841 0.2604239  0.26604667\n",
      " 0.26497439 0.26113021]\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.26172277]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[0.23623152 0.24247724 0.24977635 0.25468841 0.2604239  0.26604667\n",
      "  0.26497439 0.26113021]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010582157410681248\n",
      "Predicción post entrenamiento : [[0.25944787]]\n",
      "PERDIDAAAA despues: 0.010119296610355377\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "[[[0.24247724]\n",
      "  [0.24977635]\n",
      "  [0.25468841]\n",
      "  [0.2604239 ]\n",
      "  [0.26604667]\n",
      "  [0.26497439]\n",
      "  [0.26113021]\n",
      "  [0.26172277]]]\n",
      "ejemplar: [0.24247724 0.24977635 0.25468841 0.2604239  0.26604667 0.26497439\n",
      " 0.26113021 0.26172277]\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.2630786]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[0.24247724 0.24977635 0.25468841 0.2604239  0.26604667 0.26497439\n",
      "  0.26113021 0.26172277]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005027523264288902\n",
      "Predicción post entrenamiento : [[0.26009157]]\n",
      "PERDIDAAAA despues: 0.004612855147570372\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "[[[0.24977635]\n",
      "  [0.25468841]\n",
      "  [0.2604239 ]\n",
      "  [0.26604667]\n",
      "  [0.26497439]\n",
      "  [0.26113021]\n",
      "  [0.26172277]\n",
      "  [0.2630786 ]]]\n",
      "ejemplar: [0.24977635 0.25468841 0.2604239  0.26604667 0.26497439 0.26113021\n",
      " 0.26172277 0.2630786 ]\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.26324195]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[0.24977635 0.25468841 0.2604239  0.26604667 0.26497439 0.26113021\n",
      "  0.26172277 0.2630786 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00597026851028204\n",
      "Predicción post entrenamiento : [[0.2624536]]\n",
      "PERDIDAAAA despues: 0.005849060602486134\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "[[[0.25468841]\n",
      "  [0.2604239 ]\n",
      "  [0.26604667]\n",
      "  [0.26497439]\n",
      "  [0.26113021]\n",
      "  [0.26172277]\n",
      "  [0.2630786 ]\n",
      "  [0.26324195]]]\n",
      "ejemplar: [0.25468841 0.2604239  0.26604667 0.26497439 0.26113021 0.26172277\n",
      " 0.2630786  0.26324195]\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.2646813]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[0.25468841 0.2604239  0.26604667 0.26497439 0.26113021 0.26172277\n",
      "  0.2630786  0.26324195]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.150524430064252e-06\n",
      "Predicción post entrenamiento : [[0.2645914]]\n",
      "PERDIDAAAA despues: 5.566722393268719e-06\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "[[[0.2604239 ]\n",
      "  [0.26604667]\n",
      "  [0.26497439]\n",
      "  [0.26113021]\n",
      "  [0.26172277]\n",
      "  [0.2630786 ]\n",
      "  [0.26324195]\n",
      "  [0.26468131]]]\n",
      "ejemplar: [0.2604239  0.26604667 0.26497439 0.26113021 0.26172277 0.2630786\n",
      " 0.26324195 0.26468131]\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.26618117]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[0.2604239  0.26604667 0.26497439 0.26113021 0.26172277 0.2630786\n",
      "  0.26324195 0.26468131]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006938541191630065\n",
      "Predicción post entrenamiento : [[0.2668982]]\n",
      "PERDIDAAAA despues: 0.000656592776067555\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "[[[0.26604667]\n",
      "  [0.26497439]\n",
      "  [0.26113021]\n",
      "  [0.26172277]\n",
      "  [0.2630786 ]\n",
      "  [0.26324195]\n",
      "  [0.26468131]\n",
      "  [0.26618117]]]\n",
      "ejemplar: [0.26604667 0.26497439 0.26113021 0.26172277 0.2630786  0.26324195\n",
      " 0.26468131 0.26618117]\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.26750302]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[0.26604667 0.26497439 0.26113021 0.26172277 0.2630786  0.26324195\n",
      "  0.26468131 0.26618117]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00252037076279521\n",
      "Predicción post entrenamiento : [[0.2683956]]\n",
      "PERDIDAAAA despues: 0.0024315465707331896\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "[[[0.26497439]\n",
      "  [0.26113021]\n",
      "  [0.26172277]\n",
      "  [0.2630786 ]\n",
      "  [0.26324195]\n",
      "  [0.26468131]\n",
      "  [0.26618117]\n",
      "  [0.26750302]]]\n",
      "ejemplar: [0.26497439 0.26113021 0.26172277 0.2630786  0.26324195 0.26468131\n",
      " 0.26618117 0.26750302]\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.26786828]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[0.26497439 0.26113021 0.26172277 0.2630786  0.26324195 0.26468131\n",
      "  0.26618117 0.26750302]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0020071507897228003\n",
      "Predicción post entrenamiento : [[0.26971123]]\n",
      "PERDIDAAAA despues: 0.0018454146338626742\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "[[[0.26113021]\n",
      "  [0.26172277]\n",
      "  [0.2630786 ]\n",
      "  [0.26324195]\n",
      "  [0.26468131]\n",
      "  [0.26618117]\n",
      "  [0.26750302]\n",
      "  [0.26786828]]]\n",
      "ejemplar: [0.26113021 0.26172277 0.2630786  0.26324195 0.26468131 0.26618117\n",
      " 0.26750302 0.26786828]\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.26940286]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[0.26113021 0.26172277 0.2630786  0.26324195 0.26468131 0.26618117\n",
      "  0.26750302 0.26786828]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00038543110713362694\n",
      "Predicción post entrenamiento : [[0.26927114]]\n",
      "PERDIDAAAA despues: 0.0003906206402461976\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "[[[0.26172277]\n",
      "  [0.2630786 ]\n",
      "  [0.26324195]\n",
      "  [0.26468131]\n",
      "  [0.26618117]\n",
      "  [0.26750302]\n",
      "  [0.26786828]\n",
      "  [0.26940286]]]\n",
      "ejemplar: [0.26172277 0.2630786  0.26324195 0.26468131 0.26618117 0.26750302\n",
      " 0.26786828 0.26940286]\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.2698841]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[0.26172277 0.2630786  0.26324195 0.26468131 0.26618117 0.26750302\n",
      "  0.26786828 0.26940286]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00016775430412963033\n",
      "Predicción post entrenamiento : [[0.26882008]]\n",
      "PERDIDAAAA despues: 0.00019644915300887078\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "[[[0.2630786 ]\n",
      "  [0.26324195]\n",
      "  [0.26468131]\n",
      "  [0.26618117]\n",
      "  [0.26750302]\n",
      "  [0.26786828]\n",
      "  [0.26940286]\n",
      "  [0.26988411]]]\n",
      "ejemplar: [0.2630786  0.26324195 0.26468131 0.26618117 0.26750302 0.26786828\n",
      " 0.26940286 0.26988411]\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.26952353]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[0.2630786  0.26324195 0.26468131 0.26618117 0.26750302 0.26786828\n",
      "  0.26940286 0.26988411]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000898368249181658\n",
      "Predicción post entrenamiento : [[0.26910663]]\n",
      "PERDIDAAAA despues: 0.0009235336328856647\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "[[[0.26324195]\n",
      "  [0.26468131]\n",
      "  [0.26618117]\n",
      "  [0.26750302]\n",
      "  [0.26786828]\n",
      "  [0.26940286]\n",
      "  [0.26988411]\n",
      "  [0.26952353]]]\n",
      "ejemplar: [0.26324195 0.26468131 0.26618117 0.26750302 0.26786828 0.26940286\n",
      " 0.26988411 0.26952353]\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.26973733]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[0.26324195 0.26468131 0.26618117 0.26750302 0.26786828 0.26940286\n",
      "  0.26988411 0.26952353]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.751237818505615e-05\n",
      "Predicción post entrenamiento : [[0.26874378]]\n",
      "PERDIDAAAA despues: 5.066997618996538e-05\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "[[[0.26468131]\n",
      "  [0.26618117]\n",
      "  [0.26750302]\n",
      "  [0.26786828]\n",
      "  [0.26940286]\n",
      "  [0.26988411]\n",
      "  [0.26952353]\n",
      "  [0.26973733]]]\n",
      "ejemplar: [0.26468131 0.26618117 0.26750302 0.26786828 0.26940286 0.26988411\n",
      " 0.26952353 0.26973733]\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.26954442]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[0.26468131 0.26618117 0.26750302 0.26786828 0.26940286 0.26988411\n",
      "  0.26952353 0.26973733]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.6577068638289347e-05\n",
      "Predicción post entrenamiento : [[0.26984525]]\n",
      "PERDIDAAAA despues: 2.356588447582908e-05\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "[[[0.26618117]\n",
      "  [0.26750302]\n",
      "  [0.26786828]\n",
      "  [0.26940286]\n",
      "  [0.26988411]\n",
      "  [0.26952353]\n",
      "  [0.26973733]\n",
      "  [0.26954442]]]\n",
      "ejemplar: [0.26618117 0.26750302 0.26786828 0.26940286 0.26988411 0.26952353\n",
      " 0.26973733 0.26954442]\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.27053508]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[0.26618117 0.26750302 0.26786828 0.26940286 0.26988411 0.26952353\n",
      "  0.26973733 0.26954442]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.439891977701336e-05\n",
      "Predicción post entrenamiento : [[0.2707715]]\n",
      "PERDIDAAAA despues: 2.211919127148576e-05\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "[[[0.26750302]\n",
      "  [0.26786828]\n",
      "  [0.26940286]\n",
      "  [0.26988411]\n",
      "  [0.26952353]\n",
      "  [0.26973733]\n",
      "  [0.26954442]\n",
      "  [0.27053508]]]\n",
      "ejemplar: [0.26750302 0.26786828 0.26940286 0.26988411 0.26952353 0.26973733\n",
      " 0.26954442 0.27053508]\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.27129698]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[0.26750302 0.26786828 0.26940286 0.26988411 0.26952353 0.26973733\n",
      "  0.26954442 0.27053508]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004026788752526045\n",
      "Predicción post entrenamiento : [[0.27214587]]\n",
      "PERDIDAAAA despues: 0.003919773269444704\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "[[[0.26786828]\n",
      "  [0.26940286]\n",
      "  [0.26988411]\n",
      "  [0.26952353]\n",
      "  [0.26973733]\n",
      "  [0.26954442]\n",
      "  [0.27053508]\n",
      "  [0.27129698]]]\n",
      "ejemplar: [0.26786828 0.26940286 0.26988411 0.26952353 0.26973733 0.26954442\n",
      " 0.27053508 0.27129698]\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.27250692]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[0.26786828 0.26940286 0.26988411 0.26952353 0.26973733 0.26954442\n",
      "  0.27053508 0.27129698]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006917109712958336\n",
      "Predicción post entrenamiento : [[0.2734367]]\n",
      "PERDIDAAAA despues: 0.006763317156583071\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "[[[0.26940286]\n",
      "  [0.26988411]\n",
      "  [0.26952353]\n",
      "  [0.26973733]\n",
      "  [0.26954442]\n",
      "  [0.27053508]\n",
      "  [0.27129698]\n",
      "  [0.27250692]]]\n",
      "ejemplar: [0.26940286 0.26988411 0.26952353 0.26973733 0.26954442 0.27053508\n",
      " 0.27129698 0.27250692]\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.2738198]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[0.26940286 0.26988411 0.26952353 0.26973733 0.26954442 0.27053508\n",
      "  0.27129698 0.27250692]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0039528124034404755\n",
      "Predicción post entrenamiento : [[0.2748761]]\n",
      "PERDIDAAAA despues: 0.0038211082573980093\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "[[[0.26988411]\n",
      "  [0.26952353]\n",
      "  [0.26973733]\n",
      "  [0.26954442]\n",
      "  [0.27053508]\n",
      "  [0.27129698]\n",
      "  [0.27250692]\n",
      "  [0.2738198 ]]]\n",
      "ejemplar: [0.26988411 0.26952353 0.26973733 0.26954442 0.27053508 0.27129698\n",
      " 0.27250692 0.2738198 ]\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.2750282]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[0.26988411 0.26952353 0.26973733 0.26954442 0.27053508 0.27129698\n",
      "  0.27250692 0.2738198 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003429676638916135\n",
      "Predicción post entrenamiento : [[0.27606913]]\n",
      "PERDIDAAAA despues: 0.0033088386990129948\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "[[[0.26952353]\n",
      "  [0.26973733]\n",
      "  [0.26954442]\n",
      "  [0.27053508]\n",
      "  [0.27129698]\n",
      "  [0.27250692]\n",
      "  [0.2738198 ]\n",
      "  [0.2750282 ]]]\n",
      "ejemplar: [0.26952353 0.26973733 0.26954442 0.27053508 0.27129698 0.27250692\n",
      " 0.2738198  0.2750282 ]\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.27620748]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[0.26952353 0.26973733 0.26954442 0.27053508 0.27129698 0.27250692\n",
      "  0.2738198  0.2750282 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01177813671529293\n",
      "Predicción post entrenamiento : [[0.27790627]]\n",
      "PERDIDAAAA despues: 0.011412292718887329\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "[[[0.26973733]\n",
      "  [0.26954442]\n",
      "  [0.27053508]\n",
      "  [0.27129698]\n",
      "  [0.27250692]\n",
      "  [0.2738198 ]\n",
      "  [0.2750282 ]\n",
      "  [0.27620748]]]\n",
      "ejemplar: [0.26973733 0.26954442 0.27053508 0.27129698 0.27250692 0.2738198\n",
      " 0.2750282  0.27620748]\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.27824277]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[0.26973733 0.26954442 0.27053508 0.27129698 0.27250692 0.2738198\n",
      "  0.2750282  0.27620748]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08576329797506332\n",
      "Predicción post entrenamiento : [[0.28218648]]\n",
      "PERDIDAAAA despues: 0.08346898853778839\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "[[[0.26954442]\n",
      "  [0.27053508]\n",
      "  [0.27129698]\n",
      "  [0.27250692]\n",
      "  [0.2738198 ]\n",
      "  [0.2750282 ]\n",
      "  [0.27620748]\n",
      "  [0.27824277]]]\n",
      "ejemplar: [0.26954442 0.27053508 0.27129698 0.27250692 0.2738198  0.2750282\n",
      " 0.27620748 0.27824277]\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.28264922]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[0.26954442 0.27053508 0.27129698 0.27250692 0.2738198  0.2750282\n",
      "  0.27620748 0.27824277]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09836459159851074\n",
      "Predicción post entrenamiento : [[0.2866656]]\n",
      "PERDIDAAAA despues: 0.09586140513420105\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "[[[0.27053508]\n",
      "  [0.27129698]\n",
      "  [0.27250692]\n",
      "  [0.2738198 ]\n",
      "  [0.2750282 ]\n",
      "  [0.27620748]\n",
      "  [0.27824277]\n",
      "  [0.28264922]]]\n",
      "ejemplar: [0.27053508 0.27129698 0.27250692 0.2738198  0.2750282  0.27620748\n",
      " 0.27824277 0.28264922]\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.2874024]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[0.27053508 0.27129698 0.27250692 0.2738198  0.2750282  0.27620748\n",
      "  0.27824277 0.28264922]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08247297257184982\n",
      "Predicción post entrenamiento : [[0.29091224]]\n",
      "PERDIDAAAA despues: 0.08046936988830566\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "[[[0.27129698]\n",
      "  [0.27250692]\n",
      "  [0.2738198 ]\n",
      "  [0.2750282 ]\n",
      "  [0.27620748]\n",
      "  [0.27824277]\n",
      "  [0.28264922]\n",
      "  [0.28740239]]]\n",
      "ejemplar: [0.27129698 0.27250692 0.2738198  0.2750282  0.27620748 0.27824277\n",
      " 0.28264922 0.28740239]\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.29174653]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[0.27129698 0.27250692 0.2738198  0.2750282  0.27620748 0.27824277\n",
      "  0.28264922 0.28740239]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0989779382944107\n",
      "Predicción post entrenamiento : [[0.29561982]]\n",
      "PERDIDAAAA despues: 0.09655580669641495\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "[[[0.27250692]\n",
      "  [0.2738198 ]\n",
      "  [0.2750282 ]\n",
      "  [0.27620748]\n",
      "  [0.27824277]\n",
      "  [0.28264922]\n",
      "  [0.28740239]\n",
      "  [0.29174653]]]\n",
      "ejemplar: [0.27250692 0.2738198  0.2750282  0.27620748 0.27824277 0.28264922\n",
      " 0.28740239 0.29174653]\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.29667827]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[0.27250692 0.2738198  0.2750282  0.27620748 0.27824277 0.28264922\n",
      "  0.28740239 0.29174653]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08293182402849197\n",
      "Predicción post entrenamiento : [[0.30007267]]\n",
      "PERDIDAAAA despues: 0.0809883177280426\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "[[[0.2738198 ]\n",
      "  [0.2750282 ]\n",
      "  [0.27620748]\n",
      "  [0.27824277]\n",
      "  [0.28264922]\n",
      "  [0.28740239]\n",
      "  [0.29174653]\n",
      "  [0.29667827]]]\n",
      "ejemplar: [0.2738198  0.2750282  0.27620748 0.27824277 0.28264922 0.28740239\n",
      " 0.29174653 0.29667827]\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.30135843]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[0.2738198  0.2750282  0.27620748 0.27824277 0.28264922 0.28740239\n",
      "  0.29174653 0.29667827]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07150989770889282\n",
      "Predicción post entrenamiento : [[0.3046175]]\n",
      "PERDIDAAAA despues: 0.0697774887084961\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "[[[0.2750282 ]\n",
      "  [0.27620748]\n",
      "  [0.27824277]\n",
      "  [0.28264922]\n",
      "  [0.28740239]\n",
      "  [0.29174653]\n",
      "  [0.29667827]\n",
      "  [0.30135843]]]\n",
      "ejemplar: [0.2750282  0.27620748 0.27824277 0.28264922 0.28740239 0.29174653\n",
      " 0.29667827 0.30135843]\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.30621502]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[0.2750282  0.27620748 0.27824277 0.28264922 0.28740239 0.29174653\n",
      "  0.29667827 0.30135843]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11327201873064041\n",
      "Predicción post entrenamiento : [[0.310263]]\n",
      "PERDIDAAAA despues: 0.11056362837553024\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "[[[0.27620748]\n",
      "  [0.27824277]\n",
      "  [0.28264922]\n",
      "  [0.28740239]\n",
      "  [0.29174653]\n",
      "  [0.29667827]\n",
      "  [0.30135843]\n",
      "  [0.30621502]]]\n",
      "ejemplar: [0.27620748 0.27824277 0.28264922 0.28740239 0.29174653 0.29667827\n",
      " 0.30135843 0.30621502]\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.31231597]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[0.27620748 0.27824277 0.28264922 0.28740239 0.29174653 0.29667827\n",
      "  0.30135843 0.30621502]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12211044132709503\n",
      "Predicción post entrenamiento : [[0.31635574]]\n",
      "PERDIDAAAA despues: 0.11930342763662338\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "[[[0.27824277]\n",
      "  [0.28264922]\n",
      "  [0.28740239]\n",
      "  [0.29174653]\n",
      "  [0.29667827]\n",
      "  [0.30135843]\n",
      "  [0.30621502]\n",
      "  [0.31231597]]]\n",
      "ejemplar: [0.27824277 0.28264922 0.28740239 0.29174653 0.29667827 0.30135843\n",
      " 0.30621502 0.31231597]\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.31900728]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[0.27824277 0.28264922 0.28740239 0.29174653 0.29667827 0.30135843\n",
      "  0.30621502 0.31231597]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12530729174613953\n",
      "Predicción post entrenamiento : [[0.3228389]]\n",
      "PERDIDAAAA despues: 0.12260927259922028\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "[[[0.28264922]\n",
      "  [0.28740239]\n",
      "  [0.29174653]\n",
      "  [0.29667827]\n",
      "  [0.30135843]\n",
      "  [0.30621502]\n",
      "  [0.31231597]\n",
      "  [0.31900728]]]\n",
      "ejemplar: [0.28264922 0.28740239 0.29174653 0.29667827 0.30135843 0.30621502\n",
      " 0.31231597 0.31900728]\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.3260414]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[0.28264922 0.28740239 0.29174653 0.29667827 0.30135843 0.30621502\n",
      "  0.31231597 0.31900728]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1478678584098816\n",
      "Predicción post entrenamiento : [[0.33044195]]\n",
      "PERDIDAAAA despues: 0.1445028930902481\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "[[[0.28740239]\n",
      "  [0.29174653]\n",
      "  [0.29667827]\n",
      "  [0.30135843]\n",
      "  [0.30621502]\n",
      "  [0.31231597]\n",
      "  [0.31900728]\n",
      "  [0.3260414 ]]]\n",
      "ejemplar: [0.28740239 0.29174653 0.29667827 0.30135843 0.30621502 0.31231597\n",
      " 0.31900728 0.3260414 ]\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.33377877]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[0.28740239 0.29174653 0.29667827 0.30135843 0.30621502 0.31231597\n",
      "  0.31900728 0.3260414 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1370568722486496\n",
      "Predicción post entrenamiento : [[0.3378211]]\n",
      "PERDIDAAAA despues: 0.134080171585083\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "[[[0.29174653]\n",
      "  [0.29667827]\n",
      "  [0.30135843]\n",
      "  [0.30621502]\n",
      "  [0.31231597]\n",
      "  [0.31900728]\n",
      "  [0.3260414 ]\n",
      "  [0.33377877]]]\n",
      "ejemplar: [0.29174653 0.29667827 0.30135843 0.30621502 0.31231597 0.31900728\n",
      " 0.3260414  0.33377877]\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.34127808]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[0.29174653 0.29667827 0.30135843 0.30621502 0.31231597 0.31900728\n",
      "  0.3260414  0.33377877]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14896468818187714\n",
      "Predicción post entrenamiento : [[0.34545454]]\n",
      "PERDIDAAAA despues: 0.1457582414150238\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "[[[0.29667827]\n",
      "  [0.30135843]\n",
      "  [0.30621502]\n",
      "  [0.31231597]\n",
      "  [0.31900728]\n",
      "  [0.3260414 ]\n",
      "  [0.33377877]\n",
      "  [0.34127808]]]\n",
      "ejemplar: [0.29667827 0.30135843 0.30621502 0.31231597 0.31900728 0.3260414\n",
      " 0.33377877 0.34127808]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.3492013]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[0.29667827 0.30135843 0.30621502 0.31231597 0.31900728 0.3260414\n",
      "  0.33377877 0.34127808]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13941772282123566\n",
      "Predicción post entrenamiento : [[0.3531127]]\n",
      "PERDIDAAAA despues: 0.13651208579540253\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "[[[0.30135843]\n",
      "  [0.30621502]\n",
      "  [0.31231597]\n",
      "  [0.31900728]\n",
      "  [0.3260414 ]\n",
      "  [0.33377877]\n",
      "  [0.34127808]\n",
      "  [0.34920129]]]\n",
      "ejemplar: [0.30135843 0.30621502 0.31231597 0.31900728 0.3260414  0.33377877\n",
      " 0.34127808 0.34920129]\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.35711548]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[0.30135843 0.30621502 0.31231597 0.31900728 0.3260414  0.33377877\n",
      "  0.34127808 0.34920129]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.17195819318294525\n",
      "Predicción post entrenamiento : [[0.36149746]]\n",
      "PERDIDAAAA despues: 0.1683431714773178\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "[[[0.30621502]\n",
      "  [0.31231597]\n",
      "  [0.31900728]\n",
      "  [0.3260414 ]\n",
      "  [0.33377877]\n",
      "  [0.34127808]\n",
      "  [0.34920129]\n",
      "  [0.35711548]]]\n",
      "ejemplar: [0.30621502 0.31231597 0.31900728 0.3260414  0.33377877 0.34127808\n",
      " 0.34920129 0.35711548]\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.36591434]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[0.30621502 0.31231597 0.31900728 0.3260414  0.33377877 0.34127808\n",
      "  0.34920129 0.35711548]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12860187888145447\n",
      "Predicción post entrenamiento : [[0.36968678]]\n",
      "PERDIDAAAA despues: 0.1259104460477829\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "[[[0.31231597]\n",
      "  [0.31900728]\n",
      "  [0.3260414 ]\n",
      "  [0.33377877]\n",
      "  [0.34127808]\n",
      "  [0.34920129]\n",
      "  [0.35711548]\n",
      "  [0.36591434]]]\n",
      "ejemplar: [0.31231597 0.31900728 0.3260414  0.33377877 0.34127808 0.34920129\n",
      " 0.35711548 0.36591434]\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.3745942]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[0.31231597 0.31900728 0.3260414  0.33377877 0.34127808 0.34920129\n",
      "  0.35711548 0.36591434]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08789060264825821\n",
      "Predicción post entrenamiento : [[0.37717262]]\n",
      "PERDIDAAAA despues: 0.08636844158172607\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "[[[0.31900728]\n",
      "  [0.3260414 ]\n",
      "  [0.33377877]\n",
      "  [0.34127808]\n",
      "  [0.34920129]\n",
      "  [0.35711548]\n",
      "  [0.36591434]\n",
      "  [0.37459421]]]\n",
      "ejemplar: [0.31900728 0.3260414  0.33377877 0.34127808 0.34920129 0.35711548\n",
      " 0.36591434 0.37459421]\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.38239366]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[0.31900728 0.3260414  0.33377877 0.34127808 0.34920129 0.35711548\n",
      "  0.36591434 0.37459421]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08490007370710373\n",
      "Predicción post entrenamiento : [[0.38523245]]\n",
      "PERDIDAAAA despues: 0.08325382322072983\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "[[[0.3260414 ]\n",
      "  [0.33377877]\n",
      "  [0.34127808]\n",
      "  [0.34920129]\n",
      "  [0.35711548]\n",
      "  [0.36591434]\n",
      "  [0.37459421]\n",
      "  [0.38239366]]]\n",
      "ejemplar: [0.3260414  0.33377877 0.34127808 0.34920129 0.35711548 0.36591434\n",
      " 0.37459421 0.38239366]\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.3907057]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[0.3260414  0.33377877 0.34127808 0.34920129 0.35711548 0.36591434\n",
      "  0.37459421 0.38239366]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10481152683496475\n",
      "Predicción post entrenamiento : [[0.3935744]]\n",
      "PERDIDAAAA despues: 0.10296230763196945\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "[[[0.33377877]\n",
      "  [0.34127808]\n",
      "  [0.34920129]\n",
      "  [0.35711548]\n",
      "  [0.36591434]\n",
      "  [0.37459421]\n",
      "  [0.38239366]\n",
      "  [0.3907057 ]]]\n",
      "ejemplar: [0.33377877 0.34127808 0.34920129 0.35711548 0.36591434 0.37459421\n",
      " 0.38239366 0.3907057 ]\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.39927834]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[0.33377877 0.34127808 0.34920129 0.35711548 0.36591434 0.37459421\n",
      "  0.38239366 0.3907057 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11876252293586731\n",
      "Predicción post entrenamiento : [[0.40284246]]\n",
      "PERDIDAAAA despues: 0.1163187026977539\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "[[[0.34127808]\n",
      "  [0.34920129]\n",
      "  [0.35711548]\n",
      "  [0.36591434]\n",
      "  [0.37459421]\n",
      "  [0.38239366]\n",
      "  [0.3907057 ]\n",
      "  [0.39927834]]]\n",
      "ejemplar: [0.34127808 0.34920129 0.35711548 0.36591434 0.37459421 0.38239366\n",
      " 0.3907057  0.39927834]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.4086579]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[0.34127808 0.34920129 0.35711548 0.36591434 0.37459421 0.38239366\n",
      "  0.3907057  0.39927834]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09855218231678009\n",
      "Predicción post entrenamiento : [[0.41169757]]\n",
      "PERDIDAAAA despues: 0.09665293991565704\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "[[[0.34920129]\n",
      "  [0.35711548]\n",
      "  [0.36591434]\n",
      "  [0.37459421]\n",
      "  [0.38239366]\n",
      "  [0.3907057 ]\n",
      "  [0.39927834]\n",
      "  [0.40865791]]]\n",
      "ejemplar: [0.34920129 0.35711548 0.36591434 0.37459421 0.38239366 0.3907057\n",
      " 0.39927834 0.40865791]\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.41771173]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[0.34920129 0.35711548 0.36591434 0.37459421 0.38239366 0.3907057\n",
      "  0.39927834 0.40865791]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07931524515151978\n",
      "Predicción post entrenamiento : [[0.42025593]]\n",
      "PERDIDAAAA despues: 0.07788867503404617\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "[[[0.35711548]\n",
      "  [0.36591434]\n",
      "  [0.37459421]\n",
      "  [0.38239366]\n",
      "  [0.3907057 ]\n",
      "  [0.39927834]\n",
      "  [0.40865791]\n",
      "  [0.41771173]]]\n",
      "ejemplar: [0.35711548 0.36591434 0.37459421 0.38239366 0.3907057  0.39927834\n",
      " 0.40865791 0.41771173]\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.42640835]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[0.35711548 0.36591434 0.37459421 0.38239366 0.3907057  0.39927834\n",
      "  0.40865791 0.41771173]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09666053205728531\n",
      "Predicción post entrenamiento : [[0.42942253]]\n",
      "PERDIDAAAA despues: 0.09479539096355438\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "[[[0.36591434]\n",
      "  [0.37459421]\n",
      "  [0.38239366]\n",
      "  [0.3907057 ]\n",
      "  [0.39927834]\n",
      "  [0.40865791]\n",
      "  [0.41771173]\n",
      "  [0.42640835]]]\n",
      "ejemplar: [0.36591434 0.37459421 0.38239366 0.3907057  0.39927834 0.40865791\n",
      " 0.41771173 0.42640835]\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.43574885]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[0.36591434 0.37459421 0.38239366 0.3907057  0.39927834 0.40865791\n",
      "  0.41771173 0.42640835]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08161134272813797\n",
      "Predicción post entrenamiento : [[0.43853635]]\n",
      "PERDIDAAAA despues: 0.08002646267414093\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "[[[0.37459421]\n",
      "  [0.38239366]\n",
      "  [0.3907057 ]\n",
      "  [0.39927834]\n",
      "  [0.40865791]\n",
      "  [0.41771173]\n",
      "  [0.42640835]\n",
      "  [0.43574885]]]\n",
      "ejemplar: [0.37459421 0.38239366 0.3907057  0.39927834 0.40865791 0.41771173\n",
      " 0.42640835 0.43574885]\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.444854]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[0.37459421 0.38239366 0.3907057  0.39927834 0.40865791 0.41771173\n",
      "  0.42640835 0.43574885]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.074999138712883\n",
      "Predicción post entrenamiento : [[0.44753233]]\n",
      "PERDIDAAAA despues: 0.07353933900594711\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "[[[0.38239366]\n",
      "  [0.3907057 ]\n",
      "  [0.39927834]\n",
      "  [0.40865791]\n",
      "  [0.41771173]\n",
      "  [0.42640835]\n",
      "  [0.43574885]\n",
      "  [0.44485399]]]\n",
      "ejemplar: [0.38239366 0.3907057  0.39927834 0.40865791 0.41771173 0.42640835\n",
      " 0.43574885 0.44485399]\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.4538788]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[0.38239366 0.3907057  0.39927834 0.40865791 0.41771173 0.42640835\n",
      "  0.43574885 0.44485399]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04852263256907463\n",
      "Predicción post entrenamiento : [[0.45518515]]\n",
      "PERDIDAAAA despues: 0.04794881492853165\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "[[[0.3907057 ]\n",
      "  [0.39927834]\n",
      "  [0.40865791]\n",
      "  [0.41771173]\n",
      "  [0.42640835]\n",
      "  [0.43574885]\n",
      "  [0.44485399]\n",
      "  [0.45387879]]]\n",
      "ejemplar: [0.3907057  0.39927834 0.40865791 0.41771173 0.42640835 0.43574885\n",
      " 0.44485399 0.45387879]\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.4617946]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[0.3907057  0.39927834 0.40865791 0.41771173 0.42640835 0.43574885\n",
      "  0.44485399 0.45387879]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05606089532375336\n",
      "Predicción post entrenamiento : [[0.46401912]]\n",
      "PERDIDAAAA despues: 0.05501244217157364\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "[[[0.39927834]\n",
      "  [0.40865791]\n",
      "  [0.41771173]\n",
      "  [0.42640835]\n",
      "  [0.43574885]\n",
      "  [0.44485399]\n",
      "  [0.45387879]\n",
      "  [0.46179461]]]\n",
      "ejemplar: [0.39927834 0.40865791 0.41771173 0.42640835 0.43574885 0.44485399\n",
      " 0.45387879 0.46179461]\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.4708106]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[0.39927834 0.40865791 0.41771173 0.42640835 0.43574885 0.44485399\n",
      "  0.45387879 0.46179461]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06261392682790756\n",
      "Predicción post entrenamiento : [[0.47272542]]\n",
      "PERDIDAAAA despues: 0.0616593062877655\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "[[[0.40865791]\n",
      "  [0.41771173]\n",
      "  [0.42640835]\n",
      "  [0.43574885]\n",
      "  [0.44485399]\n",
      "  [0.45387879]\n",
      "  [0.46179461]\n",
      "  [0.47081059]]]\n",
      "ejemplar: [0.40865791 0.41771173 0.42640835 0.43574885 0.44485399 0.45387879\n",
      " 0.46179461 0.47081059]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.47965354]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[0.40865791 0.41771173 0.42640835 0.43574885 0.44485399 0.45387879\n",
      "  0.46179461 0.47081059]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05901721119880676\n",
      "Predicción post entrenamiento : [[0.48183036]]\n",
      "PERDIDAAAA despues: 0.057964298874139786\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "[[[0.41771173]\n",
      "  [0.42640835]\n",
      "  [0.43574885]\n",
      "  [0.44485399]\n",
      "  [0.45387879]\n",
      "  [0.46179461]\n",
      "  [0.47081059]\n",
      "  [0.47965354]]]\n",
      "ejemplar: [0.41771173 0.42640835 0.43574885 0.44485399 0.45387879 0.46179461\n",
      " 0.47081059 0.47965354]\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.48869833]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[0.41771173 0.42640835 0.43574885 0.44485399 0.45387879 0.46179461\n",
      "  0.47081059 0.47965354]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0716085284948349\n",
      "Predicción post entrenamiento : [[0.4914353]]\n",
      "PERDIDAAAA despues: 0.07015121728181839\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "[[[0.42640835]\n",
      "  [0.43574885]\n",
      "  [0.44485399]\n",
      "  [0.45387879]\n",
      "  [0.46179461]\n",
      "  [0.47081059]\n",
      "  [0.47965354]\n",
      "  [0.48869833]]]\n",
      "ejemplar: [0.42640835 0.43574885 0.44485399 0.45387879 0.46179461 0.47081059\n",
      " 0.47965354 0.48869833]\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.49830478]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[0.42640835 0.43574885 0.44485399 0.45387879 0.46179461 0.47081059\n",
      "  0.47965354 0.48869833]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10842627286911011\n",
      "Predicción post entrenamiento : [[0.5011986]]\n",
      "PERDIDAAAA despues: 0.10652889311313629\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "[[[0.43574885]\n",
      "  [0.44485399]\n",
      "  [0.45387879]\n",
      "  [0.46179461]\n",
      "  [0.47081059]\n",
      "  [0.47965354]\n",
      "  [0.48869833]\n",
      "  [0.49830478]]]\n",
      "ejemplar: [0.43574885 0.44485399 0.45387879 0.46179461 0.47081059 0.47965354\n",
      " 0.48869833 0.49830478]\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.5081562]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[0.43574885 0.44485399 0.45387879 0.46179461 0.47081059 0.47965354\n",
      "  0.48869833 0.49830478]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10934000462293625\n",
      "Predicción post entrenamiento : [[0.5107335]]\n",
      "PERDIDAAAA despues: 0.10764219611883163\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "[[[0.44485399]\n",
      "  [0.45387879]\n",
      "  [0.46179461]\n",
      "  [0.47081059]\n",
      "  [0.47965354]\n",
      "  [0.48869833]\n",
      "  [0.49830478]\n",
      "  [0.50815618]]]\n",
      "ejemplar: [0.44485399 0.45387879 0.46179461 0.47081059 0.47965354 0.48869833\n",
      " 0.49830478 0.50815618]\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.51762676]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[0.44485399 0.45387879 0.46179461 0.47081059 0.47965354 0.48869833\n",
      "  0.49830478 0.50815618]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07652916014194489\n",
      "Predicción post entrenamiento : [[0.5201867]]\n",
      "PERDIDAAAA despues: 0.07511934638023376\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "[[[0.45387879]\n",
      "  [0.46179461]\n",
      "  [0.47081059]\n",
      "  [0.47965354]\n",
      "  [0.48869833]\n",
      "  [0.49830478]\n",
      "  [0.50815618]\n",
      "  [0.51762676]]]\n",
      "ejemplar: [0.45387879 0.46179461 0.47081059 0.47965354 0.48869833 0.49830478\n",
      " 0.50815618 0.51762676]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.5270739]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[0.45387879 0.46179461 0.47081059 0.47965354 0.48869833 0.49830478\n",
      "  0.50815618 0.51762676]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.065910704433918\n",
      "Predicción post entrenamiento : [[0.5292513]]\n",
      "PERDIDAAAA despues: 0.06479745358228683\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "[[[0.46179461]\n",
      "  [0.47081059]\n",
      "  [0.47965354]\n",
      "  [0.48869833]\n",
      "  [0.49830478]\n",
      "  [0.50815618]\n",
      "  [0.51762676]\n",
      "  [0.52707392]]]\n",
      "ejemplar: [0.46179461 0.47081059 0.47965354 0.48869833 0.49830478 0.50815618\n",
      " 0.51762676 0.52707392]\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.53616613]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[0.46179461 0.47081059 0.47965354 0.48869833 0.49830478 0.50815618\n",
      "  0.51762676 0.52707392]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05370958894491196\n",
      "Predicción post entrenamiento : [[0.5377588]]\n",
      "PERDIDAAAA despues: 0.052973899990320206\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "[[[0.47081059]\n",
      "  [0.47965354]\n",
      "  [0.48869833]\n",
      "  [0.49830478]\n",
      "  [0.50815618]\n",
      "  [0.51762676]\n",
      "  [0.52707392]\n",
      "  [0.53616613]]]\n",
      "ejemplar: [0.47081059 0.47965354 0.48869833 0.49830478 0.50815618 0.51762676\n",
      " 0.52707392 0.53616613]\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.5450095]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[0.47081059 0.47965354 0.48869833 0.49830478 0.50815618 0.51762676\n",
      "  0.52707392 0.53616613]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05739385262131691\n",
      "Predicción post entrenamiento : [[0.5467836]]\n",
      "PERDIDAAAA despues: 0.05654694139957428\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "[[[0.47965354]\n",
      "  [0.48869833]\n",
      "  [0.49830478]\n",
      "  [0.50815618]\n",
      "  [0.51762676]\n",
      "  [0.52707392]\n",
      "  [0.53616613]\n",
      "  [0.54500949]]]\n",
      "ejemplar: [0.47965354 0.48869833 0.49830478 0.50815618 0.51762676 0.52707392\n",
      " 0.53616613 0.54500949]\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.5541407]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[0.47965354 0.48869833 0.49830478 0.50815618 0.51762676 0.52707392\n",
      "  0.53616613 0.54500949]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10535767674446106\n",
      "Predicción post entrenamiento : [[0.5568155]]\n",
      "PERDIDAAAA despues: 0.10362840443849564\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "[[[0.48869833]\n",
      "  [0.49830478]\n",
      "  [0.50815618]\n",
      "  [0.51762676]\n",
      "  [0.52707392]\n",
      "  [0.53616613]\n",
      "  [0.54500949]\n",
      "  [0.55414069]]]\n",
      "ejemplar: [0.48869833 0.49830478 0.50815618 0.51762676 0.52707392 0.53616613\n",
      " 0.54500949 0.55414069]\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.5643393]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[0.48869833 0.49830478 0.50815618 0.51762676 0.52707392 0.53616613\n",
      "  0.54500949 0.55414069]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09690166264772415\n",
      "Predicción post entrenamiento : [[0.56714135]]\n",
      "PERDIDAAAA despues: 0.09516499936580658\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "[[[0.49830478]\n",
      "  [0.50815618]\n",
      "  [0.51762676]\n",
      "  [0.52707392]\n",
      "  [0.53616613]\n",
      "  [0.54500949]\n",
      "  [0.55414069]\n",
      "  [0.56433928]]]\n",
      "ejemplar: [0.49830478 0.50815618 0.51762676 0.52707392 0.53616613 0.54500949\n",
      " 0.55414069 0.56433928]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.5747978]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[0.49830478 0.50815618 0.51762676 0.52707392 0.53616613 0.54500949\n",
      "  0.55414069 0.56433928]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07512970268726349\n",
      "Predicción post entrenamiento : [[0.5773741]]\n",
      "PERDIDAAAA despues: 0.07372402399778366\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "[[[0.50815618]\n",
      "  [0.51762676]\n",
      "  [0.52707392]\n",
      "  [0.53616613]\n",
      "  [0.54500949]\n",
      "  [0.55414069]\n",
      "  [0.56433928]\n",
      "  [0.57479781]]]\n",
      "ejemplar: [0.50815618 0.51762676 0.52707392 0.53616613 0.54500949 0.55414069\n",
      " 0.56433928 0.57479781]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.5850294]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[0.50815618 0.51762676 0.52707392 0.53616613 0.54500949 0.55414069\n",
      "  0.56433928 0.57479781]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05440932512283325\n",
      "Predicción post entrenamiento : [[0.58679444]]\n",
      "PERDIDAAAA despues: 0.05358903482556343\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "[[[0.51762676]\n",
      "  [0.52707392]\n",
      "  [0.53616613]\n",
      "  [0.54500949]\n",
      "  [0.55414069]\n",
      "  [0.56433928]\n",
      "  [0.57479781]\n",
      "  [0.58502942]]]\n",
      "ejemplar: [0.51762676 0.52707392 0.53616613 0.54500949 0.55414069 0.56433928\n",
      " 0.57479781 0.58502942]\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.59438336]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[0.51762676 0.52707392 0.53616613 0.54500949 0.55414069 0.56433928\n",
      "  0.57479781 0.58502942]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05402275547385216\n",
      "Predicción post entrenamiento : [[0.59603477]]\n",
      "PERDIDAAAA despues: 0.053257815539836884\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "[[[0.52707392]\n",
      "  [0.53616613]\n",
      "  [0.54500949]\n",
      "  [0.55414069]\n",
      "  [0.56433928]\n",
      "  [0.57479781]\n",
      "  [0.58502942]\n",
      "  [0.59438336]]]\n",
      "ejemplar: [0.52707392 0.53616613 0.54500949 0.55414069 0.56433928 0.57479781\n",
      " 0.58502942 0.59438336]\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.6036577]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[0.52707392 0.53616613 0.54500949 0.55414069 0.56433928 0.57479781\n",
      "  0.58502942 0.59438336]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.033013716340065\n",
      "Predicción post entrenamiento : [[0.60575944]]\n",
      "PERDIDAAAA despues: 0.032254382967948914\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "[[[0.53616613]\n",
      "  [0.54500949]\n",
      "  [0.55414069]\n",
      "  [0.56433928]\n",
      "  [0.57479781]\n",
      "  [0.58502942]\n",
      "  [0.59438336]\n",
      "  [0.60365772]]]\n",
      "ejemplar: [0.53616613 0.54500949 0.55414069 0.56433928 0.57479781 0.58502942\n",
      " 0.59438336 0.60365772]\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.61343926]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[0.53616613 0.54500949 0.55414069 0.56433928 0.57479781 0.58502942\n",
      "  0.59438336 0.60365772]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03090202435851097\n",
      "Predicción post entrenamiento : [[0.6150723]]\n",
      "PERDIDAAAA despues: 0.030330544337630272\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "[[[0.54500949]\n",
      "  [0.55414069]\n",
      "  [0.56433928]\n",
      "  [0.57479781]\n",
      "  [0.58502942]\n",
      "  [0.59438336]\n",
      "  [0.60365772]\n",
      "  [0.61343926]]]\n",
      "ejemplar: [0.54500949 0.55414069 0.56433928 0.57479781 0.58502942 0.59438336\n",
      " 0.60365772 0.61343926]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.62292117]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[0.54500949 0.55414069 0.56433928 0.57479781 0.58502942 0.59438336\n",
      "  0.60365772 0.61343926]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.044627245515584946\n",
      "Predicción post entrenamiento : [[0.6246159]]\n",
      "PERDIDAAAA despues: 0.043914083391427994\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "[[[0.55414069]\n",
      "  [0.56433928]\n",
      "  [0.57479781]\n",
      "  [0.58502942]\n",
      "  [0.59438336]\n",
      "  [0.60365772]\n",
      "  [0.61343926]\n",
      "  [0.62292117]]]\n",
      "ejemplar: [0.55414069 0.56433928 0.57479781 0.58502942 0.59438336 0.60365772\n",
      " 0.61343926 0.62292117]\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.63272977]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[0.55414069 0.56433928 0.57479781 0.58502942 0.59438336 0.60365772\n",
      "  0.61343926 0.62292117]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.032308634370565414\n",
      "Predicción post entrenamiento : [[0.63478124]]\n",
      "PERDIDAAAA despues: 0.03157535567879677\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "[[[0.56433928]\n",
      "  [0.57479781]\n",
      "  [0.58502942]\n",
      "  [0.59438336]\n",
      "  [0.60365772]\n",
      "  [0.61343926]\n",
      "  [0.62292117]\n",
      "  [0.63272977]]]\n",
      "ejemplar: [0.56433928 0.57479781 0.58502942 0.59438336 0.60365772 0.61343926\n",
      " 0.62292117 0.63272977]\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.64311546]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[0.56433928 0.57479781 0.58502942 0.59438336 0.60365772 0.61343926\n",
      "  0.62292117 0.63272977]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02500332146883011\n",
      "Predicción post entrenamiento : [[0.6450574]]\n",
      "PERDIDAAAA despues: 0.02439296245574951\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "[[[0.57479781]\n",
      "  [0.58502942]\n",
      "  [0.59438336]\n",
      "  [0.60365772]\n",
      "  [0.61343926]\n",
      "  [0.62292117]\n",
      "  [0.63272977]\n",
      "  [0.64311546]]]\n",
      "ejemplar: [0.57479781 0.58502942 0.59438336 0.60365772 0.61343926 0.62292117\n",
      " 0.63272977 0.64311546]\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.65333945]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[0.57479781 0.58502942 0.59438336 0.60365772 0.61343926 0.62292117\n",
      "  0.63272977 0.64311546]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022451309487223625\n",
      "Predicción post entrenamiento : [[0.65415055]]\n",
      "PERDIDAAAA despues: 0.02220890112221241\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "[[[0.58502942]\n",
      "  [0.59438336]\n",
      "  [0.60365772]\n",
      "  [0.61343926]\n",
      "  [0.62292117]\n",
      "  [0.63272977]\n",
      "  [0.64311546]\n",
      "  [0.65333945]]]\n",
      "ejemplar: [0.58502942 0.59438336 0.60365772 0.61343926 0.62292117 0.63272977\n",
      " 0.64311546 0.65333945]\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.66228646]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[0.58502942 0.59438336 0.60365772 0.61343926 0.62292117 0.63272977\n",
      "  0.64311546 0.65333945]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01721460185945034\n",
      "Predicción post entrenamiento : [[0.6636989]]\n",
      "PERDIDAAAA despues: 0.016845956444740295\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "[[[0.59438336]\n",
      "  [0.60365772]\n",
      "  [0.61343926]\n",
      "  [0.62292117]\n",
      "  [0.63272977]\n",
      "  [0.64311546]\n",
      "  [0.65333945]\n",
      "  [0.66228646]]]\n",
      "ejemplar: [0.59438336 0.60365772 0.61343926 0.62292117 0.63272977 0.64311546\n",
      " 0.65333945 0.66228646]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.6717259]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[0.59438336 0.60365772 0.61343926 0.62292117 0.63272977 0.64311546\n",
      "  0.65333945 0.66228646]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007822435349225998\n",
      "Predicción post entrenamiento : [[0.67120737]]\n",
      "PERDIDAAAA despues: 0.007914431393146515\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "[[[0.60365772]\n",
      "  [0.61343926]\n",
      "  [0.62292117]\n",
      "  [0.63272977]\n",
      "  [0.64311546]\n",
      "  [0.65333945]\n",
      "  [0.66228646]\n",
      "  [0.67172593]]]\n",
      "ejemplar: [0.60365772 0.61343926 0.62292117 0.63272977 0.64311546 0.65333945\n",
      " 0.66228646 0.67172593]\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.67934453]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[0.60365772 0.61343926 0.62292117 0.63272977 0.64311546 0.65333945\n",
      "  0.66228646 0.67172593]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003139291424304247\n",
      "Predicción post entrenamiento : [[0.6793382]]\n",
      "PERDIDAAAA despues: 0.0031399994622915983\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "[[[0.61343926]\n",
      "  [0.62292117]\n",
      "  [0.63272977]\n",
      "  [0.64311546]\n",
      "  [0.65333945]\n",
      "  [0.66228646]\n",
      "  [0.67172593]\n",
      "  [0.67934453]]]\n",
      "ejemplar: [0.61343926 0.62292117 0.63272977 0.64311546 0.65333945 0.66228646\n",
      " 0.67172593 0.67934453]\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.68761265]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[0.61343926 0.62292117 0.63272977 0.64311546 0.65333945 0.66228646\n",
      "  0.67172593 0.67934453]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005097284447401762\n",
      "Predicción post entrenamiento : [[0.6871699]]\n",
      "PERDIDAAAA despues: 0.0005299162585288286\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "[[[0.62292117]\n",
      "  [0.63272977]\n",
      "  [0.64311546]\n",
      "  [0.65333945]\n",
      "  [0.66228646]\n",
      "  [0.67172593]\n",
      "  [0.67934453]\n",
      "  [0.68761265]]]\n",
      "ejemplar: [0.62292117 0.63272977 0.64311546 0.65333945 0.66228646 0.67172593\n",
      " 0.67934453 0.68761265]\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.69542766]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[0.62292117 0.63272977 0.64311546 0.65333945 0.66228646 0.67172593\n",
      "  0.67934453 0.68761265]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002788710698951036\n",
      "Predicción post entrenamiento : [[0.6949267]]\n",
      "PERDIDAAAA despues: 0.00029585411539301276\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "[[[0.63272977]\n",
      "  [0.64311546]\n",
      "  [0.65333945]\n",
      "  [0.66228646]\n",
      "  [0.67172593]\n",
      "  [0.67934453]\n",
      "  [0.68761265]\n",
      "  [0.69542766]]]\n",
      "ejemplar: [0.63272977 0.64311546 0.65333945 0.66228646 0.67172593 0.67934453\n",
      " 0.68761265 0.69542766]\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.70320255]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[0.63272977 0.64311546 0.65333945 0.66228646 0.67172593 0.67934453\n",
      "  0.68761265 0.69542766]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013273839140310884\n",
      "Predicción post entrenamiento : [[0.7039986]]\n",
      "PERDIDAAAA despues: 0.0012700100196525455\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "[[[0.64311546]\n",
      "  [0.65333945]\n",
      "  [0.66228646]\n",
      "  [0.67172593]\n",
      "  [0.67934453]\n",
      "  [0.68761265]\n",
      "  [0.69542766]\n",
      "  [0.70320255]]]\n",
      "ejemplar: [0.64311546 0.65333945 0.66228646 0.67172593 0.67934453 0.68761265\n",
      " 0.69542766 0.70320255]\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.7121501]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[0.64311546 0.65333945 0.66228646 0.67172593 0.67934453 0.68761265\n",
      "  0.69542766 0.70320255]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000575936515815556\n",
      "Predicción post entrenamiento : [[0.7110761]]\n",
      "PERDIDAAAA despues: 0.0006286400021053851\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "[[[0.65333945]\n",
      "  [0.66228646]\n",
      "  [0.67172593]\n",
      "  [0.67934453]\n",
      "  [0.68761265]\n",
      "  [0.69542766]\n",
      "  [0.70320255]\n",
      "  [0.7121501 ]]]\n",
      "ejemplar: [0.65333945 0.66228646 0.67172593 0.67934453 0.68761265 0.69542766\n",
      " 0.70320255 0.7121501 ]\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.71885824]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[0.65333945 0.66228646 0.67172593 0.67934453 0.68761265 0.69542766\n",
      "  0.70320255 0.7121501 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002630410948768258\n",
      "Predicción post entrenamiento : [[0.71856314]]\n",
      "PERDIDAAAA despues: 0.0026002279482781887\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "[[[0.66228646]\n",
      "  [0.67172593]\n",
      "  [0.67934453]\n",
      "  [0.68761265]\n",
      "  [0.69542766]\n",
      "  [0.70320255]\n",
      "  [0.7121501 ]\n",
      "  [0.71885824]]]\n",
      "ejemplar: [0.66228646 0.67172593 0.67934453 0.68761265 0.69542766 0.70320255\n",
      " 0.7121501  0.71885824]\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.72591716]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[0.66228646 0.67172593 0.67934453 0.68761265 0.69542766 0.70320255\n",
      "  0.7121501  0.71885824]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00313843647018075\n",
      "Predicción post entrenamiento : [[0.7257831]]\n",
      "PERDIDAAAA despues: 0.0031234349589794874\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "[[[0.67172593]\n",
      "  [0.67934453]\n",
      "  [0.68761265]\n",
      "  [0.69542766]\n",
      "  [0.70320255]\n",
      "  [0.7121501 ]\n",
      "  [0.71885824]\n",
      "  [0.72591716]]]\n",
      "ejemplar: [0.67172593 0.67934453 0.68761265 0.69542766 0.70320255 0.7121501\n",
      " 0.71885824 0.72591716]\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.7329642]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[0.67172593 0.67934453 0.68761265 0.69542766 0.70320255 0.7121501\n",
      "  0.71885824 0.72591716]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013202315894886851\n",
      "Predicción post entrenamiento : [[0.7322191]]\n",
      "PERDIDAAAA despues: 0.0012666390975937247\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "[[[0.67934453]\n",
      "  [0.68761265]\n",
      "  [0.69542766]\n",
      "  [0.70320255]\n",
      "  [0.7121501 ]\n",
      "  [0.71885824]\n",
      "  [0.72591716]\n",
      "  [0.73296422]]]\n",
      "ejemplar: [0.67934453 0.68761265 0.69542766 0.70320255 0.7121501  0.71885824\n",
      " 0.72591716 0.73296422]\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.7390236]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[0.67934453 0.68761265 0.69542766 0.70320255 0.7121501  0.71885824\n",
      "  0.72591716 0.73296422]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006901671178638935\n",
      "Predicción post entrenamiento : [[0.737574]]\n",
      "PERDIDAAAA despues: 0.006662910804152489\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "[[[0.68761265]\n",
      "  [0.69542766]\n",
      "  [0.70320255]\n",
      "  [0.7121501 ]\n",
      "  [0.71885824]\n",
      "  [0.72591716]\n",
      "  [0.73296422]\n",
      "  [0.73902363]]]\n",
      "ejemplar: [0.68761265 0.69542766 0.70320255 0.7121501  0.71885824 0.72591716\n",
      " 0.73296422 0.73902363]\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.74442506]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[0.68761265 0.69542766 0.70320255 0.7121501  0.71885824 0.72591716\n",
      "  0.73296422 0.73902363]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004305773880332708\n",
      "Predicción post entrenamiento : [[0.74465144]]\n",
      "PERDIDAAAA despues: 0.004335534293204546\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "[[[0.69542766]\n",
      "  [0.70320255]\n",
      "  [0.7121501 ]\n",
      "  [0.71885824]\n",
      "  [0.72591716]\n",
      "  [0.73296422]\n",
      "  [0.73902363]\n",
      "  [0.74442506]]]\n",
      "ejemplar: [0.69542766 0.70320255 0.7121501  0.71885824 0.72591716 0.73296422\n",
      " 0.73902363 0.74442506]\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.7513298]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[0.69542766 0.70320255 0.7121501  0.71885824 0.72591716 0.73296422\n",
      "  0.73902363 0.74442506]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005660342518240213\n",
      "Predicción post entrenamiento : [[0.7515901]]\n",
      "PERDIDAAAA despues: 0.005699576810002327\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "[[[0.70320255]\n",
      "  [0.7121501 ]\n",
      "  [0.71885824]\n",
      "  [0.72591716]\n",
      "  [0.73296422]\n",
      "  [0.73902363]\n",
      "  [0.74442506]\n",
      "  [0.75132978]]]\n",
      "ejemplar: [0.70320255 0.7121501  0.71885824 0.72591716 0.73296422 0.73902363\n",
      " 0.74442506 0.75132978]\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.758149]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[0.70320255 0.7121501  0.71885824 0.72591716 0.73296422 0.73902363\n",
      "  0.74442506 0.75132978]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008172088419087231\n",
      "Predicción post entrenamiento : [[0.756956]]\n",
      "PERDIDAAAA despues: 0.0007504212553612888\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "[[[0.7121501 ]\n",
      "  [0.71885824]\n",
      "  [0.72591716]\n",
      "  [0.73296422]\n",
      "  [0.73902363]\n",
      "  [0.74442506]\n",
      "  [0.75132978]\n",
      "  [0.75814903]]]\n",
      "ejemplar: [0.7121501  0.71885824 0.72591716 0.73296422 0.73902363 0.74442506\n",
      " 0.75132978 0.75814903]\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.763339]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[0.7121501  0.71885824 0.72591716 0.73296422 0.73902363 0.74442506\n",
      "  0.75132978 0.75814903]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0038514952175319195\n",
      "Predicción post entrenamiento : [[0.7627212]]\n",
      "PERDIDAAAA despues: 0.003775194752961397\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "[[[0.71885824]\n",
      "  [0.72591716]\n",
      "  [0.73296422]\n",
      "  [0.73902363]\n",
      "  [0.74442506]\n",
      "  [0.75132978]\n",
      "  [0.75814903]\n",
      "  [0.76333898]]]\n",
      "ejemplar: [0.71885824 0.72591716 0.73296422 0.73902363 0.74442506 0.75132978\n",
      " 0.75814903 0.76333898]\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.7685217]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[0.71885824 0.72591716 0.73296422 0.73902363 0.74442506 0.75132978\n",
      "  0.75814903 0.76333898]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 9.795755886443658e-07\n",
      "Predicción post entrenamiento : [[0.7676872]]\n",
      "PERDIDAAAA despues: 2.4090297756629298e-08\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "[[[0.72591716]\n",
      "  [0.73296422]\n",
      "  [0.73902363]\n",
      "  [0.74442506]\n",
      "  [0.75132978]\n",
      "  [0.75814903]\n",
      "  [0.76333898]\n",
      "  [0.76852173]]]\n",
      "ejemplar: [0.72591716 0.73296422 0.73902363 0.74442506 0.75132978 0.75814903\n",
      " 0.76333898 0.76852173]\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.7734247]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[0.72591716 0.73296422 0.73902363 0.74442506 0.75132978 0.75814903\n",
      "  0.76333898 0.76852173]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00033456055098213255\n",
      "Predicción post entrenamiento : [[0.77337694]]\n",
      "PERDIDAAAA despues: 0.0003328163002151996\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "[[[0.73296422]\n",
      "  [0.73902363]\n",
      "  [0.74442506]\n",
      "  [0.75132978]\n",
      "  [0.75814903]\n",
      "  [0.76333898]\n",
      "  [0.76852173]\n",
      "  [0.77342469]]]\n",
      "ejemplar: [0.73296422 0.73902363 0.74442506 0.75132978 0.75814903 0.76333898\n",
      " 0.76852173 0.77342469]\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.7789082]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[0.73296422 0.73902363 0.74442506 0.75132978 0.75814903 0.76333898\n",
      "  0.76852173 0.77342469]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011456983629614115\n",
      "Predicción post entrenamiento : [[0.7786619]]\n",
      "PERDIDAAAA despues: 0.0011290863621979952\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "[[[0.73902363]\n",
      "  [0.74442506]\n",
      "  [0.75132978]\n",
      "  [0.75814903]\n",
      "  [0.76333898]\n",
      "  [0.76852173]\n",
      "  [0.77342469]\n",
      "  [0.77890819]]]\n",
      "ejemplar: [0.73902363 0.74442506 0.75132978 0.75814903 0.76333898 0.76852173\n",
      " 0.77342469 0.77890819]\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.78392446]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[0.73902363 0.74442506 0.75132978 0.75814903 0.76333898 0.76852173\n",
      "  0.77342469 0.77890819]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001016997150145471\n",
      "Predicción post entrenamiento : [[0.782804]]\n",
      "PERDIDAAAA despues: 0.0009467894560657442\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "[[[0.74442506]\n",
      "  [0.75132978]\n",
      "  [0.75814903]\n",
      "  [0.76333898]\n",
      "  [0.76852173]\n",
      "  [0.77342469]\n",
      "  [0.77890819]\n",
      "  [0.78392446]]]\n",
      "ejemplar: [0.74442506 0.75132978 0.75814903 0.76333898 0.76852173 0.77342469\n",
      " 0.77890819 0.78392446]\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.7880103]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[0.74442506 0.75132978 0.75814903 0.76333898 0.76852173 0.77342469\n",
      "  0.77890819 0.78392446]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006116477306932211\n",
      "Predicción post entrenamiento : [[0.7874701]]\n",
      "PERDIDAAAA despues: 0.006032273638993502\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "[[[0.75132978]\n",
      "  [0.75814903]\n",
      "  [0.76333898]\n",
      "  [0.76852173]\n",
      "  [0.77342469]\n",
      "  [0.77890819]\n",
      "  [0.78392446]\n",
      "  [0.7880103 ]]]\n",
      "ejemplar: [0.75132978 0.75814903 0.76333898 0.76852173 0.77342469 0.77890819\n",
      " 0.78392446 0.7880103 ]\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.7927671]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[0.75132978 0.75814903 0.76333898 0.76852173 0.77342469 0.77890819\n",
      "  0.78392446 0.7880103 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010472874157130718\n",
      "Predicción post entrenamiento : [[0.79134965]]\n",
      "PERDIDAAAA despues: 0.010184766724705696\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "[[[0.75814903]\n",
      "  [0.76333898]\n",
      "  [0.76852173]\n",
      "  [0.77342469]\n",
      "  [0.77890819]\n",
      "  [0.78392446]\n",
      "  [0.7880103 ]\n",
      "  [0.79276711]]]\n",
      "ejemplar: [0.75814903 0.76333898 0.76852173 0.77342469 0.77890819 0.78392446\n",
      " 0.7880103  0.79276711]\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.79626983]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[0.75814903 0.76333898 0.76852173 0.77342469 0.77890819 0.78392446\n",
      "  0.7880103  0.79276711]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017565374728292227\n",
      "Predicción post entrenamiento : [[0.79588205]]\n",
      "PERDIDAAAA despues: 0.00172418262809515\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "[[[0.76333898]\n",
      "  [0.76852173]\n",
      "  [0.77342469]\n",
      "  [0.77890819]\n",
      "  [0.78392446]\n",
      "  [0.7880103 ]\n",
      "  [0.79276711]\n",
      "  [0.79626983]]]\n",
      "ejemplar: [0.76333898 0.76852173 0.77342469 0.77890819 0.78392446 0.7880103\n",
      " 0.79276711 0.79626983]\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.8003517]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[0.76333898 0.76852173 0.77342469 0.77890819 0.78392446 0.7880103\n",
      "  0.79276711 0.79626983]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006107576657086611\n",
      "Predicción post entrenamiento : [[0.80021465]]\n",
      "PERDIDAAAA despues: 0.006086177192628384\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "[[[0.76852173]\n",
      "  [0.77342469]\n",
      "  [0.77890819]\n",
      "  [0.78392446]\n",
      "  [0.7880103 ]\n",
      "  [0.79276711]\n",
      "  [0.79626983]\n",
      "  [0.80035168]]]\n",
      "ejemplar: [0.76852173 0.77342469 0.77890819 0.78392446 0.7880103  0.79276711\n",
      " 0.79626983 0.80035168]\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.8046051]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[0.76852173 0.77342469 0.77890819 0.78392446 0.7880103  0.79276711\n",
      "  0.79626983 0.80035168]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001927493722178042\n",
      "Predicción post entrenamiento : [[0.8043944]]\n",
      "PERDIDAAAA despues: 0.00194603914860636\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "[[[0.77342469]\n",
      "  [0.77890819]\n",
      "  [0.78392446]\n",
      "  [0.7880103 ]\n",
      "  [0.79276711]\n",
      "  [0.79626983]\n",
      "  [0.80035168]\n",
      "  [0.80460513]]]\n",
      "ejemplar: [0.77342469 0.77890819 0.78392446 0.7880103  0.79276711 0.79626983\n",
      " 0.80035168 0.80460513]\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.8086649]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[0.77342469 0.77890819 0.78392446 0.7880103  0.79276711 0.79626983\n",
      "  0.80035168 0.80460513]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0093698650598526\n",
      "Predicción post entrenamiento : [[0.8084427]]\n",
      "PERDIDAAAA despues: 0.009412932209670544\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "[[[0.77890819]\n",
      "  [0.78392446]\n",
      "  [0.7880103 ]\n",
      "  [0.79276711]\n",
      "  [0.79626983]\n",
      "  [0.80035168]\n",
      "  [0.80460513]\n",
      "  [0.80866492]]]\n",
      "ejemplar: [0.77890819 0.78392446 0.7880103  0.79276711 0.79626983 0.80035168\n",
      " 0.80460513 0.80866492]\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.81262636]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[0.77890819 0.78392446 0.7880103  0.79276711 0.79626983 0.80035168\n",
      "  0.80460513 0.80866492]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004842747468501329\n",
      "Predicción post entrenamiento : [[0.81173503]]\n",
      "PERDIDAAAA despues: 0.004967596847563982\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "[[[0.78392446]\n",
      "  [0.7880103 ]\n",
      "  [0.79276711]\n",
      "  [0.79626983]\n",
      "  [0.80035168]\n",
      "  [0.80460513]\n",
      "  [0.80866492]\n",
      "  [0.81262636]]]\n",
      "ejemplar: [0.78392446 0.7880103  0.79276711 0.79626983 0.80035168 0.80460513\n",
      " 0.80866492 0.81262636]\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.8156213]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[0.78392446 0.7880103  0.79276711 0.79626983 0.80035168 0.80460513\n",
      "  0.80866492 0.81262636]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008494638837873936\n",
      "Predicción post entrenamiento : [[0.8153929]]\n",
      "PERDIDAAAA despues: 0.008536793291568756\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "[[[0.7880103 ]\n",
      "  [0.79276711]\n",
      "  [0.79626983]\n",
      "  [0.80035168]\n",
      "  [0.80460513]\n",
      "  [0.80866492]\n",
      "  [0.81262636]\n",
      "  [0.81562132]]]\n",
      "ejemplar: [0.7880103  0.79276711 0.79626983 0.80035168 0.80460513 0.80866492\n",
      " 0.81262636 0.81562132]\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.81905055]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[0.7880103  0.79276711 0.79626983 0.80035168 0.80460513 0.80866492\n",
      "  0.81262636 0.81562132]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0049740769900381565\n",
      "Predicción post entrenamiento : [[0.8201468]]\n",
      "PERDIDAAAA despues: 0.004820648115128279\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "[[[0.79276711]\n",
      "  [0.79626983]\n",
      "  [0.80035168]\n",
      "  [0.80460513]\n",
      "  [0.80866492]\n",
      "  [0.81262636]\n",
      "  [0.81562132]\n",
      "  [0.81905055]]]\n",
      "ejemplar: [0.79276711 0.79626983 0.80035168 0.80460513 0.80866492 0.81262636\n",
      " 0.81562132 0.81905055]\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.8237952]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[0.79276711 0.79626983 0.80035168 0.80460513 0.80866492 0.81262636\n",
      "  0.81562132 0.81905055]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002607070840895176\n",
      "Predicción post entrenamiento : [[0.8242784]]\n",
      "PERDIDAAAA despues: 0.0025579589419066906\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "[[[0.79626983]\n",
      "  [0.80035168]\n",
      "  [0.80460513]\n",
      "  [0.80866492]\n",
      "  [0.81262636]\n",
      "  [0.81562132]\n",
      "  [0.81905055]\n",
      "  [0.8237952 ]]]\n",
      "ejemplar: [0.79626983 0.80035168 0.80460513 0.80866492 0.81262636 0.81562132\n",
      " 0.81905055 0.8237952 ]\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.8277069]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[0.79626983 0.80035168 0.80460513 0.80866492 0.81262636 0.81562132\n",
      "  0.81905055 0.8237952 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0073111169040203094\n",
      "Predicción post entrenamiento : [[0.8288056]]\n",
      "PERDIDAAAA despues: 0.007124426309019327\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "[[[0.80035168]\n",
      "  [0.80460513]\n",
      "  [0.80866492]\n",
      "  [0.81262636]\n",
      "  [0.81562132]\n",
      "  [0.81905055]\n",
      "  [0.8237952 ]\n",
      "  [0.82770687]]]\n",
      "ejemplar: [0.80035168 0.80460513 0.80866492 0.81262636 0.81562132 0.81905055\n",
      " 0.8237952  0.82770687]\n",
      "y: 1.0\n",
      "Predicción : [[0.8323437]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[0.80035168 0.80460513 0.80866492 0.81262636 0.81562132 0.81905055\n",
      "  0.8237952  0.82770687]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.028108635917305946\n",
      "Predicción post entrenamiento : [[0.83305264]]\n",
      "PERDIDAAAA despues: 0.027871422469615936\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "[[[0.80460513]\n",
      "  [0.80866492]\n",
      "  [0.81262636]\n",
      "  [0.81562132]\n",
      "  [0.81905055]\n",
      "  [0.8237952 ]\n",
      "  [0.82770687]\n",
      "  [0.8323437 ]]]\n",
      "ejemplar: [0.80460513 0.80866492 0.81262636 0.81562132 0.81905055 0.8237952\n",
      " 0.82770687 0.8323437 ]\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.83654755]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[0.80460513 0.80866492 0.81262636 0.81562132 0.81905055 0.8237952\n",
      "  0.82770687 0.8323437 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017957741394639015\n",
      "Predicción post entrenamiento : [[0.8373806]]\n",
      "PERDIDAAAA despues: 0.01773517206311226\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "[[[0.80866492]\n",
      "  [0.81262636]\n",
      "  [0.81562132]\n",
      "  [0.81905055]\n",
      "  [0.8237952 ]\n",
      "  [0.82770687]\n",
      "  [0.8323437 ]\n",
      "  [0.83654755]]]\n",
      "ejemplar: [0.80866492 0.81262636 0.81562132 0.81905055 0.8237952  0.82770687\n",
      " 0.8323437  0.83654755]\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.84078175]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[0.80866492 0.81262636 0.81562132 0.81905055 0.8237952  0.82770687\n",
      "  0.8323437  0.83654755]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0023060182575136423\n",
      "Predicción post entrenamiento : [[0.84115964]]\n",
      "PERDIDAAAA despues: 0.002269867341965437\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "[[[0.81262636]\n",
      "  [0.81562132]\n",
      "  [0.81905055]\n",
      "  [0.8237952 ]\n",
      "  [0.82770687]\n",
      "  [0.8323437 ]\n",
      "  [0.83654755]\n",
      "  [0.84078175]]]\n",
      "ejemplar: [0.81262636 0.81562132 0.81905055 0.8237952  0.82770687 0.8323437\n",
      " 0.83654755 0.84078175]\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.84452164]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[0.81262636 0.81562132 0.81905055 0.8237952  0.82770687 0.8323437\n",
      "  0.83654755 0.84078175]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011177429696545005\n",
      "Predicción post entrenamiento : [[0.8447004]]\n",
      "PERDIDAAAA despues: 0.0011058223899453878\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "[[[0.81562132]\n",
      "  [0.81905055]\n",
      "  [0.8237952 ]\n",
      "  [0.82770687]\n",
      "  [0.8323437 ]\n",
      "  [0.83654755]\n",
      "  [0.84078175]\n",
      "  [0.84452164]]]\n",
      "ejemplar: [0.81562132 0.81905055 0.8237952  0.82770687 0.8323437  0.83654755\n",
      " 0.84078175 0.84452164]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.8480617]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[0.81562132 0.81905055 0.8237952  0.82770687 0.8323437  0.83654755\n",
      "  0.84078175 0.84452164]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.957351388336974e-07\n",
      "Predicción post entrenamiento : [[0.848136]]\n",
      "PERDIDAAAA despues: 5.772662916569971e-07\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "[[[0.81905055]\n",
      "  [0.8237952 ]\n",
      "  [0.82770687]\n",
      "  [0.8323437 ]\n",
      "  [0.83654755]\n",
      "  [0.84078175]\n",
      "  [0.84452164]\n",
      "  [0.84806168]]]\n",
      "ejemplar: [0.81905055 0.8237952  0.82770687 0.8323437  0.83654755 0.84078175\n",
      " 0.84452164 0.84806168]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.8517911]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[0.81905055 0.8237952  0.82770687 0.8323437  0.83654755 0.84078175\n",
      "  0.84452164 0.84806168]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003104044299107045\n",
      "Predicción post entrenamiento : [[0.85086215]]\n",
      "PERDIDAAAA despues: 0.00027853474603034556\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "[[[0.8237952 ]\n",
      "  [0.82770687]\n",
      "  [0.8323437 ]\n",
      "  [0.83654755]\n",
      "  [0.84078175]\n",
      "  [0.84452164]\n",
      "  [0.84806168]\n",
      "  [0.85179108]]]\n",
      "ejemplar: [0.8237952  0.82770687 0.8323437  0.83654755 0.84078175 0.84452164\n",
      " 0.84806168 0.85179108]\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.8547221]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[0.8237952  0.82770687 0.8323437  0.83654755 0.84078175 0.84452164\n",
      "  0.84806168 0.85179108]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.390000079481979e-07\n",
      "Predicción post entrenamiento : [[0.8537919]]\n",
      "PERDIDAAAA despues: 1.6978536905298824e-06\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "[[[0.82770687]\n",
      "  [0.8323437 ]\n",
      "  [0.83654755]\n",
      "  [0.84078175]\n",
      "  [0.84452164]\n",
      "  [0.84806168]\n",
      "  [0.85179108]\n",
      "  [0.85472208]]]\n",
      "ejemplar: [0.82770687 0.8323437  0.83654755 0.84078175 0.84452164 0.84806168\n",
      " 0.85179108 0.85472208]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.85747916]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[0.82770687 0.8323437  0.83654755 0.84078175 0.84452164 0.84806168\n",
      "  0.85179108 0.85472208]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003155248414259404\n",
      "Predicción post entrenamiento : [[0.8558052]]\n",
      "PERDIDAAAA despues: 0.00037779525155201554\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "[[[0.8323437 ]\n",
      "  [0.83654755]\n",
      "  [0.84078175]\n",
      "  [0.84452164]\n",
      "  [0.84806168]\n",
      "  [0.85179108]\n",
      "  [0.85472208]\n",
      "  [0.85747916]]]\n",
      "ejemplar: [0.8323437  0.83654755 0.84078175 0.84452164 0.84806168 0.85179108\n",
      " 0.85472208 0.85747916]\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.8595081]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[0.8323437  0.83654755 0.84078175 0.84452164 0.84806168 0.85179108\n",
      "  0.85472208 0.85747916]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.130166639195522e-06\n",
      "Predicción post entrenamiento : [[0.86024153]]\n",
      "PERDIDAAAA despues: 1.029994382406585e-05\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "[[[0.83654755]\n",
      "  [0.84078175]\n",
      "  [0.84452164]\n",
      "  [0.84806168]\n",
      "  [0.85179108]\n",
      "  [0.85472208]\n",
      "  [0.85747916]\n",
      "  [0.8595081 ]]]\n",
      "ejemplar: [0.83654755 0.84078175 0.84452164 0.84806168 0.85179108 0.85472208\n",
      " 0.85747916 0.8595081 ]\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.8637117]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[0.83654755 0.84078175 0.84452164 0.84806168 0.85179108 0.85472208\n",
      "  0.85747916 0.8595081 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001864201476564631\n",
      "Predicción post entrenamiento : [[0.8639461]]\n",
      "PERDIDAAAA despues: 0.00019287492614239454\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "[[[0.84078175]\n",
      "  [0.84452164]\n",
      "  [0.84806168]\n",
      "  [0.85179108]\n",
      "  [0.85472208]\n",
      "  [0.85747916]\n",
      "  [0.8595081 ]\n",
      "  [0.86371171]]]\n",
      "ejemplar: [0.84078175 0.84452164 0.84806168 0.85179108 0.85472208 0.85747916\n",
      " 0.8595081  0.86371171]\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.86724174]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[0.84078175 0.84452164 0.84806168 0.85179108 0.85472208 0.85747916\n",
      "  0.8595081  0.86371171]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006024635513313115\n",
      "Predicción post entrenamiento : [[0.8675639]]\n",
      "PERDIDAAAA despues: 0.0006183824152685702\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "[[[0.84452164]\n",
      "  [0.84806168]\n",
      "  [0.85179108]\n",
      "  [0.85472208]\n",
      "  [0.85747916]\n",
      "  [0.8595081 ]\n",
      "  [0.86371171]\n",
      "  [0.86724174]]]\n",
      "ejemplar: [0.84452164 0.84806168 0.85179108 0.85472208 0.85747916 0.8595081\n",
      " 0.86371171 0.86724174]\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.87062573]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[0.84452164 0.84806168 0.85179108 0.85472208 0.85747916 0.8595081\n",
      "  0.86371171 0.86724174]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0022742312867194414\n",
      "Predicción post entrenamiento : [[0.87086165]]\n",
      "PERDIDAAAA despues: 0.002296788152307272\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "[[[0.84806168]\n",
      "  [0.85179108]\n",
      "  [0.85472208]\n",
      "  [0.85747916]\n",
      "  [0.8595081 ]\n",
      "  [0.86371171]\n",
      "  [0.86724174]\n",
      "  [0.87062573]]]\n",
      "ejemplar: [0.84806168 0.85179108 0.85472208 0.85747916 0.8595081  0.86371171\n",
      " 0.86724174 0.87062573]\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.8737893]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[0.84806168 0.85179108 0.85472208 0.85747916 0.8595081  0.86371171\n",
      "  0.86724174 0.87062573]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009857169352471828\n",
      "Predicción post entrenamiento : [[0.8736194]]\n",
      "PERDIDAAAA despues: 0.009823455475270748\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "[[[0.85179108]\n",
      "  [0.85472208]\n",
      "  [0.85747916]\n",
      "  [0.8595081 ]\n",
      "  [0.86371171]\n",
      "  [0.86724174]\n",
      "  [0.87062573]\n",
      "  [0.87378931]]]\n",
      "ejemplar: [0.85179108 0.85472208 0.85747916 0.8595081  0.86371171 0.86724174\n",
      " 0.87062573 0.87378931]\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.8764493]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[0.85179108 0.85472208 0.85747916 0.8595081  0.86371171 0.86724174\n",
      "  0.87062573 0.87378931]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008511380292475224\n",
      "Predicción post entrenamiento : [[0.8741084]]\n",
      "PERDIDAAAA despues: 0.00808492861688137\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "[[[0.85472208]\n",
      "  [0.85747916]\n",
      "  [0.8595081 ]\n",
      "  [0.86371171]\n",
      "  [0.86724174]\n",
      "  [0.87062573]\n",
      "  [0.87378931]\n",
      "  [0.87644929]]]\n",
      "ejemplar: [0.85472208 0.85747916 0.8595081  0.86371171 0.86724174 0.87062573\n",
      " 0.87378931 0.87644929]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.8767685]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[0.85472208 0.85747916 0.8595081  0.86371171 0.86724174 0.87062573\n",
      "  0.87378931 0.87644929]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002898240345530212\n",
      "Predicción post entrenamiento : [[0.8760893]]\n",
      "PERDIDAAAA despues: 0.00026715785497799516\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "[[[0.85747916]\n",
      "  [0.8595081 ]\n",
      "  [0.86371171]\n",
      "  [0.86724174]\n",
      "  [0.87062573]\n",
      "  [0.87378931]\n",
      "  [0.87644929]\n",
      "  [0.87676853]]]\n",
      "ejemplar: [0.85747916 0.8595081  0.86371171 0.86724174 0.87062573 0.87378931\n",
      " 0.87644929 0.87676853]\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.878783]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[0.85747916 0.8595081  0.86371171 0.86724174 0.87062573 0.87378931\n",
      "  0.87644929 0.87676853]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005984353483654559\n",
      "Predicción post entrenamiento : [[0.87970454]]\n",
      "PERDIDAAAA despues: 0.0006443721358664334\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "[[[0.8595081 ]\n",
      "  [0.86371171]\n",
      "  [0.86724174]\n",
      "  [0.87062573]\n",
      "  [0.87378931]\n",
      "  [0.87644929]\n",
      "  [0.87676853]\n",
      "  [0.87878299]]]\n",
      "ejemplar: [0.8595081  0.86371171 0.86724174 0.87062573 0.87378931 0.87644929\n",
      " 0.87676853 0.87878299]\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.88246703]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[0.8595081  0.86371171 0.86724174 0.87062573 0.87378931 0.87644929\n",
      "  0.87676853 0.87878299]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002077729208394885\n",
      "Predicción post entrenamiento : [[0.88154507]]\n",
      "PERDIDAAAA despues: 0.001994529040530324\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "[[[0.86371171]\n",
      "  [0.86724174]\n",
      "  [0.87062573]\n",
      "  [0.87378931]\n",
      "  [0.87644929]\n",
      "  [0.87676853]\n",
      "  [0.87878299]\n",
      "  [0.88246703]]]\n",
      "ejemplar: [0.86371171 0.86724174 0.87062573 0.87378931 0.87644929 0.87676853\n",
      " 0.87878299 0.88246703]\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.88457215]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[0.86371171 0.86724174 0.87062573 0.87378931 0.87644929 0.87676853\n",
      "  0.87878299 0.88246703]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029878548812121153\n",
      "Predicción post entrenamiento : [[0.88521713]]\n",
      "PERDIDAAAA despues: 0.00305878184735775\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "[[[0.86724174]\n",
      "  [0.87062573]\n",
      "  [0.87378931]\n",
      "  [0.87644929]\n",
      "  [0.87676853]\n",
      "  [0.87878299]\n",
      "  [0.88246703]\n",
      "  [0.88457215]]]\n",
      "ejemplar: [0.86724174 0.87062573 0.87378931 0.87644929 0.87676853 0.87878299\n",
      " 0.88246703 0.88457215]\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.887867]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[0.86724174 0.87062573 0.87378931 0.87644929 0.87676853 0.87878299\n",
      "  0.88246703 0.88457215]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.7698058008572843e-07\n",
      "Predicción post entrenamiento : [[0.8876087]]\n",
      "PERDIDAAAA despues: 1.2653708836296573e-07\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "[[[0.87062573]\n",
      "  [0.87378931]\n",
      "  [0.87644929]\n",
      "  [0.87676853]\n",
      "  [0.87878299]\n",
      "  [0.88246703]\n",
      "  [0.88457215]\n",
      "  [0.88786697]]]\n",
      "ejemplar: [0.87062573 0.87378931 0.87644929 0.87676853 0.87878299 0.88246703\n",
      " 0.88457215 0.88786697]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.8899972]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[0.87062573 0.87378931 0.87644929 0.87676853 0.87878299 0.88246703\n",
      "  0.88457215 0.88786697]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009152363636530936\n",
      "Predicción post entrenamiento : [[0.8890654]]\n",
      "PERDIDAAAA despues: 0.0008597254054620862\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "[[[0.87378931]\n",
      "  [0.87644929]\n",
      "  [0.87676853]\n",
      "  [0.87878299]\n",
      "  [0.88246703]\n",
      "  [0.88457215]\n",
      "  [0.88786697]\n",
      "  [0.88999718]]]\n",
      "ejemplar: [0.87378931 0.87644929 0.87676853 0.87878299 0.88246703 0.88457215\n",
      " 0.88786697 0.88999718]\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.8911861]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[0.87378931 0.87644929 0.87676853 0.87878299 0.88246703 0.88457215\n",
      "  0.88786697 0.88999718]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002661432372406125\n",
      "Predicción post entrenamiento : [[0.89161485]]\n",
      "PERDIDAAAA despues: 0.0027058522682636976\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "[[[0.87644929]\n",
      "  [0.87676853]\n",
      "  [0.87878299]\n",
      "  [0.88246703]\n",
      "  [0.88457215]\n",
      "  [0.88786697]\n",
      "  [0.88999718]\n",
      "  [0.89118612]]]\n",
      "ejemplar: [0.87644929 0.87676853 0.87878299 0.88246703 0.88457215 0.88786697\n",
      " 0.88999718 0.89118612]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.8934908]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[0.87644929 0.87676853 0.87878299 0.88246703 0.88457215 0.88786697\n",
      "  0.88999718 0.89118612]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012031035497784615\n",
      "Predicción post entrenamiento : [[0.8936388]]\n",
      "PERDIDAAAA despues: 0.012063523754477501\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "[[[0.87676853]\n",
      "  [0.87878299]\n",
      "  [0.88246703]\n",
      "  [0.88457215]\n",
      "  [0.88786697]\n",
      "  [0.88999718]\n",
      "  [0.89118612]\n",
      "  [0.89349079]]]\n",
      "ejemplar: [0.87676853 0.87878299 0.88246703 0.88457215 0.88786697 0.88999718\n",
      " 0.89118612 0.89349079]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.895389]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[0.87676853 0.87878299 0.88246703 0.88457215 0.88786697 0.88999718\n",
      "  0.89118612 0.89349079]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005944645497947931\n",
      "Predicción post entrenamiento : [[0.89410466]]\n",
      "PERDIDAAAA despues: 0.005748243071138859\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "[[[0.87878299]\n",
      "  [0.88246703]\n",
      "  [0.88457215]\n",
      "  [0.88786697]\n",
      "  [0.88999718]\n",
      "  [0.89118612]\n",
      "  [0.89349079]\n",
      "  [0.89538902]]]\n",
      "ejemplar: [0.87878299 0.88246703 0.88457215 0.88786697 0.88999718 0.89118612\n",
      " 0.89349079 0.89538902]\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.8964096]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[0.87878299 0.88246703 0.88457215 0.88786697 0.88999718 0.89118612\n",
      "  0.89349079 0.89538902]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011076170019805431\n",
      "Predicción post entrenamiento : [[0.8948834]]\n",
      "PERDIDAAAA despues: 0.010757259093225002\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "[[[0.88246703]\n",
      "  [0.88457215]\n",
      "  [0.88786697]\n",
      "  [0.88999718]\n",
      "  [0.89118612]\n",
      "  [0.89349079]\n",
      "  [0.89538902]\n",
      "  [0.89640957]]]\n",
      "ejemplar: [0.88246703 0.88457215 0.88786697 0.88999718 0.89118612 0.89349079\n",
      " 0.89538902 0.89640957]\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.8973016]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[0.88246703 0.88457215 0.88786697 0.88999718 0.89118612 0.89349079\n",
      "  0.89538902 0.89640957]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018698830157518387\n",
      "Predicción post entrenamiento : [[0.8959536]]\n",
      "PERDIDAAAA despues: 0.0183319803327322\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "[[[0.88457215]\n",
      "  [0.88786697]\n",
      "  [0.88999718]\n",
      "  [0.89118612]\n",
      "  [0.89349079]\n",
      "  [0.89538902]\n",
      "  [0.89640957]\n",
      "  [0.89730161]]]\n",
      "ejemplar: [0.88457215 0.88786697 0.88999718 0.89118612 0.89349079 0.89538902\n",
      " 0.89640957 0.89730161]\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.8979664]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[0.88457215 0.88786697 0.88999718 0.89118612 0.89349079 0.89538902\n",
      "  0.89640957 0.89730161]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011323664337396622\n",
      "Predicción post entrenamiento : [[0.89693755]]\n",
      "PERDIDAAAA despues: 0.011105760931968689\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "[[[0.88786697]\n",
      "  [0.88999718]\n",
      "  [0.89118612]\n",
      "  [0.89349079]\n",
      "  [0.89538902]\n",
      "  [0.89640957]\n",
      "  [0.89730161]\n",
      "  [0.89796638]]]\n",
      "ejemplar: [0.88786697 0.88999718 0.89118612 0.89349079 0.89538902 0.89640957\n",
      " 0.89730161 0.89796638]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.89891213]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[0.88786697 0.88999718 0.89118612 0.89349079 0.89538902 0.89640957\n",
      "  0.89730161 0.89796638]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016956688836216927\n",
      "Predicción post entrenamiento : [[0.8968852]]\n",
      "PERDIDAAAA despues: 0.01643291488289833\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "[[[0.88999718]\n",
      "  [0.89118612]\n",
      "  [0.89349079]\n",
      "  [0.89538902]\n",
      "  [0.89640957]\n",
      "  [0.89730161]\n",
      "  [0.89796638]\n",
      "  [0.89891213]]]\n",
      "ejemplar: [0.88999718 0.89118612 0.89349079 0.89538902 0.89640957 0.89730161\n",
      " 0.89796638 0.89891213]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.8984204]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[0.88999718 0.89118612 0.89349079 0.89538902 0.89640957 0.89730161\n",
      "  0.89796638 0.89891213]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016828864812850952\n",
      "Predicción post entrenamiento : [[0.89792424]]\n",
      "PERDIDAAAA despues: 0.0167003832757473\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "[[[0.89118612]\n",
      "  [0.89349079]\n",
      "  [0.89538902]\n",
      "  [0.89640957]\n",
      "  [0.89730161]\n",
      "  [0.89796638]\n",
      "  [0.89891213]\n",
      "  [0.89842039]]]\n",
      "ejemplar: [0.89118612 0.89349079 0.89538902 0.89640957 0.89730161 0.89796638\n",
      " 0.89891213 0.89842039]\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.89926064]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[0.89118612 0.89349079 0.89538902 0.89640957 0.89730161 0.89796638\n",
      "  0.89891213 0.89842039]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010069217532873154\n",
      "Predicción post entrenamiento : [[0.8999979]]\n",
      "PERDIDAAAA despues: 0.01021772064268589\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "[[[0.89349079]\n",
      "  [0.89538902]\n",
      "  [0.89640957]\n",
      "  [0.89730161]\n",
      "  [0.89796638]\n",
      "  [0.89891213]\n",
      "  [0.89842039]\n",
      "  [0.89926064]]]\n",
      "ejemplar: [0.89349079 0.89538902 0.89640957 0.89730161 0.89796638 0.89891213\n",
      " 0.89842039 0.89926064]\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.9013488]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[0.89349079 0.89538902 0.89640957 0.89730161 0.89796638 0.89891213\n",
      "  0.89842039 0.89926064]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012397694401443005\n",
      "Predicción post entrenamiento : [[0.9015481]]\n",
      "PERDIDAAAA despues: 0.012442106381058693\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "[[[0.89538902]\n",
      "  [0.89640957]\n",
      "  [0.89730161]\n",
      "  [0.89796638]\n",
      "  [0.89891213]\n",
      "  [0.89842039]\n",
      "  [0.89926064]\n",
      "  [0.90134883]]]\n",
      "ejemplar: [0.89538902 0.89640957 0.89730161 0.89796638 0.89891213 0.89842039\n",
      " 0.89926064 0.90134883]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.9025554]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[0.89538902 0.89640957 0.89730161 0.89796638 0.89891213 0.89842039\n",
      "  0.89926064 0.90134883]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.020273473113775253\n",
      "Predicción post entrenamiento : [[0.90203494]]\n",
      "PERDIDAAAA despues: 0.020125530660152435\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "[[[0.89640957]\n",
      "  [0.89730161]\n",
      "  [0.89796638]\n",
      "  [0.89891213]\n",
      "  [0.89842039]\n",
      "  [0.89926064]\n",
      "  [0.90134883]\n",
      "  [0.90255541]]]\n",
      "ejemplar: [0.89640957 0.89730161 0.89796638 0.89891213 0.89842039 0.89926064\n",
      " 0.90134883 0.90255541]\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.9027544]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[0.89640957 0.89730161 0.89796638 0.89891213 0.89842039 0.89926064\n",
      "  0.90134883 0.90255541]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.047245871275663376\n",
      "Predicción post entrenamiento : [[0.9009437]]\n",
      "PERDIDAAAA despues: 0.046461984515190125\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "[[[0.89730161]\n",
      "  [0.89796638]\n",
      "  [0.89891213]\n",
      "  [0.89842039]\n",
      "  [0.89926064]\n",
      "  [0.90134883]\n",
      "  [0.90255541]\n",
      "  [0.90275443]]]\n",
      "ejemplar: [0.89730161 0.89796638 0.89891213 0.89842039 0.89926064 0.90134883\n",
      " 0.90255541 0.90275443]\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.9015928]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[0.89730161 0.89796638 0.89891213 0.89842039 0.89926064 0.90134883\n",
      "  0.90255541 0.90275443]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0878535658121109\n",
      "Predicción post entrenamiento : [[0.9010953]]\n",
      "PERDIDAAAA despues: 0.08755888044834137\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "[[[0.89796638]\n",
      "  [0.89891213]\n",
      "  [0.89842039]\n",
      "  [0.89926064]\n",
      "  [0.90134883]\n",
      "  [0.90255541]\n",
      "  [0.90275443]\n",
      "  [0.90159279]]]\n",
      "ejemplar: [0.89796638 0.89891213 0.89842039 0.89926064 0.90134883 0.90255541\n",
      " 0.90275443 0.90159279]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9016966]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[0.89796638 0.89891213 0.89842039 0.89926064 0.90134883 0.90255541\n",
      "  0.90275443 0.90159279]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05609225854277611\n",
      "Predicción post entrenamiento : [[0.9009029]]\n",
      "PERDIDAAAA despues: 0.05571693554520607\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "[[[0.89891213]\n",
      "  [0.89842039]\n",
      "  [0.89926064]\n",
      "  [0.90134883]\n",
      "  [0.90255541]\n",
      "  [0.90275443]\n",
      "  [0.90159279]\n",
      "  [0.90169662]]]\n",
      "ejemplar: [0.89891213 0.89842039 0.89926064 0.90134883 0.90255541 0.90275443\n",
      " 0.90159279 0.90169662]\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.9015052]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[0.89891213 0.89842039 0.89926064 0.90134883 0.90255541 0.90275443\n",
      "  0.90159279 0.90169662]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03749644756317139\n",
      "Predicción post entrenamiento : [[0.90060407]]\n",
      "PERDIDAAAA despues: 0.03714827820658684\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "[[[0.89842039]\n",
      "  [0.89926064]\n",
      "  [0.90134883]\n",
      "  [0.90255541]\n",
      "  [0.90275443]\n",
      "  [0.90159279]\n",
      "  [0.90169662]\n",
      "  [0.90150517]]]\n",
      "ejemplar: [0.89842039 0.89926064 0.90134883 0.90255541 0.90275443 0.90159279\n",
      " 0.90169662 0.90150517]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9011047]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[0.89842039 0.89926064 0.90134883 0.90255541 0.90275443 0.90159279\n",
      "  0.90169662 0.90150517]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05581222474575043\n",
      "Predicción post entrenamiento : [[0.9007192]]\n",
      "PERDIDAAAA despues: 0.05563024431467056\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "[[[0.89926064]\n",
      "  [0.90134883]\n",
      "  [0.90255541]\n",
      "  [0.90275443]\n",
      "  [0.90159279]\n",
      "  [0.90169662]\n",
      "  [0.90150517]\n",
      "  [0.90110469]]]\n",
      "ejemplar: [0.89926064 0.90134883 0.90255541 0.90275443 0.90159279 0.90169662\n",
      " 0.90150517 0.90110469]\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.90150255]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[0.89926064 0.90134883 0.90255541 0.90275443 0.90159279 0.90169662\n",
      "  0.90150517 0.90110469]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.036157168447971344\n",
      "Predicción post entrenamiento : [[0.90050524]]\n",
      "PERDIDAAAA despues: 0.03577888756990433\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "[[[0.90134883]\n",
      "  [0.90255541]\n",
      "  [0.90275443]\n",
      "  [0.90159279]\n",
      "  [0.90169662]\n",
      "  [0.90150517]\n",
      "  [0.90110469]\n",
      "  [0.90150255]]]\n",
      "ejemplar: [0.90134883 0.90255541 0.90275443 0.90159279 0.90169662 0.90150517\n",
      " 0.90110469 0.90150255]\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.9011811]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[0.90134883 0.90255541 0.90275443 0.90159279 0.90169662 0.90150517\n",
      "  0.90110469 0.90150255]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05014205724000931\n",
      "Predicción post entrenamiento : [[0.899756]]\n",
      "PERDIDAAAA despues: 0.04950586333870888\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "[[[0.90255541]\n",
      "  [0.90275443]\n",
      "  [0.90159279]\n",
      "  [0.90169662]\n",
      "  [0.90150517]\n",
      "  [0.90110469]\n",
      "  [0.90150255]\n",
      "  [0.9011811 ]]]\n",
      "ejemplar: [0.90255541 0.90275443 0.90159279 0.90169662 0.90150517 0.90110469\n",
      " 0.90150255 0.9011811 ]\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.89990145]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[0.90255541 0.90275443 0.90159279 0.90169662 0.90150517 0.90110469\n",
      "  0.90150255 0.9011811 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018987109884619713\n",
      "Predicción post entrenamiento : [[0.89887625]]\n",
      "PERDIDAAAA despues: 0.01870562881231308\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "[[[0.90275443]\n",
      "  [0.90159279]\n",
      "  [0.90169662]\n",
      "  [0.90150517]\n",
      "  [0.90110469]\n",
      "  [0.90150255]\n",
      "  [0.9011811 ]\n",
      "  [0.89990145]]]\n",
      "ejemplar: [0.90275443 0.90159279 0.90169662 0.90150517 0.90110469 0.90150255\n",
      " 0.9011811  0.89990145]\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.8986496]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[0.90275443 0.90159279 0.90169662 0.90150517 0.90110469 0.90150255\n",
      "  0.9011811  0.89990145]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008390199393033981\n",
      "Predicción post entrenamiento : [[0.89842236]]\n",
      "PERDIDAAAA despues: 0.008348627015948296\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "[[[0.90159279]\n",
      "  [0.90169662]\n",
      "  [0.90150517]\n",
      "  [0.90110469]\n",
      "  [0.90150255]\n",
      "  [0.9011811 ]\n",
      "  [0.89990145]\n",
      "  [0.89864957]]]\n",
      "ejemplar: [0.90159279 0.90169662 0.90150517 0.90110469 0.90150255 0.9011811\n",
      " 0.89990145 0.89864957]\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.8980522]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[0.90159279 0.90169662 0.90150517 0.90110469 0.90150255 0.9011811\n",
      "  0.89990145 0.89864957]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006866489537060261\n",
      "Predicción post entrenamiento : [[0.8968537]]\n",
      "PERDIDAAAA despues: 0.006669295486062765\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "[[[0.90169662]\n",
      "  [0.90150517]\n",
      "  [0.90110469]\n",
      "  [0.90150255]\n",
      "  [0.9011811 ]\n",
      "  [0.89990145]\n",
      "  [0.89864957]\n",
      "  [0.89805222]]]\n",
      "ejemplar: [0.90169662 0.90150517 0.90110469 0.90150255 0.9011811  0.89990145\n",
      " 0.89864957 0.89805222]\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.89671034]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[0.90169662 0.90150517 0.90110469 0.90150255 0.9011811  0.89990145\n",
      "  0.89864957 0.89805222]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 9.07744761207141e-05\n",
      "Predicción post entrenamiento : [[0.8963855]]\n",
      "PERDIDAAAA despues: 9.706996934255585e-05\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "[[[0.90150517]\n",
      "  [0.90110469]\n",
      "  [0.90150255]\n",
      "  [0.9011811 ]\n",
      "  [0.89990145]\n",
      "  [0.89864957]\n",
      "  [0.89805222]\n",
      "  [0.89671034]]]\n",
      "ejemplar: [0.90150517 0.90110469 0.90150255 0.9011811  0.89990145 0.89864957\n",
      " 0.89805222 0.89671034]\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.89610434]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[0.90150517 0.90110469 0.90150255 0.9011811  0.89990145 0.89864957\n",
      "  0.89805222 0.89671034]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004045112058520317\n",
      "Predicción post entrenamiento : [[0.8967978]]\n",
      "PERDIDAAAA despues: 0.003957385662943125\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "[[[0.90110469]\n",
      "  [0.90150255]\n",
      "  [0.9011811 ]\n",
      "  [0.89990145]\n",
      "  [0.89864957]\n",
      "  [0.89805222]\n",
      "  [0.89671034]\n",
      "  [0.89610434]]]\n",
      "ejemplar: [0.90110469 0.90150255 0.9011811  0.89990145 0.89864957 0.89805222\n",
      " 0.89671034 0.89610434]\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.89642084]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[0.90110469 0.90150255 0.9011811  0.89990145 0.89864957 0.89805222\n",
      "  0.89671034 0.89610434]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004615033511072397\n",
      "Predicción post entrenamiento : [[0.89602053]]\n",
      "PERDIDAAAA despues: 0.0046695820055902\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "[[[0.90150255]\n",
      "  [0.9011811 ]\n",
      "  [0.89990145]\n",
      "  [0.89864957]\n",
      "  [0.89805222]\n",
      "  [0.89671034]\n",
      "  [0.89610434]\n",
      "  [0.89642084]]]\n",
      "ejemplar: [0.90150255 0.9011811  0.89990145 0.89864957 0.89805222 0.89671034\n",
      " 0.89610434 0.89642084]\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.89558077]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[0.90150255 0.9011811  0.89990145 0.89864957 0.89805222 0.89671034\n",
      "  0.89610434 0.89642084]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.7045726862270385e-05\n",
      "Predicción post entrenamiento : [[0.8956945]]\n",
      "PERDIDAAAA despues: 5.877656803932041e-05\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "[[[0.9011811 ]\n",
      "  [0.89990145]\n",
      "  [0.89864957]\n",
      "  [0.89805222]\n",
      "  [0.89671034]\n",
      "  [0.89610434]\n",
      "  [0.89642084]\n",
      "  [0.89558077]]]\n",
      "ejemplar: [0.9011811  0.89990145 0.89864957 0.89805222 0.89671034 0.89610434\n",
      " 0.89642084 0.89558077]\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.89493895]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[0.9011811  0.89990145 0.89864957 0.89805222 0.89671034 0.89610434\n",
      "  0.89642084 0.89558077]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.115278781886445e-06\n",
      "Predicción post entrenamiento : [[0.8933005]]\n",
      "PERDIDAAAA despues: 3.884108537022257e-07\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "[[[0.89990145]\n",
      "  [0.89864957]\n",
      "  [0.89805222]\n",
      "  [0.89671034]\n",
      "  [0.89610434]\n",
      "  [0.89642084]\n",
      "  [0.89558077]\n",
      "  [0.89493895]]]\n",
      "ejemplar: [0.89990145 0.89864957 0.89805222 0.89671034 0.89610434 0.89642084\n",
      " 0.89558077 0.89493895]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.89240205]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[0.89990145 0.89864957 0.89805222 0.89671034 0.89610434 0.89642084\n",
      "  0.89558077 0.89493895]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002944614680018276\n",
      "Predicción post entrenamiento : [[0.89191294]]\n",
      "PERDIDAAAA despues: 0.0002779143687803298\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "[[[0.89864957]\n",
      "  [0.89805222]\n",
      "  [0.89671034]\n",
      "  [0.89610434]\n",
      "  [0.89642084]\n",
      "  [0.89558077]\n",
      "  [0.89493895]\n",
      "  [0.89240205]]]\n",
      "ejemplar: [0.89864957 0.89805222 0.89671034 0.89610434 0.89642084 0.89558077\n",
      " 0.89493895 0.89240205]\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.89113754]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[0.89864957 0.89805222 0.89671034 0.89610434 0.89642084 0.89558077\n",
      "  0.89493895 0.89240205]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016244560247287154\n",
      "Predicción post entrenamiento : [[0.89165056]]\n",
      "PERDIDAAAA despues: 0.0016660731052979827\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "[[[0.89805222]\n",
      "  [0.89671034]\n",
      "  [0.89610434]\n",
      "  [0.89642084]\n",
      "  [0.89558077]\n",
      "  [0.89493895]\n",
      "  [0.89240205]\n",
      "  [0.89113754]]]\n",
      "ejemplar: [0.89805222 0.89671034 0.89610434 0.89642084 0.89558077 0.89493895\n",
      " 0.89240205 0.89113754]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.8910021]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[0.89805222 0.89671034 0.89610434 0.89642084 0.89558077 0.89493895\n",
      "  0.89240205 0.89113754]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017729430692270398\n",
      "Predicción post entrenamiento : [[0.891047]]\n",
      "PERDIDAAAA despues: 0.001776724704541266\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "[[[0.89671034]\n",
      "  [0.89610434]\n",
      "  [0.89642084]\n",
      "  [0.89558077]\n",
      "  [0.89493895]\n",
      "  [0.89240205]\n",
      "  [0.89113754]\n",
      "  [0.89100212]]]\n",
      "ejemplar: [0.89671034 0.89610434 0.89642084 0.89558077 0.89493895 0.89240205\n",
      " 0.89113754 0.89100212]\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.8903415]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[0.89671034 0.89610434 0.89642084 0.89558077 0.89493895 0.89240205\n",
      "  0.89113754 0.89100212]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005194970406591892\n",
      "Predicción post entrenamiento : [[0.89042395]]\n",
      "PERDIDAAAA despues: 0.005183094181120396\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "[[[0.89610434]\n",
      "  [0.89642084]\n",
      "  [0.89558077]\n",
      "  [0.89493895]\n",
      "  [0.89240205]\n",
      "  [0.89113754]\n",
      "  [0.89100212]\n",
      "  [0.89034152]]]\n",
      "ejemplar: [0.89610434 0.89642084 0.89558077 0.89493895 0.89240205 0.89113754\n",
      " 0.89100212 0.89034152]\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.8898637]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[0.89610434 0.89642084 0.89558077 0.89493895 0.89240205 0.89113754\n",
      "  0.89100212 0.89034152]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006080598570406437\n",
      "Predicción post entrenamiento : [[0.89033157]]\n",
      "PERDIDAAAA despues: 0.006007855292409658\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "[[[0.89642084]\n",
      "  [0.89558077]\n",
      "  [0.89493895]\n",
      "  [0.89240205]\n",
      "  [0.89113754]\n",
      "  [0.89100212]\n",
      "  [0.89034152]\n",
      "  [0.88986373]]]\n",
      "ejemplar: [0.89642084 0.89558077 0.89493895 0.89240205 0.89113754 0.89100212\n",
      " 0.89034152 0.88986373]\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.88971126]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[0.89642084 0.89558077 0.89493895 0.89240205 0.89113754 0.89100212\n",
      "  0.89034152 0.88986373]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002601960673928261\n",
      "Predicción post entrenamiento : [[0.88908947]]\n",
      "PERDIDAAAA despues: 0.0026657821144908667\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "[[[0.89558077]\n",
      "  [0.89493895]\n",
      "  [0.89240205]\n",
      "  [0.89113754]\n",
      "  [0.89100212]\n",
      "  [0.89034152]\n",
      "  [0.88986373]\n",
      "  [0.88971126]]]\n",
      "ejemplar: [0.89558077 0.89493895 0.89240205 0.89113754 0.89100212 0.89034152\n",
      " 0.88986373 0.88971126]\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.88812774]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[0.89558077 0.89493895 0.89240205 0.89113754 0.89100212 0.89034152\n",
      "  0.88986373 0.88971126]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007117203436791897\n",
      "Predicción post entrenamiento : [[0.88931614]]\n",
      "PERDIDAAAA despues: 0.006918101105839014\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "[[[0.89493895]\n",
      "  [0.89240205]\n",
      "  [0.89113754]\n",
      "  [0.89100212]\n",
      "  [0.89034152]\n",
      "  [0.88986373]\n",
      "  [0.88971126]\n",
      "  [0.88812774]]]\n",
      "ejemplar: [0.89493895 0.89240205 0.89113754 0.89100212 0.89034152 0.88986373\n",
      " 0.88971126 0.88812774]\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.88831306]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[0.89493895 0.89240205 0.89113754 0.89100212 0.89034152 0.88986373\n",
      "  0.88971126 0.88812774]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011791219934821129\n",
      "Predicción post entrenamiento : [[0.8883215]]\n",
      "PERDIDAAAA despues: 0.011789381504058838\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "[[[0.89240205]\n",
      "  [0.89113754]\n",
      "  [0.89100212]\n",
      "  [0.89034152]\n",
      "  [0.88986373]\n",
      "  [0.88971126]\n",
      "  [0.88812774]\n",
      "  [0.88831306]]]\n",
      "ejemplar: [0.89240205 0.89113754 0.89100212 0.89034152 0.88986373 0.88971126\n",
      " 0.88812774 0.88831306]\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.88723576]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[0.89240205 0.89113754 0.89100212 0.89034152 0.88986373 0.88971126\n",
      "  0.88812774 0.88831306]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004089084453880787\n",
      "Predicción post entrenamiento : [[0.88674]]\n",
      "PERDIDAAAA despues: 0.004152730107307434\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "[[[0.89113754]\n",
      "  [0.89100212]\n",
      "  [0.89034152]\n",
      "  [0.88986373]\n",
      "  [0.88971126]\n",
      "  [0.88812774]\n",
      "  [0.88831306]\n",
      "  [0.88723576]]]\n",
      "ejemplar: [0.89113754 0.89100212 0.89034152 0.88986373 0.88971126 0.88812774\n",
      " 0.88831306 0.88723576]\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.8861414]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[0.89113754 0.89100212 0.89034152 0.88986373 0.88971126 0.88812774\n",
      "  0.88831306 0.88723576]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 9.284071711590514e-05\n",
      "Predicción post entrenamiento : [[0.8866185]]\n",
      "PERDIDAAAA despues: 8.387470006709918e-05\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "[[[0.89100212]\n",
      "  [0.89034152]\n",
      "  [0.88986373]\n",
      "  [0.88971126]\n",
      "  [0.88812774]\n",
      "  [0.88831306]\n",
      "  [0.88723576]\n",
      "  [0.88614142]]]\n",
      "ejemplar: [0.89100212 0.89034152 0.88986373 0.88971126 0.88812774 0.88831306\n",
      " 0.88723576 0.88614142]\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.88620657]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[0.89100212 0.89034152 0.88986373 0.88971126 0.88812774 0.88831306\n",
      "  0.88723576 0.88614142]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.2707818061462604e-05\n",
      "Predicción post entrenamiento : [[0.88586897]]\n",
      "PERDIDAAAA despues: 1.9604274712037295e-05\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "[[[0.89034152]\n",
      "  [0.88986373]\n",
      "  [0.88971126]\n",
      "  [0.88812774]\n",
      "  [0.88831306]\n",
      "  [0.88723576]\n",
      "  [0.88614142]\n",
      "  [0.88620657]]]\n",
      "ejemplar: [0.89034152 0.88986373 0.88971126 0.88812774 0.88831306 0.88723576\n",
      " 0.88614142 0.88620657]\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.88533366]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[0.89034152 0.88986373 0.88971126 0.88812774 0.88831306 0.88723576\n",
      "  0.88614142 0.88620657]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010082380613312125\n",
      "Predicción post entrenamiento : [[0.88593966]]\n",
      "PERDIDAAAA despues: 0.0009701209492050111\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "[[[0.88986373]\n",
      "  [0.88971126]\n",
      "  [0.88812774]\n",
      "  [0.88831306]\n",
      "  [0.88723576]\n",
      "  [0.88614142]\n",
      "  [0.88620657]\n",
      "  [0.88533366]]]\n",
      "ejemplar: [0.88986373 0.88971126 0.88812774 0.88831306 0.88723576 0.88614142\n",
      " 0.88620657 0.88533366]\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.8854139]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[0.88986373 0.88971126 0.88812774 0.88831306 0.88723576 0.88614142\n",
      "  0.88620657 0.88533366]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011823053937405348\n",
      "Predicción post entrenamiento : [[0.8854425]]\n",
      "PERDIDAAAA despues: 0.0011803386732935905\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "[[[0.88971126]\n",
      "  [0.88812774]\n",
      "  [0.88831306]\n",
      "  [0.88723576]\n",
      "  [0.88614142]\n",
      "  [0.88620657]\n",
      "  [0.88533366]\n",
      "  [0.88541389]]]\n",
      "ejemplar: [0.88971126 0.88812774 0.88831306 0.88723576 0.88614142 0.88620657\n",
      " 0.88533366 0.88541389]\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.88487583]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[0.88971126 0.88812774 0.88831306 0.88723576 0.88614142 0.88620657\n",
      "  0.88533366 0.88541389]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005893167108297348\n",
      "Predicción post entrenamiento : [[0.8849117]]\n",
      "PERDIDAAAA despues: 0.005887659732252359\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "[[[0.88812774]\n",
      "  [0.88831306]\n",
      "  [0.88723576]\n",
      "  [0.88614142]\n",
      "  [0.88620657]\n",
      "  [0.88533366]\n",
      "  [0.88541389]\n",
      "  [0.88487583]]]\n",
      "ejemplar: [0.88812774 0.88831306 0.88723576 0.88614142 0.88620657 0.88533366\n",
      " 0.88541389 0.88487583]\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.884208]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[0.88812774 0.88831306 0.88723576 0.88614142 0.88620657 0.88533366\n",
      "  0.88541389 0.88487583]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007059583906084299\n",
      "Predicción post entrenamiento : [[0.8850831]]\n",
      "PERDIDAAAA despues: 0.006913302931934595\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "[[[0.88831306]\n",
      "  [0.88723576]\n",
      "  [0.88614142]\n",
      "  [0.88620657]\n",
      "  [0.88533366]\n",
      "  [0.88541389]\n",
      "  [0.88487583]\n",
      "  [0.88420802]]]\n",
      "ejemplar: [0.88831306 0.88723576 0.88614142 0.88620657 0.88533366 0.88541389\n",
      " 0.88487583 0.88420802]\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.8846546]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[0.88831306 0.88723576 0.88614142 0.88620657 0.88533366 0.88541389\n",
      "  0.88487583 0.88420802]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0053456188179552555\n",
      "Predicción post entrenamiento : [[0.8846195]]\n",
      "PERDIDAAAA despues: 0.005350753664970398\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "[[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "ejemplar: [0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      " 0.03448276 0.04223169]\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.23728265]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      "  0.03448276 0.04223169]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03654845058917999\n",
      "Predicción post entrenamiento : [[0.18966813]]\n",
      "PERDIDAAAA despues: 0.020610040053725243\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "[[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23728265]]]\n",
      "ejemplar: [0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      " 0.04223169 0.23728265]\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.17401606]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      "  0.04223169 0.23728265]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00487104756757617\n",
      "Predicción post entrenamiento : [[0.1567334]]\n",
      "PERDIDAAAA despues: 0.0027573236729949713\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "[[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23728265]\n",
      "  [0.17401606]]]\n",
      "ejemplar: [0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      " 0.23728265 0.17401606]\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.16056137]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      "  0.23728265 0.17401606]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.0418639400741085e-05\n",
      "Predicción post entrenamiento : [[0.15486252]]\n",
      "PERDIDAAAA despues: 4.339130157404725e-07\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "[[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23728265]\n",
      "  [0.17401606]\n",
      "  [0.16056137]]]\n",
      "ejemplar: [0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.23728265\n",
      " 0.17401606 0.16056137]\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.16581862]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.23728265\n",
      "  0.17401606 0.16056137]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00010130491136806086\n",
      "Predicción post entrenamiento : [[0.16385373]]\n",
      "PERDIDAAAA despues: 6.56124611850828e-05\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "[[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23728265]\n",
      "  [0.17401606]\n",
      "  [0.16056137]\n",
      "  [0.16581862]]]\n",
      "ejemplar: [0.05656722 0.02595893 0.03448276 0.04223169 0.23728265 0.17401606\n",
      " 0.16056137 0.16581862]\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.1756019]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[0.05656722 0.02595893 0.03448276 0.04223169 0.23728265 0.17401606\n",
      "  0.16056137 0.16581862]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002506920136511326\n",
      "Predicción post entrenamiento : [[0.17377703]]\n",
      "PERDIDAAAA despues: 0.002327510854229331\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "[[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23728265]\n",
      "  [0.17401606]\n",
      "  [0.16056137]\n",
      "  [0.16581862]\n",
      "  [0.1756019 ]]]\n",
      "ejemplar: [0.02595893 0.03448276 0.04223169 0.23728265 0.17401606 0.16056137\n",
      " 0.16581862 0.1756019 ]\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.18228045]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[0.02595893 0.03448276 0.04223169 0.23728265 0.17401606 0.16056137\n",
      "  0.16581862 0.1756019 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013395955320447683\n",
      "Predicción post entrenamiento : [[0.18034983]]\n",
      "PERDIDAAAA despues: 0.0012019992573186755\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "[[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23728265]\n",
      "  [0.17401606]\n",
      "  [0.16056137]\n",
      "  [0.16581862]\n",
      "  [0.1756019 ]\n",
      "  [0.18228045]]]\n",
      "ejemplar: [0.03448276 0.04223169 0.23728265 0.17401606 0.16056137 0.16581862\n",
      " 0.1756019  0.18228045]\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.19916391]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[0.03448276 0.04223169 0.23728265 0.17401606 0.16056137 0.16581862\n",
      "  0.1756019  0.18228045]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0027782449033111334\n",
      "Predicción post entrenamiento : [[0.1964064]]\n",
      "PERDIDAAAA despues: 0.0024951561354100704\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "[[[0.04223169]\n",
      "  [0.23728265]\n",
      "  [0.17401606]\n",
      "  [0.16056137]\n",
      "  [0.16581862]\n",
      "  [0.1756019 ]\n",
      "  [0.18228045]\n",
      "  [0.19916391]]]\n",
      "ejemplar: [0.04223169 0.23728265 0.17401606 0.16056137 0.16581862 0.1756019\n",
      " 0.18228045 0.19916391]\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.21890077]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[0.04223169 0.23728265 0.17401606 0.16056137 0.16581862 0.1756019\n",
      "  0.18228045 0.19916391]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005222474574111402\n",
      "Predicción post entrenamiento : [[0.21597633]]\n",
      "PERDIDAAAA despues: 0.0003971368132624775\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "[[[0.23728265]\n",
      "  [0.17401606]\n",
      "  [0.16056137]\n",
      "  [0.16581862]\n",
      "  [0.1756019 ]\n",
      "  [0.18228045]\n",
      "  [0.19916391]\n",
      "  [0.21890077]]]\n",
      "ejemplar: [0.23728265 0.17401606 0.16056137 0.16581862 0.1756019  0.18228045\n",
      " 0.19916391 0.21890077]\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.24240534]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[0.23728265 0.17401606 0.16056137 0.16581862 0.1756019  0.18228045\n",
      "  0.19916391 0.21890077]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00014100474072620273\n",
      "Predicción post entrenamiento : [[0.23955384]]\n",
      "PERDIDAAAA despues: 8.141525904648006e-05\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "[[[0.17401606]\n",
      "  [0.16056137]\n",
      "  [0.16581862]\n",
      "  [0.1756019 ]\n",
      "  [0.18228045]\n",
      "  [0.19916391]\n",
      "  [0.21890077]\n",
      "  [0.24240534]]]\n",
      "ejemplar: [0.17401606 0.16056137 0.16581862 0.1756019  0.18228045 0.19916391\n",
      " 0.21890077 0.24240534]\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.22853065]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[0.17401606 0.16056137 0.16581862 0.1756019  0.18228045 0.19916391\n",
      "  0.21890077 0.24240534]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004033793811686337\n",
      "Predicción post entrenamiento : [[0.22863601]]\n",
      "PERDIDAAAA despues: 0.0004076228942722082\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "[[[0.16056137]\n",
      "  [0.16581862]\n",
      "  [0.1756019 ]\n",
      "  [0.18228045]\n",
      "  [0.19916391]\n",
      "  [0.21890077]\n",
      "  [0.24240534]\n",
      "  [0.22853065]]]\n",
      "ejemplar: [0.16056137 0.16581862 0.1756019  0.18228045 0.19916391 0.21890077\n",
      " 0.24240534 0.22853065]\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.2304834]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[0.16056137 0.16581862 0.1756019  0.18228045 0.19916391 0.21890077\n",
      "  0.24240534 0.22853065]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003441039298195392\n",
      "Predicción post entrenamiento : [[0.22954556]]\n",
      "PERDIDAAAA despues: 0.00031018973095342517\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "[[[0.16581862]\n",
      "  [0.1756019 ]\n",
      "  [0.18228045]\n",
      "  [0.19916391]\n",
      "  [0.21890077]\n",
      "  [0.24240534]\n",
      "  [0.22853065]\n",
      "  [0.2304834 ]]]\n",
      "ejemplar: [0.16581862 0.1756019  0.18228045 0.19916391 0.21890077 0.24240534\n",
      " 0.22853065 0.2304834 ]\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.23584795]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[0.16581862 0.1756019  0.18228045 0.19916391 0.21890077 0.24240534\n",
      "  0.22853065 0.2304834 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008158990531228483\n",
      "Predicción post entrenamiento : [[0.23522955]]\n",
      "PERDIDAAAA despues: 0.0007809536764398217\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "[[[0.1756019 ]\n",
      "  [0.18228045]\n",
      "  [0.19916391]\n",
      "  [0.21890077]\n",
      "  [0.24240534]\n",
      "  [0.22853065]\n",
      "  [0.2304834 ]\n",
      "  [0.23584795]]]\n",
      "ejemplar: [0.1756019  0.18228045 0.19916391 0.21890077 0.24240534 0.22853065\n",
      " 0.2304834  0.23584795]\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.2426447]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[0.1756019  0.18228045 0.19916391 0.21890077 0.24240534 0.22853065\n",
      "  0.2304834  0.23584795]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0024697144981473684\n",
      "Predicción post entrenamiento : [[0.24002579]]\n",
      "PERDIDAAAA despues: 0.0022162734530866146\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "[[[0.18228045]\n",
      "  [0.19916391]\n",
      "  [0.21890077]\n",
      "  [0.24240534]\n",
      "  [0.22853065]\n",
      "  [0.2304834 ]\n",
      "  [0.23584795]\n",
      "  [0.2426447 ]]]\n",
      "ejemplar: [0.18228045 0.19916391 0.21890077 0.24240534 0.22853065 0.2304834\n",
      " 0.23584795 0.2426447 ]\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.24758679]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[0.18228045 0.19916391 0.21890077 0.24240534 0.22853065 0.2304834\n",
      "  0.23584795 0.2426447 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0025769679341465235\n",
      "Predicción post entrenamiento : [[0.2456966]]\n",
      "PERDIDAAAA despues: 0.002388634951785207\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "[[[0.19916391]\n",
      "  [0.21890077]\n",
      "  [0.24240534]\n",
      "  [0.22853065]\n",
      "  [0.2304834 ]\n",
      "  [0.23584795]\n",
      "  [0.2426447 ]\n",
      "  [0.24758679]]]\n",
      "ejemplar: [0.19916391 0.21890077 0.24240534 0.22853065 0.2304834  0.23584795\n",
      " 0.2426447  0.24758679]\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.2539231]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[0.19916391 0.21890077 0.24240534 0.22853065 0.2304834  0.23584795\n",
      "  0.2426447  0.24758679]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015733157051727176\n",
      "Predicción post entrenamiento : [[0.2521423]]\n",
      "PERDIDAAAA despues: 0.0014352175639942288\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "[[[0.21890077]\n",
      "  [0.24240534]\n",
      "  [0.22853065]\n",
      "  [0.2304834 ]\n",
      "  [0.23584795]\n",
      "  [0.2426447 ]\n",
      "  [0.24758679]\n",
      "  [0.25392309]]]\n",
      "ejemplar: [0.21890077 0.24240534 0.22853065 0.2304834  0.23584795 0.2426447\n",
      " 0.24758679 0.25392309]\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.25865552]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[0.21890077 0.24240534 0.22853065 0.2304834  0.23584795 0.2426447\n",
      "  0.24758679 0.25392309]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0059799994342029095\n",
      "Predicción post entrenamiento : [[0.2558161]]\n",
      "PERDIDAAAA despues: 0.005548914894461632\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "[[[0.24240534]\n",
      "  [0.22853065]\n",
      "  [0.2304834 ]\n",
      "  [0.23584795]\n",
      "  [0.2426447 ]\n",
      "  [0.24758679]\n",
      "  [0.25392309]\n",
      "  [0.25865552]]]\n",
      "ejemplar: [0.24240534 0.22853065 0.2304834  0.23584795 0.2426447  0.24758679\n",
      " 0.25392309 0.25865552]\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.25950038]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[0.24240534 0.22853065 0.2304834  0.23584795 0.2426447  0.24758679\n",
      "  0.25392309 0.25865552]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007119049318134785\n",
      "Predicción post entrenamiento : [[0.25743315]]\n",
      "PERDIDAAAA despues: 0.00677447859197855\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "[[[0.22853065]\n",
      "  [0.2304834 ]\n",
      "  [0.23584795]\n",
      "  [0.2426447 ]\n",
      "  [0.24758679]\n",
      "  [0.25392309]\n",
      "  [0.25865552]\n",
      "  [0.25950038]]]\n",
      "ejemplar: [0.22853065 0.2304834  0.23584795 0.2426447  0.24758679 0.25392309\n",
      " 0.25865552 0.25950038]\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.25690225]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[0.22853065 0.2304834  0.23584795 0.2426447  0.24758679 0.25392309\n",
      "  0.25865552 0.25950038]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011858686804771423\n",
      "Predicción post entrenamiento : [[0.2564165]]\n",
      "PERDIDAAAA despues: 0.011753128841519356\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "[[[0.2304834 ]\n",
      "  [0.23584795]\n",
      "  [0.2426447 ]\n",
      "  [0.24758679]\n",
      "  [0.25392309]\n",
      "  [0.25865552]\n",
      "  [0.25950038]\n",
      "  [0.25690225]]]\n",
      "ejemplar: [0.2304834  0.23584795 0.2426447  0.24758679 0.25392309 0.25865552\n",
      " 0.25950038 0.25690225]\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.25939062]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[0.2304834  0.23584795 0.2426447  0.24758679 0.25392309 0.25865552\n",
      "  0.25950038 0.25690225]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010107781738042831\n",
      "Predicción post entrenamiento : [[0.2572186]]\n",
      "PERDIDAAAA despues: 0.009675759822130203\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "[[[0.23584795]\n",
      "  [0.2426447 ]\n",
      "  [0.24758679]\n",
      "  [0.25392309]\n",
      "  [0.25865552]\n",
      "  [0.25950038]\n",
      "  [0.25690225]\n",
      "  [0.25939062]]]\n",
      "ejemplar: [0.23584795 0.2426447  0.24758679 0.25392309 0.25865552 0.25950038\n",
      " 0.25690225 0.25939062]\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.26071888]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[0.23584795 0.2426447  0.24758679 0.25392309 0.25865552 0.25950038\n",
      "  0.25690225 0.25939062]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004698459524661303\n",
      "Predicción post entrenamiento : [[0.2598311]]\n",
      "PERDIDAAAA despues: 0.004577541258186102\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "[[[0.2426447 ]\n",
      "  [0.24758679]\n",
      "  [0.25392309]\n",
      "  [0.25865552]\n",
      "  [0.25950038]\n",
      "  [0.25690225]\n",
      "  [0.25939062]\n",
      "  [0.26071888]]]\n",
      "ejemplar: [0.2426447  0.24758679 0.25392309 0.25865552 0.25950038 0.25690225\n",
      " 0.25939062 0.26071888]\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.263087]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[0.2426447  0.24758679 0.25392309 0.25865552 0.25950038 0.25690225\n",
      "  0.25939062 0.26071888]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005946348421275616\n",
      "Predicción post entrenamiento : [[0.2605685]]\n",
      "PERDIDAAAA despues: 0.0055642747320234776\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "[[[0.24758679]\n",
      "  [0.25392309]\n",
      "  [0.25865552]\n",
      "  [0.25950038]\n",
      "  [0.25690225]\n",
      "  [0.25939062]\n",
      "  [0.26071888]\n",
      "  [0.263087  ]]]\n",
      "ejemplar: [0.24758679 0.25392309 0.25865552 0.25950038 0.25690225 0.25939062\n",
      " 0.26071888 0.263087  ]\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.26311386]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[0.24758679 0.25392309 0.25865552 0.25950038 0.25690225 0.25939062\n",
      "  0.26071888 0.263087  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.4722029845870566e-05\n",
      "Predicción post entrenamiento : [[0.26288536]]\n",
      "PERDIDAAAA despues: 1.6527674233657308e-05\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "[[[0.25392309]\n",
      "  [0.25865552]\n",
      "  [0.25950038]\n",
      "  [0.25690225]\n",
      "  [0.25939062]\n",
      "  [0.26071888]\n",
      "  [0.263087  ]\n",
      "  [0.26311386]]]\n",
      "ejemplar: [0.25392309 0.25865552 0.25950038 0.25690225 0.25939062 0.26071888\n",
      " 0.263087   0.26311386]\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.26493946]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[0.25392309 0.25865552 0.25950038 0.25690225 0.25939062 0.26071888\n",
      "  0.263087   0.26311386]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007608121959492564\n",
      "Predicción post entrenamiento : [[0.2662117]]\n",
      "PERDIDAAAA despues: 0.0006922472966834903\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "[[[0.25865552]\n",
      "  [0.25950038]\n",
      "  [0.25690225]\n",
      "  [0.25939062]\n",
      "  [0.26071888]\n",
      "  [0.263087  ]\n",
      "  [0.26311386]\n",
      "  [0.26493946]]]\n",
      "ejemplar: [0.25865552 0.25950038 0.25690225 0.25939062 0.26071888 0.263087\n",
      " 0.26311386 0.26493946]\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.26732063]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[0.25865552 0.25950038 0.25690225 0.25939062 0.26071888 0.263087\n",
      "  0.26311386 0.26493946]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002538717119023204\n",
      "Predicción post entrenamiento : [[0.26909027]]\n",
      "PERDIDAAAA despues: 0.0023635204415768385\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "[[[0.25950038]\n",
      "  [0.25690225]\n",
      "  [0.25939062]\n",
      "  [0.26071888]\n",
      "  [0.263087  ]\n",
      "  [0.26311386]\n",
      "  [0.26493946]\n",
      "  [0.26732063]]]\n",
      "ejemplar: [0.25950038 0.25690225 0.25939062 0.26071888 0.263087   0.26311386\n",
      " 0.26493946 0.26732063]\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.26944193]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[0.25950038 0.25690225 0.25939062 0.26071888 0.263087   0.26311386\n",
      "  0.26493946 0.26732063]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001868623890914023\n",
      "Predicción post entrenamiento : [[0.27035204]]\n",
      "PERDIDAAAA despues: 0.0017907690489664674\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "[[[0.25690225]\n",
      "  [0.25939062]\n",
      "  [0.26071888]\n",
      "  [0.263087  ]\n",
      "  [0.26311386]\n",
      "  [0.26493946]\n",
      "  [0.26732063]\n",
      "  [0.26944193]]]\n",
      "ejemplar: [0.25690225 0.25939062 0.26071888 0.263087   0.26311386 0.26493946\n",
      " 0.26732063 0.26944193]\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.27072293]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[0.25690225 0.25939062 0.26071888 0.263087   0.26311386 0.26493946\n",
      "  0.26732063 0.26944193]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003353416104800999\n",
      "Predicción post entrenamiento : [[0.27075016]]\n",
      "PERDIDAAAA despues: 0.0003343447169754654\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "[[[0.25939062]\n",
      "  [0.26071888]\n",
      "  [0.263087  ]\n",
      "  [0.26311386]\n",
      "  [0.26493946]\n",
      "  [0.26732063]\n",
      "  [0.26944193]\n",
      "  [0.27072293]]]\n",
      "ejemplar: [0.25939062 0.26071888 0.263087   0.26311386 0.26493946 0.26732063\n",
      " 0.26944193 0.27072293]\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.27195403]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[0.25939062 0.26071888 0.263087   0.26311386 0.26493946 0.26732063\n",
      "  0.26944193 0.27072293]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00011841965897474438\n",
      "Predicción post entrenamiento : [[0.2725375]]\n",
      "PERDIDAAAA despues: 0.00010606136493152007\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "[[[0.26071888]\n",
      "  [0.263087  ]\n",
      "  [0.26311386]\n",
      "  [0.26493946]\n",
      "  [0.26732063]\n",
      "  [0.26944193]\n",
      "  [0.27072293]\n",
      "  [0.27195403]]]\n",
      "ejemplar: [0.26071888 0.263087   0.26311386 0.26493946 0.26732063 0.26944193\n",
      " 0.27072293 0.27195403]\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.2735666]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[0.26071888 0.263087   0.26311386 0.26493946 0.26732063 0.26944193\n",
      "  0.27072293 0.27195403]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006723503465764225\n",
      "Predicción post entrenamiento : [[0.27402088]]\n",
      "PERDIDAAAA despues: 0.0006489981897175312\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "[[[0.263087  ]\n",
      "  [0.26311386]\n",
      "  [0.26493946]\n",
      "  [0.26732063]\n",
      "  [0.26944193]\n",
      "  [0.27072293]\n",
      "  [0.27195403]\n",
      "  [0.2735666 ]]]\n",
      "ejemplar: [0.263087   0.26311386 0.26493946 0.26732063 0.26944193 0.27072293\n",
      " 0.27195403 0.2735666 ]\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.27510935]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[0.263087   0.26311386 0.26493946 0.26732063 0.26944193 0.27072293\n",
      "  0.27195403 0.2735666 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.665832532031345e-07\n",
      "Predicción post entrenamiento : [[0.2750934]]\n",
      "PERDIDAAAA despues: 5.90840500080958e-07\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "[[[0.26311386]\n",
      "  [0.26493946]\n",
      "  [0.26732063]\n",
      "  [0.26944193]\n",
      "  [0.27072293]\n",
      "  [0.27195403]\n",
      "  [0.2735666 ]\n",
      "  [0.27510935]]]\n",
      "ejemplar: [0.26311386 0.26493946 0.26732063 0.26944193 0.27072293 0.27195403\n",
      " 0.2735666  0.27510935]\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.27601427]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[0.26311386 0.26493946 0.26732063 0.26944193 0.27072293 0.27195403\n",
      "  0.2735666  0.27510935]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.7280433439736953e-06\n",
      "Predicción post entrenamiento : [[0.27501372]]\n",
      "PERDIDAAAA despues: 9.859428473646403e-08\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "[[[0.26493946]\n",
      "  [0.26732063]\n",
      "  [0.26944193]\n",
      "  [0.27072293]\n",
      "  [0.27195403]\n",
      "  [0.2735666 ]\n",
      "  [0.27510935]\n",
      "  [0.27601427]]]\n",
      "ejemplar: [0.26493946 0.26732063 0.26944193 0.27072293 0.27195403 0.2735666\n",
      " 0.27510935 0.27601427]\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.27627006]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[0.26493946 0.26732063 0.26944193 0.27072293 0.27195403 0.2735666\n",
      "  0.27510935 0.27601427]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.327467190203606e-07\n",
      "Predicción post entrenamiento : [[0.27616256]]\n",
      "PERDIDAAAA despues: 4.732845582111622e-07\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "[[[0.26732063]\n",
      "  [0.26944193]\n",
      "  [0.27072293]\n",
      "  [0.27195403]\n",
      "  [0.2735666 ]\n",
      "  [0.27510935]\n",
      "  [0.27601427]\n",
      "  [0.27627006]]]\n",
      "ejemplar: [0.26732063 0.26944193 0.27072293 0.27195403 0.2735666  0.27510935\n",
      " 0.27601427 0.27627006]\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.27738634]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[0.26732063 0.26944193 0.27072293 0.27195403 0.2735666  0.27510935\n",
      "  0.27601427 0.27627006]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0032910441514104605\n",
      "Predicción post entrenamiento : [[0.27760428]]\n",
      "PERDIDAAAA despues: 0.0032660856377333403\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "[[[0.26944193]\n",
      "  [0.27072293]\n",
      "  [0.27195403]\n",
      "  [0.2735666 ]\n",
      "  [0.27510935]\n",
      "  [0.27601427]\n",
      "  [0.27627006]\n",
      "  [0.27738634]]]\n",
      "ejemplar: [0.26944193 0.27072293 0.27195403 0.2735666  0.27510935 0.27601427\n",
      " 0.27627006 0.27738634]\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.2786421]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[0.26944193 0.27072293 0.27195403 0.2735666  0.27510935 0.27601427\n",
      "  0.27627006 0.27738634]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005934236571192741\n",
      "Predicción post entrenamiento : [[0.27988884]]\n",
      "PERDIDAAAA despues: 0.005743706598877907\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "[[[0.27072293]\n",
      "  [0.27195403]\n",
      "  [0.2735666 ]\n",
      "  [0.27510935]\n",
      "  [0.27601427]\n",
      "  [0.27627006]\n",
      "  [0.27738634]\n",
      "  [0.27864209]]]\n",
      "ejemplar: [0.27072293 0.27195403 0.2735666  0.27510935 0.27601427 0.27627006\n",
      " 0.27738634 0.27864209]\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.2807526]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[0.27072293 0.27195403 0.2735666  0.27510935 0.27601427 0.27627006\n",
      "  0.27738634 0.27864209]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0031291272025555372\n",
      "Predicción post entrenamiento : [[0.28140885]]\n",
      "PERDIDAAAA despues: 0.003056138753890991\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "[[[0.27195403]\n",
      "  [0.2735666 ]\n",
      "  [0.27510935]\n",
      "  [0.27601427]\n",
      "  [0.27627006]\n",
      "  [0.27738634]\n",
      "  [0.27864209]\n",
      "  [0.2807526 ]]]\n",
      "ejemplar: [0.27195403 0.2735666  0.27510935 0.27601427 0.27627006 0.27738634\n",
      " 0.27864209 0.2807526 ]\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.28225595]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[0.27195403 0.2735666  0.27510935 0.27601427 0.27627006 0.27738634\n",
      "  0.27864209 0.2807526 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002635353244841099\n",
      "Predicción post entrenamiento : [[0.28235433]]\n",
      "PERDIDAAAA despues: 0.00262526236474514\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "[[[0.2735666 ]\n",
      "  [0.27510935]\n",
      "  [0.27601427]\n",
      "  [0.27627006]\n",
      "  [0.27738634]\n",
      "  [0.27864209]\n",
      "  [0.2807526 ]\n",
      "  [0.28225595]]]\n",
      "ejemplar: [0.2735666  0.27510935 0.27601427 0.27627006 0.27738634 0.27864209\n",
      " 0.2807526  0.28225595]\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.28319466]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[0.2735666  0.27510935 0.27601427 0.27627006 0.27738634 0.27864209\n",
      "  0.2807526  0.28225595]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010310359299182892\n",
      "Predicción post entrenamiento : [[0.28460625]]\n",
      "PERDIDAAAA despues: 0.010025686584413052\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "[[[0.27510935]\n",
      "  [0.27601427]\n",
      "  [0.27627006]\n",
      "  [0.27738634]\n",
      "  [0.27864209]\n",
      "  [0.2807526 ]\n",
      "  [0.28225595]\n",
      "  [0.28319466]]]\n",
      "ejemplar: [0.27510935 0.27601427 0.27627006 0.27738634 0.27864209 0.2807526\n",
      " 0.28225595 0.28319466]\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.2853548]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[0.27510935 0.27601427 0.27627006 0.27738634 0.27864209 0.2807526\n",
      "  0.28225595 0.28319466]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0816483125090599\n",
      "Predicción post entrenamiento : [[0.2890242]]\n",
      "PERDIDAAAA despues: 0.07956476509571075\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "[[[0.27601427]\n",
      "  [0.27627006]\n",
      "  [0.27738634]\n",
      "  [0.27864209]\n",
      "  [0.2807526 ]\n",
      "  [0.28225595]\n",
      "  [0.28319466]\n",
      "  [0.28535479]]]\n",
      "ejemplar: [0.27601427 0.27627006 0.27738634 0.27864209 0.2807526  0.28225595\n",
      " 0.28319466 0.28535479]\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.28969225]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[0.27601427 0.27627006 0.27738634 0.27864209 0.2807526  0.28225595\n",
      "  0.28319466 0.28535479]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09399636089801788\n",
      "Predicción post entrenamiento : [[0.2936146]]\n",
      "PERDIDAAAA despues: 0.09160666167736053\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "[[[0.27627006]\n",
      "  [0.27738634]\n",
      "  [0.27864209]\n",
      "  [0.2807526 ]\n",
      "  [0.28225595]\n",
      "  [0.28319466]\n",
      "  [0.28535479]\n",
      "  [0.28969225]]]\n",
      "ejemplar: [0.27627006 0.27738634 0.27864209 0.2807526  0.28225595 0.28319466\n",
      " 0.28535479 0.28969225]\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.2943631]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[0.27627006 0.27738634 0.27864209 0.2807526  0.28225595 0.28319466\n",
      "  0.28535479 0.28969225]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07852344959974289\n",
      "Predicción post entrenamiento : [[0.2978915]]\n",
      "PERDIDAAAA despues: 0.07655844837427139\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "[[[0.27738634]\n",
      "  [0.27864209]\n",
      "  [0.2807526 ]\n",
      "  [0.28225595]\n",
      "  [0.28319466]\n",
      "  [0.28535479]\n",
      "  [0.28969225]\n",
      "  [0.29436311]]]\n",
      "ejemplar: [0.27738634 0.27864209 0.2807526  0.28225595 0.28319466 0.28535479\n",
      " 0.28969225 0.29436311]\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.29892865]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[0.27738634 0.27864209 0.2807526  0.28225595 0.28319466 0.28535479\n",
      "  0.28969225 0.29436311]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09451042115688324\n",
      "Predicción post entrenamiento : [[0.30270198]]\n",
      "PERDIDAAAA despues: 0.09220462292432785\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "[[[0.27864209]\n",
      "  [0.2807526 ]\n",
      "  [0.28225595]\n",
      "  [0.28319466]\n",
      "  [0.28535479]\n",
      "  [0.28969225]\n",
      "  [0.29436311]\n",
      "  [0.29892865]]]\n",
      "ejemplar: [0.27864209 0.2807526  0.28225595 0.28319466 0.28535479 0.28969225\n",
      " 0.29436311 0.29892865]\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.30393273]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[0.27864209 0.2807526  0.28225595 0.28319466 0.28535479 0.28969225\n",
      "  0.29436311 0.29892865]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07880619168281555\n",
      "Predicción post entrenamiento : [[0.30759007]]\n",
      "PERDIDAAAA despues: 0.07676615566015244\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "[[[0.2807526 ]\n",
      "  [0.28225595]\n",
      "  [0.28319466]\n",
      "  [0.28535479]\n",
      "  [0.28969225]\n",
      "  [0.29436311]\n",
      "  [0.29892865]\n",
      "  [0.30393273]]]\n",
      "ejemplar: [0.2807526  0.28225595 0.28319466 0.28535479 0.28969225 0.29436311\n",
      " 0.29892865 0.30393273]\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.30907744]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[0.2807526  0.28225595 0.28319466 0.28535479 0.28969225 0.29436311\n",
      "  0.29892865 0.30393273]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06744115054607391\n",
      "Predicción post entrenamiento : [[0.3122332]]\n",
      "PERDIDAAAA despues: 0.06581203639507294\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "[[[0.28225595]\n",
      "  [0.28319466]\n",
      "  [0.28535479]\n",
      "  [0.28969225]\n",
      "  [0.29436311]\n",
      "  [0.29892865]\n",
      "  [0.30393273]\n",
      "  [0.30907744]]]\n",
      "ejemplar: [0.28225595 0.28319466 0.28535479 0.28969225 0.29436311 0.29892865\n",
      " 0.30393273 0.30907744]\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.31388888]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[0.28225595 0.28319466 0.28535479 0.28969225 0.29436311 0.29892865\n",
      "  0.30393273 0.30907744]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10816549509763718\n",
      "Predicción post entrenamiento : [[0.3178203]]\n",
      "PERDIDAAAA despues: 0.10559497028589249\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "[[[0.28319466]\n",
      "  [0.28535479]\n",
      "  [0.28969225]\n",
      "  [0.29436311]\n",
      "  [0.29892865]\n",
      "  [0.30393273]\n",
      "  [0.30907744]\n",
      "  [0.31388888]]]\n",
      "ejemplar: [0.28319466 0.28535479 0.28969225 0.29436311 0.29892865 0.30393273\n",
      " 0.30907744 0.31388888]\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.31988248]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[0.28319466 0.28535479 0.28969225 0.29436311 0.29892865 0.30393273\n",
      "  0.30907744 0.31388888]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11687956750392914\n",
      "Predicción post entrenamiento : [[0.32401124]]\n",
      "PERDIDAAAA despues: 0.11407356709241867\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "[[[0.28535479]\n",
      "  [0.28969225]\n",
      "  [0.29436311]\n",
      "  [0.29892865]\n",
      "  [0.30393273]\n",
      "  [0.30907744]\n",
      "  [0.31388888]\n",
      "  [0.31988248]]]\n",
      "ejemplar: [0.28535479 0.28969225 0.29436311 0.29892865 0.30393273 0.30907744\n",
      " 0.31388888 0.31988248]\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.3267439]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[0.28535479 0.28969225 0.29436311 0.29892865 0.30393273 0.30907744\n",
      "  0.31388888 0.31988248]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11988980323076248\n",
      "Predicción post entrenamiento : [[0.33066565]]\n",
      "PERDIDAAAA despues: 0.11718936264514923\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "[[[0.28969225]\n",
      "  [0.29436311]\n",
      "  [0.29892865]\n",
      "  [0.30393273]\n",
      "  [0.30907744]\n",
      "  [0.31388888]\n",
      "  [0.31988248]\n",
      "  [0.3267439 ]]]\n",
      "ejemplar: [0.28969225 0.29436311 0.29892865 0.30393273 0.30907744 0.31388888\n",
      " 0.31988248 0.3267439 ]\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.3339477]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[0.28969225 0.29436311 0.29892865 0.30393273 0.30907744 0.31388888\n",
      "  0.31988248 0.3267439 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14184987545013428\n",
      "Predicción post entrenamiento : [[0.33808535]]\n",
      "PERDIDAAAA despues: 0.13875025510787964\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "[[[0.29436311]\n",
      "  [0.29892865]\n",
      "  [0.30393273]\n",
      "  [0.30907744]\n",
      "  [0.31388888]\n",
      "  [0.31988248]\n",
      "  [0.3267439 ]\n",
      "  [0.33394769]]]\n",
      "ejemplar: [0.29436311 0.29892865 0.30393273 0.30907744 0.31388888 0.31988248\n",
      " 0.3267439  0.33394769]\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.3415397]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[0.29436311 0.29892865 0.30393273 0.30907744 0.31388888 0.31988248\n",
      "  0.3267439  0.33394769]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13137072324752808\n",
      "Predicción post entrenamiento : [[0.34561932]]\n",
      "PERDIDAAAA despues: 0.12843003869056702\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "[[[0.29892865]\n",
      "  [0.30393273]\n",
      "  [0.30907744]\n",
      "  [0.31388888]\n",
      "  [0.31988248]\n",
      "  [0.3267439 ]\n",
      "  [0.33394769]\n",
      "  [0.34153971]]]\n",
      "ejemplar: [0.29892865 0.30393273 0.30907744 0.31388888 0.31988248 0.3267439\n",
      " 0.33394769 0.34153971]\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.34923953]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[0.29892865 0.30393273 0.30907744 0.31388888 0.31988248 0.3267439\n",
      "  0.33394769 0.34153971]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14288248121738434\n",
      "Predicción post entrenamiento : [[0.3530902]]\n",
      "PERDIDAAAA despues: 0.13998621702194214\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "[[[0.30393273]\n",
      "  [0.30907744]\n",
      "  [0.31388888]\n",
      "  [0.31988248]\n",
      "  [0.3267439 ]\n",
      "  [0.33394769]\n",
      "  [0.34153971]\n",
      "  [0.34923953]]]\n",
      "ejemplar: [0.30393273 0.30907744 0.31388888 0.31988248 0.3267439  0.33394769\n",
      " 0.34153971 0.34923953]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.35698113]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[0.30393273 0.30907744 0.31388888 0.31988248 0.3267439  0.33394769\n",
      "  0.34153971 0.34923953]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1336684674024582\n",
      "Predicción post entrenamiento : [[0.3610161]]\n",
      "PERDIDAAAA despues: 0.13073432445526123\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "[[[0.30907744]\n",
      "  [0.31388888]\n",
      "  [0.31988248]\n",
      "  [0.3267439 ]\n",
      "  [0.33394769]\n",
      "  [0.34153971]\n",
      "  [0.34923953]\n",
      "  [0.35698113]]]\n",
      "ejemplar: [0.30907744 0.31388888 0.31988248 0.3267439  0.33394769 0.34153971\n",
      " 0.34923953 0.35698113]\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.36517268]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[0.30907744 0.31388888 0.31988248 0.3267439  0.33394769 0.34153971\n",
      "  0.34923953 0.35698113]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.16534081101417542\n",
      "Predicción post entrenamiento : [[0.36942932]]\n",
      "PERDIDAAAA despues: 0.16189725697040558\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "[[[0.31388888]\n",
      "  [0.31988248]\n",
      "  [0.3267439 ]\n",
      "  [0.33394769]\n",
      "  [0.34153971]\n",
      "  [0.34923953]\n",
      "  [0.35698113]\n",
      "  [0.36517268]]]\n",
      "ejemplar: [0.31388888 0.31988248 0.3267439  0.33394769 0.34153971 0.34923953\n",
      " 0.35698113 0.36517268]\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.3739164]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[0.31388888 0.31988248 0.3267439  0.33394769 0.34153971 0.34923953\n",
      "  0.35698113 0.36517268]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12292667478322983\n",
      "Predicción post entrenamiento : [[0.37761378]]\n",
      "PERDIDAAAA despues: 0.12034766376018524\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "[[[0.31988248]\n",
      "  [0.3267439 ]\n",
      "  [0.33394769]\n",
      "  [0.34153971]\n",
      "  [0.34923953]\n",
      "  [0.35698113]\n",
      "  [0.36517268]\n",
      "  [0.37391639]]]\n",
      "ejemplar: [0.31988248 0.3267439  0.33394769 0.34153971 0.34923953 0.35698113\n",
      " 0.36517268 0.37391639]\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.38261613]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[0.31988248 0.3267439  0.33394769 0.34153971 0.34923953 0.35698113\n",
      "  0.36517268 0.37391639]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08319853991270065\n",
      "Predicción post entrenamiento : [[0.38532546]]\n",
      "PERDIDAAAA despues: 0.08164291083812714\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "[[[0.3267439 ]\n",
      "  [0.33394769]\n",
      "  [0.34153971]\n",
      "  [0.34923953]\n",
      "  [0.35698113]\n",
      "  [0.36517268]\n",
      "  [0.37391639]\n",
      "  [0.38261613]]]\n",
      "ejemplar: [0.3267439  0.33394769 0.34153971 0.34923953 0.35698113 0.36517268\n",
      " 0.37391639 0.38261613]\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.3906824]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[0.3267439  0.33394769 0.34153971 0.34923953 0.35698113 0.36517268\n",
      "  0.37391639 0.38261613]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08013849705457687\n",
      "Predicción post entrenamiento : [[0.3934929]]\n",
      "PERDIDAAAA despues: 0.0785551518201828\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "[[[0.33394769]\n",
      "  [0.34153971]\n",
      "  [0.34923953]\n",
      "  [0.35698113]\n",
      "  [0.36517268]\n",
      "  [0.37391639]\n",
      "  [0.38261613]\n",
      "  [0.3906824 ]]]\n",
      "ejemplar: [0.33394769 0.34153971 0.34923953 0.35698113 0.36517268 0.37391639\n",
      " 0.38261613 0.3906824 ]\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.3990806]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[0.33394769 0.34153971 0.34923953 0.35698113 0.36517268 0.37391639\n",
      "  0.38261613 0.3906824 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09945898503065109\n",
      "Predicción post entrenamiento : [[0.40241724]]\n",
      "PERDIDAAAA despues: 0.09736555814743042\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "[[[0.34153971]\n",
      "  [0.34923953]\n",
      "  [0.35698113]\n",
      "  [0.36517268]\n",
      "  [0.37391639]\n",
      "  [0.38261613]\n",
      "  [0.3906824 ]\n",
      "  [0.3990806 ]]]\n",
      "ejemplar: [0.34153971 0.34923953 0.35698113 0.36517268 0.37391639 0.38261613\n",
      " 0.3906824  0.3990806 ]\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.4082117]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[0.34153971 0.34923953 0.35698113 0.36517268 0.37391639 0.38261613\n",
      "  0.3906824  0.3990806 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11268510669469833\n",
      "Predicción post entrenamiento : [[0.4115627]]\n",
      "PERDIDAAAA despues: 0.11044657230377197\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "[[[0.34923953]\n",
      "  [0.35698113]\n",
      "  [0.36517268]\n",
      "  [0.37391639]\n",
      "  [0.38261613]\n",
      "  [0.3906824 ]\n",
      "  [0.3990806 ]\n",
      "  [0.40821171]]]\n",
      "ejemplar: [0.34923953 0.35698113 0.36517268 0.37391639 0.38261613 0.3906824\n",
      " 0.3990806  0.40821171]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.41751933]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[0.34923953 0.35698113 0.36517268 0.37391639 0.38261613 0.3906824\n",
      "  0.3990806  0.40821171]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09306696802377701\n",
      "Predicción post entrenamiento : [[0.42063925]]\n",
      "PERDIDAAAA despues: 0.09117311984300613\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "[[[0.35698113]\n",
      "  [0.36517268]\n",
      "  [0.37391639]\n",
      "  [0.38261613]\n",
      "  [0.3906824 ]\n",
      "  [0.3990806 ]\n",
      "  [0.40821171]\n",
      "  [0.41751933]]]\n",
      "ejemplar: [0.35698113 0.36517268 0.37391639 0.38261613 0.3906824  0.3990806\n",
      " 0.40821171 0.41751933]\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.42677334]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[0.35698113 0.36517268 0.37391639 0.38261613 0.3906824  0.3990806\n",
      "  0.40821171 0.41751933]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07429332286119461\n",
      "Predicción post entrenamiento : [[0.4295351]]\n",
      "PERDIDAAAA despues: 0.07279542088508606\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "[[[0.36517268]\n",
      "  [0.37391639]\n",
      "  [0.38261613]\n",
      "  [0.3906824 ]\n",
      "  [0.3990806 ]\n",
      "  [0.40821171]\n",
      "  [0.41751933]\n",
      "  [0.42677334]]]\n",
      "ejemplar: [0.36517268 0.37391639 0.38261613 0.3906824  0.3990806  0.40821171\n",
      " 0.41751933 0.42677334]\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.43588087]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[0.36517268 0.37391639 0.38261613 0.3906824  0.3990806  0.40821171\n",
      "  0.41751933 0.42677334]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09086019545793533\n",
      "Predicción post entrenamiento : [[0.43876192]]\n",
      "PERDIDAAAA despues: 0.08913163095712662\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "[[[0.37391639]\n",
      "  [0.38261613]\n",
      "  [0.3906824 ]\n",
      "  [0.3990806 ]\n",
      "  [0.40821171]\n",
      "  [0.41751933]\n",
      "  [0.42677334]\n",
      "  [0.43588087]]]\n",
      "ejemplar: [0.37391639 0.38261613 0.3906824  0.3990806  0.40821171 0.41751933\n",
      " 0.42677334 0.43588087]\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.4452554]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[0.37391639 0.38261613 0.3906824  0.3990806  0.40821171 0.41751933\n",
      "  0.42677334 0.43588087]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07627011090517044\n",
      "Predicción post entrenamiento : [[0.44799113]]\n",
      "PERDIDAAAA despues: 0.07476653158664703\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "[[[0.38261613]\n",
      "  [0.3906824 ]\n",
      "  [0.3990806 ]\n",
      "  [0.40821171]\n",
      "  [0.41751933]\n",
      "  [0.42677334]\n",
      "  [0.43588087]\n",
      "  [0.4452554 ]]]\n",
      "ejemplar: [0.38261613 0.3906824  0.3990806  0.40821171 0.41751933 0.42677334\n",
      " 0.43588087 0.4452554 ]\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.45452893]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[0.38261613 0.3906824  0.3990806  0.40821171 0.41751933 0.42677334\n",
      "  0.43588087 0.4452554 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06979359686374664\n",
      "Predicción post entrenamiento : [[0.45729196]]\n",
      "PERDIDAAAA despues: 0.06834132969379425\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "[[[0.3906824 ]\n",
      "  [0.3990806 ]\n",
      "  [0.40821171]\n",
      "  [0.41751933]\n",
      "  [0.42677334]\n",
      "  [0.43588087]\n",
      "  [0.4452554 ]\n",
      "  [0.45452893]]]\n",
      "ejemplar: [0.3906824  0.3990806  0.40821171 0.41751933 0.42677334 0.43588087\n",
      " 0.4452554  0.45452893]\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.46390387]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[0.3906824  0.3990806  0.40821171 0.41751933 0.42677334 0.43588087\n",
      "  0.4452554  0.45452893]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04420651122927666\n",
      "Predicción post entrenamiento : [[0.4660855]]\n",
      "PERDIDAAAA despues: 0.04329388588666916\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "[[[0.3990806 ]\n",
      "  [0.40821171]\n",
      "  [0.41751933]\n",
      "  [0.42677334]\n",
      "  [0.43588087]\n",
      "  [0.4452554 ]\n",
      "  [0.45452893]\n",
      "  [0.46390387]]]\n",
      "ejemplar: [0.3990806  0.40821171 0.41751933 0.42677334 0.43588087 0.4452554\n",
      " 0.45452893 0.46390387]\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.47295552]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[0.3990806  0.40821171 0.41751933 0.42677334 0.43588087 0.4452554\n",
      "  0.45452893 0.46390387]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.050900284200906754\n",
      "Predicción post entrenamiento : [[0.4752795]]\n",
      "PERDIDAAAA despues: 0.04985705018043518\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "[[[0.40821171]\n",
      "  [0.41751933]\n",
      "  [0.42677334]\n",
      "  [0.43588087]\n",
      "  [0.4452554 ]\n",
      "  [0.45452893]\n",
      "  [0.46390387]\n",
      "  [0.47295552]]]\n",
      "ejemplar: [0.40821171 0.41751933 0.42677334 0.43588087 0.4452554  0.45452893\n",
      " 0.46390387 0.47295552]\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.48237228]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[0.40821171 0.41751933 0.42677334 0.43588087 0.4452554  0.45452893\n",
      "  0.46390387 0.47295552]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05696148797869682\n",
      "Predicción post entrenamiento : [[0.48422316]]\n",
      "PERDIDAAAA despues: 0.05608143284916878\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "[[[0.41751933]\n",
      "  [0.42677334]\n",
      "  [0.43588087]\n",
      "  [0.4452554 ]\n",
      "  [0.45452893]\n",
      "  [0.46390387]\n",
      "  [0.47295552]\n",
      "  [0.48237228]]]\n",
      "ejemplar: [0.41751933 0.42677334 0.43588087 0.4452554  0.45452893 0.46390387\n",
      " 0.47295552 0.48237228]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.49138415]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[0.41751933 0.42677334 0.43588087 0.4452554  0.45452893 0.46390387\n",
      "  0.47295552 0.48237228]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.053455278277397156\n",
      "Predicción post entrenamiento : [[0.4936421]]\n",
      "PERDIDAAAA despues: 0.05241628363728523\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "[[[0.42677334]\n",
      "  [0.43588087]\n",
      "  [0.4452554 ]\n",
      "  [0.45452893]\n",
      "  [0.46390387]\n",
      "  [0.47295552]\n",
      "  [0.48237228]\n",
      "  [0.49138415]]]\n",
      "ejemplar: [0.42677334 0.43588087 0.4452554  0.45452893 0.46390387 0.47295552\n",
      " 0.48237228 0.49138415]\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.500831]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[0.42677334 0.43588087 0.4452554  0.45452893 0.46390387 0.47295552\n",
      "  0.48237228 0.49138415]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06526238471269608\n",
      "Predicción post entrenamiento : [[0.5031675]]\n",
      "PERDIDAAAA despues: 0.06407405436038971\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "[[[0.43588087]\n",
      "  [0.4452554 ]\n",
      "  [0.45452893]\n",
      "  [0.46390387]\n",
      "  [0.47295552]\n",
      "  [0.48237228]\n",
      "  [0.49138415]\n",
      "  [0.50083101]]]\n",
      "ejemplar: [0.43588087 0.4452554  0.45452893 0.46390387 0.47295552 0.48237228\n",
      " 0.49138415 0.50083101]\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.51039654]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[0.43588087 0.4452554  0.45452893 0.46390387 0.47295552 0.48237228\n",
      "  0.49138415 0.50083101]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10060930252075195\n",
      "Predicción post entrenamiento : [[0.51338613]]\n",
      "PERDIDAAAA despues: 0.0987217053771019\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "[[[0.4452554 ]\n",
      "  [0.45452893]\n",
      "  [0.46390387]\n",
      "  [0.47295552]\n",
      "  [0.48237228]\n",
      "  [0.49138415]\n",
      "  [0.50083101]\n",
      "  [0.51039654]]]\n",
      "ejemplar: [0.4452554  0.45452893 0.46390387 0.47295552 0.48237228 0.49138415\n",
      " 0.50083101 0.51039654]\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.5206971]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[0.4452554  0.45452893 0.46390387 0.47295552 0.48237228 0.49138415\n",
      "  0.50083101 0.51039654]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1012035608291626\n",
      "Predicción post entrenamiento : [[0.5235074]]\n",
      "PERDIDAAAA despues: 0.09942340105772018\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "[[[0.45452893]\n",
      "  [0.46390387]\n",
      "  [0.47295552]\n",
      "  [0.48237228]\n",
      "  [0.49138415]\n",
      "  [0.50083101]\n",
      "  [0.51039654]\n",
      "  [0.52069712]]]\n",
      "ejemplar: [0.45452893 0.46390387 0.47295552 0.48237228 0.49138415 0.50083101\n",
      " 0.51039654 0.52069712]\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.53084373]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[0.45452893 0.46390387 0.47295552 0.48237228 0.49138415 0.50083101\n",
      "  0.51039654 0.52069712]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06939119100570679\n",
      "Predicción post entrenamiento : [[0.5336598]]\n",
      "PERDIDAAAA despues: 0.06791548430919647\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "[[[0.46390387]\n",
      "  [0.47295552]\n",
      "  [0.48237228]\n",
      "  [0.49138415]\n",
      "  [0.50083101]\n",
      "  [0.51039654]\n",
      "  [0.52069712]\n",
      "  [0.53084373]]]\n",
      "ejemplar: [0.46390387 0.47295552 0.48237228 0.49138415 0.50083101 0.51039654\n",
      " 0.52069712 0.53084373]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.5410585]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[0.46390387 0.47295552 0.48237228 0.49138415 0.50083101 0.51039654\n",
      "  0.52069712 0.53084373]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05892573297023773\n",
      "Predicción post entrenamiento : [[0.54327816]]\n",
      "PERDIDAAAA despues: 0.05785302445292473\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "[[[0.47295552]\n",
      "  [0.48237228]\n",
      "  [0.49138415]\n",
      "  [0.50083101]\n",
      "  [0.51039654]\n",
      "  [0.52069712]\n",
      "  [0.53084373]\n",
      "  [0.54105848]]]\n",
      "ejemplar: [0.47295552 0.48237228 0.49138415 0.50083101 0.51039654 0.52069712\n",
      " 0.53084373 0.54105848]\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.5507334]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[0.47295552 0.48237228 0.49138415 0.50083101 0.51039654 0.52069712\n",
      "  0.53084373 0.54105848]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.047169774770736694\n",
      "Predicción post entrenamiento : [[0.5527134]]\n",
      "PERDIDAAAA despues: 0.046313632279634476\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "[[[0.48237228]\n",
      "  [0.49138415]\n",
      "  [0.50083101]\n",
      "  [0.51039654]\n",
      "  [0.52069712]\n",
      "  [0.53084373]\n",
      "  [0.54105848]\n",
      "  [0.55073339]]]\n",
      "ejemplar: [0.48237228 0.49138415 0.50083101 0.51039654 0.52069712 0.53084373\n",
      " 0.54105848 0.55073339]\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.5603346]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[0.48237228 0.49138415 0.50083101 0.51039654 0.52069712 0.53084373\n",
      "  0.54105848 0.55073339]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05028582364320755\n",
      "Predicción post entrenamiento : [[0.56220204]]\n",
      "PERDIDAAAA despues: 0.049451794475317\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "[[[0.49138415]\n",
      "  [0.50083101]\n",
      "  [0.51039654]\n",
      "  [0.52069712]\n",
      "  [0.53084373]\n",
      "  [0.54105848]\n",
      "  [0.55073339]\n",
      "  [0.56033462]]]\n",
      "ejemplar: [0.49138415 0.50083101 0.51039654 0.52069712 0.53084373 0.54105848\n",
      " 0.55073339 0.56033462]\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.56992877]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[0.49138415 0.50083101 0.51039654 0.52069712 0.53084373 0.54105848\n",
      "  0.55073339 0.56033462]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09535768628120422\n",
      "Predicción post entrenamiento : [[0.5722253]]\n",
      "PERDIDAAAA despues: 0.09394463896751404\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "[[[0.50083101]\n",
      "  [0.51039654]\n",
      "  [0.52069712]\n",
      "  [0.53084373]\n",
      "  [0.54105848]\n",
      "  [0.55073339]\n",
      "  [0.56033462]\n",
      "  [0.56992877]]]\n",
      "ejemplar: [0.50083101 0.51039654 0.52069712 0.53084373 0.54105848 0.55073339\n",
      " 0.56033462 0.56992877]\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.580189]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[0.50083101 0.51039654 0.52069712 0.53084373 0.54105848 0.55073339\n",
      "  0.56033462 0.56992877]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08728515356779099\n",
      "Predicción post entrenamiento : [[0.58275086]]\n",
      "PERDIDAAAA despues: 0.08577796071767807\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "[[[0.51039654]\n",
      "  [0.52069712]\n",
      "  [0.53084373]\n",
      "  [0.54105848]\n",
      "  [0.55073339]\n",
      "  [0.56033462]\n",
      "  [0.56992877]\n",
      "  [0.58018899]]]\n",
      "ejemplar: [0.51039654 0.52069712 0.53084373 0.54105848 0.55073339 0.56033462\n",
      " 0.56992877 0.58018899]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.5908722]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[0.51039654 0.52069712 0.53084373 0.54105848 0.55073339 0.56033462\n",
      "  0.56992877 0.58018899]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06657616049051285\n",
      "Predicción post entrenamiento : [[0.59213406]]\n",
      "PERDIDAAAA despues: 0.06592658907175064\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "[[[0.52069712]\n",
      "  [0.53084373]\n",
      "  [0.54105848]\n",
      "  [0.55073339]\n",
      "  [0.56033462]\n",
      "  [0.56992877]\n",
      "  [0.58018899]\n",
      "  [0.59087223]]]\n",
      "ejemplar: [0.52069712 0.53084373 0.54105848 0.55073339 0.56033462 0.56992877\n",
      " 0.58018899 0.59087223]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.6003971]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[0.52069712 0.53084373 0.54105848 0.55073339 0.56033462 0.56992877\n",
      "  0.58018899 0.59087223]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04747621715068817\n",
      "Predicción post entrenamiento : [[0.602041]]\n",
      "PERDIDAAAA despues: 0.04676254093647003\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "[[[0.53084373]\n",
      "  [0.54105848]\n",
      "  [0.55073339]\n",
      "  [0.56033462]\n",
      "  [0.56992877]\n",
      "  [0.58018899]\n",
      "  [0.59087223]\n",
      "  [0.60039711]]]\n",
      "ejemplar: [0.53084373 0.54105848 0.55073339 0.56033462 0.56992877 0.58018899\n",
      " 0.59087223 0.60039711]\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.6102613]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[0.53084373 0.54105848 0.55073339 0.56033462 0.56992877 0.58018899\n",
      "  0.59087223 0.60039711]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0468938983976841\n",
      "Predicción post entrenamiento : [[0.6124379]]\n",
      "PERDIDAAAA despues: 0.04595595970749855\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "[[[0.54105848]\n",
      "  [0.55073339]\n",
      "  [0.56033462]\n",
      "  [0.56992877]\n",
      "  [0.58018899]\n",
      "  [0.59087223]\n",
      "  [0.60039711]\n",
      "  [0.61026132]]]\n",
      "ejemplar: [0.54105848 0.55073339 0.56033462 0.56992877 0.58018899 0.59087223\n",
      " 0.60039711 0.61026132]\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.6206444]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[0.54105848 0.55073339 0.56033462 0.56992877 0.58018899 0.59087223\n",
      "  0.60039711 0.61026132]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.027129419147968292\n",
      "Predicción post entrenamiento : [[0.6219375]]\n",
      "PERDIDAAAA despues: 0.02670511044561863\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "[[[0.55073339]\n",
      "  [0.56033462]\n",
      "  [0.56992877]\n",
      "  [0.58018899]\n",
      "  [0.59087223]\n",
      "  [0.60039711]\n",
      "  [0.61026132]\n",
      "  [0.62064439]]]\n",
      "ejemplar: [0.55073339 0.56033462 0.56992877 0.58018899 0.59087223 0.60039711\n",
      " 0.61026132 0.62064439]\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.6301032]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[0.55073339 0.56033462 0.56992877 0.58018899 0.59087223 0.60039711\n",
      "  0.61026132 0.62064439]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.025321021676063538\n",
      "Predicción post entrenamiento : [[0.63147175]]\n",
      "PERDIDAAAA despues: 0.024887342005968094\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "[[[0.56033462]\n",
      "  [0.56992877]\n",
      "  [0.58018899]\n",
      "  [0.59087223]\n",
      "  [0.60039711]\n",
      "  [0.61026132]\n",
      "  [0.62064439]\n",
      "  [0.63010317]]]\n",
      "ejemplar: [0.56033462 0.56992877 0.58018899 0.59087223 0.60039711 0.61026132\n",
      " 0.62064439 0.63010317]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.63973755]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[0.56033462 0.56992877 0.58018899 0.59087223 0.60039711 0.61026132\n",
      "  0.62064439 0.63010317]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03780506178736687\n",
      "Predicción post entrenamiento : [[0.6418257]]\n",
      "PERDIDAAAA despues: 0.03699741140007973\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "[[[0.56992877]\n",
      "  [0.58018899]\n",
      "  [0.59087223]\n",
      "  [0.60039711]\n",
      "  [0.61026132]\n",
      "  [0.62064439]\n",
      "  [0.63010317]\n",
      "  [0.63973755]]]\n",
      "ejemplar: [0.56992877 0.58018899 0.59087223 0.60039711 0.61026132 0.62064439\n",
      " 0.63010317 0.63973755]\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.6502252]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[0.56992877 0.58018899 0.59087223 0.60039711 0.61026132 0.62064439\n",
      "  0.63010317 0.63973755]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.026325250044465065\n",
      "Predicción post entrenamiento : [[0.6522666]]\n",
      "PERDIDAAAA despues: 0.0256669819355011\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "[[[0.58018899]\n",
      "  [0.59087223]\n",
      "  [0.60039711]\n",
      "  [0.61026132]\n",
      "  [0.62064439]\n",
      "  [0.63010317]\n",
      "  [0.63973755]\n",
      "  [0.65022522]]]\n",
      "ejemplar: [0.58018899 0.59087223 0.60039711 0.61026132 0.62064439 0.63010317\n",
      " 0.63973755 0.65022522]\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.6608151]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[0.58018899 0.59087223 0.60039711 0.61026132 0.62064439 0.63010317\n",
      "  0.63973755 0.65022522]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01971910521388054\n",
      "Predicción post entrenamiento : [[0.66097313]]\n",
      "PERDIDAAAA despues: 0.01967475190758705\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "[[[0.59087223]\n",
      "  [0.60039711]\n",
      "  [0.61026132]\n",
      "  [0.62064439]\n",
      "  [0.63010317]\n",
      "  [0.63973755]\n",
      "  [0.65022522]\n",
      "  [0.66081512]]]\n",
      "ejemplar: [0.59087223 0.60039711 0.61026132 0.62064439 0.63010317 0.63973755\n",
      " 0.65022522 0.66081512]\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.66949326]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[0.59087223 0.60039711 0.61026132 0.62064439 0.63010317 0.63973755\n",
      "  0.65022522 0.66081512]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01787135936319828\n",
      "Predicción post entrenamiento : [[0.66988534]]\n",
      "PERDIDAAAA despues: 0.0177666824311018\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "[[[0.60039711]\n",
      "  [0.61026132]\n",
      "  [0.62064439]\n",
      "  [0.63010317]\n",
      "  [0.63973755]\n",
      "  [0.65022522]\n",
      "  [0.66081512]\n",
      "  [0.66949326]]]\n",
      "ejemplar: [0.60039711 0.61026132 0.62064439 0.63010317 0.63973755 0.65022522\n",
      " 0.66081512 0.66949326]\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.67824227]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[0.60039711 0.61026132 0.62064439 0.63010317 0.63973755 0.65022522\n",
      "  0.66081512 0.66949326]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013282244093716145\n",
      "Predicción post entrenamiento : [[0.6792186]]\n",
      "PERDIDAAAA despues: 0.01305815763771534\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "[[[0.61026132]\n",
      "  [0.62064439]\n",
      "  [0.63010317]\n",
      "  [0.63973755]\n",
      "  [0.65022522]\n",
      "  [0.66081512]\n",
      "  [0.66949326]\n",
      "  [0.67824227]]]\n",
      "ejemplar: [0.61026132 0.62064439 0.63010317 0.63973755 0.65022522 0.66081512\n",
      " 0.66949326 0.67824227]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.6877001]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[0.61026132 0.62064439 0.63010317 0.63973755 0.65022522 0.66081512\n",
      "  0.66949326 0.67824227]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005251954309642315\n",
      "Predicción post entrenamiento : [[0.6890851]]\n",
      "PERDIDAAAA despues: 0.0050531248562037945\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "[[[0.62064439]\n",
      "  [0.63010317]\n",
      "  [0.63973755]\n",
      "  [0.65022522]\n",
      "  [0.66081512]\n",
      "  [0.66949326]\n",
      "  [0.67824227]\n",
      "  [0.68770009]]]\n",
      "ejemplar: [0.62064439 0.63010317 0.63973755 0.65022522 0.66081512 0.66949326\n",
      " 0.67824227 0.68770009]\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.6975965]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[0.62064439 0.63010317 0.63973755 0.65022522 0.66081512 0.66949326\n",
      "  0.67824227 0.68770009]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014271338004618883\n",
      "Predicción post entrenamiento : [[0.6972299]]\n",
      "PERDIDAAAA despues: 0.0014549641637131572\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "[[[0.63010317]\n",
      "  [0.63973755]\n",
      "  [0.65022522]\n",
      "  [0.66081512]\n",
      "  [0.66949326]\n",
      "  [0.67824227]\n",
      "  [0.68770009]\n",
      "  [0.69759649]]]\n",
      "ejemplar: [0.63010317 0.63973755 0.65022522 0.66081512 0.66949326 0.67824227\n",
      " 0.68770009 0.69759649]\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.70559925]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[0.63010317 0.63973755 0.65022522 0.66081512 0.66949326 0.67824227\n",
      "  0.68770009 0.69759649]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.1073341486044228e-05\n",
      "Predicción post entrenamiento : [[0.70608824]]\n",
      "PERDIDAAAA despues: 1.6822912584757432e-05\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "[[[0.63973755]\n",
      "  [0.65022522]\n",
      "  [0.66081512]\n",
      "  [0.66949326]\n",
      "  [0.67824227]\n",
      "  [0.68770009]\n",
      "  [0.69759649]\n",
      "  [0.70559925]]]\n",
      "ejemplar: [0.63973755 0.65022522 0.66081512 0.66949326 0.67824227 0.68770009\n",
      " 0.69759649 0.70559925]\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.7145325]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[0.63973755 0.65022522 0.66081512 0.66949326 0.67824227 0.68770009\n",
      "  0.69759649 0.70559925]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.785973371530417e-06\n",
      "Predicción post entrenamiento : [[0.71375877]]\n",
      "PERDIDAAAA despues: 2.6623704343364807e-06\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "[[[0.65022522]\n",
      "  [0.66081512]\n",
      "  [0.66949326]\n",
      "  [0.67824227]\n",
      "  [0.68770009]\n",
      "  [0.69759649]\n",
      "  [0.70559925]\n",
      "  [0.71453249]]]\n",
      "ejemplar: [0.65022522 0.66081512 0.66949326 0.67824227 0.68770009 0.69759649\n",
      " 0.70559925 0.71453249]\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.72220296]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[0.65022522 0.66081512 0.66949326 0.67824227 0.68770009 0.69759649\n",
      "  0.70559925 0.71453249]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003039049042854458\n",
      "Predicción post entrenamiento : [[0.72270274]]\n",
      "PERDIDAAAA despues: 0.00028672930784523487\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "[[[0.66081512]\n",
      "  [0.66949326]\n",
      "  [0.67824227]\n",
      "  [0.68770009]\n",
      "  [0.69759649]\n",
      "  [0.70559925]\n",
      "  [0.71453249]\n",
      "  [0.72220296]]]\n",
      "ejemplar: [0.66081512 0.66949326 0.67824227 0.68770009 0.69759649 0.70559925\n",
      " 0.71453249 0.72220296]\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.7308659]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[0.66081512 0.66949326 0.67824227 0.68770009 0.69759649 0.70559925\n",
      "  0.71453249 0.72220296]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.7908808988286182e-05\n",
      "Predicción post entrenamiento : [[0.7314752]]\n",
      "PERDIDAAAA despues: 2.1842539354111068e-05\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "[[[0.66949326]\n",
      "  [0.67824227]\n",
      "  [0.68770009]\n",
      "  [0.69759649]\n",
      "  [0.70559925]\n",
      "  [0.71453249]\n",
      "  [0.72220296]\n",
      "  [0.7308659 ]]]\n",
      "ejemplar: [0.66949326 0.67824227 0.68770009 0.69759649 0.70559925 0.71453249\n",
      " 0.72220296 0.7308659 ]\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.7392462]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[0.66949326 0.67824227 0.68770009 0.69759649 0.70559925 0.71453249\n",
      "  0.72220296 0.7308659 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00513737415894866\n",
      "Predicción post entrenamiento : [[0.73833543]]\n",
      "PERDIDAAAA despues: 0.005007645580917597\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "[[[0.67824227]\n",
      "  [0.68770009]\n",
      "  [0.69759649]\n",
      "  [0.70559925]\n",
      "  [0.71453249]\n",
      "  [0.72220296]\n",
      "  [0.7308659 ]\n",
      "  [0.73924619]]]\n",
      "ejemplar: [0.67824227 0.68770009 0.69759649 0.70559925 0.71453249 0.72220296\n",
      " 0.7308659  0.73924619]\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.7461713]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[0.67824227 0.68770009 0.69759649 0.70559925 0.71453249 0.72220296\n",
      "  0.7308659  0.73924619]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005818010773509741\n",
      "Predicción post entrenamiento : [[0.7465555]]\n",
      "PERDIDAAAA despues: 0.005876770243048668\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "[[[0.68770009]\n",
      "  [0.69759649]\n",
      "  [0.70559925]\n",
      "  [0.71453249]\n",
      "  [0.72220296]\n",
      "  [0.7308659 ]\n",
      "  [0.73924619]\n",
      "  [0.7461713 ]]]\n",
      "ejemplar: [0.68770009 0.69759649 0.70559925 0.71453249 0.72220296 0.7308659\n",
      " 0.73924619 0.7461713 ]\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.7544174]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[0.68770009 0.69759649 0.70559925 0.71453249 0.72220296 0.7308659\n",
      "  0.73924619 0.7461713 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003339475253596902\n",
      "Predicción post entrenamiento : [[0.7537141]]\n",
      "PERDIDAAAA despues: 0.00325868115760386\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "[[[0.69759649]\n",
      "  [0.70559925]\n",
      "  [0.71453249]\n",
      "  [0.72220296]\n",
      "  [0.7308659 ]\n",
      "  [0.73924619]\n",
      "  [0.7461713 ]\n",
      "  [0.75441742]]]\n",
      "ejemplar: [0.69759649 0.70559925 0.71453249 0.72220296 0.7308659  0.73924619\n",
      " 0.7461713  0.75441742]\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.761358]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[0.69759649 0.70559925 0.71453249 0.72220296 0.7308659  0.73924619\n",
      "  0.7461713  0.75441742]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01111141499131918\n",
      "Predicción post entrenamiento : [[0.7606709]]\n",
      "PERDIDAAAA despues: 0.010967026464641094\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "[[[0.70559925]\n",
      "  [0.71453249]\n",
      "  [0.72220296]\n",
      "  [0.7308659 ]\n",
      "  [0.73924619]\n",
      "  [0.7461713 ]\n",
      "  [0.75441742]\n",
      "  [0.76135802]]]\n",
      "ejemplar: [0.70559925 0.71453249 0.72220296 0.7308659  0.73924619 0.7461713\n",
      " 0.75441742 0.76135802]\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.7678964]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[0.70559925 0.71453249 0.72220296 0.7308659  0.73924619 0.7461713\n",
      "  0.75441742 0.76135802]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007936983369290829\n",
      "Predicción post entrenamiento : [[0.76851475]]\n",
      "PERDIDAAAA despues: 0.008047541603446007\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "[[[0.71453249]\n",
      "  [0.72220296]\n",
      "  [0.7308659 ]\n",
      "  [0.73924619]\n",
      "  [0.7461713 ]\n",
      "  [0.75441742]\n",
      "  [0.76135802]\n",
      "  [0.76789641]]]\n",
      "ejemplar: [0.71453249 0.72220296 0.7308659  0.73924619 0.7461713  0.75441742\n",
      " 0.76135802 0.76789641]\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.7757746]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[0.71453249 0.72220296 0.7308659  0.73924619 0.7461713  0.75441742\n",
      "  0.76135802 0.76789641]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009936115704476833\n",
      "Predicción post entrenamiento : [[0.77373827]]\n",
      "PERDIDAAAA despues: 0.009534298442304134\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "[[[0.72220296]\n",
      "  [0.7308659 ]\n",
      "  [0.73924619]\n",
      "  [0.7461713 ]\n",
      "  [0.75441742]\n",
      "  [0.76135802]\n",
      "  [0.76789641]\n",
      "  [0.7757746 ]]]\n",
      "ejemplar: [0.72220296 0.7308659  0.73924619 0.7461713  0.75441742 0.76135802\n",
      " 0.76789641 0.7757746 ]\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.7807244]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[0.72220296 0.7308659  0.73924619 0.7461713  0.75441742 0.76135802\n",
      "  0.76789641 0.7757746 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0026175749953836203\n",
      "Predicción post entrenamiento : [[0.7804167]]\n",
      "PERDIDAAAA despues: 0.002586186630651355\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "[[[0.7308659 ]\n",
      "  [0.73924619]\n",
      "  [0.7461713 ]\n",
      "  [0.75441742]\n",
      "  [0.76135802]\n",
      "  [0.76789641]\n",
      "  [0.7757746 ]\n",
      "  [0.78072441]]]\n",
      "ejemplar: [0.7308659  0.73924619 0.7461713  0.75441742 0.76135802 0.76789641\n",
      " 0.7757746  0.78072441]\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.78741795]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[0.7308659  0.73924619 0.7461713  0.75441742 0.76135802 0.76789641\n",
      "  0.7757746  0.78072441]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007419993169605732\n",
      "Predicción post entrenamiento : [[0.7877214]]\n",
      "PERDIDAAAA despues: 0.007472362369298935\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "[[[0.73924619]\n",
      "  [0.7461713 ]\n",
      "  [0.75441742]\n",
      "  [0.76135802]\n",
      "  [0.76789641]\n",
      "  [0.7757746 ]\n",
      "  [0.78072441]\n",
      "  [0.78741795]]]\n",
      "ejemplar: [0.73924619 0.7461713  0.75441742 0.76135802 0.76789641 0.7757746\n",
      " 0.78072441 0.78741795]\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.79440415]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[0.73924619 0.7461713  0.75441742 0.76135802 0.76789641 0.7757746\n",
      "  0.78072441 0.78741795]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007221128907985985\n",
      "Predicción post entrenamiento : [[0.7929382]]\n",
      "PERDIDAAAA despues: 0.0006454740650951862\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "[[[0.7461713 ]\n",
      "  [0.75441742]\n",
      "  [0.76135802]\n",
      "  [0.76789641]\n",
      "  [0.7757746 ]\n",
      "  [0.78072441]\n",
      "  [0.78741795]\n",
      "  [0.79440415]]]\n",
      "ejemplar: [0.7461713  0.75441742 0.76135802 0.76789641 0.7757746  0.78072441\n",
      " 0.78741795 0.79440415]\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.79928976]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[0.7461713  0.75441742 0.76135802 0.76789641 0.7757746  0.78072441\n",
      "  0.78741795 0.79440415]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001949758967384696\n",
      "Predicción post entrenamiento : [[0.79883456]]\n",
      "PERDIDAAAA despues: 0.0019097663462162018\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "[[[0.75441742]\n",
      "  [0.76135802]\n",
      "  [0.76789641]\n",
      "  [0.7757746 ]\n",
      "  [0.78072441]\n",
      "  [0.78741795]\n",
      "  [0.79440415]\n",
      "  [0.79928976]]]\n",
      "ejemplar: [0.75441742 0.76135802 0.76789641 0.7757746  0.78072441 0.78741795\n",
      " 0.79440415 0.79928976]\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.8051941]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[0.75441742 0.76135802 0.76789641 0.7757746  0.78072441 0.78741795\n",
      "  0.79440415 0.79928976]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003616104368120432\n",
      "Predicción post entrenamiento : [[0.8049033]]\n",
      "PERDIDAAAA despues: 0.0035812207497656345\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "[[[0.76135802]\n",
      "  [0.76789641]\n",
      "  [0.7757746 ]\n",
      "  [0.78072441]\n",
      "  [0.78741795]\n",
      "  [0.79440415]\n",
      "  [0.79928976]\n",
      "  [0.80519408]]]\n",
      "ejemplar: [0.76135802 0.76789641 0.7757746  0.78072441 0.78741795 0.79440415\n",
      " 0.79928976 0.80519408]\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.81084347]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[0.76135802 0.76789641 0.7757746  0.78072441 0.78741795 0.79440415\n",
      "  0.79928976 0.80519408]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003458545543253422\n",
      "Predicción post entrenamiento : [[0.80943197]]\n",
      "PERDIDAAAA despues: 0.0032945191487669945\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "[[[0.76789641]\n",
      "  [0.7757746 ]\n",
      "  [0.78072441]\n",
      "  [0.78741795]\n",
      "  [0.79440415]\n",
      "  [0.79928976]\n",
      "  [0.80519408]\n",
      "  [0.81084347]]]\n",
      "ejemplar: [0.76789641 0.7757746  0.78072441 0.78741795 0.79440415 0.79928976\n",
      " 0.80519408 0.81084347]\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.8152336]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[0.76789641 0.7757746  0.78072441 0.78741795 0.79440415 0.79928976\n",
      "  0.80519408 0.81084347]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011115738190710545\n",
      "Predicción post entrenamiento : [[0.81587964]]\n",
      "PERDIDAAAA despues: 0.011252383701503277\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "[[[0.7757746 ]\n",
      "  [0.78072441]\n",
      "  [0.78741795]\n",
      "  [0.79440415]\n",
      "  [0.79928976]\n",
      "  [0.80519408]\n",
      "  [0.81084347]\n",
      "  [0.81523359]]]\n",
      "ejemplar: [0.7757746  0.78072441 0.78741795 0.79440415 0.79928976 0.80519408\n",
      " 0.81084347 0.81523359]\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.8216066]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[0.7757746  0.78072441 0.78741795 0.79440415 0.79928976 0.80519408\n",
      "  0.81084347 0.81523359]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017207281664013863\n",
      "Predicción post entrenamiento : [[0.8189397]]\n",
      "PERDIDAAAA despues: 0.016514727845788002\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "[[[0.78072441]\n",
      "  [0.78741795]\n",
      "  [0.79440415]\n",
      "  [0.79928976]\n",
      "  [0.80519408]\n",
      "  [0.81084347]\n",
      "  [0.81523359]\n",
      "  [0.82160658]]]\n",
      "ejemplar: [0.78072441 0.78741795 0.79440415 0.79928976 0.80519408 0.81084347\n",
      " 0.81523359 0.82160658]\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.8241447]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[0.78072441 0.78741795 0.79440415 0.79928976 0.80519408 0.81084347\n",
      "  0.81523359 0.82160658]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00487007899209857\n",
      "Predicción post entrenamiento : [[0.8241544]]\n",
      "PERDIDAAAA despues: 0.004871427081525326\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "[[[0.78741795]\n",
      "  [0.79440415]\n",
      "  [0.79928976]\n",
      "  [0.80519408]\n",
      "  [0.81084347]\n",
      "  [0.81523359]\n",
      "  [0.82160658]\n",
      "  [0.82414472]]]\n",
      "ejemplar: [0.78741795 0.79440415 0.79928976 0.80519408 0.81084347 0.81523359\n",
      " 0.82160658 0.82414472]\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.82958925]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[0.78741795 0.79440415 0.79928976 0.80519408 0.81084347 0.81523359\n",
      "  0.82160658 0.82414472]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011532302014529705\n",
      "Predicción post entrenamiento : [[0.8282397]]\n",
      "PERDIDAAAA despues: 0.011244267225265503\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "[[[0.79440415]\n",
      "  [0.79928976]\n",
      "  [0.80519408]\n",
      "  [0.81084347]\n",
      "  [0.81523359]\n",
      "  [0.82160658]\n",
      "  [0.82414472]\n",
      "  [0.82958925]]]\n",
      "ejemplar: [0.79440415 0.79928976 0.80519408 0.81084347 0.81523359 0.82160658\n",
      " 0.82414472 0.82958925]\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.8333784]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[0.79440415 0.79928976 0.80519408 0.81084347 0.81523359 0.82160658\n",
      "  0.82414472 0.82958925]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00022891639673616737\n",
      "Predicción post entrenamiento : [[0.8336808]]\n",
      "PERDIDAAAA despues: 0.00021985622879583389\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "[[[0.79928976]\n",
      "  [0.80519408]\n",
      "  [0.81084347]\n",
      "  [0.81523359]\n",
      "  [0.82160658]\n",
      "  [0.82414472]\n",
      "  [0.82958925]\n",
      "  [0.83337837]]]\n",
      "ejemplar: [0.79928976 0.80519408 0.81084347 0.81523359 0.82160658 0.82414472\n",
      " 0.82958925 0.83337837]\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.83834815]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[0.79928976 0.80519408 0.81084347 0.81523359 0.82160658 0.82414472\n",
      "  0.82958925 0.83337837]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004504400305449963\n",
      "Predicción post entrenamiento : [[0.8384261]]\n",
      "PERDIDAAAA despues: 0.004493941552937031\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "[[[0.80519408]\n",
      "  [0.81084347]\n",
      "  [0.81523359]\n",
      "  [0.82160658]\n",
      "  [0.82414472]\n",
      "  [0.82958925]\n",
      "  [0.83337837]\n",
      "  [0.83834815]]]\n",
      "ejemplar: [0.80519408 0.81084347 0.81523359 0.82160658 0.82414472 0.82958925\n",
      " 0.83337837 0.83834815]\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.8431375]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[0.80519408 0.81084347 0.81523359 0.82160658 0.82414472 0.82958925\n",
      "  0.83337837 0.83834815]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015271457377821207\n",
      "Predicción post entrenamiento : [[0.8437341]]\n",
      "PERDIDAAAA despues: 0.0014808742562308908\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "[[[0.81084347]\n",
      "  [0.81523359]\n",
      "  [0.82160658]\n",
      "  [0.82414472]\n",
      "  [0.82958925]\n",
      "  [0.83337837]\n",
      "  [0.83834815]\n",
      "  [0.8431375 ]]]\n",
      "ejemplar: [0.81084347 0.81523359 0.82160658 0.82414472 0.82958925 0.83337837\n",
      " 0.83834815 0.8431375 ]\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.848168]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[0.81084347 0.81523359 0.82160658 0.82414472 0.82958925 0.83337837\n",
      "  0.83834815 0.8431375 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0035545043647289276\n",
      "Predicción post entrenamiento : [[0.84713036]]\n",
      "PERDIDAAAA despues: 0.0036793106701225042\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "[[[0.81523359]\n",
      "  [0.82160658]\n",
      "  [0.82414472]\n",
      "  [0.82958925]\n",
      "  [0.83337837]\n",
      "  [0.83834815]\n",
      "  [0.8431375 ]\n",
      "  [0.84816802]]]\n",
      "ejemplar: [0.81523359 0.82160658 0.82414472 0.82958925 0.83337837 0.83834815\n",
      " 0.8431375  0.84816802]\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.8513006]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[0.81523359 0.82160658 0.82414472 0.82958925 0.83337837 0.83834815\n",
      "  0.8431375  0.84816802]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014651356032118201\n",
      "Predicción post entrenamiento : [[0.8505199]]\n",
      "PERDIDAAAA despues: 0.0015255110338330269\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "[[[0.82160658]\n",
      "  [0.82414472]\n",
      "  [0.82958925]\n",
      "  [0.83337837]\n",
      "  [0.83834815]\n",
      "  [0.8431375 ]\n",
      "  [0.84816802]\n",
      "  [0.8513006 ]]]\n",
      "ejemplar: [0.82160658 0.82414472 0.82958925 0.83337837 0.83834815 0.8431375\n",
      " 0.84816802 0.8513006 ]\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.854749]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[0.82160658 0.82414472 0.82958925 0.83337837 0.83834815 0.8431375\n",
      "  0.84816802 0.8513006 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004042375658173114\n",
      "Predicción post entrenamiento : [[0.85535944]]\n",
      "PERDIDAAAA despues: 0.0003800647391472012\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "[[[0.82414472]\n",
      "  [0.82958925]\n",
      "  [0.83337837]\n",
      "  [0.83834815]\n",
      "  [0.8431375 ]\n",
      "  [0.84816802]\n",
      "  [0.8513006 ]\n",
      "  [0.85474902]]]\n",
      "ejemplar: [0.82414472 0.82958925 0.83337837 0.83834815 0.8431375  0.84816802\n",
      " 0.8513006  0.85474902]\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.859054]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[0.82414472 0.82958925 0.83337837 0.83834815 0.8431375  0.84816802\n",
      "  0.8513006  0.85474902]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029330796096473932\n",
      "Predicción post entrenamiento : [[0.8595412]]\n",
      "PERDIDAAAA despues: 0.0028805509209632874\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "[[[0.82958925]\n",
      "  [0.83337837]\n",
      "  [0.83834815]\n",
      "  [0.8431375 ]\n",
      "  [0.84816802]\n",
      "  [0.8513006 ]\n",
      "  [0.85474902]\n",
      "  [0.85905403]]]\n",
      "ejemplar: [0.82958925 0.83337837 0.83834815 0.8431375  0.84816802 0.8513006\n",
      " 0.85474902 0.85905403]\n",
      "y: 1.0\n",
      "Predicción : [[0.8637515]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[0.82958925 0.83337837 0.83834815 0.8431375  0.84816802 0.8513006\n",
      "  0.85474902 0.85905403]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018563661724328995\n",
      "Predicción post entrenamiento : [[0.8654556]]\n",
      "PERDIDAAAA despues: 0.018102187663316727\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "[[[0.83337837]\n",
      "  [0.83834815]\n",
      "  [0.8431375 ]\n",
      "  [0.84816802]\n",
      "  [0.8513006 ]\n",
      "  [0.85474902]\n",
      "  [0.85905403]\n",
      "  [0.86375147]]]\n",
      "ejemplar: [0.83337837 0.83834815 0.8431375  0.84816802 0.8513006  0.85474902\n",
      " 0.85905403 0.86375147]\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.86938244]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[0.83337837 0.83834815 0.8431375  0.84816802 0.8513006  0.85474902\n",
      "  0.85905403 0.86375147]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010235695168375969\n",
      "Predicción post entrenamiento : [[0.8710178]]\n",
      "PERDIDAAAA despues: 0.009907462634146214\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "[[[0.83834815]\n",
      "  [0.8431375 ]\n",
      "  [0.84816802]\n",
      "  [0.8513006 ]\n",
      "  [0.85474902]\n",
      "  [0.85905403]\n",
      "  [0.86375147]\n",
      "  [0.86938244]]]\n",
      "ejemplar: [0.83834815 0.8431375  0.84816802 0.8513006  0.85474902 0.85905403\n",
      " 0.86375147 0.86938244]\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.87510586]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[0.83834815 0.8431375  0.84816802 0.8513006  0.85474902 0.85905403\n",
      "  0.86375147 0.86938244]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001876053138403222\n",
      "Predicción post entrenamiento : [[0.87399304]]\n",
      "PERDIDAAAA despues: 0.00021932803792878985\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "[[[0.8431375 ]\n",
      "  [0.84816802]\n",
      "  [0.8513006 ]\n",
      "  [0.85474902]\n",
      "  [0.85905403]\n",
      "  [0.86375147]\n",
      "  [0.86938244]\n",
      "  [0.87510586]]]\n",
      "ejemplar: [0.8431375  0.84816802 0.8513006  0.85474902 0.85905403 0.86375147\n",
      " 0.86938244 0.87510586]\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.877917]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[0.8431375  0.84816802 0.8513006  0.85474902 0.85905403 0.86375147\n",
      "  0.86938244 0.87510586]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.392223225593625e-09\n",
      "Predicción post entrenamiento : [[0.8774903]]\n",
      "PERDIDAAAA despues: 2.153165610252472e-07\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "[[[0.84816802]\n",
      "  [0.8513006 ]\n",
      "  [0.85474902]\n",
      "  [0.85905403]\n",
      "  [0.86375147]\n",
      "  [0.86938244]\n",
      "  [0.87510586]\n",
      "  [0.87791699]]]\n",
      "ejemplar: [0.84816802 0.8513006  0.85474902 0.85905403 0.86375147 0.86938244\n",
      " 0.87510586 0.87791699]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.8812872]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[0.84816802 0.8513006  0.85474902 0.85905403 0.86375147 0.86938244\n",
      "  0.87510586 0.87791699]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010492046130821109\n",
      "Predicción post entrenamiento : [[0.88132983]]\n",
      "PERDIDAAAA despues: 0.0010519673814997077\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "[[[0.8513006 ]\n",
      "  [0.85474902]\n",
      "  [0.85905403]\n",
      "  [0.86375147]\n",
      "  [0.86938244]\n",
      "  [0.87510586]\n",
      "  [0.87791699]\n",
      "  [0.88128722]]]\n",
      "ejemplar: [0.8513006  0.85474902 0.85905403 0.86375147 0.86938244 0.87510586\n",
      " 0.87791699 0.88128722]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.88491696]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[0.8513006  0.85474902 0.85905403 0.86375147 0.86938244 0.87510586\n",
      "  0.87791699 0.88128722]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0025749714113771915\n",
      "Predicción post entrenamiento : [[0.88463205]]\n",
      "PERDIDAAAA despues: 0.0025461374316364527\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "[[[0.85474902]\n",
      "  [0.85905403]\n",
      "  [0.86375147]\n",
      "  [0.86938244]\n",
      "  [0.87510586]\n",
      "  [0.87791699]\n",
      "  [0.88128722]\n",
      "  [0.88491696]]]\n",
      "ejemplar: [0.85474902 0.85905403 0.86375147 0.86938244 0.87510586 0.87791699\n",
      " 0.88128722 0.88491696]\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.88855]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[0.85474902 0.85905403 0.86375147 0.86938244 0.87510586 0.87791699\n",
      "  0.88128722 0.88491696]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001119241933338344\n",
      "Predicción post entrenamiento : [[0.8879847]]\n",
      "PERDIDAAAA despues: 0.0010817378060892224\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "[[[0.85905403]\n",
      "  [0.86375147]\n",
      "  [0.86938244]\n",
      "  [0.87510586]\n",
      "  [0.87791699]\n",
      "  [0.88128722]\n",
      "  [0.88491696]\n",
      "  [0.88854998]]]\n",
      "ejemplar: [0.85905403 0.86375147 0.86938244 0.87510586 0.87791699 0.88128722\n",
      " 0.88491696 0.88854998]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.8921757]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[0.85905403 0.86375147 0.86938244 0.87510586 0.87791699 0.88128722\n",
      "  0.88491696 0.88854998]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00028674345230683684\n",
      "Predicción post entrenamiento : [[0.89192533]]\n",
      "PERDIDAAAA despues: 0.0002783278760034591\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "[[[0.86375147]\n",
      "  [0.86938244]\n",
      "  [0.87510586]\n",
      "  [0.87791699]\n",
      "  [0.88128722]\n",
      "  [0.88491696]\n",
      "  [0.88854998]\n",
      "  [0.89217567]]]\n",
      "ejemplar: [0.86375147 0.86938244 0.87510586 0.87791699 0.88128722 0.88491696\n",
      " 0.88854998 0.89217567]\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.8961418]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[0.86375147 0.86938244 0.87510586 0.87791699 0.88128722 0.88491696\n",
      "  0.88854998 0.89217567]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001529564498923719\n",
      "Predicción post entrenamiento : [[0.8964719]]\n",
      "PERDIDAAAA despues: 0.0015554928686469793\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "[[[0.86938244]\n",
      "  [0.87510586]\n",
      "  [0.87791699]\n",
      "  [0.88128722]\n",
      "  [0.88491696]\n",
      "  [0.88854998]\n",
      "  [0.89217567]\n",
      "  [0.89614183]]]\n",
      "ejemplar: [0.86938244 0.87510586 0.87791699 0.88128722 0.88491696 0.88854998\n",
      " 0.89217567 0.89614183]\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.90056026]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[0.86938244 0.87510586 0.87791699 0.88128722 0.88491696 0.88854998\n",
      "  0.89217567 0.89614183]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002550464356318116\n",
      "Predicción post entrenamiento : [[0.8991338]]\n",
      "PERDIDAAAA despues: 0.002408420667052269\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "[[[0.87510586]\n",
      "  [0.87791699]\n",
      "  [0.88128722]\n",
      "  [0.88491696]\n",
      "  [0.88854998]\n",
      "  [0.89217567]\n",
      "  [0.89614183]\n",
      "  [0.90056026]]]\n",
      "ejemplar: [0.87510586 0.87791699 0.88128722 0.88491696 0.88854998 0.89217567\n",
      " 0.89614183 0.90056026]\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.90276]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[0.87510586 0.87791699 0.88128722 0.88491696 0.88854998 0.89217567\n",
      "  0.89614183 0.90056026]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003607614664360881\n",
      "Predicción post entrenamiento : [[0.9033119]]\n",
      "PERDIDAAAA despues: 0.003674214705824852\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "[[[0.87791699]\n",
      "  [0.88128722]\n",
      "  [0.88491696]\n",
      "  [0.88854998]\n",
      "  [0.89217567]\n",
      "  [0.89614183]\n",
      "  [0.90056026]\n",
      "  [0.90276003]]]\n",
      "ejemplar: [0.87791699 0.88128722 0.88491696 0.88854998 0.89217567 0.89614183\n",
      " 0.90056026 0.90276003]\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.9063616]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[0.87791699 0.88128722 0.88491696 0.88854998 0.89217567 0.89614183\n",
      "  0.90056026 0.90276003]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006959688384085894\n",
      "Predicción post entrenamiento : [[0.90575665]]\n",
      "PERDIDAAAA despues: 0.006859122309833765\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "[[[0.88128722]\n",
      "  [0.88491696]\n",
      "  [0.88854998]\n",
      "  [0.89217567]\n",
      "  [0.89614183]\n",
      "  [0.90056026]\n",
      "  [0.90276003]\n",
      "  [0.90636158]]]\n",
      "ejemplar: [0.88128722 0.88491696 0.88854998 0.89217567 0.89614183 0.90056026\n",
      " 0.90276003 0.90636158]\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.9090163]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[0.88128722 0.88491696 0.88854998 0.89217567 0.89614183 0.90056026\n",
      "  0.90276003 0.90636158]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018093015998601913\n",
      "Predicción post entrenamiento : [[0.90845686]]\n",
      "PERDIDAAAA despues: 0.017942825332283974\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "[[[0.88491696]\n",
      "  [0.88854998]\n",
      "  [0.89217567]\n",
      "  [0.89614183]\n",
      "  [0.90056026]\n",
      "  [0.90276003]\n",
      "  [0.90636158]\n",
      "  [0.90901631]]]\n",
      "ejemplar: [0.88491696 0.88854998 0.89217567 0.89614183 0.90056026 0.90276003\n",
      " 0.90636158 0.90901631]\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.9117839]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[0.88491696 0.88854998 0.89217567 0.89614183 0.90056026 0.90276003\n",
      "  0.90636158 0.90901631]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01627964898943901\n",
      "Predicción post entrenamiento : [[0.9103342]]\n",
      "PERDIDAAAA despues: 0.015911825001239777\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "[[[0.88854998]\n",
      "  [0.89217567]\n",
      "  [0.89614183]\n",
      "  [0.90056026]\n",
      "  [0.90276003]\n",
      "  [0.90636158]\n",
      "  [0.90901631]\n",
      "  [0.91178387]]]\n",
      "ejemplar: [0.88854998 0.89217567 0.89614183 0.90056026 0.90276003 0.90636158\n",
      " 0.90901631 0.91178387]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.9136406]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[0.88854998 0.89217567 0.89614183 0.90056026 0.90276003 0.90636158\n",
      "  0.90901631 0.91178387]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029048121068626642\n",
      "Predicción post entrenamiento : [[0.9142533]]\n",
      "PERDIDAAAA despues: 0.002971229376271367\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "[[[0.89217567]\n",
      "  [0.89614183]\n",
      "  [0.90056026]\n",
      "  [0.90276003]\n",
      "  [0.90636158]\n",
      "  [0.90901631]\n",
      "  [0.91178387]\n",
      "  [0.91364062]]]\n",
      "ejemplar: [0.89217567 0.89614183 0.90056026 0.90276003 0.90636158 0.90901631\n",
      " 0.91178387 0.91364062]\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.9175065]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[0.89217567 0.89614183 0.90056026 0.90276003 0.90636158 0.90901631\n",
      "  0.91178387 0.91364062]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003992529585957527\n",
      "Predicción post entrenamiento : [[0.91729414]]\n",
      "PERDIDAAAA despues: 0.003965736832469702\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "[[[0.89614183]\n",
      "  [0.90056026]\n",
      "  [0.90276003]\n",
      "  [0.90636158]\n",
      "  [0.90901631]\n",
      "  [0.91178387]\n",
      "  [0.91364062]\n",
      "  [0.91750652]]]\n",
      "ejemplar: [0.89614183 0.90056026 0.90276003 0.90636158 0.90901631 0.91178387\n",
      " 0.91364062 0.91750652]\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.92045736]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[0.89614183 0.90056026 0.90276003 0.90636158 0.90901631 0.91178387\n",
      "  0.91364062 0.91750652]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006984353996813297\n",
      "Predicción post entrenamiento : [[0.9196115]]\n",
      "PERDIDAAAA despues: 0.006843689829111099\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "[[[0.90056026]\n",
      "  [0.90276003]\n",
      "  [0.90636158]\n",
      "  [0.90901631]\n",
      "  [0.91178387]\n",
      "  [0.91364062]\n",
      "  [0.91750652]\n",
      "  [0.92045736]]]\n",
      "ejemplar: [0.90056026 0.90276003 0.90636158 0.90901631 0.91178387 0.91364062\n",
      " 0.91750652 0.92045736]\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.9225416]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[0.90056026 0.90276003 0.90636158 0.90901631 0.91178387 0.91364062\n",
      "  0.91750652 0.92045736]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008580454625189304\n",
      "Predicción post entrenamiento : [[0.92201155]]\n",
      "PERDIDAAAA despues: 0.008482535369694233\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "[[[0.90276003]\n",
      "  [0.90636158]\n",
      "  [0.90901631]\n",
      "  [0.91178387]\n",
      "  [0.91364062]\n",
      "  [0.91750652]\n",
      "  [0.92045736]\n",
      "  [0.92254162]]]\n",
      "ejemplar: [0.90276003 0.90636158 0.90901631 0.91178387 0.91364062 0.91750652\n",
      " 0.92045736 0.92254162]\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.9245179]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[0.90276003 0.90636158 0.90901631 0.91178387 0.91364062 0.91750652\n",
      "  0.92045736 0.92254162]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013886759988963604\n",
      "Predicción post entrenamiento : [[0.9247024]]\n",
      "PERDIDAAAA despues: 0.0014024589909240603\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "[[[0.90636158]\n",
      "  [0.90901631]\n",
      "  [0.91178387]\n",
      "  [0.91364062]\n",
      "  [0.91750652]\n",
      "  [0.92045736]\n",
      "  [0.92254162]\n",
      "  [0.92451793]]]\n",
      "ejemplar: [0.90636158 0.90901631 0.91178387 0.91364062 0.91750652 0.92045736\n",
      " 0.92254162 0.92451793]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.9273789]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[0.90636158 0.90901631 0.91178387 0.91364062 0.91750652 0.92045736\n",
      "  0.92254162 0.92451793]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004574436694383621\n",
      "Predicción post entrenamiento : [[0.92695403]]\n",
      "PERDIDAAAA despues: 0.00451714638620615\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "[[[0.90901631]\n",
      "  [0.91178387]\n",
      "  [0.91364062]\n",
      "  [0.91750652]\n",
      "  [0.92045736]\n",
      "  [0.92254162]\n",
      "  [0.92451793]\n",
      "  [0.92737889]]]\n",
      "ejemplar: [0.90901631 0.91178387 0.91364062 0.91750652 0.92045736 0.92254162\n",
      " 0.92451793 0.92737889]\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.929391]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[0.90901631 0.91178387 0.91364062 0.91750652 0.92045736 0.92254162\n",
      "  0.92451793 0.92737889]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008062958717346191\n",
      "Predicción post entrenamiento : [[0.9281527]]\n",
      "PERDIDAAAA despues: 0.007842100225389004\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "[[[0.91178387]\n",
      "  [0.91364062]\n",
      "  [0.91750652]\n",
      "  [0.92045736]\n",
      "  [0.92254162]\n",
      "  [0.92451793]\n",
      "  [0.92737889]\n",
      "  [0.92939103]]]\n",
      "ejemplar: [0.91178387 0.91364062 0.91750652 0.92045736 0.92254162 0.92451793\n",
      " 0.92737889 0.92939103]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.9305883]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[0.91178387 0.91364062 0.91750652 0.92045736 0.92254162 0.92451793\n",
      "  0.92737889 0.92939103]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.021545423194766045\n",
      "Predicción post entrenamiento : [[0.92965287]]\n",
      "PERDIDAAAA despues: 0.021271685138344765\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "[[[0.91364062]\n",
      "  [0.91750652]\n",
      "  [0.92045736]\n",
      "  [0.92254162]\n",
      "  [0.92451793]\n",
      "  [0.92737889]\n",
      "  [0.92939103]\n",
      "  [0.9305883 ]]]\n",
      "ejemplar: [0.91364062 0.91750652 0.92045736 0.92254162 0.92451793 0.92737889\n",
      " 0.92939103 0.9305883 ]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.9320345]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[0.91364062 0.91750652 0.92045736 0.92254162 0.92451793 0.92737889\n",
      "  0.92939103 0.9305883 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012938380241394043\n",
      "Predicción post entrenamiento : [[0.93064404]]\n",
      "PERDIDAAAA despues: 0.012623992748558521\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "[[[0.91750652]\n",
      "  [0.92045736]\n",
      "  [0.92254162]\n",
      "  [0.92451793]\n",
      "  [0.92737889]\n",
      "  [0.92939103]\n",
      "  [0.9305883 ]\n",
      "  [0.93203449]]]\n",
      "ejemplar: [0.91750652 0.92045736 0.92254162 0.92451793 0.92737889 0.92939103\n",
      " 0.9305883  0.93203449]\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.9332101]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[0.91750652 0.92045736 0.92254162 0.92451793 0.92737889 0.92939103\n",
      "  0.9305883  0.93203449]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.020176466554403305\n",
      "Predicción post entrenamiento : [[0.9321601]]\n",
      "PERDIDAAAA despues: 0.019879277795553207\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "[[[0.92045736]\n",
      "  [0.92254162]\n",
      "  [0.92451793]\n",
      "  [0.92737889]\n",
      "  [0.92939103]\n",
      "  [0.9305883 ]\n",
      "  [0.93203449]\n",
      "  [0.93321007]]]\n",
      "ejemplar: [0.92045736 0.92254162 0.92451793 0.92737889 0.92939103 0.9305883\n",
      " 0.93203449 0.93321007]\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.93429136]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[0.92045736 0.92254162 0.92451793 0.92737889 0.92939103 0.9305883\n",
      "  0.93203449 0.93321007]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.030183298513293266\n",
      "Predicción post entrenamiento : [[0.9325128]]\n",
      "PERDIDAAAA despues: 0.029568476602435112\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "[[[0.92254162]\n",
      "  [0.92451793]\n",
      "  [0.92737889]\n",
      "  [0.92939103]\n",
      "  [0.9305883 ]\n",
      "  [0.93203449]\n",
      "  [0.93321007]\n",
      "  [0.93429136]]]\n",
      "ejemplar: [0.92254162 0.92451793 0.92737889 0.92939103 0.9305883  0.93203449\n",
      " 0.93321007 0.93429136]\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.9343814]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[0.92254162 0.92451793 0.92737889 0.92939103 0.9305883  0.93203449\n",
      "  0.93321007 0.93429136]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02039976604282856\n",
      "Predicción post entrenamiento : [[0.9326166]]\n",
      "PERDIDAAAA despues: 0.01989874616265297\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "[[[0.92451793]\n",
      "  [0.92737889]\n",
      "  [0.92939103]\n",
      "  [0.9305883 ]\n",
      "  [0.93203449]\n",
      "  [0.93321007]\n",
      "  [0.93429136]\n",
      "  [0.93438143]]]\n",
      "ejemplar: [0.92451793 0.92737889 0.92939103 0.9305883  0.93203449 0.93321007\n",
      " 0.93429136 0.93438143]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9344065]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[0.92451793 0.92737889 0.92939103 0.9305883  0.93203449 0.93321007\n",
      "  0.93429136 0.93438143]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.027460545301437378\n",
      "Predicción post entrenamiento : [[0.9334419]]\n",
      "PERDIDAAAA despues: 0.027141770347952843\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "[[[0.92737889]\n",
      "  [0.92939103]\n",
      "  [0.9305883 ]\n",
      "  [0.93203449]\n",
      "  [0.93321007]\n",
      "  [0.93429136]\n",
      "  [0.93438143]\n",
      "  [0.93440652]]]\n",
      "ejemplar: [0.92737889 0.92939103 0.9305883  0.93203449 0.93321007 0.93429136\n",
      " 0.93438143 0.93440652]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9351277]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[0.92737889 0.92939103 0.9305883  0.93203449 0.93321007 0.93429136\n",
      "  0.93438143 0.93440652]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.027700074017047882\n",
      "Predicción post entrenamiento : [[0.9333292]]\n",
      "PERDIDAAAA despues: 0.027104664593935013\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "[[[0.92939103]\n",
      "  [0.9305883 ]\n",
      "  [0.93203449]\n",
      "  [0.93321007]\n",
      "  [0.93429136]\n",
      "  [0.93438143]\n",
      "  [0.93440652]\n",
      "  [0.93512768]]]\n",
      "ejemplar: [0.92939103 0.9305883  0.93203449 0.93321007 0.93429136 0.93438143\n",
      " 0.93440652 0.93512768]\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.9345802]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[0.92939103 0.9305883  0.93203449 0.93321007 0.93429136 0.93438143\n",
      "  0.93440652 0.93512768]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0184050090610981\n",
      "Predicción post entrenamiento : [[0.93406755]]\n",
      "PERDIDAAAA despues: 0.01826617121696472\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "[[[0.9305883 ]\n",
      "  [0.93203449]\n",
      "  [0.93321007]\n",
      "  [0.93429136]\n",
      "  [0.93438143]\n",
      "  [0.93440652]\n",
      "  [0.93512768]\n",
      "  [0.93458021]]]\n",
      "ejemplar: [0.9305883  0.93203449 0.93321007 0.93429136 0.93438143 0.93440652\n",
      " 0.93512768 0.93458021]\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.93503046]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[0.9305883  0.93203449 0.93321007 0.93429136 0.93438143 0.93440652\n",
      "  0.93512768 0.93458021]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.021032704040408134\n",
      "Predicción post entrenamiento : [[0.93391854]]\n",
      "PERDIDAAAA despues: 0.020711423829197884\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "[[[0.93203449]\n",
      "  [0.93321007]\n",
      "  [0.93429136]\n",
      "  [0.93438143]\n",
      "  [0.93440652]\n",
      "  [0.93512768]\n",
      "  [0.93458021]\n",
      "  [0.93503046]]]\n",
      "ejemplar: [0.93203449 0.93321007 0.93429136 0.93438143 0.93440652 0.93512768\n",
      " 0.93458021 0.93503046]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.93475974]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[0.93203449 0.93321007 0.93429136 0.93438143 0.93440652 0.93512768\n",
      "  0.93458021 0.93503046]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03048141486942768\n",
      "Predicción post entrenamiento : [[0.93409806]]\n",
      "PERDIDAAAA despues: 0.03025081194937229\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "[[[0.93321007]\n",
      "  [0.93429136]\n",
      "  [0.93438143]\n",
      "  [0.93440652]\n",
      "  [0.93512768]\n",
      "  [0.93458021]\n",
      "  [0.93503046]\n",
      "  [0.93475974]]]\n",
      "ejemplar: [0.93321007 0.93429136 0.93438143 0.93440652 0.93512768 0.93458021\n",
      " 0.93503046 0.93475974]\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.93469065]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[0.93321007 0.93429136 0.93438143 0.93440652 0.93512768 0.93458021\n",
      "  0.93503046 0.93475974]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06214918568730354\n",
      "Predicción post entrenamiento : [[0.93190897]]\n",
      "PERDIDAAAA despues: 0.06076998636126518\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "[[[0.93429136]\n",
      "  [0.93438143]\n",
      "  [0.93440652]\n",
      "  [0.93512768]\n",
      "  [0.93458021]\n",
      "  [0.93503046]\n",
      "  [0.93475974]\n",
      "  [0.93469065]]]\n",
      "ejemplar: [0.93429136 0.93438143 0.93440652 0.93512768 0.93458021 0.93503046\n",
      " 0.93475974 0.93469065]\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.9322694]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[0.93429136 0.93438143 0.93440652 0.93512768 0.93458021 0.93503046\n",
      "  0.93475974 0.93469065]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10697977244853973\n",
      "Predicción post entrenamiento : [[0.93007284]]\n",
      "PERDIDAAAA despues: 0.1055477112531662\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "[[[0.93438143]\n",
      "  [0.93440652]\n",
      "  [0.93512768]\n",
      "  [0.93458021]\n",
      "  [0.93503046]\n",
      "  [0.93475974]\n",
      "  [0.93469065]\n",
      "  [0.93226939]]]\n",
      "ejemplar: [0.93438143 0.93440652 0.93512768 0.93458021 0.93503046 0.93475974\n",
      " 0.93469065 0.93226939]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.930162]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[0.93438143 0.93440652 0.93512768 0.93458021 0.93503046 0.93475974\n",
      "  0.93469065 0.93226939]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07038591057062149\n",
      "Predicción post entrenamiento : [[0.9290615]]\n",
      "PERDIDAAAA despues: 0.06980317085981369\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "[[[0.93440652]\n",
      "  [0.93512768]\n",
      "  [0.93458021]\n",
      "  [0.93503046]\n",
      "  [0.93475974]\n",
      "  [0.93469065]\n",
      "  [0.93226939]\n",
      "  [0.93016201]]]\n",
      "ejemplar: [0.93440652 0.93512768 0.93458021 0.93503046 0.93475974 0.93469065\n",
      " 0.93226939 0.93016201]\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.9290978]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[0.93440652 0.93512768 0.93458021 0.93503046 0.93475974 0.93469065\n",
      "  0.93226939 0.93016201]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.048943858593702316\n",
      "Predicción post entrenamiento : [[0.9289714]]\n",
      "PERDIDAAAA despues: 0.048887964338064194\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "[[[0.93512768]\n",
      "  [0.93458021]\n",
      "  [0.93503046]\n",
      "  [0.93475974]\n",
      "  [0.93469065]\n",
      "  [0.93226939]\n",
      "  [0.93016201]\n",
      "  [0.92909777]]]\n",
      "ejemplar: [0.93512768 0.93458021 0.93503046 0.93475974 0.93469065 0.93226939\n",
      " 0.93016201 0.92909777]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9289196]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[0.93512768 0.93458021 0.93503046 0.93475974 0.93469065 0.93226939\n",
      "  0.93016201 0.92909777]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06972823292016983\n",
      "Predicción post entrenamiento : [[0.9275272]]\n",
      "PERDIDAAAA despues: 0.06899479776620865\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "[[[0.93458021]\n",
      "  [0.93503046]\n",
      "  [0.93475974]\n",
      "  [0.93469065]\n",
      "  [0.93226939]\n",
      "  [0.93016201]\n",
      "  [0.92909777]\n",
      "  [0.92891961]]]\n",
      "ejemplar: [0.93458021 0.93503046 0.93475974 0.93469065 0.93226939 0.93016201\n",
      " 0.92909777 0.92891961]\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.9271218]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[0.93458021 0.93503046 0.93475974 0.93469065 0.93226939 0.93016201\n",
      "  0.92909777 0.92891961]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.046556539833545685\n",
      "Predicción post entrenamiento : [[0.92468023]]\n",
      "PERDIDAAAA despues: 0.04550886154174805\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "[[[0.93503046]\n",
      "  [0.93475974]\n",
      "  [0.93469065]\n",
      "  [0.93226939]\n",
      "  [0.93016201]\n",
      "  [0.92909777]\n",
      "  [0.92891961]\n",
      "  [0.92712182]]]\n",
      "ejemplar: [0.93503046 0.93475974 0.93469065 0.93226939 0.93016201 0.92909777\n",
      " 0.92891961 0.92712182]\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.92421186]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[0.93503046 0.93475974 0.93469065 0.93226939 0.93016201 0.92909777\n",
      "  0.92891961 0.92712182]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06098676100373268\n",
      "Predicción post entrenamiento : [[0.92311144]]\n",
      "PERDIDAAAA despues: 0.060444463044404984\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "[[[0.93475974]\n",
      "  [0.93469065]\n",
      "  [0.93226939]\n",
      "  [0.93016201]\n",
      "  [0.92909777]\n",
      "  [0.92891961]\n",
      "  [0.92712182]\n",
      "  [0.92421186]]]\n",
      "ejemplar: [0.93475974 0.93469065 0.93226939 0.93016201 0.92909777 0.92891961\n",
      " 0.92712182 0.92421186]\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.92223084]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[0.93475974 0.93469065 0.93226939 0.93016201 0.92909777 0.92891961\n",
      "  0.92712182 0.92421186]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.025639411062002182\n",
      "Predicción post entrenamiento : [[0.9195312]]\n",
      "PERDIDAAAA despues: 0.024782156571745872\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "[[[0.93469065]\n",
      "  [0.93226939]\n",
      "  [0.93016201]\n",
      "  [0.92909777]\n",
      "  [0.92891961]\n",
      "  [0.92712182]\n",
      "  [0.92421186]\n",
      "  [0.92223084]]]\n",
      "ejemplar: [0.93469065 0.93226939 0.93016201 0.92909777 0.92891961 0.92712182\n",
      " 0.92421186 0.92223084]\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.91836005]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[0.93469065 0.93226939 0.93016201 0.92909777 0.92891961 0.92712182\n",
      "  0.92421186 0.92223084]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012389585375785828\n",
      "Predicción post entrenamiento : [[0.9171463]]\n",
      "PERDIDAAAA despues: 0.012120861560106277\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "[[[0.93226939]\n",
      "  [0.93016201]\n",
      "  [0.92909777]\n",
      "  [0.92891961]\n",
      "  [0.92712182]\n",
      "  [0.92421186]\n",
      "  [0.92223084]\n",
      "  [0.91836005]]]\n",
      "ejemplar: [0.93226939 0.93016201 0.92909777 0.92891961 0.92712182 0.92421186\n",
      " 0.92223084 0.91836005]\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.91554636]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[0.93226939 0.93016201 0.92909777 0.92891961 0.92712182 0.92421186\n",
      "  0.92223084 0.91836005]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010071814060211182\n",
      "Predicción post entrenamiento : [[0.9147528]]\n",
      "PERDIDAAAA despues: 0.009913159534335136\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "[[[0.93016201]\n",
      "  [0.92909777]\n",
      "  [0.92891961]\n",
      "  [0.92712182]\n",
      "  [0.92421186]\n",
      "  [0.92223084]\n",
      "  [0.91836005]\n",
      "  [0.91554636]]]\n",
      "ejemplar: [0.93016201 0.92909777 0.92891961 0.92712182 0.92421186 0.92223084\n",
      " 0.91836005 0.91554636]\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.913331]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[0.93016201 0.92909777 0.92891961 0.92712182 0.92421186 0.92223084\n",
      "  0.91836005 0.91554636]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.031166801927611e-05\n",
      "Predicción post entrenamiento : [[0.9128275]]\n",
      "PERDIDAAAA despues: 4.3422714952612296e-05\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "[[[0.92909777]\n",
      "  [0.92891961]\n",
      "  [0.92712182]\n",
      "  [0.92421186]\n",
      "  [0.92223084]\n",
      "  [0.91836005]\n",
      "  [0.91554636]\n",
      "  [0.91333097]]]\n",
      "ejemplar: [0.92909777 0.92891961 0.92712182 0.92421186 0.92223084 0.91836005\n",
      " 0.91554636 0.91333097]\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.9114762]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[0.92909777 0.92891961 0.92712182 0.92421186 0.92223084 0.91836005\n",
      "  0.91554636 0.91333097]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0023260689340531826\n",
      "Predicción post entrenamiento : [[0.91166496]]\n",
      "PERDIDAAAA despues: 0.0023078962694853544\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "[[[0.92891961]\n",
      "  [0.92712182]\n",
      "  [0.92421186]\n",
      "  [0.92223084]\n",
      "  [0.91836005]\n",
      "  [0.91554636]\n",
      "  [0.91333097]\n",
      "  [0.91147619]]]\n",
      "ejemplar: [0.92891961 0.92712182 0.92421186 0.92223084 0.91836005 0.91554636\n",
      " 0.91333097 0.91147619]\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.9100405]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[0.92891961 0.92712182 0.92421186 0.92223084 0.91836005 0.91554636\n",
      "  0.91333097 0.91147619]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029500513337552547\n",
      "Predicción post entrenamiento : [[0.9103833]]\n",
      "PERDIDAAAA despues: 0.0029129323083907366\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "[[[0.92712182]\n",
      "  [0.92421186]\n",
      "  [0.92223084]\n",
      "  [0.91836005]\n",
      "  [0.91554636]\n",
      "  [0.91333097]\n",
      "  [0.91147619]\n",
      "  [0.9100405 ]]]\n",
      "ejemplar: [0.92712182 0.92421186 0.92223084 0.91836005 0.91554636 0.91333097\n",
      " 0.91147619 0.9100405 ]\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.9081552]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[0.92712182 0.92421186 0.92223084 0.91836005 0.91554636 0.91333097\n",
      "  0.91147619 0.9100405 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004051080613862723\n",
      "Predicción post entrenamiento : [[0.90824646]]\n",
      "PERDIDAAAA despues: 0.00040878981235437095\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "[[[0.92421186]\n",
      "  [0.92223084]\n",
      "  [0.91836005]\n",
      "  [0.91554636]\n",
      "  [0.91333097]\n",
      "  [0.91147619]\n",
      "  [0.9100405 ]\n",
      "  [0.9081552 ]]]\n",
      "ejemplar: [0.92421186 0.92223084 0.91836005 0.91554636 0.91333097 0.91147619\n",
      " 0.9100405  0.9081552 ]\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.90581363]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[0.92421186 0.92223084 0.91836005 0.91554636 0.91333097 0.91147619\n",
      "  0.9100405  0.9081552 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00017256465798709542\n",
      "Predicción post entrenamiento : [[0.9060214]]\n",
      "PERDIDAAAA despues: 0.00017806683899834752\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "[[[0.92223084]\n",
      "  [0.91836005]\n",
      "  [0.91554636]\n",
      "  [0.91333097]\n",
      "  [0.91147619]\n",
      "  [0.9100405 ]\n",
      "  [0.9081552 ]\n",
      "  [0.90581363]]]\n",
      "ejemplar: [0.92223084 0.91836005 0.91554636 0.91333097 0.91147619 0.9100405\n",
      " 0.9081552  0.90581363]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.9037075]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[0.92223084 0.91836005 0.91554636 0.91333097 0.91147619 0.9100405\n",
      "  0.9081552  0.90581363]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000810275028925389\n",
      "Predicción post entrenamiento : [[0.90350574]]\n",
      "PERDIDAAAA despues: 0.0007988293073140085\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "[[[0.91836005]\n",
      "  [0.91554636]\n",
      "  [0.91333097]\n",
      "  [0.91147619]\n",
      "  [0.9100405 ]\n",
      "  [0.9081552 ]\n",
      "  [0.90581363]\n",
      "  [0.9037075 ]]]\n",
      "ejemplar: [0.91836005 0.91554636 0.91333097 0.91147619 0.9100405  0.9081552\n",
      " 0.90581363 0.9037075 ]\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.90107787]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[0.91836005 0.91554636 0.91333097 0.91147619 0.9100405  0.9081552\n",
      "  0.90581363 0.9037075 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0025245468132197857\n",
      "Predicción post entrenamiento : [[0.900268]]\n",
      "PERDIDAAAA despues: 0.002443821169435978\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "[[[0.91554636]\n",
      "  [0.91333097]\n",
      "  [0.91147619]\n",
      "  [0.9100405 ]\n",
      "  [0.9081552 ]\n",
      "  [0.90581363]\n",
      "  [0.9037075 ]\n",
      "  [0.90107787]]]\n",
      "ejemplar: [0.91554636 0.91333097 0.91147619 0.9100405  0.9081552  0.90581363\n",
      " 0.9037075  0.90107787]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.8982941]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[0.91554636 0.91333097 0.91147619 0.9100405  0.9081552  0.90581363\n",
      "  0.9037075  0.90107787]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0024401922710239887\n",
      "Predicción post entrenamiento : [[0.8973757]]\n",
      "PERDIDAAAA despues: 0.002350302180275321\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "[[[0.91333097]\n",
      "  [0.91147619]\n",
      "  [0.9100405 ]\n",
      "  [0.9081552 ]\n",
      "  [0.90581363]\n",
      "  [0.9037075 ]\n",
      "  [0.90107787]\n",
      "  [0.89829409]]]\n",
      "ejemplar: [0.91333097 0.91147619 0.9100405  0.9081552  0.90581363 0.9037075\n",
      " 0.90107787 0.89829409]\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.89561105]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[0.91333097 0.91147619 0.9100405  0.9081552  0.90581363 0.9037075\n",
      "  0.90107787 0.89829409]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004463123623281717\n",
      "Predicción post entrenamiento : [[0.89642936]]\n",
      "PERDIDAAAA despues: 0.004354455973953009\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "[[[0.91147619]\n",
      "  [0.9100405 ]\n",
      "  [0.9081552 ]\n",
      "  [0.90581363]\n",
      "  [0.9037075 ]\n",
      "  [0.90107787]\n",
      "  [0.89829409]\n",
      "  [0.89561105]]]\n",
      "ejemplar: [0.91147619 0.9100405  0.9081552  0.90581363 0.9037075  0.90107787\n",
      " 0.89829409 0.89561105]\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.89470994]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[0.91147619 0.9100405  0.9081552  0.90581363 0.9037075  0.90107787\n",
      "  0.89829409 0.89561105]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005348286125808954\n",
      "Predicción post entrenamiento : [[0.8941849]]\n",
      "PERDIDAAAA despues: 0.00542535912245512\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "[[[0.9100405 ]\n",
      "  [0.9081552 ]\n",
      "  [0.90581363]\n",
      "  [0.9037075 ]\n",
      "  [0.90107787]\n",
      "  [0.89829409]\n",
      "  [0.89561105]\n",
      "  [0.89470994]]]\n",
      "ejemplar: [0.9100405  0.9081552  0.90581363 0.9037075  0.90107787 0.89829409\n",
      " 0.89561105 0.89470994]\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.8923969]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[0.9100405  0.9081552  0.90581363 0.9037075  0.90107787 0.89829409\n",
      "  0.89561105 0.89470994]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0023351849522441626\n",
      "Predicción post entrenamiento : [[0.89304364]]\n",
      "PERDIDAAAA despues: 0.002273100195452571\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "[[[0.9081552 ]\n",
      "  [0.90581363]\n",
      "  [0.9037075 ]\n",
      "  [0.90107787]\n",
      "  [0.89829409]\n",
      "  [0.89561105]\n",
      "  [0.89470994]\n",
      "  [0.89239693]]]\n",
      "ejemplar: [0.9081552  0.90581363 0.9037075  0.90107787 0.89829409 0.89561105\n",
      " 0.89470994 0.89239693]\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.8910417]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[0.9081552  0.90581363 0.9037075  0.90107787 0.89829409 0.89561105\n",
      "  0.89470994 0.89239693]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006634032353758812\n",
      "Predicción post entrenamiento : [[0.8914155]]\n",
      "PERDIDAAAA despues: 0.006573283113539219\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "[[[0.90581363]\n",
      "  [0.9037075 ]\n",
      "  [0.90107787]\n",
      "  [0.89829409]\n",
      "  [0.89561105]\n",
      "  [0.89470994]\n",
      "  [0.89239693]\n",
      "  [0.8910417 ]]]\n",
      "ejemplar: [0.90581363 0.9037075  0.90107787 0.89829409 0.89561105 0.89470994\n",
      " 0.89239693 0.8910417 ]\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.8893071]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[0.90581363 0.9037075  0.90107787 0.89829409 0.89561105 0.89470994\n",
      "  0.89239693 0.8910417 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011576330289244652\n",
      "Predicción post entrenamiento : [[0.8890832]]\n",
      "PERDIDAAAA despues: 0.01162455603480339\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "[[[0.9037075 ]\n",
      "  [0.90107787]\n",
      "  [0.89829409]\n",
      "  [0.89561105]\n",
      "  [0.89470994]\n",
      "  [0.89239693]\n",
      "  [0.8910417 ]\n",
      "  [0.88930708]]]\n",
      "ejemplar: [0.9037075  0.90107787 0.89829409 0.89561105 0.89470994 0.89239693\n",
      " 0.8910417  0.88930708]\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.8870051]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[0.9037075  0.90107787 0.89829409 0.89561105 0.89470994 0.89239693\n",
      "  0.8910417  0.88930708]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004118638578802347\n",
      "Predicción post entrenamiento : [[0.88743407]]\n",
      "PERDIDAAAA despues: 0.004063762258738279\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "[[[0.90107787]\n",
      "  [0.89829409]\n",
      "  [0.89561105]\n",
      "  [0.89470994]\n",
      "  [0.89239693]\n",
      "  [0.8910417 ]\n",
      "  [0.88930708]\n",
      "  [0.88700509]]]\n",
      "ejemplar: [0.90107787 0.89829409 0.89561105 0.89470994 0.89239693 0.8910417\n",
      " 0.88930708 0.88700509]\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.8853397]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[0.90107787 0.89829409 0.89561105 0.89470994 0.89239693 0.8910417\n",
      "  0.88930708 0.88700509]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00010893370199482888\n",
      "Predicción post entrenamiento : [[0.8851814]]\n",
      "PERDIDAAAA despues: 0.00011226210335735232\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "[[[0.89829409]\n",
      "  [0.89561105]\n",
      "  [0.89470994]\n",
      "  [0.89239693]\n",
      "  [0.8910417 ]\n",
      "  [0.88930708]\n",
      "  [0.88700509]\n",
      "  [0.88533968]]]\n",
      "ejemplar: [0.89829409 0.89561105 0.89470994 0.89239693 0.8910417  0.88930708\n",
      " 0.88700509 0.88533968]\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.88324374]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[0.89829409 0.89561105 0.89470994 0.89239693 0.8910417  0.88930708\n",
      "  0.88700509 0.88533968]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.248806024203077e-06\n",
      "Predicción post entrenamiento : [[0.8833422]]\n",
      "PERDIDAAAA despues: 3.6134638321527746e-06\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "[[[0.89561105]\n",
      "  [0.89470994]\n",
      "  [0.89239693]\n",
      "  [0.8910417 ]\n",
      "  [0.88930708]\n",
      "  [0.88700509]\n",
      "  [0.88533968]\n",
      "  [0.88324374]]]\n",
      "ejemplar: [0.89561105 0.89470994 0.89239693 0.8910417  0.88930708 0.88700509\n",
      " 0.88533968 0.88324374]\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.8816441]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[0.89561105 0.89470994 0.89239693 0.8910417  0.88930708 0.88700509\n",
      "  0.88533968 0.88324374]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001256156130693853\n",
      "Predicción post entrenamiento : [[0.88212675]]\n",
      "PERDIDAAAA despues: 0.0012221788056194782\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "[[[0.89470994]\n",
      "  [0.89239693]\n",
      "  [0.8910417 ]\n",
      "  [0.88930708]\n",
      "  [0.88700509]\n",
      "  [0.88533968]\n",
      "  [0.88324374]\n",
      "  [0.88164413]]]\n",
      "ejemplar: [0.89470994 0.89239693 0.8910417  0.88930708 0.88700509 0.88533968\n",
      " 0.88324374 0.88164413]\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.8806766]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[0.89470994 0.89239693 0.8910417  0.88930708 0.88700509 0.88533968\n",
      "  0.88324374 0.88164413]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001530525041744113\n",
      "Predicción post entrenamiento : [[0.88076335]]\n",
      "PERDIDAAAA despues: 0.0015237468760460615\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "[[[0.89239693]\n",
      "  [0.8910417 ]\n",
      "  [0.88930708]\n",
      "  [0.88700509]\n",
      "  [0.88533968]\n",
      "  [0.88324374]\n",
      "  [0.88164413]\n",
      "  [0.88067663]]]\n",
      "ejemplar: [0.89239693 0.8910417  0.88930708 0.88700509 0.88533968 0.88324374\n",
      " 0.88164413 0.88067663]\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.87906986]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[0.89239693 0.8910417  0.88930708 0.88700509 0.88533968 0.88324374\n",
      "  0.88164413 0.88067663]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006818289868533611\n",
      "Predicción post entrenamiento : [[0.8799476]]\n",
      "PERDIDAAAA despues: 0.006674105767160654\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "[[[0.8910417 ]\n",
      "  [0.88930708]\n",
      "  [0.88700509]\n",
      "  [0.88533968]\n",
      "  [0.88324374]\n",
      "  [0.88164413]\n",
      "  [0.88067663]\n",
      "  [0.87906986]]]\n",
      "ejemplar: [0.8910417  0.88930708 0.88700509 0.88533968 0.88324374 0.88164413\n",
      " 0.88067663 0.87906986]\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.878399]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[0.8910417  0.88930708 0.88700509 0.88533968 0.88324374 0.88164413\n",
      "  0.88067663 0.87906986]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00806949008256197\n",
      "Predicción post entrenamiento : [[0.879103]]\n",
      "PERDIDAAAA despues: 0.007943506352603436\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "[[[0.88930708]\n",
      "  [0.88700509]\n",
      "  [0.88533968]\n",
      "  [0.88324374]\n",
      "  [0.88164413]\n",
      "  [0.88067663]\n",
      "  [0.87906986]\n",
      "  [0.87839901]]]\n",
      "ejemplar: [0.88930708 0.88700509 0.88533968 0.88324374 0.88164413 0.88067663\n",
      " 0.87906986 0.87839901]\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.8774507]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[0.88930708 0.88700509 0.88533968 0.88324374 0.88164413 0.88067663\n",
      "  0.87906986 0.87839901]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006450919434428215\n",
      "Predicción post entrenamiento : [[0.87782675]]\n",
      "PERDIDAAAA despues: 0.006390654947608709\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "[[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "ejemplar: [0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      " 0.03448276 0.04223169]\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.2296323]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      "  0.03448276 0.04223169]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03368184715509415\n",
      "Predicción post entrenamiento : [[0.1839393]]\n",
      "PERDIDAAAA despues: 0.018997972831130028\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "[[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.2296323 ]]]\n",
      "ejemplar: [0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      " 0.04223169 0.2296323 ]\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.16823483]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      "  0.04223169 0.2296323 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004097491968423128\n",
      "Predicción post entrenamiento : [[0.1549084]]\n",
      "PERDIDAAAA despues: 0.002568993018940091\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "[[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.2296323 ]\n",
      "  [0.16823483]]]\n",
      "ejemplar: [0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      " 0.2296323  0.16823483]\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.15865445]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      "  0.2296323  0.16823483]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.9808276192634366e-05\n",
      "Predicción post entrenamiento : [[0.15984078]]\n",
      "PERDIDAAAA despues: 3.1775489333085716e-05\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "[[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.2296323 ]\n",
      "  [0.16823483]\n",
      "  [0.15865445]]]\n",
      "ejemplar: [0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.2296323\n",
      " 0.16823483 0.15865445]\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.17068475]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.2296323\n",
      "  0.16823483 0.15865445]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00022293989604804665\n",
      "Predicción post entrenamiento : [[0.16722335]]\n",
      "PERDIDAAAA despues: 0.00013155554188415408\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "[[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.2296323 ]\n",
      "  [0.16823483]\n",
      "  [0.15865445]\n",
      "  [0.17068475]]]\n",
      "ejemplar: [0.05656722 0.02595893 0.03448276 0.04223169 0.2296323  0.16823483\n",
      " 0.15865445 0.17068475]\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.17877519]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[0.05656722 0.02595893 0.03448276 0.04223169 0.2296323  0.16823483\n",
      "  0.15865445 0.17068475]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002834758022800088\n",
      "Predicción post entrenamiento : [[0.17208946]]\n",
      "PERDIDAAAA despues: 0.0021675273310393095\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "[[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.2296323 ]\n",
      "  [0.16823483]\n",
      "  [0.15865445]\n",
      "  [0.17068475]\n",
      "  [0.17877519]]]\n",
      "ejemplar: [0.02595893 0.03448276 0.04223169 0.2296323  0.16823483 0.15865445\n",
      " 0.17068475 0.17877519]\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.1803069]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[0.02595893 0.03448276 0.04223169 0.2296323  0.16823483 0.15865445\n",
      "  0.17068475 0.17877519]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00119902438018471\n",
      "Predicción post entrenamiento : [[0.17652224]]\n",
      "PERDIDAAAA despues: 0.0009512458927929401\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "[[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.2296323 ]\n",
      "  [0.16823483]\n",
      "  [0.15865445]\n",
      "  [0.17068475]\n",
      "  [0.17877519]\n",
      "  [0.1803069 ]]]\n",
      "ejemplar: [0.03448276 0.04223169 0.2296323  0.16823483 0.15865445 0.17068475\n",
      " 0.17877519 0.1803069 ]\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.1950325]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[0.03448276 0.04223169 0.2296323  0.16823483 0.15865445 0.17068475\n",
      "  0.17877519 0.1803069 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002359788166359067\n",
      "Predicción post entrenamiento : [[0.19273926]]\n",
      "PERDIDAAAA despues: 0.0021422463469207287\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "[[[0.04223169]\n",
      "  [0.2296323 ]\n",
      "  [0.16823483]\n",
      "  [0.15865445]\n",
      "  [0.17068475]\n",
      "  [0.17877519]\n",
      "  [0.1803069 ]\n",
      "  [0.19503251]]]\n",
      "ejemplar: [0.04223169 0.2296323  0.16823483 0.15865445 0.17068475 0.17877519\n",
      " 0.1803069  0.19503251]\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.21490957]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[0.04223169 0.2296323  0.16823483 0.15865445 0.17068475 0.17877519\n",
      "  0.1803069  0.19503251]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00035575739457271993\n",
      "Predicción post entrenamiento : [[0.21444225]]\n",
      "PERDIDAAAA despues: 0.0003383472212590277\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "[[[0.2296323 ]\n",
      "  [0.16823483]\n",
      "  [0.15865445]\n",
      "  [0.17068475]\n",
      "  [0.17877519]\n",
      "  [0.1803069 ]\n",
      "  [0.19503251]\n",
      "  [0.21490957]]]\n",
      "ejemplar: [0.2296323  0.16823483 0.15865445 0.17068475 0.17877519 0.1803069\n",
      " 0.19503251 0.21490957]\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.24054573]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[0.2296323  0.16823483 0.15865445 0.17068475 0.17877519 0.1803069\n",
      "  0.19503251 0.21490957]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00010029895202023908\n",
      "Predicción post entrenamiento : [[0.24328521]]\n",
      "PERDIDAAAA despues: 0.00016267498722299933\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "[[[0.16823483]\n",
      "  [0.15865445]\n",
      "  [0.17068475]\n",
      "  [0.17877519]\n",
      "  [0.1803069 ]\n",
      "  [0.19503251]\n",
      "  [0.21490957]\n",
      "  [0.24054573]]]\n",
      "ejemplar: [0.16823483 0.15865445 0.17068475 0.17877519 0.1803069  0.19503251\n",
      " 0.21490957 0.24054573]\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.23343779]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[0.16823483 0.15865445 0.17068475 0.17877519 0.1803069  0.19503251\n",
      "  0.21490957 0.24054573]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006245726835913956\n",
      "Predicción post entrenamiento : [[0.2319453]]\n",
      "PERDIDAAAA despues: 0.000552201468963176\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "[[[0.15865445]\n",
      "  [0.17068475]\n",
      "  [0.17877519]\n",
      "  [0.1803069 ]\n",
      "  [0.19503251]\n",
      "  [0.21490957]\n",
      "  [0.24054573]\n",
      "  [0.23343779]]]\n",
      "ejemplar: [0.15865445 0.17068475 0.17877519 0.1803069  0.19503251 0.21490957\n",
      " 0.24054573 0.23343779]\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.23486021]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[0.15865445 0.17068475 0.17877519 0.1803069  0.19503251 0.21490957\n",
      "  0.24054573 0.23343779]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000525640556588769\n",
      "Predicción post entrenamiento : [[0.23239699]]\n",
      "PERDIDAAAA despues: 0.0004187601734884083\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "[[[0.17068475]\n",
      "  [0.17877519]\n",
      "  [0.1803069 ]\n",
      "  [0.19503251]\n",
      "  [0.21490957]\n",
      "  [0.24054573]\n",
      "  [0.23343779]\n",
      "  [0.23486021]]]\n",
      "ejemplar: [0.17068475 0.17877519 0.1803069  0.19503251 0.21490957 0.24054573\n",
      " 0.23343779 0.23486021]\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.23913033]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[0.17068475 0.17877519 0.1803069  0.19503251 0.21490957 0.24054573\n",
      "  0.23343779 0.23486021]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010141887469217181\n",
      "Predicción post entrenamiento : [[0.23944537]]\n",
      "PERDIDAAAA despues: 0.0010343537433072925\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "[[[0.17877519]\n",
      "  [0.1803069 ]\n",
      "  [0.19503251]\n",
      "  [0.21490957]\n",
      "  [0.24054573]\n",
      "  [0.23343779]\n",
      "  [0.23486021]\n",
      "  [0.23913033]]]\n",
      "ejemplar: [0.17877519 0.1803069  0.19503251 0.21490957 0.24054573 0.23343779\n",
      " 0.23486021 0.23913033]\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.24588762]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[0.17877519 0.1803069  0.19503251 0.21490957 0.24054573 0.23343779\n",
      "  0.23486021 0.23913033]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002802553353831172\n",
      "Predicción post entrenamiento : [[0.24229282]]\n",
      "PERDIDAAAA despues: 0.0024348644074052572\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "[[[0.1803069 ]\n",
      "  [0.19503251]\n",
      "  [0.21490957]\n",
      "  [0.24054573]\n",
      "  [0.23343779]\n",
      "  [0.23486021]\n",
      "  [0.23913033]\n",
      "  [0.24588762]]]\n",
      "ejemplar: [0.1803069  0.19503251 0.21490957 0.24054573 0.23343779 0.23486021\n",
      " 0.23913033 0.24588762]\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.24914145]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[0.1803069  0.19503251 0.21490957 0.24054573 0.23343779 0.23486021\n",
      "  0.23913033 0.24588762]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0027372268959879875\n",
      "Predicción post entrenamiento : [[0.24620657]]\n",
      "PERDIDAAAA despues: 0.002438742434605956\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "[[[0.19503251]\n",
      "  [0.21490957]\n",
      "  [0.24054573]\n",
      "  [0.23343779]\n",
      "  [0.23486021]\n",
      "  [0.23913033]\n",
      "  [0.24588762]\n",
      "  [0.24914145]]]\n",
      "ejemplar: [0.19503251 0.21490957 0.24054573 0.23343779 0.23486021 0.23913033\n",
      " 0.24588762 0.24914145]\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.25484848]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[0.19503251 0.21490957 0.24054573 0.23343779 0.23486021 0.23913033\n",
      "  0.24588762 0.24914145]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016475834418088198\n",
      "Predicción post entrenamiento : [[0.25411528]]\n",
      "PERDIDAAAA despues: 0.0015885994071140885\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "[[[0.21490957]\n",
      "  [0.24054573]\n",
      "  [0.23343779]\n",
      "  [0.23486021]\n",
      "  [0.23913033]\n",
      "  [0.24588762]\n",
      "  [0.24914145]\n",
      "  [0.25484848]]]\n",
      "ejemplar: [0.21490957 0.24054573 0.23343779 0.23486021 0.23913033 0.24588762\n",
      " 0.24914145 0.25484848]\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.261699]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[0.21490957 0.24054573 0.23343779 0.23486021 0.23913033 0.24588762\n",
      "  0.24914145 0.25484848]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006459968164563179\n",
      "Predicción post entrenamiento : [[0.2583884]]\n",
      "PERDIDAAAA despues: 0.005938757676631212\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "[[[0.24054573]\n",
      "  [0.23343779]\n",
      "  [0.23486021]\n",
      "  [0.23913033]\n",
      "  [0.24588762]\n",
      "  [0.24914145]\n",
      "  [0.25484848]\n",
      "  [0.26169899]]]\n",
      "ejemplar: [0.24054573 0.23343779 0.23486021 0.23913033 0.24588762 0.24914145\n",
      " 0.25484848 0.26169899]\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.26334172]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[0.24054573 0.23343779 0.23486021 0.23913033 0.24588762 0.24914145\n",
      "  0.25484848 0.26169899]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0077820271253585815\n",
      "Predicción post entrenamiento : [[0.26116034]]\n",
      "PERDIDAAAA despues: 0.007401920855045319\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "[[[0.23343779]\n",
      "  [0.23486021]\n",
      "  [0.23913033]\n",
      "  [0.24588762]\n",
      "  [0.24914145]\n",
      "  [0.25484848]\n",
      "  [0.26169899]\n",
      "  [0.26334172]]]\n",
      "ejemplar: [0.23343779 0.23486021 0.23913033 0.24588762 0.24914145 0.25484848\n",
      " 0.26169899 0.26334172]\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.2616204]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[0.23343779 0.23486021 0.23913033 0.24588762 0.24914145 0.25484848\n",
      "  0.26169899 0.26334172]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012908538803458214\n",
      "Predicción post entrenamiento : [[0.25791588]]\n",
      "PERDIDAAAA despues: 0.01208047941327095\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "[[[0.23486021]\n",
      "  [0.23913033]\n",
      "  [0.24588762]\n",
      "  [0.24914145]\n",
      "  [0.25484848]\n",
      "  [0.26169899]\n",
      "  [0.26334172]\n",
      "  [0.2616204 ]]]\n",
      "ejemplar: [0.23486021 0.23913033 0.24588762 0.24914145 0.25484848 0.26169899\n",
      " 0.26334172 0.2616204 ]\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.26053274]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[0.23486021 0.23913033 0.24588762 0.24914145 0.25484848 0.26169899\n",
      "  0.26334172 0.2616204 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010338736698031425\n",
      "Predicción post entrenamiento : [[0.25896224]]\n",
      "PERDIDAAAA despues: 0.010021829046308994\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "[[[0.23913033]\n",
      "  [0.24588762]\n",
      "  [0.24914145]\n",
      "  [0.25484848]\n",
      "  [0.26169899]\n",
      "  [0.26334172]\n",
      "  [0.2616204 ]\n",
      "  [0.26053274]]]\n",
      "ejemplar: [0.23913033 0.24588762 0.24914145 0.25484848 0.26169899 0.26334172\n",
      " 0.2616204  0.26053274]\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.2621539]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[0.23913033 0.24588762 0.24914145 0.25484848 0.26169899 0.26334172\n",
      "  0.2616204  0.26053274]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004897245671600103\n",
      "Predicción post entrenamiento : [[0.26055902]]\n",
      "PERDIDAAAA despues: 0.004676570184528828\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "[[[0.24588762]\n",
      "  [0.24914145]\n",
      "  [0.25484848]\n",
      "  [0.26169899]\n",
      "  [0.26334172]\n",
      "  [0.2616204 ]\n",
      "  [0.26053274]\n",
      "  [0.26215389]]]\n",
      "ejemplar: [0.24588762 0.24914145 0.25484848 0.26169899 0.26334172 0.2616204\n",
      " 0.26053274 0.26215389]\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.26369143]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[0.24588762 0.24914145 0.25484848 0.26169899 0.26334172 0.2616204\n",
      "  0.26053274 0.26215389]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006039930507540703\n",
      "Predicción post entrenamiento : [[0.26083997]]\n",
      "PERDIDAAAA despues: 0.005604848265647888\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "[[[0.24914145]\n",
      "  [0.25484848]\n",
      "  [0.26169899]\n",
      "  [0.26334172]\n",
      "  [0.2616204 ]\n",
      "  [0.26053274]\n",
      "  [0.26215389]\n",
      "  [0.26369143]]]\n",
      "ejemplar: [0.24914145 0.25484848 0.26169899 0.26334172 0.2616204  0.26053274\n",
      " 0.26215389 0.26369143]\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.26323473]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[0.24914145 0.25484848 0.26169899 0.26334172 0.2616204  0.26053274\n",
      "  0.26215389 0.26369143]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.3809039046464022e-05\n",
      "Predicción post entrenamiento : [[0.2644407]]\n",
      "PERDIDAAAA despues: 6.300605036813067e-06\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "[[[0.25484848]\n",
      "  [0.26169899]\n",
      "  [0.26334172]\n",
      "  [0.2616204 ]\n",
      "  [0.26053274]\n",
      "  [0.26215389]\n",
      "  [0.26369143]\n",
      "  [0.26323473]]]\n",
      "ejemplar: [0.25484848 0.26169899 0.26334172 0.2616204  0.26053274 0.26215389\n",
      " 0.26369143 0.26323473]\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.26667976]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[0.25484848 0.26169899 0.26334172 0.2616204  0.26053274 0.26215389\n",
      "  0.26369143 0.26323473]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000667835702188313\n",
      "Predicción post entrenamiento : [[0.2658965]]\n",
      "PERDIDAAAA despues: 0.0007089322898536921\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "[[[0.26169899]\n",
      "  [0.26334172]\n",
      "  [0.2616204 ]\n",
      "  [0.26053274]\n",
      "  [0.26215389]\n",
      "  [0.26369143]\n",
      "  [0.26323473]\n",
      "  [0.26667976]]]\n",
      "ejemplar: [0.26169899 0.26334172 0.2616204  0.26053274 0.26215389 0.26369143\n",
      " 0.26323473 0.26667976]\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.26732495]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[0.26169899 0.26334172 0.2616204  0.26053274 0.26215389 0.26369143\n",
      "  0.26323473 0.26667976]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002538281725719571\n",
      "Predicción post entrenamiento : [[0.26895365]]\n",
      "PERDIDAAAA despues: 0.0023768222890794277\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "[[[0.26334172]\n",
      "  [0.2616204 ]\n",
      "  [0.26053274]\n",
      "  [0.26215389]\n",
      "  [0.26369143]\n",
      "  [0.26323473]\n",
      "  [0.26667976]\n",
      "  [0.26732495]]]\n",
      "ejemplar: [0.26334172 0.2616204  0.26053274 0.26215389 0.26369143 0.26323473\n",
      " 0.26667976 0.26732495]\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.26914048]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[0.26334172 0.2616204  0.26053274 0.26215389 0.26369143 0.26323473\n",
      "  0.26667976 0.26732495]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018947768257930875\n",
      "Predicción post entrenamiento : [[0.27027175]]\n",
      "PERDIDAAAA despues: 0.0017975707305595279\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "[[[0.2616204 ]\n",
      "  [0.26053274]\n",
      "  [0.26215389]\n",
      "  [0.26369143]\n",
      "  [0.26323473]\n",
      "  [0.26667976]\n",
      "  [0.26732495]\n",
      "  [0.26914048]]]\n",
      "ejemplar: [0.2616204  0.26053274 0.26215389 0.26369143 0.26323473 0.26667976\n",
      " 0.26732495 0.26914048]\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.27020934]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[0.2616204  0.26053274 0.26215389 0.26369143 0.26323473 0.26667976\n",
      "  0.26732495 0.26914048]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00035441521322354674\n",
      "Predicción post entrenamiento : [[0.27095148]]\n",
      "PERDIDAAAA despues: 0.00032702312455512583\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "[[[0.26053274]\n",
      "  [0.26215389]\n",
      "  [0.26369143]\n",
      "  [0.26323473]\n",
      "  [0.26667976]\n",
      "  [0.26732495]\n",
      "  [0.26914048]\n",
      "  [0.27020934]]]\n",
      "ejemplar: [0.26053274 0.26215389 0.26369143 0.26323473 0.26667976 0.26732495\n",
      " 0.26914048 0.27020934]\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.27140126]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[0.26053274 0.26215389 0.26369143 0.26323473 0.26667976 0.26732495\n",
      "  0.26914048 0.27020934]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00013075587048660964\n",
      "Predicción post entrenamiento : [[0.2722609]]\n",
      "PERDIDAAAA despues: 0.00011183496098965406\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "[[[0.26215389]\n",
      "  [0.26369143]\n",
      "  [0.26323473]\n",
      "  [0.26667976]\n",
      "  [0.26732495]\n",
      "  [0.26914048]\n",
      "  [0.27020934]\n",
      "  [0.27140126]]]\n",
      "ejemplar: [0.26215389 0.26369143 0.26323473 0.26667976 0.26732495 0.26914048\n",
      " 0.27020934 0.27140126]\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.27318862]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[0.26215389 0.26369143 0.26323473 0.26667976 0.26732495 0.26914048\n",
      "  0.27020934 0.27140126]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006920952000655234\n",
      "Predicción post entrenamiento : [[0.2735422]]\n",
      "PERDIDAAAA despues: 0.0006736167124472558\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "[[[0.26369143]\n",
      "  [0.26323473]\n",
      "  [0.26667976]\n",
      "  [0.26732495]\n",
      "  [0.26914048]\n",
      "  [0.27020934]\n",
      "  [0.27140126]\n",
      "  [0.27318862]]]\n",
      "ejemplar: [0.26369143 0.26323473 0.26667976 0.26732495 0.26914048 0.27020934\n",
      " 0.27140126 0.27318862]\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.27441707]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[0.26369143 0.26323473 0.26667976 0.26732495 0.26914048 0.27020934\n",
      "  0.27140126 0.27318862]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.0880117972410517e-06\n",
      "Predicción post entrenamiento : [[0.27419177]]\n",
      "PERDIDAAAA despues: 2.7899052383872913e-06\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "[[[0.26323473]\n",
      "  [0.26667976]\n",
      "  [0.26732495]\n",
      "  [0.26914048]\n",
      "  [0.27020934]\n",
      "  [0.27140126]\n",
      "  [0.27318862]\n",
      "  [0.27441707]]]\n",
      "ejemplar: [0.26323473 0.26667976 0.26732495 0.26914048 0.27020934 0.27140126\n",
      " 0.27318862 0.27441707]\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.27502596]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[0.26323473 0.26667976 0.26732495 0.26914048 0.27020934 0.27140126\n",
      "  0.27318862 0.27441707]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.0643646675134733e-07\n",
      "Predicción post entrenamiento : [[0.2747547]]\n",
      "PERDIDAAAA despues: 3.023381545119719e-09\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "[[[0.26667976]\n",
      "  [0.26732495]\n",
      "  [0.26914048]\n",
      "  [0.27020934]\n",
      "  [0.27140126]\n",
      "  [0.27318862]\n",
      "  [0.27441707]\n",
      "  [0.27502596]]]\n",
      "ejemplar: [0.26667976 0.26732495 0.26914048 0.27020934 0.27140126 0.27318862\n",
      " 0.27441707 0.27502596]\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.27599606]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[0.26667976 0.26732495 0.26914048 0.27020934 0.27140126 0.27318862\n",
      "  0.27441707 0.27502596]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.719114036153769e-07\n",
      "Predicción post entrenamiento : [[0.2753202]]\n",
      "PERDIDAAAA despues: 2.3841160157189734e-08\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "[[[0.26732495]\n",
      "  [0.26914048]\n",
      "  [0.27020934]\n",
      "  [0.27140126]\n",
      "  [0.27318862]\n",
      "  [0.27441707]\n",
      "  [0.27502596]\n",
      "  [0.27599606]]]\n",
      "ejemplar: [0.26732495 0.26914048 0.27020934 0.27140126 0.27318862 0.27441707\n",
      " 0.27502596 0.27599606]\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.27613148]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[0.26732495 0.26914048 0.27020934 0.27140126 0.27318862 0.27441707\n",
      "  0.27502596 0.27599606]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0034365952014923096\n",
      "Predicción post entrenamiento : [[0.27717054]]\n",
      "PERDIDAAAA despues: 0.003315850393846631\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "[[[0.26914048]\n",
      "  [0.27020934]\n",
      "  [0.27140126]\n",
      "  [0.27318862]\n",
      "  [0.27441707]\n",
      "  [0.27502596]\n",
      "  [0.27599606]\n",
      "  [0.27613148]]]\n",
      "ejemplar: [0.26914048 0.27020934 0.27140126 0.27318862 0.27441707 0.27502596\n",
      " 0.27599606 0.27613148]\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.278108]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[0.26914048 0.27020934 0.27140126 0.27318862 0.27441707 0.27502596\n",
      "  0.27599606 0.27613148]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00601680763065815\n",
      "Predicción post entrenamiento : [[0.2789968]]\n",
      "PERDIDAAAA despues: 0.005879713222384453\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "[[[0.27020934]\n",
      "  [0.27140126]\n",
      "  [0.27318862]\n",
      "  [0.27441707]\n",
      "  [0.27502596]\n",
      "  [0.27599606]\n",
      "  [0.27613148]\n",
      "  [0.278108  ]]]\n",
      "ejemplar: [0.27020934 0.27140126 0.27318862 0.27441707 0.27502596 0.27599606\n",
      " 0.27613148 0.278108  ]\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.27980426]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[0.27020934 0.27140126 0.27318862 0.27441707 0.27502596 0.27599606\n",
      "  0.27613148 0.278108  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0032361240591853857\n",
      "Predicción post entrenamiento : [[0.28055185]]\n",
      "PERDIDAAAA despues: 0.0031516265589743853\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "[[[0.27140126]\n",
      "  [0.27318862]\n",
      "  [0.27441707]\n",
      "  [0.27502596]\n",
      "  [0.27599606]\n",
      "  [0.27613148]\n",
      "  [0.278108  ]\n",
      "  [0.27980426]]]\n",
      "ejemplar: [0.27140126 0.27318862 0.27441707 0.27502596 0.27599606 0.27613148\n",
      " 0.278108   0.27980426]\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.2813751]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[0.27140126 0.27318862 0.27441707 0.27502596 0.27599606 0.27613148\n",
      "  0.278108   0.27980426]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002726566046476364\n",
      "Predicción post entrenamiento : [[0.28265586]]\n",
      "PERDIDAAAA despues: 0.0025944532826542854\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "[[[0.27318862]\n",
      "  [0.27441707]\n",
      "  [0.27502596]\n",
      "  [0.27599606]\n",
      "  [0.27613148]\n",
      "  [0.278108  ]\n",
      "  [0.27980426]\n",
      "  [0.28137511]]]\n",
      "ejemplar: [0.27318862 0.27441707 0.27502596 0.27599606 0.27613148 0.278108\n",
      " 0.27980426 0.28137511]\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.28347135]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[0.27318862 0.27441707 0.27502596 0.27599606 0.27613148 0.278108\n",
      "  0.27980426 0.28137511]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01025424711406231\n",
      "Predicción post entrenamiento : [[0.28494373]]\n",
      "PERDIDAAAA despues: 0.009958217851817608\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "[[[0.27441707]\n",
      "  [0.27502596]\n",
      "  [0.27599606]\n",
      "  [0.27613148]\n",
      "  [0.278108  ]\n",
      "  [0.27980426]\n",
      "  [0.28137511]\n",
      "  [0.28347135]]]\n",
      "ejemplar: [0.27441707 0.27502596 0.27599606 0.27613148 0.278108   0.27980426\n",
      " 0.28137511 0.28347135]\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.28562197]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[0.27441707 0.27502596 0.27599606 0.27613148 0.278108   0.27980426\n",
      "  0.28137511 0.28347135]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08149569481611252\n",
      "Predicción post entrenamiento : [[0.2893867]]\n",
      "PERDIDAAAA despues: 0.07936040312051773\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "[[[0.27502596]\n",
      "  [0.27599606]\n",
      "  [0.27613148]\n",
      "  [0.278108  ]\n",
      "  [0.27980426]\n",
      "  [0.28137511]\n",
      "  [0.28347135]\n",
      "  [0.28562197]]]\n",
      "ejemplar: [0.27502596 0.27599606 0.27613148 0.278108   0.27980426 0.28137511\n",
      " 0.28347135 0.28562197]\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.29005274]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[0.27502596 0.27599606 0.27613148 0.278108   0.27980426 0.28137511\n",
      "  0.28347135 0.28562197]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09377545118331909\n",
      "Predicción post entrenamiento : [[0.29422477]]\n",
      "PERDIDAAAA despues: 0.09123767167329788\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "[[[0.27599606]\n",
      "  [0.27613148]\n",
      "  [0.278108  ]\n",
      "  [0.27980426]\n",
      "  [0.28137511]\n",
      "  [0.28347135]\n",
      "  [0.28562197]\n",
      "  [0.29005274]]]\n",
      "ejemplar: [0.27599606 0.27613148 0.278108   0.27980426 0.28137511 0.28347135\n",
      " 0.28562197 0.29005274]\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.29505536]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[0.27599606 0.27613148 0.278108   0.27980426 0.28137511 0.28347135\n",
      "  0.28562197 0.29005274]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07813596725463867\n",
      "Predicción post entrenamiento : [[0.29860586]]\n",
      "PERDIDAAAA despues: 0.0761636421084404\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "[[[0.27613148]\n",
      "  [0.278108  ]\n",
      "  [0.27980426]\n",
      "  [0.28137511]\n",
      "  [0.28347135]\n",
      "  [0.28562197]\n",
      "  [0.29005274]\n",
      "  [0.29505536]]]\n",
      "ejemplar: [0.27613148 0.278108   0.27980426 0.28137511 0.28347135 0.28562197\n",
      " 0.29005274 0.29505536]\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.2995963]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[0.27613148 0.278108   0.27980426 0.28137511 0.28347135 0.28562197\n",
      "  0.29005274 0.29505536]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09410035610198975\n",
      "Predicción post entrenamiento : [[0.30337626]]\n",
      "PERDIDAAAA despues: 0.09179558604955673\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "[[[0.278108  ]\n",
      "  [0.27980426]\n",
      "  [0.28137511]\n",
      "  [0.28347135]\n",
      "  [0.28562197]\n",
      "  [0.29005274]\n",
      "  [0.29505536]\n",
      "  [0.29959631]]]\n",
      "ejemplar: [0.278108   0.27980426 0.28137511 0.28347135 0.28562197 0.29005274\n",
      " 0.29505536 0.29959631]\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.30480886]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[0.278108   0.27980426 0.28137511 0.28347135 0.28562197 0.29005274\n",
      "  0.29505536 0.29959631]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07831505686044693\n",
      "Predicción post entrenamiento : [[0.30846098]]\n",
      "PERDIDAAAA despues: 0.07628431171178818\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "[[[0.27980426]\n",
      "  [0.28137511]\n",
      "  [0.28347135]\n",
      "  [0.28562197]\n",
      "  [0.29005274]\n",
      "  [0.29505536]\n",
      "  [0.29959631]\n",
      "  [0.30480886]]]\n",
      "ejemplar: [0.27980426 0.28137511 0.28347135 0.28562197 0.29005274 0.29505536\n",
      " 0.29959631 0.30480886]\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.3100458]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[0.27980426 0.28137511 0.28347135 0.28562197 0.29005274 0.29505536\n",
      "  0.29959631 0.30480886]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06693913042545319\n",
      "Predicción post entrenamiento : [[0.3130541]]\n",
      "PERDIDAAAA despues: 0.06539152562618256\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "[[[0.28137511]\n",
      "  [0.28347135]\n",
      "  [0.28562197]\n",
      "  [0.29005274]\n",
      "  [0.29505536]\n",
      "  [0.29959631]\n",
      "  [0.30480886]\n",
      "  [0.31004581]]]\n",
      "ejemplar: [0.28137511 0.28347135 0.28562197 0.29005274 0.29505536 0.29959631\n",
      " 0.30480886 0.31004581]\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.31494886]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[0.28137511 0.28347135 0.28562197 0.29005274 0.29505536 0.29959631\n",
      "  0.30480886 0.31004581]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10746939480304718\n",
      "Predicción post entrenamiento : [[0.31886446]]\n",
      "PERDIDAAAA despues: 0.10491745173931122\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "[[[0.28347135]\n",
      "  [0.28562197]\n",
      "  [0.29005274]\n",
      "  [0.29505536]\n",
      "  [0.29959631]\n",
      "  [0.30480886]\n",
      "  [0.31004581]\n",
      "  [0.31494886]]]\n",
      "ejemplar: [0.28347135 0.28562197 0.29005274 0.29505536 0.29959631 0.30480886\n",
      " 0.31004581 0.31494886]\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.32121527]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[0.28347135 0.28562197 0.29005274 0.29505536 0.29959631 0.30480886\n",
      "  0.31004581 0.31494886]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11597004532814026\n",
      "Predicción post entrenamiento : [[0.32526755]]\n",
      "PERDIDAAAA despues: 0.1132265031337738\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "[[[0.28562197]\n",
      "  [0.29005274]\n",
      "  [0.29505536]\n",
      "  [0.29959631]\n",
      "  [0.30480886]\n",
      "  [0.31004581]\n",
      "  [0.31494886]\n",
      "  [0.32121527]]]\n",
      "ejemplar: [0.28562197 0.29005274 0.29505536 0.29959631 0.30480886 0.31004581\n",
      " 0.31494886 0.32121527]\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.32808533]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[0.28562197 0.29005274 0.29505536 0.29959631 0.30480886 0.31004581\n",
      "  0.31494886 0.32121527]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11896266043186188\n",
      "Predicción post entrenamiento : [[0.33198184]]\n",
      "PERDIDAAAA despues: 0.11628995835781097\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "[[[0.29005274]\n",
      "  [0.29505536]\n",
      "  [0.29959631]\n",
      "  [0.30480886]\n",
      "  [0.31004581]\n",
      "  [0.31494886]\n",
      "  [0.32121527]\n",
      "  [0.32808533]]]\n",
      "ejemplar: [0.29005274 0.29505536 0.29959631 0.30480886 0.31004581 0.31494886\n",
      " 0.32121527 0.32808533]\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.3353827]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[0.29005274 0.29505536 0.29959631 0.30480886 0.31004581 0.31494886\n",
      "  0.32121527 0.32808533]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14077100157737732\n",
      "Predicción post entrenamiento : [[0.3396325]]\n",
      "PERDIDAAAA despues: 0.13760004937648773\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "[[[0.29505536]\n",
      "  [0.29959631]\n",
      "  [0.30480886]\n",
      "  [0.31004581]\n",
      "  [0.31494886]\n",
      "  [0.32121527]\n",
      "  [0.32808533]\n",
      "  [0.3353827 ]]]\n",
      "ejemplar: [0.29505536 0.29959631 0.30480886 0.31004581 0.31494886 0.32121527\n",
      " 0.32808533 0.3353827 ]\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.34321785]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[0.29505536 0.29959631 0.30480886 0.31004581 0.31494886 0.32121527\n",
      "  0.32808533 0.3353827 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13015705347061157\n",
      "Predicción post entrenamiento : [[0.34712848]]\n",
      "PERDIDAAAA despues: 0.12735064327716827\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "[[[0.29959631]\n",
      "  [0.30480886]\n",
      "  [0.31004581]\n",
      "  [0.31494886]\n",
      "  [0.32121527]\n",
      "  [0.32808533]\n",
      "  [0.3353827 ]\n",
      "  [0.34321785]]]\n",
      "ejemplar: [0.29959631 0.30480886 0.31004581 0.31494886 0.32121527 0.32808533\n",
      " 0.3353827  0.34321785]\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.3508372]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[0.29959631 0.30480886 0.31004581 0.31494886 0.32121527 0.32808533\n",
      "  0.3353827  0.34321785]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14167720079421997\n",
      "Predicción post entrenamiento : [[0.35482943]]\n",
      "PERDIDAAAA despues: 0.13868778944015503\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "[[[0.30480886]\n",
      "  [0.31004581]\n",
      "  [0.31494886]\n",
      "  [0.32121527]\n",
      "  [0.32808533]\n",
      "  [0.3353827 ]\n",
      "  [0.34321785]\n",
      "  [0.3508372 ]]]\n",
      "ejemplar: [0.30480886 0.31004581 0.31494886 0.32121527 0.32808533 0.3353827\n",
      " 0.34321785 0.3508372 ]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.3588441]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[0.30480886 0.31004581 0.31494886 0.32121527 0.32808533 0.3353827\n",
      "  0.34321785 0.3508372 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1323097050189972\n",
      "Predicción post entrenamiento : [[0.36278868]]\n",
      "PERDIDAAAA despues: 0.12945564091205597\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "[[[0.31004581]\n",
      "  [0.31494886]\n",
      "  [0.32121527]\n",
      "  [0.32808533]\n",
      "  [0.3353827 ]\n",
      "  [0.34321785]\n",
      "  [0.3508372 ]\n",
      "  [0.3588441 ]]]\n",
      "ejemplar: [0.31004581 0.31494886 0.32121527 0.32808533 0.3353827  0.34321785\n",
      " 0.3508372  0.3588441 ]\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.36705273]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[0.31004581 0.31494886 0.32121527 0.32808533 0.3353827  0.34321785\n",
      "  0.3508372  0.3588441 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.16381540894508362\n",
      "Predicción post entrenamiento : [[0.3711989]]\n",
      "PERDIDAAAA despues: 0.16047635674476624\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "[[[0.31494886]\n",
      "  [0.32121527]\n",
      "  [0.32808533]\n",
      "  [0.3353827 ]\n",
      "  [0.34321785]\n",
      "  [0.3508372 ]\n",
      "  [0.3588441 ]\n",
      "  [0.36705273]]]\n",
      "ejemplar: [0.31494886 0.32121527 0.32808533 0.3353827  0.34321785 0.3508372\n",
      " 0.3588441  0.36705273]\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.37580207]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[0.31494886 0.32121527 0.32808533 0.3353827  0.34321785 0.3508372\n",
      "  0.3588441  0.36705273]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1216079518198967\n",
      "Predicción post entrenamiento : [[0.37943012]]\n",
      "PERDIDAAAA despues: 0.11909075081348419\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "[[[0.32121527]\n",
      "  [0.32808533]\n",
      "  [0.3353827 ]\n",
      "  [0.34321785]\n",
      "  [0.3508372 ]\n",
      "  [0.3588441 ]\n",
      "  [0.36705273]\n",
      "  [0.37580207]]]\n",
      "ejemplar: [0.32121527 0.32808533 0.3353827  0.34321785 0.3508372  0.3588441\n",
      " 0.36705273 0.37580207]\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.38455835]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[0.32121527 0.32808533 0.3353827  0.34321785 0.3508372  0.3588441\n",
      "  0.36705273 0.37580207]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0820818766951561\n",
      "Predicción post entrenamiento : [[0.38759798]]\n",
      "PERDIDAAAA despues: 0.08034941554069519\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "[[[0.32808533]\n",
      "  [0.3353827 ]\n",
      "  [0.34321785]\n",
      "  [0.3508372 ]\n",
      "  [0.3588441 ]\n",
      "  [0.36705273]\n",
      "  [0.37580207]\n",
      "  [0.38455835]]]\n",
      "ejemplar: [0.32808533 0.3353827  0.34321785 0.3508372  0.3588441  0.36705273\n",
      " 0.37580207 0.38455835]\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.39304554]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[0.32808533 0.3353827  0.34321785 0.3508372  0.3588441  0.36705273\n",
      "  0.37580207 0.38455835]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07880612462759018\n",
      "Predicción post entrenamiento : [[0.396051]]\n",
      "PERDIDAAAA despues: 0.07712775468826294\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "[[[0.3353827 ]\n",
      "  [0.34321785]\n",
      "  [0.3508372 ]\n",
      "  [0.3588441 ]\n",
      "  [0.36705273]\n",
      "  [0.37580207]\n",
      "  [0.38455835]\n",
      "  [0.39304554]]]\n",
      "ejemplar: [0.3353827  0.34321785 0.3508372  0.3588441  0.36705273 0.37580207\n",
      " 0.38455835 0.39304554]\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.40175202]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[0.3353827  0.34321785 0.3508372  0.3588441  0.36705273 0.37580207\n",
      "  0.38455835 0.39304554]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09778114408254623\n",
      "Predicción post entrenamiento : [[0.40485466]]\n",
      "PERDIDAAAA despues: 0.0958503857254982\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "[[[0.34321785]\n",
      "  [0.3508372 ]\n",
      "  [0.3588441 ]\n",
      "  [0.36705273]\n",
      "  [0.37580207]\n",
      "  [0.38455835]\n",
      "  [0.39304554]\n",
      "  [0.40175202]]]\n",
      "ejemplar: [0.34321785 0.3508372  0.3588441  0.36705273 0.37580207 0.38455835\n",
      " 0.39304554 0.40175202]\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.41076866]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[0.34321785 0.3508372  0.3588441  0.36705273 0.37580207 0.38455835\n",
      "  0.39304554 0.40175202]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.110974982380867\n",
      "Predicción post entrenamiento : [[0.41416723]]\n",
      "PERDIDAAAA despues: 0.10872220993041992\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "[[[0.3508372 ]\n",
      "  [0.3588441 ]\n",
      "  [0.36705273]\n",
      "  [0.37580207]\n",
      "  [0.38455835]\n",
      "  [0.39304554]\n",
      "  [0.40175202]\n",
      "  [0.41076866]]]\n",
      "ejemplar: [0.3508372  0.3588441  0.36705273 0.37580207 0.38455835 0.39304554\n",
      " 0.40175202 0.41076866]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.42021483]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[0.3508372  0.3588441  0.36705273 0.37580207 0.38455835 0.39304554\n",
      "  0.40175202 0.41076866]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09142960608005524\n",
      "Predicción post entrenamiento : [[0.42299992]]\n",
      "PERDIDAAAA despues: 0.08975309133529663\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "[[[0.3588441 ]\n",
      "  [0.36705273]\n",
      "  [0.37580207]\n",
      "  [0.38455835]\n",
      "  [0.39304554]\n",
      "  [0.40175202]\n",
      "  [0.41076866]\n",
      "  [0.42021483]]]\n",
      "ejemplar: [0.3588441  0.36705273 0.37580207 0.38455835 0.39304554 0.40175202\n",
      " 0.41076866 0.42021483]\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.42927337]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[0.3588441  0.36705273 0.37580207 0.38455835 0.39304554 0.40175202\n",
      "  0.41076866 0.42021483]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07293672114610672\n",
      "Predicción post entrenamiento : [[0.43206093]]\n",
      "PERDIDAAAA despues: 0.07143882662057877\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "[[[0.36705273]\n",
      "  [0.37580207]\n",
      "  [0.38455835]\n",
      "  [0.39304554]\n",
      "  [0.40175202]\n",
      "  [0.41076866]\n",
      "  [0.42021483]\n",
      "  [0.42927337]]]\n",
      "ejemplar: [0.36705273 0.37580207 0.38455835 0.39304554 0.40175202 0.41076866\n",
      " 0.42021483 0.42927337]\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.43851557]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[0.36705273 0.37580207 0.38455835 0.39304554 0.40175202 0.41076866\n",
      "  0.42021483 0.42927337]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08927877992391586\n",
      "Predicción post entrenamiento : [[0.44164172]]\n",
      "PERDIDAAAA despues: 0.08742039650678635\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "[[[0.37580207]\n",
      "  [0.38455835]\n",
      "  [0.39304554]\n",
      "  [0.40175202]\n",
      "  [0.41076866]\n",
      "  [0.42021483]\n",
      "  [0.42927337]\n",
      "  [0.43851557]]]\n",
      "ejemplar: [0.37580207 0.38455835 0.39304554 0.40175202 0.41076866 0.42021483\n",
      " 0.42927337 0.43851557]\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.44826898]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[0.37580207 0.38455835 0.39304554 0.40175202 0.41076866 0.42021483\n",
      "  0.42927337 0.43851557]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07461466640233994\n",
      "Predicción post entrenamiento : [[0.4506328]]\n",
      "PERDIDAAAA despues: 0.07332886010408401\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "[[[0.38455835]\n",
      "  [0.39304554]\n",
      "  [0.40175202]\n",
      "  [0.41076866]\n",
      "  [0.42021483]\n",
      "  [0.42927337]\n",
      "  [0.43851557]\n",
      "  [0.44826898]]]\n",
      "ejemplar: [0.38455835 0.39304554 0.40175202 0.41076866 0.42021483 0.42927337\n",
      " 0.43851557 0.44826898]\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.45733336]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[0.38455835 0.39304554 0.40175202 0.41076866 0.42021483 0.42927337\n",
      "  0.43851557 0.44826898]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06831968575716019\n",
      "Predicción post entrenamiento : [[0.45992932]]\n",
      "PERDIDAAAA despues: 0.0669693574309349\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "[[[0.39304554]\n",
      "  [0.40175202]\n",
      "  [0.41076866]\n",
      "  [0.42021483]\n",
      "  [0.42927337]\n",
      "  [0.43851557]\n",
      "  [0.44826898]\n",
      "  [0.45733336]]]\n",
      "ejemplar: [0.39304554 0.40175202 0.41076866 0.42021483 0.42927337 0.43851557\n",
      " 0.44826898 0.45733336]\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.466723]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[0.39304554 0.40175202 0.41076866 0.42021483 0.42927337 0.43851557\n",
      "  0.44826898 0.45733336]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.043028999119997025\n",
      "Predicción post entrenamiento : [[0.46874368]]\n",
      "PERDIDAAAA despues: 0.04219476506114006\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "[[[0.40175202]\n",
      "  [0.41076866]\n",
      "  [0.42021483]\n",
      "  [0.42927337]\n",
      "  [0.43851557]\n",
      "  [0.44826898]\n",
      "  [0.45733336]\n",
      "  [0.466723  ]]]\n",
      "ejemplar: [0.40175202 0.41076866 0.42021483 0.42927337 0.43851557 0.44826898\n",
      " 0.45733336 0.466723  ]\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.47572124]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[0.40175202 0.41076866 0.42021483 0.42927337 0.43851557 0.44826898\n",
      "  0.45733336 0.466723  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.049659982323646545\n",
      "Predicción post entrenamiento : [[0.477571]]\n",
      "PERDIDAAAA despues: 0.04883897677063942\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "[[[0.41076866]\n",
      "  [0.42021483]\n",
      "  [0.42927337]\n",
      "  [0.43851557]\n",
      "  [0.44826898]\n",
      "  [0.45733336]\n",
      "  [0.466723  ]\n",
      "  [0.47572124]]]\n",
      "ejemplar: [0.41076866 0.42021483 0.42927337 0.43851557 0.44826898 0.45733336\n",
      " 0.466723   0.47572124]\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.48470858]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[0.41076866 0.42021483 0.42927337 0.43851557 0.44826898 0.45733336\n",
      "  0.466723   0.47572124]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.055851757526397705\n",
      "Predicción post entrenamiento : [[0.4870101]]\n",
      "PERDIDAAAA despues: 0.05476922169327736\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "[[[0.42021483]\n",
      "  [0.42927337]\n",
      "  [0.43851557]\n",
      "  [0.44826898]\n",
      "  [0.45733336]\n",
      "  [0.466723  ]\n",
      "  [0.47572124]\n",
      "  [0.48470858]]]\n",
      "ejemplar: [0.42021483 0.42927337 0.43851557 0.44826898 0.45733336 0.466723\n",
      " 0.47572124 0.48470858]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.49425045]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[0.42021483 0.42927337 0.43851557 0.44826898 0.45733336 0.466723\n",
      "  0.47572124 0.48470858]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05213809385895729\n",
      "Predicción post entrenamiento : [[0.49658066]]\n",
      "PERDIDAAAA despues: 0.05107937380671501\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "[[[0.42927337]\n",
      "  [0.43851557]\n",
      "  [0.44826898]\n",
      "  [0.45733336]\n",
      "  [0.466723  ]\n",
      "  [0.47572124]\n",
      "  [0.48470858]\n",
      "  [0.49425045]]]\n",
      "ejemplar: [0.42927337 0.43851557 0.44826898 0.45733336 0.466723   0.47572124\n",
      " 0.48470858 0.49425045]\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.50382054]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[0.42927337 0.43851557 0.44826898 0.45733336 0.466723   0.47572124\n",
      "  0.48470858 0.49425045]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06374387443065643\n",
      "Predicción post entrenamiento : [[0.505475]]\n",
      "PERDIDAAAA despues: 0.06291119754314423\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "[[[0.43851557]\n",
      "  [0.44826898]\n",
      "  [0.45733336]\n",
      "  [0.466723  ]\n",
      "  [0.47572124]\n",
      "  [0.48470858]\n",
      "  [0.49425045]\n",
      "  [0.50382054]]]\n",
      "ejemplar: [0.43851557 0.44826898 0.45733336 0.466723   0.47572124 0.48470858\n",
      " 0.49425045 0.50382054]\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.5128064]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[0.43851557 0.44826898 0.45733336 0.466723   0.47572124 0.48470858\n",
      "  0.49425045 0.50382054]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09908633679151535\n",
      "Predicción post entrenamiento : [[0.5157919]]\n",
      "PERDIDAAAA despues: 0.09721571207046509\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "[[[0.44826898]\n",
      "  [0.45733336]\n",
      "  [0.466723  ]\n",
      "  [0.47572124]\n",
      "  [0.48470858]\n",
      "  [0.49425045]\n",
      "  [0.50382054]\n",
      "  [0.51280642]]]\n",
      "ejemplar: [0.44826898 0.45733336 0.466723   0.47572124 0.48470858 0.49425045\n",
      " 0.50382054 0.51280642]\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.523179]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[0.44826898 0.45733336 0.466723   0.47572124 0.48470858 0.49425045\n",
      "  0.50382054 0.51280642]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09963062405586243\n",
      "Predicción post entrenamiento : [[0.52598727]]\n",
      "PERDIDAAAA despues: 0.09786568582057953\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "[[[0.45733336]\n",
      "  [0.466723  ]\n",
      "  [0.47572124]\n",
      "  [0.48470858]\n",
      "  [0.49425045]\n",
      "  [0.50382054]\n",
      "  [0.51280642]\n",
      "  [0.52317899]]]\n",
      "ejemplar: [0.45733336 0.466723   0.47572124 0.48470858 0.49425045 0.50382054\n",
      " 0.51280642 0.52317899]\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.5332999]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[0.45733336 0.466723   0.47572124 0.48470858 0.49425045 0.50382054\n",
      "  0.51280642 0.52317899]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06810319423675537\n",
      "Predicción post entrenamiento : [[0.5355124]]\n",
      "PERDIDAAAA despues: 0.06695333123207092\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "[[[0.466723  ]\n",
      "  [0.47572124]\n",
      "  [0.48470858]\n",
      "  [0.49425045]\n",
      "  [0.50382054]\n",
      "  [0.51280642]\n",
      "  [0.52317899]\n",
      "  [0.53329992]]]\n",
      "ejemplar: [0.466723   0.47572124 0.48470858 0.49425045 0.50382054 0.51280642\n",
      " 0.52317899 0.53329992]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.54292494]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[0.466723   0.47572124 0.48470858 0.49425045 0.50382054 0.51280642\n",
      "  0.52317899 0.53329992]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05802306532859802\n",
      "Predicción post entrenamiento : [[0.54554474]]\n",
      "PERDIDAAAA despues: 0.05676781386137009\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "[[[0.47572124]\n",
      "  [0.48470858]\n",
      "  [0.49425045]\n",
      "  [0.50382054]\n",
      "  [0.51280642]\n",
      "  [0.52317899]\n",
      "  [0.53329992]\n",
      "  [0.54292494]]]\n",
      "ejemplar: [0.47572124 0.48470858 0.49425045 0.50382054 0.51280642 0.52317899\n",
      " 0.53329992 0.54292494]\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.5529981]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[0.47572124 0.48470858 0.49425045 0.50382054 0.51280642 0.52317899\n",
      "  0.53329992 0.54292494]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04619116336107254\n",
      "Predicción post entrenamiento : [[0.5550451]]\n",
      "PERDIDAAAA despues: 0.0453154630959034\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "[[[0.48470858]\n",
      "  [0.49425045]\n",
      "  [0.50382054]\n",
      "  [0.51280642]\n",
      "  [0.52317899]\n",
      "  [0.53329992]\n",
      "  [0.54292494]\n",
      "  [0.55299813]]]\n",
      "ejemplar: [0.48470858 0.49425045 0.50382054 0.51280642 0.52317899 0.53329992\n",
      " 0.54292494 0.55299813]\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.56266177]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[0.48470858 0.49425045 0.50382054 0.51280642 0.52317899 0.53329992\n",
      "  0.54292494 0.55299813]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04924754053354263\n",
      "Predicción post entrenamiento : [[0.56440973]]\n",
      "PERDIDAAAA despues: 0.048474784940481186\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "[[[0.49425045]\n",
      "  [0.50382054]\n",
      "  [0.51280642]\n",
      "  [0.52317899]\n",
      "  [0.53329992]\n",
      "  [0.54292494]\n",
      "  [0.55299813]\n",
      "  [0.56266177]]]\n",
      "ejemplar: [0.49425045 0.50382054 0.51280642 0.52317899 0.53329992 0.54292494\n",
      " 0.55299813 0.56266177]\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.5722286]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[0.49425045 0.50382054 0.51280642 0.52317899 0.53329992 0.54292494\n",
      "  0.55299813 0.56266177]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09394259005784988\n",
      "Predicción post entrenamiento : [[0.5751173]]\n",
      "PERDIDAAAA despues: 0.09218017011880875\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "[[[0.50382054]\n",
      "  [0.51280642]\n",
      "  [0.52317899]\n",
      "  [0.53329992]\n",
      "  [0.54292494]\n",
      "  [0.55299813]\n",
      "  [0.56266177]\n",
      "  [0.57222861]]]\n",
      "ejemplar: [0.50382054 0.51280642 0.52317899 0.53329992 0.54292494 0.55299813\n",
      " 0.56266177 0.57222861]\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.58302814]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[0.50382054 0.51280642 0.52317899 0.53329992 0.54292494 0.55299813\n",
      "  0.56266177 0.57222861]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0856156200170517\n",
      "Predicción post entrenamiento : [[0.5852181]]\n",
      "PERDIDAAAA despues: 0.08433885872364044\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "[[[0.51280642]\n",
      "  [0.52317899]\n",
      "  [0.53329992]\n",
      "  [0.54292494]\n",
      "  [0.55299813]\n",
      "  [0.56266177]\n",
      "  [0.57222861]\n",
      "  [0.58302814]]]\n",
      "ejemplar: [0.51280642 0.52317899 0.53329992 0.54292494 0.55299813 0.56266177\n",
      " 0.57222861 0.58302814]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.593229]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[0.51280642 0.52317899 0.53329992 0.54292494 0.55299813 0.56266177\n",
      "  0.57222861 0.58302814]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0653655081987381\n",
      "Predicción post entrenamiento : [[0.5955876]]\n",
      "PERDIDAAAA despues: 0.06416503340005875\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "[[[0.52317899]\n",
      "  [0.53329992]\n",
      "  [0.54292494]\n",
      "  [0.55299813]\n",
      "  [0.56266177]\n",
      "  [0.57222861]\n",
      "  [0.58302814]\n",
      "  [0.593229  ]]]\n",
      "ejemplar: [0.52317899 0.53329992 0.54292494 0.55299813 0.56266177 0.57222861\n",
      " 0.58302814 0.593229  ]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.60387707]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[0.52317899 0.53329992 0.54292494 0.55299813 0.56266177 0.57222861\n",
      "  0.58302814 0.593229  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04597182944417\n",
      "Predicción post entrenamiento : [[0.6053554]]\n",
      "PERDIDAAAA despues: 0.04534008353948593\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "[[[0.53329992]\n",
      "  [0.54292494]\n",
      "  [0.55299813]\n",
      "  [0.56266177]\n",
      "  [0.57222861]\n",
      "  [0.58302814]\n",
      "  [0.593229  ]\n",
      "  [0.60387707]]]\n",
      "ejemplar: [0.53329992 0.54292494 0.55299813 0.56266177 0.57222861 0.58302814\n",
      " 0.593229   0.60387707]\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.6135877]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[0.53329992 0.54292494 0.55299813 0.56266177 0.57222861 0.58302814\n",
      "  0.593229   0.60387707]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04546431824564934\n",
      "Predicción post entrenamiento : [[0.6155838]]\n",
      "PERDIDAAAA despues: 0.044617071747779846\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "[[[0.54292494]\n",
      "  [0.55299813]\n",
      "  [0.56266177]\n",
      "  [0.57222861]\n",
      "  [0.58302814]\n",
      "  [0.593229  ]\n",
      "  [0.60387707]\n",
      "  [0.61358768]]]\n",
      "ejemplar: [0.54292494 0.55299813 0.56266177 0.57222861 0.58302814 0.593229\n",
      " 0.60387707 0.61358768]\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.6238222]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[0.54292494 0.55299813 0.56266177 0.57222861 0.58302814 0.593229\n",
      "  0.60387707 0.61358768]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02609267830848694\n",
      "Predicción post entrenamiento : [[0.6248096]]\n",
      "PERDIDAAAA despues: 0.025774655863642693\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "[[[0.55299813]\n",
      "  [0.56266177]\n",
      "  [0.57222861]\n",
      "  [0.58302814]\n",
      "  [0.593229  ]\n",
      "  [0.60387707]\n",
      "  [0.61358768]\n",
      "  [0.62382221]]]\n",
      "ejemplar: [0.55299813 0.56266177 0.57222861 0.58302814 0.593229   0.60387707\n",
      " 0.61358768 0.62382221]\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.633192]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[0.55299813 0.56266177 0.57222861 0.58302814 0.593229   0.60387707\n",
      "  0.61358768 0.62382221]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.024347536265850067\n",
      "Predicción post entrenamiento : [[0.6344156]]\n",
      "PERDIDAAAA despues: 0.02396717295050621\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "[[[0.56266177]\n",
      "  [0.57222861]\n",
      "  [0.58302814]\n",
      "  [0.593229  ]\n",
      "  [0.60387707]\n",
      "  [0.61358768]\n",
      "  [0.62382221]\n",
      "  [0.633192  ]]]\n",
      "ejemplar: [0.56266177 0.57222861 0.58302814 0.593229   0.60387707 0.61358768\n",
      " 0.62382221 0.633192  ]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.64283925]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[0.56266177 0.57222861 0.58302814 0.593229   0.60387707 0.61358768\n",
      "  0.62382221 0.633192  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03660852089524269\n",
      "Predicción post entrenamiento : [[0.6437891]]\n",
      "PERDIDAAAA despues: 0.03624594211578369\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "[[[0.57222861]\n",
      "  [0.58302814]\n",
      "  [0.593229  ]\n",
      "  [0.60387707]\n",
      "  [0.61358768]\n",
      "  [0.62382221]\n",
      "  [0.633192  ]\n",
      "  [0.64283925]]]\n",
      "ejemplar: [0.57222861 0.58302814 0.593229   0.60387707 0.61358768 0.62382221\n",
      " 0.633192   0.64283925]\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.65236396]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[0.57222861 0.58302814 0.593229   0.60387707 0.61358768 0.62382221\n",
      "  0.633192   0.64283925]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02563580311834812\n",
      "Predicción post entrenamiento : [[0.6543479]]\n",
      "PERDIDAAAA despues: 0.0250044334679842\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "[[[0.58302814]\n",
      "  [0.593229  ]\n",
      "  [0.60387707]\n",
      "  [0.61358768]\n",
      "  [0.62382221]\n",
      "  [0.633192  ]\n",
      "  [0.64283925]\n",
      "  [0.65236396]]]\n",
      "ejemplar: [0.58302814 0.593229   0.60387707 0.61358768 0.62382221 0.633192\n",
      " 0.64283925 0.65236396]\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.6631111]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[0.58302814 0.593229   0.60387707 0.61358768 0.62382221 0.633192\n",
      "  0.64283925 0.65236396]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019079552963376045\n",
      "Predicción post entrenamiento : [[0.6640745]]\n",
      "PERDIDAAAA despues: 0.018814338371157646\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "[[[0.593229  ]\n",
      "  [0.60387707]\n",
      "  [0.61358768]\n",
      "  [0.62382221]\n",
      "  [0.633192  ]\n",
      "  [0.64283925]\n",
      "  [0.65236396]\n",
      "  [0.66311109]]]\n",
      "ejemplar: [0.593229   0.60387707 0.61358768 0.62382221 0.633192   0.64283925\n",
      " 0.65236396 0.66311109]\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.6726843]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[0.593229   0.60387707 0.61358768 0.62382221 0.633192   0.64283925\n",
      "  0.65236396 0.66311109]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017028357833623886\n",
      "Predicción post entrenamiento : [[0.6740082]]\n",
      "PERDIDAAAA despues: 0.016684597358107567\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "[[[0.60387707]\n",
      "  [0.61358768]\n",
      "  [0.62382221]\n",
      "  [0.633192  ]\n",
      "  [0.64283925]\n",
      "  [0.65236396]\n",
      "  [0.66311109]\n",
      "  [0.67268431]]]\n",
      "ejemplar: [0.60387707 0.61358768 0.62382221 0.633192   0.64283925 0.65236396\n",
      " 0.66311109 0.67268431]\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.68259156]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[0.60387707 0.61358768 0.62382221 0.633192   0.64283925 0.65236396\n",
      "  0.66311109 0.67268431]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012298661284148693\n",
      "Predicción post entrenamiento : [[0.6842091]]\n",
      "PERDIDAAAA despues: 0.011942506767809391\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "[[[0.61358768]\n",
      "  [0.62382221]\n",
      "  [0.633192  ]\n",
      "  [0.64283925]\n",
      "  [0.65236396]\n",
      "  [0.66311109]\n",
      "  [0.67268431]\n",
      "  [0.68259156]]]\n",
      "ejemplar: [0.61358768 0.62382221 0.633192   0.64283925 0.65236396 0.66311109\n",
      " 0.67268431 0.68259156]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.6926238]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[0.61358768 0.62382221 0.633192   0.64283925 0.65236396 0.66311109\n",
      "  0.67268431 0.68259156]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004562552087008953\n",
      "Predicción post entrenamiento : [[0.69368786]]\n",
      "PERDIDAAAA despues: 0.004419936798512936\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "[[[0.62382221]\n",
      "  [0.633192  ]\n",
      "  [0.64283925]\n",
      "  [0.65236396]\n",
      "  [0.66311109]\n",
      "  [0.67268431]\n",
      "  [0.68259156]\n",
      "  [0.69262379]]]\n",
      "ejemplar: [0.62382221 0.633192   0.64283925 0.65236396 0.66311109 0.67268431\n",
      " 0.68259156 0.69262379]\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.7021663]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[0.62382221 0.633192   0.64283925 0.65236396 0.66311109 0.67268431\n",
      "  0.68259156 0.69262379]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011027443688362837\n",
      "Predicción post entrenamiento : [[0.7025675]]\n",
      "PERDIDAAAA despues: 0.0010762596502900124\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "[[[0.633192  ]\n",
      "  [0.64283925]\n",
      "  [0.65236396]\n",
      "  [0.66311109]\n",
      "  [0.67268431]\n",
      "  [0.68259156]\n",
      "  [0.69262379]\n",
      "  [0.70216632]]]\n",
      "ejemplar: [0.633192   0.64283925 0.65236396 0.66311109 0.67268431 0.68259156\n",
      " 0.69262379 0.70216632]\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.7109652]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[0.633192   0.64283925 0.65236396 0.66311109 0.67268431 0.68259156\n",
      "  0.69262379 0.70216632]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.012402309352183e-07\n",
      "Predicción post entrenamiento : [[0.7104879]]\n",
      "PERDIDAAAA despues: 8.885336910680053e-08\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "[[[0.64283925]\n",
      "  [0.65236396]\n",
      "  [0.66311109]\n",
      "  [0.67268431]\n",
      "  [0.68259156]\n",
      "  [0.69262379]\n",
      "  [0.70216632]\n",
      "  [0.71096522]]]\n",
      "ejemplar: [0.64283925 0.65236396 0.66311109 0.67268431 0.68259156 0.69262379\n",
      " 0.70216632 0.71096522]\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.7190285]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[0.64283925 0.65236396 0.66311109 0.67268431 0.68259156 0.69262379\n",
      "  0.70216632 0.71096522]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.762909156852402e-05\n",
      "Predicción post entrenamiento : [[0.7189801]]\n",
      "PERDIDAAAA despues: 4.696339601650834e-05\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "[[[0.65236396]\n",
      "  [0.66311109]\n",
      "  [0.67268431]\n",
      "  [0.68259156]\n",
      "  [0.69262379]\n",
      "  [0.70216632]\n",
      "  [0.71096522]\n",
      "  [0.71902847]]]\n",
      "ejemplar: [0.65236396 0.66311109 0.67268431 0.68259156 0.69262379 0.70216632\n",
      " 0.71096522 0.71902847]\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.7275865]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[0.65236396 0.66311109 0.67268431 0.68259156 0.69262379 0.70216632\n",
      "  0.71096522 0.71902847]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00014518604439217597\n",
      "Predicción post entrenamiento : [[0.72641397]]\n",
      "PERDIDAAAA despues: 0.00017481758550275117\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "[[[0.66311109]\n",
      "  [0.67268431]\n",
      "  [0.68259156]\n",
      "  [0.69262379]\n",
      "  [0.70216632]\n",
      "  [0.71096522]\n",
      "  [0.71902847]\n",
      "  [0.72758651]]]\n",
      "ejemplar: [0.66311109 0.67268431 0.68259156 0.69262379 0.70216632 0.71096522\n",
      " 0.71902847 0.72758651]\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.7350904]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[0.66311109 0.67268431 0.68259156 0.69262379 0.70216632 0.71096522\n",
      "  0.71902847 0.72758651]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.120209844884812e-06\n",
      "Predicción post entrenamiento : [[0.7361781]]\n",
      "PERDIDAAAA despues: 8.599840839451645e-10\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "[[[0.67268431]\n",
      "  [0.68259156]\n",
      "  [0.69262379]\n",
      "  [0.70216632]\n",
      "  [0.71096522]\n",
      "  [0.71902847]\n",
      "  [0.72758651]\n",
      "  [0.73509037]]]\n",
      "ejemplar: [0.67268431 0.68259156 0.69262379 0.70216632 0.71096522 0.71902847\n",
      " 0.72758651 0.73509037]\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.74453896]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[0.67268431 0.68259156 0.69262379 0.70216632 0.71096522 0.71902847\n",
      "  0.72758651 0.73509037]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005924111697822809\n",
      "Predicción post entrenamiento : [[0.74287546]]\n",
      "PERDIDAAAA despues: 0.005670804996043444\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "[[[0.68259156]\n",
      "  [0.69262379]\n",
      "  [0.70216632]\n",
      "  [0.71096522]\n",
      "  [0.71902847]\n",
      "  [0.72758651]\n",
      "  [0.73509037]\n",
      "  [0.74453896]]]\n",
      "ejemplar: [0.68259156 0.69262379 0.70216632 0.71096522 0.71902847 0.72758651\n",
      " 0.73509037 0.74453896]\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.7511531]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[0.68259156 0.69262379 0.70216632 0.71096522 0.71902847 0.72758651\n",
      "  0.73509037 0.74453896]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006602813955396414\n",
      "Predicción post entrenamiento : [[0.7508505]]\n",
      "PERDIDAAAA despues: 0.0065537262707948685\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "[[[0.69262379]\n",
      "  [0.70216632]\n",
      "  [0.71096522]\n",
      "  [0.71902847]\n",
      "  [0.72758651]\n",
      "  [0.73509037]\n",
      "  [0.74453896]\n",
      "  [0.75115311]]]\n",
      "ejemplar: [0.69262379 0.70216632 0.71096522 0.71902847 0.72758651 0.73509037\n",
      " 0.74453896 0.75115311]\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.75888914]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[0.69262379 0.70216632 0.71096522 0.71902847 0.72758651 0.73509037\n",
      "  0.74453896 0.75115311]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003876296803355217\n",
      "Predicción post entrenamiento : [[0.7578649]]\n",
      "PERDIDAAAA despues: 0.0037498068995773792\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "[[[0.70216632]\n",
      "  [0.71096522]\n",
      "  [0.71902847]\n",
      "  [0.72758651]\n",
      "  [0.73509037]\n",
      "  [0.74453896]\n",
      "  [0.75115311]\n",
      "  [0.75888914]]]\n",
      "ejemplar: [0.70216632 0.71096522 0.71902847 0.72758651 0.73509037 0.74453896\n",
      " 0.75115311 0.75888914]\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.7655378]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[0.70216632 0.71096522 0.71902847 0.72758651 0.73509037 0.74453896\n",
      "  0.75115311 0.75888914]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01201007142663002\n",
      "Predicción post entrenamiento : [[0.7652772]]\n",
      "PERDIDAAAA despues: 0.011953022330999374\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "[[[0.71096522]\n",
      "  [0.71902847]\n",
      "  [0.72758651]\n",
      "  [0.73509037]\n",
      "  [0.74453896]\n",
      "  [0.75115311]\n",
      "  [0.75888914]\n",
      "  [0.7655378 ]]]\n",
      "ejemplar: [0.71096522 0.71902847 0.72758651 0.73509037 0.74453896 0.75115311\n",
      " 0.75888914 0.7655378 ]\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.772626]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[0.71096522 0.71902847 0.72758651 0.73509037 0.74453896 0.75115311\n",
      "  0.75888914 0.7655378 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008802064694464207\n",
      "Predicción post entrenamiento : [[0.77023154]]\n",
      "PERDIDAAAA despues: 0.00835850927978754\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "[[[0.71902847]\n",
      "  [0.72758651]\n",
      "  [0.73509037]\n",
      "  [0.74453896]\n",
      "  [0.75115311]\n",
      "  [0.75888914]\n",
      "  [0.7655378 ]\n",
      "  [0.77262598]]]\n",
      "ejemplar: [0.71902847 0.72758651 0.73509037 0.74453896 0.75115311 0.75888914\n",
      " 0.7655378  0.77262598]\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.7773756]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[0.71902847 0.72758651 0.73509037 0.74453896 0.75115311 0.75888914\n",
      "  0.7655378  0.77262598]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010257850401103497\n",
      "Predicción post entrenamiento : [[0.7745554]]\n",
      "PERDIDAAAA despues: 0.009694539941847324\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "[[[0.72758651]\n",
      "  [0.73509037]\n",
      "  [0.74453896]\n",
      "  [0.75115311]\n",
      "  [0.75888914]\n",
      "  [0.7655378 ]\n",
      "  [0.77262598]\n",
      "  [0.77737558]]]\n",
      "ejemplar: [0.72758651 0.73509037 0.74453896 0.75115311 0.75888914 0.7655378\n",
      " 0.77262598 0.77737558]\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.7816264]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[0.72758651 0.73509037 0.74453896 0.75115311 0.75888914 0.7655378\n",
      "  0.77262598 0.77737558]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002710685133934021\n",
      "Predicción post entrenamiento : [[0.78150177]]\n",
      "PERDIDAAAA despues: 0.002697722753509879\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "[[[0.73509037]\n",
      "  [0.74453896]\n",
      "  [0.75115311]\n",
      "  [0.75888914]\n",
      "  [0.7655378 ]\n",
      "  [0.77262598]\n",
      "  [0.77737558]\n",
      "  [0.7816264 ]]]\n",
      "ejemplar: [0.73509037 0.74453896 0.75115311 0.75888914 0.7655378  0.77262598\n",
      " 0.77737558 0.7816264 ]\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.78828275]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[0.73509037 0.74453896 0.75115311 0.75888914 0.7655378  0.77262598\n",
      "  0.77737558 0.7816264 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0075697279535233974\n",
      "Predicción post entrenamiento : [[0.78762984]]\n",
      "PERDIDAAAA despues: 0.007456542924046516\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "[[[0.74453896]\n",
      "  [0.75115311]\n",
      "  [0.75888914]\n",
      "  [0.7655378 ]\n",
      "  [0.77262598]\n",
      "  [0.77737558]\n",
      "  [0.7816264 ]\n",
      "  [0.78828275]]]\n",
      "ejemplar: [0.74453896 0.75115311 0.75888914 0.7655378  0.77262598 0.77737558\n",
      " 0.7816264  0.78828275]\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.79431057]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[0.74453896 0.75115311 0.75888914 0.7655378  0.77262598 0.77737558\n",
      "  0.7816264  0.78828275]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007170923054218292\n",
      "Predicción post entrenamiento : [[0.7941308]]\n",
      "PERDIDAAAA despues: 0.0007074967725202441\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "[[[0.75115311]\n",
      "  [0.75888914]\n",
      "  [0.7655378 ]\n",
      "  [0.77262598]\n",
      "  [0.77737558]\n",
      "  [0.7816264 ]\n",
      "  [0.78828275]\n",
      "  [0.79431057]]]\n",
      "ejemplar: [0.75115311 0.75888914 0.7655378  0.77262598 0.77737558 0.7816264\n",
      " 0.78828275 0.79431057]\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.80005866]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[0.75115311 0.75888914 0.7655378  0.77262598 0.77737558 0.7816264\n",
      "  0.78828275 0.79431057]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002018253318965435\n",
      "Predicción post entrenamiento : [[0.80035526]]\n",
      "PERDIDAAAA despues: 0.0020449901930987835\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "[[[0.75888914]\n",
      "  [0.7655378 ]\n",
      "  [0.77262598]\n",
      "  [0.77737558]\n",
      "  [0.7816264 ]\n",
      "  [0.78828275]\n",
      "  [0.79431057]\n",
      "  [0.80005866]]]\n",
      "ejemplar: [0.75888914 0.7655378  0.77262598 0.77737558 0.7816264  0.78828275\n",
      " 0.79431057 0.80005866]\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.8062002]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[0.75888914 0.7655378  0.77262598 0.77737558 0.7816264  0.78828275\n",
      "  0.79431057 0.80005866]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003738121595233679\n",
      "Predicción post entrenamiento : [[0.80615544]]\n",
      "PERDIDAAAA despues: 0.0037326498422771692\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "[[[0.7655378 ]\n",
      "  [0.77262598]\n",
      "  [0.77737558]\n",
      "  [0.7816264 ]\n",
      "  [0.78828275]\n",
      "  [0.79431057]\n",
      "  [0.80005866]\n",
      "  [0.80620021]]]\n",
      "ejemplar: [0.7655378  0.77262598 0.77737558 0.7816264  0.78828275 0.79431057\n",
      " 0.80005866 0.80620021]\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.81154144]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[0.7655378  0.77262598 0.77737558 0.7816264  0.78828275 0.79431057\n",
      "  0.80005866 0.80620021]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0035411270800977945\n",
      "Predicción post entrenamiento : [[0.8103751]]\n",
      "PERDIDAAAA despues: 0.003403675276786089\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "[[[0.77262598]\n",
      "  [0.77737558]\n",
      "  [0.7816264 ]\n",
      "  [0.78828275]\n",
      "  [0.79431057]\n",
      "  [0.80005866]\n",
      "  [0.80620021]\n",
      "  [0.81154144]]]\n",
      "ejemplar: [0.77262598 0.77737558 0.7816264  0.78828275 0.79431057 0.80005866\n",
      " 0.80620021 0.81154144]\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.8155326]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[0.77262598 0.77737558 0.7816264  0.78828275 0.79431057 0.80005866\n",
      "  0.80620021 0.81154144]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011178882792592049\n",
      "Predicción post entrenamiento : [[0.8137645]]\n",
      "PERDIDAAAA despues: 0.010808123275637627\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "[[[0.77737558]\n",
      "  [0.7816264 ]\n",
      "  [0.78828275]\n",
      "  [0.79431057]\n",
      "  [0.80005866]\n",
      "  [0.80620021]\n",
      "  [0.81154144]\n",
      "  [0.81553262]]]\n",
      "ejemplar: [0.77737558 0.7816264  0.78828275 0.79431057 0.80005866 0.80620021\n",
      " 0.81154144 0.81553262]\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.81851596]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[0.77737558 0.7816264  0.78828275 0.79431057 0.80005866 0.80620021\n",
      "  0.81154144 0.81553262]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016406001523137093\n",
      "Predicción post entrenamiento : [[0.81798685]]\n",
      "PERDIDAAAA despues: 0.01627073809504509\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "[[[0.7816264 ]\n",
      "  [0.78828275]\n",
      "  [0.79431057]\n",
      "  [0.80005866]\n",
      "  [0.80620021]\n",
      "  [0.81154144]\n",
      "  [0.81553262]\n",
      "  [0.81851596]]]\n",
      "ejemplar: [0.7816264  0.78828275 0.79431057 0.80005866 0.80620021 0.81154144\n",
      " 0.81553262 0.81851596]\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.8229458]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[0.7816264  0.78828275 0.79431057 0.80005866 0.80620021 0.81154144\n",
      "  0.81553262 0.81851596]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004704177379608154\n",
      "Predicción post entrenamiento : [[0.82217276]]\n",
      "PERDIDAAAA despues: 0.004598737694323063\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "[[[0.78828275]\n",
      "  [0.79431057]\n",
      "  [0.80005866]\n",
      "  [0.80620021]\n",
      "  [0.81154144]\n",
      "  [0.81553262]\n",
      "  [0.81851596]\n",
      "  [0.82294577]]]\n",
      "ejemplar: [0.78828275 0.79431057 0.80005866 0.80620021 0.81154144 0.81553262\n",
      " 0.81851596 0.82294577]\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.8274821]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[0.78828275 0.79431057 0.80005866 0.80620021 0.81154144 0.81553262\n",
      "  0.81851596 0.82294577]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011084175668656826\n",
      "Predicción post entrenamiento : [[0.82710284]]\n",
      "PERDIDAAAA despues: 0.011004460975527763\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "[[[0.79431057]\n",
      "  [0.80005866]\n",
      "  [0.80620021]\n",
      "  [0.81154144]\n",
      "  [0.81553262]\n",
      "  [0.81851596]\n",
      "  [0.82294577]\n",
      "  [0.8274821 ]]]\n",
      "ejemplar: [0.79431057 0.80005866 0.80620021 0.81154144 0.81553262 0.81851596\n",
      " 0.82294577 0.8274821 ]\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.8320486]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[0.79431057 0.80005866 0.80620021 0.81154144 0.81553262 0.81851596\n",
      "  0.82294577 0.8274821 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00027092380332760513\n",
      "Predicción post entrenamiento : [[0.8323847]]\n",
      "PERDIDAAAA despues: 0.0002599721774458885\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "[[[0.80005866]\n",
      "  [0.80620021]\n",
      "  [0.81154144]\n",
      "  [0.81553262]\n",
      "  [0.81851596]\n",
      "  [0.82294577]\n",
      "  [0.8274821 ]\n",
      "  [0.83204859]]]\n",
      "ejemplar: [0.80005866 0.80620021 0.81154144 0.81553262 0.81851596 0.82294577\n",
      " 0.8274821  0.83204859]\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.8370459]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[0.80005866 0.80620021 0.81154144 0.81553262 0.81851596 0.82294577\n",
      "  0.8274821  0.83204859]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004680895712226629\n",
      "Predicción post entrenamiento : [[0.8367916]]\n",
      "PERDIDAAAA despues: 0.004715762101113796\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "[[[0.80620021]\n",
      "  [0.81154144]\n",
      "  [0.81553262]\n",
      "  [0.81851596]\n",
      "  [0.82294577]\n",
      "  [0.8274821 ]\n",
      "  [0.83204859]\n",
      "  [0.83704591]]]\n",
      "ejemplar: [0.80620021 0.81154144 0.81553262 0.81851596 0.82294577 0.8274821\n",
      " 0.83204859 0.83704591]\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.84116906]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[0.80620021 0.81154144 0.81553262 0.81851596 0.82294577 0.8274821\n",
      "  0.83204859 0.83704591]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016848690574988723\n",
      "Predicción post entrenamiento : [[0.8412093]]\n",
      "PERDIDAAAA despues: 0.001681567751802504\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "[[[0.81154144]\n",
      "  [0.81553262]\n",
      "  [0.81851596]\n",
      "  [0.82294577]\n",
      "  [0.8274821 ]\n",
      "  [0.83204859]\n",
      "  [0.83704591]\n",
      "  [0.84116906]]]\n",
      "ejemplar: [0.81154144 0.81553262 0.81851596 0.82294577 0.8274821  0.83204859\n",
      " 0.83704591 0.84116906]\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.84512174]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[0.81154144 0.81553262 0.81851596 0.82294577 0.8274821  0.83204859\n",
      "  0.83704591 0.84116906]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003927019890397787\n",
      "Predicción post entrenamiento : [[0.84595895]]\n",
      "PERDIDAAAA despues: 0.003822792088612914\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "[[[0.81553262]\n",
      "  [0.81851596]\n",
      "  [0.82294577]\n",
      "  [0.8274821 ]\n",
      "  [0.83204859]\n",
      "  [0.83704591]\n",
      "  [0.84116906]\n",
      "  [0.84512174]]]\n",
      "ejemplar: [0.81553262 0.81851596 0.82294577 0.8274821  0.83204859 0.83704591\n",
      " 0.84116906 0.84512174]\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.84957075]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[0.81553262 0.81851596 0.82294577 0.8274821  0.83204859 0.83704591\n",
      "  0.84116906 0.84512174]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016005549114197493\n",
      "Predicción post entrenamiento : [[0.8500965]]\n",
      "PERDIDAAAA despues: 0.001558762276545167\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "[[[0.81851596]\n",
      "  [0.82294577]\n",
      "  [0.8274821 ]\n",
      "  [0.83204859]\n",
      "  [0.83704591]\n",
      "  [0.84116906]\n",
      "  [0.84512174]\n",
      "  [0.84957075]]]\n",
      "ejemplar: [0.81851596 0.82294577 0.8274821  0.83204859 0.83704591 0.84116906\n",
      " 0.84512174 0.84957075]\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.8537747]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[0.81851596 0.82294577 0.8274821  0.83204859 0.83704591 0.84116906\n",
      "  0.84512174 0.84957075]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004443646175786853\n",
      "Predicción post entrenamiento : [[0.8540893]]\n",
      "PERDIDAAAA despues: 0.00043120034388266504\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "[[[0.82294577]\n",
      "  [0.8274821 ]\n",
      "  [0.83204859]\n",
      "  [0.83704591]\n",
      "  [0.84116906]\n",
      "  [0.84512174]\n",
      "  [0.84957075]\n",
      "  [0.85377473]]]\n",
      "ejemplar: [0.82294577 0.8274821  0.83204859 0.83704591 0.84116906 0.84512174\n",
      " 0.84957075 0.85377473]\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.85815316]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[0.82294577 0.8274821  0.83204859 0.83704591 0.84116906 0.84512174\n",
      "  0.84957075 0.85377473]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003031468950212002\n",
      "Predicción post entrenamiento : [[0.8570149]]\n",
      "PERDIDAAAA despues: 0.0031581080984324217\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "[[[0.8274821 ]\n",
      "  [0.83204859]\n",
      "  [0.83704591]\n",
      "  [0.84116906]\n",
      "  [0.84512174]\n",
      "  [0.84957075]\n",
      "  [0.85377473]\n",
      "  [0.85815316]]]\n",
      "ejemplar: [0.8274821  0.83204859 0.83704591 0.84116906 0.84512174 0.84957075\n",
      " 0.85377473 0.85815316]\n",
      "y: 1.0\n",
      "Predicción : [[0.8610857]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[0.8274821  0.83204859 0.83704591 0.84116906 0.84512174 0.84957075\n",
      "  0.85377473 0.85815316]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019297178834676743\n",
      "Predicción post entrenamiento : [[0.86201185]]\n",
      "PERDIDAAAA despues: 0.019040729850530624\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "[[[0.83204859]\n",
      "  [0.83704591]\n",
      "  [0.84116906]\n",
      "  [0.84512174]\n",
      "  [0.84957075]\n",
      "  [0.85377473]\n",
      "  [0.85815316]\n",
      "  [0.86108571]]]\n",
      "ejemplar: [0.83204859 0.83704591 0.84116906 0.84512174 0.84957075 0.85377473\n",
      " 0.85815316 0.86108571]\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.86604506]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[0.83204859 0.83704591 0.84116906 0.84512174 0.84957075 0.85377473\n",
      "  0.85815316 0.86108571]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010922130197286606\n",
      "Predicción post entrenamiento : [[0.86748976]]\n",
      "PERDIDAAAA despues: 0.01062224991619587\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "[[[0.83704591]\n",
      "  [0.84116906]\n",
      "  [0.84512174]\n",
      "  [0.84957075]\n",
      "  [0.85377473]\n",
      "  [0.85815316]\n",
      "  [0.86108571]\n",
      "  [0.86604506]]]\n",
      "ejemplar: [0.83704591 0.84116906 0.84512174 0.84957075 0.85377473 0.85815316\n",
      " 0.86108571 0.86604506]\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.8714562]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[0.83704591 0.84116906 0.84512174 0.84957075 0.85377473 0.85815316\n",
      "  0.86108571 0.86604506]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00030090316431596875\n",
      "Predicción post entrenamiento : [[0.87184936]]\n",
      "PERDIDAAAA despues: 0.00028741807909682393\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "[[[0.84116906]\n",
      "  [0.84512174]\n",
      "  [0.84957075]\n",
      "  [0.85377473]\n",
      "  [0.85815316]\n",
      "  [0.86108571]\n",
      "  [0.86604506]\n",
      "  [0.87145621]]]\n",
      "ejemplar: [0.84116906 0.84512174 0.84957075 0.85377473 0.85815316 0.86108571\n",
      " 0.86604506 0.87145621]\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.8756044]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[0.84116906 0.84512174 0.84957075 0.85377473 0.85815316 0.86108571\n",
      "  0.86604506 0.87145621]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.522091669263318e-06\n",
      "Predicción post entrenamiento : [[0.8748982]]\n",
      "PERDIDAAAA despues: 9.339802090835292e-06\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "[[[0.84512174]\n",
      "  [0.84957075]\n",
      "  [0.85377473]\n",
      "  [0.85815316]\n",
      "  [0.86108571]\n",
      "  [0.86604506]\n",
      "  [0.87145621]\n",
      "  [0.87560439]]]\n",
      "ejemplar: [0.84512174 0.84957075 0.85377473 0.85815316 0.86108571 0.86604506\n",
      " 0.87145621 0.87560439]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.87867594]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[0.84512174 0.84957075 0.85377473 0.85815316 0.86108571 0.86604506\n",
      "  0.87145621 0.87560439]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008868572767823935\n",
      "Predicción post entrenamiento : [[0.878189]]\n",
      "PERDIDAAAA despues: 0.0008580938447266817\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "[[[0.84957075]\n",
      "  [0.85377473]\n",
      "  [0.85815316]\n",
      "  [0.86108571]\n",
      "  [0.86604506]\n",
      "  [0.87145621]\n",
      "  [0.87560439]\n",
      "  [0.87867594]]]\n",
      "ejemplar: [0.84957075 0.85377473 0.85815316 0.86108571 0.86604506 0.87145621\n",
      " 0.87560439 0.87867594]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.88204765]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[0.84957075 0.85377473 0.85815316 0.86108571 0.86604506 0.87145621\n",
      "  0.87560439 0.87867594]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0022920030169188976\n",
      "Predicción post entrenamiento : [[0.8824473]]\n",
      "PERDIDAAAA despues: 0.002330428920686245\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "[[[0.85377473]\n",
      "  [0.85815316]\n",
      "  [0.86108571]\n",
      "  [0.86604506]\n",
      "  [0.87145621]\n",
      "  [0.87560439]\n",
      "  [0.87867594]\n",
      "  [0.88204765]]]\n",
      "ejemplar: [0.85377473 0.85815316 0.86108571 0.86604506 0.87145621 0.87560439\n",
      " 0.87867594 0.88204765]\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.8862442]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[0.85377473 0.85815316 0.86108571 0.86604506 0.87145621 0.87560439\n",
      "  0.87867594 0.88204765]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009702768875285983\n",
      "Predicción post entrenamiento : [[0.88675344]]\n",
      "PERDIDAAAA despues: 0.0010022625792771578\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "[[[0.85815316]\n",
      "  [0.86108571]\n",
      "  [0.86604506]\n",
      "  [0.87145621]\n",
      "  [0.87560439]\n",
      "  [0.87867594]\n",
      "  [0.88204765]\n",
      "  [0.88624418]]]\n",
      "ejemplar: [0.85815316 0.86108571 0.86604506 0.87145621 0.87560439 0.87867594\n",
      " 0.88204765 0.88624418]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.8905438]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[0.85815316 0.86108571 0.86604506 0.87145621 0.87560439 0.87867594\n",
      "  0.88204765 0.88624418]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00023414033057633787\n",
      "Predicción post entrenamiento : [[0.8902705]]\n",
      "PERDIDAAAA despues: 0.00022584974067285657\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "[[[0.86108571]\n",
      "  [0.86604506]\n",
      "  [0.87145621]\n",
      "  [0.87560439]\n",
      "  [0.87867594]\n",
      "  [0.88204765]\n",
      "  [0.88624418]\n",
      "  [0.89054382]]]\n",
      "ejemplar: [0.86108571 0.86604506 0.87145621 0.87560439 0.87867594 0.88204765\n",
      " 0.88624418 0.89054382]\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.89399153]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[0.86108571 0.86604506 0.87145621 0.87560439 0.87867594 0.88204765\n",
      "  0.88624418 0.89054382]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013659935211762786\n",
      "Predicción post entrenamiento : [[0.89320296]]\n",
      "PERDIDAAAA despues: 0.0013083253288641572\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "[[[0.86604506]\n",
      "  [0.87145621]\n",
      "  [0.87560439]\n",
      "  [0.87867594]\n",
      "  [0.88204765]\n",
      "  [0.88624418]\n",
      "  [0.89054382]\n",
      "  [0.89399153]]]\n",
      "ejemplar: [0.86604506 0.87145621 0.87560439 0.87867594 0.88204765 0.88624418\n",
      " 0.89054382 0.89399153]\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.8972659]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[0.86604506 0.87145621 0.87560439 0.87867594 0.88204765 0.88624418\n",
      "  0.89054382 0.89399153]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0022285738959908485\n",
      "Predicción post entrenamiento : [[0.89784473]]\n",
      "PERDIDAAAA despues: 0.0022835584823042154\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "[[[0.87145621]\n",
      "  [0.87560439]\n",
      "  [0.87867594]\n",
      "  [0.88204765]\n",
      "  [0.88624418]\n",
      "  [0.89054382]\n",
      "  [0.89399153]\n",
      "  [0.89726591]]]\n",
      "ejemplar: [0.87145621 0.87560439 0.87867594 0.88204765 0.88624418 0.89054382\n",
      " 0.89399153 0.89726591]\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.90166694]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[0.87145621 0.87560439 0.87867594 0.88204765 0.88624418 0.89054382\n",
      "  0.89399153 0.89726591]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0034775000531226397\n",
      "Predicción post entrenamiento : [[0.9016629]]\n",
      "PERDIDAAAA despues: 0.0034770220518112183\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "[[[0.87560439]\n",
      "  [0.87867594]\n",
      "  [0.88204765]\n",
      "  [0.88624418]\n",
      "  [0.89054382]\n",
      "  [0.89399153]\n",
      "  [0.89726591]\n",
      "  [0.90166694]]]\n",
      "ejemplar: [0.87560439 0.87867594 0.88204765 0.88624418 0.89054382 0.89399153\n",
      " 0.89726591 0.90166694]\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.90505135]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[0.87560439 0.87867594 0.88204765 0.88624418 0.89054382 0.89399153\n",
      "  0.89726591 0.90166694]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006742794066667557\n",
      "Predicción post entrenamiento : [[0.90470684]]\n",
      "PERDIDAAAA despues: 0.006686333566904068\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "[[[0.87867594]\n",
      "  [0.88204765]\n",
      "  [0.88624418]\n",
      "  [0.89054382]\n",
      "  [0.89399153]\n",
      "  [0.89726591]\n",
      "  [0.90166694]\n",
      "  [0.90505135]]]\n",
      "ejemplar: [0.87867594 0.88204765 0.88624418 0.89054382 0.89399153 0.89726591\n",
      " 0.90166694 0.90505135]\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.90797347]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[0.87867594 0.88204765 0.88624418 0.89054382 0.89399153 0.89726591\n",
      "  0.90166694 0.90505135]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017813555896282196\n",
      "Predicción post entrenamiento : [[0.9071544]]\n",
      "PERDIDAAAA despues: 0.017595583572983742\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "[[[0.88204765]\n",
      "  [0.88624418]\n",
      "  [0.89054382]\n",
      "  [0.89399153]\n",
      "  [0.89726591]\n",
      "  [0.90166694]\n",
      "  [0.90505135]\n",
      "  [0.90797347]]]\n",
      "ejemplar: [0.88204765 0.88624418 0.89054382 0.89399153 0.89726591 0.90166694\n",
      " 0.90505135 0.90797347]\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.91060406]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[0.88204765 0.88624418 0.89054382 0.89399153 0.89726591 0.90166694\n",
      "  0.90505135 0.90797347]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01597997173666954\n",
      "Predicción post entrenamiento : [[0.9095176]]\n",
      "PERDIDAAAA despues: 0.015706466510891914\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "[[[0.88624418]\n",
      "  [0.89054382]\n",
      "  [0.89399153]\n",
      "  [0.89726591]\n",
      "  [0.90166694]\n",
      "  [0.90505135]\n",
      "  [0.90797347]\n",
      "  [0.91060406]]]\n",
      "ejemplar: [0.88624418 0.89054382 0.89399153 0.89726591 0.90166694 0.90505135\n",
      " 0.90797347 0.91060406]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.913073]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[0.88624418 0.89054382 0.89399153 0.89726591 0.90166694 0.90505135\n",
      "  0.90797347 0.91060406]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0028439494781196117\n",
      "Predicción post entrenamiento : [[0.9122503]]\n",
      "PERDIDAAAA despues: 0.0027568768709897995\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "[[[0.89054382]\n",
      "  [0.89399153]\n",
      "  [0.89726591]\n",
      "  [0.90166694]\n",
      "  [0.90505135]\n",
      "  [0.90797347]\n",
      "  [0.91060406]\n",
      "  [0.913073  ]]]\n",
      "ejemplar: [0.89054382 0.89399153 0.89726591 0.90166694 0.90505135 0.90797347\n",
      " 0.91060406 0.913073  ]\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.91564924]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[0.89054382 0.89399153 0.89726591 0.90166694 0.90505135 0.90797347\n",
      "  0.91060406 0.913073  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0037612691521644592\n",
      "Predicción post entrenamiento : [[0.9144088]]\n",
      "PERDIDAAAA despues: 0.0036106582265347242\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "[[[0.89399153]\n",
      "  [0.89726591]\n",
      "  [0.90166694]\n",
      "  [0.90505135]\n",
      "  [0.90797347]\n",
      "  [0.91060406]\n",
      "  [0.913073  ]\n",
      "  [0.91564924]]]\n",
      "ejemplar: [0.89399153 0.89726591 0.90166694 0.90505135 0.90797347 0.91060406\n",
      " 0.913073   0.91564924]\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.9175622]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[0.89399153 0.89726591 0.90166694 0.90505135 0.90797347 0.91060406\n",
      "  0.913073   0.91564924]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006508822087198496\n",
      "Predicción post entrenamiento : [[0.9172504]]\n",
      "PERDIDAAAA despues: 0.00645861029624939\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "[[[0.89726591]\n",
      "  [0.90166694]\n",
      "  [0.90505135]\n",
      "  [0.90797347]\n",
      "  [0.91060406]\n",
      "  [0.913073  ]\n",
      "  [0.91564924]\n",
      "  [0.91756219]]]\n",
      "ejemplar: [0.89726591 0.90166694 0.90505135 0.90797347 0.91060406 0.913073\n",
      " 0.91564924 0.91756219]\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.9203445]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[0.89726591 0.90166694 0.90505135 0.90797347 0.91060406 0.913073\n",
      "  0.91564924 0.91756219]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008178235962986946\n",
      "Predicción post entrenamiento : [[0.92024785]]\n",
      "PERDIDAAAA despues: 0.008160769939422607\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "[[[0.90166694]\n",
      "  [0.90505135]\n",
      "  [0.90797347]\n",
      "  [0.91060406]\n",
      "  [0.913073  ]\n",
      "  [0.91564924]\n",
      "  [0.91756219]\n",
      "  [0.92034447]]]\n",
      "ejemplar: [0.90166694 0.90505135 0.90797347 0.91060406 0.913073   0.91564924\n",
      " 0.91756219 0.92034447]\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.92328984]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[0.90166694 0.90505135 0.90797347 0.91060406 0.913073   0.91564924\n",
      "  0.91756219 0.92034447]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00129865447524935\n",
      "Predicción post entrenamiento : [[0.9231641]]\n",
      "PERDIDAAAA despues: 0.0012896101688966155\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "[[[0.90505135]\n",
      "  [0.90797347]\n",
      "  [0.91060406]\n",
      "  [0.913073  ]\n",
      "  [0.91564924]\n",
      "  [0.91756219]\n",
      "  [0.92034447]\n",
      "  [0.92328984]]]\n",
      "ejemplar: [0.90505135 0.90797347 0.91060406 0.913073   0.91564924 0.91756219\n",
      " 0.92034447 0.92328984]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.92577314]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[0.90505135 0.90797347 0.91060406 0.913073   0.91564924 0.91756219\n",
      "  0.92034447 0.92328984]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004359806887805462\n",
      "Predicción post entrenamiento : [[0.925984]]\n",
      "PERDIDAAAA despues: 0.0043876999989151955\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "[[[0.90797347]\n",
      "  [0.91060406]\n",
      "  [0.913073  ]\n",
      "  [0.91564924]\n",
      "  [0.91756219]\n",
      "  [0.92034447]\n",
      "  [0.92328984]\n",
      "  [0.92577314]]]\n",
      "ejemplar: [0.90797347 0.91060406 0.913073   0.91564924 0.91756219 0.92034447\n",
      " 0.92328984 0.92577314]\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.9283851]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[0.90797347 0.91060406 0.913073   0.91564924 0.91756219 0.92034447\n",
      "  0.92328984 0.92577314]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007883314974606037\n",
      "Predicción post entrenamiento : [[0.92880356]]\n",
      "PERDIDAAAA despues: 0.007957803085446358\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "[[[0.91060406]\n",
      "  [0.913073  ]\n",
      "  [0.91564924]\n",
      "  [0.91756219]\n",
      "  [0.92034447]\n",
      "  [0.92328984]\n",
      "  [0.92577314]\n",
      "  [0.92838508]]]\n",
      "ejemplar: [0.91060406 0.913073   0.91564924 0.91756219 0.92034447 0.92328984\n",
      " 0.92577314 0.92838508]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.9311001]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[0.91060406 0.913073   0.91564924 0.91756219 0.92034447 0.92328984\n",
      "  0.92577314 0.92838508]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.021695921197533607\n",
      "Predicción post entrenamiento : [[0.9311045]]\n",
      "PERDIDAAAA despues: 0.02169722132384777\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "[[[0.913073  ]\n",
      "  [0.91564924]\n",
      "  [0.91756219]\n",
      "  [0.92034447]\n",
      "  [0.92328984]\n",
      "  [0.92577314]\n",
      "  [0.92838508]\n",
      "  [0.93110007]]]\n",
      "ejemplar: [0.913073   0.91564924 0.91756219 0.92034447 0.92328984 0.92577314\n",
      " 0.92838508 0.93110007]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.9333722]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[0.913073   0.91564924 0.91756219 0.92034447 0.92328984 0.92577314\n",
      "  0.92838508 0.93110007]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013244490139186382\n",
      "Predicción post entrenamiento : [[0.93297905]]\n",
      "PERDIDAAAA despues: 0.013154152780771255\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "[[[0.91564924]\n",
      "  [0.91756219]\n",
      "  [0.92034447]\n",
      "  [0.92328984]\n",
      "  [0.92577314]\n",
      "  [0.92838508]\n",
      "  [0.93110007]\n",
      "  [0.9333722 ]]]\n",
      "ejemplar: [0.91564924 0.91756219 0.92034447 0.92328984 0.92577314 0.92838508\n",
      " 0.93110007 0.9333722 ]\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.9352661]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[0.91564924 0.91756219 0.92034447 0.92328984 0.92577314 0.92838508\n",
      "  0.93110007 0.9333722 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.020764779299497604\n",
      "Predicción post entrenamiento : [[0.93345803]]\n",
      "PERDIDAAAA despues: 0.020246969535946846\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "[[[0.91756219]\n",
      "  [0.92034447]\n",
      "  [0.92328984]\n",
      "  [0.92577314]\n",
      "  [0.92838508]\n",
      "  [0.93110007]\n",
      "  [0.9333722 ]\n",
      "  [0.93526608]]]\n",
      "ejemplar: [0.91756219 0.92034447 0.92328984 0.92577314 0.92838508 0.93110007\n",
      " 0.9333722  0.93526608]\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.93573284]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[0.91756219 0.92034447 0.92328984 0.92577314 0.92838508 0.93110007\n",
      "  0.9333722  0.93526608]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.030686242505908012\n",
      "Predicción post entrenamiento : [[0.93508214]]\n",
      "PERDIDAAAA despues: 0.030458692461252213\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "[[[0.92034447]\n",
      "  [0.92328984]\n",
      "  [0.92577314]\n",
      "  [0.92838508]\n",
      "  [0.93110007]\n",
      "  [0.9333722 ]\n",
      "  [0.93526608]\n",
      "  [0.93573284]]]\n",
      "ejemplar: [0.92034447 0.92328984 0.92577314 0.92838508 0.93110007 0.9333722\n",
      " 0.93526608 0.93573284]\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.93752855]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[0.92034447 0.92328984 0.92577314 0.92838508 0.93110007 0.9333722\n",
      "  0.93526608 0.93573284]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.021308664232492447\n",
      "Predicción post entrenamiento : [[0.9369114]]\n",
      "PERDIDAAAA despues: 0.02112886868417263\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "[[[0.92328984]\n",
      "  [0.92577314]\n",
      "  [0.92838508]\n",
      "  [0.93110007]\n",
      "  [0.9333722 ]\n",
      "  [0.93526608]\n",
      "  [0.93573284]\n",
      "  [0.93752855]]]\n",
      "ejemplar: [0.92328984 0.92577314 0.92838508 0.93110007 0.9333722  0.93526608\n",
      " 0.93573284 0.93752855]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9392615]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[0.92328984 0.92577314 0.92838508 0.93110007 0.9333722  0.93526608\n",
      "  0.93573284 0.93752855]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.029093174263834953\n",
      "Predicción post entrenamiento : [[0.93874156]]\n",
      "PERDIDAAAA despues: 0.028916077688336372\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "[[[0.92577314]\n",
      "  [0.92838508]\n",
      "  [0.93110007]\n",
      "  [0.9333722 ]\n",
      "  [0.93526608]\n",
      "  [0.93573284]\n",
      "  [0.93752855]\n",
      "  [0.9392615 ]]]\n",
      "ejemplar: [0.92577314 0.92838508 0.93110007 0.9333722  0.93526608 0.93573284\n",
      " 0.93752855 0.9392615 ]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.940896]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[0.92577314 0.92838508 0.93110007 0.9333722  0.93526608 0.93573284\n",
      "  0.93752855 0.9392615 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02965342253446579\n",
      "Predicción post entrenamiento : [[0.9407768]]\n",
      "PERDIDAAAA despues: 0.029612401500344276\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "[[[0.92838508]\n",
      "  [0.93110007]\n",
      "  [0.9333722 ]\n",
      "  [0.93526608]\n",
      "  [0.93573284]\n",
      "  [0.93752855]\n",
      "  [0.9392615 ]\n",
      "  [0.94089597]]]\n",
      "ejemplar: [0.92838508 0.93110007 0.9333722  0.93526608 0.93573284 0.93752855\n",
      " 0.9392615  0.94089597]\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.94281363]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[0.92838508 0.93110007 0.9333722  0.93526608 0.93573284 0.93752855\n",
      "  0.9392615  0.94089597]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.020706774666905403\n",
      "Predicción post entrenamiento : [[0.9410363]]\n",
      "PERDIDAAAA despues: 0.020198417827486992\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "[[[0.93110007]\n",
      "  [0.9333722 ]\n",
      "  [0.93526608]\n",
      "  [0.93573284]\n",
      "  [0.93752855]\n",
      "  [0.9392615 ]\n",
      "  [0.94089597]\n",
      "  [0.94281363]]]\n",
      "ejemplar: [0.93110007 0.9333722  0.93526608 0.93573284 0.93752855 0.9392615\n",
      " 0.94089597 0.94281363]\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.94287056]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[0.93110007 0.9333722  0.93526608 0.93573284 0.93752855 0.9392615\n",
      "  0.94089597 0.94281363]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.023368217051029205\n",
      "Predicción post entrenamiento : [[0.9426205]]\n",
      "PERDIDAAAA despues: 0.023291831836104393\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "[[[0.9333722 ]\n",
      "  [0.93526608]\n",
      "  [0.93573284]\n",
      "  [0.93752855]\n",
      "  [0.9392615 ]\n",
      "  [0.94089597]\n",
      "  [0.94281363]\n",
      "  [0.94287056]]]\n",
      "ejemplar: [0.9333722  0.93526608 0.93573284 0.93752855 0.9392615  0.94089597\n",
      " 0.94281363 0.94287056]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.94416517]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[0.9333722  0.93526608 0.93573284 0.93752855 0.9392615  0.94089597\n",
      "  0.94281363 0.94287056]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03385405242443085\n",
      "Predicción post entrenamiento : [[0.9425876]]\n",
      "PERDIDAAAA despues: 0.033276017755270004\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "[[[0.93526608]\n",
      "  [0.93573284]\n",
      "  [0.93752855]\n",
      "  [0.9392615 ]\n",
      "  [0.94089597]\n",
      "  [0.94281363]\n",
      "  [0.94287056]\n",
      "  [0.94416517]]]\n",
      "ejemplar: [0.93526608 0.93573284 0.93752855 0.9392615  0.94089597 0.94281363\n",
      " 0.94287056 0.94416517]\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.9439144]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[0.93526608 0.93573284 0.93752855 0.9392615  0.94089597 0.94281363\n",
      "  0.94287056 0.94416517]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06683318316936493\n",
      "Predicción post entrenamiento : [[0.94219023]]\n",
      "PERDIDAAAA despues: 0.06594467908143997\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "[[[0.93573284]\n",
      "  [0.93752855]\n",
      "  [0.9392615 ]\n",
      "  [0.94089597]\n",
      "  [0.94281363]\n",
      "  [0.94287056]\n",
      "  [0.94416517]\n",
      "  [0.94391441]]]\n",
      "ejemplar: [0.93573284 0.93752855 0.9392615  0.94089597 0.94281363 0.94287056\n",
      " 0.94416517 0.94391441]\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.9433622]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[0.93573284 0.93752855 0.9392615  0.94089597 0.94281363 0.94287056\n",
      "  0.94416517 0.94391441]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11435922235250473\n",
      "Predicción post entrenamiento : [[0.94176435]]\n",
      "PERDIDAAAA despues: 0.11328110843896866\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "[[[0.93752855]\n",
      "  [0.9392615 ]\n",
      "  [0.94089597]\n",
      "  [0.94281363]\n",
      "  [0.94287056]\n",
      "  [0.94416517]\n",
      "  [0.94391441]\n",
      "  [0.94336218]]]\n",
      "ejemplar: [0.93752855 0.9392615  0.94089597 0.94281363 0.94287056 0.94416517\n",
      " 0.94391441 0.94336218]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.94316137]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[0.93752855 0.9392615  0.94089597 0.94281363 0.94287056 0.94416517\n",
      "  0.94391441 0.94336218]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07745244354009628\n",
      "Predicción post entrenamiento : [[0.94098645]]\n",
      "PERDIDAAAA despues: 0.07624660432338715\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "[[[0.9392615 ]\n",
      "  [0.94089597]\n",
      "  [0.94281363]\n",
      "  [0.94287056]\n",
      "  [0.94416517]\n",
      "  [0.94391441]\n",
      "  [0.94336218]\n",
      "  [0.94316137]]]\n",
      "ejemplar: [0.9392615  0.94089597 0.94281363 0.94287056 0.94416517 0.94391441\n",
      " 0.94336218 0.94316137]\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.9421926]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[0.9392615  0.94089597 0.94281363 0.94287056 0.94416517 0.94391441\n",
      "  0.94336218 0.94316137]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.054909348487854004\n",
      "Predicción post entrenamiento : [[0.94009924]]\n",
      "PERDIDAAAA despues: 0.053932659327983856\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "[[[0.94089597]\n",
      "  [0.94281363]\n",
      "  [0.94287056]\n",
      "  [0.94416517]\n",
      "  [0.94391441]\n",
      "  [0.94336218]\n",
      "  [0.94316137]\n",
      "  [0.94219261]]]\n",
      "ejemplar: [0.94089597 0.94281363 0.94287056 0.94416517 0.94391441 0.94336218\n",
      " 0.94316137 0.94219261]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9410458]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[0.94089597 0.94281363 0.94287056 0.94416517 0.94391441 0.94336218\n",
      "  0.94316137 0.94219261]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07627939432859421\n",
      "Predicción post entrenamiento : [[0.94007933]]\n",
      "PERDIDAAAA despues: 0.07574646174907684\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "[[[0.94281363]\n",
      "  [0.94287056]\n",
      "  [0.94416517]\n",
      "  [0.94391441]\n",
      "  [0.94336218]\n",
      "  [0.94316137]\n",
      "  [0.94219261]\n",
      "  [0.94104582]]]\n",
      "ejemplar: [0.94281363 0.94287056 0.94416517 0.94391441 0.94336218 0.94316137\n",
      " 0.94219261 0.94104582]\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.9406962]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[0.94281363 0.94287056 0.94416517 0.94391441 0.94336218 0.94316137\n",
      "  0.94219261 0.94104582]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05259867385029793\n",
      "Predicción post entrenamiento : [[0.93944293]]\n",
      "PERDIDAAAA despues: 0.05202539637684822\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "[[[0.94287056]\n",
      "  [0.94416517]\n",
      "  [0.94391441]\n",
      "  [0.94336218]\n",
      "  [0.94316137]\n",
      "  [0.94219261]\n",
      "  [0.94104582]\n",
      "  [0.94069618]]]\n",
      "ejemplar: [0.94287056 0.94416517 0.94391441 0.94336218 0.94316137 0.94219261\n",
      " 0.94104582 0.94069618]\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.9395419]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[0.94287056 0.94416517 0.94391441 0.94336218 0.94316137 0.94219261\n",
      "  0.94104582 0.94069618]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0687934160232544\n",
      "Predicción post entrenamiento : [[0.9378929]]\n",
      "PERDIDAAAA despues: 0.06793113797903061\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "[[[0.94416517]\n",
      "  [0.94391441]\n",
      "  [0.94336218]\n",
      "  [0.94316137]\n",
      "  [0.94219261]\n",
      "  [0.94104582]\n",
      "  [0.94069618]\n",
      "  [0.93954188]]]\n",
      "ejemplar: [0.94416517 0.94391441 0.94336218 0.94316137 0.94219261 0.94104582\n",
      " 0.94069618 0.93954188]\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.9379177]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[0.94416517 0.94391441 0.94336218 0.94316137 0.94219261 0.94104582\n",
      "  0.94069618 0.93954188]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03090914897620678\n",
      "Predicción post entrenamiento : [[0.93719816]]\n",
      "PERDIDAAAA despues: 0.030656659975647926\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "[[[0.94391441]\n",
      "  [0.94336218]\n",
      "  [0.94316137]\n",
      "  [0.94219261]\n",
      "  [0.94104582]\n",
      "  [0.94069618]\n",
      "  [0.93954188]\n",
      "  [0.93791771]]]\n",
      "ejemplar: [0.94391441 0.94336218 0.94316137 0.94219261 0.94104582 0.94069618\n",
      " 0.93954188 0.93791771]\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.9367259]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[0.94391441 0.94336218 0.94316137 0.94219261 0.94104582 0.94069618\n",
      "  0.93954188 0.93791771]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016815444454550743\n",
      "Predicción post entrenamiento : [[0.93616796]]\n",
      "PERDIDAAAA despues: 0.01667104847729206\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "[[[0.94336218]\n",
      "  [0.94316137]\n",
      "  [0.94219261]\n",
      "  [0.94104582]\n",
      "  [0.94069618]\n",
      "  [0.93954188]\n",
      "  [0.93791771]\n",
      "  [0.93672591]]]\n",
      "ejemplar: [0.94336218 0.94316137 0.94219261 0.94104582 0.94069618 0.93954188\n",
      " 0.93791771 0.93672591]\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.93556315]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[0.94336218 0.94316137 0.94219261 0.94104582 0.94069618 0.93954188\n",
      "  0.93791771 0.93672591]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014490192756056786\n",
      "Predicción post entrenamiento : [[0.9356731]]\n",
      "PERDIDAAAA despues: 0.014516680501401424\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "[[[0.94316137]\n",
      "  [0.94219261]\n",
      "  [0.94104582]\n",
      "  [0.94069618]\n",
      "  [0.93954188]\n",
      "  [0.93791771]\n",
      "  [0.93672591]\n",
      "  [0.93556315]]]\n",
      "ejemplar: [0.94316137 0.94219261 0.94104582 0.94069618 0.93954188 0.93791771\n",
      " 0.93672591 0.93556315]\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.93498594]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[0.94316137 0.94219261 0.94104582 0.94069618 0.93954188 0.93791771\n",
      "  0.93672591 0.93556315]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008264495409093797\n",
      "Predicción post entrenamiento : [[0.93455195]]\n",
      "PERDIDAAAA despues: 0.0008016856736503541\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "[[[0.94219261]\n",
      "  [0.94104582]\n",
      "  [0.94069618]\n",
      "  [0.93954188]\n",
      "  [0.93791771]\n",
      "  [0.93672591]\n",
      "  [0.93556315]\n",
      "  [0.93498594]]]\n",
      "ejemplar: [0.94219261 0.94104582 0.94069618 0.93954188 0.93791771 0.93672591\n",
      " 0.93556315 0.93498594]\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.93365026]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[0.94219261 0.94104582 0.94069618 0.93954188 0.93791771 0.93672591\n",
      "  0.93556315 0.93498594]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006788774044252932\n",
      "Predicción post entrenamiento : [[0.933832]]\n",
      "PERDIDAAAA despues: 0.0006694401381537318\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "[[[0.94104582]\n",
      "  [0.94069618]\n",
      "  [0.93954188]\n",
      "  [0.93791771]\n",
      "  [0.93672591]\n",
      "  [0.93556315]\n",
      "  [0.93498594]\n",
      "  [0.93365026]]]\n",
      "ejemplar: [0.94104582 0.94069618 0.93954188 0.93791771 0.93672591 0.93556315\n",
      " 0.93498594 0.93365026]\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.93290716]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[0.94104582 0.94069618 0.93954188 0.93791771 0.93672591 0.93556315\n",
      "  0.93498594 0.93365026]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000988958403468132\n",
      "Predicción post entrenamiento : [[0.9326356]]\n",
      "PERDIDAAAA despues: 0.0010061119683086872\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "[[[0.94069618]\n",
      "  [0.93954188]\n",
      "  [0.93791771]\n",
      "  [0.93672591]\n",
      "  [0.93556315]\n",
      "  [0.93498594]\n",
      "  [0.93365026]\n",
      "  [0.93290716]]]\n",
      "ejemplar: [0.94069618 0.93954188 0.93791771 0.93672591 0.93556315 0.93498594\n",
      " 0.93365026 0.93290716]\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.9317362]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[0.94069618 0.93954188 0.93791771 0.93672591 0.93556315 0.93498594\n",
      "  0.93365026 0.93290716]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0019104124512523413\n",
      "Predicción post entrenamiento : [[0.9317804]]\n",
      "PERDIDAAAA despues: 0.001914280466735363\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "[[[0.93954188]\n",
      "  [0.93791771]\n",
      "  [0.93672591]\n",
      "  [0.93556315]\n",
      "  [0.93498594]\n",
      "  [0.93365026]\n",
      "  [0.93290716]\n",
      "  [0.93173617]]]\n",
      "ejemplar: [0.93954188 0.93791771 0.93672591 0.93556315 0.93498594 0.93365026\n",
      " 0.93290716 0.93173617]\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.9306686]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[0.93954188 0.93791771 0.93672591 0.93556315 0.93498594 0.93365026\n",
      "  0.93290716 0.93173617]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014433423057198524\n",
      "Predicción post entrenamiento : [[0.9303917]]\n",
      "PERDIDAAAA despues: 0.0014223820762708783\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "[[[0.93791771]\n",
      "  [0.93672591]\n",
      "  [0.93556315]\n",
      "  [0.93498594]\n",
      "  [0.93365026]\n",
      "  [0.93290716]\n",
      "  [0.93173617]\n",
      "  [0.93066859]]]\n",
      "ejemplar: [0.93791771 0.93672591 0.93556315 0.93498594 0.93365026 0.93290716\n",
      " 0.93173617 0.93066859]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.92928475]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[0.93791771 0.93672591 0.93556315 0.93498594 0.93365026 0.93290716\n",
      "  0.93173617 0.93066859]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029206001199781895\n",
      "Predicción post entrenamiento : [[0.9291512]]\n",
      "PERDIDAAAA despues: 0.0029061806853860617\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "[[[0.93672591]\n",
      "  [0.93556315]\n",
      "  [0.93498594]\n",
      "  [0.93365026]\n",
      "  [0.93290716]\n",
      "  [0.93173617]\n",
      "  [0.93066859]\n",
      "  [0.92928475]]]\n",
      "ejemplar: [0.93672591 0.93556315 0.93498594 0.93365026 0.93290716 0.93173617\n",
      " 0.93066859 0.92928475]\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.92819655]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[0.93672591 0.93556315 0.93498594 0.93365026 0.93290716 0.93173617\n",
      "  0.93066859 0.92928475]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005985118914395571\n",
      "Predicción post entrenamiento : [[0.9286603]]\n",
      "PERDIDAAAA despues: 0.006057084538042545\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "[[[0.93556315]\n",
      "  [0.93498594]\n",
      "  [0.93365026]\n",
      "  [0.93290716]\n",
      "  [0.93173617]\n",
      "  [0.93066859]\n",
      "  [0.92928475]\n",
      "  [0.92819655]]]\n",
      "ejemplar: [0.93556315 0.93498594 0.93365026 0.93290716 0.93173617 0.93066859\n",
      " 0.92928475 0.92819655]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.9277496]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[0.93556315 0.93498594 0.93365026 0.93290716 0.93173617 0.93066859\n",
      "  0.92928475 0.92819655]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006217919755727053\n",
      "Predicción post entrenamiento : [[0.9283565]]\n",
      "PERDIDAAAA despues: 0.006314009428024292\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "[[[0.93498594]\n",
      "  [0.93365026]\n",
      "  [0.93290716]\n",
      "  [0.93173617]\n",
      "  [0.93066859]\n",
      "  [0.92928475]\n",
      "  [0.92819655]\n",
      "  [0.92774957]]]\n",
      "ejemplar: [0.93498594 0.93365026 0.93290716 0.93173617 0.93066859 0.92928475\n",
      " 0.92819655 0.92774957]\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.92748654]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[0.93498594 0.93365026 0.93290716 0.93173617 0.93066859 0.92928475\n",
      "  0.92819655 0.92774957]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012201833305880427\n",
      "Predicción post entrenamiento : [[0.9277278]]\n",
      "PERDIDAAAA despues: 0.001203385298140347\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "[[[0.93365026]\n",
      "  [0.93290716]\n",
      "  [0.93173617]\n",
      "  [0.93066859]\n",
      "  [0.92928475]\n",
      "  [0.92819655]\n",
      "  [0.92774957]\n",
      "  [0.92748654]]]\n",
      "ejemplar: [0.93365026 0.93290716 0.93173617 0.93066859 0.92928475 0.92819655\n",
      " 0.92774957 0.92748654]\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.9267322]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[0.93365026 0.93290716 0.93173617 0.93066859 0.92928475 0.92819655\n",
      "  0.92774957 0.92748654]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016900107730180025\n",
      "Predicción post entrenamiento : [[0.92609173]]\n",
      "PERDIDAAAA despues: 0.001743078581057489\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "[[[0.93290716]\n",
      "  [0.93173617]\n",
      "  [0.93066859]\n",
      "  [0.92928475]\n",
      "  [0.92819655]\n",
      "  [0.92774957]\n",
      "  [0.92748654]\n",
      "  [0.92673218]]]\n",
      "ejemplar: [0.93290716 0.93173617 0.93066859 0.92928475 0.92819655 0.92774957\n",
      " 0.92748654 0.92673218]\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.9251906]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[0.93290716 0.93173617 0.93066859 0.92928475 0.92819655 0.92774957\n",
      "  0.92748654 0.92673218]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00024118245346471667\n",
      "Predicción post entrenamiento : [[0.92524916]]\n",
      "PERDIDAAAA despues: 0.000239367873291485\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "[[[0.93173617]\n",
      "  [0.93066859]\n",
      "  [0.92928475]\n",
      "  [0.92819655]\n",
      "  [0.92774957]\n",
      "  [0.92748654]\n",
      "  [0.92673218]\n",
      "  [0.92519063]]]\n",
      "ejemplar: [0.93173617 0.93066859 0.92928475 0.92819655 0.92774957 0.92748654\n",
      " 0.92673218 0.92519063]\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.924286]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[0.93173617 0.93066859 0.92928475 0.92819655 0.92774957 0.92748654\n",
      "  0.92673218 0.92519063]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002323746681213379\n",
      "Predicción post entrenamiento : [[0.92455155]]\n",
      "PERDIDAAAA despues: 0.0022982165683060884\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "[[[0.93066859]\n",
      "  [0.92928475]\n",
      "  [0.92819655]\n",
      "  [0.92774957]\n",
      "  [0.92748654]\n",
      "  [0.92673218]\n",
      "  [0.92519063]\n",
      "  [0.92428601]]]\n",
      "ejemplar: [0.93066859 0.92928475 0.92819655 0.92774957 0.92748654 0.92673218\n",
      " 0.92519063 0.92428601]\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.92365336]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[0.93066859 0.92928475 0.92819655 0.92774957 0.92748654 0.92673218\n",
      "  0.92519063 0.92428601]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0053651342168450356\n",
      "Predicción post entrenamiento : [[0.9235797]]\n",
      "PERDIDAAAA despues: 0.005375931970775127\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "[[[0.92928475]\n",
      "  [0.92819655]\n",
      "  [0.92774957]\n",
      "  [0.92748654]\n",
      "  [0.92673218]\n",
      "  [0.92519063]\n",
      "  [0.92428601]\n",
      "  [0.92365336]]]\n",
      "ejemplar: [0.92928475 0.92819655 0.92774957 0.92748654 0.92673218 0.92519063\n",
      " 0.92428601 0.92365336]\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.92273176]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[0.92928475 0.92819655 0.92774957 0.92748654 0.92673218 0.92519063\n",
      "  0.92428601 0.92365336]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008093998185358942\n",
      "Predicción post entrenamiento : [[0.9228738]]\n",
      "PERDIDAAAA despues: 0.0008013380574993789\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "[[[0.92819655]\n",
      "  [0.92774957]\n",
      "  [0.92748654]\n",
      "  [0.92673218]\n",
      "  [0.92519063]\n",
      "  [0.92428601]\n",
      "  [0.92365336]\n",
      "  [0.92273176]]]\n",
      "ejemplar: [0.92819655 0.92774957 0.92748654 0.92673218 0.92519063 0.92428601\n",
      " 0.92365336 0.92273176]\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.92218226]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[0.92819655 0.92774957 0.92748654 0.92673218 0.92519063 0.92428601\n",
      "  0.92365336 0.92273176]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006972479750402272\n",
      "Predicción post entrenamiento : [[0.9221597]]\n",
      "PERDIDAAAA despues: 0.000696055474691093\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "[[[0.92774957]\n",
      "  [0.92748654]\n",
      "  [0.92673218]\n",
      "  [0.92519063]\n",
      "  [0.92428601]\n",
      "  [0.92365336]\n",
      "  [0.92273176]\n",
      "  [0.92218226]]]\n",
      "ejemplar: [0.92774957 0.92748654 0.92673218 0.92519063 0.92428601 0.92365336\n",
      " 0.92273176 0.92218226]\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.92155623]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[0.92774957 0.92748654 0.92673218 0.92519063 0.92428601 0.92365336\n",
      "  0.92273176 0.92218226]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001609208295121789\n",
      "Predicción post entrenamiento : [[0.9209972]]\n",
      "PERDIDAAAA despues: 0.0015646697720512748\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "[[[0.92748654]\n",
      "  [0.92673218]\n",
      "  [0.92519063]\n",
      "  [0.92428601]\n",
      "  [0.92365336]\n",
      "  [0.92273176]\n",
      "  [0.92218226]\n",
      "  [0.92155623]]]\n",
      "ejemplar: [0.92748654 0.92673218 0.92519063 0.92428601 0.92365336 0.92273176\n",
      " 0.92218226 0.92155623]\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.92029804]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[0.92748654 0.92673218 0.92519063 0.92428601 0.92365336 0.92273176\n",
      "  0.92218226 0.92155623]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.0314486644347198e-05\n",
      "Predicción post entrenamiento : [[0.92041796]]\n",
      "PERDIDAAAA despues: 1.109917229769053e-05\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "[[[0.92673218]\n",
      "  [0.92519063]\n",
      "  [0.92428601]\n",
      "  [0.92365336]\n",
      "  [0.92273176]\n",
      "  [0.92218226]\n",
      "  [0.92155623]\n",
      "  [0.92029804]]]\n",
      "ejemplar: [0.92673218 0.92519063 0.92428601 0.92365336 0.92273176 0.92218226\n",
      " 0.92155623 0.92029804]\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.9195504]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[0.92673218 0.92519063 0.92428601 0.92365336 0.92273176 0.92218226\n",
      "  0.92155623 0.92029804]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.157054599498224e-08\n",
      "Predicción post entrenamiento : [[0.9199021]]\n",
      "PERDIDAAAA despues: 1.0719137577552829e-08\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "[[[0.92519063]\n",
      "  [0.92428601]\n",
      "  [0.92365336]\n",
      "  [0.92273176]\n",
      "  [0.92218226]\n",
      "  [0.92155623]\n",
      "  [0.92029804]\n",
      "  [0.91955042]]]\n",
      "ejemplar: [0.92519063 0.92428601 0.92365336 0.92273176 0.92218226 0.92155623\n",
      " 0.92029804 0.91955042]\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.9189928]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[0.92519063 0.92428601 0.92365336 0.92273176 0.92218226 0.92155623\n",
      "  0.92029804 0.91955042]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018190211849287152\n",
      "Predicción post entrenamiento : [[0.91898566]]\n",
      "PERDIDAAAA despues: 0.0018196313176304102\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "[[[0.92428601]\n",
      "  [0.92365336]\n",
      "  [0.92273176]\n",
      "  [0.92218226]\n",
      "  [0.92155623]\n",
      "  [0.92029804]\n",
      "  [0.91955042]\n",
      "  [0.91899282]]]\n",
      "ejemplar: [0.92428601 0.92365336 0.92273176 0.92218226 0.92155623 0.92029804\n",
      " 0.91955042 0.91899282]\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.91827357]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[0.92428601 0.92365336 0.92273176 0.92218226 0.92155623 0.92029804\n",
      "  0.91955042 0.91899282]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0024955805856734514\n",
      "Predicción post entrenamiento : [[0.9183453]]\n",
      "PERDIDAAAA despues: 0.0024884215090423822\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "[[[0.92365336]\n",
      "  [0.92273176]\n",
      "  [0.92218226]\n",
      "  [0.92155623]\n",
      "  [0.92029804]\n",
      "  [0.91955042]\n",
      "  [0.91899282]\n",
      "  [0.91827357]]]\n",
      "ejemplar: [0.92365336 0.92273176 0.92218226 0.92155623 0.92029804 0.91955042\n",
      " 0.91899282 0.91827357]\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.91767067]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[0.92365336 0.92273176 0.92218226 0.92155623 0.92029804 0.91955042\n",
      "  0.91899282 0.91827357]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016078217886388302\n",
      "Predicción post entrenamiento : [[0.9178624]]\n",
      "PERDIDAAAA despues: 0.0015924812760204077\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "[[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "ejemplar: [0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      " 0.03448276 0.04223169]\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.23177692]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      "  0.03448276 0.04223169]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03447363153100014\n",
      "Predicción post entrenamiento : [[0.19763488]]\n",
      "PERDIDAAAA despues: 0.022960951551795006\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "[[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23177692]]]\n",
      "ejemplar: [0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      " 0.04223169 0.23177692]\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.18173097]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      "  0.04223169 0.23177692]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006007459480315447\n",
      "Predicción post entrenamiento : [[0.16091703]]\n",
      "PERDIDAAAA despues: 0.0032141937408596277\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "[[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23177692]\n",
      "  [0.18173097]]]\n",
      "ejemplar: [0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      " 0.23177692 0.18173097]\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.16477372]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      "  0.23177692 0.18173097]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00011172310769325122\n",
      "Predicción post entrenamiento : [[0.16278589]]\n",
      "PERDIDAAAA despues: 7.365219062194228e-05\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "[[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23177692]\n",
      "  [0.18173097]\n",
      "  [0.16477372]]]\n",
      "ejemplar: [0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.23177692\n",
      " 0.18173097 0.16477372]\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.17391218]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.23177692\n",
      "  0.18173097 0.16477372]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00032973475754261017\n",
      "Predicción post entrenamiento : [[0.17287673]]\n",
      "PERDIDAAAA despues: 0.00029320220346562564\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "[[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23177692]\n",
      "  [0.18173097]\n",
      "  [0.16477372]\n",
      "  [0.17391218]]]\n",
      "ejemplar: [0.05656722 0.02595893 0.03448276 0.04223169 0.23177692 0.18173097\n",
      " 0.16477372 0.17391218]\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.18488723]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[0.05656722 0.02595893 0.03448276 0.04223169 0.23177692 0.18173097\n",
      "  0.16477372 0.17391218]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0035229548811912537\n",
      "Predicción post entrenamiento : [[0.17830318]]\n",
      "PERDIDAAAA despues: 0.002784718992188573\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "[[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23177692]\n",
      "  [0.18173097]\n",
      "  [0.16477372]\n",
      "  [0.17391218]\n",
      "  [0.18488723]]]\n",
      "ejemplar: [0.02595893 0.03448276 0.04223169 0.23177692 0.18173097 0.16477372\n",
      " 0.17391218 0.18488723]\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.18713267]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[0.02595893 0.03448276 0.04223169 0.23177692 0.18173097 0.16477372\n",
      "  0.17391218 0.18488723]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017183268209919333\n",
      "Predicción post entrenamiento : [[0.18136677]]\n",
      "PERDIDAAAA despues: 0.0012735481141135097\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "[[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.23177692]\n",
      "  [0.18173097]\n",
      "  [0.16477372]\n",
      "  [0.17391218]\n",
      "  [0.18488723]\n",
      "  [0.18713267]]]\n",
      "ejemplar: [0.03448276 0.04223169 0.23177692 0.18173097 0.16477372 0.17391218\n",
      " 0.18488723 0.18713267]\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.20079623]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[0.03448276 0.04223169 0.23177692 0.18173097 0.16477372 0.17391218\n",
      "  0.18488723 0.18713267]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002952985232695937\n",
      "Predicción post entrenamiento : [[0.19492754]]\n",
      "PERDIDAAAA despues: 0.002349601360037923\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "[[[0.04223169]\n",
      "  [0.23177692]\n",
      "  [0.18173097]\n",
      "  [0.16477372]\n",
      "  [0.17391218]\n",
      "  [0.18488723]\n",
      "  [0.18713267]\n",
      "  [0.20079623]]]\n",
      "ejemplar: [0.04223169 0.23177692 0.18173097 0.16477372 0.17391218 0.18488723\n",
      " 0.18713267 0.20079623]\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.21825552]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[0.04223169 0.23177692 0.18173097 0.16477372 0.17391218 0.18488723\n",
      "  0.18713267 0.20079623]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004931723233312368\n",
      "Predicción post entrenamiento : [[0.21924403]]\n",
      "PERDIDAAAA despues: 0.0005380542716011405\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "[[[0.23177692]\n",
      "  [0.18173097]\n",
      "  [0.16477372]\n",
      "  [0.17391218]\n",
      "  [0.18488723]\n",
      "  [0.18713267]\n",
      "  [0.20079623]\n",
      "  [0.21825552]]]\n",
      "ejemplar: [0.23177692 0.18173097 0.16477372 0.17391218 0.18488723 0.18713267\n",
      " 0.20079623 0.21825552]\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.24680613]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[0.23177692 0.18173097 0.16477372 0.17391218 0.18488723 0.18713267\n",
      "  0.20079623 0.21825552]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002648864174261689\n",
      "Predicción post entrenamiento : [[0.24442431]]\n",
      "PERDIDAAAA despues: 0.00019302975852042437\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "[[[0.18173097]\n",
      "  [0.16477372]\n",
      "  [0.17391218]\n",
      "  [0.18488723]\n",
      "  [0.18713267]\n",
      "  [0.20079623]\n",
      "  [0.21825552]\n",
      "  [0.24680613]]]\n",
      "ejemplar: [0.18173097 0.16477372 0.17391218 0.18488723 0.18713267 0.20079623\n",
      " 0.21825552 0.24680613]\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.23537831]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[0.18173097 0.16477372 0.17391218 0.18488723 0.18713267 0.20079623\n",
      "  0.21825552 0.24680613]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007253310759551823\n",
      "Predicción post entrenamiento : [[0.23386791]]\n",
      "PERDIDAAAA despues: 0.0006462564342655241\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "[[[0.16477372]\n",
      "  [0.17391218]\n",
      "  [0.18488723]\n",
      "  [0.18713267]\n",
      "  [0.20079623]\n",
      "  [0.21825552]\n",
      "  [0.24680613]\n",
      "  [0.23537831]]]\n",
      "ejemplar: [0.16477372 0.17391218 0.18488723 0.18713267 0.20079623 0.21825552\n",
      " 0.24680613 0.23537831]\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.23527616]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[0.16477372 0.17391218 0.18488723 0.18713267 0.20079623 0.21825552\n",
      "  0.24680613 0.23537831]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005448864540085196\n",
      "Predicción post entrenamiento : [[0.23443335]]\n",
      "PERDIDAAAA despues: 0.0005062497220933437\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "[[[0.17391218]\n",
      "  [0.18488723]\n",
      "  [0.18713267]\n",
      "  [0.20079623]\n",
      "  [0.21825552]\n",
      "  [0.24680613]\n",
      "  [0.23537831]\n",
      "  [0.23527616]]]\n",
      "ejemplar: [0.17391218 0.18488723 0.18713267 0.20079623 0.21825552 0.24680613\n",
      " 0.23537831 0.23527616]\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.24100953]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[0.17391218 0.18488723 0.18713267 0.20079623 0.21825552 0.24680613\n",
      "  0.23537831 0.23527616]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011374113382771611\n",
      "Predicción post entrenamiento : [[0.24055181]]\n",
      "PERDIDAAAA despues: 0.001106747193261981\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "[[[0.18488723]\n",
      "  [0.18713267]\n",
      "  [0.20079623]\n",
      "  [0.21825552]\n",
      "  [0.24680613]\n",
      "  [0.23537831]\n",
      "  [0.23527616]\n",
      "  [0.24100953]]]\n",
      "ejemplar: [0.18488723 0.18713267 0.20079623 0.21825552 0.24680613 0.23537831\n",
      " 0.23527616 0.24100953]\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.24738121]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[0.18488723 0.18713267 0.20079623 0.21825552 0.24680613 0.23537831\n",
      "  0.23527616 0.24100953]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002962922677397728\n",
      "Predicción post entrenamiento : [[0.24468647]]\n",
      "PERDIDAAAA despues: 0.0026768199168145657\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "[[[0.18713267]\n",
      "  [0.20079623]\n",
      "  [0.21825552]\n",
      "  [0.24680613]\n",
      "  [0.23537831]\n",
      "  [0.23527616]\n",
      "  [0.24100953]\n",
      "  [0.24738121]]]\n",
      "ejemplar: [0.18713267 0.20079623 0.21825552 0.24680613 0.23537831 0.23527616\n",
      " 0.24100953 0.24738121]\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.2512577]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[0.18713267 0.20079623 0.21825552 0.24680613 0.23537831 0.23527616\n",
      "  0.24100953 0.24738121]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029631415382027626\n",
      "Predicción post entrenamiento : [[0.24988398]]\n",
      "PERDIDAAAA despues: 0.002815473824739456\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "[[[0.20079623]\n",
      "  [0.21825552]\n",
      "  [0.24680613]\n",
      "  [0.23537831]\n",
      "  [0.23527616]\n",
      "  [0.24100953]\n",
      "  [0.24738121]\n",
      "  [0.25125769]]]\n",
      "ejemplar: [0.20079623 0.21825552 0.24680613 0.23537831 0.23527616 0.24100953\n",
      " 0.24738121 0.25125769]\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.2579626]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[0.20079623 0.21825552 0.24680613 0.23537831 0.23527616 0.24100953\n",
      "  0.24738121 0.25125769]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0019100893987342715\n",
      "Predicción post entrenamiento : [[0.25730926]]\n",
      "PERDIDAAAA despues: 0.0018534068949520588\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "[[[0.21825552]\n",
      "  [0.24680613]\n",
      "  [0.23537831]\n",
      "  [0.23527616]\n",
      "  [0.24100953]\n",
      "  [0.24738121]\n",
      "  [0.25125769]\n",
      "  [0.25796261]]]\n",
      "ejemplar: [0.21825552 0.24680613 0.23537831 0.23527616 0.24100953 0.24738121\n",
      " 0.25125769 0.25796261]\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.26438212]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[0.21825552 0.24680613 0.23537831 0.23527616 0.24100953 0.24738121\n",
      "  0.25125769 0.25796261]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006898475345224142\n",
      "Predicción post entrenamiento : [[0.2595966]]\n",
      "PERDIDAAAA despues: 0.006126431282609701\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "[[[0.24680613]\n",
      "  [0.23537831]\n",
      "  [0.23527616]\n",
      "  [0.24100953]\n",
      "  [0.24738121]\n",
      "  [0.25125769]\n",
      "  [0.25796261]\n",
      "  [0.26438212]]]\n",
      "ejemplar: [0.24680613 0.23537831 0.23527616 0.24100953 0.24738121 0.25125769\n",
      " 0.25796261 0.26438212]\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.26442698]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[0.24680613 0.23537831 0.23527616 0.24100953 0.24738121 0.25125769\n",
      "  0.25796261 0.26438212]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007974677719175816\n",
      "Predicción post entrenamiento : [[0.26118982]]\n",
      "PERDIDAAAA despues: 0.007406993303447962\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "[[[0.23537831]\n",
      "  [0.23527616]\n",
      "  [0.24100953]\n",
      "  [0.24738121]\n",
      "  [0.25125769]\n",
      "  [0.25796261]\n",
      "  [0.26438212]\n",
      "  [0.26442698]]]\n",
      "ejemplar: [0.23537831 0.23527616 0.24100953 0.24738121 0.25125769 0.25796261\n",
      " 0.26438212 0.26442698]\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.26078087]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[0.23537831 0.23527616 0.24100953 0.24738121 0.25125769 0.25796261\n",
      "  0.26438212 0.26442698]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012718475423753262\n",
      "Predicción post entrenamiento : [[0.2584538]]\n",
      "PERDIDAAAA despues: 0.012199011631309986\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "[[[0.23527616]\n",
      "  [0.24100953]\n",
      "  [0.24738121]\n",
      "  [0.25125769]\n",
      "  [0.25796261]\n",
      "  [0.26438212]\n",
      "  [0.26442698]\n",
      "  [0.26078087]]]\n",
      "ejemplar: [0.23527616 0.24100953 0.24738121 0.25125769 0.25796261 0.26438212\n",
      " 0.26442698 0.26078087]\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.261045]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[0.23527616 0.24100953 0.24738121 0.25125769 0.25796261 0.26438212\n",
      "  0.26442698 0.26078087]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01044317428022623\n",
      "Predicción post entrenamiento : [[0.25741035]]\n",
      "PERDIDAAAA despues: 0.009713519364595413\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "[[[0.24100953]\n",
      "  [0.24738121]\n",
      "  [0.25125769]\n",
      "  [0.25796261]\n",
      "  [0.26438212]\n",
      "  [0.26442698]\n",
      "  [0.26078087]\n",
      "  [0.26104501]]]\n",
      "ejemplar: [0.24100953 0.24738121 0.25125769 0.25796261 0.26438212 0.26442698\n",
      " 0.26078087 0.26104501]\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.2609056]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[0.24100953 0.24738121 0.25125769 0.25796261 0.26438212 0.26442698\n",
      "  0.26078087 0.26104501]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0047240909188985825\n",
      "Predicción post entrenamiento : [[0.25900766]]\n",
      "PERDIDAAAA despues: 0.004466795828193426\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "[[[0.24738121]\n",
      "  [0.25125769]\n",
      "  [0.25796261]\n",
      "  [0.26438212]\n",
      "  [0.26442698]\n",
      "  [0.26078087]\n",
      "  [0.26104501]\n",
      "  [0.26090559]]]\n",
      "ejemplar: [0.24738121 0.25125769 0.25796261 0.26438212 0.26442698 0.26078087\n",
      " 0.26104501 0.26090559]\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.26212254]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[0.24738121 0.25125769 0.25796261 0.26438212 0.26442698 0.26078087\n",
      "  0.26104501 0.26090559]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005798534490168095\n",
      "Predicción post entrenamiento : [[0.26037446]]\n",
      "PERDIDAAAA despues: 0.005535363219678402\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "[[[0.25125769]\n",
      "  [0.25796261]\n",
      "  [0.26438212]\n",
      "  [0.26442698]\n",
      "  [0.26078087]\n",
      "  [0.26104501]\n",
      "  [0.26090559]\n",
      "  [0.26212254]]]\n",
      "ejemplar: [0.25125769 0.25796261 0.26438212 0.26442698 0.26078087 0.26104501\n",
      " 0.26090559 0.26212254]\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.26277375]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[0.25125769 0.25796261 0.26438212 0.26442698 0.26078087 0.26104501\n",
      "  0.26090559 0.26212254]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.7447611753595993e-05\n",
      "Predicción post entrenamiento : [[0.26331308]]\n",
      "PERDIDAAAA despues: 1.3232870514912065e-05\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "[[[0.25796261]\n",
      "  [0.26438212]\n",
      "  [0.26442698]\n",
      "  [0.26078087]\n",
      "  [0.26104501]\n",
      "  [0.26090559]\n",
      "  [0.26212254]\n",
      "  [0.26277375]]]\n",
      "ejemplar: [0.25796261 0.26438212 0.26442698 0.26078087 0.26104501 0.26090559\n",
      " 0.26212254 0.26277375]\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.2653444]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[0.25796261 0.26438212 0.26442698 0.26078087 0.26104501 0.26090559\n",
      "  0.26212254 0.26277375]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00073863664874807\n",
      "Predicción post entrenamiento : [[0.26536506]]\n",
      "PERDIDAAAA despues: 0.0007375144632533193\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "[[[0.26438212]\n",
      "  [0.26442698]\n",
      "  [0.26078087]\n",
      "  [0.26104501]\n",
      "  [0.26090559]\n",
      "  [0.26212254]\n",
      "  [0.26277375]\n",
      "  [0.26534441]]]\n",
      "ejemplar: [0.26438212 0.26442698 0.26078087 0.26104501 0.26090559 0.26212254\n",
      " 0.26277375 0.26534441]\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.26624855]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[0.26438212 0.26442698 0.26078087 0.26104501 0.26090559 0.26212254\n",
      "  0.26277375 0.26534441]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0026479014195501804\n",
      "Predicción post entrenamiento : [[0.2669216]]\n",
      "PERDIDAAAA despues: 0.00257908646017313\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "[[[0.26442698]\n",
      "  [0.26078087]\n",
      "  [0.26104501]\n",
      "  [0.26090559]\n",
      "  [0.26212254]\n",
      "  [0.26277375]\n",
      "  [0.26534441]\n",
      "  [0.26624855]]]\n",
      "ejemplar: [0.26442698 0.26078087 0.26104501 0.26090559 0.26212254 0.26277375\n",
      " 0.26534441 0.26624855]\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.2665093]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[0.26442698 0.26078087 0.26104501 0.26090559 0.26212254 0.26277375\n",
      "  0.26534441 0.26624855]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0021307659335434437\n",
      "Predicción post entrenamiento : [[0.26730788]]\n",
      "PERDIDAAAA despues: 0.002057678299024701\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "[[[0.26078087]\n",
      "  [0.26104501]\n",
      "  [0.26090559]\n",
      "  [0.26212254]\n",
      "  [0.26277375]\n",
      "  [0.26534441]\n",
      "  [0.26624855]\n",
      "  [0.26650929]]]\n",
      "ejemplar: [0.26078087 0.26104501 0.26090559 0.26212254 0.26277375 0.26534441\n",
      " 0.26624855 0.26650929]\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.26687303]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[0.26078087 0.26104501 0.26090559 0.26212254 0.26277375 0.26534441\n",
      "  0.26624855 0.26650929]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004911643918603659\n",
      "Predicción post entrenamiento : [[0.2671025]]\n",
      "PERDIDAAAA despues: 0.0004810455720871687\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "[[[0.26104501]\n",
      "  [0.26090559]\n",
      "  [0.26212254]\n",
      "  [0.26277375]\n",
      "  [0.26534441]\n",
      "  [0.26624855]\n",
      "  [0.26650929]\n",
      "  [0.26687303]]]\n",
      "ejemplar: [0.26104501 0.26090559 0.26212254 0.26277375 0.26534441 0.26624855\n",
      " 0.26650929 0.26687303]\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.26752672]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[0.26104501 0.26090559 0.26212254 0.26277375 0.26534441 0.26624855\n",
      "  0.26650929 0.26687303]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00023437752679456025\n",
      "Predicción post entrenamiento : [[0.26768166]]\n",
      "PERDIDAAAA despues: 0.00022965739481151104\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "[[[0.26090559]\n",
      "  [0.26212254]\n",
      "  [0.26277375]\n",
      "  [0.26534441]\n",
      "  [0.26624855]\n",
      "  [0.26650929]\n",
      "  [0.26687303]\n",
      "  [0.26752672]]]\n",
      "ejemplar: [0.26090559 0.26212254 0.26277375 0.26534441 0.26624855 0.26650929\n",
      " 0.26687303 0.26752672]\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.2682277]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[0.26090559 0.26212254 0.26277375 0.26534441 0.26624855 0.26650929\n",
      "  0.26687303 0.26752672]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009777270024642348\n",
      "Predicción post entrenamiento : [[0.268225]]\n",
      "PERDIDAAAA despues: 0.0009778947569429874\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "[[[0.26212254]\n",
      "  [0.26277375]\n",
      "  [0.26534441]\n",
      "  [0.26624855]\n",
      "  [0.26650929]\n",
      "  [0.26687303]\n",
      "  [0.26752672]\n",
      "  [0.2682277 ]]]\n",
      "ejemplar: [0.26212254 0.26277375 0.26534441 0.26624855 0.26650929 0.26687303\n",
      " 0.26752672 0.2682277 ]\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.2690034]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[0.26212254 0.26277375 0.26534441 0.26624855 0.26650929 0.26687303\n",
      "  0.26752672 0.2682277 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.7041445213835686e-05\n",
      "Predicción post entrenamiento : [[0.26874527]]\n",
      "PERDIDAAAA despues: 5.064876677352004e-05\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "[[[0.26277375]\n",
      "  [0.26534441]\n",
      "  [0.26624855]\n",
      "  [0.26650929]\n",
      "  [0.26687303]\n",
      "  [0.26752672]\n",
      "  [0.2682277 ]\n",
      "  [0.26900339]]]\n",
      "ejemplar: [0.26277375 0.26534441 0.26624855 0.26650929 0.26687303 0.26752672\n",
      " 0.2682277  0.26900339]\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.26947337]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[0.26277375 0.26534441 0.26624855 0.26650929 0.26687303 0.26752672\n",
      "  0.2682277  0.26900339]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.7314670660416596e-05\n",
      "Predicción post entrenamiento : [[0.269403]]\n",
      "PERDIDAAAA despues: 2.805510666803457e-05\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "[[[0.26534441]\n",
      "  [0.26624855]\n",
      "  [0.26650929]\n",
      "  [0.26687303]\n",
      "  [0.26752672]\n",
      "  [0.2682277 ]\n",
      "  [0.26900339]\n",
      "  [0.26947337]]]\n",
      "ejemplar: [0.26534441 0.26624855 0.26650929 0.26687303 0.26752672 0.2682277\n",
      " 0.26900339 0.26947337]\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.27018854]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[0.26534441 0.26624855 0.26650929 0.26687303 0.26752672 0.2682277\n",
      "  0.26900339 0.26947337]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.794251122395508e-05\n",
      "Predicción post entrenamiento : [[0.27079535]]\n",
      "PERDIDAAAA despues: 2.1895499230595306e-05\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "[[[0.26624855]\n",
      "  [0.26650929]\n",
      "  [0.26687303]\n",
      "  [0.26752672]\n",
      "  [0.2682277 ]\n",
      "  [0.26900339]\n",
      "  [0.26947337]\n",
      "  [0.27018854]]]\n",
      "ejemplar: [0.26624855 0.26650929 0.26687303 0.26752672 0.2682277  0.26900339\n",
      " 0.26947337 0.27018854]\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.27119455]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[0.26624855 0.26650929 0.26687303 0.26752672 0.2682277  0.26900339\n",
      "  0.26947337 0.27018854]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004039798863232136\n",
      "Predicción post entrenamiento : [[0.27271107]]\n",
      "PERDIDAAAA despues: 0.0038493203464895487\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "[[[0.26650929]\n",
      "  [0.26687303]\n",
      "  [0.26752672]\n",
      "  [0.2682277 ]\n",
      "  [0.26900339]\n",
      "  [0.26947337]\n",
      "  [0.27018854]\n",
      "  [0.27119455]]]\n",
      "ejemplar: [0.26650929 0.26687303 0.26752672 0.2682277  0.26900339 0.26947337\n",
      " 0.27018854 0.27119455]\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.27304086]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[0.26650929 0.26687303 0.26752672 0.2682277  0.26900339 0.26947337\n",
      "  0.27018854 0.27119455]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006828580051660538\n",
      "Predicción post entrenamiento : [[0.2737278]]\n",
      "PERDIDAAAA despues: 0.00671552075073123\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "[[[0.26687303]\n",
      "  [0.26752672]\n",
      "  [0.2682277 ]\n",
      "  [0.26900339]\n",
      "  [0.26947337]\n",
      "  [0.27018854]\n",
      "  [0.27119455]\n",
      "  [0.27304086]]]\n",
      "ejemplar: [0.26687303 0.26752672 0.2682277  0.26900339 0.26947337 0.27018854\n",
      " 0.27119455 0.27304086]\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.2741354]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[0.26687303 0.26752672 0.2682277  0.26900339 0.26947337 0.27018854\n",
      "  0.27119455 0.27304086]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003913227003067732\n",
      "Predicción post entrenamiento : [[0.27394432]]\n",
      "PERDIDAAAA despues: 0.003937171306461096\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "[[[0.26752672]\n",
      "  [0.2682277 ]\n",
      "  [0.26900339]\n",
      "  [0.26947337]\n",
      "  [0.27018854]\n",
      "  [0.27119455]\n",
      "  [0.27304086]\n",
      "  [0.27413541]]]\n",
      "ejemplar: [0.26752672 0.2682277  0.26900339 0.26947337 0.27018854 0.27119455\n",
      " 0.27304086 0.27413541]\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.27443218]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[0.26752672 0.2682277  0.26900339 0.26947337 0.27018854 0.27119455\n",
      "  0.27304086 0.27413541]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0034998413175344467\n",
      "Predicción post entrenamiento : [[0.2757892]]\n",
      "PERDIDAAAA despues: 0.003341121831908822\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "[[[0.2682277 ]\n",
      "  [0.26900339]\n",
      "  [0.26947337]\n",
      "  [0.27018854]\n",
      "  [0.27119455]\n",
      "  [0.27304086]\n",
      "  [0.27413541]\n",
      "  [0.27443218]]]\n",
      "ejemplar: [0.2682277  0.26900339 0.26947337 0.27018854 0.27119455 0.27304086\n",
      " 0.27413541 0.27443218]\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.2763134]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[0.2682277  0.26900339 0.26947337 0.27018854 0.27119455 0.27304086\n",
      "  0.27413541 0.27443218]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011755158193409443\n",
      "Predicción post entrenamiento : [[0.2780685]]\n",
      "PERDIDAAAA despues: 0.011377654038369656\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "[[[0.26900339]\n",
      "  [0.26947337]\n",
      "  [0.27018854]\n",
      "  [0.27119455]\n",
      "  [0.27304086]\n",
      "  [0.27413541]\n",
      "  [0.27443218]\n",
      "  [0.27631339]]]\n",
      "ejemplar: [0.26900339 0.26947337 0.27018854 0.27119455 0.27304086 0.27413541\n",
      " 0.27443218 0.27631339]\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.2786344]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[0.26900339 0.26947337 0.27018854 0.27119455 0.27304086 0.27413541\n",
      "  0.27443218 0.27631339]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08553406596183777\n",
      "Predicción post entrenamiento : [[0.28256845]]\n",
      "PERDIDAAAA despues: 0.08324842154979706\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "[[[0.26947337]\n",
      "  [0.27018854]\n",
      "  [0.27119455]\n",
      "  [0.27304086]\n",
      "  [0.27413541]\n",
      "  [0.27443218]\n",
      "  [0.27631339]\n",
      "  [0.2786344 ]]]\n",
      "ejemplar: [0.26947337 0.27018854 0.27119455 0.27304086 0.27413541 0.27443218\n",
      " 0.27631339 0.2786344 ]\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.28318197]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[0.26947337 0.27018854 0.27119455 0.27304086 0.27413541 0.27443218\n",
      "  0.27631339 0.2786344 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0980307012796402\n",
      "Predicción post entrenamiento : [[0.28734383]]\n",
      "PERDIDAAAA despues: 0.09544187784194946\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "[[[0.27018854]\n",
      "  [0.27119455]\n",
      "  [0.27304086]\n",
      "  [0.27413541]\n",
      "  [0.27443218]\n",
      "  [0.27631339]\n",
      "  [0.2786344 ]\n",
      "  [0.28318197]]]\n",
      "ejemplar: [0.27018854 0.27119455 0.27304086 0.27413541 0.27443218 0.27631339\n",
      " 0.2786344  0.28318197]\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.28811482]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[0.27018854 0.27119455 0.27304086 0.27413541 0.27443218 0.27631339\n",
      "  0.2786344  0.28318197]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08206429332494736\n",
      "Predicción post entrenamiento : [[0.2918006]]\n",
      "PERDIDAAAA despues: 0.07996615767478943\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "[[[0.27119455]\n",
      "  [0.27304086]\n",
      "  [0.27413541]\n",
      "  [0.27443218]\n",
      "  [0.27631339]\n",
      "  [0.2786344 ]\n",
      "  [0.28318197]\n",
      "  [0.28811482]]]\n",
      "ejemplar: [0.27119455 0.27304086 0.27413541 0.27443218 0.27631339 0.2786344\n",
      " 0.28318197 0.28811482]\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.29274717]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[0.27119455 0.27304086 0.27413541 0.27443218 0.27631339 0.2786344\n",
      "  0.28318197 0.28811482]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09834931790828705\n",
      "Predicción post entrenamiento : [[0.29667345]]\n",
      "PERDIDAAAA despues: 0.09590211510658264\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "[[[0.27304086]\n",
      "  [0.27413541]\n",
      "  [0.27443218]\n",
      "  [0.27631339]\n",
      "  [0.2786344 ]\n",
      "  [0.28318197]\n",
      "  [0.28811482]\n",
      "  [0.29274717]]]\n",
      "ejemplar: [0.27304086 0.27413541 0.27443218 0.27631339 0.2786344  0.28318197\n",
      " 0.28811482 0.29274717]\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.29781932]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[0.27304086 0.27413541 0.27443218 0.27631339 0.2786344  0.28318197\n",
      "  0.28811482 0.29274717]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08227593451738358\n",
      "Predicción post entrenamiento : [[0.30128953]]\n",
      "PERDIDAAAA despues: 0.08029720187187195\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "[[[0.27413541]\n",
      "  [0.27443218]\n",
      "  [0.27631339]\n",
      "  [0.2786344 ]\n",
      "  [0.28318197]\n",
      "  [0.28811482]\n",
      "  [0.29274717]\n",
      "  [0.29781932]]]\n",
      "ejemplar: [0.27413541 0.27443218 0.27631339 0.2786344  0.28318197 0.28811482\n",
      " 0.29274717 0.29781932]\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.302544]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[0.27413541 0.27443218 0.27631339 0.2786344  0.28318197 0.28811482\n",
      "  0.29274717 0.29781932]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07087723165750504\n",
      "Predicción post entrenamiento : [[0.305621]]\n",
      "PERDIDAAAA despues: 0.06924833357334137\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "[[[0.27443218]\n",
      "  [0.27631339]\n",
      "  [0.2786344 ]\n",
      "  [0.28318197]\n",
      "  [0.28811482]\n",
      "  [0.29274717]\n",
      "  [0.29781932]\n",
      "  [0.302544  ]]]\n",
      "ejemplar: [0.27443218 0.27631339 0.2786344  0.28318197 0.28811482 0.29274717\n",
      " 0.29781932 0.302544  ]\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.30725557]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[0.27443218 0.27631339 0.2786344  0.28318197 0.28811482 0.29274717\n",
      "  0.29781932 0.302544  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11257269233465195\n",
      "Predicción post entrenamiento : [[0.3114066]]\n",
      "PERDIDAAAA despues: 0.1098044142127037\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "[[[0.27631339]\n",
      "  [0.2786344 ]\n",
      "  [0.28318197]\n",
      "  [0.28811482]\n",
      "  [0.29274717]\n",
      "  [0.29781932]\n",
      "  [0.302544  ]\n",
      "  [0.30725557]]]\n",
      "ejemplar: [0.27631339 0.2786344  0.28318197 0.28811482 0.29274717 0.29781932\n",
      " 0.302544   0.30725557]\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.31374404]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[0.27631339 0.2786344  0.28318197 0.28811482 0.29274717 0.29781932\n",
      "  0.302544   0.30725557]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12111442536115646\n",
      "Predicción post entrenamiento : [[0.31757104]]\n",
      "PERDIDAAAA despues: 0.1184653639793396\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "[[[0.2786344 ]\n",
      "  [0.28318197]\n",
      "  [0.28811482]\n",
      "  [0.29274717]\n",
      "  [0.29781932]\n",
      "  [0.302544  ]\n",
      "  [0.30725557]\n",
      "  [0.31374404]]]\n",
      "ejemplar: [0.2786344  0.28318197 0.28811482 0.29274717 0.29781932 0.302544\n",
      " 0.30725557 0.31374404]\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.32041556]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[0.2786344  0.28318197 0.28811482 0.29274717 0.29781932 0.302544\n",
      "  0.30725557 0.31374404]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12431224435567856\n",
      "Predicción post entrenamiento : [[0.32460442]]\n",
      "PERDIDAAAA despues: 0.12137597799301147\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "[[[0.28318197]\n",
      "  [0.28811482]\n",
      "  [0.29274717]\n",
      "  [0.29781932]\n",
      "  [0.302544  ]\n",
      "  [0.30725557]\n",
      "  [0.31374404]\n",
      "  [0.32041556]]]\n",
      "ejemplar: [0.28318197 0.28811482 0.29274717 0.29781932 0.302544   0.30725557\n",
      " 0.31374404 0.32041556]\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.32798398]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[0.28318197 0.28811482 0.29274717 0.29781932 0.302544   0.30725557\n",
      "  0.31374404 0.32041556]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14637765288352966\n",
      "Predicción post entrenamiento : [[0.33219463]]\n",
      "PERDIDAAAA despues: 0.1431734561920166\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "[[[0.28811482]\n",
      "  [0.29274717]\n",
      "  [0.29781932]\n",
      "  [0.302544  ]\n",
      "  [0.30725557]\n",
      "  [0.31374404]\n",
      "  [0.32041556]\n",
      "  [0.32798398]]]\n",
      "ejemplar: [0.28811482 0.29274717 0.29781932 0.302544   0.30725557 0.31374404\n",
      " 0.32041556 0.32798398]\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.33571315]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[0.28811482 0.29274717 0.29781932 0.302544   0.30725557 0.31374404\n",
      "  0.32041556 0.32798398]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1356283575296402\n",
      "Predicción post entrenamiento : [[0.3397068]]\n",
      "PERDIDAAAA despues: 0.1327027529478073\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "[[[0.29274717]\n",
      "  [0.29781932]\n",
      "  [0.302544  ]\n",
      "  [0.30725557]\n",
      "  [0.31374404]\n",
      "  [0.32041556]\n",
      "  [0.32798398]\n",
      "  [0.33571315]]]\n",
      "ejemplar: [0.29274717 0.29781932 0.302544   0.30725557 0.31374404 0.32041556\n",
      " 0.32798398 0.33571315]\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.3433411]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[0.29274717 0.29781932 0.302544   0.30725557 0.31374404 0.32041556\n",
      "  0.32798398 0.33571315]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14737644791603088\n",
      "Predicción post entrenamiento : [[0.34739166]]\n",
      "PERDIDAAAA despues: 0.14428287744522095\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "[[[0.29781932]\n",
      "  [0.302544  ]\n",
      "  [0.30725557]\n",
      "  [0.31374404]\n",
      "  [0.32041556]\n",
      "  [0.32798398]\n",
      "  [0.33571315]\n",
      "  [0.34334111]]]\n",
      "ejemplar: [0.29781932 0.302544   0.30725557 0.31374404 0.32041556 0.32798398\n",
      " 0.33571315 0.34334111]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.35128745]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[0.29781932 0.302544   0.30725557 0.31374404 0.32041556 0.32798398\n",
      "  0.33571315 0.34334111]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13786418735980988\n",
      "Predicción post entrenamiento : [[0.3550678]]\n",
      "PERDIDAAAA despues: 0.13507118821144104\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "[[[0.302544  ]\n",
      "  [0.30725557]\n",
      "  [0.31374404]\n",
      "  [0.32041556]\n",
      "  [0.32798398]\n",
      "  [0.33571315]\n",
      "  [0.34334111]\n",
      "  [0.35128745]]]\n",
      "ejemplar: [0.302544   0.30725557 0.31374404 0.32041556 0.32798398 0.33571315\n",
      " 0.34334111 0.35128745]\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.35922155]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[0.302544   0.30725557 0.31374404 0.32041556 0.32798398 0.33571315\n",
      "  0.34334111 0.35128745]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.17021594941616058\n",
      "Predicción post entrenamiento : [[0.36361086]]\n",
      "PERDIDAAAA despues: 0.1666133999824524\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "[[[0.30725557]\n",
      "  [0.31374404]\n",
      "  [0.32041556]\n",
      "  [0.32798398]\n",
      "  [0.33571315]\n",
      "  [0.34334111]\n",
      "  [0.35128745]\n",
      "  [0.35922155]]]\n",
      "ejemplar: [0.30725557 0.31374404 0.32041556 0.32798398 0.33571315 0.34334111\n",
      " 0.35128745 0.35922155]\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.3682073]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[0.30725557 0.31374404 0.32041556 0.32798398 0.33571315 0.34334111\n",
      "  0.35128745 0.35922155]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1269625723361969\n",
      "Predicción post entrenamiento : [[0.3717901]]\n",
      "PERDIDAAAA despues: 0.12442217767238617\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "[[[0.31374404]\n",
      "  [0.32041556]\n",
      "  [0.32798398]\n",
      "  [0.33571315]\n",
      "  [0.34334111]\n",
      "  [0.35128745]\n",
      "  [0.35922155]\n",
      "  [0.36820731]]]\n",
      "ejemplar: [0.31374404 0.32041556 0.32798398 0.33571315 0.34334111 0.35128745\n",
      " 0.35922155 0.36820731]\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.37695634]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[0.31374404 0.32041556 0.32798398 0.33571315 0.34334111 0.35128745\n",
      "  0.35922155 0.36820731]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08649560809135437\n",
      "Predicción post entrenamiento : [[0.3801133]]\n",
      "PERDIDAAAA despues: 0.08464863896369934\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "[[[0.32041556]\n",
      "  [0.32798398]\n",
      "  [0.33571315]\n",
      "  [0.34334111]\n",
      "  [0.35128745]\n",
      "  [0.35922155]\n",
      "  [0.36820731]\n",
      "  [0.37695634]]]\n",
      "ejemplar: [0.32041556 0.32798398 0.33571315 0.34334111 0.35128745 0.35922155\n",
      " 0.36820731 0.37695634]\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.38554853]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[0.32041556 0.32798398 0.33571315 0.34334111 0.35128745 0.35922155\n",
      "  0.36820731 0.37695634]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0830715149641037\n",
      "Predicción post entrenamiento : [[0.3885103]]\n",
      "PERDIDAAAA despues: 0.08137300610542297\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "[[[0.32798398]\n",
      "  [0.33571315]\n",
      "  [0.34334111]\n",
      "  [0.35128745]\n",
      "  [0.35922155]\n",
      "  [0.36820731]\n",
      "  [0.37695634]\n",
      "  [0.38554853]]]\n",
      "ejemplar: [0.32798398 0.33571315 0.34334111 0.35128745 0.35922155 0.36820731\n",
      " 0.37695634 0.38554853]\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.3942433]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[0.32798398 0.33571315 0.34334111 0.35128745 0.35922155 0.36820731\n",
      "  0.37695634 0.38554853]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10253347456455231\n",
      "Predicción post entrenamiento : [[0.3975349]]\n",
      "PERDIDAAAA despues: 0.10043630748987198\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "[[[0.33571315]\n",
      "  [0.34334111]\n",
      "  [0.35128745]\n",
      "  [0.35922155]\n",
      "  [0.36820731]\n",
      "  [0.37695634]\n",
      "  [0.38554853]\n",
      "  [0.3942433 ]]]\n",
      "ejemplar: [0.33571315 0.34334111 0.35128745 0.35922155 0.36820731 0.37695634\n",
      " 0.38554853 0.3942433 ]\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.4034178]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[0.33571315 0.34334111 0.35128745 0.35922155 0.36820731 0.37695634\n",
      "  0.38554853 0.3942433 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1159265860915184\n",
      "Predicción post entrenamiento : [[0.40683654]]\n",
      "PERDIDAAAA despues: 0.11361025273799896\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "[[[0.34334111]\n",
      "  [0.35128745]\n",
      "  [0.35922155]\n",
      "  [0.36820731]\n",
      "  [0.37695634]\n",
      "  [0.38554853]\n",
      "  [0.3942433 ]\n",
      "  [0.4034178 ]]]\n",
      "ejemplar: [0.34334111 0.35128745 0.35922155 0.36820731 0.37695634 0.38554853\n",
      " 0.3942433  0.4034178 ]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.41287407]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[0.34334111 0.35128745 0.35922155 0.36820731 0.37695634 0.38554853\n",
      "  0.3942433  0.4034178 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0959227904677391\n",
      "Predicción post entrenamiento : [[0.41526258]]\n",
      "PERDIDAAAA despues: 0.0944489911198616\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "[[[0.35128745]\n",
      "  [0.35922155]\n",
      "  [0.36820731]\n",
      "  [0.37695634]\n",
      "  [0.38554853]\n",
      "  [0.3942433 ]\n",
      "  [0.4034178 ]\n",
      "  [0.41287407]]]\n",
      "ejemplar: [0.35128745 0.35922155 0.36820731 0.37695634 0.38554853 0.3942433\n",
      " 0.4034178  0.41287407]\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.42152378]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[0.35128745 0.35922155 0.36820731 0.37695634 0.38554853 0.3942433\n",
      "  0.4034178  0.41287407]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07718260586261749\n",
      "Predicción post entrenamiento : [[0.4243015]]\n",
      "PERDIDAAAA despues: 0.07564692199230194\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "[[[0.35922155]\n",
      "  [0.36820731]\n",
      "  [0.37695634]\n",
      "  [0.38554853]\n",
      "  [0.3942433 ]\n",
      "  [0.4034178 ]\n",
      "  [0.41287407]\n",
      "  [0.42152378]]]\n",
      "ejemplar: [0.35922155 0.36820731 0.37695634 0.38554853 0.3942433  0.4034178\n",
      " 0.41287407 0.42152378]\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.43076015]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[0.35922155 0.36820731 0.37695634 0.38554853 0.3942433  0.4034178\n",
      "  0.41287407 0.42152378]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09397350251674652\n",
      "Predicción post entrenamiento : [[0.43380392]]\n",
      "PERDIDAAAA despues: 0.09211662411689758\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "[[[0.36820731]\n",
      "  [0.37695634]\n",
      "  [0.38554853]\n",
      "  [0.3942433 ]\n",
      "  [0.4034178 ]\n",
      "  [0.41287407]\n",
      "  [0.42152378]\n",
      "  [0.43076015]]]\n",
      "ejemplar: [0.36820731 0.37695634 0.38554853 0.3942433  0.4034178  0.41287407\n",
      " 0.42152378 0.43076015]\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.44050705]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[0.36820731 0.37695634 0.38554853 0.3942433  0.4034178  0.41287407\n",
      "  0.42152378 0.43076015]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07891535758972168\n",
      "Predicción post entrenamiento : [[0.44342217]]\n",
      "PERDIDAAAA despues: 0.07728603482246399\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "[[[0.37695634]\n",
      "  [0.38554853]\n",
      "  [0.3942433 ]\n",
      "  [0.4034178 ]\n",
      "  [0.41287407]\n",
      "  [0.42152378]\n",
      "  [0.43076015]\n",
      "  [0.44050705]]]\n",
      "ejemplar: [0.37695634 0.38554853 0.3942433  0.4034178  0.41287407 0.42152378\n",
      " 0.43076015 0.44050705]\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.4501499]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[0.37695634 0.38554853 0.3942433  0.4034178  0.41287407 0.42152378\n",
      "  0.43076015 0.44050705]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07212651520967484\n",
      "Predicción post entrenamiento : [[0.4526276]]\n",
      "PERDIDAAAA despues: 0.07080181688070297\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "[[[0.38554853]\n",
      "  [0.3942433 ]\n",
      "  [0.4034178 ]\n",
      "  [0.41287407]\n",
      "  [0.42152378]\n",
      "  [0.43076015]\n",
      "  [0.44050705]\n",
      "  [0.45014989]]]\n",
      "ejemplar: [0.38554853 0.3942433  0.4034178  0.41287407 0.42152378 0.43076015\n",
      " 0.44050705 0.45014989]\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.45945165]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[0.38554853 0.3942433  0.4034178  0.41287407 0.42152378 0.43076015\n",
      "  0.44050705 0.45014989]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04609852656722069\n",
      "Predicción post entrenamiento : [[0.4612575]]\n",
      "PERDIDAAAA despues: 0.045326340943574905\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "[[[0.3942433 ]\n",
      "  [0.4034178 ]\n",
      "  [0.41287407]\n",
      "  [0.42152378]\n",
      "  [0.43076015]\n",
      "  [0.44050705]\n",
      "  [0.45014989]\n",
      "  [0.45945165]]]\n",
      "ejemplar: [0.3942433  0.4034178  0.41287407 0.42152378 0.43076015 0.44050705\n",
      " 0.45014989 0.45945165]\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.46824136]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[0.3942433  0.4034178  0.41287407 0.42152378 0.43076015 0.44050705\n",
      "  0.45014989 0.45945165]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.053049638867378235\n",
      "Predicción post entrenamiento : [[0.4704313]]\n",
      "PERDIDAAAA despues: 0.05204564332962036\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "[[[0.4034178 ]\n",
      "  [0.41287407]\n",
      "  [0.42152378]\n",
      "  [0.43076015]\n",
      "  [0.44050705]\n",
      "  [0.45014989]\n",
      "  [0.45945165]\n",
      "  [0.46824136]]]\n",
      "ejemplar: [0.4034178  0.41287407 0.42152378 0.43076015 0.44050705 0.45014989\n",
      " 0.45945165 0.46824136]\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.47757998]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[0.4034178  0.41287407 0.42152378 0.43076015 0.44050705 0.45014989\n",
      "  0.45945165 0.46824136]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05927197262644768\n",
      "Predicción post entrenamiento : [[0.47978204]]\n",
      "PERDIDAAAA despues: 0.05820460245013237\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "[[[0.41287407]\n",
      "  [0.42152378]\n",
      "  [0.43076015]\n",
      "  [0.44050705]\n",
      "  [0.45014989]\n",
      "  [0.45945165]\n",
      "  [0.46824136]\n",
      "  [0.47757998]]]\n",
      "ejemplar: [0.41287407 0.42152378 0.43076015 0.44050705 0.45014989 0.45945165\n",
      " 0.46824136 0.47757998]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.486996]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[0.41287407 0.42152378 0.43076015 0.44050705 0.45014989 0.45945165\n",
      "  0.46824136 0.47757998]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05550365149974823\n",
      "Predicción post entrenamiento : [[0.4893553]]\n",
      "PERDIDAAAA despues: 0.054397549480199814\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "[[[0.42152378]\n",
      "  [0.43076015]\n",
      "  [0.44050705]\n",
      "  [0.45014989]\n",
      "  [0.45945165]\n",
      "  [0.46824136]\n",
      "  [0.47757998]\n",
      "  [0.486996  ]]]\n",
      "ejemplar: [0.42152378 0.43076015 0.44050705 0.45014989 0.45945165 0.46824136\n",
      " 0.47757998 0.486996  ]\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.4965671]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[0.42152378 0.43076015 0.44050705 0.45014989 0.45945165 0.46824136\n",
      "  0.47757998 0.486996  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0674591213464737\n",
      "Predicción post entrenamiento : [[0.49896875]]\n",
      "PERDIDAAAA despues: 0.0662173330783844\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "[[[0.43076015]\n",
      "  [0.44050705]\n",
      "  [0.45014989]\n",
      "  [0.45945165]\n",
      "  [0.46824136]\n",
      "  [0.47757998]\n",
      "  [0.486996  ]\n",
      "  [0.4965671 ]]]\n",
      "ejemplar: [0.43076015 0.44050705 0.45014989 0.45945165 0.46824136 0.47757998\n",
      " 0.486996   0.4965671 ]\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.5063853]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[0.43076015 0.44050705 0.45014989 0.45945165 0.46824136 0.47757998\n",
      "  0.486996   0.4965671 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10317002236843109\n",
      "Predicción post entrenamiento : [[0.5095066]]\n",
      "PERDIDAAAA despues: 0.10117466747760773\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "[[[0.44050705]\n",
      "  [0.45014989]\n",
      "  [0.45945165]\n",
      "  [0.46824136]\n",
      "  [0.47757998]\n",
      "  [0.486996  ]\n",
      "  [0.4965671 ]\n",
      "  [0.50638533]]]\n",
      "ejemplar: [0.44050705 0.45014989 0.45945165 0.46824136 0.47757998 0.486996\n",
      " 0.4965671  0.50638533]\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.51700586]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[0.44050705 0.45014989 0.45945165 0.46824136 0.47757998 0.486996\n",
      "  0.4965671  0.50638533]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1035657450556755\n",
      "Predicción post entrenamiento : [[0.52006465]]\n",
      "PERDIDAAAA despues: 0.10160636901855469\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "[[[0.45014989]\n",
      "  [0.45945165]\n",
      "  [0.46824136]\n",
      "  [0.47757998]\n",
      "  [0.486996  ]\n",
      "  [0.4965671 ]\n",
      "  [0.50638533]\n",
      "  [0.51700586]]]\n",
      "ejemplar: [0.45014989 0.45945165 0.46824136 0.47757998 0.486996   0.4965671\n",
      " 0.50638533 0.51700586]\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.52752554]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[0.45014989 0.45945165 0.46824136 0.47757998 0.486996   0.4965671\n",
      "  0.50638533 0.51700586]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07115036994218826\n",
      "Predicción post entrenamiento : [[0.530231]]\n",
      "PERDIDAAAA despues: 0.06971438229084015\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "[[[0.45945165]\n",
      "  [0.46824136]\n",
      "  [0.47757998]\n",
      "  [0.486996  ]\n",
      "  [0.4965671 ]\n",
      "  [0.50638533]\n",
      "  [0.51700586]\n",
      "  [0.52752554]]]\n",
      "ejemplar: [0.45945165 0.46824136 0.47757998 0.486996   0.4965671  0.50638533\n",
      " 0.51700586 0.52752554]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.53768384]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[0.45945165 0.46824136 0.47757998 0.486996   0.4965671  0.50638533\n",
      "  0.51700586 0.52752554]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06057548150420189\n",
      "Predicción post entrenamiento : [[0.54017776]]\n",
      "PERDIDAAAA despues: 0.05935409292578697\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "[[[0.46824136]\n",
      "  [0.47757998]\n",
      "  [0.486996  ]\n",
      "  [0.4965671 ]\n",
      "  [0.50638533]\n",
      "  [0.51700586]\n",
      "  [0.52752554]\n",
      "  [0.53768384]]]\n",
      "ejemplar: [0.46824136 0.47757998 0.486996   0.4965671  0.50638533 0.51700586\n",
      " 0.52752554 0.53768384]\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.5477318]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[0.46824136 0.47757998 0.486996   0.4965671  0.50638533 0.51700586\n",
      "  0.52752554 0.53768384]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04848258197307587\n",
      "Predicción post entrenamiento : [[0.5496792]]\n",
      "PERDIDAAAA despues: 0.04762878641486168\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "[[[0.47757998]\n",
      "  [0.486996  ]\n",
      "  [0.4965671 ]\n",
      "  [0.50638533]\n",
      "  [0.51700586]\n",
      "  [0.52752554]\n",
      "  [0.53768384]\n",
      "  [0.54773182]]]\n",
      "ejemplar: [0.47757998 0.486996   0.4965671  0.50638533 0.51700586 0.52752554\n",
      " 0.53768384 0.54773182]\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.5575081]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[0.47757998 0.486996   0.4965671  0.50638533 0.51700586 0.52752554\n",
      "  0.53768384 0.54773182]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05156147852540016\n",
      "Predicción post entrenamiento : [[0.56003404]]\n",
      "PERDIDAAAA despues: 0.05042072385549545\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "[[[0.486996  ]\n",
      "  [0.4965671 ]\n",
      "  [0.50638533]\n",
      "  [0.51700586]\n",
      "  [0.52752554]\n",
      "  [0.53768384]\n",
      "  [0.54773182]\n",
      "  [0.55750811]]]\n",
      "ejemplar: [0.486996   0.4965671  0.50638533 0.51700586 0.52752554 0.53768384\n",
      " 0.54773182 0.55750811]\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.5680509]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[0.486996   0.4965671  0.50638533 0.51700586 0.52752554 0.53768384\n",
      "  0.54773182 0.55750811]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09652096778154373\n",
      "Predicción post entrenamiento : [[0.57037276]]\n",
      "PERDIDAAAA despues: 0.09508366882801056\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "[[[0.4965671 ]\n",
      "  [0.50638533]\n",
      "  [0.51700586]\n",
      "  [0.52752554]\n",
      "  [0.53768384]\n",
      "  [0.54773182]\n",
      "  [0.55750811]\n",
      "  [0.56805092]]]\n",
      "ejemplar: [0.4965671  0.50638533 0.51700586 0.52752554 0.53768384 0.54773182\n",
      " 0.55750811 0.56805092]\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.5785944]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[0.4965671  0.50638533 0.51700586 0.52752554 0.53768384 0.54773182\n",
      "  0.55750811 0.56805092]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08822991698980331\n",
      "Predicción post entrenamiento : [[0.5815506]]\n",
      "PERDIDAAAA despues: 0.0864824652671814\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "[[[0.50638533]\n",
      "  [0.51700586]\n",
      "  [0.52752554]\n",
      "  [0.53768384]\n",
      "  [0.54773182]\n",
      "  [0.55750811]\n",
      "  [0.56805092]\n",
      "  [0.57859439]]]\n",
      "ejemplar: [0.50638533 0.51700586 0.52752554 0.53768384 0.54773182 0.55750811\n",
      " 0.56805092 0.57859439]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.5899722]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[0.50638533 0.51700586 0.52752554 0.53768384 0.54773182 0.55750811\n",
      "  0.56805092 0.57859439]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06704142689704895\n",
      "Predicción post entrenamiento : [[0.59266603]]\n",
      "PERDIDAAAA despues: 0.06565368920564651\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "[[[0.51700586]\n",
      "  [0.52752554]\n",
      "  [0.53768384]\n",
      "  [0.54773182]\n",
      "  [0.55750811]\n",
      "  [0.56805092]\n",
      "  [0.57859439]\n",
      "  [0.5899722 ]]]\n",
      "ejemplar: [0.51700586 0.52752554 0.53768384 0.54773182 0.55750811 0.56805092\n",
      " 0.57859439 0.5899722 ]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.6012536]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[0.51700586 0.52752554 0.53768384 0.54773182 0.55750811 0.56805092\n",
      "  0.57859439 0.5899722 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.047103699296712875\n",
      "Predicción post entrenamiento : [[0.6036077]]\n",
      "PERDIDAAAA despues: 0.04608740657567978\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "[[[0.52752554]\n",
      "  [0.53768384]\n",
      "  [0.54773182]\n",
      "  [0.55750811]\n",
      "  [0.56805092]\n",
      "  [0.57859439]\n",
      "  [0.5899722 ]\n",
      "  [0.60125363]]]\n",
      "ejemplar: [0.52752554 0.53768384 0.54773182 0.55750811 0.56805092 0.57859439\n",
      " 0.5899722  0.60125363]\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.6121721]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[0.52752554 0.53768384 0.54773182 0.55750811 0.56805092 0.57859439\n",
      "  0.5899722  0.60125363]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.046069979667663574\n",
      "Predicción post entrenamiento : [[0.61449116]]\n",
      "PERDIDAAAA despues: 0.04507984593510628\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "[[[0.53768384]\n",
      "  [0.54773182]\n",
      "  [0.55750811]\n",
      "  [0.56805092]\n",
      "  [0.57859439]\n",
      "  [0.5899722 ]\n",
      "  [0.60125363]\n",
      "  [0.61217213]]]\n",
      "ejemplar: [0.53768384 0.54773182 0.55750811 0.56805092 0.57859439 0.5899722\n",
      " 0.60125363 0.61217213]\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.623068]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[0.53768384 0.54773182 0.55750811 0.56805092 0.57859439 0.5899722\n",
      "  0.60125363 0.61217213]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02633691392838955\n",
      "Predicción post entrenamiento : [[0.62381774]]\n",
      "PERDIDAAAA despues: 0.026094121858477592\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "[[[0.54773182]\n",
      "  [0.55750811]\n",
      "  [0.56805092]\n",
      "  [0.57859439]\n",
      "  [0.5899722 ]\n",
      "  [0.60125363]\n",
      "  [0.61217213]\n",
      "  [0.62306798]]]\n",
      "ejemplar: [0.54773182 0.55750811 0.56805092 0.57859439 0.5899722  0.60125363\n",
      " 0.61217213 0.62306798]\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.6325204]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[0.54773182 0.55750811 0.56805092 0.57859439 0.5899722  0.60125363\n",
      "  0.61217213 0.62306798]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.024557584896683693\n",
      "Predicción post entrenamiento : [[0.6340434]]\n",
      "PERDIDAAAA despues: 0.024082563817501068\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "[[[0.55750811]\n",
      "  [0.56805092]\n",
      "  [0.57859439]\n",
      "  [0.5899722 ]\n",
      "  [0.60125363]\n",
      "  [0.61217213]\n",
      "  [0.62306798]\n",
      "  [0.63252038]]]\n",
      "ejemplar: [0.55750811 0.56805092 0.57859439 0.5899722  0.60125363 0.61217213\n",
      " 0.62306798 0.63252038]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.64293593]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[0.55750811 0.56805092 0.57859439 0.5899722  0.60125363 0.61217213\n",
      "  0.62306798 0.63252038]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03657153248786926\n",
      "Predicción post entrenamiento : [[0.6446425]]\n",
      "PERDIDAAAA despues: 0.035921741276979446\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "[[[0.56805092]\n",
      "  [0.57859439]\n",
      "  [0.5899722 ]\n",
      "  [0.60125363]\n",
      "  [0.61217213]\n",
      "  [0.62306798]\n",
      "  [0.63252038]\n",
      "  [0.64293593]]]\n",
      "ejemplar: [0.56805092 0.57859439 0.5899722  0.60125363 0.61217213 0.62306798\n",
      " 0.63252038 0.64293593]\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.65382963]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[0.56805092 0.57859439 0.5899722  0.60125363 0.61217213 0.62306798\n",
      "  0.63252038 0.64293593]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.025168607011437416\n",
      "Predicción post entrenamiento : [[0.6547654]]\n",
      "PERDIDAAAA despues: 0.024872561916708946\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "[[[0.57859439]\n",
      "  [0.5899722 ]\n",
      "  [0.60125363]\n",
      "  [0.61217213]\n",
      "  [0.62306798]\n",
      "  [0.63252038]\n",
      "  [0.64293593]\n",
      "  [0.65382963]]]\n",
      "ejemplar: [0.57859439 0.5899722  0.60125363 0.61217213 0.62306798 0.63252038\n",
      " 0.64293593 0.65382963]\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.66406196]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[0.57859439 0.5899722  0.60125363 0.61217213 0.62306798 0.63252038\n",
      "  0.64293593 0.65382963]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01881777122616768\n",
      "Predicción post entrenamiento : [[0.6653246]]\n",
      "PERDIDAAAA despues: 0.01847294718027115\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "[[[0.5899722 ]\n",
      "  [0.60125363]\n",
      "  [0.61217213]\n",
      "  [0.62306798]\n",
      "  [0.63252038]\n",
      "  [0.64293593]\n",
      "  [0.65382963]\n",
      "  [0.66406196]]]\n",
      "ejemplar: [0.5899722  0.60125363 0.61217213 0.62306798 0.63252038 0.64293593\n",
      " 0.65382963 0.66406196]\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.6747266]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[0.5899722  0.60125363 0.61217213 0.62306798 0.63252038 0.64293593\n",
      "  0.65382963 0.66406196]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01649951934814453\n",
      "Predicción post entrenamiento : [[0.6758861]]\n",
      "PERDIDAAAA despues: 0.01620298996567726\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "[[[0.60125363]\n",
      "  [0.61217213]\n",
      "  [0.62306798]\n",
      "  [0.63252038]\n",
      "  [0.64293593]\n",
      "  [0.65382963]\n",
      "  [0.66406196]\n",
      "  [0.67472661]]]\n",
      "ejemplar: [0.60125363 0.61217213 0.62306798 0.63252038 0.64293593 0.65382963\n",
      " 0.66406196 0.67472661]\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.6851474]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[0.60125363 0.61217213 0.62306798 0.63252038 0.64293593 0.65382963\n",
      "  0.66406196 0.67472661]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011738309636712074\n",
      "Predicción post entrenamiento : [[0.6858273]]\n",
      "PERDIDAAAA despues: 0.011591444723308086\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "[[[0.61217213]\n",
      "  [0.62306798]\n",
      "  [0.63252038]\n",
      "  [0.64293593]\n",
      "  [0.65382963]\n",
      "  [0.66406196]\n",
      "  [0.67472661]\n",
      "  [0.6851474 ]]]\n",
      "ejemplar: [0.61217213 0.62306798 0.63252038 0.64293593 0.65382963 0.66406196\n",
      " 0.67472661 0.6851474 ]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.6949295]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[0.61217213 0.62306798 0.63252038 0.64293593 0.65382963 0.66406196\n",
      "  0.67472661 0.6851474 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004256385378539562\n",
      "Predicción post entrenamiento : [[0.6956007]]\n",
      "PERDIDAAAA despues: 0.004169255495071411\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "[[[0.62306798]\n",
      "  [0.63252038]\n",
      "  [0.64293593]\n",
      "  [0.65382963]\n",
      "  [0.66406196]\n",
      "  [0.67472661]\n",
      "  [0.6851474 ]\n",
      "  [0.69492948]]]\n",
      "ejemplar: [0.62306798 0.63252038 0.64293593 0.65382963 0.66406196 0.67472661\n",
      " 0.6851474  0.69492948]\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.70460707]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[0.62306798 0.63252038 0.64293593 0.65382963 0.66406196 0.67472661\n",
      "  0.6851474  0.69492948]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009465987095609307\n",
      "Predicción post entrenamiento : [[0.7049577]]\n",
      "PERDIDAAAA despues: 0.0009251446463167667\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "[[[0.63252038]\n",
      "  [0.64293593]\n",
      "  [0.65382963]\n",
      "  [0.66406196]\n",
      "  [0.67472661]\n",
      "  [0.6851474 ]\n",
      "  [0.69492948]\n",
      "  [0.70460707]]]\n",
      "ejemplar: [0.63252038 0.64293593 0.65382963 0.66406196 0.67472661 0.6851474\n",
      " 0.69492948 0.70460707]\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.71384436]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[0.63252038 0.64293593 0.65382963 0.66406196 0.67472661 0.6851474\n",
      "  0.69492948 0.70460707]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.3355659575609025e-05\n",
      "Predicción post entrenamiento : [[0.7118352]]\n",
      "PERDIDAAAA despues: 2.7072958346252562e-06\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "[[[0.64293593]\n",
      "  [0.65382963]\n",
      "  [0.66406196]\n",
      "  [0.67472661]\n",
      "  [0.6851474 ]\n",
      "  [0.69492948]\n",
      "  [0.70460707]\n",
      "  [0.71384436]]]\n",
      "ejemplar: [0.64293593 0.65382963 0.66406196 0.67472661 0.6851474  0.69492948\n",
      " 0.70460707 0.71384436]\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.7209718]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[0.64293593 0.65382963 0.66406196 0.67472661 0.6851474  0.69492948\n",
      "  0.70460707 0.71384436]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.82293063821271e-05\n",
      "Predicción post entrenamiento : [[0.72063833]]\n",
      "PERDIDAAAA despues: 7.244129665195942e-05\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "[[[0.65382963]\n",
      "  [0.66406196]\n",
      "  [0.67472661]\n",
      "  [0.6851474 ]\n",
      "  [0.69492948]\n",
      "  [0.70460707]\n",
      "  [0.71384436]\n",
      "  [0.72097182]]]\n",
      "ejemplar: [0.65382963 0.66406196 0.67472661 0.6851474  0.69492948 0.70460707\n",
      " 0.71384436 0.72097182]\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.7297527]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[0.65382963 0.66406196 0.67472661 0.6851474  0.69492948 0.70460707\n",
      "  0.71384436 0.72097182]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 9.767578012542799e-05\n",
      "Predicción post entrenamiento : [[0.72976553]]\n",
      "PERDIDAAAA despues: 9.742264228407294e-05\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "[[[0.66406196]\n",
      "  [0.67472661]\n",
      "  [0.6851474 ]\n",
      "  [0.69492948]\n",
      "  [0.70460707]\n",
      "  [0.71384436]\n",
      "  [0.72097182]\n",
      "  [0.72975272]]]\n",
      "ejemplar: [0.66406196 0.67472661 0.6851474  0.69492948 0.70460707 0.71384436\n",
      " 0.72097182 0.72975272]\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.73865885]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[0.66406196 0.67472661 0.6851474  0.69492948 0.70460707 0.71384436\n",
      "  0.72097182 0.72975272]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.300455424934626e-06\n",
      "Predicción post entrenamiento : [[0.73784924]]\n",
      "PERDIDAAAA despues: 2.891567419283092e-06\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "[[[0.67472661]\n",
      "  [0.6851474 ]\n",
      "  [0.69492948]\n",
      "  [0.70460707]\n",
      "  [0.71384436]\n",
      "  [0.72097182]\n",
      "  [0.72975272]\n",
      "  [0.73865885]]]\n",
      "ejemplar: [0.67472661 0.6851474  0.69492948 0.70460707 0.71384436 0.72097182\n",
      " 0.72975272 0.73865885]\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.74661636]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[0.67472661 0.6851474  0.69492948 0.70460707 0.71384436 0.72097182\n",
      "  0.72975272 0.73865885]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006248215213418007\n",
      "Predicción post entrenamiento : [[0.74523765]]\n",
      "PERDIDAAAA despues: 0.006032153498381376\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "[[[0.6851474 ]\n",
      "  [0.69492948]\n",
      "  [0.70460707]\n",
      "  [0.71384436]\n",
      "  [0.72097182]\n",
      "  [0.72975272]\n",
      "  [0.73865885]\n",
      "  [0.74661636]]]\n",
      "ejemplar: [0.6851474  0.69492948 0.70460707 0.71384436 0.72097182 0.72975272\n",
      " 0.73865885 0.74661636]\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.7536712]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[0.6851474  0.69492948 0.70460707 0.71384436 0.72097182 0.72975272\n",
      "  0.73865885 0.74661636]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007018387783318758\n",
      "Predicción post entrenamiento : [[0.7510956]]\n",
      "PERDIDAAAA despues: 0.006593469530344009\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "[[[0.69492948]\n",
      "  [0.70460707]\n",
      "  [0.71384436]\n",
      "  [0.72097182]\n",
      "  [0.72975272]\n",
      "  [0.73865885]\n",
      "  [0.74661636]\n",
      "  [0.75367123]]]\n",
      "ejemplar: [0.69492948 0.70460707 0.71384436 0.72097182 0.72975272 0.73865885\n",
      " 0.74661636 0.75367123]\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.75915027]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[0.69492948 0.70460707 0.71384436 0.72097182 0.72975272 0.73865885\n",
      "  0.74661636 0.75367123]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003908880520612001\n",
      "Predicción post entrenamiento : [[0.7588375]]\n",
      "PERDIDAAAA despues: 0.0038698718417435884\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "[[[0.70460707]\n",
      "  [0.71384436]\n",
      "  [0.72097182]\n",
      "  [0.72975272]\n",
      "  [0.73865885]\n",
      "  [0.74661636]\n",
      "  [0.75367123]\n",
      "  [0.75915027]]]\n",
      "ejemplar: [0.70460707 0.71384436 0.72097182 0.72975272 0.73865885 0.74661636\n",
      " 0.75367123 0.75915027]\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.7665863]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[0.70460707 0.71384436 0.72097182 0.72975272 0.73865885 0.74661636\n",
      "  0.75367123 0.75915027]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012240982614457607\n",
      "Predicción post entrenamiento : [[0.76609576]]\n",
      "PERDIDAAAA despues: 0.01213267631828785\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "[[[0.71384436]\n",
      "  [0.72097182]\n",
      "  [0.72975272]\n",
      "  [0.73865885]\n",
      "  [0.74661636]\n",
      "  [0.75367123]\n",
      "  [0.75915027]\n",
      "  [0.7665863 ]]]\n",
      "ejemplar: [0.71384436 0.72097182 0.72975272 0.73865885 0.74661636 0.75367123\n",
      " 0.75915027 0.7665863 ]\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.7734601]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[0.71384436 0.72097182 0.72975272 0.73865885 0.74661636 0.75367123\n",
      "  0.75915027 0.7665863 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008959271013736725\n",
      "Predicción post entrenamiento : [[0.7716268]]\n",
      "PERDIDAAAA despues: 0.00861557200551033\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "[[[0.72097182]\n",
      "  [0.72975272]\n",
      "  [0.73865885]\n",
      "  [0.74661636]\n",
      "  [0.75367123]\n",
      "  [0.75915027]\n",
      "  [0.7665863 ]\n",
      "  [0.77346009]]]\n",
      "ejemplar: [0.72097182 0.72975272 0.73865885 0.74661636 0.75367123 0.75915027\n",
      " 0.7665863  0.77346009]\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.77861804]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[0.72097182 0.72975272 0.73865885 0.74661636 0.75367123 0.75915027\n",
      "  0.7665863  0.77346009]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010511069558560848\n",
      "Predicción post entrenamiento : [[0.7791361]]\n",
      "PERDIDAAAA despues: 0.010617569088935852\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "[[[0.72975272]\n",
      "  [0.73865885]\n",
      "  [0.74661636]\n",
      "  [0.75367123]\n",
      "  [0.75915027]\n",
      "  [0.7665863 ]\n",
      "  [0.77346009]\n",
      "  [0.77861804]]]\n",
      "ejemplar: [0.72975272 0.73865885 0.74661636 0.75367123 0.75915027 0.7665863\n",
      " 0.77346009 0.77861804]\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.78626996]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[0.72975272 0.73865885 0.74661636 0.75367123 0.75915027 0.7665863\n",
      "  0.77346009 0.77861804]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003215774428099394\n",
      "Predicción post entrenamiento : [[0.78664404]]\n",
      "PERDIDAAAA despues: 0.003258340759202838\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "[[[0.73865885]\n",
      "  [0.74661636]\n",
      "  [0.75367123]\n",
      "  [0.75915027]\n",
      "  [0.7665863 ]\n",
      "  [0.77346009]\n",
      "  [0.77861804]\n",
      "  [0.78626996]]]\n",
      "ejemplar: [0.73865885 0.74661636 0.75367123 0.75915027 0.7665863  0.77346009\n",
      " 0.77861804 0.78626996]\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.79340065]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[0.73865885 0.74661636 0.75367123 0.75915027 0.7665863  0.77346009\n",
      "  0.77861804 0.78626996]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00848647765815258\n",
      "Predicción post entrenamiento : [[0.7926996]]\n",
      "PERDIDAAAA despues: 0.008357800543308258\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "[[[0.74661636]\n",
      "  [0.75367123]\n",
      "  [0.75915027]\n",
      "  [0.7665863 ]\n",
      "  [0.77346009]\n",
      "  [0.77861804]\n",
      "  [0.78626996]\n",
      "  [0.79340065]]]\n",
      "ejemplar: [0.74661636 0.75367123 0.75915027 0.7665863  0.77346009 0.77861804\n",
      " 0.78626996 0.79340065]\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.79893917]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[0.74661636 0.75367123 0.75915027 0.7665863  0.77346009 0.77861804\n",
      "  0.78626996 0.79340065]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009864107705652714\n",
      "Predicción post entrenamiento : [[0.79963344]]\n",
      "PERDIDAAAA despues: 0.0010305031901225448\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "[[[0.75367123]\n",
      "  [0.75915027]\n",
      "  [0.7665863 ]\n",
      "  [0.77346009]\n",
      "  [0.77861804]\n",
      "  [0.78626996]\n",
      "  [0.79340065]\n",
      "  [0.79893917]]]\n",
      "ejemplar: [0.75367123 0.75915027 0.7665863  0.77346009 0.77861804 0.78626996\n",
      " 0.79340065 0.79893917]\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.805536]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[0.75367123 0.75915027 0.7665863  0.77346009 0.77861804 0.78626996\n",
      "  0.79340065 0.79893917]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0025403902400285006\n",
      "Predicción post entrenamiento : [[0.8046677]]\n",
      "PERDIDAAAA despues: 0.0024536193814128637\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "[[[0.75915027]\n",
      "  [0.7665863 ]\n",
      "  [0.77346009]\n",
      "  [0.77861804]\n",
      "  [0.78626996]\n",
      "  [0.79340065]\n",
      "  [0.79893917]\n",
      "  [0.80553597]]]\n",
      "ejemplar: [0.75915027 0.7665863  0.77346009 0.77861804 0.78626996 0.79340065\n",
      " 0.79893917 0.80553597]\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.8104365]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[0.75915027 0.7665863  0.77346009 0.77861804 0.78626996 0.79340065\n",
      "  0.79893917 0.80553597]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004274081438779831\n",
      "Predicción post entrenamiento : [[0.81022465]]\n",
      "PERDIDAAAA despues: 0.004246428608894348\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "[[[0.7665863 ]\n",
      "  [0.77346009]\n",
      "  [0.77861804]\n",
      "  [0.78626996]\n",
      "  [0.79340065]\n",
      "  [0.79893917]\n",
      "  [0.80553597]\n",
      "  [0.81043649]]]\n",
      "ejemplar: [0.7665863  0.77346009 0.77861804 0.78626996 0.79340065 0.79893917\n",
      " 0.80553597 0.81043649]\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.8162966]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[0.7665863  0.77346009 0.77861804 0.78626996 0.79340065 0.79893917\n",
      "  0.80553597 0.81043649]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0041296700946986675\n",
      "Predicción post entrenamiento : [[0.81570905]]\n",
      "PERDIDAAAA despues: 0.004054503981024027\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "[[[0.77346009]\n",
      "  [0.77861804]\n",
      "  [0.78626996]\n",
      "  [0.79340065]\n",
      "  [0.79893917]\n",
      "  [0.80553597]\n",
      "  [0.81043649]\n",
      "  [0.81629658]]]\n",
      "ejemplar: [0.77346009 0.77861804 0.78626996 0.79340065 0.79893917 0.80553597\n",
      " 0.81043649 0.81629658]\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.82152426]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[0.77346009 0.77861804 0.78626996 0.79340065 0.79893917 0.80553597\n",
      "  0.81043649 0.81629658]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012481776997447014\n",
      "Predicción post entrenamiento : [[0.82096726]]\n",
      "PERDIDAAAA despues: 0.012357627972960472\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "[[[0.77861804]\n",
      "  [0.78626996]\n",
      "  [0.79340065]\n",
      "  [0.79893917]\n",
      "  [0.80553597]\n",
      "  [0.81043649]\n",
      "  [0.81629658]\n",
      "  [0.82152426]]]\n",
      "ejemplar: [0.77861804 0.78626996 0.79340065 0.79893917 0.80553597 0.81043649\n",
      " 0.81629658 0.82152426]\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.8266245]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[0.77861804 0.78626996 0.79340065 0.79893917 0.80553597 0.81043649\n",
      "  0.81629658 0.82152426]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018548933789134026\n",
      "Predicción post entrenamiento : [[0.8259389]]\n",
      "PERDIDAAAA despues: 0.01836264505982399\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "[[[0.78626996]\n",
      "  [0.79340065]\n",
      "  [0.79893917]\n",
      "  [0.80553597]\n",
      "  [0.81043649]\n",
      "  [0.81629658]\n",
      "  [0.82152426]\n",
      "  [0.82662451]]]\n",
      "ejemplar: [0.78626996 0.79340065 0.79893917 0.80553597 0.81043649 0.81629658\n",
      " 0.82152426 0.82662451]\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.8318916]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[0.78626996 0.79340065 0.79893917 0.80553597 0.81043649 0.81629658\n",
      "  0.82152426 0.82662451]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006011339370161295\n",
      "Predicción post entrenamiento : [[0.8317679]]\n",
      "PERDIDAAAA despues: 0.0059921760112047195\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "[[[0.79340065]\n",
      "  [0.79893917]\n",
      "  [0.80553597]\n",
      "  [0.81043649]\n",
      "  [0.81629658]\n",
      "  [0.82152426]\n",
      "  [0.82662451]\n",
      "  [0.8318916 ]]]\n",
      "ejemplar: [0.79340065 0.79893917 0.80553597 0.81043649 0.81629658 0.82152426\n",
      " 0.82662451 0.8318916 ]\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.83727515]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[0.79340065 0.79893917 0.80553597 0.81043649 0.81629658 0.82152426\n",
      "  0.82662451 0.8318916 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013242130167782307\n",
      "Predicción post entrenamiento : [[0.83622825]]\n",
      "PERDIDAAAA despues: 0.013002284802496433\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "[[[0.79893917]\n",
      "  [0.80553597]\n",
      "  [0.81043649]\n",
      "  [0.81629658]\n",
      "  [0.82152426]\n",
      "  [0.82662451]\n",
      "  [0.8318916 ]\n",
      "  [0.83727515]]]\n",
      "ejemplar: [0.79893917 0.80553597 0.81043649 0.81629658 0.82152426 0.82662451\n",
      " 0.8318916  0.83727515]\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.8413391]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[0.79893917 0.80553597 0.81043649 0.81629658 0.82152426 0.82662451\n",
      "  0.8318916  0.83727515]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.139809945831075e-05\n",
      "Predicción post entrenamiento : [[0.84157735]]\n",
      "PERDIDAAAA despues: 4.803885531146079e-05\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "[[[0.80553597]\n",
      "  [0.81043649]\n",
      "  [0.81629658]\n",
      "  [0.82152426]\n",
      "  [0.82662451]\n",
      "  [0.8318916 ]\n",
      "  [0.83727515]\n",
      "  [0.84133911]]]\n",
      "ejemplar: [0.80553597 0.81043649 0.81629658 0.82152426 0.82662451 0.8318916\n",
      " 0.83727515 0.84133911]\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.84668183]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[0.80553597 0.81043649 0.81629658 0.82152426 0.82662451 0.8318916\n",
      "  0.83727515 0.84133911]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0034552232827991247\n",
      "Predicción post entrenamiento : [[0.848018]]\n",
      "PERDIDAAAA despues: 0.0032999268732964993\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "[[[0.81043649]\n",
      "  [0.81629658]\n",
      "  [0.82152426]\n",
      "  [0.82662451]\n",
      "  [0.8318916 ]\n",
      "  [0.83727515]\n",
      "  [0.84133911]\n",
      "  [0.84668183]]]\n",
      "ejemplar: [0.81043649 0.81629658 0.82152426 0.82662451 0.8318916  0.83727515\n",
      " 0.84133911 0.84668183]\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.85277677]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[0.81043649 0.81629658 0.82152426 0.82662451 0.8318916  0.83727515\n",
      "  0.84133911 0.84668183]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008666811627335846\n",
      "Predicción post entrenamiento : [[0.85316885]]\n",
      "PERDIDAAAA despues: 0.000843749672640115\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "[[[0.81629658]\n",
      "  [0.82152426]\n",
      "  [0.82662451]\n",
      "  [0.8318916 ]\n",
      "  [0.83727515]\n",
      "  [0.84133911]\n",
      "  [0.84668183]\n",
      "  [0.85277677]]]\n",
      "ejemplar: [0.81629658 0.82152426 0.82662451 0.8318916  0.83727515 0.84133911\n",
      " 0.84668183 0.85277677]\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.8580258]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[0.81629658 0.82152426 0.82662451 0.8318916  0.83727515 0.84133911\n",
      "  0.84668183 0.85277677]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0024762458633631468\n",
      "Predicción post entrenamiento : [[0.85752773]]\n",
      "PERDIDAAAA despues: 0.0025260623078793287\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "[[[0.82152426]\n",
      "  [0.82662451]\n",
      "  [0.8318916 ]\n",
      "  [0.83727515]\n",
      "  [0.84133911]\n",
      "  [0.84668183]\n",
      "  [0.85277677]\n",
      "  [0.85802579]]]\n",
      "ejemplar: [0.82152426 0.82662451 0.8318916  0.83727515 0.84133911 0.84668183\n",
      " 0.85277677 0.85802579]\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.8622043]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[0.82152426 0.82662451 0.8318916  0.83727515 0.84133911 0.84668183\n",
      "  0.85277677 0.85802579]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007493015727959573\n",
      "Predicción post entrenamiento : [[0.86299145]]\n",
      "PERDIDAAAA despues: 0.0007068278500810266\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "[[[0.82662451]\n",
      "  [0.8318916 ]\n",
      "  [0.83727515]\n",
      "  [0.84133911]\n",
      "  [0.84668183]\n",
      "  [0.85277677]\n",
      "  [0.85802579]\n",
      "  [0.86220431]]]\n",
      "ejemplar: [0.82662451 0.8318916  0.83727515 0.84133911 0.84668183 0.85277677\n",
      " 0.85802579 0.86220431]\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.86764854]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[0.82662451 0.8318916  0.83727515 0.84133911 0.84668183 0.85277677\n",
      "  0.85802579 0.86220431]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.1928480388596654e-05\n",
      "Predicción post entrenamiento : [[0.8684722]]\n",
      "PERDIDAAAA despues: 4.073586387676187e-05\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "[[[0.8318916 ]\n",
      "  [0.83727515]\n",
      "  [0.84133911]\n",
      "  [0.84668183]\n",
      "  [0.85277677]\n",
      "  [0.85802579]\n",
      "  [0.86220431]\n",
      "  [0.86764854]]]\n",
      "ejemplar: [0.8318916  0.83727515 0.84133911 0.84668183 0.85277677 0.85802579\n",
      " 0.86220431 0.86764854]\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.87314415]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[0.8318916  0.83727515 0.84133911 0.84668183 0.85277677 0.85802579\n",
      "  0.86220431 0.86764854]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001605427940376103\n",
      "Predicción post entrenamiento : [[0.87379396]]\n",
      "PERDIDAAAA despues: 0.0015537772560492158\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "[[[0.83727515]\n",
      "  [0.84133911]\n",
      "  [0.84668183]\n",
      "  [0.85277677]\n",
      "  [0.85802579]\n",
      "  [0.86220431]\n",
      "  [0.86764854]\n",
      "  [0.87314415]]]\n",
      "ejemplar: [0.83727515 0.84133911 0.84668183 0.85277677 0.85802579 0.86220431\n",
      " 0.86764854 0.87314415]\n",
      "y: 1.0\n",
      "Predicción : [[0.878434]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[0.83727515 0.84133911 0.84668183 0.85277677 0.85802579 0.86220431\n",
      "  0.86764854 0.87314415]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014778291806578636\n",
      "Predicción post entrenamiento : [[0.8804355]]\n",
      "PERDIDAAAA despues: 0.014295663684606552\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "[[[0.84133911]\n",
      "  [0.84668183]\n",
      "  [0.85277677]\n",
      "  [0.85802579]\n",
      "  [0.86220431]\n",
      "  [0.86764854]\n",
      "  [0.87314415]\n",
      "  [0.878434  ]]]\n",
      "ejemplar: [0.84133911 0.84668183 0.85277677 0.85802579 0.86220431 0.86764854\n",
      " 0.87314415 0.878434  ]\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.8850106]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[0.84133911 0.84668183 0.85277677 0.85802579 0.86220431 0.86764854\n",
      "  0.87314415 0.878434  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007317682262510061\n",
      "Predicción post entrenamiento : [[0.8853762]]\n",
      "PERDIDAAAA despues: 0.007255264092236757\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "[[[0.84668183]\n",
      "  [0.85277677]\n",
      "  [0.85802579]\n",
      "  [0.86220431]\n",
      "  [0.86764854]\n",
      "  [0.87314415]\n",
      "  [0.878434  ]\n",
      "  [0.8850106 ]]]\n",
      "ejemplar: [0.84668183 0.85277677 0.85802579 0.86220431 0.86764854 0.87314415\n",
      " 0.878434   0.8850106 ]\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.890286]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[0.84668183 0.85277677 0.85802579 0.86220431 0.86764854 0.87314415\n",
      "  0.878434   0.8850106 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.200064955104608e-06\n",
      "Predicción post entrenamiento : [[0.8902943]]\n",
      "PERDIDAAAA despues: 2.2247113520279527e-06\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "[[[0.85277677]\n",
      "  [0.85802579]\n",
      "  [0.86220431]\n",
      "  [0.86764854]\n",
      "  [0.87314415]\n",
      "  [0.878434  ]\n",
      "  [0.8850106 ]\n",
      "  [0.89028603]]]\n",
      "ejemplar: [0.85277677 0.85802579 0.86220431 0.86764854 0.87314415 0.878434\n",
      " 0.8850106  0.89028603]\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.89521086]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[0.85277677 0.85802579 0.86220431 0.86764854 0.87314415 0.878434\n",
      "  0.8850106  0.89028603]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00029778879252262414\n",
      "Predicción post entrenamiento : [[0.895066]]\n",
      "PERDIDAAAA despues: 0.00029281090246513486\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "[[[0.85802579]\n",
      "  [0.86220431]\n",
      "  [0.86764854]\n",
      "  [0.87314415]\n",
      "  [0.878434  ]\n",
      "  [0.8850106 ]\n",
      "  [0.89028603]\n",
      "  [0.89521086]]]\n",
      "ejemplar: [0.85802579 0.86220431 0.86764854 0.87314415 0.878434   0.8850106\n",
      " 0.89028603 0.89521086]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.89976627]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[0.85802579 0.86220431 0.86764854 0.87314415 0.878434   0.8850106\n",
      "  0.89028603 0.89521086]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00258780550211668\n",
      "Predicción post entrenamiento : [[0.89913005]]\n",
      "PERDIDAAAA despues: 0.0025234806817024946\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "[[[0.86220431]\n",
      "  [0.86764854]\n",
      "  [0.87314415]\n",
      "  [0.878434  ]\n",
      "  [0.8850106 ]\n",
      "  [0.89028603]\n",
      "  [0.89521086]\n",
      "  [0.89976627]]]\n",
      "ejemplar: [0.86220431 0.86764854 0.87314415 0.878434   0.8850106  0.89028603\n",
      " 0.89521086 0.89976627]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.90384287]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[0.86220431 0.86764854 0.87314415 0.878434   0.8850106  0.89028603\n",
      "  0.89521086 0.89976627]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004853920079767704\n",
      "Predicción post entrenamiento : [[0.90343356]]\n",
      "PERDIDAAAA despues: 0.004797054920345545\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "[[[0.86764854]\n",
      "  [0.87314415]\n",
      "  [0.878434  ]\n",
      "  [0.8850106 ]\n",
      "  [0.89028603]\n",
      "  [0.89521086]\n",
      "  [0.89976627]\n",
      "  [0.90384287]]]\n",
      "ejemplar: [0.86764854 0.87314415 0.878434   0.8850106  0.89028603 0.89521086\n",
      " 0.89976627 0.90384287]\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.9084822]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[0.86764854 0.87314415 0.878434   0.8850106  0.89028603 0.89521086\n",
      "  0.89976627 0.90384287]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0028502021450549364\n",
      "Predicción post entrenamiento : [[0.90802675]]\n",
      "PERDIDAAAA despues: 0.0028017801232635975\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "[[[0.87314415]\n",
      "  [0.878434  ]\n",
      "  [0.8850106 ]\n",
      "  [0.89028603]\n",
      "  [0.89521086]\n",
      "  [0.89976627]\n",
      "  [0.90384287]\n",
      "  [0.90848219]]]\n",
      "ejemplar: [0.87314415 0.878434   0.8850106  0.89028603 0.89521086 0.89976627\n",
      " 0.90384287 0.90848219]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.91305447]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[0.87314415 0.878434   0.8850106  0.89028603 0.89521086 0.89976627\n",
      "  0.90384287 0.90848219]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014297694433480501\n",
      "Predicción post entrenamiento : [[0.91244113]]\n",
      "PERDIDAAAA despues: 0.0013837626902386546\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "[[[0.878434  ]\n",
      "  [0.8850106 ]\n",
      "  [0.89028603]\n",
      "  [0.89521086]\n",
      "  [0.89976627]\n",
      "  [0.90384287]\n",
      "  [0.90848219]\n",
      "  [0.91305447]]]\n",
      "ejemplar: [0.878434   0.8850106  0.89028603 0.89521086 0.89976627 0.90384287\n",
      " 0.90848219 0.91305447]\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.9173953]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[0.878434   0.8850106  0.89028603 0.89521086 0.89976627 0.90384287\n",
      "  0.90848219 0.91305447]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0036437055096030235\n",
      "Predicción post entrenamiento : [[0.91775054]]\n",
      "PERDIDAAAA despues: 0.003686718875542283\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "[[[0.8850106 ]\n",
      "  [0.89028603]\n",
      "  [0.89521086]\n",
      "  [0.89976627]\n",
      "  [0.90384287]\n",
      "  [0.90848219]\n",
      "  [0.91305447]\n",
      "  [0.91739529]]]\n",
      "ejemplar: [0.8850106  0.89028603 0.89521086 0.89976627 0.90384287 0.90848219\n",
      " 0.91305447 0.91739529]\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.9226469]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[0.8850106  0.89028603 0.89521086 0.89976627 0.90384287 0.90848219\n",
      "  0.91305447 0.91739529]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005269125569611788\n",
      "Predicción post entrenamiento : [[0.9236279]]\n",
      "PERDIDAAAA despues: 0.0054125115275382996\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "[[[0.89028603]\n",
      "  [0.89521086]\n",
      "  [0.89976627]\n",
      "  [0.90384287]\n",
      "  [0.90848219]\n",
      "  [0.91305447]\n",
      "  [0.91739529]\n",
      "  [0.92264688]]]\n",
      "ejemplar: [0.89028603 0.89521086 0.89976627 0.90384287 0.90848219 0.91305447\n",
      " 0.91739529 0.92264688]\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.9280351]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[0.89028603 0.89521086 0.89976627 0.90384287 0.90848219 0.91305447\n",
      "  0.91739529 0.92264688]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007282655220478773\n",
      "Predicción post entrenamiento : [[0.9273741]]\n",
      "PERDIDAAAA despues: 0.0071702818386256695\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "[[[0.89521086]\n",
      "  [0.89976627]\n",
      "  [0.90384287]\n",
      "  [0.90848219]\n",
      "  [0.91305447]\n",
      "  [0.91739529]\n",
      "  [0.92264688]\n",
      "  [0.92803508]]]\n",
      "ejemplar: [0.89521086 0.89976627 0.90384287 0.90848219 0.91305447 0.91739529\n",
      " 0.92264688 0.92803508]\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.9316033]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[0.89521086 0.89976627 0.90384287 0.90848219 0.91305447 0.91739529\n",
      "  0.92264688 0.92803508]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011808403767645359\n",
      "Predicción post entrenamiento : [[0.92960703]]\n",
      "PERDIDAAAA despues: 0.011378531344234943\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "[[[0.89976627]\n",
      "  [0.90384287]\n",
      "  [0.90848219]\n",
      "  [0.91305447]\n",
      "  [0.91739529]\n",
      "  [0.92264688]\n",
      "  [0.92803508]\n",
      "  [0.93160331]]]\n",
      "ejemplar: [0.89976627 0.90384287 0.90848219 0.91305447 0.91739529 0.92264688\n",
      " 0.92803508 0.93160331]\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.93373585]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[0.89976627 0.90384287 0.90848219 0.91305447 0.91739529 0.92264688\n",
      "  0.92803508 0.93160331]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.025354133918881416\n",
      "Predicción post entrenamiento : [[0.933243]]\n",
      "PERDIDAAAA despues: 0.02519741654396057\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "[[[0.90384287]\n",
      "  [0.90848219]\n",
      "  [0.91305447]\n",
      "  [0.91739529]\n",
      "  [0.92264688]\n",
      "  [0.92803508]\n",
      "  [0.93160331]\n",
      "  [0.93373585]]]\n",
      "ejemplar: [0.90384287 0.90848219 0.91305447 0.91739529 0.92264688 0.92803508\n",
      " 0.93160331 0.93373585]\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.93736225]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[0.90384287 0.90848219 0.91305447 0.91739529 0.92264688 0.92803508\n",
      "  0.93160331 0.93373585]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.023461082950234413\n",
      "Predicción post entrenamiento : [[0.93560845]]\n",
      "PERDIDAAAA despues: 0.022926896810531616\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "[[[0.90848219]\n",
      "  [0.91305447]\n",
      "  [0.91739529]\n",
      "  [0.92264688]\n",
      "  [0.92803508]\n",
      "  [0.93160331]\n",
      "  [0.93373585]\n",
      "  [0.93736225]]]\n",
      "ejemplar: [0.90848219 0.91305447 0.91739529 0.92264688 0.92803508 0.93160331\n",
      " 0.93373585 0.93736225]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.9398389]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[0.90848219 0.91305447 0.91739529 0.92264688 0.92803508 0.93160331\n",
      "  0.93373585 0.93736225]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0064151412807404995\n",
      "Predicción post entrenamiento : [[0.93906873]]\n",
      "PERDIDAAAA despues: 0.006292364094406366\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "[[[0.91305447]\n",
      "  [0.91739529]\n",
      "  [0.92264688]\n",
      "  [0.92803508]\n",
      "  [0.93160331]\n",
      "  [0.93373585]\n",
      "  [0.93736225]\n",
      "  [0.93983889]]]\n",
      "ejemplar: [0.91305447 0.91739529 0.92264688 0.92803508 0.93160331 0.93373585\n",
      " 0.93736225 0.93983889]\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.9432166]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[0.91305447 0.91739529 0.92264688 0.92803508 0.93160331 0.93373585\n",
      "  0.93736225 0.93983889]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007902600802481174\n",
      "Predicción post entrenamiento : [[0.94326323]]\n",
      "PERDIDAAAA despues: 0.007910889573395252\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "[[[0.91739529]\n",
      "  [0.92264688]\n",
      "  [0.92803508]\n",
      "  [0.93160331]\n",
      "  [0.93373585]\n",
      "  [0.93736225]\n",
      "  [0.93983889]\n",
      "  [0.94321662]]]\n",
      "ejemplar: [0.91739529 0.92264688 0.92803508 0.93160331 0.93373585 0.93736225\n",
      " 0.93983889 0.94321662]\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.9472872]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[0.91739529 0.92264688 0.92803508 0.93160331 0.93373585 0.93736225\n",
      "  0.93983889 0.94321662]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012188664637506008\n",
      "Predicción post entrenamiento : [[0.9470847]]\n",
      "PERDIDAAAA despues: 0.012143997475504875\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "[[[0.92264688]\n",
      "  [0.92803508]\n",
      "  [0.93160331]\n",
      "  [0.93373585]\n",
      "  [0.93736225]\n",
      "  [0.93983889]\n",
      "  [0.94321662]\n",
      "  [0.9472872 ]]]\n",
      "ejemplar: [0.92264688 0.92803508 0.93160331 0.93373585 0.93736225 0.93983889\n",
      " 0.94321662 0.9472872 ]\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.9509893]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[0.92264688 0.92803508 0.93160331 0.93373585 0.93736225 0.93983889\n",
      "  0.94321662 0.9472872 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014659986831247807\n",
      "Predicción post entrenamiento : [[0.9515329]]\n",
      "PERDIDAAAA despues: 0.01479191705584526\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "[[[0.92803508]\n",
      "  [0.93160331]\n",
      "  [0.93373585]\n",
      "  [0.93736225]\n",
      "  [0.93983889]\n",
      "  [0.94321662]\n",
      "  [0.9472872 ]\n",
      "  [0.95098931]]]\n",
      "ejemplar: [0.92803508 0.93160331 0.93373585 0.93736225 0.93983889 0.94321662\n",
      " 0.9472872  0.95098931]\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.9549829]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[0.92803508 0.93160331 0.93373585 0.93736225 0.93983889 0.94321662\n",
      "  0.9472872  0.95098931]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004587337840348482\n",
      "Predicción post entrenamiento : [[0.9538672]]\n",
      "PERDIDAAAA despues: 0.0044374531134963036\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "[[[0.93160331]\n",
      "  [0.93373585]\n",
      "  [0.93736225]\n",
      "  [0.93983889]\n",
      "  [0.94321662]\n",
      "  [0.9472872 ]\n",
      "  [0.95098931]\n",
      "  [0.95498288]]]\n",
      "ejemplar: [0.93160331 0.93373585 0.93736225 0.93983889 0.94321662 0.9472872\n",
      " 0.95098931 0.95498288]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.95673597]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[0.93160331 0.93373585 0.93736225 0.93983889 0.94321662 0.9472872\n",
      "  0.95098931 0.95498288]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009407381527125835\n",
      "Predicción post entrenamiento : [[0.9558935]]\n",
      "PERDIDAAAA despues: 0.009244670160114765\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "[[[0.93373585]\n",
      "  [0.93736225]\n",
      "  [0.93983889]\n",
      "  [0.94321662]\n",
      "  [0.9472872 ]\n",
      "  [0.95098931]\n",
      "  [0.95498288]\n",
      "  [0.95673597]]]\n",
      "ejemplar: [0.93373585 0.93736225 0.93983889 0.94321662 0.9472872  0.95098931\n",
      " 0.95498288 0.95673597]\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.9586549]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[0.93373585 0.93736225 0.93983889 0.94321662 0.9472872  0.95098931\n",
      "  0.95498288 0.95673597]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014174767769873142\n",
      "Predicción post entrenamiento : [[0.95821536]]\n",
      "PERDIDAAAA despues: 0.014070303179323673\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "[[[0.93736225]\n",
      "  [0.93983889]\n",
      "  [0.94321662]\n",
      "  [0.9472872 ]\n",
      "  [0.95098931]\n",
      "  [0.95498288]\n",
      "  [0.95673597]\n",
      "  [0.95865488]]]\n",
      "ejemplar: [0.93736225 0.93983889 0.94321662 0.9472872  0.95098931 0.95498288\n",
      " 0.95673597 0.95865488]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.9612949]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[0.93736225 0.93983889 0.94321662 0.9472872  0.95098931 0.95498288\n",
      "  0.95673597 0.95865488]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03150276094675064\n",
      "Predicción post entrenamiento : [[0.9591454]]\n",
      "PERDIDAAAA despues: 0.030744364485144615\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "[[[0.93983889]\n",
      "  [0.94321662]\n",
      "  [0.9472872 ]\n",
      "  [0.95098931]\n",
      "  [0.95498288]\n",
      "  [0.95673597]\n",
      "  [0.95865488]\n",
      "  [0.96129489]]]\n",
      "ejemplar: [0.93983889 0.94321662 0.9472872  0.95098931 0.95498288 0.95673597\n",
      " 0.95865488 0.96129489]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.9621174]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[0.93983889 0.94321662 0.9472872  0.95098931 0.95498288 0.95673597\n",
      "  0.95865488 0.96129489]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.020687034353613853\n",
      "Predicción post entrenamiento : [[0.9618466]]\n",
      "PERDIDAAAA despues: 0.020609214901924133\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "[[[0.94321662]\n",
      "  [0.9472872 ]\n",
      "  [0.95098931]\n",
      "  [0.95498288]\n",
      "  [0.95673597]\n",
      "  [0.95865488]\n",
      "  [0.96129489]\n",
      "  [0.96211737]]]\n",
      "ejemplar: [0.94321662 0.9472872  0.95098931 0.95498288 0.95673597 0.95865488\n",
      " 0.96129489 0.96211737]\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.96501374]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[0.94321662 0.9472872  0.95098931 0.95498288 0.95673597 0.95865488\n",
      "  0.96129489 0.96211737]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.030222972854971886\n",
      "Predicción post entrenamiento : [[0.9632775]]\n",
      "PERDIDAAAA despues: 0.029622310772538185\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "[[[0.9472872 ]\n",
      "  [0.95098931]\n",
      "  [0.95498288]\n",
      "  [0.95673597]\n",
      "  [0.95865488]\n",
      "  [0.96129489]\n",
      "  [0.96211737]\n",
      "  [0.96501374]]]\n",
      "ejemplar: [0.9472872  0.95098931 0.95498288 0.95673597 0.95865488 0.96129489\n",
      " 0.96211737 0.96501374]\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.9663441]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[0.9472872  0.95098931 0.95498288 0.95673597 0.95865488 0.96129489\n",
      "  0.96211737 0.96501374]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.042347948998212814\n",
      "Predicción post entrenamiento : [[0.96559143]]\n",
      "PERDIDAAAA despues: 0.042038727551698685\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "[[[0.95098931]\n",
      "  [0.95498288]\n",
      "  [0.95673597]\n",
      "  [0.95865488]\n",
      "  [0.96129489]\n",
      "  [0.96211737]\n",
      "  [0.96501374]\n",
      "  [0.96634412]]]\n",
      "ejemplar: [0.95098931 0.95498288 0.95673597 0.95865488 0.96129489 0.96211737\n",
      " 0.96501374 0.96634412]\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.96827614]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[0.95098931 0.95498288 0.95673597 0.95865488 0.96129489 0.96211737\n",
      "  0.96501374 0.96634412]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.031230829656124115\n",
      "Predicción post entrenamiento : [[0.9675219]]\n",
      "PERDIDAAAA despues: 0.030964817851781845\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "[[[0.95498288]\n",
      "  [0.95673597]\n",
      "  [0.95865488]\n",
      "  [0.96129489]\n",
      "  [0.96211737]\n",
      "  [0.96501374]\n",
      "  [0.96634412]\n",
      "  [0.96827614]]]\n",
      "ejemplar: [0.95498288 0.95673597 0.95865488 0.96129489 0.96211737 0.96501374\n",
      " 0.96634412 0.96827614]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9698337]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[0.95498288 0.95673597 0.95865488 0.96129489 0.96211737 0.96501374\n",
      "  0.96634412 0.96827614]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04045705497264862\n",
      "Predicción post entrenamiento : [[0.9677657]]\n",
      "PERDIDAAAA despues: 0.03962942585349083\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "[[[0.95673597]\n",
      "  [0.95865488]\n",
      "  [0.96129489]\n",
      "  [0.96211737]\n",
      "  [0.96501374]\n",
      "  [0.96634412]\n",
      "  [0.96827614]\n",
      "  [0.96983367]]]\n",
      "ejemplar: [0.95673597 0.95865488 0.96129489 0.96211737 0.96501374 0.96634412\n",
      " 0.96827614 0.96983367]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9695269]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[0.95673597 0.95865488 0.96129489 0.96211737 0.96501374 0.96634412\n",
      "  0.96827614 0.96983367]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.040333736687898636\n",
      "Predicción post entrenamiento : [[0.9690263]]\n",
      "PERDIDAAAA despues: 0.040132928639650345\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "[[[0.95865488]\n",
      "  [0.96129489]\n",
      "  [0.96211737]\n",
      "  [0.96501374]\n",
      "  [0.96634412]\n",
      "  [0.96827614]\n",
      "  [0.96983367]\n",
      "  [0.96952689]]]\n",
      "ejemplar: [0.95865488 0.96129489 0.96211737 0.96501374 0.96634412 0.96827614\n",
      " 0.96983367 0.96952689]\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.970817]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[0.95865488 0.96129489 0.96211737 0.96501374 0.96634412 0.96827614\n",
      "  0.96983367 0.96952689]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.029550256207585335\n",
      "Predicción post entrenamiento : [[0.9692155]]\n",
      "PERDIDAAAA despues: 0.02900221385061741\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "[[[0.96129489]\n",
      "  [0.96211737]\n",
      "  [0.96501374]\n",
      "  [0.96634412]\n",
      "  [0.96827614]\n",
      "  [0.96983367]\n",
      "  [0.96952689]\n",
      "  [0.97081703]]]\n",
      "ejemplar: [0.96129489 0.96211737 0.96501374 0.96634412 0.96827614 0.96983367\n",
      " 0.96952689 0.97081703]\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.97096205]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[0.96129489 0.96211737 0.96501374 0.96634412 0.96827614 0.96983367\n",
      "  0.96952689 0.97081703]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0327458530664444\n",
      "Predicción post entrenamiento : [[0.96965176]]\n",
      "PERDIDAAAA despues: 0.03227335587143898\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "[[[0.96211737]\n",
      "  [0.96501374]\n",
      "  [0.96634412]\n",
      "  [0.96827614]\n",
      "  [0.96983367]\n",
      "  [0.96952689]\n",
      "  [0.97081703]\n",
      "  [0.97096205]]]\n",
      "ejemplar: [0.96211737 0.96501374 0.96634412 0.96827614 0.96983367 0.96952689\n",
      " 0.97081703 0.97096205]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.9710905]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[0.96211737 0.96501374 0.96634412 0.96827614 0.96983367 0.96952689\n",
      "  0.97081703 0.97096205]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04448726028203964\n",
      "Predicción post entrenamiento : [[0.97010916]]\n",
      "PERDIDAAAA despues: 0.04407425969839096\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "[[[0.96501374]\n",
      "  [0.96634412]\n",
      "  [0.96827614]\n",
      "  [0.96983367]\n",
      "  [0.96952689]\n",
      "  [0.97081703]\n",
      "  [0.97096205]\n",
      "  [0.9710905 ]]]\n",
      "ejemplar: [0.96501374 0.96634412 0.96827614 0.96983367 0.96952689 0.97081703\n",
      " 0.97096205 0.9710905 ]\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.97171056]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[0.96501374 0.96634412 0.96827614 0.96983367 0.96952689 0.97081703\n",
      "  0.97096205 0.9710905 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08197759091854095\n",
      "Predicción post entrenamiento : [[0.9700605]]\n",
      "PERDIDAAAA despues: 0.08103544265031815\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "[[[0.96634412]\n",
      "  [0.96827614]\n",
      "  [0.96983367]\n",
      "  [0.96952689]\n",
      "  [0.97081703]\n",
      "  [0.97096205]\n",
      "  [0.9710905 ]\n",
      "  [0.97171056]]]\n",
      "ejemplar: [0.96634412 0.96827614 0.96983367 0.96952689 0.97081703 0.97096205\n",
      " 0.9710905  0.97171056]\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.97116834]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[0.96634412 0.96827614 0.96983367 0.96952689 0.97081703 0.97096205\n",
      "  0.9710905  0.97171056]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13393884897232056\n",
      "Predicción post entrenamiento : [[0.9661312]]\n",
      "PERDIDAAAA despues: 0.13027727603912354\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "[[[0.96827614]\n",
      "  [0.96983367]\n",
      "  [0.96952689]\n",
      "  [0.97081703]\n",
      "  [0.97096205]\n",
      "  [0.9710905 ]\n",
      "  [0.97171056]\n",
      "  [0.97116834]]]\n",
      "ejemplar: [0.96827614 0.96983367 0.96952689 0.97081703 0.97096205 0.9710905\n",
      " 0.97171056 0.97116834]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9671062]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[0.96827614 0.96983367 0.96952689 0.97081703 0.97096205 0.9710905\n",
      "  0.97171056 0.97116834]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.091353639960289\n",
      "Predicción post entrenamiento : [[0.96598554]]\n",
      "PERDIDAAAA despues: 0.09067744761705399\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "[[[0.96983367]\n",
      "  [0.96952689]\n",
      "  [0.97081703]\n",
      "  [0.97096205]\n",
      "  [0.9710905 ]\n",
      "  [0.97171056]\n",
      "  [0.97116834]\n",
      "  [0.96710622]]]\n",
      "ejemplar: [0.96983367 0.96952689 0.97081703 0.97096205 0.9710905  0.97171056\n",
      " 0.97116834 0.96710622]\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.9665639]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[0.96983367 0.96952689 0.97081703 0.97096205 0.9710905  0.97171056\n",
      "  0.97116834 0.96710622]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06692501902580261\n",
      "Predicción post entrenamiento : [[0.96594435]]\n",
      "PERDIDAAAA despues: 0.0666048601269722\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "[[[0.96952689]\n",
      "  [0.97081703]\n",
      "  [0.97096205]\n",
      "  [0.9710905 ]\n",
      "  [0.97171056]\n",
      "  [0.97116834]\n",
      "  [0.96710622]\n",
      "  [0.96656388]]]\n",
      "ejemplar: [0.96952689 0.97081703 0.97096205 0.9710905  0.97171056 0.97116834\n",
      " 0.96710622 0.96656388]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9661192]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[0.96952689 0.97081703 0.97096205 0.9710905  0.97171056 0.97116834\n",
      "  0.96710622 0.96656388]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09075798094272614\n",
      "Predicción post entrenamiento : [[0.9645238]]\n",
      "PERDIDAAAA despues: 0.08979924023151398\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "[[[0.97081703]\n",
      "  [0.97096205]\n",
      "  [0.9710905 ]\n",
      "  [0.97171056]\n",
      "  [0.97116834]\n",
      "  [0.96710622]\n",
      "  [0.96656388]\n",
      "  [0.96611923]]]\n",
      "ejemplar: [0.97081703 0.97096205 0.9710905  0.97171056 0.97116834 0.96710622\n",
      " 0.96656388 0.96611923]\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.9647495]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[0.97081703 0.97096205 0.9710905  0.97171056 0.97116834 0.96710622\n",
      "  0.96656388 0.96611923]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06421021372079849\n",
      "Predicción post entrenamiento : [[0.96218526]]\n",
      "PERDIDAAAA despues: 0.06291723996400833\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "[[[0.97096205]\n",
      "  [0.9710905 ]\n",
      "  [0.97171056]\n",
      "  [0.97116834]\n",
      "  [0.96710622]\n",
      "  [0.96656388]\n",
      "  [0.96611923]\n",
      "  [0.96474952]]]\n",
      "ejemplar: [0.97096205 0.9710905  0.97171056 0.97116834 0.96710622 0.96656388\n",
      " 0.96611923 0.96474952]\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.96192664]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[0.97096205 0.9710905  0.97171056 0.97116834 0.96710622 0.96656388\n",
      "  0.96611923 0.96474952]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08103687316179276\n",
      "Predicción post entrenamiento : [[0.9613584]]\n",
      "PERDIDAAAA despues: 0.08071368932723999\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "[[[0.9710905 ]\n",
      "  [0.97171056]\n",
      "  [0.97116834]\n",
      "  [0.96710622]\n",
      "  [0.96656388]\n",
      "  [0.96611923]\n",
      "  [0.96474952]\n",
      "  [0.96192664]]]\n",
      "ejemplar: [0.9710905  0.97171056 0.97116834 0.96710622 0.96656388 0.96611923\n",
      " 0.96474952 0.96192664]\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.9608371]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[0.9710905  0.97171056 0.97116834 0.96710622 0.96656388 0.96611923\n",
      "  0.96474952 0.96192664]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0394933745265007\n",
      "Predicción post entrenamiento : [[0.95783705]]\n",
      "PERDIDAAAA despues: 0.038309965282678604\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "[[[0.97171056]\n",
      "  [0.97116834]\n",
      "  [0.96710622]\n",
      "  [0.96656388]\n",
      "  [0.96611923]\n",
      "  [0.96474952]\n",
      "  [0.96192664]\n",
      "  [0.96083713]]]\n",
      "ejemplar: [0.97171056 0.97116834 0.96710622 0.96656388 0.96611923 0.96474952\n",
      " 0.96192664 0.96083713]\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.95697653]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[0.97171056 0.97116834 0.96710622 0.96656388 0.96611923 0.96474952\n",
      "  0.96192664 0.96083713]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02247750386595726\n",
      "Predicción post entrenamiento : [[0.955894]]\n",
      "PERDIDAAAA despues: 0.022154076024889946\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "[[[0.97116834]\n",
      "  [0.96710622]\n",
      "  [0.96656388]\n",
      "  [0.96611923]\n",
      "  [0.96474952]\n",
      "  [0.96192664]\n",
      "  [0.96083713]\n",
      "  [0.95697653]]]\n",
      "ejemplar: [0.97116834 0.96710622 0.96656388 0.96611923 0.96474952 0.96192664\n",
      " 0.96083713 0.95697653]\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.9544529]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[0.97116834 0.96710622 0.96656388 0.96611923 0.96474952 0.96192664\n",
      "  0.96083713 0.95697653]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01939472369849682\n",
      "Predicción post entrenamiento : [[0.95401895]]\n",
      "PERDIDAAAA despues: 0.01927405223250389\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "[[[0.96710622]\n",
      "  [0.96656388]\n",
      "  [0.96611923]\n",
      "  [0.96474952]\n",
      "  [0.96192664]\n",
      "  [0.96083713]\n",
      "  [0.95697653]\n",
      "  [0.95445287]]]\n",
      "ejemplar: [0.96710622 0.96656388 0.96611923 0.96474952 0.96192664 0.96083713\n",
      " 0.95697653 0.95445287]\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.95223576]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[0.96710622 0.96656388 0.96611923 0.96474952 0.96192664 0.96083713\n",
      "  0.95697653 0.95445287]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002115802839398384\n",
      "Predicción post entrenamiento : [[0.9515632]]\n",
      "PERDIDAAAA despues: 0.002054380951449275\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "[[[0.96656388]\n",
      "  [0.96611923]\n",
      "  [0.96474952]\n",
      "  [0.96192664]\n",
      "  [0.96083713]\n",
      "  [0.95697653]\n",
      "  [0.95445287]\n",
      "  [0.95223576]]]\n",
      "ejemplar: [0.96656388 0.96611923 0.96474952 0.96192664 0.96083713 0.95697653\n",
      " 0.95445287 0.95223576]\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.9504326]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[0.96656388 0.96611923 0.96474952 0.96192664 0.96083713 0.95697653\n",
      "  0.95445287 0.95223576]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.598728891229257e-05\n",
      "Predicción post entrenamiento : [[0.95026195]]\n",
      "PERDIDAAAA despues: 8.918122330214828e-05\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "[[[0.96611923]\n",
      "  [0.96474952]\n",
      "  [0.96192664]\n",
      "  [0.96083713]\n",
      "  [0.95697653]\n",
      "  [0.95445287]\n",
      "  [0.95223576]\n",
      "  [0.9504326 ]]]\n",
      "ejemplar: [0.96611923 0.96474952 0.96192664 0.96083713 0.95697653 0.95445287\n",
      " 0.95223576 0.9504326 ]\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.94877493]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[0.96611923 0.96474952 0.96192664 0.96083713 0.95697653 0.95445287\n",
      "  0.95223576 0.9504326 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00024273450253531337\n",
      "Predicción post entrenamiento : [[0.949154]]\n",
      "PERDIDAAAA despues: 0.0002310659474460408\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "[[[0.96474952]\n",
      "  [0.96192664]\n",
      "  [0.96083713]\n",
      "  [0.95697653]\n",
      "  [0.95445287]\n",
      "  [0.95223576]\n",
      "  [0.9504326 ]\n",
      "  [0.94877493]]]\n",
      "ejemplar: [0.96474952 0.96192664 0.96083713 0.95697653 0.95445287 0.95223576\n",
      " 0.9504326  0.94877493]\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.94719785]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[0.96474952 0.96192664 0.96083713 0.95697653 0.95445287 0.95223576\n",
      "  0.9504326  0.94877493]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003501082770526409\n",
      "Predicción post entrenamiento : [[0.9462513]]\n",
      "PERDIDAAAA despues: 0.0033899603877216578\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "[[[0.96192664]\n",
      "  [0.96083713]\n",
      "  [0.95697653]\n",
      "  [0.95445287]\n",
      "  [0.95223576]\n",
      "  [0.9504326 ]\n",
      "  [0.94877493]\n",
      "  [0.94719785]]]\n",
      "ejemplar: [0.96192664 0.96083713 0.95697653 0.95445287 0.95223576 0.9504326\n",
      " 0.94877493 0.94719785]\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.94403476]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[0.96192664 0.96083713 0.95697653 0.95445287 0.95223576 0.9504326\n",
      "  0.94877493 0.94719785]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0026375935412943363\n",
      "Predicción post entrenamiento : [[0.94357723]]\n",
      "PERDIDAAAA despues: 0.002590808318927884\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "[[[0.96083713]\n",
      "  [0.95697653]\n",
      "  [0.95445287]\n",
      "  [0.95223576]\n",
      "  [0.9504326 ]\n",
      "  [0.94877493]\n",
      "  [0.94719785]\n",
      "  [0.94403476]]]\n",
      "ejemplar: [0.96083713 0.95697653 0.95445287 0.95223576 0.9504326  0.94877493\n",
      " 0.94719785 0.94403476]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.9415094]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[0.96083713 0.95697653 0.95445287 0.95223576 0.9504326  0.94877493\n",
      "  0.94719785 0.94403476]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004391348455101252\n",
      "Predicción post entrenamiento : [[0.93976974]]\n",
      "PERDIDAAAA despues: 0.004163807258009911\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "[[[0.95697653]\n",
      "  [0.95445287]\n",
      "  [0.95223576]\n",
      "  [0.9504326 ]\n",
      "  [0.94877493]\n",
      "  [0.94719785]\n",
      "  [0.94403476]\n",
      "  [0.94150943]]]\n",
      "ejemplar: [0.95697653 0.95445287 0.95223576 0.9504326  0.94877493 0.94719785\n",
      " 0.94403476 0.94150943]\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.93735623]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[0.95697653 0.95445287 0.95223576 0.9504326  0.94877493 0.94719785\n",
      "  0.94403476 0.94150943]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007486270274966955\n",
      "Predicción post entrenamiento : [[0.93730986]]\n",
      "PERDIDAAAA despues: 0.0074782478623092175\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "[[[0.95445287]\n",
      "  [0.95223576]\n",
      "  [0.9504326 ]\n",
      "  [0.94877493]\n",
      "  [0.94719785]\n",
      "  [0.94403476]\n",
      "  [0.94150943]\n",
      "  [0.93735623]]]\n",
      "ejemplar: [0.95445287 0.95223576 0.9504326  0.94877493 0.94719785 0.94403476\n",
      " 0.94150943 0.93735623]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.9353353]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[0.95445287 0.95223576 0.9504326  0.94877493 0.94719785 0.94403476\n",
      "  0.94150943 0.93735623]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007471785414963961\n",
      "Predicción post entrenamiento : [[0.9348145]]\n",
      "PERDIDAAAA despues: 0.007382027339190245\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "[[[0.95223576]\n",
      "  [0.9504326 ]\n",
      "  [0.94877493]\n",
      "  [0.94719785]\n",
      "  [0.94403476]\n",
      "  [0.94150943]\n",
      "  [0.93735623]\n",
      "  [0.93533528]]]\n",
      "ejemplar: [0.95223576 0.9504326  0.94877493 0.94719785 0.94403476 0.94150943\n",
      " 0.93735623 0.93533528]\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.9329262]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[0.95223576 0.9504326  0.94877493 0.94719785 0.94403476 0.94150943\n",
      "  0.93735623 0.93533528]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008697476587258279\n",
      "Predicción post entrenamiento : [[0.93290716]]\n",
      "PERDIDAAAA despues: 0.0008708694949746132\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "[[[0.9504326 ]\n",
      "  [0.94877493]\n",
      "  [0.94719785]\n",
      "  [0.94403476]\n",
      "  [0.94150943]\n",
      "  [0.93735623]\n",
      "  [0.93533528]\n",
      "  [0.93292618]]]\n",
      "ejemplar: [0.9504326  0.94877493 0.94719785 0.94403476 0.94150943 0.93735623\n",
      " 0.93533528 0.93292618]\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.9309999]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[0.9504326  0.94877493 0.94719785 0.94403476 0.94150943 0.93735623\n",
      "  0.93533528 0.93292618]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013573365285992622\n",
      "Predicción post entrenamiento : [[0.9307581]]\n",
      "PERDIDAAAA despues: 0.0013752086088061333\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "[[[0.94877493]\n",
      "  [0.94719785]\n",
      "  [0.94403476]\n",
      "  [0.94150943]\n",
      "  [0.93735623]\n",
      "  [0.93533528]\n",
      "  [0.93292618]\n",
      "  [0.93099988]]]\n",
      "ejemplar: [0.94877493 0.94719785 0.94403476 0.94150943 0.93735623 0.93533528\n",
      " 0.93292618 0.93099988]\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.928682]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[0.94877493 0.94719785 0.94403476 0.94150943 0.93735623 0.93533528\n",
      "  0.93292618 0.93099988]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00014492904301732779\n",
      "Predicción post entrenamiento : [[0.9292761]]\n",
      "PERDIDAAAA despues: 0.00013097815099172294\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "[[[0.94719785]\n",
      "  [0.94403476]\n",
      "  [0.94150943]\n",
      "  [0.93735623]\n",
      "  [0.93533528]\n",
      "  [0.93292618]\n",
      "  [0.93099988]\n",
      "  [0.92868203]]]\n",
      "ejemplar: [0.94719785 0.94403476 0.94150943 0.93735623 0.93533528 0.93292618\n",
      " 0.93099988 0.92868203]\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.92695016]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[0.94719785 0.94403476 0.94150943 0.93735623 0.93533528 0.93292618\n",
      "  0.93099988 0.92868203]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002073992509394884\n",
      "Predicción post entrenamiento : [[0.92674613]]\n",
      "PERDIDAAAA despues: 0.002092617331072688\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "[[[0.94403476]\n",
      "  [0.94150943]\n",
      "  [0.93735623]\n",
      "  [0.93533528]\n",
      "  [0.93292618]\n",
      "  [0.93099988]\n",
      "  [0.92868203]\n",
      "  [0.92695016]]]\n",
      "ejemplar: [0.94403476 0.94150943 0.93735623 0.93533528 0.93292618 0.93099988\n",
      " 0.92868203 0.92695016]\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.9241179]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[0.94403476 0.94150943 0.93735623 0.93533528 0.93292618 0.93099988\n",
      "  0.92868203 0.92695016]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005297294817864895\n",
      "Predicción post entrenamiento : [[0.9243266]]\n",
      "PERDIDAAAA despues: 0.005266962572932243\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "[[[0.94150943]\n",
      "  [0.93735623]\n",
      "  [0.93533528]\n",
      "  [0.93292618]\n",
      "  [0.93099988]\n",
      "  [0.92868203]\n",
      "  [0.92695016]\n",
      "  [0.92411792]]]\n",
      "ejemplar: [0.94150943 0.93735623 0.93533528 0.93292618 0.93099988 0.92868203\n",
      " 0.92695016 0.92411792]\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.92185]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[0.94150943 0.93735623 0.93533528 0.93292618 0.93099988 0.92868203\n",
      "  0.92695016 0.92411792]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008603477035649121\n",
      "Predicción post entrenamiento : [[0.922596]]\n",
      "PERDIDAAAA despues: 0.0008171440567821264\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "[[[0.93735623]\n",
      "  [0.93533528]\n",
      "  [0.93292618]\n",
      "  [0.93099988]\n",
      "  [0.92868203]\n",
      "  [0.92695016]\n",
      "  [0.92411792]\n",
      "  [0.92185003]]]\n",
      "ejemplar: [0.93735623 0.93533528 0.93292618 0.93099988 0.92868203 0.92695016\n",
      " 0.92411792 0.92185003]\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.92012256]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[0.93735623 0.93533528 0.93292618 0.93099988 0.92868203 0.92695016\n",
      "  0.92411792 0.92185003]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005927158053964376\n",
      "Predicción post entrenamiento : [[0.91957897]]\n",
      "PERDIDAAAA despues: 0.0005665429052896798\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "[[[0.93533528]\n",
      "  [0.93292618]\n",
      "  [0.93099988]\n",
      "  [0.92868203]\n",
      "  [0.92695016]\n",
      "  [0.92411792]\n",
      "  [0.92185003]\n",
      "  [0.92012256]]]\n",
      "ejemplar: [0.93533528 0.93292618 0.93099988 0.92868203 0.92695016 0.92411792\n",
      " 0.92185003 0.92012256]\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.9176216]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[0.93533528 0.93292618 0.93099988 0.92868203 0.92695016 0.92411792\n",
      "  0.92185003 0.92012256]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013090153224766254\n",
      "Predicción post entrenamiento : [[0.91788423]]\n",
      "PERDIDAAAA despues: 0.0013280875282362103\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "[[[0.93292618]\n",
      "  [0.93099988]\n",
      "  [0.92868203]\n",
      "  [0.92695016]\n",
      "  [0.92411792]\n",
      "  [0.92185003]\n",
      "  [0.92012256]\n",
      "  [0.91762161]]]\n",
      "ejemplar: [0.93292618 0.93099988 0.92868203 0.92695016 0.92411792 0.92185003\n",
      " 0.92012256 0.91762161]\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.9158803]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[0.93292618 0.93099988 0.92868203 0.92695016 0.92411792 0.92185003\n",
      "  0.92012256 0.91762161]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.4546772035828326e-06\n",
      "Predicción post entrenamiento : [[0.9159144]]\n",
      "PERDIDAAAA despues: 1.3735983657170436e-06\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "[[[0.93099988]\n",
      "  [0.92868203]\n",
      "  [0.92695016]\n",
      "  [0.92411792]\n",
      "  [0.92185003]\n",
      "  [0.92012256]\n",
      "  [0.91762161]\n",
      "  [0.91588032]]]\n",
      "ejemplar: [0.93099988 0.92868203 0.92695016 0.92411792 0.92185003 0.92012256\n",
      " 0.91762161 0.91588032]\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.91397524]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[0.93099988 0.92868203 0.92695016 0.92411792 0.92185003 0.92012256\n",
      "  0.91762161 0.91588032]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.391098653082736e-05\n",
      "Predicción post entrenamiento : [[0.91418165]]\n",
      "PERDIDAAAA despues: 3.1549603590974584e-05\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "[[[0.92868203]\n",
      "  [0.92695016]\n",
      "  [0.92411792]\n",
      "  [0.92185003]\n",
      "  [0.92012256]\n",
      "  [0.91762161]\n",
      "  [0.91588032]\n",
      "  [0.91397524]]]\n",
      "ejemplar: [0.92868203 0.92695016 0.92411792 0.92185003 0.92012256 0.91762161\n",
      " 0.91588032 0.91397524]\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.9121738]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[0.92868203 0.92695016 0.92411792 0.92185003 0.92012256 0.91762161\n",
      "  0.91588032 0.91397524]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0024471813812851906\n",
      "Predicción post entrenamiento : [[0.91179043]]\n",
      "PERDIDAAAA despues: 0.0024852589704096317\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "[[[0.92695016]\n",
      "  [0.92411792]\n",
      "  [0.92185003]\n",
      "  [0.92012256]\n",
      "  [0.91762161]\n",
      "  [0.91588032]\n",
      "  [0.91397524]\n",
      "  [0.91217381]]]\n",
      "ejemplar: [0.92695016 0.92411792 0.92185003 0.92012256 0.91762161 0.91588032\n",
      " 0.91397524 0.91217381]\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.9098296]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[0.92695016 0.92411792 0.92185003 0.92012256 0.91762161 0.91588032\n",
      "  0.91397524 0.91217381]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0034105293452739716\n",
      "Predicción post entrenamiento : [[0.91038173]]\n",
      "PERDIDAAAA despues: 0.003346347017213702\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "[[[0.92411792]\n",
      "  [0.92185003]\n",
      "  [0.92012256]\n",
      "  [0.91762161]\n",
      "  [0.91588032]\n",
      "  [0.91397524]\n",
      "  [0.91217381]\n",
      "  [0.90982962]]]\n",
      "ejemplar: [0.92411792 0.92185003 0.92012256 0.91762161 0.91588032 0.91397524\n",
      " 0.91217381 0.90982962]\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.9083048]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[0.92411792 0.92185003 0.92012256 0.91762161 0.91588032 0.91397524\n",
      "  0.91217381 0.90982962]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002446638885885477\n",
      "Predicción post entrenamiento : [[0.9087349]]\n",
      "PERDIDAAAA despues: 0.0024042746517807245\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "[[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "ejemplar: [0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      " 0.03448276 0.04223169]\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.22457577]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      "  0.03448276 0.04223169]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.031851403415203094\n",
      "Predicción post entrenamiento : [[0.18015821]]\n",
      "PERDIDAAAA despues: 0.017969952896237373\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "[[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22457577]]]\n",
      "ejemplar: [0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      " 0.04223169 0.22457577]\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.16431859]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      "  0.04223169 0.22457577]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003611459629610181\n",
      "Predicción post entrenamiento : [[0.14963377]]\n",
      "PERDIDAAAA despues: 0.002062122104689479\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "[[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22457577]\n",
      "  [0.16431859]]]\n",
      "ejemplar: [0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      " 0.22457577 0.16431859]\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.15334071]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      "  0.22457577 0.16431859]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.449246481883165e-07\n",
      "Predicción post entrenamiento : [[0.15244327]]\n",
      "PERDIDAAAA despues: 3.0994569897302426e-06\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "[[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22457577]\n",
      "  [0.16431859]\n",
      "  [0.15334071]]]\n",
      "ejemplar: [0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.22457577\n",
      " 0.16431859 0.15334071]\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.1632066]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.22457577\n",
      "  0.16431859 0.15334071]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.554757080972195e-05\n",
      "Predicción post entrenamiento : [[0.15866925]]\n",
      "PERDIDAAAA despues: 8.501105185132474e-06\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "[[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22457577]\n",
      "  [0.16431859]\n",
      "  [0.15334071]\n",
      "  [0.16320661]]]\n",
      "ejemplar: [0.05656722 0.02595893 0.03448276 0.04223169 0.22457577 0.16431859\n",
      " 0.15334071 0.16320661]\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.17001805]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[0.05656722 0.02595893 0.03448276 0.04223169 0.22457577 0.16431859\n",
      "  0.15334071 0.16320661]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001978941960260272\n",
      "Predicción post entrenamiento : [[0.16518478]]\n",
      "PERDIDAAAA despues: 0.0015722837997600436\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "[[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22457577]\n",
      "  [0.16431859]\n",
      "  [0.15334071]\n",
      "  [0.16320661]\n",
      "  [0.17001805]]]\n",
      "ejemplar: [0.02595893 0.03448276 0.04223169 0.22457577 0.16431859 0.15334071\n",
      " 0.16320661 0.17001805]\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.17302237]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[0.02595893 0.03448276 0.04223169 0.22457577 0.16431859 0.15334071\n",
      "  0.16320661 0.17001805]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000747607322409749\n",
      "Predicción post entrenamiento : [[0.17255294]]\n",
      "PERDIDAAAA despues: 0.00072215695399791\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "[[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22457577]\n",
      "  [0.16431859]\n",
      "  [0.15334071]\n",
      "  [0.16320661]\n",
      "  [0.17001805]\n",
      "  [0.17302237]]]\n",
      "ejemplar: [0.03448276 0.04223169 0.22457577 0.16431859 0.15334071 0.16320661\n",
      " 0.17001805 0.17302237]\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.19055314]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[0.03448276 0.04223169 0.22457577 0.16431859 0.15334071 0.16320661\n",
      "  0.17001805 0.17302237]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0019446590449661016\n",
      "Predicción post entrenamiento : [[0.18628132]]\n",
      "PERDIDAAAA despues: 0.0015861474676057696\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "[[[0.04223169]\n",
      "  [0.22457577]\n",
      "  [0.16431859]\n",
      "  [0.15334071]\n",
      "  [0.16320661]\n",
      "  [0.17001805]\n",
      "  [0.17302237]\n",
      "  [0.19055314]]]\n",
      "ejemplar: [0.04223169 0.22457577 0.16431859 0.15334071 0.16320661 0.17001805\n",
      " 0.17302237 0.19055314]\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.20770139]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[0.04223169 0.22457577 0.16431859 0.15334071 0.16320661 0.17001805\n",
      "  0.17302237 0.19055314]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001358005392830819\n",
      "Predicción post entrenamiento : [[0.20888849]]\n",
      "PERDIDAAAA despues: 0.00016487715765833855\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "[[[0.22457577]\n",
      "  [0.16431859]\n",
      "  [0.15334071]\n",
      "  [0.16320661]\n",
      "  [0.17001805]\n",
      "  [0.17302237]\n",
      "  [0.19055314]\n",
      "  [0.20770139]]]\n",
      "ejemplar: [0.22457577 0.16431859 0.15334071 0.16320661 0.17001805 0.17302237\n",
      " 0.19055314 0.20770139]\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.23401646]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[0.22457577 0.16431859 0.15334071 0.16320661 0.17001805 0.17302237\n",
      "  0.19055314 0.20770139]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.214985877595609e-05\n",
      "Predicción post entrenamiento : [[0.2316852]]\n",
      "PERDIDAAAA despues: 1.3326574617167353e-06\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "[[[0.16431859]\n",
      "  [0.15334071]\n",
      "  [0.16320661]\n",
      "  [0.17001805]\n",
      "  [0.17302237]\n",
      "  [0.19055314]\n",
      "  [0.20770139]\n",
      "  [0.23401646]]]\n",
      "ejemplar: [0.16431859 0.15334071 0.16320661 0.17001805 0.17302237 0.19055314\n",
      " 0.20770139 0.23401646]\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.2215876]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[0.16431859 0.15334071 0.16320661 0.17001805 0.17302237 0.19055314\n",
      "  0.20770139 0.23401646]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00017269270028918982\n",
      "Predicción post entrenamiento : [[0.22106583]]\n",
      "PERDIDAAAA despues: 0.00015925166371744126\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "[[[0.15334071]\n",
      "  [0.16320661]\n",
      "  [0.17001805]\n",
      "  [0.17302237]\n",
      "  [0.19055314]\n",
      "  [0.20770139]\n",
      "  [0.23401646]\n",
      "  [0.2215876 ]]]\n",
      "ejemplar: [0.15334071 0.16320661 0.17001805 0.17302237 0.19055314 0.20770139\n",
      " 0.23401646 0.2215876 ]\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.22342536]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[0.15334071 0.16320661 0.17001805 0.17302237 0.19055314 0.20770139\n",
      "  0.23401646 0.2215876 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00013206603762228042\n",
      "Predicción post entrenamiento : [[0.22362912]]\n",
      "PERDIDAAAA despues: 0.00013679073890671134\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "[[[0.16320661]\n",
      "  [0.17001805]\n",
      "  [0.17302237]\n",
      "  [0.19055314]\n",
      "  [0.20770139]\n",
      "  [0.23401646]\n",
      "  [0.2215876 ]\n",
      "  [0.22342536]]]\n",
      "ejemplar: [0.16320661 0.17001805 0.17302237 0.19055314 0.20770139 0.23401646\n",
      " 0.2215876  0.22342536]\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.22998294]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[0.16320661 0.17001805 0.17302237 0.19055314 0.20770139 0.23401646\n",
      "  0.2215876  0.22342536]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005152418161742389\n",
      "Predicción post entrenamiento : [[0.22884314]]\n",
      "PERDIDAAAA despues: 0.0004647962632589042\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "[[[0.17001805]\n",
      "  [0.17302237]\n",
      "  [0.19055314]\n",
      "  [0.20770139]\n",
      "  [0.23401646]\n",
      "  [0.2215876 ]\n",
      "  [0.22342536]\n",
      "  [0.22998294]]]\n",
      "ejemplar: [0.17001805 0.17302237 0.19055314 0.20770139 0.23401646 0.2215876\n",
      " 0.22342536 0.22998294]\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.2352599]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[0.17001805 0.17302237 0.19055314 0.20770139 0.23401646 0.2215876\n",
      "  0.22342536 0.22998294]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017902570543810725\n",
      "Predicción post entrenamiento : [[0.23278633]]\n",
      "PERDIDAAAA despues: 0.0015870544593781233\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "[[[0.17302237]\n",
      "  [0.19055314]\n",
      "  [0.20770139]\n",
      "  [0.23401646]\n",
      "  [0.2215876 ]\n",
      "  [0.22342536]\n",
      "  [0.22998294]\n",
      "  [0.23525991]]]\n",
      "ejemplar: [0.17302237 0.19055314 0.20770139 0.23401646 0.2215876  0.22342536\n",
      " 0.22998294 0.23525991]\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.23983243]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[0.17302237 0.19055314 0.20770139 0.23401646 0.2215876  0.22342536\n",
      "  0.22998294 0.23525991]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018498161807656288\n",
      "Predicción post entrenamiento : [[0.23920709]]\n",
      "PERDIDAAAA despues: 0.0017964160069823265\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "[[[0.19055314]\n",
      "  [0.20770139]\n",
      "  [0.23401646]\n",
      "  [0.2215876 ]\n",
      "  [0.22342536]\n",
      "  [0.22998294]\n",
      "  [0.23525991]\n",
      "  [0.23983243]]]\n",
      "ejemplar: [0.19055314 0.20770139 0.23401646 0.2215876  0.22342536 0.22998294\n",
      " 0.23525991 0.23983243]\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.24769302]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[0.19055314 0.20770139 0.23401646 0.2215876  0.22342536 0.22998294\n",
      "  0.23525991 0.23983243]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001117897336371243\n",
      "Predicción post entrenamiento : [[0.24569745]]\n",
      "PERDIDAAAA despues: 0.00098843639716506\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "[[[0.20770139]\n",
      "  [0.23401646]\n",
      "  [0.2215876 ]\n",
      "  [0.22342536]\n",
      "  [0.22998294]\n",
      "  [0.23525991]\n",
      "  [0.23983243]\n",
      "  [0.24769302]]]\n",
      "ejemplar: [0.20770139 0.23401646 0.2215876  0.22342536 0.22998294 0.23525991\n",
      " 0.23983243 0.24769302]\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.25239238]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[0.20770139 0.23401646 0.2215876  0.22342536 0.22998294 0.23525991\n",
      "  0.23983243 0.24769302]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005050563719123602\n",
      "Predicción post entrenamiento : [[0.2501897]]\n",
      "PERDIDAAAA despues: 0.004742336925119162\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "[[[0.23401646]\n",
      "  [0.2215876 ]\n",
      "  [0.22342536]\n",
      "  [0.22998294]\n",
      "  [0.23525991]\n",
      "  [0.23983243]\n",
      "  [0.24769302]\n",
      "  [0.25239238]]]\n",
      "ejemplar: [0.23401646 0.2215876  0.22342536 0.22998294 0.23525991 0.23983243\n",
      " 0.24769302 0.25239238]\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.25468677]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[0.23401646 0.2215876  0.22342536 0.22998294 0.23525991 0.23983243\n",
      "  0.24769302 0.25239238]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006329928059130907\n",
      "Predicción post entrenamiento : [[0.25260153]]\n",
      "PERDIDAAAA despues: 0.006002469919621944\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "[[[0.2215876 ]\n",
      "  [0.22342536]\n",
      "  [0.22998294]\n",
      "  [0.23525991]\n",
      "  [0.23983243]\n",
      "  [0.24769302]\n",
      "  [0.25239238]\n",
      "  [0.25468677]]]\n",
      "ejemplar: [0.2215876  0.22342536 0.22998294 0.23525991 0.23983243 0.24769302\n",
      " 0.25239238 0.25468677]\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.25236985]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[0.2215876  0.22342536 0.22998294 0.23525991 0.23983243 0.24769302\n",
      "  0.25239238 0.25468677]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010892095044255257\n",
      "Predicción post entrenamiento : [[0.24934518]]\n",
      "PERDIDAAAA despues: 0.01026990357786417\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "[[[0.22342536]\n",
      "  [0.22998294]\n",
      "  [0.23525991]\n",
      "  [0.23983243]\n",
      "  [0.24769302]\n",
      "  [0.25239238]\n",
      "  [0.25468677]\n",
      "  [0.25236985]]]\n",
      "ejemplar: [0.22342536 0.22998294 0.23525991 0.23983243 0.24769302 0.25239238\n",
      " 0.25468677 0.25236985]\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.2524018]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[0.22342536 0.22998294 0.23525991 0.23983243 0.24769302 0.25239238\n",
      "  0.25468677 0.25236985]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008751348592340946\n",
      "Predicción post entrenamiento : [[0.25094175]]\n",
      "PERDIDAAAA despues: 0.008480309508740902\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "[[[0.22998294]\n",
      "  [0.23525991]\n",
      "  [0.23983243]\n",
      "  [0.24769302]\n",
      "  [0.25239238]\n",
      "  [0.25468677]\n",
      "  [0.25236985]\n",
      "  [0.2524018 ]]]\n",
      "ejemplar: [0.22998294 0.23525991 0.23983243 0.24769302 0.25239238 0.25468677\n",
      " 0.25236985 0.2524018 ]\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.25459227]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[0.22998294 0.23525991 0.23983243 0.24769302 0.25239238 0.25468677\n",
      "  0.25236985 0.2524018 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003896093927323818\n",
      "Predicción post entrenamiento : [[0.25340432]]\n",
      "PERDIDAAAA despues: 0.0037492045667022467\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "[[[0.23525991]\n",
      "  [0.23983243]\n",
      "  [0.24769302]\n",
      "  [0.25239238]\n",
      "  [0.25468677]\n",
      "  [0.25236985]\n",
      "  [0.2524018 ]\n",
      "  [0.25459227]]]\n",
      "ejemplar: [0.23525991 0.23983243 0.24769302 0.25239238 0.25468677 0.25236985\n",
      " 0.2524018  0.25459227]\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.25657976]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[0.23525991 0.23983243 0.24769302 0.25239238 0.25468677 0.25236985\n",
      "  0.2524018  0.25459227]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004985111765563488\n",
      "Predicción post entrenamiento : [[0.25513345]]\n",
      "PERDIDAAAA despues: 0.00478296959772706\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "[[[0.23983243]\n",
      "  [0.24769302]\n",
      "  [0.25239238]\n",
      "  [0.25468677]\n",
      "  [0.25236985]\n",
      "  [0.2524018 ]\n",
      "  [0.25459227]\n",
      "  [0.25657976]]]\n",
      "ejemplar: [0.23983243 0.24769302 0.25239238 0.25468677 0.25236985 0.2524018\n",
      " 0.25459227 0.25657976]\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.2579412]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[0.23983243 0.24769302 0.25239238 0.25468677 0.25236985 0.2524018\n",
      "  0.25459227 0.25657976]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.1172889622394e-05\n",
      "Predicción post entrenamiento : [[0.25784925]]\n",
      "PERDIDAAAA despues: 8.283802890218794e-05\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "[[[0.24769302]\n",
      "  [0.25239238]\n",
      "  [0.25468677]\n",
      "  [0.25236985]\n",
      "  [0.2524018 ]\n",
      "  [0.25459227]\n",
      "  [0.25657976]\n",
      "  [0.25794119]]]\n",
      "ejemplar: [0.24769302 0.25239238 0.25468677 0.25236985 0.2524018  0.25459227\n",
      " 0.25657976 0.25794119]\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.26030105]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[0.24769302 0.25239238 0.25468677 0.25236985 0.2524018  0.25459227\n",
      "  0.25657976 0.25794119]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010382075561210513\n",
      "Predicción post entrenamiento : [[0.26120663]]\n",
      "PERDIDAAAA despues: 0.0009806702146306634\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "[[[0.25239238]\n",
      "  [0.25468677]\n",
      "  [0.25236985]\n",
      "  [0.2524018 ]\n",
      "  [0.25459227]\n",
      "  [0.25657976]\n",
      "  [0.25794119]\n",
      "  [0.26030105]]]\n",
      "ejemplar: [0.25239238 0.25468677 0.25236985 0.2524018  0.25459227 0.25657976\n",
      " 0.25794119 0.26030105]\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.26242673]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[0.25239238 0.25468677 0.25236985 0.2524018  0.25459227 0.25657976\n",
      "  0.25794119 0.26030105]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0030558323487639427\n",
      "Predicción post entrenamiento : [[0.26387092]]\n",
      "PERDIDAAAA despues: 0.0028982495423406363\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "[[[0.25468677]\n",
      "  [0.25236985]\n",
      "  [0.2524018 ]\n",
      "  [0.25459227]\n",
      "  [0.25657976]\n",
      "  [0.25794119]\n",
      "  [0.26030105]\n",
      "  [0.26242673]]]\n",
      "ejemplar: [0.25468677 0.25236985 0.2524018  0.25459227 0.25657976 0.25794119\n",
      " 0.26030105 0.26242673]\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.26435646]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[0.25468677 0.25236985 0.2524018  0.25459227 0.25657976 0.25794119\n",
      "  0.26030105 0.26242673]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0023341509513556957\n",
      "Predicción post entrenamiento : [[0.26525936]]\n",
      "PERDIDAAAA despues: 0.0022477232851088047\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "[[[0.25236985]\n",
      "  [0.2524018 ]\n",
      "  [0.25459227]\n",
      "  [0.25657976]\n",
      "  [0.25794119]\n",
      "  [0.26030105]\n",
      "  [0.26242673]\n",
      "  [0.26435646]]]\n",
      "ejemplar: [0.25236985 0.2524018  0.25459227 0.25657976 0.25794119 0.26030105\n",
      " 0.26242673 0.26435646]\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.2654619]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[0.25236985 0.2524018  0.25459227 0.25657976 0.25794119 0.26030105\n",
      "  0.26242673 0.26435646]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005557037075050175\n",
      "Predicción post entrenamiento : [[0.265773]]\n",
      "PERDIDAAAA despues: 0.0005411328747868538\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "[[[0.2524018 ]\n",
      "  [0.25459227]\n",
      "  [0.25657976]\n",
      "  [0.25794119]\n",
      "  [0.26030105]\n",
      "  [0.26242673]\n",
      "  [0.26435646]\n",
      "  [0.26546189]]]\n",
      "ejemplar: [0.2524018  0.25459227 0.25657976 0.25794119 0.26030105 0.26242673\n",
      " 0.26435646 0.26546189]\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.26673856]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[0.2524018  0.25459227 0.25657976 0.25794119 0.26030105 0.26242673\n",
      "  0.26435646 0.26546189]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00025913098943419755\n",
      "Predicción post entrenamiento : [[0.2674504]]\n",
      "PERDIDAAAA despues: 0.00023672029783483595\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "[[[0.25459227]\n",
      "  [0.25657976]\n",
      "  [0.25794119]\n",
      "  [0.26030105]\n",
      "  [0.26242673]\n",
      "  [0.26435646]\n",
      "  [0.26546189]\n",
      "  [0.26673856]]]\n",
      "ejemplar: [0.25459227 0.25657976 0.25794119 0.26030105 0.26242673 0.26435646\n",
      " 0.26546189 0.26673856]\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.2687848]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[0.25459227 0.25657976 0.25794119 0.26030105 0.26242673 0.26435646\n",
      "  0.26546189 0.26673856]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000943198159802705\n",
      "Predicción post entrenamiento : [[0.26992387]]\n",
      "PERDIDAAAA despues: 0.0008745302329771221\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "[[[0.25657976]\n",
      "  [0.25794119]\n",
      "  [0.26030105]\n",
      "  [0.26242673]\n",
      "  [0.26435646]\n",
      "  [0.26546189]\n",
      "  [0.26673856]\n",
      "  [0.26878479]]]\n",
      "ejemplar: [0.25657976 0.25794119 0.26030105 0.26242673 0.26435646 0.26546189\n",
      " 0.26673856 0.26878479]\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.27119023]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[0.25657976 0.25794119 0.26030105 0.26242673 0.26435646 0.26546189\n",
      "  0.26673856 0.26878479]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.1826106603839435e-05\n",
      "Predicción post entrenamiento : [[0.27162486]]\n",
      "PERDIDAAAA despues: 1.7953903807210736e-05\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "[[[0.25794119]\n",
      "  [0.26030105]\n",
      "  [0.26242673]\n",
      "  [0.26435646]\n",
      "  [0.26546189]\n",
      "  [0.26673856]\n",
      "  [0.26878479]\n",
      "  [0.27119023]]]\n",
      "ejemplar: [0.25794119 0.26030105 0.26242673 0.26435646 0.26546189 0.26673856\n",
      " 0.26878479 0.27119023]\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.27285424]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[0.25794119 0.26030105 0.26242673 0.26435646 0.26546189 0.26673856\n",
      "  0.26878479 0.27119023]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.405792767807725e-06\n",
      "Predicción post entrenamiento : [[0.2727442]]\n",
      "PERDIDAAAA despues: 3.824015948339365e-06\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "[[[0.26030105]\n",
      "  [0.26242673]\n",
      "  [0.26435646]\n",
      "  [0.26546189]\n",
      "  [0.26673856]\n",
      "  [0.26878479]\n",
      "  [0.27119023]\n",
      "  [0.27285424]]]\n",
      "ejemplar: [0.26030105 0.26242673 0.26435646 0.26546189 0.26673856 0.26878479\n",
      " 0.27119023 0.27285424]\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.2740732]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[0.26030105 0.26242673 0.26435646 0.26546189 0.26673856 0.26878479\n",
      "  0.27119023 0.27285424]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.963906925084302e-06\n",
      "Predicción post entrenamiento : [[0.2743047]]\n",
      "PERDIDAAAA despues: 1.3687126738659572e-06\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "[[[0.26242673]\n",
      "  [0.26435646]\n",
      "  [0.26546189]\n",
      "  [0.26673856]\n",
      "  [0.26878479]\n",
      "  [0.27119023]\n",
      "  [0.27285424]\n",
      "  [0.27407321]]]\n",
      "ejemplar: [0.26242673 0.26435646 0.26546189 0.26673856 0.26878479 0.27119023\n",
      " 0.27285424 0.27407321]\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.27551556]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[0.26242673 0.26435646 0.26546189 0.26673856 0.26878479 0.27119023\n",
      "  0.27285424 0.27407321]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003509188536554575\n",
      "Predicción post entrenamiento : [[0.27687657]]\n",
      "PERDIDAAAA despues: 0.003349792445078492\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "[[[0.26435646]\n",
      "  [0.26546189]\n",
      "  [0.26673856]\n",
      "  [0.26878479]\n",
      "  [0.27119023]\n",
      "  [0.27285424]\n",
      "  [0.27407321]\n",
      "  [0.27551556]]]\n",
      "ejemplar: [0.26435646 0.26546189 0.26673856 0.26878479 0.27119023 0.27285424\n",
      " 0.27407321 0.27551556]\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.27799952]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[0.26435646 0.26546189 0.26673856 0.26878479 0.27119023 0.27285424\n",
      "  0.27407321 0.27551556]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006033648736774921\n",
      "Predicción post entrenamiento : [[0.27925748]]\n",
      "PERDIDAAAA despues: 0.005839803721755743\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "[[[0.26546189]\n",
      "  [0.26673856]\n",
      "  [0.26878479]\n",
      "  [0.27119023]\n",
      "  [0.27285424]\n",
      "  [0.27407321]\n",
      "  [0.27551556]\n",
      "  [0.27799952]]]\n",
      "ejemplar: [0.26546189 0.26673856 0.26878479 0.27119023 0.27285424 0.27407321\n",
      " 0.27551556 0.27799952]\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.28032497]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[0.26546189 0.26673856 0.26878479 0.27119023 0.27285424 0.27407321\n",
      "  0.27551556 0.27799952]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00317715248093009\n",
      "Predicción post entrenamiento : [[0.28085417]]\n",
      "PERDIDAAAA despues: 0.003117774613201618\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "[[[0.26673856]\n",
      "  [0.26878479]\n",
      "  [0.27119023]\n",
      "  [0.27285424]\n",
      "  [0.27407321]\n",
      "  [0.27551556]\n",
      "  [0.27799952]\n",
      "  [0.28032497]]]\n",
      "ejemplar: [0.26673856 0.26878479 0.27119023 0.27285424 0.27407321 0.27551556\n",
      " 0.27799952 0.28032497]\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.2820551]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[0.26673856 0.26878479 0.27119023 0.27285424 0.27407321 0.27551556\n",
      "  0.27799952 0.28032497]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002656013937667012\n",
      "Predicción post entrenamiento : [[0.28352672]]\n",
      "PERDIDAAAA despues: 0.002506496384739876\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "[[[0.26878479]\n",
      "  [0.27119023]\n",
      "  [0.27285424]\n",
      "  [0.27407321]\n",
      "  [0.27551556]\n",
      "  [0.27799952]\n",
      "  [0.28032497]\n",
      "  [0.28205511]]]\n",
      "ejemplar: [0.26878479 0.27119023 0.27285424 0.27407321 0.27551556 0.27799952\n",
      " 0.28032497 0.28205511]\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.28485036]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[0.26878479 0.27119023 0.27285424 0.27407321 0.27551556 0.27799952\n",
      "  0.28032497 0.28205511]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009976861998438835\n",
      "Predicción post entrenamiento : [[0.28632268]]\n",
      "PERDIDAAAA despues: 0.009684905409812927\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "[[[0.27119023]\n",
      "  [0.27285424]\n",
      "  [0.27407321]\n",
      "  [0.27551556]\n",
      "  [0.27799952]\n",
      "  [0.28032497]\n",
      "  [0.28205511]\n",
      "  [0.28485036]]]\n",
      "ejemplar: [0.27119023 0.27285424 0.27407321 0.27551556 0.27799952 0.28032497\n",
      " 0.28205511 0.28485036]\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.28761697]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[0.27119023 0.27285424 0.27407321 0.27551556 0.27799952 0.28032497\n",
      "  0.28205511 0.28485036]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08036063611507416\n",
      "Predicción post entrenamiento : [[0.29142743]]\n",
      "PERDIDAAAA despues: 0.07821477204561234\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "[[[0.27285424]\n",
      "  [0.27407321]\n",
      "  [0.27551556]\n",
      "  [0.27799952]\n",
      "  [0.28032497]\n",
      "  [0.28205511]\n",
      "  [0.28485036]\n",
      "  [0.28761697]]]\n",
      "ejemplar: [0.27285424 0.27407321 0.27551556 0.27799952 0.28032497 0.28205511\n",
      " 0.28485036 0.28761697]\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.29261634]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[0.27285424 0.27407321 0.27551556 0.27799952 0.28032497 0.28205511\n",
      "  0.28485036 0.28761697]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09221193194389343\n",
      "Predicción post entrenamiento : [[0.29648295]]\n",
      "PERDIDAAAA despues: 0.08987858146429062\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "[[[0.27407321]\n",
      "  [0.27551556]\n",
      "  [0.27799952]\n",
      "  [0.28032497]\n",
      "  [0.28205511]\n",
      "  [0.28485036]\n",
      "  [0.28761697]\n",
      "  [0.29261634]]]\n",
      "ejemplar: [0.27407321 0.27551556 0.27799952 0.28032497 0.28205511 0.28485036\n",
      " 0.28761697 0.29261634]\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.2977511]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[0.27407321 0.27551556 0.27799952 0.28032497 0.28205511 0.28485036\n",
      "  0.28761697 0.29261634]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0766361653804779\n",
      "Predicción post entrenamiento : [[0.30095413]]\n",
      "PERDIDAAAA despues: 0.07487301528453827\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "[[[0.27551556]\n",
      "  [0.27799952]\n",
      "  [0.28032497]\n",
      "  [0.28205511]\n",
      "  [0.28485036]\n",
      "  [0.28761697]\n",
      "  [0.29261634]\n",
      "  [0.2977511 ]]]\n",
      "ejemplar: [0.27551556 0.27799952 0.28032497 0.28205511 0.28485036 0.28761697\n",
      " 0.29261634 0.2977511 ]\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.3024653]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[0.27551556 0.27799952 0.28032497 0.28205511 0.28485036 0.28761697\n",
      "  0.29261634 0.2977511 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09234841912984848\n",
      "Predicción post entrenamiento : [[0.30636036]]\n",
      "PERDIDAAAA despues: 0.08999624848365784\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "[[[0.27799952]\n",
      "  [0.28032497]\n",
      "  [0.28205511]\n",
      "  [0.28485036]\n",
      "  [0.28761697]\n",
      "  [0.29261634]\n",
      "  [0.2977511 ]\n",
      "  [0.30246529]]]\n",
      "ejemplar: [0.27799952 0.28032497 0.28205511 0.28485036 0.28761697 0.29261634\n",
      " 0.2977511  0.30246529]\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.30815732]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[0.27799952 0.28032497 0.28205511 0.28485036 0.28761697 0.29261634\n",
      "  0.2977511  0.30246529]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07645214349031448\n",
      "Predicción post entrenamiento : [[0.31165576]]\n",
      "PERDIDAAAA despues: 0.0745297521352768\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "[[[0.28032497]\n",
      "  [0.28205511]\n",
      "  [0.28485036]\n",
      "  [0.28761697]\n",
      "  [0.29261634]\n",
      "  [0.2977511 ]\n",
      "  [0.30246529]\n",
      "  [0.30815732]]]\n",
      "ejemplar: [0.28032497 0.28205511 0.28485036 0.28761697 0.29261634 0.2977511\n",
      " 0.30246529 0.30815732]\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.3136007]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[0.28032497 0.28205511 0.28485036 0.28761697 0.29261634 0.2977511\n",
      "  0.30246529 0.30815732]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06511228531599045\n",
      "Predicción post entrenamiento : [[0.3167011]]\n",
      "PERDIDAAAA despues: 0.06353961676359177\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "[[[0.28205511]\n",
      "  [0.28485036]\n",
      "  [0.28761697]\n",
      "  [0.29261634]\n",
      "  [0.2977511 ]\n",
      "  [0.30246529]\n",
      "  [0.30815732]\n",
      "  [0.31360069]]]\n",
      "ejemplar: [0.28205511 0.28485036 0.28761697 0.29261634 0.2977511  0.30246529\n",
      " 0.30815732 0.31360069]\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.31891897]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[0.28205511 0.28485036 0.28761697 0.29261634 0.2977511  0.30246529\n",
      "  0.30815732 0.31360069]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1048821434378624\n",
      "Predicción post entrenamiento : [[0.32270142]]\n",
      "PERDIDAAAA despues: 0.10244651883840561\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "[[[0.28485036]\n",
      "  [0.28761697]\n",
      "  [0.29261634]\n",
      "  [0.2977511 ]\n",
      "  [0.30246529]\n",
      "  [0.30815732]\n",
      "  [0.31360069]\n",
      "  [0.31891897]]]\n",
      "ejemplar: [0.28485036 0.28761697 0.29261634 0.2977511  0.30246529 0.30815732\n",
      " 0.31360069 0.31891897]\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.3254412]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[0.28485036 0.28761697 0.29261634 0.2977511  0.30246529 0.30815732\n",
      "  0.31360069 0.31891897]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11310967057943344\n",
      "Predicción post entrenamiento : [[0.329221]]\n",
      "PERDIDAAAA despues: 0.11058152467012405\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "[[[0.28761697]\n",
      "  [0.29261634]\n",
      "  [0.2977511 ]\n",
      "  [0.30246529]\n",
      "  [0.30815732]\n",
      "  [0.31360069]\n",
      "  [0.31891897]\n",
      "  [0.32544121]]]\n",
      "ejemplar: [0.28761697 0.29261634 0.2977511  0.30246529 0.30815732 0.31360069\n",
      " 0.31891897 0.32544121]\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.33237055]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[0.28761697 0.29261634 0.2977511  0.30246529 0.30815732 0.31360069\n",
      "  0.31891897 0.32544121]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11602499336004257\n",
      "Predicción post entrenamiento : [[0.33599684]]\n",
      "PERDIDAAAA despues: 0.11356773972511292\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "[[[0.29261634]\n",
      "  [0.2977511 ]\n",
      "  [0.30246529]\n",
      "  [0.30815732]\n",
      "  [0.31360069]\n",
      "  [0.31891897]\n",
      "  [0.32544121]\n",
      "  [0.33237055]]]\n",
      "ejemplar: [0.29261634 0.2977511  0.30246529 0.30815732 0.31360069 0.31891897\n",
      " 0.32544121 0.33237055]\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.33967733]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[0.29261634 0.2977511  0.30246529 0.30815732 0.31360069 0.31891897\n",
      "  0.32544121 0.33237055]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13756678998470306\n",
      "Predicción post entrenamiento : [[0.34374636]]\n",
      "PERDIDAAAA despues: 0.13456493616104126\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "[[[0.2977511 ]\n",
      "  [0.30246529]\n",
      "  [0.30815732]\n",
      "  [0.31360069]\n",
      "  [0.31891897]\n",
      "  [0.32544121]\n",
      "  [0.33237055]\n",
      "  [0.33967733]]]\n",
      "ejemplar: [0.2977511  0.30246529 0.30815732 0.31360069 0.31891897 0.32544121\n",
      " 0.33237055 0.33967733]\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.3475507]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[0.2977511  0.30246529 0.30815732 0.31360069 0.31891897 0.32544121\n",
      "  0.33237055 0.33967733]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12704947590827942\n",
      "Predicción post entrenamiento : [[0.3515337]]\n",
      "PERDIDAAAA despues: 0.1242259293794632\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "[[[0.30246529]\n",
      "  [0.30815732]\n",
      "  [0.31360069]\n",
      "  [0.31891897]\n",
      "  [0.32544121]\n",
      "  [0.33237055]\n",
      "  [0.33967733]\n",
      "  [0.34755069]]]\n",
      "ejemplar: [0.30246529 0.30815732 0.31360069 0.31891897 0.32544121 0.33237055\n",
      " 0.33967733 0.34755069]\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.35549074]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[0.30246529 0.30815732 0.31360069 0.31891897 0.32544121 0.33237055\n",
      "  0.33967733 0.34755069]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13819566369056702\n",
      "Predicción post entrenamiento : [[0.35925576]]\n",
      "PERDIDAAAA despues: 0.13541057705879211\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "[[[0.30815732]\n",
      "  [0.31360069]\n",
      "  [0.31891897]\n",
      "  [0.32544121]\n",
      "  [0.33237055]\n",
      "  [0.33967733]\n",
      "  [0.34755069]\n",
      "  [0.35549074]]]\n",
      "ejemplar: [0.30815732 0.31360069 0.31891897 0.32544121 0.33237055 0.33967733\n",
      " 0.34755069 0.35549074]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.36354098]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[0.30815732 0.31360069 0.31891897 0.32544121 0.33237055 0.33967733\n",
      "  0.34755069 0.35549074]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12891484797000885\n",
      "Predicción post entrenamiento : [[0.36725134]]\n",
      "PERDIDAAAA despues: 0.12626422941684723\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "[[[0.31360069]\n",
      "  [0.31891897]\n",
      "  [0.32544121]\n",
      "  [0.33237055]\n",
      "  [0.33967733]\n",
      "  [0.34755069]\n",
      "  [0.35549074]\n",
      "  [0.36354098]]]\n",
      "ejemplar: [0.31360069 0.31891897 0.32544121 0.33237055 0.33967733 0.34755069\n",
      " 0.35549074 0.36354098]\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.3717316]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[0.31360069 0.31891897 0.32544121 0.33237055 0.33967733 0.34755069\n",
      "  0.35549074 0.36354098]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.16004984080791473\n",
      "Predicción post entrenamiento : [[0.37599337]]\n",
      "PERDIDAAAA despues: 0.15665805339813232\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "[[[0.31891897]\n",
      "  [0.32544121]\n",
      "  [0.33237055]\n",
      "  [0.33967733]\n",
      "  [0.34755069]\n",
      "  [0.35549074]\n",
      "  [0.36354098]\n",
      "  [0.37173161]]]\n",
      "ejemplar: [0.31891897 0.32544121 0.33237055 0.33967733 0.34755069 0.35549074\n",
      " 0.36354098 0.37173161]\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.38081086]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[0.31891897 0.32544121 0.33237055 0.33967733 0.34755069 0.35549074\n",
      "  0.36354098 0.37173161]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11813968420028687\n",
      "Predicción post entrenamiento : [[0.38433152]]\n",
      "PERDIDAAAA despues: 0.1157318651676178\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "[[[0.32544121]\n",
      "  [0.33237055]\n",
      "  [0.33967733]\n",
      "  [0.34755069]\n",
      "  [0.35549074]\n",
      "  [0.36354098]\n",
      "  [0.37173161]\n",
      "  [0.38081086]]]\n",
      "ejemplar: [0.32544121 0.33237055 0.33967733 0.34755069 0.35549074 0.36354098\n",
      " 0.37173161 0.38081086]\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.38961956]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[0.32544121 0.33237055 0.33967733 0.34755069 0.35549074 0.36354098\n",
      "  0.37173161 0.38081086]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07920742779970169\n",
      "Predicción post entrenamiento : [[0.39264804]]\n",
      "PERDIDAAAA despues: 0.07751193642616272\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "[[[0.33237055]\n",
      "  [0.33967733]\n",
      "  [0.34755069]\n",
      "  [0.35549074]\n",
      "  [0.36354098]\n",
      "  [0.37173161]\n",
      "  [0.38081086]\n",
      "  [0.38961956]]]\n",
      "ejemplar: [0.33237055 0.33967733 0.34755069 0.35549074 0.36354098 0.37173161\n",
      " 0.38081086 0.38961956]\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.39822608]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[0.33237055 0.33967733 0.34755069 0.35549074 0.36354098 0.37173161\n",
      "  0.38081086 0.38961956]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0759243592619896\n",
      "Predicción post entrenamiento : [[0.4009309]]\n",
      "PERDIDAAAA despues: 0.07444107532501221\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "[[[0.33967733]\n",
      "  [0.34755069]\n",
      "  [0.35549074]\n",
      "  [0.36354098]\n",
      "  [0.37173161]\n",
      "  [0.38081086]\n",
      "  [0.38961956]\n",
      "  [0.39822608]]]\n",
      "ejemplar: [0.33967733 0.34755069 0.35549074 0.36354098 0.37173161 0.38081086\n",
      " 0.38961956 0.39822608]\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.4067755]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[0.33967733 0.34755069 0.35549074 0.36354098 0.37173161 0.38081086\n",
      "  0.38961956 0.39822608]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09466470032930374\n",
      "Predicción post entrenamiento : [[0.40983883]]\n",
      "PERDIDAAAA despues: 0.09278906136751175\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "[[[0.34755069]\n",
      "  [0.35549074]\n",
      "  [0.36354098]\n",
      "  [0.37173161]\n",
      "  [0.38081086]\n",
      "  [0.38961956]\n",
      "  [0.39822608]\n",
      "  [0.4067755 ]]]\n",
      "ejemplar: [0.34755069 0.35549074 0.36354098 0.37173161 0.38081086 0.38961956\n",
      " 0.39822608 0.4067755 ]\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.4159235]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[0.34755069 0.35549074 0.36354098 0.37173161 0.38081086 0.38961956\n",
      "  0.39822608 0.4067755 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10756709426641464\n",
      "Predicción post entrenamiento : [[0.41930157]]\n",
      "PERDIDAAAA despues: 0.105362668633461\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "[[[0.35549074]\n",
      "  [0.36354098]\n",
      "  [0.37173161]\n",
      "  [0.38081086]\n",
      "  [0.38961956]\n",
      "  [0.39822608]\n",
      "  [0.4067755 ]\n",
      "  [0.41592351]]]\n",
      "ejemplar: [0.35549074 0.36354098 0.37173161 0.38081086 0.38961956 0.39822608\n",
      " 0.4067755  0.41592351]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.4255417]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[0.35549074 0.36354098 0.37173161 0.38081086 0.38961956 0.39822608\n",
      "  0.4067755  0.41592351]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08823657780885696\n",
      "Predicción post entrenamiento : [[0.42850736]]\n",
      "PERDIDAAAA despues: 0.08648349344730377\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "[[[0.36354098]\n",
      "  [0.37173161]\n",
      "  [0.38081086]\n",
      "  [0.38961956]\n",
      "  [0.39822608]\n",
      "  [0.4067755 ]\n",
      "  [0.41592351]\n",
      "  [0.4255417 ]]]\n",
      "ejemplar: [0.36354098 0.37173161 0.38081086 0.38961956 0.39822608 0.4067755\n",
      " 0.41592351 0.4255417 ]\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.43492618]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[0.36354098 0.37173161 0.38081086 0.38961956 0.39822608 0.4067755\n",
      "  0.41592351 0.4255417 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06991538405418396\n",
      "Predicción post entrenamiento : [[0.43750614]]\n",
      "PERDIDAAAA despues: 0.06855767965316772\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "[[[0.37173161]\n",
      "  [0.38081086]\n",
      "  [0.38961956]\n",
      "  [0.39822608]\n",
      "  [0.4067755 ]\n",
      "  [0.41592351]\n",
      "  [0.4255417 ]\n",
      "  [0.43492618]]]\n",
      "ejemplar: [0.37173161 0.38081086 0.38961956 0.39822608 0.4067755  0.41592351\n",
      " 0.4255417  0.43492618]\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.44411984]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[0.37173161 0.38081086 0.38961956 0.39822608 0.4067755  0.41592351\n",
      "  0.4255417  0.43492618]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08596112579107285\n",
      "Predicción post entrenamiento : [[0.4471125]]\n",
      "PERDIDAAAA despues: 0.08421523869037628\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "[[[0.38081086]\n",
      "  [0.38961956]\n",
      "  [0.39822608]\n",
      "  [0.4067755 ]\n",
      "  [0.41592351]\n",
      "  [0.4255417 ]\n",
      "  [0.43492618]\n",
      "  [0.44411984]]]\n",
      "ejemplar: [0.38081086 0.38961956 0.39822608 0.4067755  0.41592351 0.4255417\n",
      " 0.43492618 0.44411984]\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.45393085]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[0.38081086 0.38961956 0.39822608 0.4067755  0.41592351 0.4255417\n",
      "  0.43492618 0.44411984]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07155356556177139\n",
      "Predicción post entrenamiento : [[0.45642284]]\n",
      "PERDIDAAAA despues: 0.07022658735513687\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "[[[0.38961956]\n",
      "  [0.39822608]\n",
      "  [0.4067755 ]\n",
      "  [0.41592351]\n",
      "  [0.4255417 ]\n",
      "  [0.43492618]\n",
      "  [0.44411984]\n",
      "  [0.45393085]]]\n",
      "ejemplar: [0.38961956 0.39822608 0.4067755  0.41592351 0.4255417  0.43492618\n",
      " 0.44411984 0.45393085]\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.46326065]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[0.38961956 0.39822608 0.4067755  0.41592351 0.4255417  0.43492618\n",
      "  0.44411984 0.45393085]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0652562603354454\n",
      "Predicción post entrenamiento : [[0.46561915]]\n",
      "PERDIDAAAA despues: 0.06405685096979141\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "[[[0.39822608]\n",
      "  [0.4067755 ]\n",
      "  [0.41592351]\n",
      "  [0.4255417 ]\n",
      "  [0.43492618]\n",
      "  [0.44411984]\n",
      "  [0.45393085]\n",
      "  [0.46326065]]]\n",
      "ejemplar: [0.39822608 0.4067755  0.41592351 0.4255417  0.43492618 0.44411984\n",
      " 0.45393085 0.46326065]\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.47255963]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[0.39822608 0.4067755  0.41592351 0.4255417  0.43492618 0.44411984\n",
      "  0.45393085 0.46326065]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.040641628205776215\n",
      "Predicción post entrenamiento : [[0.47432336]]\n",
      "PERDIDAAAA despues: 0.03993361070752144\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "[[[0.4067755 ]\n",
      "  [0.41592351]\n",
      "  [0.4255417 ]\n",
      "  [0.43492618]\n",
      "  [0.44411984]\n",
      "  [0.45393085]\n",
      "  [0.46326065]\n",
      "  [0.47255963]]]\n",
      "ejemplar: [0.4067755  0.41592351 0.4255417  0.43492618 0.44411984 0.45393085\n",
      " 0.46326065 0.47255963]\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.48144323]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[0.4067755  0.41592351 0.4255417  0.43492618 0.44411984 0.45393085\n",
      "  0.46326065 0.47255963]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04714248701930046\n",
      "Predicción post entrenamiento : [[0.48351634]]\n",
      "PERDIDAAAA despues: 0.046246547251939774\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "[[[0.41592351]\n",
      "  [0.4255417 ]\n",
      "  [0.43492618]\n",
      "  [0.44411984]\n",
      "  [0.45393085]\n",
      "  [0.46326065]\n",
      "  [0.47255963]\n",
      "  [0.48144323]]]\n",
      "ejemplar: [0.41592351 0.4255417  0.43492618 0.44411984 0.45393085 0.46326065\n",
      " 0.47255963 0.48144323]\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.49086305]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[0.41592351 0.4255417  0.43492618 0.44411984 0.45393085 0.46326065\n",
      "  0.47255963 0.48144323]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.052980661392211914\n",
      "Predicción post entrenamiento : [[0.49255836]]\n",
      "PERDIDAAAA despues: 0.05220310017466545\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "[[[0.4255417 ]\n",
      "  [0.43492618]\n",
      "  [0.44411984]\n",
      "  [0.45393085]\n",
      "  [0.46326065]\n",
      "  [0.47255963]\n",
      "  [0.48144323]\n",
      "  [0.49086305]]]\n",
      "ejemplar: [0.4255417  0.43492618 0.44411984 0.45393085 0.46326065 0.47255963\n",
      " 0.48144323 0.49086305]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.50000507]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[0.4255417  0.43492618 0.44411984 0.45393085 0.46326065 0.47255963\n",
      "  0.48144323 0.49086305]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.049543216824531555\n",
      "Predicción post entrenamiento : [[0.50217485]]\n",
      "PERDIDAAAA despues: 0.048582009971141815\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "[[[0.43492618]\n",
      "  [0.44411984]\n",
      "  [0.45393085]\n",
      "  [0.46326065]\n",
      "  [0.47255963]\n",
      "  [0.48144323]\n",
      "  [0.49086305]\n",
      "  [0.50000507]]]\n",
      "ejemplar: [0.43492618 0.44411984 0.45393085 0.46326065 0.47255963 0.48144323\n",
      " 0.49086305 0.50000507]\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.50960374]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[0.43492618 0.44411984 0.45393085 0.46326065 0.47255963 0.48144323\n",
      "  0.49086305 0.50000507]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06085709109902382\n",
      "Predicción post entrenamiento : [[0.51156515]]\n",
      "PERDIDAAAA despues: 0.05989320948719978\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "[[[0.44411984]\n",
      "  [0.45393085]\n",
      "  [0.46326065]\n",
      "  [0.47255963]\n",
      "  [0.48144323]\n",
      "  [0.49086305]\n",
      "  [0.50000507]\n",
      "  [0.50960374]]]\n",
      "ejemplar: [0.44411984 0.45393085 0.46326065 0.47255963 0.48144323 0.49086305\n",
      " 0.50000507 0.50960374]\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.51902324]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[0.44411984 0.45393085 0.46326065 0.47255963 0.48144323 0.49086305\n",
      "  0.50000507 0.50960374]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09521111845970154\n",
      "Predicción post entrenamiento : [[0.52188027]]\n",
      "PERDIDAAAA despues: 0.09345613420009613\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "[[[0.45393085]\n",
      "  [0.46326065]\n",
      "  [0.47255963]\n",
      "  [0.48144323]\n",
      "  [0.49086305]\n",
      "  [0.50000507]\n",
      "  [0.50960374]\n",
      "  [0.51902324]]]\n",
      "ejemplar: [0.45393085 0.46326065 0.47255963 0.48144323 0.49086305 0.50000507\n",
      " 0.50960374 0.51902324]\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.52941746]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[0.45393085 0.46326065 0.47255963 0.48144323 0.49086305 0.50000507\n",
      "  0.50960374 0.51902324]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09573128819465637\n",
      "Predicción post entrenamiento : [[0.5323385]]\n",
      "PERDIDAAAA despues: 0.09393224865198135\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "[[[0.46326065]\n",
      "  [0.47255963]\n",
      "  [0.48144323]\n",
      "  [0.49086305]\n",
      "  [0.50000507]\n",
      "  [0.50960374]\n",
      "  [0.51902324]\n",
      "  [0.52941746]]]\n",
      "ejemplar: [0.46326065 0.47255963 0.48144323 0.49086305 0.50000507 0.50960374\n",
      " 0.51902324 0.52941746]\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.5398006]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[0.46326065 0.47255963 0.48144323 0.49086305 0.50000507 0.50960374\n",
      "  0.51902324 0.52941746]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06475254893302917\n",
      "Predicción post entrenamiento : [[0.5420047]]\n",
      "PERDIDAAAA despues: 0.06363566219806671\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "[[[0.47255963]\n",
      "  [0.48144323]\n",
      "  [0.49086305]\n",
      "  [0.50000507]\n",
      "  [0.50960374]\n",
      "  [0.51902324]\n",
      "  [0.52941746]\n",
      "  [0.53980058]]]\n",
      "ejemplar: [0.47255963 0.48144323 0.49086305 0.50000507 0.50960374 0.51902324\n",
      " 0.52941746 0.53980058]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.5495137]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[0.47255963 0.48144323 0.49086305 0.50000507 0.50960374 0.51902324\n",
      "  0.52941746 0.53980058]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05489227920770645\n",
      "Predicción post entrenamiento : [[0.55195683]]\n",
      "PERDIDAAAA despues: 0.05375343933701515\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "[[[0.48144323]\n",
      "  [0.49086305]\n",
      "  [0.50000507]\n",
      "  [0.50960374]\n",
      "  [0.51902324]\n",
      "  [0.52941746]\n",
      "  [0.53980058]\n",
      "  [0.5495137 ]]]\n",
      "ejemplar: [0.48144323 0.49086305 0.50000507 0.50960374 0.51902324 0.52941746\n",
      " 0.53980058 0.5495137 ]\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.5595434]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[0.48144323 0.49086305 0.50000507 0.50960374 0.51902324 0.52941746\n",
      "  0.53980058 0.5495137 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04342057928442955\n",
      "Predicción post entrenamiento : [[0.56184775]]\n",
      "PERDIDAAAA despues: 0.042465534061193466\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "[[[0.49086305]\n",
      "  [0.50000507]\n",
      "  [0.50960374]\n",
      "  [0.51902324]\n",
      "  [0.52941746]\n",
      "  [0.53980058]\n",
      "  [0.5495137 ]\n",
      "  [0.55954337]]]\n",
      "ejemplar: [0.49086305 0.50000507 0.50960374 0.51902324 0.52941746 0.53980058\n",
      " 0.5495137  0.55954337]\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.56965256]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[0.49086305 0.50000507 0.50960374 0.51902324 0.52941746 0.53980058\n",
      "  0.5495137  0.55954337]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.046193648129701614\n",
      "Predicción post entrenamiento : [[0.57134444]]\n",
      "PERDIDAAAA despues: 0.0454692505300045\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "[[[0.50000507]\n",
      "  [0.50960374]\n",
      "  [0.51902324]\n",
      "  [0.52941746]\n",
      "  [0.53980058]\n",
      "  [0.5495137 ]\n",
      "  [0.55954337]\n",
      "  [0.56965256]]]\n",
      "ejemplar: [0.50000507 0.50960374 0.51902324 0.52941746 0.53980058 0.5495137\n",
      " 0.55954337 0.56965256]\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.57926834]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[0.50000507 0.50960374 0.51902324 0.52941746 0.53980058 0.5495137\n",
      "  0.55954337 0.56965256]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08967678993940353\n",
      "Predicción post entrenamiento : [[0.5822033]]\n",
      "PERDIDAAAA despues: 0.08792757242918015\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "[[[0.50960374]\n",
      "  [0.51902324]\n",
      "  [0.52941746]\n",
      "  [0.53980058]\n",
      "  [0.5495137 ]\n",
      "  [0.55954337]\n",
      "  [0.56965256]\n",
      "  [0.57926834]]]\n",
      "ejemplar: [0.50960374 0.51902324 0.52941746 0.53980058 0.5495137  0.55954337\n",
      " 0.56965256 0.57926834]\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.5903527]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[0.50960374 0.51902324 0.52941746 0.53980058 0.5495137  0.55954337\n",
      "  0.56965256 0.57926834]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08138290047645569\n",
      "Predicción post entrenamiento : [[0.59267783]]\n",
      "PERDIDAAAA despues: 0.08006170392036438\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "[[[0.51902324]\n",
      "  [0.52941746]\n",
      "  [0.53980058]\n",
      "  [0.5495137 ]\n",
      "  [0.55954337]\n",
      "  [0.56965256]\n",
      "  [0.57926834]\n",
      "  [0.59035271]]]\n",
      "ejemplar: [0.51902324 0.52941746 0.53980058 0.5495137  0.55954337 0.56965256\n",
      " 0.57926834 0.59035271]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.60096675]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[0.51902324 0.52941746 0.53980058 0.5495137  0.55954337 0.56965256\n",
      "  0.57926834 0.59035271]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.061468806117773056\n",
      "Predicción post entrenamiento : [[0.6027048]]\n",
      "PERDIDAAAA despues: 0.06060999259352684\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "[[[0.52941746]\n",
      "  [0.53980058]\n",
      "  [0.5495137 ]\n",
      "  [0.55954337]\n",
      "  [0.56965256]\n",
      "  [0.57926834]\n",
      "  [0.59035271]\n",
      "  [0.60096675]]]\n",
      "ejemplar: [0.52941746 0.53980058 0.5495137  0.55954337 0.56965256 0.57926834\n",
      " 0.59035271 0.60096675]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.61120784]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[0.52941746 0.53980058 0.5495137  0.55954337 0.56965256 0.57926834\n",
      "  0.59035271 0.60096675]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.042881980538368225\n",
      "Predicción post entrenamiento : [[0.6130716]]\n",
      "PERDIDAAAA despues: 0.04211355373263359\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "[[[0.53980058]\n",
      "  [0.5495137 ]\n",
      "  [0.55954337]\n",
      "  [0.56965256]\n",
      "  [0.57926834]\n",
      "  [0.59035271]\n",
      "  [0.60096675]\n",
      "  [0.61120784]]]\n",
      "ejemplar: [0.53980058 0.5495137  0.55954337 0.56965256 0.57926834 0.59035271\n",
      " 0.60096675 0.61120784]\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.62155473]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[0.53980058 0.5495137  0.55954337 0.56965256 0.57926834 0.59035271\n",
      "  0.60096675 0.61120784]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04213026538491249\n",
      "Predicción post entrenamiento : [[0.62312794]]\n",
      "PERDIDAAAA despues: 0.041486918926239014\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "[[[0.5495137 ]\n",
      "  [0.55954337]\n",
      "  [0.56965256]\n",
      "  [0.57926834]\n",
      "  [0.59035271]\n",
      "  [0.60096675]\n",
      "  [0.61120784]\n",
      "  [0.62155473]]]\n",
      "ejemplar: [0.5495137  0.55954337 0.56965256 0.57926834 0.59035271 0.60096675\n",
      " 0.61120784 0.62155473]\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.6315924]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[0.5495137  0.55954337 0.56965256 0.57926834 0.59035271 0.60096675\n",
      "  0.61120784 0.62155473]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.023642783984541893\n",
      "Predicción post entrenamiento : [[0.6321601]]\n",
      "PERDIDAAAA despues: 0.023468514904379845\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "[[[0.55954337]\n",
      "  [0.56965256]\n",
      "  [0.57926834]\n",
      "  [0.59035271]\n",
      "  [0.60096675]\n",
      "  [0.61120784]\n",
      "  [0.62155473]\n",
      "  [0.63159239]]]\n",
      "ejemplar: [0.55954337 0.56965256 0.57926834 0.59035271 0.60096675 0.61120784\n",
      " 0.62155473 0.63159239]\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.64078975]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[0.55954337 0.56965256 0.57926834 0.59035271 0.60096675 0.61120784\n",
      "  0.62155473 0.63159239]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022034205496311188\n",
      "Predicción post entrenamiento : [[0.6423536]]\n",
      "PERDIDAAAA despues: 0.021572377532720566\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "[[[0.56965256]\n",
      "  [0.57926834]\n",
      "  [0.59035271]\n",
      "  [0.60096675]\n",
      "  [0.61120784]\n",
      "  [0.62155473]\n",
      "  [0.63159239]\n",
      "  [0.64078975]]]\n",
      "ejemplar: [0.56965256 0.57926834 0.59035271 0.60096675 0.61120784 0.62155473\n",
      " 0.63159239 0.64078975]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.6510844]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[0.56965256 0.57926834 0.59035271 0.60096675 0.61120784 0.62155473\n",
      "  0.63159239 0.64078975]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.033521346747875214\n",
      "Predicción post entrenamiento : [[0.6521638]]\n",
      "PERDIDAAAA despues: 0.03312727063894272\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "[[[0.57926834]\n",
      "  [0.59035271]\n",
      "  [0.60096675]\n",
      "  [0.61120784]\n",
      "  [0.62155473]\n",
      "  [0.63159239]\n",
      "  [0.64078975]\n",
      "  [0.65108442]]]\n",
      "ejemplar: [0.57926834 0.59035271 0.60096675 0.61120784 0.62155473 0.63159239\n",
      " 0.64078975 0.65108442]\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.6609748]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[0.57926834 0.59035271 0.60096675 0.61120784 0.62155473 0.63159239\n",
      "  0.64078975 0.65108442]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022952552884817123\n",
      "Predicción post entrenamiento : [[0.66208595]]\n",
      "PERDIDAAAA despues: 0.02261710725724697\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "[[[0.59035271]\n",
      "  [0.60096675]\n",
      "  [0.61120784]\n",
      "  [0.62155473]\n",
      "  [0.63159239]\n",
      "  [0.64078975]\n",
      "  [0.65108442]\n",
      "  [0.6609748 ]]]\n",
      "ejemplar: [0.59035271 0.60096675 0.61120784 0.62155473 0.63159239 0.64078975\n",
      " 0.65108442 0.6609748 ]\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.67111117]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[0.59035271 0.60096675 0.61120784 0.62155473 0.63159239 0.64078975\n",
      "  0.65108442 0.6609748 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01693347468972206\n",
      "Predicción post entrenamiento : [[0.6725888]]\n",
      "PERDIDAAAA despues: 0.01655108481645584\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "[[[0.60096675]\n",
      "  [0.61120784]\n",
      "  [0.62155473]\n",
      "  [0.63159239]\n",
      "  [0.64078975]\n",
      "  [0.65108442]\n",
      "  [0.6609748 ]\n",
      "  [0.67111117]]]\n",
      "ejemplar: [0.60096675 0.61120784 0.62155473 0.63159239 0.64078975 0.65108442\n",
      " 0.6609748  0.67111117]\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.68142235]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[0.60096675 0.61120784 0.62155473 0.63159239 0.64078975 0.65108442\n",
      "  0.6609748  0.67111117]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014824208803474903\n",
      "Predicción post entrenamiento : [[0.68256354]]\n",
      "PERDIDAAAA despues: 0.014547619968652725\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "[[[0.61120784]\n",
      "  [0.62155473]\n",
      "  [0.63159239]\n",
      "  [0.64078975]\n",
      "  [0.65108442]\n",
      "  [0.6609748 ]\n",
      "  [0.67111117]\n",
      "  [0.68142235]]]\n",
      "ejemplar: [0.61120784 0.62155473 0.63159239 0.64078975 0.65108442 0.6609748\n",
      " 0.67111117 0.68142235]\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.6912892]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[0.61120784 0.62155473 0.63159239 0.64078975 0.65108442 0.6609748\n",
      "  0.67111117 0.68142235]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01044518779963255\n",
      "Predicción post entrenamiento : [[0.69182646]]\n",
      "PERDIDAAAA despues: 0.010335654951632023\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "[[[0.62155473]\n",
      "  [0.63159239]\n",
      "  [0.64078975]\n",
      "  [0.65108442]\n",
      "  [0.6609748 ]\n",
      "  [0.67111117]\n",
      "  [0.68142235]\n",
      "  [0.69128919]]]\n",
      "ejemplar: [0.62155473 0.63159239 0.64078975 0.65108442 0.6609748  0.67111117\n",
      " 0.68142235 0.69128919]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.70052075]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[0.62155473 0.63159239 0.64078975 0.65108442 0.6609748  0.67111117\n",
      "  0.68142235 0.69128919]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003558087395504117\n",
      "Predicción post entrenamiento : [[0.7010121]]\n",
      "PERDIDAAAA despues: 0.0034997144248336554\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "[[[0.63159239]\n",
      "  [0.64078975]\n",
      "  [0.65108442]\n",
      "  [0.6609748 ]\n",
      "  [0.67111117]\n",
      "  [0.68142235]\n",
      "  [0.69128919]\n",
      "  [0.70052075]]]\n",
      "ejemplar: [0.63159239 0.64078975 0.65108442 0.6609748  0.67111117 0.68142235\n",
      " 0.69128919 0.70052075]\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.709631]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[0.63159239 0.64078975 0.65108442 0.6609748  0.67111117 0.68142235\n",
      "  0.69128919 0.70052075]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006626963149756193\n",
      "Predicción post entrenamiento : [[0.7089988]]\n",
      "PERDIDAAAA despues: 0.0006956466822884977\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "[[[0.64078975]\n",
      "  [0.65108442]\n",
      "  [0.6609748 ]\n",
      "  [0.67111117]\n",
      "  [0.68142235]\n",
      "  [0.69128919]\n",
      "  [0.70052075]\n",
      "  [0.70963103]]]\n",
      "ejemplar: [0.64078975 0.65108442 0.6609748  0.67111117 0.68142235 0.69128919\n",
      " 0.70052075 0.70963103]\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.7176027]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[0.64078975 0.65108442 0.6609748  0.67111117 0.68142235 0.69128919\n",
      "  0.70052075 0.70963103]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.495124059962109e-05\n",
      "Predicción post entrenamiento : [[0.7180986]]\n",
      "PERDIDAAAA despues: 6.254851177800447e-05\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "[[[0.65108442]\n",
      "  [0.6609748 ]\n",
      "  [0.67111117]\n",
      "  [0.68142235]\n",
      "  [0.69128919]\n",
      "  [0.70052075]\n",
      "  [0.70963103]\n",
      "  [0.71760273]]]\n",
      "ejemplar: [0.65108442 0.6609748  0.67111117 0.68142235 0.69128919 0.70052075\n",
      " 0.70963103 0.71760273]\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.7269096]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[0.65108442 0.6609748  0.67111117 0.68142235 0.69128919 0.70052075\n",
      "  0.70963103 0.71760273]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00021852196368854493\n",
      "Predicción post entrenamiento : [[0.7266037]]\n",
      "PERDIDAAAA despues: 0.0002095718664349988\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "[[[0.6609748 ]\n",
      "  [0.67111117]\n",
      "  [0.68142235]\n",
      "  [0.69128919]\n",
      "  [0.70052075]\n",
      "  [0.70963103]\n",
      "  [0.71760273]\n",
      "  [0.72690958]]]\n",
      "ejemplar: [0.6609748  0.67111117 0.68142235 0.69128919 0.70052075 0.70963103\n",
      " 0.71760273 0.72690958]\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.73529714]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[0.6609748  0.67111117 0.68142235 0.69128919 0.70052075 0.70963103\n",
      "  0.71760273 0.72690958]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.8824159269570373e-05\n",
      "Predicción post entrenamiento : [[0.7368117]]\n",
      "PERDIDAAAA despues: 7.975697371875867e-06\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "[[[0.67111117]\n",
      "  [0.68142235]\n",
      "  [0.69128919]\n",
      "  [0.70052075]\n",
      "  [0.70963103]\n",
      "  [0.71760273]\n",
      "  [0.72690958]\n",
      "  [0.73529714]]]\n",
      "ejemplar: [0.67111117 0.68142235 0.69128919 0.70052075 0.70963103 0.71760273\n",
      " 0.72690958 0.73529714]\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.74545]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[0.67111117 0.68142235 0.69128919 0.70052075 0.70963103 0.71760273\n",
      "  0.72690958 0.73529714]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.651316602481529e-05\n",
      "Predicción post entrenamiento : [[0.745409]]\n",
      "PERDIDAAAA despues: 8.575199171900749e-05\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "[[[0.68142235]\n",
      "  [0.69128919]\n",
      "  [0.70052075]\n",
      "  [0.70963103]\n",
      "  [0.71760273]\n",
      "  [0.72690958]\n",
      "  [0.73529714]\n",
      "  [0.74545002]]]\n",
      "ejemplar: [0.68142235 0.69128919 0.70052075 0.70963103 0.71760273 0.72690958\n",
      " 0.73529714 0.74545002]\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.75386995]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[0.68142235 0.69128919 0.70052075 0.70963103 0.71760273 0.72690958\n",
      "  0.73529714 0.74545002]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007447558920830488\n",
      "Predicción post entrenamiento : [[0.75173414]]\n",
      "PERDIDAAAA despues: 0.007083482574671507\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "[[[0.69128919]\n",
      "  [0.70052075]\n",
      "  [0.70963103]\n",
      "  [0.71760273]\n",
      "  [0.72690958]\n",
      "  [0.73529714]\n",
      "  [0.74545002]\n",
      "  [0.75386995]]]\n",
      "ejemplar: [0.69128919 0.70052075 0.70963103 0.71760273 0.72690958 0.73529714\n",
      " 0.74545002 0.75386995]\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.7599014]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[0.69128919 0.70052075 0.70963103 0.71760273 0.72690958 0.73529714\n",
      "  0.74545002 0.75386995]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008101078681647778\n",
      "Predicción post entrenamiento : [[0.75882435]]\n",
      "PERDIDAAAA despues: 0.007908356375992298\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "[[[0.70052075]\n",
      "  [0.70963103]\n",
      "  [0.71760273]\n",
      "  [0.72690958]\n",
      "  [0.73529714]\n",
      "  [0.74545002]\n",
      "  [0.75386995]\n",
      "  [0.7599014 ]]]\n",
      "ejemplar: [0.70052075 0.70963103 0.71760273 0.72690958 0.73529714 0.74545002\n",
      " 0.75386995 0.7599014 ]\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.7667529]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[0.70052075 0.70963103 0.71760273 0.72690958 0.73529714 0.74545002\n",
      "  0.75386995 0.7599014 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004917329642921686\n",
      "Predicción post entrenamiento : [[0.7662836]]\n",
      "PERDIDAAAA despues: 0.004851727746427059\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "[[[0.70963103]\n",
      "  [0.71760273]\n",
      "  [0.72690958]\n",
      "  [0.73529714]\n",
      "  [0.74545002]\n",
      "  [0.75386995]\n",
      "  [0.7599014 ]\n",
      "  [0.7667529 ]]]\n",
      "ejemplar: [0.70963103 0.71760273 0.72690958 0.73529714 0.74545002 0.75386995\n",
      " 0.7599014  0.7667529 ]\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.7740851]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[0.70963103 0.71760273 0.72690958 0.73529714 0.74545002 0.75386995\n",
      "  0.7599014  0.7667529 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013956534676253796\n",
      "Predicción post entrenamiento : [[0.7731557]]\n",
      "PERDIDAAAA despues: 0.013737799599766731\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "[[[0.71760273]\n",
      "  [0.72690958]\n",
      "  [0.73529714]\n",
      "  [0.74545002]\n",
      "  [0.75386995]\n",
      "  [0.7599014 ]\n",
      "  [0.7667529 ]\n",
      "  [0.7740851 ]]]\n",
      "ejemplar: [0.71760273 0.72690958 0.73529714 0.74545002 0.75386995 0.7599014\n",
      " 0.7667529  0.7740851 ]\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.7807995]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[0.71760273 0.72690958 0.73529714 0.74545002 0.75386995 0.7599014\n",
      "  0.7667529  0.7740851 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010402540676295757\n",
      "Predicción post entrenamiento : [[0.78044343]]\n",
      "PERDIDAAAA despues: 0.01033003255724907\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "[[[0.72690958]\n",
      "  [0.73529714]\n",
      "  [0.74545002]\n",
      "  [0.75386995]\n",
      "  [0.7599014 ]\n",
      "  [0.7667529 ]\n",
      "  [0.7740851 ]\n",
      "  [0.78079951]]]\n",
      "ejemplar: [0.72690958 0.73529714 0.74545002 0.75386995 0.7599014  0.7667529\n",
      " 0.7740851  0.78079951]\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.7881895]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[0.72690958 0.73529714 0.74545002 0.75386995 0.7599014  0.7667529\n",
      "  0.7740851  0.78079951]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01256527565419674\n",
      "Predicción post entrenamiento : [[0.7870075]]\n",
      "PERDIDAAAA despues: 0.012301689013838768\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "[[[0.73529714]\n",
      "  [0.74545002]\n",
      "  [0.75386995]\n",
      "  [0.7599014 ]\n",
      "  [0.7667529 ]\n",
      "  [0.7740851 ]\n",
      "  [0.78079951]\n",
      "  [0.78818947]]]\n",
      "ejemplar: [0.73529714 0.74545002 0.75386995 0.7599014  0.7667529  0.7740851\n",
      " 0.78079951 0.78818947]\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.79441357]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[0.73529714 0.74545002 0.75386995 0.7599014  0.7667529  0.7740851\n",
      "  0.78079951 0.78818947]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004205704666674137\n",
      "Predicción post entrenamiento : [[0.79331696]]\n",
      "PERDIDAAAA despues: 0.004064674023538828\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "[[[0.74545002]\n",
      "  [0.75386995]\n",
      "  [0.7599014 ]\n",
      "  [0.7667529 ]\n",
      "  [0.7740851 ]\n",
      "  [0.78079951]\n",
      "  [0.78818947]\n",
      "  [0.79441357]]]\n",
      "ejemplar: [0.74545002 0.75386995 0.7599014  0.7667529  0.7740851  0.78079951\n",
      " 0.78818947 0.79441357]\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.800543]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[0.74545002 0.75386995 0.7599014  0.7667529  0.7740851  0.78079951\n",
      "  0.78818947 0.79441357]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009853430092334747\n",
      "Predicción post entrenamiento : [[0.7997821]]\n",
      "PERDIDAAAA despues: 0.009702945128083229\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "[[[0.75386995]\n",
      "  [0.7599014 ]\n",
      "  [0.7667529 ]\n",
      "  [0.7740851 ]\n",
      "  [0.78079951]\n",
      "  [0.78818947]\n",
      "  [0.79441357]\n",
      "  [0.80054301]]]\n",
      "ejemplar: [0.75386995 0.7599014  0.7667529  0.7740851  0.78079951 0.78818947\n",
      " 0.79441357 0.80054301]\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.80622333]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[0.75386995 0.7599014  0.7667529  0.7740851  0.78079951 0.78818947\n",
      "  0.79441357 0.80054301]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014970198972150683\n",
      "Predicción post entrenamiento : [[0.8062718]]\n",
      "PERDIDAAAA despues: 0.001500772195868194\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "[[[0.7599014 ]\n",
      "  [0.7667529 ]\n",
      "  [0.7740851 ]\n",
      "  [0.78079951]\n",
      "  [0.78818947]\n",
      "  [0.79441357]\n",
      "  [0.80054301]\n",
      "  [0.80622333]]]\n",
      "ejemplar: [0.7599014  0.7667529  0.7740851  0.78079951 0.78818947 0.79441357\n",
      " 0.80054301 0.80622333]\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.81228745]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[0.7599014  0.7667529  0.7740851  0.78079951 0.78818947 0.79441357\n",
      "  0.80054301 0.80622333]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0032665524631738663\n",
      "Predicción post entrenamiento : [[0.8117931]]\n",
      "PERDIDAAAA despues: 0.0032102877739816904\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "[[[0.7667529 ]\n",
      "  [0.7740851 ]\n",
      "  [0.78079951]\n",
      "  [0.78818947]\n",
      "  [0.79441357]\n",
      "  [0.80054301]\n",
      "  [0.80622333]\n",
      "  [0.81228745]]]\n",
      "ejemplar: [0.7667529  0.7740851  0.78079951 0.78818947 0.79441357 0.80054301\n",
      " 0.80622333 0.81228745]\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.8180044]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[0.7667529  0.7740851  0.78079951 0.78818947 0.79441357 0.80054301\n",
      "  0.80622333 0.81228745]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005320885684341192\n",
      "Predicción post entrenamiento : [[0.81673366]]\n",
      "PERDIDAAAA despues: 0.005137109663337469\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "[[[0.7740851 ]\n",
      "  [0.78079951]\n",
      "  [0.78818947]\n",
      "  [0.79441357]\n",
      "  [0.80054301]\n",
      "  [0.80622333]\n",
      "  [0.81228745]\n",
      "  [0.81800443]]]\n",
      "ejemplar: [0.7740851  0.78079951 0.78818947 0.79441357 0.80054301 0.80622333\n",
      " 0.81228745 0.81800443]\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.822894]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[0.7740851  0.78079951 0.78818947 0.79441357 0.80054301 0.80622333\n",
      "  0.81228745 0.81800443]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005021126940846443\n",
      "Predicción post entrenamiento : [[0.8228361]]\n",
      "PERDIDAAAA despues: 0.005012928042560816\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "[[[0.78079951]\n",
      "  [0.78818947]\n",
      "  [0.79441357]\n",
      "  [0.80054301]\n",
      "  [0.80622333]\n",
      "  [0.81228745]\n",
      "  [0.81800443]\n",
      "  [0.82289398]]]\n",
      "ejemplar: [0.78079951 0.78818947 0.79441357 0.80054301 0.80622333 0.81228745\n",
      " 0.81800443 0.82289398]\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.8287562]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[0.78079951 0.78818947 0.79441357 0.80054301 0.80622333 0.81228745\n",
      "  0.81800443 0.82289398]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014150012284517288\n",
      "Predicción post entrenamiento : [[0.8287395]]\n",
      "PERDIDAAAA despues: 0.014146042056381702\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "[[[0.78818947]\n",
      "  [0.79441357]\n",
      "  [0.80054301]\n",
      "  [0.80622333]\n",
      "  [0.81228745]\n",
      "  [0.81800443]\n",
      "  [0.82289398]\n",
      "  [0.82875621]]]\n",
      "ejemplar: [0.78818947 0.79441357 0.80054301 0.80622333 0.81228745 0.81800443\n",
      " 0.82289398 0.82875621]\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.834528]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[0.78818947 0.79441357 0.80054301 0.80622333 0.81228745 0.81800443\n",
      "  0.82289398 0.82875621]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02076422981917858\n",
      "Predicción post entrenamiento : [[0.83431774]]\n",
      "PERDIDAAAA despues: 0.020703669637441635\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "[[[0.79441357]\n",
      "  [0.80054301]\n",
      "  [0.80622333]\n",
      "  [0.81228745]\n",
      "  [0.81800443]\n",
      "  [0.82289398]\n",
      "  [0.82875621]\n",
      "  [0.83452803]]]\n",
      "ejemplar: [0.79441357 0.80054301 0.80622333 0.81228745 0.81800443 0.82289398\n",
      " 0.82875621 0.83452803]\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.83972]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[0.79441357 0.80054301 0.80622333 0.81228745 0.81800443 0.82289398\n",
      "  0.82875621 0.83452803]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0072865416295826435\n",
      "Predicción post entrenamiento : [[0.8406109]]\n",
      "PERDIDAAAA despues: 0.007439434062689543\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "[[[0.80054301]\n",
      "  [0.80622333]\n",
      "  [0.81228745]\n",
      "  [0.81800443]\n",
      "  [0.82289398]\n",
      "  [0.82875621]\n",
      "  [0.83452803]\n",
      "  [0.83972001]]]\n",
      "ejemplar: [0.80054301 0.80622333 0.81228745 0.81800443 0.82289398 0.82875621\n",
      " 0.83452803 0.83972001]\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.84589726]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[0.80054301 0.80622333 0.81228745 0.81800443 0.82289398 0.82875621\n",
      "  0.83452803 0.83972001]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015300840139389038\n",
      "Predicción post entrenamiento : [[0.8451975]]\n",
      "PERDIDAAAA despues: 0.015128214843571186\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "[[[0.80622333]\n",
      "  [0.81228745]\n",
      "  [0.81800443]\n",
      "  [0.82289398]\n",
      "  [0.82875621]\n",
      "  [0.83452803]\n",
      "  [0.83972001]\n",
      "  [0.84589726]]]\n",
      "ejemplar: [0.80622333 0.81228745 0.81800443 0.82289398 0.82875621 0.83452803\n",
      " 0.83972001 0.84589726]\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.8503639]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[0.80622333 0.81228745 0.81800443 0.82289398 0.82875621 0.83452803\n",
      "  0.83972001 0.84589726]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.443073865128099e-06\n",
      "Predicción post entrenamiento : [[0.85073453]]\n",
      "PERDIDAAAA despues: 4.9558502723812126e-06\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "[[[0.81228745]\n",
      "  [0.81800443]\n",
      "  [0.82289398]\n",
      "  [0.82875621]\n",
      "  [0.83452803]\n",
      "  [0.83972001]\n",
      "  [0.84589726]\n",
      "  [0.85036391]]]\n",
      "ejemplar: [0.81228745 0.81800443 0.82289398 0.82875621 0.83452803 0.83972001\n",
      " 0.84589726 0.85036391]\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.8558889]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[0.81228745 0.81800443 0.82289398 0.82875621 0.83452803 0.83972001\n",
      "  0.84589726 0.85036391]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002457589143887162\n",
      "Predicción post entrenamiento : [[0.8567409]]\n",
      "PERDIDAAAA despues: 0.0023738418240100145\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "[[[0.81800443]\n",
      "  [0.82289398]\n",
      "  [0.82875621]\n",
      "  [0.83452803]\n",
      "  [0.83972001]\n",
      "  [0.84589726]\n",
      "  [0.85036391]\n",
      "  [0.8558889 ]]]\n",
      "ejemplar: [0.81800443 0.82289398 0.82875621 0.83452803 0.83972001 0.84589726\n",
      " 0.85036391 0.8558889 ]\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.8617562]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[0.81800443 0.82289398 0.82875621 0.83452803 0.83972001 0.84589726\n",
      "  0.85036391 0.8558889 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004186120058875531\n",
      "Predicción post entrenamiento : [[0.8629946]]\n",
      "PERDIDAAAA despues: 0.00036947004264220595\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "[[[0.82289398]\n",
      "  [0.82875621]\n",
      "  [0.83452803]\n",
      "  [0.83972001]\n",
      "  [0.84589726]\n",
      "  [0.85036391]\n",
      "  [0.8558889 ]\n",
      "  [0.86175621]]]\n",
      "ejemplar: [0.82289398 0.82875621 0.83452803 0.83972001 0.84589726 0.85036391\n",
      " 0.8558889  0.86175621]\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.8679512]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[0.82289398 0.82875621 0.83452803 0.83972001 0.84589726 0.85036391\n",
      "  0.8558889  0.86175621]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015869440976530313\n",
      "Predicción post entrenamiento : [[0.86784095]]\n",
      "PERDIDAAAA despues: 0.0015957416035234928\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "[[[0.82875621]\n",
      "  [0.83452803]\n",
      "  [0.83972001]\n",
      "  [0.84589726]\n",
      "  [0.85036391]\n",
      "  [0.8558889 ]\n",
      "  [0.86175621]\n",
      "  [0.86795121]]]\n",
      "ejemplar: [0.82875621 0.83452803 0.83972001 0.84589726 0.85036391 0.8558889\n",
      " 0.86175621 0.86795121]\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.8729795]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[0.82875621 0.83452803 0.83972001 0.84589726 0.85036391 0.8558889\n",
      "  0.86175621 0.86795121]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00027549907099455595\n",
      "Predicción post entrenamiento : [[0.8736275]]\n",
      "PERDIDAAAA despues: 0.00025440898025408387\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "[[[0.83452803]\n",
      "  [0.83972001]\n",
      "  [0.84589726]\n",
      "  [0.85036391]\n",
      "  [0.8558889 ]\n",
      "  [0.86175621]\n",
      "  [0.86795121]\n",
      "  [0.87297952]]]\n",
      "ejemplar: [0.83452803 0.83972001 0.84589726 0.85036391 0.8558889  0.86175621\n",
      " 0.86795121 0.87297952]\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.878682]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[0.83452803 0.83972001 0.84589726 0.85036391 0.8558889  0.86175621\n",
      "  0.86795121 0.87297952]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.4648481737822294e-05\n",
      "Predicción post entrenamiento : [[0.87871534]]\n",
      "PERDIDAAAA despues: 1.4904637282597832e-05\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "[[[0.83972001]\n",
      "  [0.84589726]\n",
      "  [0.85036391]\n",
      "  [0.8558889 ]\n",
      "  [0.86175621]\n",
      "  [0.86795121]\n",
      "  [0.87297952]\n",
      "  [0.87868202]]]\n",
      "ejemplar: [0.83972001 0.84589726 0.85036391 0.8558889  0.86175621 0.86795121\n",
      " 0.87297952 0.87868202]\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.88369936]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[0.83972001 0.84589726 0.85036391 0.8558889  0.86175621 0.86795121\n",
      "  0.87297952 0.87868202]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008709926041774452\n",
      "Predicción post entrenamiento : [[0.8828633]]\n",
      "PERDIDAAAA despues: 0.0009210410644300282\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "[[[0.84589726]\n",
      "  [0.85036391]\n",
      "  [0.8558889 ]\n",
      "  [0.86175621]\n",
      "  [0.86795121]\n",
      "  [0.87297952]\n",
      "  [0.87868202]\n",
      "  [0.88369936]]]\n",
      "ejemplar: [0.84589726 0.85036391 0.8558889  0.86175621 0.86795121 0.87297952\n",
      " 0.87868202 0.88369936]\n",
      "y: 1.0\n",
      "Predicción : [[0.8879403]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[0.84589726 0.85036391 0.8558889  0.86175621 0.86795121 0.87297952\n",
      "  0.87868202 0.88369936]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012557378970086575\n",
      "Predicción post entrenamiento : [[0.8889997]]\n",
      "PERDIDAAAA despues: 0.012321066111326218\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "[[[0.85036391]\n",
      "  [0.8558889 ]\n",
      "  [0.86175621]\n",
      "  [0.86795121]\n",
      "  [0.87297952]\n",
      "  [0.87868202]\n",
      "  [0.88369936]\n",
      "  [0.88794029]]]\n",
      "ejemplar: [0.85036391 0.8558889  0.86175621 0.86795121 0.87297952 0.87868202\n",
      " 0.88369936 0.88794029]\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.8938807]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[0.85036391 0.8558889  0.86175621 0.86795121 0.87297952 0.87868202\n",
      "  0.88369936 0.88794029]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005878799129277468\n",
      "Predicción post entrenamiento : [[0.89394075]]\n",
      "PERDIDAAAA despues: 0.005869598593562841\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "[[[0.8558889 ]\n",
      "  [0.86175621]\n",
      "  [0.86795121]\n",
      "  [0.87297952]\n",
      "  [0.87868202]\n",
      "  [0.88369936]\n",
      "  [0.88794029]\n",
      "  [0.89388072]]]\n",
      "ejemplar: [0.8558889  0.86175621 0.86795121 0.87297952 0.87868202 0.88369936\n",
      " 0.88794029 0.89388072]\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.899107]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[0.8558889  0.86175621 0.86795121 0.87297952 0.87868202 0.88369936\n",
      "  0.88794029 0.89388072]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0001061767979990691\n",
      "Predicción post entrenamiento : [[0.8992825]]\n",
      "PERDIDAAAA despues: 0.00010982512321788818\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "[[[0.86175621]\n",
      "  [0.86795121]\n",
      "  [0.87297952]\n",
      "  [0.87868202]\n",
      "  [0.88369936]\n",
      "  [0.88794029]\n",
      "  [0.89388072]\n",
      "  [0.89910698]]]\n",
      "ejemplar: [0.86175621 0.86795121 0.87297952 0.87868202 0.88369936 0.88794029\n",
      " 0.89388072 0.89910698]\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.9044412]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[0.86175621 0.86795121 0.87297952 0.87868202 0.88369936 0.88794029\n",
      "  0.89388072 0.89910698]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007015544688329101\n",
      "Predicción post entrenamiento : [[0.90512854]]\n",
      "PERDIDAAAA despues: 0.0007384390337392688\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "[[[0.86795121]\n",
      "  [0.87297952]\n",
      "  [0.87868202]\n",
      "  [0.88369936]\n",
      "  [0.88794029]\n",
      "  [0.89388072]\n",
      "  [0.89910698]\n",
      "  [0.90444118]]]\n",
      "ejemplar: [0.86795121 0.87297952 0.87868202 0.88369936 0.88794029 0.89388072\n",
      " 0.89910698 0.90444118]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.91015863]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[0.86795121 0.87297952 0.87868202 0.88369936 0.88794029 0.89388072\n",
      "  0.89910698 0.90444118]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0037531363777816296\n",
      "Predicción post entrenamiento : [[0.9103026]]\n",
      "PERDIDAAAA despues: 0.0037707940209656954\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "[[[0.87297952]\n",
      "  [0.87868202]\n",
      "  [0.88369936]\n",
      "  [0.88794029]\n",
      "  [0.89388072]\n",
      "  [0.89910698]\n",
      "  [0.90444118]\n",
      "  [0.91015863]]]\n",
      "ejemplar: [0.87297952 0.87868202 0.88369936 0.88794029 0.89388072 0.89910698\n",
      " 0.90444118 0.91015863]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.9150748]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[0.87297952 0.87868202 0.88369936 0.88794029 0.89388072 0.89910698\n",
      "  0.90444118 0.91015863]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006545139942318201\n",
      "Predicción post entrenamiento : [[0.9161063]]\n",
      "PERDIDAAAA despues: 0.006713098380714655\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "[[[0.87868202]\n",
      "  [0.88369936]\n",
      "  [0.88794029]\n",
      "  [0.89388072]\n",
      "  [0.89910698]\n",
      "  [0.90444118]\n",
      "  [0.91015863]\n",
      "  [0.91507483]]]\n",
      "ejemplar: [0.87868202 0.88369936 0.88794029 0.89388072 0.89910698 0.90444118\n",
      " 0.91015863 0.91507483]\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.9209395]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[0.87868202 0.88369936 0.88794029 0.89388072 0.89910698 0.90444118\n",
      "  0.91015863 0.91507483]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004335510544478893\n",
      "Predicción post entrenamiento : [[0.91971946]]\n",
      "PERDIDAAAA despues: 0.004176332149654627\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "[[[0.88369936]\n",
      "  [0.88794029]\n",
      "  [0.89388072]\n",
      "  [0.89910698]\n",
      "  [0.90444118]\n",
      "  [0.91015863]\n",
      "  [0.91507483]\n",
      "  [0.92093951]]]\n",
      "ejemplar: [0.88369936 0.88794029 0.89388072 0.89910698 0.90444118 0.91015863\n",
      " 0.91507483 0.92093951]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.9244202]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[0.88369936 0.88794029 0.89388072 0.89910698 0.90444118 0.91015863\n",
      "  0.91507483 0.92093951]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0024184761568903923\n",
      "Predicción post entrenamiento : [[0.92492527]]\n",
      "PERDIDAAAA despues: 0.002468409948050976\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "[[[0.88794029]\n",
      "  [0.89388072]\n",
      "  [0.89910698]\n",
      "  [0.90444118]\n",
      "  [0.91015863]\n",
      "  [0.91507483]\n",
      "  [0.92093951]\n",
      "  [0.92442018]]]\n",
      "ejemplar: [0.88794029 0.89388072 0.89910698 0.90444118 0.91015863 0.91507483\n",
      " 0.92093951 0.92442018]\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.9296864]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[0.88794029 0.89388072 0.89910698 0.90444118 0.91015863 0.91507483\n",
      "  0.92093951 0.92442018]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005278639495372772\n",
      "Predicción post entrenamiento : [[0.9284346]]\n",
      "PERDIDAAAA despues: 0.00509830703958869\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "[[[0.89388072]\n",
      "  [0.89910698]\n",
      "  [0.90444118]\n",
      "  [0.91015863]\n",
      "  [0.91507483]\n",
      "  [0.92093951]\n",
      "  [0.92442018]\n",
      "  [0.92968643]]]\n",
      "ejemplar: [0.89388072 0.89910698 0.90444118 0.91015863 0.91507483 0.92093951\n",
      " 0.92442018 0.92968643]\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.9334943]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[0.89388072 0.89910698 0.90444118 0.91015863 0.91507483 0.92093951\n",
      "  0.92442018 0.92968643]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006961598061025143\n",
      "Predicción post entrenamiento : [[0.9335957]]\n",
      "PERDIDAAAA despues: 0.0069785271771252155\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "[[[0.89910698]\n",
      "  [0.90444118]\n",
      "  [0.91015863]\n",
      "  [0.91507483]\n",
      "  [0.92093951]\n",
      "  [0.92442018]\n",
      "  [0.92968643]\n",
      "  [0.93349433]]]\n",
      "ejemplar: [0.89910698 0.90444118 0.91015863 0.91507483 0.92093951 0.92442018\n",
      " 0.92968643 0.93349433]\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.93845695]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[0.89910698 0.90444118 0.91015863 0.91507483 0.92093951 0.92442018\n",
      "  0.92968643 0.93349433]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009170044213533401\n",
      "Predicción post entrenamiento : [[0.93736744]]\n",
      "PERDIDAAAA despues: 0.008962566033005714\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "[[[0.90444118]\n",
      "  [0.91015863]\n",
      "  [0.91507483]\n",
      "  [0.92093951]\n",
      "  [0.92442018]\n",
      "  [0.92968643]\n",
      "  [0.93349433]\n",
      "  [0.93845695]]]\n",
      "ejemplar: [0.90444118 0.91015863 0.91507483 0.92093951 0.92442018 0.92968643\n",
      " 0.93349433 0.93845695]\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.9421897]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[0.90444118 0.91015863 0.91507483 0.92093951 0.92442018 0.92968643\n",
      "  0.93349433 0.93845695]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014221244491636753\n",
      "Predicción post entrenamiento : [[0.9407965]]\n",
      "PERDIDAAAA despues: 0.01389089971780777\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "[[[0.91015863]\n",
      "  [0.91507483]\n",
      "  [0.92093951]\n",
      "  [0.92442018]\n",
      "  [0.92968643]\n",
      "  [0.93349433]\n",
      "  [0.93845695]\n",
      "  [0.94218969]]]\n",
      "ejemplar: [0.91015863 0.91507483 0.92093951 0.92442018 0.92968643 0.93349433\n",
      " 0.93845695 0.94218969]\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.945509]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[0.91015863 0.91507483 0.92093951 0.92442018 0.92968643 0.93349433\n",
      "  0.93845695 0.94218969]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02924202010035515\n",
      "Predicción post entrenamiento : [[0.94502026]]\n",
      "PERDIDAAAA despues: 0.029075101017951965\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "[[[0.91507483]\n",
      "  [0.92093951]\n",
      "  [0.92442018]\n",
      "  [0.92968643]\n",
      "  [0.93349433]\n",
      "  [0.93845695]\n",
      "  [0.94218969]\n",
      "  [0.94550902]]]\n",
      "ejemplar: [0.91507483 0.92093951 0.92442018 0.92968643 0.93349433 0.93845695\n",
      " 0.94218969 0.94550902]\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.94945246]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[0.91507483 0.92093951 0.92442018 0.92968643 0.93349433 0.93845695\n",
      "  0.94218969 0.94550902]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.027310971170663834\n",
      "Predicción post entrenamiento : [[0.94915724]]\n",
      "PERDIDAAAA despues: 0.027213482186198235\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "[[[0.92093951]\n",
      "  [0.92442018]\n",
      "  [0.92968643]\n",
      "  [0.93349433]\n",
      "  [0.93845695]\n",
      "  [0.94218969]\n",
      "  [0.94550902]\n",
      "  [0.94945246]]]\n",
      "ejemplar: [0.92093951 0.92442018 0.92968643 0.93349433 0.93845695 0.94218969\n",
      " 0.94550902 0.94945246]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.9534783]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[0.92093951 0.92442018 0.92968643 0.93349433 0.93845695 0.94218969\n",
      "  0.94550902 0.94945246]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008786056190729141\n",
      "Predicción post entrenamiento : [[0.95330137]]\n",
      "PERDIDAAAA despues: 0.008752923458814621\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "[[[0.92442018]\n",
      "  [0.92968643]\n",
      "  [0.93349433]\n",
      "  [0.93845695]\n",
      "  [0.94218969]\n",
      "  [0.94550902]\n",
      "  [0.94945246]\n",
      "  [0.95347828]]]\n",
      "ejemplar: [0.92442018 0.92968643 0.93349433 0.93845695 0.94218969 0.94550902\n",
      " 0.94945246 0.95347828]\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.9571739]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[0.92442018 0.92968643 0.93349433 0.93845695 0.94218969 0.94550902\n",
      "  0.94945246 0.95347828]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010578911751508713\n",
      "Predicción post entrenamiento : [[0.9563253]]\n",
      "PERDIDAAAA despues: 0.010405069217085838\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "[[[0.92968643]\n",
      "  [0.93349433]\n",
      "  [0.93845695]\n",
      "  [0.94218969]\n",
      "  [0.94550902]\n",
      "  [0.94945246]\n",
      "  [0.95347828]\n",
      "  [0.95717388]]]\n",
      "ejemplar: [0.92968643 0.93349433 0.93845695 0.94218969 0.94550902 0.94945246\n",
      " 0.95347828 0.95717388]\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.96039325]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[0.92968643 0.93349433 0.93845695 0.94218969 0.94550902 0.94945246\n",
      "  0.95347828 0.95717388]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015254308469593525\n",
      "Predicción post entrenamiento : [[0.95982933]]\n",
      "PERDIDAAAA despues: 0.015115329064428806\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "[[[0.93349433]\n",
      "  [0.93845695]\n",
      "  [0.94218969]\n",
      "  [0.94550902]\n",
      "  [0.94945246]\n",
      "  [0.95347828]\n",
      "  [0.95717388]\n",
      "  [0.96039325]]]\n",
      "ejemplar: [0.93349433 0.93845695 0.94218969 0.94550902 0.94945246 0.95347828\n",
      " 0.95717388 0.96039325]\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.9635496]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[0.93349433 0.93845695 0.94218969 0.94550902 0.94945246 0.95347828\n",
      "  0.95717388 0.96039325]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.017859313637018204\n",
      "Predicción post entrenamiento : [[0.9624633]]\n",
      "PERDIDAAAA despues: 0.017570151016116142\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "[[[0.93845695]\n",
      "  [0.94218969]\n",
      "  [0.94550902]\n",
      "  [0.94945246]\n",
      "  [0.95347828]\n",
      "  [0.95717388]\n",
      "  [0.96039325]\n",
      "  [0.96354961]]]\n",
      "ejemplar: [0.93845695 0.94218969 0.94550902 0.94945246 0.95347828 0.95717388\n",
      " 0.96039325 0.96354961]\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.96620876]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[0.93845695 0.94218969 0.94550902 0.94945246 0.95347828 0.95717388\n",
      "  0.96039325 0.96354961]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0062340134754776955\n",
      "Predicción post entrenamiento : [[0.9667084]]\n",
      "PERDIDAAAA despues: 0.006313166115432978\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "[[[0.94218969]\n",
      "  [0.94550902]\n",
      "  [0.94945246]\n",
      "  [0.95347828]\n",
      "  [0.95717388]\n",
      "  [0.96039325]\n",
      "  [0.96354961]\n",
      "  [0.96620876]]]\n",
      "ejemplar: [0.94218969 0.94550902 0.94945246 0.95347828 0.95717388 0.96039325\n",
      " 0.96354961 0.96620876]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.9701033]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[0.94218969 0.94550902 0.94945246 0.95347828 0.95717388 0.96039325\n",
      "  0.96354961 0.96620876]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012179112061858177\n",
      "Predicción post entrenamiento : [[0.9704684]]\n",
      "PERDIDAAAA despues: 0.012259824201464653\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "[[[0.94550902]\n",
      "  [0.94945246]\n",
      "  [0.95347828]\n",
      "  [0.95717388]\n",
      "  [0.96039325]\n",
      "  [0.96354961]\n",
      "  [0.96620876]\n",
      "  [0.97010332]]]\n",
      "ejemplar: [0.94550902 0.94945246 0.95347828 0.95717388 0.96039325 0.96354961\n",
      " 0.96620876 0.97010332]\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.9738216]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[0.94550902 0.94945246 0.95347828 0.95717388 0.96039325 0.96354961\n",
      "  0.96620876 0.97010332]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01801622472703457\n",
      "Predicción post entrenamiento : [[0.9728277]]\n",
      "PERDIDAAAA despues: 0.017750399187207222\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "[[[0.94945246]\n",
      "  [0.95347828]\n",
      "  [0.95717388]\n",
      "  [0.96039325]\n",
      "  [0.96354961]\n",
      "  [0.96620876]\n",
      "  [0.97010332]\n",
      "  [0.97382158]]]\n",
      "ejemplar: [0.94945246 0.95347828 0.95717388 0.96039325 0.96354961 0.96620876\n",
      " 0.97010332 0.97382158]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.9762474]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[0.94945246 0.95347828 0.95717388 0.96039325 0.96354961 0.96620876\n",
      "  0.97010332 0.97382158]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03703417629003525\n",
      "Predicción post entrenamiento : [[0.9741768]]\n",
      "PERDIDAAAA despues: 0.03624153882265091\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "[[[0.95347828]\n",
      "  [0.95717388]\n",
      "  [0.96039325]\n",
      "  [0.96354961]\n",
      "  [0.96620876]\n",
      "  [0.97010332]\n",
      "  [0.97382158]\n",
      "  [0.97624737]]]\n",
      "ejemplar: [0.95347828 0.95717388 0.96039325 0.96354961 0.96620876 0.97010332\n",
      " 0.97382158 0.97624737]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.9774616]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[0.95347828 0.95717388 0.96039325 0.96354961 0.96620876 0.97010332\n",
      "  0.97382158 0.97624737]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.025336388498544693\n",
      "Predicción post entrenamiento : [[0.97666395]]\n",
      "PERDIDAAAA despues: 0.02508310228586197\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "[[[0.95717388]\n",
      "  [0.96039325]\n",
      "  [0.96354961]\n",
      "  [0.96620876]\n",
      "  [0.97010332]\n",
      "  [0.97382158]\n",
      "  [0.97624737]\n",
      "  [0.97746158]]]\n",
      "ejemplar: [0.95717388 0.96039325 0.96354961 0.96620876 0.97010332 0.97382158\n",
      " 0.97624737 0.97746158]\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.97974235]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[0.95717388 0.96039325 0.96354961 0.96620876 0.97010332 0.97382158\n",
      "  0.97624737 0.97746158]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0355609692633152\n",
      "Predicción post entrenamiento : [[0.978086]]\n",
      "PERDIDAAAA despues: 0.03493901342153549\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "[[[0.96039325]\n",
      "  [0.96354961]\n",
      "  [0.96620876]\n",
      "  [0.97010332]\n",
      "  [0.97382158]\n",
      "  [0.97624737]\n",
      "  [0.97746158]\n",
      "  [0.97974235]]]\n",
      "ejemplar: [0.96039325 0.96354961 0.96620876 0.97010332 0.97382158 0.97624737\n",
      " 0.97746158 0.97974235]\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.9809984]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[0.96039325 0.96354961 0.96620876 0.97010332 0.97382158 0.97624737\n",
      "  0.97746158 0.97974235]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04859399050474167\n",
      "Predicción post entrenamiento : [[0.9796089]]\n",
      "PERDIDAAAA despues: 0.0479833148419857\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "[[[0.96354961]\n",
      "  [0.96620876]\n",
      "  [0.97010332]\n",
      "  [0.97382158]\n",
      "  [0.97624737]\n",
      "  [0.97746158]\n",
      "  [0.97974235]\n",
      "  [0.9809984 ]]]\n",
      "ejemplar: [0.96354961 0.96620876 0.97010332 0.97382158 0.97624737 0.97746158\n",
      " 0.97974235 0.9809984 ]\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.9824403]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[0.96354961 0.96620876 0.97010332 0.97382158 0.97624737 0.97746158\n",
      "  0.97974235 0.9809984 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03643770143389702\n",
      "Predicción post entrenamiento : [[0.98057646]]\n",
      "PERDIDAAAA despues: 0.03572960942983627\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "[[[0.96620876]\n",
      "  [0.97010332]\n",
      "  [0.97382158]\n",
      "  [0.97624737]\n",
      "  [0.97746158]\n",
      "  [0.97974235]\n",
      "  [0.9809984 ]\n",
      "  [0.98244029]]]\n",
      "ejemplar: [0.96620876 0.97010332 0.97382158 0.97624737 0.97746158 0.97974235\n",
      " 0.9809984  0.98244029]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9832891]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[0.96620876 0.97010332 0.97382158 0.97624737 0.97746158 0.97974235\n",
      "  0.9809984  0.98244029]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04605094715952873\n",
      "Predicción post entrenamiento : [[0.9811263]]\n",
      "PERDIDAAAA despues: 0.04512736573815346\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "[[[0.97010332]\n",
      "  [0.97382158]\n",
      "  [0.97624737]\n",
      "  [0.97746158]\n",
      "  [0.97974235]\n",
      "  [0.9809984 ]\n",
      "  [0.98244029]\n",
      "  [0.98328912]]]\n",
      "ejemplar: [0.97010332 0.97382158 0.97624737 0.97746158 0.97974235 0.9809984\n",
      " 0.98244029 0.98328912]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9837987]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[0.97010332 0.97382158 0.97624737 0.97746158 0.97974235 0.9809984\n",
      "  0.98244029 0.98328912]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04626990482211113\n",
      "Predicción post entrenamiento : [[0.98101187]]\n",
      "PERDIDAAAA despues: 0.04507875815033913\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "[[[0.97382158]\n",
      "  [0.97624737]\n",
      "  [0.97746158]\n",
      "  [0.97974235]\n",
      "  [0.9809984 ]\n",
      "  [0.98244029]\n",
      "  [0.98328912]\n",
      "  [0.98379868]]]\n",
      "ejemplar: [0.97382158 0.97624737 0.97746158 0.97974235 0.9809984  0.98244029\n",
      " 0.98328912 0.98379868]\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.98319185]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[0.97382158 0.97624737 0.97746158 0.97974235 0.9809984  0.98244029\n",
      "  0.98328912 0.98379868]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03395790234208107\n",
      "Predicción post entrenamiento : [[0.98079866]]\n",
      "PERDIDAAAA despues: 0.03308161348104477\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "[[[0.97624737]\n",
      "  [0.97746158]\n",
      "  [0.97974235]\n",
      "  [0.9809984 ]\n",
      "  [0.98244029]\n",
      "  [0.98328912]\n",
      "  [0.98379868]\n",
      "  [0.98319185]]]\n",
      "ejemplar: [0.97624737 0.97746158 0.97974235 0.9809984  0.98244029 0.98328912\n",
      " 0.98379868 0.98319185]\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.9824012]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[0.97624737 0.97746158 0.97974235 0.9809984  0.98244029 0.98328912\n",
      "  0.98379868 0.98319185]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.037016719579696655\n",
      "Predicción post entrenamiento : [[0.9817973]]\n",
      "PERDIDAAAA despues: 0.03678470104932785\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "[[[0.97746158]\n",
      "  [0.97974235]\n",
      "  [0.9809984 ]\n",
      "  [0.98244029]\n",
      "  [0.98328912]\n",
      "  [0.98379868]\n",
      "  [0.98319185]\n",
      "  [0.98240119]]]\n",
      "ejemplar: [0.97746158 0.97974235 0.9809984  0.98244029 0.98328912 0.98379868\n",
      " 0.98319185 0.98240119]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.9830744]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[0.97746158 0.97974235 0.9809984  0.98244029 0.98328912 0.98379868\n",
      "  0.98319185 0.98240119]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04968617856502533\n",
      "Predicción post entrenamiento : [[0.98019856]]\n",
      "PERDIDAAAA despues: 0.04841236770153046\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "[[[0.97974235]\n",
      "  [0.9809984 ]\n",
      "  [0.98244029]\n",
      "  [0.98328912]\n",
      "  [0.98379868]\n",
      "  [0.98319185]\n",
      "  [0.98240119]\n",
      "  [0.98307443]]]\n",
      "ejemplar: [0.97974235 0.9809984  0.98244029 0.98328912 0.98379868 0.98319185\n",
      " 0.98240119 0.98307443]\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.9814203]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[0.97974235 0.9809984  0.98244029 0.98328912 0.98379868 0.98319185\n",
      "  0.98240119 0.98307443]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08763198554515839\n",
      "Predicción post entrenamiento : [[0.9798936]]\n",
      "PERDIDAAAA despues: 0.08673045784235\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "[[[0.9809984 ]\n",
      "  [0.98244029]\n",
      "  [0.98328912]\n",
      "  [0.98379868]\n",
      "  [0.98319185]\n",
      "  [0.98240119]\n",
      "  [0.98307443]\n",
      "  [0.98142028]]]\n",
      "ejemplar: [0.9809984  0.98244029 0.98328912 0.98379868 0.98319185 0.98240119\n",
      " 0.98307443 0.98142028]\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.98066294]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[0.9809984  0.98244029 0.98328912 0.98379868 0.98319185 0.98240119\n",
      "  0.98307443 0.98142028]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14097860455513\n",
      "Predicción post entrenamiento : [[0.9795142]]\n",
      "PERDIDAAAA despues: 0.14011727273464203\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "[[[0.98244029]\n",
      "  [0.98328912]\n",
      "  [0.98379868]\n",
      "  [0.98319185]\n",
      "  [0.98240119]\n",
      "  [0.98307443]\n",
      "  [0.98142028]\n",
      "  [0.98066294]]]\n",
      "ejemplar: [0.98244029 0.98328912 0.98379868 0.98319185 0.98240119 0.98307443\n",
      " 0.98142028 0.98066294]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.98001987]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[0.98244029 0.98328912 0.98379868 0.98319185 0.98240119 0.98307443\n",
      "  0.98142028 0.98066294]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09932664036750793\n",
      "Predicción post entrenamiento : [[0.9790448]]\n",
      "PERDIDAAAA despues: 0.0987129807472229\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "[[[0.98328912]\n",
      "  [0.98379868]\n",
      "  [0.98319185]\n",
      "  [0.98240119]\n",
      "  [0.98307443]\n",
      "  [0.98142028]\n",
      "  [0.98066294]\n",
      "  [0.98001987]]]\n",
      "ejemplar: [0.98328912 0.98379868 0.98319185 0.98240119 0.98307443 0.98142028\n",
      " 0.98066294 0.98001987]\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.97914]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[0.98328912 0.98379868 0.98319185 0.98240119 0.98307443 0.98142028\n",
      "  0.98066294 0.98001987]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07359001785516739\n",
      "Predicción post entrenamiento : [[0.97776026]]\n",
      "PERDIDAAAA despues: 0.07284335047006607\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "[[[0.98379868]\n",
      "  [0.98319185]\n",
      "  [0.98240119]\n",
      "  [0.98307443]\n",
      "  [0.98142028]\n",
      "  [0.98066294]\n",
      "  [0.98001987]\n",
      "  [0.97913998]]]\n",
      "ejemplar: [0.98379868 0.98319185 0.98240119 0.98307443 0.98142028 0.98066294\n",
      " 0.98001987 0.97913998]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9775272]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[0.98379868 0.98319185 0.98240119 0.98307443 0.98142028 0.98066294\n",
      "  0.98001987 0.97913998]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09776166826486588\n",
      "Predicción post entrenamiento : [[0.97634894]]\n",
      "PERDIDAAAA despues: 0.09702624380588531\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "[[[0.98319185]\n",
      "  [0.98240119]\n",
      "  [0.98307443]\n",
      "  [0.98142028]\n",
      "  [0.98066294]\n",
      "  [0.98001987]\n",
      "  [0.97913998]\n",
      "  [0.9775272 ]]]\n",
      "ejemplar: [0.98319185 0.98240119 0.98307443 0.98142028 0.98066294 0.98001987\n",
      " 0.97913998 0.9775272 ]\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.97581315]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[0.98319185 0.98240119 0.98307443 0.98142028 0.98066294 0.98001987\n",
      "  0.97913998 0.9775272 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06993961334228516\n",
      "Predicción post entrenamiento : [[0.97495323]]\n",
      "PERDIDAAAA despues: 0.06948552280664444\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "[[[0.98240119]\n",
      "  [0.98307443]\n",
      "  [0.98142028]\n",
      "  [0.98066294]\n",
      "  [0.98001987]\n",
      "  [0.97913998]\n",
      "  [0.9775272 ]\n",
      "  [0.97581315]]]\n",
      "ejemplar: [0.98240119 0.98307443 0.98142028 0.98066294 0.98001987 0.97913998\n",
      " 0.9775272  0.97581315]\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.97438645]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[0.98240119 0.98307443 0.98142028 0.98066294 0.98001987 0.97913998\n",
      "  0.9775272  0.97581315]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08828598260879517\n",
      "Predicción post entrenamiento : [[0.973395]]\n",
      "PERDIDAAAA despues: 0.08769778162240982\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "[[[0.98307443]\n",
      "  [0.98142028]\n",
      "  [0.98066294]\n",
      "  [0.98001987]\n",
      "  [0.97913998]\n",
      "  [0.9775272 ]\n",
      "  [0.97581315]\n",
      "  [0.97438645]]]\n",
      "ejemplar: [0.98307443 0.98142028 0.98066294 0.98001987 0.97913998 0.9775272\n",
      " 0.97581315 0.97438645]\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.97282183]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[0.98307443 0.98142028 0.98066294 0.98001987 0.97913998 0.9775272\n",
      "  0.97581315 0.97438645]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04440043121576309\n",
      "Predicción post entrenamiento : [[0.97050464]]\n",
      "PERDIDAAAA despues: 0.04342927411198616\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "[[[0.98142028]\n",
      "  [0.98066294]\n",
      "  [0.98001987]\n",
      "  [0.97913998]\n",
      "  [0.9775272 ]\n",
      "  [0.97581315]\n",
      "  [0.97438645]\n",
      "  [0.97282183]]]\n",
      "ejemplar: [0.98142028 0.98066294 0.98001987 0.97913998 0.9775272  0.97581315\n",
      " 0.97438645 0.97282183]\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.96944726]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[0.98142028 0.98066294 0.98001987 0.97913998 0.9775272  0.97581315\n",
      "  0.97438645 0.97282183]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02637236937880516\n",
      "Predicción post entrenamiento : [[0.9689312]]\n",
      "PERDIDAAAA despues: 0.026205023750662804\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "[[[0.98066294]\n",
      "  [0.98001987]\n",
      "  [0.97913998]\n",
      "  [0.9775272 ]\n",
      "  [0.97581315]\n",
      "  [0.97438645]\n",
      "  [0.97282183]\n",
      "  [0.96944726]]]\n",
      "ejemplar: [0.98066294 0.98001987 0.97913998 0.9775272  0.97581315 0.97438645\n",
      " 0.97282183 0.96944726]\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.9679973]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[0.98066294 0.98001987 0.97913998 0.9775272  0.97581315 0.97438645\n",
      "  0.97282183 0.96944726]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.023350706323981285\n",
      "Predicción post entrenamiento : [[0.9652742]]\n",
      "PERDIDAAAA despues: 0.022525891661643982\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "[[[0.98001987]\n",
      "  [0.97913998]\n",
      "  [0.9775272 ]\n",
      "  [0.97581315]\n",
      "  [0.97438645]\n",
      "  [0.97282183]\n",
      "  [0.96944726]\n",
      "  [0.96799731]]]\n",
      "ejemplar: [0.98001987 0.97913998 0.9775272  0.97581315 0.97438645 0.97282183\n",
      " 0.96944726 0.96799731]\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.96417546]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[0.98001987 0.97913998 0.9775272  0.97581315 0.97438645 0.97282183\n",
      "  0.96944726 0.96799731]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0033567610662430525\n",
      "Predicción post entrenamiento : [[0.9635662]]\n",
      "PERDIDAAAA despues: 0.003286532126367092\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "[[[0.97913998]\n",
      "  [0.9775272 ]\n",
      "  [0.97581315]\n",
      "  [0.97438645]\n",
      "  [0.97282183]\n",
      "  [0.96944726]\n",
      "  [0.96799731]\n",
      "  [0.96417546]]]\n",
      "ejemplar: [0.97913998 0.9775272  0.97581315 0.97438645 0.97282183 0.96944726\n",
      " 0.96799731 0.96417546]\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.962198]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[0.97913998 0.9775272  0.97581315 0.97438645 0.97282183 0.96944726\n",
      "  0.96799731 0.96417546]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.212493644852657e-06\n",
      "Predicción post entrenamiento : [[0.96197546]]\n",
      "PERDIDAAAA despues: 5.152553512743907e-06\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "[[[0.9775272 ]\n",
      "  [0.97581315]\n",
      "  [0.97438645]\n",
      "  [0.97282183]\n",
      "  [0.96944726]\n",
      "  [0.96799731]\n",
      "  [0.96417546]\n",
      "  [0.96219802]]]\n",
      "ejemplar: [0.9775272  0.97581315 0.97438645 0.97282183 0.96944726 0.96799731\n",
      " 0.96417546 0.96219802]\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.96033067]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[0.9775272  0.97581315 0.97438645 0.97282183 0.96944726 0.96799731\n",
      "  0.96417546 0.96219802]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.6194246200029738e-05\n",
      "Predicción post entrenamiento : [[0.96112514]]\n",
      "PERDIDAAAA despues: 1.043120300892042e-05\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "[[[0.97581315]\n",
      "  [0.97438645]\n",
      "  [0.97282183]\n",
      "  [0.96944726]\n",
      "  [0.96799731]\n",
      "  [0.96417546]\n",
      "  [0.96219802]\n",
      "  [0.96033067]]]\n",
      "ejemplar: [0.97581315 0.97438645 0.97282183 0.96944726 0.96799731 0.96417546\n",
      " 0.96219802 0.96033067]\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.9593579]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[0.97581315 0.97438645 0.97282183 0.96944726 0.96799731 0.96417546\n",
      "  0.96219802 0.96033067]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005087970290333033\n",
      "Predicción post entrenamiento : [[0.95936054]]\n",
      "PERDIDAAAA despues: 0.005088344682008028\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "[[[0.97438645]\n",
      "  [0.97282183]\n",
      "  [0.96944726]\n",
      "  [0.96799731]\n",
      "  [0.96417546]\n",
      "  [0.96219802]\n",
      "  [0.96033067]\n",
      "  [0.95935792]]]\n",
      "ejemplar: [0.97438645 0.97282183 0.96944726 0.96799731 0.96417546 0.96219802\n",
      " 0.96033067 0.95935792]\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.957472]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[0.97438645 0.97282183 0.96944726 0.96799731 0.96417546 0.96219802\n",
      "  0.96033067 0.95935792]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004198363516479731\n",
      "Predicción post entrenamiento : [[0.95723313]]\n",
      "PERDIDAAAA despues: 0.004167462233453989\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "[[[0.97282183]\n",
      "  [0.96944726]\n",
      "  [0.96799731]\n",
      "  [0.96417546]\n",
      "  [0.96219802]\n",
      "  [0.96033067]\n",
      "  [0.95935792]\n",
      "  [0.95747203]]]\n",
      "ejemplar: [0.97282183 0.96944726 0.96799731 0.96417546 0.96219802 0.96033067\n",
      " 0.95935792 0.95747203]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.9551181]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[0.97282183 0.96944726 0.96799731 0.96417546 0.96219802 0.96033067\n",
      "  0.95935792 0.95747203]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006380166858434677\n",
      "Predicción post entrenamiento : [[0.954646]]\n",
      "PERDIDAAAA despues: 0.006304966285824776\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "[[[0.96944726]\n",
      "  [0.96799731]\n",
      "  [0.96417546]\n",
      "  [0.96219802]\n",
      "  [0.96033067]\n",
      "  [0.95935792]\n",
      "  [0.95747203]\n",
      "  [0.95511812]]]\n",
      "ejemplar: [0.96944726 0.96799731 0.96417546 0.96219802 0.96033067 0.95935792\n",
      " 0.95747203 0.95511812]\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.95232546]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[0.96944726 0.96799731 0.96417546 0.96219802 0.96033067 0.95935792\n",
      "  0.95747203 0.95511812]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010300720110535622\n",
      "Predicción post entrenamiento : [[0.9510087]]\n",
      "PERDIDAAAA despues: 0.010035166516900063\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "[[[0.96799731]\n",
      "  [0.96417546]\n",
      "  [0.96219802]\n",
      "  [0.96033067]\n",
      "  [0.95935792]\n",
      "  [0.95747203]\n",
      "  [0.95511812]\n",
      "  [0.95232546]]]\n",
      "ejemplar: [0.96799731 0.96417546 0.96219802 0.96033067 0.95935792 0.95747203\n",
      " 0.95511812 0.95232546]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.9490214]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[0.96799731 0.96417546 0.96219802 0.96033067 0.95935792 0.95747203\n",
      "  0.95511812 0.95232546]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010025138035416603\n",
      "Predicción post entrenamiento : [[0.949188]]\n",
      "PERDIDAAAA despues: 0.010058526881039143\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "[[[0.96417546]\n",
      "  [0.96219802]\n",
      "  [0.96033067]\n",
      "  [0.95935792]\n",
      "  [0.95747203]\n",
      "  [0.95511812]\n",
      "  [0.95232546]\n",
      "  [0.9490214 ]]]\n",
      "ejemplar: [0.96417546 0.96219802 0.96033067 0.95935792 0.95747203 0.95511812\n",
      " 0.95232546 0.9490214 ]\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.9469988]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[0.96417546 0.96219802 0.96033067 0.95935792 0.95747203 0.95511812\n",
      "  0.95232546 0.9490214 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00023774207511451095\n",
      "Predicción post entrenamiento : [[0.94762856]]\n",
      "PERDIDAAAA despues: 0.00021871761418879032\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "[[[0.96219802]\n",
      "  [0.96033067]\n",
      "  [0.95935792]\n",
      "  [0.95747203]\n",
      "  [0.95511812]\n",
      "  [0.95232546]\n",
      "  [0.9490214 ]\n",
      "  [0.94699878]]]\n",
      "ejemplar: [0.96219802 0.96033067 0.95935792 0.95747203 0.95511812 0.95232546\n",
      " 0.9490214  0.94699878]\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.94592565]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[0.96219802 0.96033067 0.95935792 0.95747203 0.95511812 0.95232546\n",
      "  0.9490214  0.94699878]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00048032289487309754\n",
      "Predicción post entrenamiento : [[0.94656146]]\n",
      "PERDIDAAAA despues: 0.0004528583085630089\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "[[[0.96033067]\n",
      "  [0.95935792]\n",
      "  [0.95747203]\n",
      "  [0.95511812]\n",
      "  [0.95232546]\n",
      "  [0.9490214 ]\n",
      "  [0.94699878]\n",
      "  [0.94592565]]]\n",
      "ejemplar: [0.96033067 0.95935792 0.95747203 0.95511812 0.95232546 0.9490214\n",
      " 0.94699878 0.94592565]\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.94484544]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[0.96033067 0.95935792 0.95747203 0.95511812 0.95232546 0.9490214\n",
      "  0.94699878 0.94592565]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.7013649994623847e-05\n",
      "Predicción post entrenamiento : [[0.9453588]]\n",
      "PERDIDAAAA despues: 2.1512300008907914e-05\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "[[[0.95935792]\n",
      "  [0.95747203]\n",
      "  [0.95511812]\n",
      "  [0.95232546]\n",
      "  [0.9490214 ]\n",
      "  [0.94699878]\n",
      "  [0.94592565]\n",
      "  [0.94484544]]]\n",
      "ejemplar: [0.95935792 0.95747203 0.95511812 0.95232546 0.9490214  0.94699878\n",
      " 0.94592565 0.94484544]\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.94358605]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[0.95935792 0.95747203 0.95511812 0.95232546 0.9490214  0.94699878\n",
      "  0.94592565 0.94484544]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008355113095603883\n",
      "Predicción post entrenamiento : [[0.94346493]]\n",
      "PERDIDAAAA despues: 0.0008425277774222195\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "[[[0.95747203]\n",
      "  [0.95511812]\n",
      "  [0.95232546]\n",
      "  [0.9490214 ]\n",
      "  [0.94699878]\n",
      "  [0.94592565]\n",
      "  [0.94484544]\n",
      "  [0.94358605]]]\n",
      "ejemplar: [0.95747203 0.95511812 0.95232546 0.9490214  0.94699878 0.94592565\n",
      " 0.94484544 0.94358605]\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.9413609]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[0.95747203 0.95511812 0.95232546 0.9490214  0.94699878 0.94592565\n",
      "  0.94484544 0.94358605]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0030846414156258106\n",
      "Predicción post entrenamiento : [[0.94160444]]\n",
      "PERDIDAAAA despues: 0.0030576479621231556\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "[[[0.95511812]\n",
      "  [0.95232546]\n",
      "  [0.9490214 ]\n",
      "  [0.94699878]\n",
      "  [0.94592565]\n",
      "  [0.94484544]\n",
      "  [0.94358605]\n",
      "  [0.94136089]]]\n",
      "ejemplar: [0.95511812 0.95232546 0.9490214  0.94699878 0.94592565 0.94484544\n",
      " 0.94358605 0.94136089]\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.93941814]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[0.95511812 0.95232546 0.9490214  0.94699878 0.94592565 0.94484544\n",
      "  0.94358605 0.94136089]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00013838164159096777\n",
      "Predicción post entrenamiento : [[0.93922174]]\n",
      "PERDIDAAAA despues: 0.0001430408883607015\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "[[[0.95232546]\n",
      "  [0.9490214 ]\n",
      "  [0.94699878]\n",
      "  [0.94592565]\n",
      "  [0.94484544]\n",
      "  [0.94358605]\n",
      "  [0.94136089]\n",
      "  [0.93941814]]]\n",
      "ejemplar: [0.95232546 0.9490214  0.94699878 0.94592565 0.94484544 0.94358605\n",
      " 0.94136089 0.93941814]\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.9371129]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[0.95232546 0.9490214  0.94699878 0.94592565 0.94484544 0.94358605\n",
      "  0.94136089 0.93941814]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017086747102439404\n",
      "Predicción post entrenamiento : [[0.93596065]]\n",
      "PERDIDAAAA despues: 0.0016147411661222577\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "[[[0.9490214 ]\n",
      "  [0.94699878]\n",
      "  [0.94592565]\n",
      "  [0.94484544]\n",
      "  [0.94358605]\n",
      "  [0.94136089]\n",
      "  [0.93941814]\n",
      "  [0.93711293]]]\n",
      "ejemplar: [0.9490214  0.94699878 0.94592565 0.94484544 0.94358605 0.94136089\n",
      " 0.93941814 0.93711293]\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.93409944]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[0.9490214  0.94699878 0.94592565 0.94484544 0.94358605 0.94136089\n",
      "  0.93941814 0.93711293]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0027728797867894173\n",
      "Predicción post entrenamiento : [[0.93449605]]\n",
      "PERDIDAAAA despues: 0.002814806532114744\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "[[[0.94699878]\n",
      "  [0.94592565]\n",
      "  [0.94484544]\n",
      "  [0.94358605]\n",
      "  [0.94136089]\n",
      "  [0.93941814]\n",
      "  [0.93711293]\n",
      "  [0.93409944]]]\n",
      "ejemplar: [0.94699878 0.94592565 0.94484544 0.94358605 0.94136089 0.93941814\n",
      " 0.93711293 0.93409944]\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.9330754]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[0.94699878 0.94592565 0.94484544 0.94358605 0.94136089 0.93941814\n",
      "  0.93711293 0.93409944]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00025564830866642296\n",
      "Predicción post entrenamiento : [[0.9326447]]\n",
      "PERDIDAAAA despues: 0.00024206077796407044\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "[[[0.94592565]\n",
      "  [0.94484544]\n",
      "  [0.94358605]\n",
      "  [0.94136089]\n",
      "  [0.93941814]\n",
      "  [0.93711293]\n",
      "  [0.93409944]\n",
      "  [0.93307543]]]\n",
      "ejemplar: [0.94592565 0.94484544 0.94358605 0.94136089 0.93941814 0.93711293\n",
      " 0.93409944 0.93307543]\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.93132776]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[0.94592565 0.94484544 0.94358605 0.94136089 0.93941814 0.93711293\n",
      "  0.93409944 0.93307543]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000132922621560283\n",
      "Predicción post entrenamiento : [[0.9303786]]\n",
      "PERDIDAAAA despues: 0.00011193772661499679\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "[[[0.94484544]\n",
      "  [0.94358605]\n",
      "  [0.94136089]\n",
      "  [0.93941814]\n",
      "  [0.93711293]\n",
      "  [0.93409944]\n",
      "  [0.93307543]\n",
      "  [0.93132776]]]\n",
      "ejemplar: [0.94484544 0.94358605 0.94136089 0.93941814 0.93711293 0.93409944\n",
      " 0.93307543 0.93132776]\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.9288713]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[0.94484544 0.94358605 0.94136089 0.93941814 0.93711293 0.93409944\n",
      "  0.93307543 0.93132776]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010739730205386877\n",
      "Predicción post entrenamiento : [[0.9289727]]\n",
      "PERDIDAAAA despues: 0.001067334203980863\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "[[[0.94358605]\n",
      "  [0.94136089]\n",
      "  [0.93941814]\n",
      "  [0.93711293]\n",
      "  [0.93409944]\n",
      "  [0.93307543]\n",
      "  [0.93132776]\n",
      "  [0.92887127]]]\n",
      "ejemplar: [0.94358605 0.94136089 0.93941814 0.93711293 0.93409944 0.93307543\n",
      " 0.93132776 0.92887127]\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.92722964]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[0.94358605 0.94136089 0.93941814 0.93711293 0.93409944 0.93307543\n",
      "  0.93132776 0.92887127]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016809762455523014\n",
      "Predicción post entrenamiento : [[0.9266946]]\n",
      "PERDIDAAAA despues: 0.0017251380486413836\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "[[[0.94136089]\n",
      "  [0.93941814]\n",
      "  [0.93711293]\n",
      "  [0.93409944]\n",
      "  [0.93307543]\n",
      "  [0.93132776]\n",
      "  [0.92887127]\n",
      "  [0.92722964]]]\n",
      "ejemplar: [0.94136089 0.93941814 0.93711293 0.93409944 0.93307543 0.93132776\n",
      " 0.92887127 0.92722964]\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.92473006]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[0.94136089 0.93941814 0.93711293 0.93409944 0.93307543 0.93132776\n",
      "  0.92887127 0.92722964]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010915264720097184\n",
      "Predicción post entrenamiento : [[0.9249261]]\n",
      "PERDIDAAAA despues: 0.0010786113562062383\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "[[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "ejemplar: [0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      " 0.03448276 0.04223169]\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.22270891]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      "  0.03448276 0.04223169]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03118853084743023\n",
      "Predicción post entrenamiento : [[0.1906898]]\n",
      "PERDIDAAAA despues: 0.020904429256916046\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "[[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22270891]]]\n",
      "ejemplar: [0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      " 0.04223169 0.22270891]\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.174703]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      "  0.04223169 0.22270891]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0049674068577587605\n",
      "Predicción post entrenamiento : [[0.15675922]]\n",
      "PERDIDAAAA despues: 0.0027600363828241825\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "[[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22270891]\n",
      "  [0.174703  ]]]\n",
      "ejemplar: [0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      " 0.22270891 0.174703  ]\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.16051945]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      "  0.22270891 0.174703  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.9887418097350746e-05\n",
      "Predicción post entrenamiento : [[0.16164094]]\n",
      "PERDIDAAAA despues: 5.531104761757888e-05\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "[[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22270891]\n",
      "  [0.174703  ]\n",
      "  [0.16051945]]]\n",
      "ejemplar: [0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.22270891\n",
      " 0.174703   0.16051945]\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.17259942]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.22270891\n",
      "  0.174703   0.16051945]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00028378222486935556\n",
      "Predicción post entrenamiento : [[0.17206825]]\n",
      "PERDIDAAAA despues: 0.0002661684702616185\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "[[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22270891]\n",
      "  [0.174703  ]\n",
      "  [0.16051945]\n",
      "  [0.17259942]]]\n",
      "ejemplar: [0.05656722 0.02595893 0.03448276 0.04223169 0.22270891 0.174703\n",
      " 0.16051945 0.17259942]\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.18378021]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[0.05656722 0.02595893 0.03448276 0.04223169 0.22270891 0.174703\n",
      "  0.16051945 0.17259942]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0033927669283002615\n",
      "Predicción post entrenamiento : [[0.18186086]]\n",
      "PERDIDAAAA despues: 0.003172856755554676\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "[[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22270891]\n",
      "  [0.174703  ]\n",
      "  [0.16051945]\n",
      "  [0.17259942]\n",
      "  [0.18378021]]]\n",
      "ejemplar: [0.02595893 0.03448276 0.04223169 0.22270891 0.174703   0.16051945\n",
      " 0.17259942 0.18378021]\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.19025739]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[0.02595893 0.03448276 0.04223169 0.22270891 0.174703   0.16051945\n",
      "  0.17259942 0.18378021]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001987146446481347\n",
      "Predicción post entrenamiento : [[0.18380034]]\n",
      "PERDIDAAAA despues: 0.001453162869438529\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "[[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22270891]\n",
      "  [0.174703  ]\n",
      "  [0.16051945]\n",
      "  [0.17259942]\n",
      "  [0.18378021]\n",
      "  [0.19025739]]]\n",
      "ejemplar: [0.03448276 0.04223169 0.22270891 0.174703   0.16051945 0.17259942\n",
      " 0.18378021 0.19025739]\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.20275405]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[0.03448276 0.04223169 0.22270891 0.174703   0.16051945 0.17259942\n",
      "  0.18378021 0.19025739]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0031695992220193148\n",
      "Predicción post entrenamiento : [[0.19857475]]\n",
      "PERDIDAAAA despues: 0.002716483548283577\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "[[[0.04223169]\n",
      "  [0.22270891]\n",
      "  [0.174703  ]\n",
      "  [0.16051945]\n",
      "  [0.17259942]\n",
      "  [0.18378021]\n",
      "  [0.19025739]\n",
      "  [0.20275405]]]\n",
      "ejemplar: [0.04223169 0.22270891 0.174703   0.16051945 0.17259942 0.18378021\n",
      " 0.19025739 0.20275405]\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.22139457]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[0.04223169 0.22270891 0.174703   0.16051945 0.17259942 0.18378021\n",
      "  0.19025739 0.20275405]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006424466846510768\n",
      "Predicción post entrenamiento : [[0.21952912]]\n",
      "PERDIDAAAA despues: 0.0005513614160008729\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "[[[0.22270891]\n",
      "  [0.174703  ]\n",
      "  [0.16051945]\n",
      "  [0.17259942]\n",
      "  [0.18378021]\n",
      "  [0.19025739]\n",
      "  [0.20275405]\n",
      "  [0.22139457]]]\n",
      "ejemplar: [0.22270891 0.174703   0.16051945 0.17259942 0.18378021 0.19025739\n",
      " 0.20275405 0.22139457]\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.24654701]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[0.22270891 0.174703   0.16051945 0.17259942 0.18378021 0.19025739\n",
      "  0.20275405 0.22139457]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00025651915348134935\n",
      "Predicción post entrenamiento : [[0.24461563]]\n",
      "PERDIDAAAA despues: 0.0001983824622584507\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "[[[0.174703  ]\n",
      "  [0.16051945]\n",
      "  [0.17259942]\n",
      "  [0.18378021]\n",
      "  [0.19025739]\n",
      "  [0.20275405]\n",
      "  [0.22139457]\n",
      "  [0.24654701]]]\n",
      "ejemplar: [0.174703   0.16051945 0.17259942 0.18378021 0.19025739 0.20275405\n",
      " 0.22139457 0.24654701]\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.23690757]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[0.174703   0.16051945 0.17259942 0.18378021 0.19025739 0.20275405\n",
      "  0.22139457 0.24654701]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008100417908281088\n",
      "Predicción post entrenamiento : [[0.23530689]]\n",
      "PERDIDAAAA despues: 0.0007214891375042498\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "[[[0.16051945]\n",
      "  [0.17259942]\n",
      "  [0.18378021]\n",
      "  [0.19025739]\n",
      "  [0.20275405]\n",
      "  [0.22139457]\n",
      "  [0.24654701]\n",
      "  [0.23690757]]]\n",
      "ejemplar: [0.16051945 0.17259942 0.18378021 0.19025739 0.20275405 0.22139457\n",
      " 0.24654701 0.23690757]\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.2380181]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[0.16051945 0.17259942 0.18378021 0.19025739 0.20275405 0.22139457\n",
      "  0.24654701 0.23690757]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006804134463891387\n",
      "Predicción post entrenamiento : [[0.23623157]]\n",
      "PERDIDAAAA despues: 0.0005904028075747192\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "[[[0.17259942]\n",
      "  [0.18378021]\n",
      "  [0.19025739]\n",
      "  [0.20275405]\n",
      "  [0.22139457]\n",
      "  [0.24654701]\n",
      "  [0.23690757]\n",
      "  [0.2380181 ]]]\n",
      "ejemplar: [0.17259942 0.18378021 0.19025739 0.20275405 0.22139457 0.24654701\n",
      " 0.23690757 0.2380181 ]\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.24383762]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[0.17259942 0.18378021 0.19025739 0.20275405 0.22139457 0.24654701\n",
      "  0.23690757 0.2380181 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001336167217232287\n",
      "Predicción post entrenamiento : [[0.2434369]]\n",
      "PERDIDAAAA despues: 0.0013070320710539818\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "[[[0.18378021]\n",
      "  [0.19025739]\n",
      "  [0.20275405]\n",
      "  [0.22139457]\n",
      "  [0.24654701]\n",
      "  [0.23690757]\n",
      "  [0.2380181 ]\n",
      "  [0.24383762]]]\n",
      "ejemplar: [0.18378021 0.19025739 0.20275405 0.22139457 0.24654701 0.23690757\n",
      " 0.2380181  0.24383762]\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.25086367]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[0.18378021 0.19025739 0.20275405 0.22139457 0.24654701 0.23690757\n",
      "  0.2380181  0.24383762]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0033541698940098286\n",
      "Predicción post entrenamiento : [[0.24866238]]\n",
      "PERDIDAAAA despues: 0.003104039467871189\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "[[[0.19025739]\n",
      "  [0.20275405]\n",
      "  [0.22139457]\n",
      "  [0.24654701]\n",
      "  [0.23690757]\n",
      "  [0.2380181 ]\n",
      "  [0.24383762]\n",
      "  [0.25086367]]]\n",
      "ejemplar: [0.19025739 0.20275405 0.22139457 0.24654701 0.23690757 0.2380181\n",
      " 0.24383762 0.25086367]\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.25591367]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[0.19025739 0.20275405 0.22139457 0.24654701 0.23690757 0.2380181\n",
      "  0.24383762 0.25086367]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0034917148295789957\n",
      "Predicción post entrenamiento : [[0.25326344]]\n",
      "PERDIDAAAA despues: 0.003185530425980687\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "[[[0.20275405]\n",
      "  [0.22139457]\n",
      "  [0.24654701]\n",
      "  [0.23690757]\n",
      "  [0.2380181 ]\n",
      "  [0.24383762]\n",
      "  [0.25086367]\n",
      "  [0.25591367]]]\n",
      "ejemplar: [0.20275405 0.22139457 0.24654701 0.23690757 0.2380181  0.24383762\n",
      " 0.25086367 0.25591367]\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.2612022]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[0.20275405 0.22139457 0.24654701 0.23690757 0.2380181  0.24383762\n",
      "  0.25086367 0.25591367]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0022037525195628405\n",
      "Predicción post entrenamiento : [[0.25941318]]\n",
      "PERDIDAAAA despues: 0.002038986422121525\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "[[[0.22139457]\n",
      "  [0.24654701]\n",
      "  [0.23690757]\n",
      "  [0.2380181 ]\n",
      "  [0.24383762]\n",
      "  [0.25086367]\n",
      "  [0.25591367]\n",
      "  [0.26120219]]]\n",
      "ejemplar: [0.22139457 0.24654701 0.23690757 0.2380181  0.24383762 0.25086367\n",
      " 0.25591367 0.26120219]\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.2665964]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[0.22139457 0.24654701 0.23690757 0.2380181  0.24383762 0.25086367\n",
      "  0.25591367 0.26120219]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007271201815456152\n",
      "Predicción post entrenamiento : [[0.26399684]]\n",
      "PERDIDAAAA despues: 0.006834622472524643\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "[[[0.24654701]\n",
      "  [0.23690757]\n",
      "  [0.2380181 ]\n",
      "  [0.24383762]\n",
      "  [0.25086367]\n",
      "  [0.25591367]\n",
      "  [0.26120219]\n",
      "  [0.26659641]]]\n",
      "ejemplar: [0.24654701 0.23690757 0.2380181  0.24383762 0.25086367 0.25591367\n",
      " 0.26120219 0.26659641]\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.26870054]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[0.24654701 0.23690757 0.2380181  0.24383762 0.25086367 0.25591367\n",
      "  0.26120219 0.26659641]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00875620823353529\n",
      "Predicción post entrenamiento : [[0.26613477]]\n",
      "PERDIDAAAA despues: 0.008282609283924103\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "[[[0.23690757]\n",
      "  [0.2380181 ]\n",
      "  [0.24383762]\n",
      "  [0.25086367]\n",
      "  [0.25591367]\n",
      "  [0.26120219]\n",
      "  [0.26659641]\n",
      "  [0.26870054]]]\n",
      "ejemplar: [0.23690757 0.2380181  0.24383762 0.25086367 0.25591367 0.26120219\n",
      " 0.26659641 0.26870054]\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.26634708]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[0.23690757 0.2380181  0.24383762 0.25086367 0.25591367 0.26120219\n",
      "  0.26659641 0.26870054]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014004930853843689\n",
      "Predicción post entrenamiento : [[0.26224455]]\n",
      "PERDIDAAAA despues: 0.013050755485892296\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "[[[0.2380181 ]\n",
      "  [0.24383762]\n",
      "  [0.25086367]\n",
      "  [0.25591367]\n",
      "  [0.26120219]\n",
      "  [0.26659641]\n",
      "  [0.26870054]\n",
      "  [0.26634708]]]\n",
      "ejemplar: [0.2380181  0.24383762 0.25086367 0.25591367 0.26120219 0.26659641\n",
      " 0.26870054 0.26634708]\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.26521388]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[0.2380181  0.24383762 0.25086367 0.25591367 0.26120219 0.26659641\n",
      "  0.26870054 0.26634708]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011312602087855339\n",
      "Predicción post entrenamiento : [[0.2622704]]\n",
      "PERDIDAAAA despues: 0.010695124045014381\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "[[[0.24383762]\n",
      "  [0.25086367]\n",
      "  [0.25591367]\n",
      "  [0.26120219]\n",
      "  [0.26659641]\n",
      "  [0.26870054]\n",
      "  [0.26634708]\n",
      "  [0.26521388]]]\n",
      "ejemplar: [0.24383762 0.25086367 0.25591367 0.26120219 0.26659641 0.26870054\n",
      " 0.26634708 0.26521388]\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.2659615]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[0.24383762 0.25086367 0.25591367 0.26120219 0.26659641 0.26870054\n",
      "  0.26634708 0.26521388]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005444658454507589\n",
      "Predicción post entrenamiento : [[0.2639622]]\n",
      "PERDIDAAAA despues: 0.00515360850840807\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "[[[0.25086367]\n",
      "  [0.25591367]\n",
      "  [0.26120219]\n",
      "  [0.26659641]\n",
      "  [0.26870054]\n",
      "  [0.26634708]\n",
      "  [0.26521388]\n",
      "  [0.2659615 ]]]\n",
      "ejemplar: [0.25086367 0.25591367 0.26120219 0.26659641 0.26870054 0.26634708\n",
      " 0.26521388 0.2659615 ]\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.26730263]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[0.25086367 0.25591367 0.26120219 0.26659641 0.26870054 0.26634708\n",
      "  0.26521388 0.2659615 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0066142757423222065\n",
      "Predicción post entrenamiento : [[0.26483908]]\n",
      "PERDIDAAAA despues: 0.006219632923603058\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "[[[0.25591367]\n",
      "  [0.26120219]\n",
      "  [0.26659641]\n",
      "  [0.26870054]\n",
      "  [0.26634708]\n",
      "  [0.26521388]\n",
      "  [0.2659615 ]\n",
      "  [0.26730263]]]\n",
      "ejemplar: [0.25591367 0.26120219 0.26659641 0.26870054 0.26634708 0.26521388\n",
      " 0.2659615  0.26730263]\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.26736477]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[0.25591367 0.26120219 0.26659641 0.26870054 0.26634708 0.26521388\n",
      "  0.2659615  0.26730263]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.7138280838935316e-07\n",
      "Predicción post entrenamiento : [[0.26567551]]\n",
      "PERDIDAAAA despues: 1.6263165889540687e-06\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "[[[0.26120219]\n",
      "  [0.26659641]\n",
      "  [0.26870054]\n",
      "  [0.26634708]\n",
      "  [0.26521388]\n",
      "  [0.2659615 ]\n",
      "  [0.26730263]\n",
      "  [0.26736477]]]\n",
      "ejemplar: [0.26120219 0.26659641 0.26870054 0.26634708 0.26521388 0.2659615\n",
      " 0.26730263 0.26736477]\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.26760018]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[0.26120219 0.26659641 0.26870054 0.26634708 0.26521388 0.2659615\n",
      "  0.26730263 0.26736477]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006211111904121935\n",
      "Predicción post entrenamiento : [[0.26759398]]\n",
      "PERDIDAAAA despues: 0.0006214202148839831\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "[[[0.26659641]\n",
      "  [0.26870054]\n",
      "  [0.26634708]\n",
      "  [0.26521388]\n",
      "  [0.2659615 ]\n",
      "  [0.26730263]\n",
      "  [0.26736477]\n",
      "  [0.26760018]]]\n",
      "ejemplar: [0.26659641 0.26870054 0.26634708 0.26521388 0.2659615  0.26730263\n",
      " 0.26736477 0.26760018]\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.26868474]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[0.26659641 0.26870054 0.26634708 0.26521388 0.2659615  0.26730263\n",
      "  0.26736477 0.26760018]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0024031144566833973\n",
      "Predicción post entrenamiento : [[0.2698174]]\n",
      "PERDIDAAAA despues: 0.0022933471482247114\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "[[[0.26870054]\n",
      "  [0.26634708]\n",
      "  [0.26521388]\n",
      "  [0.2659615 ]\n",
      "  [0.26730263]\n",
      "  [0.26736477]\n",
      "  [0.26760018]\n",
      "  [0.26868474]]]\n",
      "ejemplar: [0.26870054 0.26634708 0.26521388 0.2659615  0.26730263 0.26736477\n",
      " 0.26760018 0.26868474]\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.26986974]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[0.26870054 0.26634708 0.26521388 0.2659615  0.26730263 0.26736477\n",
      "  0.26760018 0.26868474]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0018318203510716558\n",
      "Predicción post entrenamiento : [[0.27043378]]\n",
      "PERDIDAAAA despues: 0.0017838571220636368\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "[[[0.26634708]\n",
      "  [0.26521388]\n",
      "  [0.2659615 ]\n",
      "  [0.26730263]\n",
      "  [0.26736477]\n",
      "  [0.26760018]\n",
      "  [0.26868474]\n",
      "  [0.26986974]]]\n",
      "ejemplar: [0.26634708 0.26521388 0.2659615  0.26730263 0.26736477 0.26760018\n",
      " 0.26868474 0.26986974]\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.2700387]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[0.26634708 0.26521388 0.2659615  0.26730263 0.26736477 0.26760018\n",
      "  0.26868474 0.26986974]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003608695406001061\n",
      "Predicción post entrenamiento : [[0.26991633]]\n",
      "PERDIDAAAA despues: 0.00036553366226144135\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "[[[0.26521388]\n",
      "  [0.2659615 ]\n",
      "  [0.26730263]\n",
      "  [0.26736477]\n",
      "  [0.26760018]\n",
      "  [0.26868474]\n",
      "  [0.26986974]\n",
      "  [0.27003869]]]\n",
      "ejemplar: [0.26521388 0.2659615  0.26730263 0.26736477 0.26760018 0.26868474\n",
      " 0.26986974 0.27003869]\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.27005637]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[0.26521388 0.2659615  0.26730263 0.26736477 0.26760018 0.26868474\n",
      "  0.26986974 0.27003869]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00016332181985490024\n",
      "Predicción post entrenamiento : [[0.27062482]]\n",
      "PERDIDAAAA despues: 0.00014911567268427461\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "[[[0.2659615 ]\n",
      "  [0.26730263]\n",
      "  [0.26736477]\n",
      "  [0.26760018]\n",
      "  [0.26868474]\n",
      "  [0.26986974]\n",
      "  [0.27003869]\n",
      "  [0.27005637]]]\n",
      "ejemplar: [0.2659615  0.26730263 0.26736477 0.26760018 0.26868474 0.26986974\n",
      " 0.27003869 0.27005637]\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.27112266]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[0.2659615  0.26730263 0.26736477 0.26760018 0.26868474 0.26986974\n",
      "  0.27003869 0.27005637]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008050645119510591\n",
      "Predicción post entrenamiento : [[0.27095586]]\n",
      "PERDIDAAAA despues: 0.0008145580068230629\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "[[[0.26730263]\n",
      "  [0.26736477]\n",
      "  [0.26760018]\n",
      "  [0.26868474]\n",
      "  [0.26986974]\n",
      "  [0.27003869]\n",
      "  [0.27005637]\n",
      "  [0.27112266]]]\n",
      "ejemplar: [0.26730263 0.26736477 0.26760018 0.26868474 0.26986974 0.27003869\n",
      " 0.27005637 0.27112266]\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.27143678]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[0.26730263 0.26736477 0.26760018 0.26868474 0.26986974 0.27003869\n",
      "  0.27005637 0.27112266]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.958316715899855e-05\n",
      "Predicción post entrenamiento : [[0.27095228]]\n",
      "PERDIDAAAA despues: 2.410597517155111e-05\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "[[[0.26736477]\n",
      "  [0.26760018]\n",
      "  [0.26868474]\n",
      "  [0.26986974]\n",
      "  [0.27003869]\n",
      "  [0.27005637]\n",
      "  [0.27112266]\n",
      "  [0.27143678]]]\n",
      "ejemplar: [0.26736477 0.26760018 0.26868474 0.26986974 0.27003869 0.27005637\n",
      " 0.27112266 0.27143678]\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.27127236]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[0.26736477 0.26760018 0.26868474 0.26986974 0.27003869 0.27005637\n",
      "  0.27112266 0.27143678]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.1746772543119732e-05\n",
      "Predicción post entrenamiento : [[0.27167207]]\n",
      "PERDIDAAAA despues: 9.166650670522358e-06\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "[[[0.26760018]\n",
      "  [0.26868474]\n",
      "  [0.26986974]\n",
      "  [0.27003869]\n",
      "  [0.27005637]\n",
      "  [0.27112266]\n",
      "  [0.27143678]\n",
      "  [0.27127236]]]\n",
      "ejemplar: [0.26760018 0.26868474 0.26986974 0.27003869 0.27005637 0.27112266\n",
      " 0.27143678 0.27127236]\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.27209634]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[0.26760018 0.26868474 0.26986974 0.27003869 0.27005637 0.27112266\n",
      "  0.27143678 0.27127236]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.141272241511615e-05\n",
      "Predicción post entrenamiento : [[0.27241838]]\n",
      "PERDIDAAAA despues: 9.340530596091412e-06\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "[[[0.26868474]\n",
      "  [0.26986974]\n",
      "  [0.27003869]\n",
      "  [0.27005637]\n",
      "  [0.27112266]\n",
      "  [0.27143678]\n",
      "  [0.27127236]\n",
      "  [0.27209634]]]\n",
      "ejemplar: [0.26868474 0.26986974 0.27003869 0.27005637 0.27112266 0.27143678\n",
      " 0.27127236 0.27209634]\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.2729193]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[0.26868474 0.26986974 0.27003869 0.27005637 0.27112266 0.27143678\n",
      "  0.27127236 0.27209634]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0038235255051404238\n",
      "Predicción post entrenamiento : [[0.27380648]]\n",
      "PERDIDAAAA despues: 0.00371459499001503\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "[[[0.26986974]\n",
      "  [0.27003869]\n",
      "  [0.27005637]\n",
      "  [0.27112266]\n",
      "  [0.27143678]\n",
      "  [0.27127236]\n",
      "  [0.27209634]\n",
      "  [0.2729193 ]]]\n",
      "ejemplar: [0.26986974 0.27003869 0.27005637 0.27112266 0.27143678 0.27127236\n",
      " 0.27209634 0.2729193 ]\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.2741945]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[0.26986974 0.27003869 0.27005637 0.27112266 0.27143678 0.27127236\n",
      "  0.27209634 0.2729193 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006639247294515371\n",
      "Predicción post entrenamiento : [[0.2751156]]\n",
      "PERDIDAAAA despues: 0.006489990279078484\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "[[[0.27003869]\n",
      "  [0.27005637]\n",
      "  [0.27112266]\n",
      "  [0.27143678]\n",
      "  [0.27127236]\n",
      "  [0.27209634]\n",
      "  [0.2729193 ]\n",
      "  [0.27419451]]]\n",
      "ejemplar: [0.27003869 0.27005637 0.27112266 0.27143678 0.27127236 0.27209634\n",
      " 0.2729193  0.27419451]\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.27535003]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[0.27003869 0.27005637 0.27112266 0.27143678 0.27127236 0.27209634\n",
      "  0.2729193  0.27419451]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0037627387791872025\n",
      "Predicción post entrenamiento : [[0.27660763]]\n",
      "PERDIDAAAA despues: 0.0036100351717323065\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "[[[0.27005637]\n",
      "  [0.27112266]\n",
      "  [0.27143678]\n",
      "  [0.27127236]\n",
      "  [0.27209634]\n",
      "  [0.2729193 ]\n",
      "  [0.27419451]\n",
      "  [0.27535003]]]\n",
      "ejemplar: [0.27005637 0.27112266 0.27143678 0.27127236 0.27209634 0.2729193\n",
      " 0.27419451 0.27535003]\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.27690968]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[0.27005637 0.27112266 0.27143678 0.27127236 0.27209634 0.2729193\n",
      "  0.27419451 0.27535003]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003212844720110297\n",
      "Predicción post entrenamiento : [[0.27760026]]\n",
      "PERDIDAAAA despues: 0.003135034814476967\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "[[[0.27112266]\n",
      "  [0.27143678]\n",
      "  [0.27127236]\n",
      "  [0.27209634]\n",
      "  [0.2729193 ]\n",
      "  [0.27419451]\n",
      "  [0.27535003]\n",
      "  [0.27690968]]]\n",
      "ejemplar: [0.27112266 0.27143678 0.27127236 0.27209634 0.2729193  0.27419451\n",
      " 0.27535003 0.27690968]\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.27803302]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[0.27112266 0.27143678 0.27127236 0.27209634 0.2729193  0.27419451\n",
      "  0.27535003 0.27690968]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011385227553546429\n",
      "Predicción post entrenamiento : [[0.2794943]]\n",
      "PERDIDAAAA despues: 0.011075523681938648\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "[[[0.27143678]\n",
      "  [0.27127236]\n",
      "  [0.27209634]\n",
      "  [0.2729193 ]\n",
      "  [0.27419451]\n",
      "  [0.27535003]\n",
      "  [0.27690968]\n",
      "  [0.27803302]]]\n",
      "ejemplar: [0.27143678 0.27127236 0.27209634 0.2729193  0.27419451 0.27535003\n",
      " 0.27690968 0.27803302]\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.27985275]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[0.27143678 0.27127236 0.27209634 0.2729193  0.27419451 0.27535003\n",
      "  0.27690968 0.27803302]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08482290804386139\n",
      "Predicción post entrenamiento : [[0.28395122]]\n",
      "PERDIDAAAA despues: 0.08245240151882172\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "[[[0.27127236]\n",
      "  [0.27209634]\n",
      "  [0.2729193 ]\n",
      "  [0.27419451]\n",
      "  [0.27535003]\n",
      "  [0.27690968]\n",
      "  [0.27803302]\n",
      "  [0.27985275]]]\n",
      "ejemplar: [0.27127236 0.27209634 0.2729193  0.27419451 0.27535003 0.27690968\n",
      " 0.27803302 0.27985275]\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.2844195]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[0.27127236 0.27209634 0.2729193  0.27419451 0.27535003 0.27690968\n",
      "  0.27803302 0.27985275]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09725728631019592\n",
      "Predicción post entrenamiento : [[0.2883927]]\n",
      "PERDIDAAAA despues: 0.09479491412639618\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "[[[0.27209634]\n",
      "  [0.2729193 ]\n",
      "  [0.27419451]\n",
      "  [0.27535003]\n",
      "  [0.27690968]\n",
      "  [0.27803302]\n",
      "  [0.27985275]\n",
      "  [0.28441951]]]\n",
      "ejemplar: [0.27209634 0.2729193  0.27419451 0.27535003 0.27690968 0.27803302\n",
      " 0.27985275 0.28441951]\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.28913674]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[0.27209634 0.2729193  0.27419451 0.27535003 0.27690968 0.27803302\n",
      "  0.27985275 0.28441951]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08147983998060226\n",
      "Predicción post entrenamiento : [[0.29289326]]\n",
      "PERDIDAAAA despues: 0.07934937626123428\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "[[[0.2729193 ]\n",
      "  [0.27419451]\n",
      "  [0.27535003]\n",
      "  [0.27690968]\n",
      "  [0.27803302]\n",
      "  [0.27985275]\n",
      "  [0.28441951]\n",
      "  [0.28913674]]]\n",
      "ejemplar: [0.2729193  0.27419451 0.27535003 0.27690968 0.27803302 0.27985275\n",
      " 0.28441951 0.28913674]\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.2937767]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[0.2729193  0.27419451 0.27535003 0.27690968 0.27803302 0.27985275\n",
      "  0.28441951 0.28913674]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09770464897155762\n",
      "Predicción post entrenamiento : [[0.29763663]]\n",
      "PERDIDAAAA despues: 0.09530648589134216\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "[[[0.27419451]\n",
      "  [0.27535003]\n",
      "  [0.27690968]\n",
      "  [0.27803302]\n",
      "  [0.27985275]\n",
      "  [0.28441951]\n",
      "  [0.28913674]\n",
      "  [0.29377669]]]\n",
      "ejemplar: [0.27419451 0.27535003 0.27690968 0.27803302 0.27985275 0.28441951\n",
      " 0.28913674 0.29377669]\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.2987438]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[0.27419451 0.27535003 0.27690968 0.27803302 0.27985275 0.28441951\n",
      "  0.28913674 0.29377669]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0817464292049408\n",
      "Predicción post entrenamiento : [[0.30207816]]\n",
      "PERDIDAAAA despues: 0.07985087484121323\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "[[[0.27535003]\n",
      "  [0.27690968]\n",
      "  [0.27803302]\n",
      "  [0.27985275]\n",
      "  [0.28441951]\n",
      "  [0.28913674]\n",
      "  [0.29377669]\n",
      "  [0.29874381]]]\n",
      "ejemplar: [0.27535003 0.27690968 0.27803302 0.27985275 0.28441951 0.28913674\n",
      " 0.29377669 0.29874381]\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.3034113]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[0.27535003 0.27690968 0.27803302 0.27985275 0.28441951 0.28913674\n",
      "  0.29377669 0.29874381]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07041618227958679\n",
      "Predicción post entrenamiento : [[0.30668068]]\n",
      "PERDIDAAAA despues: 0.06869174540042877\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "[[[0.27690968]\n",
      "  [0.27803302]\n",
      "  [0.27985275]\n",
      "  [0.28441951]\n",
      "  [0.28913674]\n",
      "  [0.29377669]\n",
      "  [0.29874381]\n",
      "  [0.3034113 ]]]\n",
      "ejemplar: [0.27690968 0.27803302 0.27985275 0.28441951 0.28913674 0.29377669\n",
      " 0.29874381 0.3034113 ]\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.30837902]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[0.27690968 0.27803302 0.27985275 0.28441951 0.28913674 0.29377669\n",
      "  0.29874381 0.3034113 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11182007193565369\n",
      "Predicción post entrenamiento : [[0.31227392]]\n",
      "PERDIDAAAA despues: 0.10923036932945251\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "[[[0.27803302]\n",
      "  [0.27985275]\n",
      "  [0.28441951]\n",
      "  [0.28913674]\n",
      "  [0.29377669]\n",
      "  [0.29874381]\n",
      "  [0.3034113 ]\n",
      "  [0.30837902]]]\n",
      "ejemplar: [0.27803302 0.27985275 0.28441951 0.28913674 0.29377669 0.29874381\n",
      " 0.3034113  0.30837902]\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.31437302]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[0.27803302 0.27985275 0.28441951 0.28913674 0.29377669 0.29874381\n",
      "  0.3034113  0.30837902]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12067703157663345\n",
      "Predicción post entrenamiento : [[0.31852055]]\n",
      "PERDIDAAAA despues: 0.11781264841556549\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "[[[0.27985275]\n",
      "  [0.28441951]\n",
      "  [0.28913674]\n",
      "  [0.29377669]\n",
      "  [0.29874381]\n",
      "  [0.3034113 ]\n",
      "  [0.30837902]\n",
      "  [0.31437302]]]\n",
      "ejemplar: [0.27985275 0.28441951 0.28913674 0.29377669 0.29874381 0.3034113\n",
      " 0.30837902 0.31437302]\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.32125363]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[0.27985275 0.28441951 0.28913674 0.29377669 0.29874381 0.3034113\n",
      "  0.30837902 0.31437302]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12372197210788727\n",
      "Predicción post entrenamiento : [[0.32501304]]\n",
      "PERDIDAAAA despues: 0.12109142541885376\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "[[[0.28441951]\n",
      "  [0.28913674]\n",
      "  [0.29377669]\n",
      "  [0.29874381]\n",
      "  [0.3034113 ]\n",
      "  [0.30837902]\n",
      "  [0.31437302]\n",
      "  [0.32125363]]]\n",
      "ejemplar: [0.28441951 0.28913674 0.29377669 0.29874381 0.3034113  0.30837902\n",
      " 0.31437302 0.32125363]\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.32837376]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[0.28441951 0.28913674 0.29377669 0.29874381 0.3034113  0.30837902\n",
      "  0.31437302 0.32125363]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14607955515384674\n",
      "Predicción post entrenamiento : [[0.33288497]]\n",
      "PERDIDAAAA despues: 0.1426514983177185\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "[[[0.28913674]\n",
      "  [0.29377669]\n",
      "  [0.29874381]\n",
      "  [0.3034113 ]\n",
      "  [0.30837902]\n",
      "  [0.31437302]\n",
      "  [0.32125363]\n",
      "  [0.32837376]]]\n",
      "ejemplar: [0.28913674 0.29377669 0.29874381 0.3034113  0.30837902 0.31437302\n",
      " 0.32125363 0.32837376]\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.33636585]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[0.28913674 0.29377669 0.29874381 0.3034113  0.30837902 0.31437302\n",
      "  0.32125363 0.32837376]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1351480334997177\n",
      "Predicción post entrenamiento : [[0.3402753]]\n",
      "PERDIDAAAA despues: 0.13228890299797058\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "[[[0.29377669]\n",
      "  [0.29874381]\n",
      "  [0.3034113 ]\n",
      "  [0.30837902]\n",
      "  [0.31437302]\n",
      "  [0.32125363]\n",
      "  [0.32837376]\n",
      "  [0.33636585]]]\n",
      "ejemplar: [0.29377669 0.29874381 0.3034113  0.30837902 0.31437302 0.32125363\n",
      " 0.32837376 0.33636585]\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.3439056]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[0.29377669 0.29874381 0.3034113  0.30837902 0.31437302 0.32125363\n",
      "  0.32837376 0.33636585]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1469433605670929\n",
      "Predicción post entrenamiento : [[0.34822163]]\n",
      "PERDIDAAAA despues: 0.1436530500650406\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "[[[0.29874381]\n",
      "  [0.3034113 ]\n",
      "  [0.30837902]\n",
      "  [0.31437302]\n",
      "  [0.32125363]\n",
      "  [0.32837376]\n",
      "  [0.33636585]\n",
      "  [0.3439056 ]]]\n",
      "ejemplar: [0.29874381 0.3034113  0.30837902 0.31437302 0.32125363 0.32837376\n",
      " 0.33636585 0.3439056 ]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.35210082]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[0.29874381 0.3034113  0.30837902 0.31437302 0.32125363 0.32837376\n",
      "  0.33636585 0.3439056 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13726083934307098\n",
      "Predicción post entrenamiento : [[0.35628507]]\n",
      "PERDIDAAAA despues: 0.13417792320251465\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "[[[0.3034113 ]\n",
      "  [0.30837902]\n",
      "  [0.31437302]\n",
      "  [0.32125363]\n",
      "  [0.32837376]\n",
      "  [0.33636585]\n",
      "  [0.3439056 ]\n",
      "  [0.35210082]]]\n",
      "ejemplar: [0.3034113  0.30837902 0.31437302 0.32125363 0.32837376 0.33636585\n",
      " 0.3439056  0.35210082]\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.3604354]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[0.3034113  0.30837902 0.31437302 0.32125363 0.32837376 0.33636585\n",
      "  0.3439056  0.35210082]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.16921581327915192\n",
      "Predicción post entrenamiento : [[0.36493665]]\n",
      "PERDIDAAAA despues: 0.16553282737731934\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "[[[0.30837902]\n",
      "  [0.31437302]\n",
      "  [0.32125363]\n",
      "  [0.32837376]\n",
      "  [0.33636585]\n",
      "  [0.3439056 ]\n",
      "  [0.35210082]\n",
      "  [0.3604354 ]]]\n",
      "ejemplar: [0.30837902 0.31437302 0.32125363 0.32837376 0.33636585 0.3439056\n",
      " 0.35210082 0.3604354 ]\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.36953798]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[0.30837902 0.31437302 0.32125363 0.32837376 0.33636585 0.3439056\n",
      "  0.35210082 0.3604354 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1260160654783249\n",
      "Predicción post entrenamiento : [[0.3730874]]\n",
      "PERDIDAAAA despues: 0.12350865453481674\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "[[[0.31437302]\n",
      "  [0.32125363]\n",
      "  [0.32837376]\n",
      "  [0.33636585]\n",
      "  [0.3439056 ]\n",
      "  [0.35210082]\n",
      "  [0.3604354 ]\n",
      "  [0.36953798]]]\n",
      "ejemplar: [0.31437302 0.32125363 0.32837376 0.33636585 0.3439056  0.35210082\n",
      " 0.3604354  0.36953798]\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.37819806]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[0.31437302 0.32125363 0.32837376 0.33636585 0.3439056  0.35210082\n",
      "  0.3604354  0.36953798]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08576676994562149\n",
      "Predicción post entrenamiento : [[0.38151804]]\n",
      "PERDIDAAAA despues: 0.08383321762084961\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "[[[0.32125363]\n",
      "  [0.32837376]\n",
      "  [0.33636585]\n",
      "  [0.3439056 ]\n",
      "  [0.35210082]\n",
      "  [0.3604354 ]\n",
      "  [0.36953798]\n",
      "  [0.37819806]]]\n",
      "ejemplar: [0.32125363 0.32837376 0.33636585 0.3439056  0.35210082 0.3604354\n",
      " 0.36953798 0.37819806]\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.38701576]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[0.32125363 0.32837376 0.33636585 0.3439056  0.35210082 0.3604354\n",
      "  0.36953798 0.37819806]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08222790062427521\n",
      "Predicción post entrenamiento : [[0.3900215]]\n",
      "PERDIDAAAA despues: 0.0805131122469902\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "[[[0.32837376]\n",
      "  [0.33636585]\n",
      "  [0.3439056 ]\n",
      "  [0.35210082]\n",
      "  [0.3604354 ]\n",
      "  [0.36953798]\n",
      "  [0.37819806]\n",
      "  [0.38701576]]]\n",
      "ejemplar: [0.32837376 0.33636585 0.3439056  0.35210082 0.3604354  0.36953798\n",
      " 0.37819806 0.38701576]\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.39578637]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[0.32837376 0.33636585 0.3439056  0.35210082 0.3604354  0.36953798\n",
      "  0.37819806 0.38701576]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10154764354228973\n",
      "Predicción post entrenamiento : [[0.39917794]]\n",
      "PERDIDAAAA despues: 0.09939759969711304\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "[[[0.33636585]\n",
      "  [0.3439056 ]\n",
      "  [0.35210082]\n",
      "  [0.3604354 ]\n",
      "  [0.36953798]\n",
      "  [0.37819806]\n",
      "  [0.38701576]\n",
      "  [0.39578637]]]\n",
      "ejemplar: [0.33636585 0.3439056  0.35210082 0.3604354  0.36953798 0.37819806\n",
      " 0.38701576 0.39578637]\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.40522265]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[0.33636585 0.3439056  0.35210082 0.3604354  0.36953798 0.37819806\n",
      "  0.38701576 0.39578637]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1147008091211319\n",
      "Predicción post entrenamiento : [[0.40849853]]\n",
      "PERDIDAAAA despues: 0.1124926283955574\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "[[[0.3439056 ]\n",
      "  [0.35210082]\n",
      "  [0.3604354 ]\n",
      "  [0.36953798]\n",
      "  [0.37819806]\n",
      "  [0.38701576]\n",
      "  [0.39578637]\n",
      "  [0.40522265]]]\n",
      "ejemplar: [0.3439056  0.35210082 0.3604354  0.36953798 0.37819806 0.38701576\n",
      " 0.39578637 0.40522265]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.41467324]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[0.3439056  0.35210082 0.3604354  0.36953798 0.37819806 0.38701576\n",
      "  0.39578637 0.40522265]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0948115736246109\n",
      "Predicción post entrenamiento : [[0.41764107]]\n",
      "PERDIDAAAA despues: 0.09299270063638687\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "[[[0.35210082]\n",
      "  [0.3604354 ]\n",
      "  [0.36953798]\n",
      "  [0.37819806]\n",
      "  [0.38701576]\n",
      "  [0.39578637]\n",
      "  [0.40522265]\n",
      "  [0.41467324]]]\n",
      "ejemplar: [0.35210082 0.3604354  0.36953798 0.37819806 0.38701576 0.39578637\n",
      " 0.40522265 0.41467324]\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.42410022]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[0.35210082 0.3604354  0.36953798 0.37819806 0.38701576 0.39578637\n",
      "  0.40522265 0.41467324]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07575768232345581\n",
      "Predicción post entrenamiento : [[0.42648208]]\n",
      "PERDIDAAAA despues: 0.07445218414068222\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "[[[0.3604354 ]\n",
      "  [0.36953798]\n",
      "  [0.37819806]\n",
      "  [0.38701576]\n",
      "  [0.39578637]\n",
      "  [0.40522265]\n",
      "  [0.41467324]\n",
      "  [0.42410022]]]\n",
      "ejemplar: [0.3604354  0.36953798 0.37819806 0.38701576 0.39578637 0.40522265\n",
      " 0.41467324 0.42410022]\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.43312258]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[0.3604354  0.36953798 0.37819806 0.38701576 0.39578637 0.40522265\n",
      "  0.41467324 0.42410022]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09253067523241043\n",
      "Predicción post entrenamiento : [[0.4360437]]\n",
      "PERDIDAAAA despues: 0.09076205641031265\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "[[[0.36953798]\n",
      "  [0.37819806]\n",
      "  [0.38701576]\n",
      "  [0.39578637]\n",
      "  [0.40522265]\n",
      "  [0.41467324]\n",
      "  [0.42410022]\n",
      "  [0.43312258]]]\n",
      "ejemplar: [0.36953798 0.37819806 0.38701576 0.39578637 0.40522265 0.41467324\n",
      " 0.42410022 0.43312258]\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.44287273]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[0.36953798 0.37819806 0.38701576 0.39578637 0.40522265 0.41467324\n",
      "  0.42410022 0.43312258]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07759182900190353\n",
      "Predicción post entrenamiento : [[0.44551674]]\n",
      "PERDIDAAAA despues: 0.07612583041191101\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "[[[0.37819806]\n",
      "  [0.38701576]\n",
      "  [0.39578637]\n",
      "  [0.40522265]\n",
      "  [0.41467324]\n",
      "  [0.42410022]\n",
      "  [0.43312258]\n",
      "  [0.44287273]]]\n",
      "ejemplar: [0.37819806 0.38701576 0.39578637 0.40522265 0.41467324 0.42410022\n",
      " 0.43312258 0.44287273]\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.4523764]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[0.37819806 0.38701576 0.39578637 0.40522265 0.41467324 0.42410022\n",
      "  0.43312258 0.44287273]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07093556225299835\n",
      "Predicción post entrenamiento : [[0.45456025]]\n",
      "PERDIDAAAA despues: 0.06977704912424088\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "[[[0.38701576]\n",
      "  [0.39578637]\n",
      "  [0.40522265]\n",
      "  [0.41467324]\n",
      "  [0.42410022]\n",
      "  [0.43312258]\n",
      "  [0.44287273]\n",
      "  [0.4523764 ]]]\n",
      "ejemplar: [0.38701576 0.39578637 0.40522265 0.41467324 0.42410022 0.43312258\n",
      " 0.44287273 0.4523764 ]\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.4615751]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[0.38701576 0.39578637 0.40522265 0.41467324 0.42410022 0.43312258\n",
      "  0.44287273 0.4523764 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0451912060379982\n",
      "Predicción post entrenamiento : [[0.46385276]]\n",
      "PERDIDAAAA despues: 0.04422800615429878\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "[[[0.39578637]\n",
      "  [0.40522265]\n",
      "  [0.41467324]\n",
      "  [0.42410022]\n",
      "  [0.43312258]\n",
      "  [0.44287273]\n",
      "  [0.4523764 ]\n",
      "  [0.46157509]]]\n",
      "ejemplar: [0.39578637 0.40522265 0.41467324 0.42410022 0.43312258 0.44287273\n",
      " 0.4523764  0.46157509]\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.4710134]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[0.39578637 0.40522265 0.41467324 0.42410022 0.43312258 0.44287273\n",
      "  0.4523764  0.46157509]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05178038775920868\n",
      "Predicción post entrenamiento : [[0.47307077]]\n",
      "PERDIDAAAA despues: 0.05084829404950142\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "[[[0.40522265]\n",
      "  [0.41467324]\n",
      "  [0.42410022]\n",
      "  [0.43312258]\n",
      "  [0.44287273]\n",
      "  [0.4523764 ]\n",
      "  [0.46157509]\n",
      "  [0.4710134 ]]]\n",
      "ejemplar: [0.40522265 0.41467324 0.42410022 0.43312258 0.44287273 0.4523764\n",
      " 0.46157509 0.4710134 ]\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.4804131]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[0.40522265 0.41467324 0.42410022 0.43312258 0.44287273 0.4523764\n",
      "  0.46157509 0.4710134 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.057900503277778625\n",
      "Predicción post entrenamiento : [[0.48217005]]\n",
      "PERDIDAAAA despues: 0.05705806240439415\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "[[[0.41467324]\n",
      "  [0.42410022]\n",
      "  [0.43312258]\n",
      "  [0.44287273]\n",
      "  [0.4523764 ]\n",
      "  [0.46157509]\n",
      "  [0.4710134 ]\n",
      "  [0.48041311]]]\n",
      "ejemplar: [0.41467324 0.42410022 0.43312258 0.44287273 0.4523764  0.46157509\n",
      " 0.4710134  0.48041311]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.48954532]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[0.41467324 0.42410022 0.43312258 0.44287273 0.4523764  0.46157509\n",
      "  0.4710134  0.48041311]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.054308950901031494\n",
      "Predicción post entrenamiento : [[0.4920816]]\n",
      "PERDIDAAAA despues: 0.053133249282836914\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "[[[0.42410022]\n",
      "  [0.43312258]\n",
      "  [0.44287273]\n",
      "  [0.4523764 ]\n",
      "  [0.46157509]\n",
      "  [0.4710134 ]\n",
      "  [0.48041311]\n",
      "  [0.48954532]]]\n",
      "ejemplar: [0.42410022 0.43312258 0.44287273 0.4523764  0.46157509 0.4710134\n",
      " 0.48041311 0.48954532]\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.49948484]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[0.42410022 0.43312258 0.44287273 0.4523764  0.46157509 0.4710134\n",
      "  0.48041311 0.48954532]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06595199555158615\n",
      "Predicción post entrenamiento : [[0.50206584]]\n",
      "PERDIDAAAA despues: 0.06463299691677094\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "[[[0.43312258]\n",
      "  [0.44287273]\n",
      "  [0.4523764 ]\n",
      "  [0.46157509]\n",
      "  [0.4710134 ]\n",
      "  [0.48041311]\n",
      "  [0.48954532]\n",
      "  [0.49948484]]]\n",
      "ejemplar: [0.43312258 0.44287273 0.4523764  0.46157509 0.4710134  0.48041311\n",
      " 0.48954532 0.49948484]\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.50950277]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[0.43312258 0.44287273 0.4523764  0.46157509 0.4710134  0.48041311\n",
      "  0.48954532 0.49948484]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10117708891630173\n",
      "Predicción post entrenamiento : [[0.5125748]]\n",
      "PERDIDAAAA despues: 0.09923221170902252\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "[[[0.44287273]\n",
      "  [0.4523764 ]\n",
      "  [0.46157509]\n",
      "  [0.4710134 ]\n",
      "  [0.48041311]\n",
      "  [0.48954532]\n",
      "  [0.49948484]\n",
      "  [0.50950277]]]\n",
      "ejemplar: [0.44287273 0.4523764  0.46157509 0.4710134  0.48041311 0.48954532\n",
      " 0.49948484 0.50950277]\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.52015847]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[0.44287273 0.4523764  0.46157509 0.4710134  0.48041311 0.48954532\n",
      "  0.49948484 0.50950277]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10154656320810318\n",
      "Predicción post entrenamiento : [[0.5232723]]\n",
      "PERDIDAAAA despues: 0.09957174211740494\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "[[[0.4523764 ]\n",
      "  [0.46157509]\n",
      "  [0.4710134 ]\n",
      "  [0.48041311]\n",
      "  [0.48954532]\n",
      "  [0.49948484]\n",
      "  [0.50950277]\n",
      "  [0.52015847]]]\n",
      "ejemplar: [0.4523764  0.46157509 0.4710134  0.48041311 0.48954532 0.49948484\n",
      " 0.50950277 0.52015847]\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.5308373]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[0.4523764  0.46157509 0.4710134  0.48041311 0.48954532 0.49948484\n",
      "  0.50950277 0.52015847]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06939458101987839\n",
      "Predicción post entrenamiento : [[0.53318745]]\n",
      "PERDIDAAAA despues: 0.06816191226243973\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "[[[0.46157509]\n",
      "  [0.4710134 ]\n",
      "  [0.48041311]\n",
      "  [0.48954532]\n",
      "  [0.49948484]\n",
      "  [0.50950277]\n",
      "  [0.52015847]\n",
      "  [0.5308373 ]]]\n",
      "ejemplar: [0.46157509 0.4710134  0.48041311 0.48954532 0.49948484 0.50950277\n",
      " 0.52015847 0.5308373 ]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.54080755]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[0.46157509 0.4710134  0.48041311 0.48954532 0.49948484 0.50950277\n",
      "  0.52015847 0.5308373 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.059047624468803406\n",
      "Predicción post entrenamiento : [[0.5432496]]\n",
      "PERDIDAAAA despues: 0.05786675959825516\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "[[[0.4710134 ]\n",
      "  [0.48041311]\n",
      "  [0.48954532]\n",
      "  [0.49948484]\n",
      "  [0.50950277]\n",
      "  [0.52015847]\n",
      "  [0.5308373 ]\n",
      "  [0.54080755]]]\n",
      "ejemplar: [0.4710134  0.48041311 0.48954532 0.49948484 0.50950277 0.52015847\n",
      " 0.5308373  0.54080755]\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.5510349]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[0.4710134  0.48041311 0.48954532 0.49948484 0.50950277 0.52015847\n",
      "  0.5308373  0.54080755]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.047038882970809937\n",
      "Predicción post entrenamiento : [[0.5519502]]\n",
      "PERDIDAAAA despues: 0.04664269834756851\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "[[[0.48041311]\n",
      "  [0.48954532]\n",
      "  [0.49948484]\n",
      "  [0.50950277]\n",
      "  [0.52015847]\n",
      "  [0.5308373 ]\n",
      "  [0.54080755]\n",
      "  [0.55103493]]]\n",
      "ejemplar: [0.48041311 0.48954532 0.49948484 0.50950277 0.52015847 0.5308373\n",
      " 0.54080755 0.55103493]\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.55987585]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[0.48041311 0.48954532 0.49948484 0.50950277 0.52015847 0.5308373\n",
      "  0.54080755 0.55103493]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05049179121851921\n",
      "Predicción post entrenamiento : [[0.5615913]]\n",
      "PERDIDAAAA despues: 0.0497237853705883\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "[[[0.48954532]\n",
      "  [0.49948484]\n",
      "  [0.50950277]\n",
      "  [0.52015847]\n",
      "  [0.5308373 ]\n",
      "  [0.54080755]\n",
      "  [0.55103493]\n",
      "  [0.55987585]]]\n",
      "ejemplar: [0.48954532 0.49948484 0.50950277 0.52015847 0.5308373  0.54080755\n",
      " 0.55103493 0.55987585]\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.5697005]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[0.48954532 0.49948484 0.50950277 0.52015847 0.5308373  0.54080755\n",
      "  0.55103493 0.55987585]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09549872577190399\n",
      "Predicción post entrenamiento : [[0.5726388]]\n",
      "PERDIDAAAA despues: 0.09369130432605743\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "[[[0.49948484]\n",
      "  [0.50950277]\n",
      "  [0.52015847]\n",
      "  [0.5308373 ]\n",
      "  [0.54080755]\n",
      "  [0.55103493]\n",
      "  [0.55987585]\n",
      "  [0.56970048]]]\n",
      "ejemplar: [0.49948484 0.50950277 0.52015847 0.5308373  0.54080755 0.55103493\n",
      " 0.55987585 0.56970048]\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.58103544]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[0.49948484 0.50950277 0.52015847 0.5308373  0.54080755 0.55103493\n",
      "  0.55987585 0.56970048]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08678572624921799\n",
      "Predicción post entrenamiento : [[0.58382964]]\n",
      "PERDIDAAAA despues: 0.08514721691608429\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "[[[0.50950277]\n",
      "  [0.52015847]\n",
      "  [0.5308373 ]\n",
      "  [0.54080755]\n",
      "  [0.55103493]\n",
      "  [0.55987585]\n",
      "  [0.56970048]\n",
      "  [0.58103544]]]\n",
      "ejemplar: [0.50950277 0.52015847 0.5308373  0.54080755 0.55103493 0.55987585\n",
      " 0.56970048 0.58103544]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.59232926]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[0.50950277 0.52015847 0.5308373  0.54080755 0.55103493 0.55987585\n",
      "  0.56970048 0.58103544]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06582637876272202\n",
      "Predicción post entrenamiento : [[0.5939825]]\n",
      "PERDIDAAAA despues: 0.06498077511787415\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "[[[0.52015847]\n",
      "  [0.5308373 ]\n",
      "  [0.54080755]\n",
      "  [0.55103493]\n",
      "  [0.55987585]\n",
      "  [0.56970048]\n",
      "  [0.58103544]\n",
      "  [0.59232926]]]\n",
      "ejemplar: [0.52015847 0.5308373  0.54080755 0.55103493 0.55987585 0.56970048\n",
      " 0.58103544 0.59232926]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.6025711]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[0.52015847 0.5308373  0.54080755 0.55103493 0.55987585 0.56970048\n",
      "  0.58103544 0.59232926]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04653354734182358\n",
      "Predicción post entrenamiento : [[0.60380125]]\n",
      "PERDIDAAAA despues: 0.04600434750318527\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "[[[0.5308373 ]\n",
      "  [0.54080755]\n",
      "  [0.55103493]\n",
      "  [0.55987585]\n",
      "  [0.56970048]\n",
      "  [0.58103544]\n",
      "  [0.59232926]\n",
      "  [0.60257113]]]\n",
      "ejemplar: [0.5308373  0.54080755 0.55103493 0.55987585 0.56970048 0.58103544\n",
      " 0.59232926 0.60257113]\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.61231256]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[0.5308373  0.54080755 0.55103493 0.55987585 0.56970048 0.58103544\n",
      "  0.59232926 0.60257113]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.046009715646505356\n",
      "Predicción post entrenamiento : [[0.6140213]]\n",
      "PERDIDAAAA despues: 0.04527958855032921\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "[[[0.54080755]\n",
      "  [0.55103493]\n",
      "  [0.55987585]\n",
      "  [0.56970048]\n",
      "  [0.58103544]\n",
      "  [0.59232926]\n",
      "  [0.60257113]\n",
      "  [0.61231256]]]\n",
      "ejemplar: [0.54080755 0.55103493 0.55987585 0.56970048 0.58103544 0.59232926\n",
      " 0.60257113 0.61231256]\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.62243867]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[0.54080755 0.55103493 0.55987585 0.56970048 0.58103544 0.59232926\n",
      "  0.60257113 0.61231256]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.026541566476225853\n",
      "Predicción post entrenamiento : [[0.6243334]]\n",
      "PERDIDAAAA despues: 0.025927798822522163\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "[[[0.55103493]\n",
      "  [0.55987585]\n",
      "  [0.56970048]\n",
      "  [0.58103544]\n",
      "  [0.59232926]\n",
      "  [0.60257113]\n",
      "  [0.61231256]\n",
      "  [0.62243867]]]\n",
      "ejemplar: [0.55103493 0.55987585 0.56970048 0.58103544 0.59232926 0.60257113\n",
      " 0.61231256 0.62243867]\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.632844]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[0.55103493 0.55987585 0.56970048 0.58103544 0.59232926 0.60257113\n",
      "  0.61231256 0.62243867]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.024456270039081573\n",
      "Predicción post entrenamiento : [[0.6342501]]\n",
      "PERDIDAAAA despues: 0.02401844970881939\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "[[[0.55987585]\n",
      "  [0.56970048]\n",
      "  [0.58103544]\n",
      "  [0.59232926]\n",
      "  [0.60257113]\n",
      "  [0.61231256]\n",
      "  [0.62243867]\n",
      "  [0.63284397]]]\n",
      "ejemplar: [0.55987585 0.56970048 0.58103544 0.59232926 0.60257113 0.61231256\n",
      " 0.62243867 0.63284397]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.6427996]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[0.55987585 0.56970048 0.58103544 0.59232926 0.60257113 0.61231256\n",
      "  0.62243867 0.63284397]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03662369027733803\n",
      "Predicción post entrenamiento : [[0.64466375]]\n",
      "PERDIDAAAA despues: 0.03591367229819298\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "[[[0.56970048]\n",
      "  [0.58103544]\n",
      "  [0.59232926]\n",
      "  [0.60257113]\n",
      "  [0.61231256]\n",
      "  [0.62243867]\n",
      "  [0.63284397]\n",
      "  [0.64279962]]]\n",
      "ejemplar: [0.56970048 0.58103544 0.59232926 0.60257113 0.61231256 0.62243867\n",
      " 0.63284397 0.64279962]\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.6536497]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[0.56970048 0.58103544 0.59232926 0.60257113 0.61231256 0.62243867\n",
      "  0.63284397 0.64279962]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02522573433816433\n",
      "Predicción post entrenamiento : [[0.65525454]]\n",
      "PERDIDAAAA despues: 0.024718523025512695\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "[[[0.58103544]\n",
      "  [0.59232926]\n",
      "  [0.60257113]\n",
      "  [0.61231256]\n",
      "  [0.62243867]\n",
      "  [0.63284397]\n",
      "  [0.64279962]\n",
      "  [0.65364969]]]\n",
      "ejemplar: [0.58103544 0.59232926 0.60257113 0.61231256 0.62243867 0.63284397\n",
      " 0.64279962 0.65364969]\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.6644572]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[0.58103544 0.59232926 0.60257113 0.61231256 0.62243867 0.63284397\n",
      "  0.64279962 0.65364969]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018709491938352585\n",
      "Predicción post entrenamiento : [[0.6654058]]\n",
      "PERDIDAAAA despues: 0.018450886011123657\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "[[[0.59232926]\n",
      "  [0.60257113]\n",
      "  [0.61231256]\n",
      "  [0.62243867]\n",
      "  [0.63284397]\n",
      "  [0.64279962]\n",
      "  [0.65364969]\n",
      "  [0.6644572 ]]]\n",
      "ejemplar: [0.59232926 0.60257113 0.61231256 0.62243867 0.63284397 0.64279962\n",
      " 0.65364969 0.6644572 ]\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.6744105]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[0.59232926 0.60257113 0.61231256 0.62243867 0.63284397 0.64279962\n",
      "  0.65364969 0.6644572 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016580820083618164\n",
      "Predicción post entrenamiento : [[0.6759931]]\n",
      "PERDIDAAAA despues: 0.016175763681530952\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "[[[0.60257113]\n",
      "  [0.61231256]\n",
      "  [0.62243867]\n",
      "  [0.63284397]\n",
      "  [0.64279962]\n",
      "  [0.65364969]\n",
      "  [0.6644572 ]\n",
      "  [0.67441052]]]\n",
      "ejemplar: [0.60257113 0.61231256 0.62243867 0.63284397 0.64279962 0.65364969\n",
      " 0.6644572  0.67441052]\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.6847695]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[0.60257113 0.61231256 0.62243867 0.63284397 0.64279962 0.65364969\n",
      "  0.6644572  0.67441052]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011820337735116482\n",
      "Predicción post entrenamiento : [[0.68474853]]\n",
      "PERDIDAAAA despues: 0.011824900284409523\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "[[[0.61231256]\n",
      "  [0.62243867]\n",
      "  [0.63284397]\n",
      "  [0.64279962]\n",
      "  [0.65364969]\n",
      "  [0.6644572 ]\n",
      "  [0.67441052]\n",
      "  [0.68476951]]]\n",
      "ejemplar: [0.61231256 0.62243867 0.63284397 0.64279962 0.65364969 0.6644572\n",
      " 0.67441052 0.68476951]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.6935542]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[0.61231256 0.62243867 0.63284397 0.64279962 0.65364969 0.6644572\n",
      "  0.67441052 0.68476951]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004437723197042942\n",
      "Predicción post entrenamiento : [[0.6933079]]\n",
      "PERDIDAAAA despues: 0.0044706049375236034\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "[[[0.62243867]\n",
      "  [0.63284397]\n",
      "  [0.64279962]\n",
      "  [0.65364969]\n",
      "  [0.6644572 ]\n",
      "  [0.67441052]\n",
      "  [0.68476951]\n",
      "  [0.69355422]]]\n",
      "ejemplar: [0.62243867 0.63284397 0.64279962 0.65364969 0.6644572  0.67441052\n",
      " 0.68476951 0.69355422]\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.7022846]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[0.62243867 0.63284397 0.64279962 0.65364969 0.6644572  0.67441052\n",
      "  0.68476951 0.69355422]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0010949043789878488\n",
      "Predicción post entrenamiento : [[0.70216733]]\n",
      "PERDIDAAAA despues: 0.0011026770807802677\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "[[[0.63284397]\n",
      "  [0.64279962]\n",
      "  [0.65364969]\n",
      "  [0.6644572 ]\n",
      "  [0.67441052]\n",
      "  [0.68476951]\n",
      "  [0.69355422]\n",
      "  [0.70228457]]]\n",
      "ejemplar: [0.63284397 0.64279962 0.65364969 0.6644572  0.67441052 0.68476951\n",
      " 0.69355422 0.70228457]\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.7112094]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[0.63284397 0.64279962 0.65364969 0.6644572  0.67441052 0.68476951\n",
      "  0.69355422 0.70228457]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.039578137351782e-06\n",
      "Predicción post entrenamiento : [[0.71246845]]\n",
      "PERDIDAAAA despues: 5.1921360864071175e-06\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "[[[0.64279962]\n",
      "  [0.65364969]\n",
      "  [0.6644572 ]\n",
      "  [0.67441052]\n",
      "  [0.68476951]\n",
      "  [0.69355422]\n",
      "  [0.70228457]\n",
      "  [0.71120942]]]\n",
      "ejemplar: [0.64279962 0.65364969 0.6644572  0.67441052 0.68476951 0.69355422\n",
      " 0.70228457 0.71120942]\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.7214724]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[0.64279962 0.65364969 0.6644572  0.67441052 0.68476951 0.69355422\n",
      "  0.70228457 0.71120942]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.733450522413477e-05\n",
      "Predicción post entrenamiento : [[0.7211353]]\n",
      "PERDIDAAAA despues: 8.114818774629384e-05\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "[[[0.65364969]\n",
      "  [0.6644572 ]\n",
      "  [0.67441052]\n",
      "  [0.68476951]\n",
      "  [0.69355422]\n",
      "  [0.70228457]\n",
      "  [0.71120942]\n",
      "  [0.72147238]]]\n",
      "ejemplar: [0.65364969 0.6644572  0.67441052 0.68476951 0.69355422 0.70228457\n",
      " 0.71120942 0.72147238]\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.73018]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[0.65364969 0.6644572  0.67441052 0.68476951 0.69355422 0.70228457\n",
      "  0.71120942 0.72147238]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.941215492086485e-05\n",
      "Predicción post entrenamiento : [[0.73024917]]\n",
      "PERDIDAAAA despues: 8.810935833025724e-05\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "[[[0.6644572 ]\n",
      "  [0.67441052]\n",
      "  [0.68476951]\n",
      "  [0.69355422]\n",
      "  [0.70228457]\n",
      "  [0.71120942]\n",
      "  [0.72147238]\n",
      "  [0.73018003]]]\n",
      "ejemplar: [0.6644572  0.67441052 0.68476951 0.69355422 0.70228457 0.71120942\n",
      " 0.72147238 0.73018003]\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.73903924]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[0.6644572  0.67441052 0.68476951 0.69355422 0.70228457 0.71120942\n",
      "  0.72147238 0.73018003]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.354802957910579e-06\n",
      "Predicción post entrenamiento : [[0.740268]]\n",
      "PERDIDAAAA despues: 1.6967951523838565e-05\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "[[[0.67441052]\n",
      "  [0.68476951]\n",
      "  [0.69355422]\n",
      "  [0.70228457]\n",
      "  [0.71120942]\n",
      "  [0.72147238]\n",
      "  [0.73018003]\n",
      "  [0.73903924]]]\n",
      "ejemplar: [0.67441052 0.68476951 0.69355422 0.70228457 0.71120942 0.72147238\n",
      " 0.73018003 0.73903924]\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.7487407]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[0.67441052 0.68476951 0.69355422 0.70228457 0.71120942 0.72147238\n",
      "  0.73018003 0.73903924]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006588562857359648\n",
      "Predicción post entrenamiento : [[0.7468375]]\n",
      "PERDIDAAAA despues: 0.006283223628997803\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "[[[0.68476951]\n",
      "  [0.69355422]\n",
      "  [0.70228457]\n",
      "  [0.71120942]\n",
      "  [0.72147238]\n",
      "  [0.73018003]\n",
      "  [0.73903924]\n",
      "  [0.74874067]]]\n",
      "ejemplar: [0.68476951 0.69355422 0.70228457 0.71120942 0.72147238 0.73018003\n",
      " 0.73903924 0.74874067]\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.75515836]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[0.68476951 0.69355422 0.70228457 0.71120942 0.72147238 0.73018003\n",
      "  0.73903924 0.74874067]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007269771303981543\n",
      "Predicción post entrenamiento : [[0.75475824]]\n",
      "PERDIDAAAA despues: 0.007201699540019035\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "[[[0.69355422]\n",
      "  [0.70228457]\n",
      "  [0.71120942]\n",
      "  [0.72147238]\n",
      "  [0.73018003]\n",
      "  [0.73903924]\n",
      "  [0.74874067]\n",
      "  [0.75515836]]]\n",
      "ejemplar: [0.69355422 0.70228457 0.71120942 0.72147238 0.73018003 0.73903924\n",
      " 0.74874067 0.75515836]\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.7627632]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[0.69355422 0.70228457 0.71120942 0.72147238 0.73018003 0.73903924\n",
      "  0.74874067 0.75515836]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004373702686280012\n",
      "Predicción post entrenamiento : [[0.7625449]]\n",
      "PERDIDAAAA despues: 0.004344872198998928\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "[[[0.70228457]\n",
      "  [0.71120942]\n",
      "  [0.72147238]\n",
      "  [0.73018003]\n",
      "  [0.73903924]\n",
      "  [0.74874067]\n",
      "  [0.75515836]\n",
      "  [0.7627632 ]]]\n",
      "ejemplar: [0.70228457 0.71120942 0.72147238 0.73018003 0.73903924 0.74874067\n",
      " 0.75515836 0.7627632 ]\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.7706187]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[0.70228457 0.71120942 0.72147238 0.73018003 0.73903924 0.74874067\n",
      "  0.75515836 0.7627632 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013149518519639969\n",
      "Predicción post entrenamiento : [[0.7683144]]\n",
      "PERDIDAAAA despues: 0.012626363895833492\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "[[[0.71120942]\n",
      "  [0.72147238]\n",
      "  [0.73018003]\n",
      "  [0.73903924]\n",
      "  [0.74874067]\n",
      "  [0.75515836]\n",
      "  [0.7627632 ]\n",
      "  [0.77061868]]]\n",
      "ejemplar: [0.71120942 0.72147238 0.73018003 0.73903924 0.74874067 0.75515836\n",
      " 0.7627632  0.77061868]\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.7764377]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[0.71120942 0.72147238 0.73018003 0.73903924 0.74874067 0.75515836\n",
      "  0.7627632  0.77061868]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009531819261610508\n",
      "Predicción post entrenamiento : [[0.77505875]]\n",
      "PERDIDAAAA despues: 0.009264463558793068\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "[[[0.72147238]\n",
      "  [0.73018003]\n",
      "  [0.73903924]\n",
      "  [0.74874067]\n",
      "  [0.75515836]\n",
      "  [0.7627632 ]\n",
      "  [0.77061868]\n",
      "  [0.7764377 ]]]\n",
      "ejemplar: [0.72147238 0.73018003 0.73903924 0.74874067 0.75515836 0.7627632\n",
      " 0.77061868 0.7764377 ]\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.78312504]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[0.72147238 0.73018003 0.73903924 0.74874067 0.75515836 0.7627632\n",
      "  0.77061868 0.7764377 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011455530300736427\n",
      "Predicción post entrenamiento : [[0.7831863]]\n",
      "PERDIDAAAA despues: 0.011468649841845036\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "[[[0.73018003]\n",
      "  [0.73903924]\n",
      "  [0.74874067]\n",
      "  [0.75515836]\n",
      "  [0.7627632 ]\n",
      "  [0.77061868]\n",
      "  [0.7764377 ]\n",
      "  [0.78312504]]]\n",
      "ejemplar: [0.73018003 0.73903924 0.74874067 0.75515836 0.7627632  0.77061868\n",
      " 0.7764377  0.78312504]\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.7907224]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[0.73018003 0.73903924 0.74874067 0.75515836 0.7627632  0.77061868\n",
      "  0.7764377  0.78312504]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003740578191354871\n",
      "Predicción post entrenamiento : [[0.7907462]]\n",
      "PERDIDAAAA despues: 0.003743487875908613\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "[[[0.73903924]\n",
      "  [0.74874067]\n",
      "  [0.75515836]\n",
      "  [0.7627632 ]\n",
      "  [0.77061868]\n",
      "  [0.7764377 ]\n",
      "  [0.78312504]\n",
      "  [0.79072243]]]\n",
      "ejemplar: [0.73903924 0.74874067 0.75515836 0.7627632  0.77061868 0.7764377\n",
      " 0.78312504 0.79072243]\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.7980684]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[0.73903924 0.74874067 0.75515836 0.7627632  0.77061868 0.7764377\n",
      "  0.78312504 0.79072243]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009368272498250008\n",
      "Predicción post entrenamiento : [[0.7972897]]\n",
      "PERDIDAAAA despues: 0.009218143299221992\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "[[[0.74874067]\n",
      "  [0.75515836]\n",
      "  [0.7627632 ]\n",
      "  [0.77061868]\n",
      "  [0.7764377 ]\n",
      "  [0.78312504]\n",
      "  [0.79072243]\n",
      "  [0.7980684 ]]]\n",
      "ejemplar: [0.74874067 0.75515836 0.7627632  0.77061868 0.7764377  0.78312504\n",
      " 0.79072243 0.7980684 ]\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.8042685]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[0.74874067 0.75515836 0.7627632  0.77061868 0.7764377  0.78312504\n",
      "  0.79072243 0.7980684 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013495695311576128\n",
      "Predicción post entrenamiento : [[0.8027561]]\n",
      "PERDIDAAAA despues: 0.001240735873579979\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "[[[0.75515836]\n",
      "  [0.7627632 ]\n",
      "  [0.77061868]\n",
      "  [0.7764377 ]\n",
      "  [0.78312504]\n",
      "  [0.79072243]\n",
      "  [0.7980684 ]\n",
      "  [0.80426848]]]\n",
      "ejemplar: [0.75515836 0.7627632  0.77061868 0.7764377  0.78312504 0.79072243\n",
      " 0.7980684  0.80426848]\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.80904895]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[0.75515836 0.7627632  0.77061868 0.7764377  0.78312504 0.79072243\n",
      "  0.7980684  0.80426848]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029068554285913706\n",
      "Predicción post entrenamiento : [[0.807339]]\n",
      "PERDIDAAAA despues: 0.00272539583966136\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "[[[0.7627632 ]\n",
      "  [0.77061868]\n",
      "  [0.7764377 ]\n",
      "  [0.78312504]\n",
      "  [0.79072243]\n",
      "  [0.7980684 ]\n",
      "  [0.80426848]\n",
      "  [0.80904895]]]\n",
      "ejemplar: [0.7627632  0.77061868 0.7764377  0.78312504 0.79072243 0.7980684\n",
      " 0.80426848 0.80904895]\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.81379104]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[0.7627632  0.77061868 0.7764377  0.78312504 0.79072243 0.7980684\n",
      "  0.80426848 0.80904895]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0047239516861736774\n",
      "Predicción post entrenamiento : [[0.8139309]]\n",
      "PERDIDAAAA despues: 0.004743201192468405\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "[[[0.77061868]\n",
      "  [0.7764377 ]\n",
      "  [0.78312504]\n",
      "  [0.79072243]\n",
      "  [0.7980684 ]\n",
      "  [0.80426848]\n",
      "  [0.80904895]\n",
      "  [0.81379104]]]\n",
      "ejemplar: [0.77061868 0.7764377  0.78312504 0.79072243 0.7980684  0.80426848\n",
      " 0.80904895 0.81379104]\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.8201774]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[0.77061868 0.7764377  0.78312504 0.79072243 0.7980684  0.80426848\n",
      "  0.80904895 0.81379104]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004643510561436415\n",
      "Predicción post entrenamiento : [[0.8199534]]\n",
      "PERDIDAAAA despues: 0.004613033030182123\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "[[[0.7764377 ]\n",
      "  [0.78312504]\n",
      "  [0.79072243]\n",
      "  [0.7980684 ]\n",
      "  [0.80426848]\n",
      "  [0.80904895]\n",
      "  [0.81379104]\n",
      "  [0.82017738]]]\n",
      "ejemplar: [0.7764377  0.78312504 0.79072243 0.7980684  0.80426848 0.80904895\n",
      " 0.81379104 0.82017738]\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.82584417]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[0.7764377  0.78312504 0.79072243 0.7980684  0.80426848 0.80904895\n",
      "  0.81379104 0.82017738]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013465694151818752\n",
      "Predicción post entrenamiento : [[0.82563245]]\n",
      "PERDIDAAAA despues: 0.01341660413891077\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "[[[0.78312504]\n",
      "  [0.79072243]\n",
      "  [0.7980684 ]\n",
      "  [0.80426848]\n",
      "  [0.80904895]\n",
      "  [0.81379104]\n",
      "  [0.82017738]\n",
      "  [0.82584417]]]\n",
      "ejemplar: [0.78312504 0.79072243 0.7980684  0.80426848 0.80904895 0.81379104\n",
      " 0.82017738 0.82584417]\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.83168554]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[0.78312504 0.79072243 0.7980684  0.80426848 0.80904895 0.81379104\n",
      "  0.82017738 0.82584417]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019953114911913872\n",
      "Predicción post entrenamiento : [[0.8318671]]\n",
      "PERDIDAAAA despues: 0.02000444009900093\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "[[[0.79072243]\n",
      "  [0.7980684 ]\n",
      "  [0.80426848]\n",
      "  [0.80904895]\n",
      "  [0.81379104]\n",
      "  [0.82017738]\n",
      "  [0.82584417]\n",
      "  [0.83168554]]]\n",
      "ejemplar: [0.79072243 0.7980684  0.80426848 0.80904895 0.81379104 0.82017738\n",
      " 0.82584417 0.83168554]\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.8378082]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[0.79072243 0.7980684  0.80426848 0.80904895 0.81379104 0.82017738\n",
      "  0.82584417 0.83168554]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006963806226849556\n",
      "Predicción post entrenamiento : [[0.8379955]]\n",
      "PERDIDAAAA despues: 0.006995107512921095\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "[[[0.7980684 ]\n",
      "  [0.80426848]\n",
      "  [0.80904895]\n",
      "  [0.81379104]\n",
      "  [0.82017738]\n",
      "  [0.82584417]\n",
      "  [0.83168554]\n",
      "  [0.83780819]]]\n",
      "ejemplar: [0.7980684  0.80426848 0.80904895 0.81379104 0.82017738 0.82584417\n",
      " 0.83168554 0.83780819]\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.84349895]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[0.7980684  0.80426848 0.80904895 0.81379104 0.82017738 0.82584417\n",
      "  0.83168554 0.83780819]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014713265933096409\n",
      "Predicción post entrenamiento : [[0.84255016]]\n",
      "PERDIDAAAA despues: 0.014483993873000145\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "[[[0.80426848]\n",
      "  [0.80904895]\n",
      "  [0.81379104]\n",
      "  [0.82017738]\n",
      "  [0.82584417]\n",
      "  [0.83168554]\n",
      "  [0.83780819]\n",
      "  [0.84349895]]]\n",
      "ejemplar: [0.80426848 0.80904895 0.81379104 0.82017738 0.82584417 0.83168554\n",
      " 0.83780819 0.84349895]\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.84760463]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[0.80426848 0.80904895 0.81379104 0.82017738 0.82584417 0.83168554\n",
      "  0.83780819 0.84349895]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.167199894160149e-07\n",
      "Predicción post entrenamiento : [[0.8478752]]\n",
      "PERDIDAAAA despues: 4.009170879726298e-07\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "[[[0.80904895]\n",
      "  [0.81379104]\n",
      "  [0.82017738]\n",
      "  [0.82584417]\n",
      "  [0.83168554]\n",
      "  [0.83780819]\n",
      "  [0.84349895]\n",
      "  [0.84760463]]]\n",
      "ejemplar: [0.80904895 0.81379104 0.82017738 0.82584417 0.83168554 0.83780819\n",
      " 0.84349895 0.84760463]\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.85275453]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[0.80904895 0.81379104 0.82017738 0.82584417 0.83168554 0.83780819\n",
      "  0.84349895 0.84760463]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0027781804092228413\n",
      "Predicción post entrenamiento : [[0.85308015]]\n",
      "PERDIDAAAA despues: 0.002743960591033101\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "[[[0.81379104]\n",
      "  [0.82017738]\n",
      "  [0.82584417]\n",
      "  [0.83168554]\n",
      "  [0.83780819]\n",
      "  [0.84349895]\n",
      "  [0.84760463]\n",
      "  [0.85275453]]]\n",
      "ejemplar: [0.81379104 0.82017738 0.82584417 0.83168554 0.83780819 0.84349895\n",
      " 0.84760463 0.85275453]\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.8581839]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[0.81379104 0.82017738 0.82584417 0.83168554 0.83780819 0.84349895\n",
      "  0.84760463 0.85275453]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005775511963292956\n",
      "Predicción post entrenamiento : [[0.85784376]]\n",
      "PERDIDAAAA despues: 0.0005940167466178536\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "[[[0.82017738]\n",
      "  [0.82584417]\n",
      "  [0.83168554]\n",
      "  [0.83780819]\n",
      "  [0.84349895]\n",
      "  [0.84760463]\n",
      "  [0.85275453]\n",
      "  [0.85818392]]]\n",
      "ejemplar: [0.82017738 0.82584417 0.83168554 0.83780819 0.84349895 0.84760463\n",
      " 0.85275453 0.85818392]\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.8632053]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[0.82017738 0.82584417 0.83168554 0.83780819 0.84349895 0.84760463\n",
      "  0.85275453 0.85818392]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0019875874277204275\n",
      "Predicción post entrenamiento : [[0.8619835]]\n",
      "PERDIDAAAA despues: 0.002098025055602193\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "[[[0.82584417]\n",
      "  [0.83168554]\n",
      "  [0.83780819]\n",
      "  [0.84349895]\n",
      "  [0.84760463]\n",
      "  [0.85275453]\n",
      "  [0.85818392]\n",
      "  [0.86320531]]]\n",
      "ejemplar: [0.82584417 0.83168554 0.83780819 0.84349895 0.84760463 0.85275453\n",
      " 0.85818392 0.86320531]\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.86711854]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[0.82584417 0.83168554 0.83780819 0.84349895 0.84760463 0.85275453\n",
      "  0.85818392 0.86320531]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005044133868068457\n",
      "Predicción post entrenamiento : [[0.8671387]]\n",
      "PERDIDAAAA despues: 0.0005035088397562504\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "[[[0.83168554]\n",
      "  [0.83780819]\n",
      "  [0.84349895]\n",
      "  [0.84760463]\n",
      "  [0.85275453]\n",
      "  [0.85818392]\n",
      "  [0.86320531]\n",
      "  [0.86711854]]]\n",
      "ejemplar: [0.83168554 0.83780819 0.84349895 0.84760463 0.85275453 0.85818392\n",
      " 0.86320531 0.86711854]\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.8722018]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[0.83168554 0.83780819 0.84349895 0.84760463 0.85275453 0.85818392\n",
      "  0.86320531 0.86711854]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.0377909651142545e-06\n",
      "Predicción post entrenamiento : [[0.87203467]]\n",
      "PERDIDAAAA despues: 7.952484338602517e-06\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "[[[0.83780819]\n",
      "  [0.84349895]\n",
      "  [0.84760463]\n",
      "  [0.85275453]\n",
      "  [0.85818392]\n",
      "  [0.86320531]\n",
      "  [0.86711854]\n",
      "  [0.8722018 ]]]\n",
      "ejemplar: [0.83780819 0.84349895 0.84760463 0.85275453 0.85818392 0.86320531\n",
      " 0.86711854 0.8722018 ]\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.87693214]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[0.83780819 0.84349895 0.84760463 0.85275453 0.85818392 0.86320531\n",
      "  0.86711854 0.8722018 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013162237592041492\n",
      "Predicción post entrenamiento : [[0.8763775]]\n",
      "PERDIDAAAA despues: 0.00135677435901016\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "[[[0.84349895]\n",
      "  [0.84760463]\n",
      "  [0.85275453]\n",
      "  [0.85818392]\n",
      "  [0.86320531]\n",
      "  [0.86711854]\n",
      "  [0.8722018 ]\n",
      "  [0.87693214]]]\n",
      "ejemplar: [0.84349895 0.84760463 0.85275453 0.85818392 0.86320531 0.86711854\n",
      " 0.8722018  0.87693214]\n",
      "y: 1.0\n",
      "Predicción : [[0.8809731]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[0.84349895 0.84760463 0.85275453 0.85818392 0.86320531 0.86711854\n",
      "  0.8722018  0.87693214]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014167402870953083\n",
      "Predicción post entrenamiento : [[0.88233477]]\n",
      "PERDIDAAAA despues: 0.013845106586813927\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "[[[0.84760463]\n",
      "  [0.85275453]\n",
      "  [0.85818392]\n",
      "  [0.86320531]\n",
      "  [0.86711854]\n",
      "  [0.8722018 ]\n",
      "  [0.87693214]\n",
      "  [0.8809731 ]]]\n",
      "ejemplar: [0.84760463 0.85275453 0.85818392 0.86320531 0.86711854 0.8722018\n",
      " 0.87693214 0.8809731 ]\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.8866986]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[0.84760463 0.85275453 0.85818392 0.86320531 0.86711854 0.8722018\n",
      "  0.87693214 0.8809731 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007031736429780722\n",
      "Predicción post entrenamiento : [[0.8882146]]\n",
      "PERDIDAAAA despues: 0.0067797875963151455\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "[[[0.85275453]\n",
      "  [0.85818392]\n",
      "  [0.86320531]\n",
      "  [0.86711854]\n",
      "  [0.8722018 ]\n",
      "  [0.87693214]\n",
      "  [0.8809731 ]\n",
      "  [0.8866986 ]]]\n",
      "ejemplar: [0.85275453 0.85818392 0.86320531 0.86711854 0.8722018  0.87693214\n",
      " 0.8809731  0.8866986 ]\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.89278805]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[0.85275453 0.85818392 0.86320531 0.86711854 0.8722018  0.87693214\n",
      "  0.8809731  0.8866986 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.588250233908184e-05\n",
      "Predicción post entrenamiento : [[0.89425915]]\n",
      "PERDIDAAAA despues: 2.9772170819342136e-05\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "[[[0.85818392]\n",
      "  [0.86320531]\n",
      "  [0.86711854]\n",
      "  [0.8722018 ]\n",
      "  [0.87693214]\n",
      "  [0.8809731 ]\n",
      "  [0.8866986 ]\n",
      "  [0.89278805]]]\n",
      "ejemplar: [0.85818392 0.86320531 0.86711854 0.8722018  0.87693214 0.8809731\n",
      " 0.8866986  0.89278805]\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.89875823]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[0.85818392 0.86320531 0.86711854 0.8722018  0.87693214 0.8809731\n",
      "  0.8866986  0.89278805]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00043280344107188284\n",
      "Predicción post entrenamiento : [[0.89820504]]\n",
      "PERDIDAAAA despues: 0.0004100923833902925\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "[[[0.86320531]\n",
      "  [0.86711854]\n",
      "  [0.8722018 ]\n",
      "  [0.87693214]\n",
      "  [0.8809731 ]\n",
      "  [0.8866986 ]\n",
      "  [0.89278805]\n",
      "  [0.89875823]]]\n",
      "ejemplar: [0.86320531 0.86711854 0.8722018  0.87693214 0.8809731  0.8866986\n",
      " 0.89278805 0.89875823]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.9025429]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[0.86320531 0.86711854 0.8722018  0.87693214 0.8809731  0.8866986\n",
      "  0.89278805 0.89875823]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0028780114371329546\n",
      "Predicción post entrenamiento : [[0.90280694]]\n",
      "PERDIDAAAA despues: 0.0029064121190458536\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "[[[0.86711854]\n",
      "  [0.8722018 ]\n",
      "  [0.87693214]\n",
      "  [0.8809731 ]\n",
      "  [0.8866986 ]\n",
      "  [0.89278805]\n",
      "  [0.89875823]\n",
      "  [0.90254289]]]\n",
      "ejemplar: [0.86711854 0.8722018  0.87693214 0.8809731  0.8866986  0.89278805\n",
      " 0.89875823 0.90254289]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.9071026]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[0.86711854 0.8722018  0.87693214 0.8809731  0.8866986  0.89278805\n",
      "  0.89875823 0.90254289]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005318755749613047\n",
      "Predicción post entrenamiento : [[0.9061593]]\n",
      "PERDIDAAAA despues: 0.005182055756449699\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "[[[0.8722018 ]\n",
      "  [0.87693214]\n",
      "  [0.8809731 ]\n",
      "  [0.8866986 ]\n",
      "  [0.89278805]\n",
      "  [0.89875823]\n",
      "  [0.90254289]\n",
      "  [0.90710258]]]\n",
      "ejemplar: [0.8722018  0.87693214 0.8809731  0.8866986  0.89278805 0.89875823\n",
      " 0.90254289 0.90710258]\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.9107584]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[0.8722018  0.87693214 0.8809731  0.8866986  0.89278805 0.89875823\n",
      "  0.90254289 0.90710258]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003098421497270465\n",
      "Predicción post entrenamiento : [[0.910408]]\n",
      "PERDIDAAAA despues: 0.0030595401767641306\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "[[[0.87693214]\n",
      "  [0.8809731 ]\n",
      "  [0.8866986 ]\n",
      "  [0.89278805]\n",
      "  [0.89875823]\n",
      "  [0.90254289]\n",
      "  [0.90710258]\n",
      "  [0.91075838]]]\n",
      "ejemplar: [0.87693214 0.8809731  0.8866986  0.89278805 0.89875823 0.90254289\n",
      " 0.90710258 0.91075838]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.9149967]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[0.87693214 0.8809731  0.8866986  0.89278805 0.89875823 0.90254289\n",
      "  0.90710258 0.91075838]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015804211143404245\n",
      "Predicción post entrenamiento : [[0.9149769]]\n",
      "PERDIDAAAA despues: 0.001578848110511899\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "[[[0.8809731 ]\n",
      "  [0.8866986 ]\n",
      "  [0.89278805]\n",
      "  [0.89875823]\n",
      "  [0.90254289]\n",
      "  [0.90710258]\n",
      "  [0.91075838]\n",
      "  [0.91499668]]]\n",
      "ejemplar: [0.8809731  0.8866986  0.89278805 0.89875823 0.90254289 0.90710258\n",
      " 0.91075838 0.91499668]\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.919645]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[0.8809731  0.8866986  0.89278805 0.89875823 0.90254289 0.90710258\n",
      "  0.91075838 0.91499668]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003920366521924734\n",
      "Predicción post entrenamiento : [[0.9201686]]\n",
      "PERDIDAAAA despues: 0.0039862049743533134\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "[[[0.8866986 ]\n",
      "  [0.89278805]\n",
      "  [0.89875823]\n",
      "  [0.90254289]\n",
      "  [0.90710258]\n",
      "  [0.91075838]\n",
      "  [0.91499668]\n",
      "  [0.91964501]]]\n",
      "ejemplar: [0.8866986  0.89278805 0.89875823 0.90254289 0.90710258 0.91075838\n",
      " 0.91499668 0.91964501]\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.9251125]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[0.8866986  0.89278805 0.89875823 0.90254289 0.90710258 0.91075838\n",
      "  0.91499668 0.91964501]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005633154883980751\n",
      "Predicción post entrenamiento : [[0.92372924]]\n",
      "PERDIDAAAA despues: 0.0054274313151836395\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "[[[0.89278805]\n",
      "  [0.89875823]\n",
      "  [0.90254289]\n",
      "  [0.90710258]\n",
      "  [0.91075838]\n",
      "  [0.91499668]\n",
      "  [0.91964501]\n",
      "  [0.92511249]]]\n",
      "ejemplar: [0.89278805 0.89875823 0.90254289 0.90710258 0.91075838 0.91499668\n",
      " 0.91964501 0.92511249]\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.92843854]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[0.89278805 0.89875823 0.90254289 0.90710258 0.91075838 0.91499668\n",
      "  0.91964501 0.92511249]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007351679727435112\n",
      "Predicción post entrenamiento : [[0.9281517]]\n",
      "PERDIDAAAA despues: 0.00730257760733366\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "[[[0.89875823]\n",
      "  [0.90254289]\n",
      "  [0.90710258]\n",
      "  [0.91075838]\n",
      "  [0.91499668]\n",
      "  [0.91964501]\n",
      "  [0.92511249]\n",
      "  [0.92843854]]]\n",
      "ejemplar: [0.89875823 0.90254289 0.90710258 0.91075838 0.91499668 0.91964501\n",
      " 0.92511249 0.92843854]\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.9324477]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[0.89875823 0.90254289 0.90710258 0.91075838 0.91499668 0.91964501\n",
      "  0.92511249 0.92843854]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011992624029517174\n",
      "Predicción post entrenamiento : [[0.9310712]]\n",
      "PERDIDAAAA despues: 0.011693046428263187\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "[[[0.90254289]\n",
      "  [0.90710258]\n",
      "  [0.91075838]\n",
      "  [0.91499668]\n",
      "  [0.91964501]\n",
      "  [0.92511249]\n",
      "  [0.92843854]\n",
      "  [0.93244767]]]\n",
      "ejemplar: [0.90254289 0.90710258 0.91075838 0.91499668 0.91964501 0.92511249\n",
      " 0.92843854 0.93244767]\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.93490773]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[0.90254289 0.90710258 0.91075838 0.91499668 0.91964501 0.92511249\n",
      "  0.92843854 0.93244767]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.025728706270456314\n",
      "Predicción post entrenamiento : [[0.9346298]]\n",
      "PERDIDAAAA despues: 0.025639619678258896\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "[[[0.90710258]\n",
      "  [0.91075838]\n",
      "  [0.91499668]\n",
      "  [0.91964501]\n",
      "  [0.92511249]\n",
      "  [0.92843854]\n",
      "  [0.93244767]\n",
      "  [0.93490773]]]\n",
      "ejemplar: [0.90710258 0.91075838 0.91499668 0.91964501 0.92511249 0.92843854\n",
      " 0.93244767 0.93490773]\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.93859625]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[0.90710258 0.91075838 0.91499668 0.91964501 0.92511249 0.92843854\n",
      "  0.93244767 0.93490773]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02384062670171261\n",
      "Predicción post entrenamiento : [[0.93821925]]\n",
      "PERDIDAAAA despues: 0.023724349215626717\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "[[[0.91075838]\n",
      "  [0.91499668]\n",
      "  [0.91964501]\n",
      "  [0.92511249]\n",
      "  [0.92843854]\n",
      "  [0.93244767]\n",
      "  [0.93490773]\n",
      "  [0.93859625]]]\n",
      "ejemplar: [0.91075838 0.91499668 0.91964501 0.92511249 0.92843854 0.93244767\n",
      " 0.93490773 0.93859625]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.9420795]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[0.91075838 0.91499668 0.91964501 0.92511249 0.92843854 0.93244767\n",
      "  0.93490773 0.93859625]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006779080722481012\n",
      "Predicción post entrenamiento : [[0.94144356]]\n",
      "PERDIDAAAA despues: 0.006674767937511206\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "[[[0.91499668]\n",
      "  [0.91964501]\n",
      "  [0.92511249]\n",
      "  [0.92843854]\n",
      "  [0.93244767]\n",
      "  [0.93490773]\n",
      "  [0.93859625]\n",
      "  [0.94207948]]]\n",
      "ejemplar: [0.91499668 0.91964501 0.92511249 0.92843854 0.93244767 0.93490773\n",
      " 0.93859625 0.94207948]\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.9454337]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[0.91499668 0.91964501 0.92511249 0.92843854 0.93244767 0.93490773\n",
      "  0.93859625 0.94207948]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008301693014800549\n",
      "Predicción post entrenamiento : [[0.94562614]]\n",
      "PERDIDAAAA despues: 0.008336802013218403\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "[[[0.91964501]\n",
      "  [0.92511249]\n",
      "  [0.92843854]\n",
      "  [0.93244767]\n",
      "  [0.93490773]\n",
      "  [0.93859625]\n",
      "  [0.94207948]\n",
      "  [0.94543368]]]\n",
      "ejemplar: [0.91964501 0.92511249 0.92843854 0.93244767 0.93490773 0.93859625\n",
      " 0.94207948 0.94543368]\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.94955426]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[0.91964501 0.92511249 0.92843854 0.93244767 0.93490773 0.93859625\n",
      "  0.94207948 0.94543368]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01269438210874796\n",
      "Predicción post entrenamiento : [[0.94958264]]\n",
      "PERDIDAAAA despues: 0.012700776569545269\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "[[[0.92511249]\n",
      "  [0.92843854]\n",
      "  [0.93244767]\n",
      "  [0.93490773]\n",
      "  [0.93859625]\n",
      "  [0.94207948]\n",
      "  [0.94543368]\n",
      "  [0.94955426]]]\n",
      "ejemplar: [0.92511249 0.92843854 0.93244767 0.93490773 0.93859625 0.94207948\n",
      " 0.94543368 0.94955426]\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.95328027]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[0.92511249 0.92843854 0.93244767 0.93490773 0.93859625 0.94207948\n",
      "  0.94543368 0.94955426]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015220007859170437\n",
      "Predicción post entrenamiento : [[0.952222]]\n",
      "PERDIDAAAA despues: 0.014960008673369884\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "[[[0.92843854]\n",
      "  [0.93244767]\n",
      "  [0.93490773]\n",
      "  [0.93859625]\n",
      "  [0.94207948]\n",
      "  [0.94543368]\n",
      "  [0.94955426]\n",
      "  [0.95328027]]]\n",
      "ejemplar: [0.92843854 0.93244767 0.93490773 0.93859625 0.94207948 0.94543368\n",
      " 0.94955426 0.95328027]\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.95538193]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[0.92843854 0.93244767 0.93490773 0.93859625 0.94207948 0.94543368\n",
      "  0.94955426 0.95328027]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004641552921384573\n",
      "Predicción post entrenamiento : [[0.95484316]]\n",
      "PERDIDAAAA despues: 0.004568431992083788\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "[[[0.93244767]\n",
      "  [0.93490773]\n",
      "  [0.93859625]\n",
      "  [0.94207948]\n",
      "  [0.94543368]\n",
      "  [0.94955426]\n",
      "  [0.95328027]\n",
      "  [0.95538193]]]\n",
      "ejemplar: [0.93244767 0.93490773 0.93859625 0.94207948 0.94543368 0.94955426\n",
      " 0.95328027 0.95538193]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.9580356]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[0.93244767 0.93490773 0.93859625 0.94207948 0.94543368 0.94955426\n",
      "  0.95328027 0.95538193]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009661175310611725\n",
      "Predicción post entrenamiento : [[0.9566774]]\n",
      "PERDIDAAAA despues: 0.009396019391715527\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "[[[0.93490773]\n",
      "  [0.93859625]\n",
      "  [0.94207948]\n",
      "  [0.94543368]\n",
      "  [0.94955426]\n",
      "  [0.95328027]\n",
      "  [0.95538193]\n",
      "  [0.95803559]]]\n",
      "ejemplar: [0.93490773 0.93859625 0.94207948 0.94543368 0.94955426 0.95328027\n",
      " 0.95538193 0.95803559]\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.9596889]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[0.93490773 0.93859625 0.94207948 0.94543368 0.94955426 0.95328027\n",
      "  0.95538193 0.95803559]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014422053471207619\n",
      "Predicción post entrenamiento : [[0.95892304]]\n",
      "PERDIDAAAA despues: 0.014238692820072174\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "[[[0.93859625]\n",
      "  [0.94207948]\n",
      "  [0.94543368]\n",
      "  [0.94955426]\n",
      "  [0.95328027]\n",
      "  [0.95538193]\n",
      "  [0.95803559]\n",
      "  [0.9596889 ]]]\n",
      "ejemplar: [0.93859625 0.94207948 0.94543368 0.94955426 0.95328027 0.95538193\n",
      " 0.95803559 0.9596889 ]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.962187]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[0.93859625 0.94207948 0.94543368 0.94955426 0.95328027 0.95538193\n",
      "  0.95803559 0.9596889 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03182023763656616\n",
      "Predicción post entrenamiento : [[0.95999664]]\n",
      "PERDIDAAAA despues: 0.03104359470307827\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "[[[0.94207948]\n",
      "  [0.94543368]\n",
      "  [0.94955426]\n",
      "  [0.95328027]\n",
      "  [0.95538193]\n",
      "  [0.95803559]\n",
      "  [0.9596889 ]\n",
      "  [0.96218699]]]\n",
      "ejemplar: [0.94207948 0.94543368 0.94955426 0.95328027 0.95538193 0.95803559\n",
      " 0.9596889  0.96218699]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.9631378]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[0.94207948 0.94543368 0.94955426 0.95328027 0.95538193 0.95803559\n",
      "  0.9596889  0.96218699]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02098161354660988\n",
      "Predicción post entrenamiento : [[0.9636197]]\n",
      "PERDIDAAAA despues: 0.021121453493833542\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "[[[0.94543368]\n",
      "  [0.94955426]\n",
      "  [0.95328027]\n",
      "  [0.95538193]\n",
      "  [0.95803559]\n",
      "  [0.9596889 ]\n",
      "  [0.96218699]\n",
      "  [0.96313781]]]\n",
      "ejemplar: [0.94543368 0.94955426 0.95328027 0.95538193 0.95803559 0.9596889\n",
      " 0.96218699 0.96313781]\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.9666373]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[0.94543368 0.94955426 0.95328027 0.95538193 0.95803559 0.9596889\n",
      "  0.96218699 0.96313781]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.030790116637945175\n",
      "Predicción post entrenamiento : [[0.9652006]]\n",
      "PERDIDAAAA despues: 0.030287977308034897\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "[[[0.94955426]\n",
      "  [0.95328027]\n",
      "  [0.95538193]\n",
      "  [0.95803559]\n",
      "  [0.9596889 ]\n",
      "  [0.96218699]\n",
      "  [0.96313781]\n",
      "  [0.96663731]]]\n",
      "ejemplar: [0.94955426 0.95328027 0.95538193 0.95803559 0.9596889  0.96218699\n",
      " 0.96313781 0.96663731]\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.96806926]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[0.94955426 0.95328027 0.95538193 0.95803559 0.9596889  0.96218699\n",
      "  0.96313781 0.96663731]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.043060943484306335\n",
      "Predicción post entrenamiento : [[0.9668225]]\n",
      "PERDIDAAAA despues: 0.04254506528377533\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "[[[0.95328027]\n",
      "  [0.95538193]\n",
      "  [0.95803559]\n",
      "  [0.9596889 ]\n",
      "  [0.96218699]\n",
      "  [0.96313781]\n",
      "  [0.96663731]\n",
      "  [0.96806926]]]\n",
      "ejemplar: [0.95328027 0.95538193 0.95803559 0.9596889  0.96218699 0.96313781\n",
      " 0.96663731 0.96806926]\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.9692409]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[0.95328027 0.95538193 0.95803559 0.9596889  0.96218699 0.96313781\n",
      "  0.96663731 0.96806926]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03157275170087814\n",
      "Predicción post entrenamiento : [[0.9687073]]\n",
      "PERDIDAAAA despues: 0.031383413821458817\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "[[[0.95538193]\n",
      "  [0.95803559]\n",
      "  [0.9596889 ]\n",
      "  [0.96218699]\n",
      "  [0.96313781]\n",
      "  [0.96663731]\n",
      "  [0.96806926]\n",
      "  [0.9692409 ]]]\n",
      "ejemplar: [0.95538193 0.95803559 0.9596889  0.96218699 0.96313781 0.96663731\n",
      " 0.96806926 0.9692409 ]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9706983]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[0.95538193 0.95803559 0.9596889  0.96218699 0.96313781 0.96663731\n",
      "  0.96806926 0.9692409 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.040805622935295105\n",
      "Predicción post entrenamiento : [[0.96896106]]\n",
      "PERDIDAAAA despues: 0.04010678082704544\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "[[[0.95803559]\n",
      "  [0.9596889 ]\n",
      "  [0.96218699]\n",
      "  [0.96313781]\n",
      "  [0.96663731]\n",
      "  [0.96806926]\n",
      "  [0.9692409 ]\n",
      "  [0.9706983 ]]]\n",
      "ejemplar: [0.95803559 0.9596889  0.96218699 0.96313781 0.96663731 0.96806926\n",
      " 0.9692409  0.9706983 ]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9709387]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[0.95803559 0.9596889  0.96218699 0.96313781 0.96663731 0.96806926\n",
      "  0.9692409  0.9706983 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.040902797132730484\n",
      "Predicción post entrenamiento : [[0.9698175]]\n",
      "PERDIDAAAA despues: 0.0404505580663681\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "[[[0.9596889 ]\n",
      "  [0.96218699]\n",
      "  [0.96313781]\n",
      "  [0.96663731]\n",
      "  [0.96806926]\n",
      "  [0.9692409 ]\n",
      "  [0.9706983 ]\n",
      "  [0.97093868]]]\n",
      "ejemplar: [0.9596889  0.96218699 0.96313781 0.96663731 0.96806926 0.9692409\n",
      " 0.9706983  0.97093868]\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.9715848]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[0.9596889  0.96218699 0.96313781 0.96663731 0.96806926 0.9692409\n",
      "  0.9706983  0.97093868]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.029814807698130608\n",
      "Predicción post entrenamiento : [[0.97117513]]\n",
      "PERDIDAAAA despues: 0.02967350371181965\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "[[[0.96218699]\n",
      "  [0.96313781]\n",
      "  [0.96663731]\n",
      "  [0.96806926]\n",
      "  [0.9692409 ]\n",
      "  [0.9706983 ]\n",
      "  [0.97093868]\n",
      "  [0.9715848 ]]]\n",
      "ejemplar: [0.96218699 0.96313781 0.96663731 0.96806926 0.9692409  0.9706983\n",
      " 0.97093868 0.9715848 ]\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.9729772]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[0.96218699 0.96313781 0.96663731 0.96806926 0.9692409  0.9706983\n",
      "  0.97093868 0.9715848 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0334792360663414\n",
      "Predicción post entrenamiento : [[0.9713114]]\n",
      "PERDIDAAAA despues: 0.032872408628463745\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "[[[0.96313781]\n",
      "  [0.96663731]\n",
      "  [0.96806926]\n",
      "  [0.9692409 ]\n",
      "  [0.9706983 ]\n",
      "  [0.97093868]\n",
      "  [0.9715848 ]\n",
      "  [0.97297722]]]\n",
      "ejemplar: [0.96313781 0.96663731 0.96806926 0.9692409  0.9706983  0.97093868\n",
      " 0.9715848  0.97297722]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.97285795]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[0.96313781 0.96663731 0.96806926 0.9692409  0.9706983  0.97093868\n",
      "  0.9715848  0.97297722]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04523596912622452\n",
      "Predicción post entrenamiento : [[0.9710106]]\n",
      "PERDIDAAAA despues: 0.04445357620716095\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "[[[0.96663731]\n",
      "  [0.96806926]\n",
      "  [0.9692409 ]\n",
      "  [0.9706983 ]\n",
      "  [0.97093868]\n",
      "  [0.9715848 ]\n",
      "  [0.97297722]\n",
      "  [0.97285795]]]\n",
      "ejemplar: [0.96663731 0.96806926 0.9692409  0.9706983  0.97093868 0.9715848\n",
      " 0.97297722 0.97285795]\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.9726988]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[0.96663731 0.96806926 0.9692409  0.9706983  0.97093868 0.9715848\n",
      "  0.97297722 0.97285795]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0825444683432579\n",
      "Predicción post entrenamiento : [[0.96952325]]\n",
      "PERDIDAAAA despues: 0.08072984218597412\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "[[[0.96806926]\n",
      "  [0.9692409 ]\n",
      "  [0.9706983 ]\n",
      "  [0.97093868]\n",
      "  [0.9715848 ]\n",
      "  [0.97297722]\n",
      "  [0.97285795]\n",
      "  [0.97269881]]]\n",
      "ejemplar: [0.96806926 0.9692409  0.9706983  0.97093868 0.9715848  0.97297722\n",
      " 0.97285795 0.97269881]\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.9705421]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[0.96806926 0.9692409  0.9706983  0.97093868 0.9715848  0.97297722\n",
      "  0.97285795 0.97269881]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13348084688186646\n",
      "Predicción post entrenamiento : [[0.9678861]]\n",
      "PERDIDAAAA despues: 0.13154716789722443\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "[[[0.9692409 ]\n",
      "  [0.9706983 ]\n",
      "  [0.97093868]\n",
      "  [0.9715848 ]\n",
      "  [0.97297722]\n",
      "  [0.97285795]\n",
      "  [0.97269881]\n",
      "  [0.97054207]]]\n",
      "ejemplar: [0.9692409  0.9706983  0.97093868 0.9715848  0.97297722 0.97285795\n",
      " 0.97269881 0.97054207]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.96871924]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[0.9692409  0.9706983  0.97093868 0.9715848  0.97297722 0.97285795\n",
      "  0.97269881 0.97054207]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09233130514621735\n",
      "Predicción post entrenamiento : [[0.966817]]\n",
      "PERDIDAAAA despues: 0.09117890149354935\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "[[[0.9706983 ]\n",
      "  [0.97093868]\n",
      "  [0.9715848 ]\n",
      "  [0.97297722]\n",
      "  [0.97285795]\n",
      "  [0.97269881]\n",
      "  [0.97054207]\n",
      "  [0.96871924]]]\n",
      "ejemplar: [0.9706983  0.97093868 0.9715848  0.97297722 0.97285795 0.97269881\n",
      " 0.97054207 0.96871924]\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.96745825]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[0.9706983  0.97093868 0.9715848  0.97297722 0.97285795 0.97269881\n",
      "  0.97054207 0.96871924]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06738856434822083\n",
      "Predicción post entrenamiento : [[0.9655843]]\n",
      "PERDIDAAAA despues: 0.06641913205385208\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "[[[0.97093868]\n",
      "  [0.9715848 ]\n",
      "  [0.97297722]\n",
      "  [0.97285795]\n",
      "  [0.97269881]\n",
      "  [0.97054207]\n",
      "  [0.96871924]\n",
      "  [0.96745825]]]\n",
      "ejemplar: [0.97093868 0.9715848  0.97297722 0.97285795 0.97269881 0.97054207\n",
      " 0.96871924 0.96745825]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9658517]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[0.97093868 0.9715848  0.97297722 0.97285795 0.97269881 0.97054207\n",
      "  0.96871924 0.96745825]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09059686958789825\n",
      "Predicción post entrenamiento : [[0.96358865]]\n",
      "PERDIDAAAA despues: 0.08923965692520142\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "[[[0.9715848 ]\n",
      "  [0.97297722]\n",
      "  [0.97285795]\n",
      "  [0.97269881]\n",
      "  [0.97054207]\n",
      "  [0.96871924]\n",
      "  [0.96745825]\n",
      "  [0.96585172]]]\n",
      "ejemplar: [0.9715848  0.97297722 0.97285795 0.97269881 0.97054207 0.96871924\n",
      " 0.96745825 0.96585172]\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.9637315]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[0.9715848  0.97297722 0.97285795 0.97269881 0.97054207 0.96871924\n",
      "  0.96745825 0.96585172]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06369534134864807\n",
      "Predicción post entrenamiento : [[0.9624214]]\n",
      "PERDIDAAAA despues: 0.0630357638001442\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "[[[0.97297722]\n",
      "  [0.97285795]\n",
      "  [0.97269881]\n",
      "  [0.97054207]\n",
      "  [0.96871924]\n",
      "  [0.96745825]\n",
      "  [0.96585172]\n",
      "  [0.96373153]]]\n",
      "ejemplar: [0.97297722 0.97285795 0.97269881 0.97054207 0.96871924 0.96745825\n",
      " 0.96585172 0.96373153]\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.96222615]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[0.97297722 0.97285795 0.97269881 0.97054207 0.96871924 0.96745825\n",
      "  0.96585172 0.96373153]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08120748400688171\n",
      "Predicción post entrenamiento : [[0.9605717]]\n",
      "PERDIDAAAA despues: 0.0802672877907753\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "[[[0.97285795]\n",
      "  [0.97269881]\n",
      "  [0.97054207]\n",
      "  [0.96871924]\n",
      "  [0.96745825]\n",
      "  [0.96585172]\n",
      "  [0.96373153]\n",
      "  [0.96222615]]]\n",
      "ejemplar: [0.97285795 0.97269881 0.97054207 0.96871924 0.96745825 0.96585172\n",
      " 0.96373153 0.96222615]\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.95969737]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[0.97285795 0.97269881 0.97054207 0.96871924 0.96745825 0.96585172\n",
      "  0.96373153 0.96222615]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0390416644513607\n",
      "Predicción post entrenamiento : [[0.95868915]]\n",
      "PERDIDAAAA despues: 0.038644254207611084\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "[[[0.97269881]\n",
      "  [0.97054207]\n",
      "  [0.96871924]\n",
      "  [0.96745825]\n",
      "  [0.96585172]\n",
      "  [0.96373153]\n",
      "  [0.96222615]\n",
      "  [0.95969737]]]\n",
      "ejemplar: [0.97269881 0.97054207 0.96871924 0.96745825 0.96585172 0.96373153\n",
      " 0.96222615 0.95969737]\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.95745265]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[0.97269881 0.97054207 0.96871924 0.96745825 0.96585172 0.96373153\n",
      "  0.96222615 0.95969737]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022620495408773422\n",
      "Predicción post entrenamiento : [[0.9574934]]\n",
      "PERDIDAAAA despues: 0.022632760927081108\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "[[[0.97054207]\n",
      "  [0.96871924]\n",
      "  [0.96745825]\n",
      "  [0.96585172]\n",
      "  [0.96373153]\n",
      "  [0.96222615]\n",
      "  [0.95969737]\n",
      "  [0.95745265]]]\n",
      "ejemplar: [0.97054207 0.96871924 0.96745825 0.96585172 0.96373153 0.96222615\n",
      " 0.95969737 0.95745265]\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.9558247]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[0.97054207 0.96871924 0.96745825 0.96585172 0.96373153 0.96222615\n",
      "  0.95969737 0.95745265]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019778693094849586\n",
      "Predicción post entrenamiento : [[0.9544773]]\n",
      "PERDIDAAAA despues: 0.019401531666517258\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "[[[0.96871924]\n",
      "  [0.96745825]\n",
      "  [0.96585172]\n",
      "  [0.96373153]\n",
      "  [0.96222615]\n",
      "  [0.95969737]\n",
      "  [0.95745265]\n",
      "  [0.95582467]]]\n",
      "ejemplar: [0.96871924 0.96745825 0.96585172 0.96373153 0.96222615 0.95969737\n",
      " 0.95745265 0.95582467]\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.95291054]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[0.96871924 0.96745825 0.96585172 0.96373153 0.96222615 0.95969737\n",
      "  0.95745265 0.95582467]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002178335562348366\n",
      "Predicción post entrenamiento : [[0.95115876]]\n",
      "PERDIDAAAA despues: 0.0020178838167339563\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "[[[0.96745825]\n",
      "  [0.96585172]\n",
      "  [0.96373153]\n",
      "  [0.96222615]\n",
      "  [0.95969737]\n",
      "  [0.95745265]\n",
      "  [0.95582467]\n",
      "  [0.95291054]]]\n",
      "ejemplar: [0.96745825 0.96585172 0.96373153 0.96222615 0.95969737 0.95745265\n",
      " 0.95582467 0.95291054]\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.94959116]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[0.96745825 0.96585172 0.96373153 0.96222615 0.95969737 0.95745265\n",
      "  0.95582467 0.95291054]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00010230051702819765\n",
      "Predicción post entrenamiento : [[0.95030147]]\n",
      "PERDIDAAAA despues: 8.843640534905717e-05\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "[[[0.96585172]\n",
      "  [0.96373153]\n",
      "  [0.96222615]\n",
      "  [0.95969737]\n",
      "  [0.95745265]\n",
      "  [0.95582467]\n",
      "  [0.95291054]\n",
      "  [0.94959116]]]\n",
      "ejemplar: [0.96585172 0.96373153 0.96222615 0.95969737 0.95745265 0.95582467\n",
      " 0.95291054 0.94959116]\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.9485328]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[0.96585172 0.96373153 0.96222615 0.95969737 0.95745265 0.95582467\n",
      "  0.95291054 0.94959116]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002503373543731868\n",
      "Predicción post entrenamiento : [[0.9485672]]\n",
      "PERDIDAAAA despues: 0.00024925023899413645\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "[[[0.96373153]\n",
      "  [0.96222615]\n",
      "  [0.95969737]\n",
      "  [0.95745265]\n",
      "  [0.95582467]\n",
      "  [0.95291054]\n",
      "  [0.94959116]\n",
      "  [0.94853282]]]\n",
      "ejemplar: [0.96373153 0.96222615 0.95969737 0.95745265 0.95582467 0.95291054\n",
      " 0.94959116 0.94853282]\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.9466555]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[0.96373153 0.96222615 0.95969737 0.95745265 0.95582467 0.95291054\n",
      "  0.94959116 0.94853282]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00343719613738358\n",
      "Predicción post entrenamiento : [[0.94624746]]\n",
      "PERDIDAAAA despues: 0.003389516146853566\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "[[[0.96222615]\n",
      "  [0.95969737]\n",
      "  [0.95745265]\n",
      "  [0.95582467]\n",
      "  [0.95291054]\n",
      "  [0.94959116]\n",
      "  [0.94853282]\n",
      "  [0.94665551]]]\n",
      "ejemplar: [0.96222615 0.95969737 0.95745265 0.95582467 0.95291054 0.94959116\n",
      " 0.94853282 0.94665551]\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.94432104]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[0.96222615 0.95969737 0.95745265 0.95582467 0.95291054 0.94959116\n",
      "  0.94853282 0.94665551]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002667080843821168\n",
      "Predicción post entrenamiento : [[0.94366014]]\n",
      "PERDIDAAAA despues: 0.0025992554146796465\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "[[[0.95969737]\n",
      "  [0.95745265]\n",
      "  [0.95582467]\n",
      "  [0.95291054]\n",
      "  [0.94959116]\n",
      "  [0.94853282]\n",
      "  [0.94665551]\n",
      "  [0.94432104]]]\n",
      "ejemplar: [0.95969737 0.95745265 0.95582467 0.95291054 0.94959116 0.94853282\n",
      " 0.94665551 0.94432104]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.941526]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[0.95969737 0.95745265 0.95582467 0.95291054 0.94959116 0.94853282\n",
      "  0.94665551 0.94432104]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004393544979393482\n",
      "Predicción post entrenamiento : [[0.941119]]\n",
      "PERDIDAAAA despues: 0.0043397583067417145\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "[[[0.95745265]\n",
      "  [0.95582467]\n",
      "  [0.95291054]\n",
      "  [0.94959116]\n",
      "  [0.94853282]\n",
      "  [0.94665551]\n",
      "  [0.94432104]\n",
      "  [0.941526  ]]]\n",
      "ejemplar: [0.95745265 0.95582467 0.95291054 0.94959116 0.94853282 0.94665551\n",
      " 0.94432104 0.941526  ]\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.93905866]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[0.95745265 0.95582467 0.95291054 0.94959116 0.94853282 0.94665551\n",
      "  0.94432104 0.941526  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007783767767250538\n",
      "Predicción post entrenamiento : [[0.9387817]]\n",
      "PERDIDAAAA despues: 0.007734970189630985\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "[[[0.95582467]\n",
      "  [0.95291054]\n",
      "  [0.94959116]\n",
      "  [0.94853282]\n",
      "  [0.94665551]\n",
      "  [0.94432104]\n",
      "  [0.941526  ]\n",
      "  [0.93905866]]]\n",
      "ejemplar: [0.95582467 0.95291054 0.94959116 0.94853282 0.94665551 0.94432104\n",
      " 0.941526   0.93905866]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.9367179]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[0.95582467 0.95291054 0.94959116 0.94853282 0.94665551 0.94432104\n",
      "  0.941526   0.93905866]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007712728343904018\n",
      "Predicción post entrenamiento : [[0.93600464]]\n",
      "PERDIDAAAA despues: 0.007587951608002186\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "[[[0.95291054]\n",
      "  [0.94959116]\n",
      "  [0.94853282]\n",
      "  [0.94665551]\n",
      "  [0.94432104]\n",
      "  [0.941526  ]\n",
      "  [0.93905866]\n",
      "  [0.93671793]]]\n",
      "ejemplar: [0.95291054 0.94959116 0.94853282 0.94665551 0.94432104 0.941526\n",
      " 0.93905866 0.93671793]\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.93374854]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[0.95291054 0.94959116 0.94853282 0.94665551 0.94432104 0.941526\n",
      "  0.93905866 0.93671793]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008219183655455709\n",
      "Predicción post entrenamiento : [[0.93432385]]\n",
      "PERDIDAAAA despues: 0.0007892624125815928\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "[[[0.94959116]\n",
      "  [0.94853282]\n",
      "  [0.94665551]\n",
      "  [0.94432104]\n",
      "  [0.941526  ]\n",
      "  [0.93905866]\n",
      "  [0.93671793]\n",
      "  [0.93374854]]]\n",
      "ejemplar: [0.94959116 0.94853282 0.94665551 0.94432104 0.941526   0.93905866\n",
      " 0.93671793 0.93374854]\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.9322339]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[0.94959116 0.94853282 0.94665551 0.94432104 0.941526   0.93905866\n",
      "  0.93671793 0.93374854]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012679292121902108\n",
      "Predicción post entrenamiento : [[0.9322393]]\n",
      "PERDIDAAAA despues: 0.0012675472535192966\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "[[[0.94853282]\n",
      "  [0.94665551]\n",
      "  [0.94432104]\n",
      "  [0.941526  ]\n",
      "  [0.93905866]\n",
      "  [0.93671793]\n",
      "  [0.93374854]\n",
      "  [0.93223393]]]\n",
      "ejemplar: [0.94853282 0.94665551 0.94432104 0.941526   0.93905866 0.93671793\n",
      " 0.93374854 0.93223393]\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.93045974]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[0.94853282 0.94665551 0.94432104 0.941526   0.93905866 0.93671793\n",
      "  0.93374854 0.93223393]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00010528688289923593\n",
      "Predicción post entrenamiento : [[0.92888796]]\n",
      "PERDIDAAAA despues: 0.00014001312956679612\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "[[[0.94665551]\n",
      "  [0.94432104]\n",
      "  [0.941526  ]\n",
      "  [0.93905866]\n",
      "  [0.93671793]\n",
      "  [0.93374854]\n",
      "  [0.93223393]\n",
      "  [0.93045974]]]\n",
      "ejemplar: [0.94665551 0.94432104 0.941526   0.93905866 0.93671793 0.93374854\n",
      " 0.93223393 0.93045974]\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.9267708]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[0.94665551 0.94432104 0.941526   0.93905866 0.93671793 0.93374854\n",
      "  0.93223393 0.93045974]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0020903602708131075\n",
      "Predicción post entrenamiento : [[0.92750806]]\n",
      "PERDIDAAAA despues: 0.0020234889816492796\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "[[[0.94432104]\n",
      "  [0.941526  ]\n",
      "  [0.93905866]\n",
      "  [0.93671793]\n",
      "  [0.93374854]\n",
      "  [0.93223393]\n",
      "  [0.93045974]\n",
      "  [0.92677081]]]\n",
      "ejemplar: [0.94432104 0.941526   0.93905866 0.93671793 0.93374854 0.93223393\n",
      " 0.93045974 0.92677081]\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.92524153]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[0.94432104 0.941526   0.93905866 0.93671793 0.93374854 0.93223393\n",
      "  0.93045974 0.92677081]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00513499928638339\n",
      "Predicción post entrenamiento : [[0.9258409]]\n",
      "PERDIDAAAA despues: 0.005049455910921097\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "[[[0.941526  ]\n",
      "  [0.93905866]\n",
      "  [0.93671793]\n",
      "  [0.93374854]\n",
      "  [0.93223393]\n",
      "  [0.93045974]\n",
      "  [0.92677081]\n",
      "  [0.92524153]]]\n",
      "ejemplar: [0.941526   0.93905866 0.93671793 0.93374854 0.93223393 0.93045974\n",
      " 0.92677081 0.92524153]\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.92354673]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[0.941526   0.93905866 0.93671793 0.93374854 0.93223393 0.93045974\n",
      "  0.92677081 0.92524153]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007636920199729502\n",
      "Predicción post entrenamiento : [[0.92447865]]\n",
      "PERDIDAAAA despues: 0.0007130533922463655\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "[[[0.93905866]\n",
      "  [0.93671793]\n",
      "  [0.93374854]\n",
      "  [0.93223393]\n",
      "  [0.93045974]\n",
      "  [0.92677081]\n",
      "  [0.92524153]\n",
      "  [0.92354673]]]\n",
      "ejemplar: [0.93905866 0.93671793 0.93374854 0.93223393 0.93045974 0.92677081\n",
      " 0.92524153 0.92354673]\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.9223046]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[0.93905866 0.93671793 0.93374854 0.93223393 0.93045974 0.92677081\n",
      "  0.92524153 0.92354673]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007037221803329885\n",
      "Predicción post entrenamiento : [[0.9223237]]\n",
      "PERDIDAAAA despues: 0.0007047376711852849\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "[[[0.93671793]\n",
      "  [0.93374854]\n",
      "  [0.93223393]\n",
      "  [0.93045974]\n",
      "  [0.92677081]\n",
      "  [0.92524153]\n",
      "  [0.92354673]\n",
      "  [0.92230457]]]\n",
      "ejemplar: [0.93671793 0.93374854 0.93223393 0.93045974 0.92677081 0.92524153\n",
      " 0.92354673 0.92230457]\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.9202052]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[0.93671793 0.93374854 0.93223393 0.93045974 0.92677081 0.92524153\n",
      "  0.92354673 0.92230457]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015026384498924017\n",
      "Predicción post entrenamiento : [[0.9207581]]\n",
      "PERDIDAAAA despues: 0.001545813400298357\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "[[[0.93374854]\n",
      "  [0.93223393]\n",
      "  [0.93045974]\n",
      "  [0.92677081]\n",
      "  [0.92524153]\n",
      "  [0.92354673]\n",
      "  [0.92230457]\n",
      "  [0.92020518]]]\n",
      "ejemplar: [0.93374854 0.93223393 0.93045974 0.92677081 0.92524153 0.92354673\n",
      " 0.92230457 0.92020518]\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.91868204]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[0.93374854 0.93223393 0.93045974 0.92677081 0.92524153 0.92354673\n",
      "  0.92230457 0.92020518]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.5459914922976168e-06\n",
      "Predicción post entrenamiento : [[0.91816616]]\n",
      "PERDIDAAAA despues: 1.1658344192255754e-06\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "[[[0.93223393]\n",
      "  [0.93045974]\n",
      "  [0.92677081]\n",
      "  [0.92524153]\n",
      "  [0.92354673]\n",
      "  [0.92230457]\n",
      "  [0.92020518]\n",
      "  [0.91868204]]]\n",
      "ejemplar: [0.93223393 0.93045974 0.92677081 0.92524153 0.92354673 0.92230457\n",
      " 0.92020518 0.91868204]\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.9163479]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[0.93223393 0.93045974 0.92677081 0.92524153 0.92354673 0.92230457\n",
      "  0.92020518 0.91868204]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.1906861800525803e-05\n",
      "Predicción post entrenamiento : [[0.91586316]]\n",
      "PERDIDAAAA despues: 1.548734690004494e-05\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "[[[0.93045974]\n",
      "  [0.92677081]\n",
      "  [0.92524153]\n",
      "  [0.92354673]\n",
      "  [0.92230457]\n",
      "  [0.92020518]\n",
      "  [0.91868204]\n",
      "  [0.91634792]]]\n",
      "ejemplar: [0.93045974 0.92677081 0.92524153 0.92354673 0.92230457 0.92020518\n",
      " 0.91868204 0.91634792]\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.9139116]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[0.93045974 0.92677081 0.92524153 0.92354673 0.92230457 0.92020518\n",
      "  0.91868204 0.91634792]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002278269501402974\n",
      "Predicción post entrenamiento : [[0.91450113]]\n",
      "PERDIDAAAA despues: 0.0022223370615392923\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "[[[0.92677081]\n",
      "  [0.92524153]\n",
      "  [0.92354673]\n",
      "  [0.92230457]\n",
      "  [0.92020518]\n",
      "  [0.91868204]\n",
      "  [0.91634792]\n",
      "  [0.91391158]]]\n",
      "ejemplar: [0.92677081 0.92524153 0.92354673 0.92230457 0.92020518 0.91868204\n",
      " 0.91634792 0.91391158]\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.91248226]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[0.92677081 0.92524153 0.92354673 0.92230457 0.92020518 0.91868204\n",
      "  0.91634792 0.91391158]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0031077382154762745\n",
      "Predicción post entrenamiento : [[0.9126123]]\n",
      "PERDIDAAAA despues: 0.0030932545196264982\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "[[[0.92524153]\n",
      "  [0.92354673]\n",
      "  [0.92230457]\n",
      "  [0.92020518]\n",
      "  [0.91868204]\n",
      "  [0.91634792]\n",
      "  [0.91391158]\n",
      "  [0.91248226]]]\n",
      "ejemplar: [0.92524153 0.92354673 0.92230457 0.92020518 0.91868204 0.91634792\n",
      " 0.91391158 0.91248226]\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.91110563]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[0.92524153 0.92354673 0.92230457 0.92020518 0.91868204 0.91634792\n",
      "  0.91391158 0.91248226]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002177406568080187\n",
      "Predicción post entrenamiento : [[0.91063464]]\n",
      "PERDIDAAAA despues: 0.0022215840872377157\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "[[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "ejemplar: [0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      " 0.03448276 0.04223169]\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.22132114]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      "  0.03448276 0.04223169]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.030700288712978363\n",
      "Predicción post entrenamiento : [[0.18630919]]\n",
      "PERDIDAAAA despues: 0.019656889140605927\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "[[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22132114]]]\n",
      "ejemplar: [0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      " 0.04223169 0.22132114]\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.17030942]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      "  0.04223169 0.22132114]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004367392975836992\n",
      "Predicción post entrenamiento : [[0.16660216]]\n",
      "PERDIDAAAA despues: 0.00389113905839622\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "[[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22132114]\n",
      "  [0.17030942]]]\n",
      "ejemplar: [0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      " 0.22132114 0.17030942]\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.1703623]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      "  0.22132114 0.17030942]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002610968367662281\n",
      "Predicción post entrenamiento : [[0.16609205]]\n",
      "PERDIDAAAA despues: 0.00014133049990050495\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "[[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22132114]\n",
      "  [0.17030942]\n",
      "  [0.17036229]]]\n",
      "ejemplar: [0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.22132114\n",
      " 0.17030942 0.17036229]\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.17707565]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.22132114\n",
      "  0.17030942 0.17036229]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000454630731837824\n",
      "Predicción post entrenamiento : [[0.1758906]]\n",
      "PERDIDAAAA despues: 0.00040549924597144127\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "[[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22132114]\n",
      "  [0.17030942]\n",
      "  [0.17036229]\n",
      "  [0.17707565]]]\n",
      "ejemplar: [0.05656722 0.02595893 0.03448276 0.04223169 0.22132114 0.17030942\n",
      " 0.17036229 0.17707565]\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.18766575]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[0.05656722 0.02595893 0.03448276 0.04223169 0.22132114 0.17030942\n",
      "  0.17036229 0.17707565]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0038605094887316227\n",
      "Predicción post entrenamiento : [[0.18195511]]\n",
      "PERDIDAAAA despues: 0.003183483611792326\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "[[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22132114]\n",
      "  [0.17030942]\n",
      "  [0.17036229]\n",
      "  [0.17707565]\n",
      "  [0.18766575]]]\n",
      "ejemplar: [0.02595893 0.03448276 0.04223169 0.22132114 0.17030942 0.17036229\n",
      " 0.17707565 0.18766575]\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.19045867]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[0.02595893 0.03448276 0.04223169 0.22132114 0.17030942 0.17036229\n",
      "  0.17707565 0.18766575]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002005132380872965\n",
      "Predicción post entrenamiento : [[0.18613186]]\n",
      "PERDIDAAAA despues: 0.0016363561153411865\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "[[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.22132114]\n",
      "  [0.17030942]\n",
      "  [0.17036229]\n",
      "  [0.17707565]\n",
      "  [0.18766575]\n",
      "  [0.19045867]]]\n",
      "ejemplar: [0.03448276 0.04223169 0.22132114 0.17030942 0.17036229 0.17707565\n",
      " 0.18766575 0.19045867]\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.20533049]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[0.03448276 0.04223169 0.22132114 0.17030942 0.17036229 0.17707565\n",
      "  0.18766575 0.19045867]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0034663404803723097\n",
      "Predicción post entrenamiento : [[0.2030843]]\n",
      "PERDIDAAAA despues: 0.003206894500181079\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "[[[0.04223169]\n",
      "  [0.22132114]\n",
      "  [0.17030942]\n",
      "  [0.17036229]\n",
      "  [0.17707565]\n",
      "  [0.18766575]\n",
      "  [0.19045867]\n",
      "  [0.20533049]]]\n",
      "ejemplar: [0.04223169 0.22132114 0.17030942 0.17036229 0.17707565 0.18766575\n",
      " 0.19045867 0.20533049]\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.22629161]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[0.04223169 0.22132114 0.17030942 0.17036229 0.17707565 0.18766575\n",
      "  0.19045867 0.20533049]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009146738448180258\n",
      "Predicción post entrenamiento : [[0.22364837]]\n",
      "PERDIDAAAA despues: 0.0007617783849127591\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "[[[0.22132114]\n",
      "  [0.17030942]\n",
      "  [0.17036229]\n",
      "  [0.17707565]\n",
      "  [0.18766575]\n",
      "  [0.19045867]\n",
      "  [0.20533049]\n",
      "  [0.22629161]]]\n",
      "ejemplar: [0.22132114 0.17030942 0.17036229 0.17707565 0.18766575 0.19045867\n",
      " 0.20533049 0.22629161]\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.2511886]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[0.22132114 0.17030942 0.17036229 0.17707565 0.18766575 0.19045867\n",
      "  0.20533049 0.22629161]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004267450131010264\n",
      "Predicción post entrenamiento : [[0.25002903]]\n",
      "PERDIDAAAA despues: 0.00038018092163838446\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "[[[0.17030942]\n",
      "  [0.17036229]\n",
      "  [0.17707565]\n",
      "  [0.18766575]\n",
      "  [0.19045867]\n",
      "  [0.20533049]\n",
      "  [0.22629161]\n",
      "  [0.25118861]]]\n",
      "ejemplar: [0.17030942 0.17036229 0.17707565 0.18766575 0.19045867 0.20533049\n",
      " 0.22629161 0.25118861]\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.24312218]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[0.17030942 0.17036229 0.17707565 0.18766575 0.19045867 0.20533049\n",
      "  0.22629161 0.25118861]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012024136958643794\n",
      "Predicción post entrenamiento : [[0.24161366]]\n",
      "PERDIDAAAA despues: 0.00110007100738585\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "[[[0.17036229]\n",
      "  [0.17707565]\n",
      "  [0.18766575]\n",
      "  [0.19045867]\n",
      "  [0.20533049]\n",
      "  [0.22629161]\n",
      "  [0.25118861]\n",
      "  [0.24312218]]]\n",
      "ejemplar: [0.17036229 0.17707565 0.18766575 0.19045867 0.20533049 0.22629161\n",
      " 0.25118861 0.24312218]\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.24604495]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[0.17036229 0.17707565 0.18766575 0.19045867 0.20533049 0.22629161\n",
      "  0.25118861 0.24312218]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0011636004783213139\n",
      "Predicción post entrenamiento : [[0.24542052]]\n",
      "PERDIDAAAA despues: 0.0011213895631954074\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "[[[0.17707565]\n",
      "  [0.18766575]\n",
      "  [0.19045867]\n",
      "  [0.20533049]\n",
      "  [0.22629161]\n",
      "  [0.25118861]\n",
      "  [0.24312218]\n",
      "  [0.24604495]]]\n",
      "ejemplar: [0.17707565 0.18766575 0.19045867 0.20533049 0.22629161 0.25118861\n",
      " 0.24312218 0.24604495]\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.2518909]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[0.17707565 0.18766575 0.19045867 0.20533049 0.22629161 0.25118861\n",
      "  0.24312218 0.24604495]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0019897751044481993\n",
      "Predicción post entrenamiento : [[0.2495747]]\n",
      "PERDIDAAAA despues: 0.0017885034903883934\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "[[[0.18766575]\n",
      "  [0.19045867]\n",
      "  [0.20533049]\n",
      "  [0.22629161]\n",
      "  [0.25118861]\n",
      "  [0.24312218]\n",
      "  [0.24604495]\n",
      "  [0.2518909 ]]]\n",
      "ejemplar: [0.18766575 0.19045867 0.20533049 0.22629161 0.25118861 0.24312218\n",
      " 0.24604495 0.2518909 ]\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.25691548]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[0.18766575 0.19045867 0.20533049 0.22629161 0.25118861 0.24312218\n",
      "  0.24604495 0.2518909 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004091777838766575\n",
      "Predicción post entrenamiento : [[0.2524914]]\n",
      "PERDIDAAAA despues: 0.0035453615710139275\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "[[[0.19045867]\n",
      "  [0.20533049]\n",
      "  [0.22629161]\n",
      "  [0.25118861]\n",
      "  [0.24312218]\n",
      "  [0.24604495]\n",
      "  [0.2518909 ]\n",
      "  [0.25691548]]]\n",
      "ejemplar: [0.19045867 0.20533049 0.22629161 0.25118861 0.24312218 0.24604495\n",
      " 0.2518909  0.25691548]\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.2598466]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[0.19045867 0.20533049 0.22629161 0.25118861 0.24312218 0.24604495\n",
      "  0.2518909  0.25691548]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0039719813503324986\n",
      "Predicción post entrenamiento : [[0.25930715]]\n",
      "PERDIDAAAA despues: 0.003904275828972459\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "[[[0.20533049]\n",
      "  [0.22629161]\n",
      "  [0.25118861]\n",
      "  [0.24312218]\n",
      "  [0.24604495]\n",
      "  [0.2518909 ]\n",
      "  [0.25691548]\n",
      "  [0.2598466 ]]]\n",
      "ejemplar: [0.20533049 0.22629161 0.25118861 0.24312218 0.24604495 0.2518909\n",
      " 0.25691548 0.2598466 ]\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.26829982]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[0.20533049 0.22629161 0.25118861 0.24312218 0.24604495 0.2518909\n",
      "  0.25691548 0.2598466 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029205132741481066\n",
      "Predicción post entrenamiento : [[0.26526892]]\n",
      "PERDIDAAAA despues: 0.0026021094527095556\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "[[[0.22629161]\n",
      "  [0.25118861]\n",
      "  [0.24312218]\n",
      "  [0.24604495]\n",
      "  [0.2518909 ]\n",
      "  [0.25691548]\n",
      "  [0.2598466 ]\n",
      "  [0.26829982]]]\n",
      "ejemplar: [0.22629161 0.25118861 0.24312218 0.24604495 0.2518909  0.25691548\n",
      " 0.2598466  0.26829982]\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.27318117]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[0.22629161 0.25118861 0.24312218 0.24604495 0.2518909  0.25691548\n",
      "  0.2598466  0.26829982]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008437544107437134\n",
      "Predicción post entrenamiento : [[0.26991802]]\n",
      "PERDIDAAAA despues: 0.007848712615668774\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "[[[0.25118861]\n",
      "  [0.24312218]\n",
      "  [0.24604495]\n",
      "  [0.2518909 ]\n",
      "  [0.25691548]\n",
      "  [0.2598466 ]\n",
      "  [0.26829982]\n",
      "  [0.27318117]]]\n",
      "ejemplar: [0.25118861 0.24312218 0.24604495 0.2518909  0.25691548 0.2598466\n",
      " 0.26829982 0.27318117]\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.27493718]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[0.25118861 0.24312218 0.24604495 0.2518909  0.25691548 0.2598466\n",
      "  0.26829982 0.27318117]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009962286800146103\n",
      "Predicción post entrenamiento : [[0.27273908]]\n",
      "PERDIDAAAA despues: 0.009528327733278275\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "[[[0.24312218]\n",
      "  [0.24604495]\n",
      "  [0.2518909 ]\n",
      "  [0.25691548]\n",
      "  [0.2598466 ]\n",
      "  [0.26829982]\n",
      "  [0.27318117]\n",
      "  [0.27493718]]]\n",
      "ejemplar: [0.24312218 0.24604495 0.2518909  0.25691548 0.2598466  0.26829982\n",
      " 0.27318117 0.27493718]\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.27334905]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[0.24312218 0.24604495 0.2518909  0.25691548 0.2598466  0.26829982\n",
      "  0.27318117 0.27493718]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015711218118667603\n",
      "Predicción post entrenamiento : [[0.26975194]]\n",
      "PERDIDAAAA despues: 0.014822401106357574\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "[[[0.24604495]\n",
      "  [0.2518909 ]\n",
      "  [0.25691548]\n",
      "  [0.2598466 ]\n",
      "  [0.26829982]\n",
      "  [0.27318117]\n",
      "  [0.27493718]\n",
      "  [0.27334905]]]\n",
      "ejemplar: [0.24604495 0.2518909  0.25691548 0.2598466  0.26829982 0.27318117\n",
      " 0.27493718 0.27334905]\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.2728334]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[0.24604495 0.2518909  0.25691548 0.2598466  0.26829982 0.27318117\n",
      "  0.27493718 0.27334905]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012991497293114662\n",
      "Predicción post entrenamiento : [[0.26916617]]\n",
      "PERDIDAAAA despues: 0.012168960645794868\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "[[[0.2518909 ]\n",
      "  [0.25691548]\n",
      "  [0.2598466 ]\n",
      "  [0.26829982]\n",
      "  [0.27318117]\n",
      "  [0.27493718]\n",
      "  [0.27334905]\n",
      "  [0.27283341]]]\n",
      "ejemplar: [0.2518909  0.25691548 0.2598466  0.26829982 0.27318117 0.27493718\n",
      " 0.27334905 0.27283341]\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.2725625]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[0.2518909  0.25691548 0.2598466  0.26829982 0.27318117 0.27493718\n",
      "  0.27334905 0.27283341]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00646238075569272\n",
      "Predicción post entrenamiento : [[0.27079946]]\n",
      "PERDIDAAAA despues: 0.006182030308991671\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "[[[0.25691548]\n",
      "  [0.2598466 ]\n",
      "  [0.26829982]\n",
      "  [0.27318117]\n",
      "  [0.27493718]\n",
      "  [0.27334905]\n",
      "  [0.27283341]\n",
      "  [0.2725625 ]]]\n",
      "ejemplar: [0.25691548 0.2598466  0.26829982 0.27318117 0.27493718 0.27334905\n",
      " 0.27283341 0.2725625 ]\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.27378818]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[0.25691548 0.2598466  0.26829982 0.27318117 0.27493718 0.27334905\n",
      "  0.27283341 0.2725625 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007711254525929689\n",
      "Predicción post entrenamiento : [[0.27053267]]\n",
      "PERDIDAAAA despues: 0.007150094956159592\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "[[[0.2598466 ]\n",
      "  [0.26829982]\n",
      "  [0.27318117]\n",
      "  [0.27493718]\n",
      "  [0.27334905]\n",
      "  [0.27283341]\n",
      "  [0.2725625 ]\n",
      "  [0.27378818]]]\n",
      "ejemplar: [0.2598466  0.26829982 0.27318117 0.27493718 0.27334905 0.27283341\n",
      " 0.2725625  0.27378818]\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.2731209]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[0.2598466  0.26829982 0.27318117 0.27493718 0.27334905 0.27283341\n",
      "  0.2725625  0.27378818]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.807042958214879e-05\n",
      "Predicción post entrenamiento : [[0.27263004]]\n",
      "PERDIDAAAA despues: 3.225387627026066e-05\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "[[[0.26829982]\n",
      "  [0.27318117]\n",
      "  [0.27493718]\n",
      "  [0.27334905]\n",
      "  [0.27283341]\n",
      "  [0.2725625 ]\n",
      "  [0.27378818]\n",
      "  [0.27312091]]]\n",
      "ejemplar: [0.26829982 0.27318117 0.27493718 0.27334905 0.27283341 0.2725625\n",
      " 0.27378818 0.27312091]\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.27513096]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[0.26829982 0.27318117 0.27493718 0.27334905 0.27283341 0.2725625\n",
      "  0.27378818 0.27312091]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003024581528734416\n",
      "Predicción post entrenamiento : [[0.2748359]]\n",
      "PERDIDAAAA despues: 0.0003128075913991779\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "[[[0.27318117]\n",
      "  [0.27493718]\n",
      "  [0.27334905]\n",
      "  [0.27283341]\n",
      "  [0.2725625 ]\n",
      "  [0.27378818]\n",
      "  [0.27312091]\n",
      "  [0.27513096]]]\n",
      "ejemplar: [0.27318117 0.27493718 0.27334905 0.27283341 0.2725625  0.27378818\n",
      " 0.27312091 0.27513096]\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.27586043]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[0.27318117 0.27493718 0.27334905 0.27283341 0.2725625  0.27378818\n",
      "  0.27312091 0.27513096]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017510782927274704\n",
      "Predicción post entrenamiento : [[0.2770308]]\n",
      "PERDIDAAAA despues: 0.0016544980462640524\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "[[[0.27493718]\n",
      "  [0.27334905]\n",
      "  [0.27283341]\n",
      "  [0.2725625 ]\n",
      "  [0.27378818]\n",
      "  [0.27312091]\n",
      "  [0.27513096]\n",
      "  [0.27586043]]]\n",
      "ejemplar: [0.27493718 0.27334905 0.27283341 0.2725625  0.27378818 0.27312091\n",
      " 0.27513096 0.27586043]\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.27711752]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[0.27493718 0.27334905 0.27283341 0.2725625  0.27378818 0.27312091\n",
      "  0.27513096 0.27586043]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0012639443157240748\n",
      "Predicción post entrenamiento : [[0.27751184]]\n",
      "PERDIDAAAA despues: 0.0012360624969005585\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "[[[0.27334905]\n",
      "  [0.27283341]\n",
      "  [0.2725625 ]\n",
      "  [0.27378818]\n",
      "  [0.27312091]\n",
      "  [0.27513096]\n",
      "  [0.27586043]\n",
      "  [0.27711752]]]\n",
      "ejemplar: [0.27334905 0.27283341 0.2725625  0.27378818 0.27312091 0.27513096\n",
      " 0.27586043 0.27711752]\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.2772391]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[0.27334905 0.27283341 0.2725625  0.27378818 0.27312091 0.27513096\n",
      "  0.27586043 0.27711752]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00013914908049628139\n",
      "Predicción post entrenamiento : [[0.27722043]]\n",
      "PERDIDAAAA despues: 0.000139590265462175\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "[[[0.27283341]\n",
      "  [0.2725625 ]\n",
      "  [0.27378818]\n",
      "  [0.27312091]\n",
      "  [0.27513096]\n",
      "  [0.27586043]\n",
      "  [0.27711752]\n",
      "  [0.27723911]]]\n",
      "ejemplar: [0.27283341 0.2725625  0.27378818 0.27312091 0.27513096 0.27586043\n",
      " 0.27711752 0.27723911]\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.27733365]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[0.27283341 0.2725625  0.27378818 0.27312091 0.27513096 0.27586043\n",
      "  0.27711752 0.27723911]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 3.027709317393601e-05\n",
      "Predicción post entrenamiento : [[0.2776593]]\n",
      "PERDIDAAAA despues: 2.6799387342180125e-05\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "[[[0.2725625 ]\n",
      "  [0.27378818]\n",
      "  [0.27312091]\n",
      "  [0.27513096]\n",
      "  [0.27586043]\n",
      "  [0.27711752]\n",
      "  [0.27723911]\n",
      "  [0.27733365]]]\n",
      "ejemplar: [0.2725625  0.27378818 0.27312091 0.27513096 0.27586043 0.27711752\n",
      " 0.27723911 0.27733365]\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.27799144]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[0.2725625  0.27378818 0.27312091 0.27513096 0.27586043 0.27711752\n",
      "  0.27723911 0.27733365]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00046245980774983764\n",
      "Predicción post entrenamiento : [[0.27745906]]\n",
      "PERDIDAAAA despues: 0.0004856411542277783\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "[[[0.27378818]\n",
      "  [0.27312091]\n",
      "  [0.27513096]\n",
      "  [0.27586043]\n",
      "  [0.27711752]\n",
      "  [0.27723911]\n",
      "  [0.27733365]\n",
      "  [0.27799144]]]\n",
      "ejemplar: [0.27378818 0.27312091 0.27513096 0.27586043 0.27711752 0.27723911\n",
      " 0.27733365 0.27799144]\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.27799475]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[0.27378818 0.27312091 0.27513096 0.27586043 0.27711752 0.27723911\n",
      "  0.27733365 0.27799144]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 4.5483411668101326e-06\n",
      "Predicción post entrenamiento : [[0.27810177]]\n",
      "PERDIDAAAA despues: 5.016274371882901e-06\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "[[[0.27312091]\n",
      "  [0.27513096]\n",
      "  [0.27586043]\n",
      "  [0.27711752]\n",
      "  [0.27723911]\n",
      "  [0.27733365]\n",
      "  [0.27799144]\n",
      "  [0.27799475]]]\n",
      "ejemplar: [0.27312091 0.27513096 0.27586043 0.27711752 0.27723911 0.27733365\n",
      " 0.27799144 0.27799475]\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.27852073]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[0.27312091 0.27513096 0.27586043 0.27711752 0.27723911 0.27733365\n",
      "  0.27799144 0.27799475]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.4600158465327695e-05\n",
      "Predicción post entrenamiento : [[0.2786438]]\n",
      "PERDIDAAAA despues: 1.5555680874967948e-05\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "[[[0.27513096]\n",
      "  [0.27586043]\n",
      "  [0.27711752]\n",
      "  [0.27723911]\n",
      "  [0.27733365]\n",
      "  [0.27799144]\n",
      "  [0.27799475]\n",
      "  [0.27852073]]]\n",
      "ejemplar: [0.27513096 0.27586043 0.27711752 0.27723911 0.27733365 0.27799144\n",
      " 0.27799475 0.27852073]\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.27935803]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[0.27513096 0.27586043 0.27711752 0.27723911 0.27733365 0.27799144\n",
      "  0.27799475 0.27852073]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.5080961929925252e-05\n",
      "Predicción post entrenamiento : [[0.27980512]]\n",
      "PERDIDAAAA despues: 1.8753367839963175e-05\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "[[[0.27586043]\n",
      "  [0.27711752]\n",
      "  [0.27723911]\n",
      "  [0.27733365]\n",
      "  [0.27799144]\n",
      "  [0.27799475]\n",
      "  [0.27852073]\n",
      "  [0.27935803]]]\n",
      "ejemplar: [0.27586043 0.27711752 0.27723911 0.27733365 0.27799144 0.27799475\n",
      " 0.27852073 0.27935803]\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.28022802]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[0.27586043 0.27711752 0.27723911 0.27733365 0.27799144 0.27799475\n",
      "  0.27852073 0.27935803]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029730782844126225\n",
      "Predicción post entrenamiento : [[0.2813752]]\n",
      "PERDIDAAAA despues: 0.0028492920100688934\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "[[[0.27711752]\n",
      "  [0.27723911]\n",
      "  [0.27733365]\n",
      "  [0.27799144]\n",
      "  [0.27799475]\n",
      "  [0.27852073]\n",
      "  [0.27935803]\n",
      "  [0.28022802]]]\n",
      "ejemplar: [0.27711752 0.27723911 0.27733365 0.27799144 0.27799475 0.27852073\n",
      " 0.27935803 0.28022802]\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.28175095]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[0.27711752 0.27723911 0.27733365 0.27799144 0.27799475 0.27852073\n",
      "  0.27935803 0.28022802]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005464925896376371\n",
      "Predicción post entrenamiento : [[0.28261945]]\n",
      "PERDIDAAAA despues: 0.005337272305041552\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "[[[0.27723911]\n",
      "  [0.27733365]\n",
      "  [0.27799144]\n",
      "  [0.27799475]\n",
      "  [0.27852073]\n",
      "  [0.27935803]\n",
      "  [0.28022802]\n",
      "  [0.28175095]]]\n",
      "ejemplar: [0.27723911 0.27733365 0.27799144 0.27799475 0.27852073 0.27935803\n",
      " 0.28022802 0.28175095]\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.28282312]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[0.27723911 0.27733365 0.27799144 0.27799475 0.27852073 0.27935803\n",
      "  0.28022802 0.28175095]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029017706401646137\n",
      "Predicción post entrenamiento : [[0.28343529]]\n",
      "PERDIDAAAA despues: 0.0028361924923956394\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "[[[0.27733365]\n",
      "  [0.27799144]\n",
      "  [0.27799475]\n",
      "  [0.27852073]\n",
      "  [0.27935803]\n",
      "  [0.28022802]\n",
      "  [0.28175095]\n",
      "  [0.28282312]]]\n",
      "ejemplar: [0.27733365 0.27799144 0.27799475 0.27852073 0.27935803 0.28022802\n",
      " 0.28175095 0.28282312]\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.28371847]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[0.27733365 0.27799144 0.27799475 0.27852073 0.27935803 0.28022802\n",
      "  0.28175095 0.28282312]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0024873334914445877\n",
      "Predicción post entrenamiento : [[0.2832756]]\n",
      "PERDIDAAAA despues: 0.0025317035615444183\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "[[[0.27799144]\n",
      "  [0.27799475]\n",
      "  [0.27852073]\n",
      "  [0.27935803]\n",
      "  [0.28022802]\n",
      "  [0.28175095]\n",
      "  [0.28282312]\n",
      "  [0.28371847]]]\n",
      "ejemplar: [0.27799144 0.27799475 0.27852073 0.27935803 0.28022802 0.28175095\n",
      " 0.28282312 0.28371847]\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.28367487]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[0.27799144 0.27799475 0.27852073 0.27935803 0.28022802 0.28175095\n",
      "  0.28282312 0.28371847]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01021306961774826\n",
      "Predicción post entrenamiento : [[0.2845174]]\n",
      "PERDIDAAAA despues: 0.010043486021459103\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "[[[0.27799475]\n",
      "  [0.27852073]\n",
      "  [0.27935803]\n",
      "  [0.28022802]\n",
      "  [0.28175095]\n",
      "  [0.28282312]\n",
      "  [0.28371847]\n",
      "  [0.28367487]]]\n",
      "ejemplar: [0.27799475 0.27852073 0.27935803 0.28022802 0.28175095 0.28282312\n",
      " 0.28371847 0.28367487]\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.28493056]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[0.27799475 0.27852073 0.27935803 0.28022802 0.28175095 0.28282312\n",
      "  0.28371847 0.28367487]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08189093321561813\n",
      "Predicción post entrenamiento : [[0.2888774]]\n",
      "PERDIDAAAA despues: 0.07964760810136795\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "[[[0.27852073]\n",
      "  [0.27935803]\n",
      "  [0.28022802]\n",
      "  [0.28175095]\n",
      "  [0.28282312]\n",
      "  [0.28371847]\n",
      "  [0.28367487]\n",
      "  [0.28493056]]]\n",
      "ejemplar: [0.27852073 0.27935803 0.28022802 0.28175095 0.28282312 0.28371847\n",
      " 0.28367487 0.28493056]\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.2894674]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[0.27852073 0.27935803 0.28022802 0.28175095 0.28282312 0.28371847\n",
      "  0.28367487 0.28493056]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09413429349660873\n",
      "Predicción post entrenamiento : [[0.29354095]]\n",
      "PERDIDAAAA despues: 0.09165123850107193\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "[[[0.27935803]\n",
      "  [0.28022802]\n",
      "  [0.28175095]\n",
      "  [0.28282312]\n",
      "  [0.28371847]\n",
      "  [0.28367487]\n",
      "  [0.28493056]\n",
      "  [0.28946739]]]\n",
      "ejemplar: [0.27935803 0.28022802 0.28175095 0.28282312 0.28371847 0.28367487\n",
      " 0.28493056 0.28946739]\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.29423383]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[0.27935803 0.28022802 0.28175095 0.28282312 0.28371847 0.28367487\n",
      "  0.28493056 0.28946739]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07859592139720917\n",
      "Predicción post entrenamiento : [[0.29790923]]\n",
      "PERDIDAAAA despues: 0.07654863595962524\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "[[[0.28022802]\n",
      "  [0.28175095]\n",
      "  [0.28282312]\n",
      "  [0.28371847]\n",
      "  [0.28367487]\n",
      "  [0.28493056]\n",
      "  [0.28946739]\n",
      "  [0.29423383]]]\n",
      "ejemplar: [0.28022802 0.28175095 0.28282312 0.28371847 0.28367487 0.28493056\n",
      " 0.28946739 0.29423383]\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.298686]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[0.28022802 0.28175095 0.28282312 0.28371847 0.28367487 0.28493056\n",
      "  0.28946739 0.29423383]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09465967118740082\n",
      "Predicción post entrenamiento : [[0.30272445]]\n",
      "PERDIDAAAA despues: 0.09219097346067429\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "[[[0.28175095]\n",
      "  [0.28282312]\n",
      "  [0.28371847]\n",
      "  [0.28367487]\n",
      "  [0.28493056]\n",
      "  [0.28946739]\n",
      "  [0.29423383]\n",
      "  [0.298686  ]]]\n",
      "ejemplar: [0.28175095 0.28282312 0.28371847 0.28367487 0.28493056 0.28946739\n",
      " 0.29423383 0.298686  ]\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.30364752]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[0.28175095 0.28282312 0.28371847 0.28367487 0.28493056 0.28946739\n",
      "  0.29423383 0.298686  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0789664015173912\n",
      "Predicción post entrenamiento : [[0.3072225]]\n",
      "PERDIDAAAA despues: 0.07696998119354248\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "[[[0.28282312]\n",
      "  [0.28371847]\n",
      "  [0.28367487]\n",
      "  [0.28493056]\n",
      "  [0.28946739]\n",
      "  [0.29423383]\n",
      "  [0.298686  ]\n",
      "  [0.30364752]]]\n",
      "ejemplar: [0.28282312 0.28371847 0.28367487 0.28493056 0.28946739 0.29423383\n",
      " 0.298686   0.30364752]\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.30823424]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[0.28282312 0.28371847 0.28367487 0.28493056 0.28946739 0.29423383\n",
      "  0.298686   0.30364752]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0678798034787178\n",
      "Predicción post entrenamiento : [[0.3113073]]\n",
      "PERDIDAAAA despues: 0.06628794968128204\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "[[[0.28371847]\n",
      "  [0.28367487]\n",
      "  [0.28493056]\n",
      "  [0.28946739]\n",
      "  [0.29423383]\n",
      "  [0.298686  ]\n",
      "  [0.30364752]\n",
      "  [0.30823424]]]\n",
      "ejemplar: [0.28371847 0.28367487 0.28493056 0.28946739 0.29423383 0.298686\n",
      " 0.30364752 0.30823424]\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.31261098]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[0.28371847 0.28367487 0.28493056 0.28946739 0.29423383 0.298686\n",
      "  0.30364752 0.30823424]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10900768637657166\n",
      "Predicción post entrenamiento : [[0.31661057]]\n",
      "PERDIDAAAA despues: 0.10638264566659927\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "[[[0.28367487]\n",
      "  [0.28493056]\n",
      "  [0.28946739]\n",
      "  [0.29423383]\n",
      "  [0.298686  ]\n",
      "  [0.30364752]\n",
      "  [0.30823424]\n",
      "  [0.31261098]]]\n",
      "ejemplar: [0.28367487 0.28493056 0.28946739 0.29423383 0.298686   0.30364752\n",
      " 0.30823424 0.31261098]\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.3183775]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[0.28367487 0.28493056 0.28946739 0.29423383 0.298686   0.30364752\n",
      "  0.30823424 0.31261098]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11791086941957474\n",
      "Predicción post entrenamiento : [[0.32234854]]\n",
      "PERDIDAAAA despues: 0.11519947648048401\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "[[[0.28493056]\n",
      "  [0.28946739]\n",
      "  [0.29423383]\n",
      "  [0.298686  ]\n",
      "  [0.30364752]\n",
      "  [0.30823424]\n",
      "  [0.31261098]\n",
      "  [0.31837749]]]\n",
      "ejemplar: [0.28493056 0.28946739 0.29423383 0.298686   0.30364752 0.30823424\n",
      " 0.31261098 0.31837749]\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.32495135]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[0.28493056 0.28946739 0.29423383 0.298686   0.30364752 0.30823424\n",
      "  0.31261098 0.31837749]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12113436311483383\n",
      "Predicción post entrenamiento : [[0.3290464]]\n",
      "PERDIDAAAA despues: 0.11830062419176102\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "[[[0.28946739]\n",
      "  [0.29423383]\n",
      "  [0.298686  ]\n",
      "  [0.30364752]\n",
      "  [0.30823424]\n",
      "  [0.31261098]\n",
      "  [0.31837749]\n",
      "  [0.32495135]]]\n",
      "ejemplar: [0.28946739 0.29423383 0.298686   0.30364752 0.30823424 0.31261098\n",
      " 0.31837749 0.32495135]\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.3323702]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[0.28946739 0.29423383 0.298686   0.30364752 0.30823424 0.31261098\n",
      "  0.31837749 0.32495135]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14304062724113464\n",
      "Predicción post entrenamiento : [[0.3366322]]\n",
      "PERDIDAAAA despues: 0.1398349553346634\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "[[[0.29423383]\n",
      "  [0.298686  ]\n",
      "  [0.30364752]\n",
      "  [0.30823424]\n",
      "  [0.31261098]\n",
      "  [0.31837749]\n",
      "  [0.32495135]\n",
      "  [0.33237019]]]\n",
      "ejemplar: [0.29423383 0.298686   0.30364752 0.30823424 0.31261098 0.31837749\n",
      " 0.32495135 0.33237019]\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.3400521]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[0.29423383 0.298686   0.30364752 0.30823424 0.31261098 0.31837749\n",
      "  0.32495135 0.33237019]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.13245131075382233\n",
      "Predicción post entrenamiento : [[0.34403276]]\n",
      "PERDIDAAAA despues: 0.12956970930099487\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "[[[0.298686  ]\n",
      "  [0.30364752]\n",
      "  [0.30823424]\n",
      "  [0.31261098]\n",
      "  [0.31837749]\n",
      "  [0.32495135]\n",
      "  [0.33237019]\n",
      "  [0.3400521 ]]]\n",
      "ejemplar: [0.298686   0.30364752 0.30823424 0.31261098 0.31837749 0.32495135\n",
      " 0.33237019 0.3400521 ]\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.34755313]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[0.298686   0.30364752 0.30823424 0.31261098 0.31837749 0.32495135\n",
      "  0.33237019 0.3400521 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.14416024088859558\n",
      "Predicción post entrenamiento : [[0.35171017]]\n",
      "PERDIDAAAA despues: 0.1410207897424698\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "[[[0.30364752]\n",
      "  [0.30823424]\n",
      "  [0.31261098]\n",
      "  [0.31837749]\n",
      "  [0.32495135]\n",
      "  [0.33237019]\n",
      "  [0.3400521 ]\n",
      "  [0.34755313]]]\n",
      "ejemplar: [0.30364752 0.30823424 0.31261098 0.31837749 0.32495135 0.33237019\n",
      " 0.3400521  0.34755313]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.35548013]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[0.30364752 0.30823424 0.31261098 0.31837749 0.32495135 0.33237019\n",
      "  0.3400521  0.34755313]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1347682774066925\n",
      "Predicción post entrenamiento : [[0.3594758]]\n",
      "PERDIDAAAA despues: 0.13185057044029236\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "[[[0.30823424]\n",
      "  [0.31261098]\n",
      "  [0.31837749]\n",
      "  [0.32495135]\n",
      "  [0.33237019]\n",
      "  [0.3400521 ]\n",
      "  [0.34755313]\n",
      "  [0.35548013]]]\n",
      "ejemplar: [0.30823424 0.31261098 0.31837749 0.32495135 0.33237019 0.3400521\n",
      " 0.34755313 0.35548013]\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.36347434]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[0.30823424 0.31261098 0.31837749 0.32495135 0.33237019 0.3400521\n",
      "  0.34755313 0.35548013]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.16672486066818237\n",
      "Predicción post entrenamiento : [[0.3678559]]\n",
      "PERDIDAAAA despues: 0.1631658971309662\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "[[[0.31261098]\n",
      "  [0.31837749]\n",
      "  [0.32495135]\n",
      "  [0.33237019]\n",
      "  [0.3400521 ]\n",
      "  [0.34755313]\n",
      "  [0.35548013]\n",
      "  [0.36347434]]]\n",
      "ejemplar: [0.31261098 0.31837749 0.32495135 0.33237019 0.3400521  0.34755313\n",
      " 0.35548013 0.36347434]\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.37227648]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[0.31261098 0.31837749 0.32495135 0.33237019 0.3400521  0.34755313\n",
      "  0.35548013 0.36347434]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.12407929450273514\n",
      "Predicción post entrenamiento : [[0.37608588]]\n",
      "PERDIDAAAA despues: 0.12141009420156479\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "[[[0.31837749]\n",
      "  [0.32495135]\n",
      "  [0.33237019]\n",
      "  [0.3400521 ]\n",
      "  [0.34755313]\n",
      "  [0.35548013]\n",
      "  [0.36347434]\n",
      "  [0.37227648]]]\n",
      "ejemplar: [0.31837749 0.32495135 0.33237019 0.3400521  0.34755313 0.35548013\n",
      " 0.36347434 0.37227648]\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.38110852]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[0.31837749 0.32495135 0.33237019 0.3400521  0.34755313 0.35548013\n",
      "  0.36347434 0.37227648]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08407052606344223\n",
      "Predicción post entrenamiento : [[0.3843854]]\n",
      "PERDIDAAAA despues: 0.08218100666999817\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "[[[0.32495135]\n",
      "  [0.33237019]\n",
      "  [0.3400521 ]\n",
      "  [0.34755313]\n",
      "  [0.35548013]\n",
      "  [0.36347434]\n",
      "  [0.37227648]\n",
      "  [0.38110852]]]\n",
      "ejemplar: [0.32495135 0.33237019 0.3400521  0.34755313 0.35548013 0.36347434\n",
      " 0.37227648 0.38110852]\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.38981375]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[0.32495135 0.33237019 0.3400521  0.34755313 0.35548013 0.36347434\n",
      "  0.37227648 0.38110852]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08063105493783951\n",
      "Predicción post entrenamiento : [[0.3928142]]\n",
      "PERDIDAAAA despues: 0.07893607020378113\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "[[[0.33237019]\n",
      "  [0.3400521 ]\n",
      "  [0.34755313]\n",
      "  [0.35548013]\n",
      "  [0.36347434]\n",
      "  [0.37227648]\n",
      "  [0.38110852]\n",
      "  [0.38981375]]]\n",
      "ejemplar: [0.33237019 0.3400521  0.34755313 0.35548013 0.36347434 0.37227648\n",
      " 0.38110852 0.38981375]\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.39855]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[0.33237019 0.3400521  0.34755313 0.35548013 0.36347434 0.37227648\n",
      "  0.38110852 0.38981375]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.099793940782547\n",
      "Predicción post entrenamiento : [[0.40196848]]\n",
      "PERDIDAAAA despues: 0.0976458191871643\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "[[[0.3400521 ]\n",
      "  [0.34755313]\n",
      "  [0.35548013]\n",
      "  [0.36347434]\n",
      "  [0.37227648]\n",
      "  [0.38110852]\n",
      "  [0.38981375]\n",
      "  [0.39855   ]]]\n",
      "ejemplar: [0.3400521  0.34755313 0.35548013 0.36347434 0.37227648 0.38110852\n",
      " 0.38981375 0.39855   ]\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.40787932]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[0.3400521  0.34755313 0.35548013 0.36347434 0.37227648 0.38110852\n",
      "  0.38981375 0.39855   ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11290837079286575\n",
      "Predicción post entrenamiento : [[0.41097784]]\n",
      "PERDIDAAAA despues: 0.11083565652370453\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "[[[0.34755313]\n",
      "  [0.35548013]\n",
      "  [0.36347434]\n",
      "  [0.37227648]\n",
      "  [0.38110852]\n",
      "  [0.38981375]\n",
      "  [0.39855   ]\n",
      "  [0.40787932]]]\n",
      "ejemplar: [0.34755313 0.35548013 0.36347434 0.37227648 0.38110852 0.38981375\n",
      " 0.39855    0.40787932]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.41705063]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[0.34755313 0.35548013 0.36347434 0.37227648 0.38110852 0.38981375\n",
      "  0.39855    0.40787932]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09335315972566605\n",
      "Predicción post entrenamiento : [[0.4200225]]\n",
      "PERDIDAAAA despues: 0.0915459617972374\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "[[[0.35548013]\n",
      "  [0.36347434]\n",
      "  [0.37227648]\n",
      "  [0.38110852]\n",
      "  [0.38981375]\n",
      "  [0.39855   ]\n",
      "  [0.40787932]\n",
      "  [0.41705063]]]\n",
      "ejemplar: [0.35548013 0.36347434 0.37227648 0.38110852 0.38981375 0.39855\n",
      " 0.40787932 0.41705063]\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.4263517]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[0.35548013 0.36347434 0.37227648 0.38110852 0.38981375 0.39855\n",
      "  0.40787932 0.41705063]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07452335208654404\n",
      "Predicción post entrenamiento : [[0.42927065]]\n",
      "PERDIDAAAA despues: 0.07293818145990372\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "[[[0.36347434]\n",
      "  [0.37227648]\n",
      "  [0.38110852]\n",
      "  [0.38981375]\n",
      "  [0.39855   ]\n",
      "  [0.40787932]\n",
      "  [0.41705063]\n",
      "  [0.4263517 ]]]\n",
      "ejemplar: [0.36347434 0.37227648 0.38110852 0.38981375 0.39855    0.40787932\n",
      " 0.41705063 0.4263517 ]\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.43580994]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[0.36347434 0.37227648 0.38110852 0.38981375 0.39855    0.40787932\n",
      "  0.41705063 0.4263517 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09090296179056168\n",
      "Predicción post entrenamiento : [[0.43886226]]\n",
      "PERDIDAAAA despues: 0.08907172083854675\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "[[[0.37227648]\n",
      "  [0.38110852]\n",
      "  [0.38981375]\n",
      "  [0.39855   ]\n",
      "  [0.40787932]\n",
      "  [0.41705063]\n",
      "  [0.4263517 ]\n",
      "  [0.43580994]]]\n",
      "ejemplar: [0.37227648 0.38110852 0.38981375 0.39855    0.40787932 0.41705063\n",
      " 0.4263517  0.43580994]\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.4456451]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[0.37227648 0.38110852 0.38981375 0.39855    0.40787932 0.41705063\n",
      "  0.4263517  0.43580994]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07605501264333725\n",
      "Predicción post entrenamiento : [[0.448355]]\n",
      "PERDIDAAAA despues: 0.07456768304109573\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "[[[0.38110852]\n",
      "  [0.38981375]\n",
      "  [0.39855   ]\n",
      "  [0.40787932]\n",
      "  [0.41705063]\n",
      "  [0.4263517 ]\n",
      "  [0.43580994]\n",
      "  [0.44564509]]]\n",
      "ejemplar: [0.38110852 0.38981375 0.39855    0.40787932 0.41705063 0.4263517\n",
      " 0.43580994 0.44564509]\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.45522597]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[0.38110852 0.38981375 0.39855    0.40787932 0.41705063 0.4263517\n",
      "  0.43580994 0.44564509]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0694257840514183\n",
      "Predicción post entrenamiento : [[0.45813432]]\n",
      "PERDIDAAAA despues: 0.067901611328125\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "[[[0.38981375]\n",
      "  [0.39855   ]\n",
      "  [0.40787932]\n",
      "  [0.41705063]\n",
      "  [0.4263517 ]\n",
      "  [0.43580994]\n",
      "  [0.44564509]\n",
      "  [0.45522597]]]\n",
      "ejemplar: [0.38981375 0.39855    0.40787932 0.41705063 0.4263517  0.43580994\n",
      " 0.44564509 0.45522597]\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.46511206]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[0.38981375 0.39855    0.40787932 0.41705063 0.4263517  0.43580994\n",
      "  0.44564509 0.45522597]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04369992017745972\n",
      "Predicción post entrenamiento : [[0.46687222]]\n",
      "PERDIDAAAA despues: 0.042967114597558975\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "[[[0.39855   ]\n",
      "  [0.40787932]\n",
      "  [0.41705063]\n",
      "  [0.4263517 ]\n",
      "  [0.43580994]\n",
      "  [0.44564509]\n",
      "  [0.45522597]\n",
      "  [0.46511206]]]\n",
      "ejemplar: [0.39855    0.40787932 0.41705063 0.4263517  0.43580994 0.44564509\n",
      " 0.45522597 0.46511206]\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.47401667]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[0.39855    0.40787932 0.41705063 0.4263517  0.43580994 0.44564509\n",
      "  0.45522597 0.46511206]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05042259767651558\n",
      "Predicción post entrenamiento : [[0.47617415]]\n",
      "PERDIDAAAA despues: 0.0494583323597908\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "[[[0.40787932]\n",
      "  [0.41705063]\n",
      "  [0.4263517 ]\n",
      "  [0.43580994]\n",
      "  [0.44564509]\n",
      "  [0.45522597]\n",
      "  [0.46511206]\n",
      "  [0.47401667]]]\n",
      "ejemplar: [0.40787932 0.41705063 0.4263517  0.43580994 0.44564509 0.45522597\n",
      " 0.46511206 0.47401667]\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.48351362]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[0.40787932 0.41705063 0.4263517  0.43580994 0.44564509 0.45522597\n",
      "  0.46511206 0.47401667]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05641799047589302\n",
      "Predicción post entrenamiento : [[0.4857068]]\n",
      "PERDIDAAAA despues: 0.0553809329867363\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "[[[0.41705063]\n",
      "  [0.4263517 ]\n",
      "  [0.43580994]\n",
      "  [0.44564509]\n",
      "  [0.45522597]\n",
      "  [0.46511206]\n",
      "  [0.47401667]\n",
      "  [0.48351362]]]\n",
      "ejemplar: [0.41705063 0.4263517  0.43580994 0.44564509 0.45522597 0.46511206\n",
      " 0.47401667 0.48351362]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.4931188]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[0.41705063 0.4263517  0.43580994 0.44564509 0.45522597 0.46511206\n",
      "  0.47401667 0.48351362]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05265617370605469\n",
      "Predicción post entrenamiento : [[0.49540785]]\n",
      "PERDIDAAAA despues: 0.05161087587475777\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "[[[0.4263517 ]\n",
      "  [0.43580994]\n",
      "  [0.44564509]\n",
      "  [0.45522597]\n",
      "  [0.46511206]\n",
      "  [0.47401667]\n",
      "  [0.48351362]\n",
      "  [0.49311879]]]\n",
      "ejemplar: [0.4263517  0.43580994 0.44564509 0.45522597 0.46511206 0.47401667\n",
      " 0.48351362 0.49311879]\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.5029414]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[0.4263517  0.43580994 0.44564509 0.45522597 0.46511206 0.47401667\n",
      "  0.48351362 0.49311879]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06418855488300323\n",
      "Predicción post entrenamiento : [[0.5052408]]\n",
      "PERDIDAAAA despues: 0.0630287304520607\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "[[[0.43580994]\n",
      "  [0.44564509]\n",
      "  [0.45522597]\n",
      "  [0.46511206]\n",
      "  [0.47401667]\n",
      "  [0.48351362]\n",
      "  [0.49311879]\n",
      "  [0.50294143]]]\n",
      "ejemplar: [0.43580994 0.44564509 0.45522597 0.46511206 0.47401667 0.48351362\n",
      " 0.49311879 0.50294143]\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.5128778]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[0.43580994 0.44564509 0.45522597 0.46511206 0.47401667 0.48351362\n",
      "  0.49311879 0.50294143]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09904138743877411\n",
      "Predicción post entrenamiento : [[0.51585865]]\n",
      "PERDIDAAAA despues: 0.09717408567667007\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "[[[0.44564509]\n",
      "  [0.45522597]\n",
      "  [0.46511206]\n",
      "  [0.47401667]\n",
      "  [0.48351362]\n",
      "  [0.49311879]\n",
      "  [0.50294143]\n",
      "  [0.51287782]]]\n",
      "ejemplar: [0.44564509 0.45522597 0.46511206 0.47401667 0.48351362 0.49311879\n",
      " 0.50294143 0.51287782]\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.52357125]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[0.44564509 0.45522597 0.46511206 0.47401667 0.48351362 0.49311879\n",
      "  0.50294143 0.51287782]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0993831530213356\n",
      "Predicción post entrenamiento : [[0.5265484]]\n",
      "PERDIDAAAA despues: 0.09751492738723755\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "[[[0.45522597]\n",
      "  [0.46511206]\n",
      "  [0.47401667]\n",
      "  [0.48351362]\n",
      "  [0.49311879]\n",
      "  [0.50294143]\n",
      "  [0.51287782]\n",
      "  [0.52357125]]]\n",
      "ejemplar: [0.45522597 0.46511206 0.47401667 0.48351362 0.49311879 0.50294143\n",
      " 0.51287782 0.52357125]\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.53424793]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[0.45522597 0.46511206 0.47401667 0.48351362 0.49311879 0.50294143\n",
      "  0.51287782 0.52357125]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06760929524898529\n",
      "Predicción post entrenamiento : [[0.5358373]]\n",
      "PERDIDAAAA despues: 0.0667852982878685\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "[[[0.46511206]\n",
      "  [0.47401667]\n",
      "  [0.48351362]\n",
      "  [0.49311879]\n",
      "  [0.50294143]\n",
      "  [0.51287782]\n",
      "  [0.52357125]\n",
      "  [0.53424793]]]\n",
      "ejemplar: [0.46511206 0.47401667 0.48351362 0.49311879 0.50294143 0.51287782\n",
      " 0.52357125 0.53424793]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.54359466]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[0.46511206 0.47401667 0.48351362 0.49311879 0.50294143 0.51287782\n",
      "  0.52357125 0.53424793]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05770087242126465\n",
      "Predicción post entrenamiento : [[0.5461185]]\n",
      "PERDIDAAAA despues: 0.05649473890662193\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "[[[0.47401667]\n",
      "  [0.48351362]\n",
      "  [0.49311879]\n",
      "  [0.50294143]\n",
      "  [0.51287782]\n",
      "  [0.52357125]\n",
      "  [0.53424793]\n",
      "  [0.54359466]]]\n",
      "ejemplar: [0.47401667 0.48351362 0.49311879 0.50294143 0.51287782 0.52357125\n",
      " 0.53424793 0.54359466]\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.5538759]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[0.47401667 0.48351362 0.49311879 0.50294143 0.51287782 0.52357125\n",
      "  0.53424793 0.54359466]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04581461846828461\n",
      "Predicción post entrenamiento : [[0.55564094]]\n",
      "PERDIDAAAA despues: 0.04506215453147888\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "[[[0.48351362]\n",
      "  [0.49311879]\n",
      "  [0.50294143]\n",
      "  [0.51287782]\n",
      "  [0.52357125]\n",
      "  [0.53424793]\n",
      "  [0.54359466]\n",
      "  [0.55387592]]]\n",
      "ejemplar: [0.48351362 0.49311879 0.50294143 0.51287782 0.52357125 0.53424793\n",
      " 0.54359466 0.55387592]\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.5636749]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[0.48351362 0.49311879 0.50294143 0.51287782 0.52357125 0.53424793\n",
      "  0.54359466 0.55387592]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04879888892173767\n",
      "Predicción post entrenamiento : [[0.5658826]]\n",
      "PERDIDAAAA despues: 0.04782838374376297\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "[[[0.49311879]\n",
      "  [0.50294143]\n",
      "  [0.51287782]\n",
      "  [0.52357125]\n",
      "  [0.53424793]\n",
      "  [0.54359466]\n",
      "  [0.55387592]\n",
      "  [0.56367493]]]\n",
      "ejemplar: [0.49311879 0.50294143 0.51287782 0.52357125 0.53424793 0.54359466\n",
      " 0.55387592 0.56367493]\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.5740853]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[0.49311879 0.50294143 0.51287782 0.52357125 0.53424793 0.54359466\n",
      "  0.55387592 0.56367493]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09280788898468018\n",
      "Predicción post entrenamiento : [[0.5765415]]\n",
      "PERDIDAAAA despues: 0.09131739288568497\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "[[[0.50294143]\n",
      "  [0.51287782]\n",
      "  [0.52357125]\n",
      "  [0.53424793]\n",
      "  [0.54359466]\n",
      "  [0.55387592]\n",
      "  [0.56367493]\n",
      "  [0.5740853 ]]]\n",
      "ejemplar: [0.50294143 0.51287782 0.52357125 0.53424793 0.54359466 0.55387592\n",
      " 0.56367493 0.5740853 ]\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.5849112]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[0.50294143 0.51287782 0.52357125 0.53424793 0.54359466 0.55387592\n",
      "  0.56367493 0.5740853 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08451717346906662\n",
      "Predicción post entrenamiento : [[0.58643615]]\n",
      "PERDIDAAAA despues: 0.08363284915685654\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "[[[0.51287782]\n",
      "  [0.52357125]\n",
      "  [0.53424793]\n",
      "  [0.54359466]\n",
      "  [0.55387592]\n",
      "  [0.56367493]\n",
      "  [0.5740853 ]\n",
      "  [0.58491123]]]\n",
      "ejemplar: [0.51287782 0.52357125 0.53424793 0.54359466 0.55387592 0.56367493\n",
      " 0.5740853  0.58491123]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.5949354]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[0.51287782 0.52357125 0.53424793 0.54359466 0.55387592 0.56367493\n",
      "  0.5740853  0.58491123]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06449586898088455\n",
      "Predicción post entrenamiento : [[0.5972295]]\n",
      "PERDIDAAAA despues: 0.06333593279123306\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "[[[0.52357125]\n",
      "  [0.53424793]\n",
      "  [0.54359466]\n",
      "  [0.55387592]\n",
      "  [0.56367493]\n",
      "  [0.5740853 ]\n",
      "  [0.58491123]\n",
      "  [0.59493542]]]\n",
      "ejemplar: [0.52357125 0.53424793 0.54359466 0.55387592 0.56367493 0.5740853\n",
      " 0.58491123 0.59493542]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.6058451]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[0.52357125 0.53424793 0.54359466 0.55387592 0.56367493 0.5740853\n",
      "  0.58491123 0.59493542]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04513177275657654\n",
      "Predicción post entrenamiento : [[0.60762167]]\n",
      "PERDIDAAAA despues: 0.04438008740544319\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "[[[0.53424793]\n",
      "  [0.54359466]\n",
      "  [0.55387592]\n",
      "  [0.56367493]\n",
      "  [0.5740853 ]\n",
      "  [0.58491123]\n",
      "  [0.59493542]\n",
      "  [0.60584509]]]\n",
      "ejemplar: [0.53424793 0.54359466 0.55387592 0.56367493 0.5740853  0.58491123\n",
      " 0.59493542 0.60584509]\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.6161565]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[0.53424793 0.54359466 0.55387592 0.56367493 0.5740853  0.58491123\n",
      "  0.59493542 0.60584509]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04437544196844101\n",
      "Predicción post entrenamiento : [[0.6175999]]\n",
      "PERDIDAAAA despues: 0.043769415467977524\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "[[[0.54359466]\n",
      "  [0.55387592]\n",
      "  [0.56367493]\n",
      "  [0.5740853 ]\n",
      "  [0.58491123]\n",
      "  [0.59493542]\n",
      "  [0.60584509]\n",
      "  [0.61615652]]]\n",
      "ejemplar: [0.54359466 0.55387592 0.56367493 0.5740853  0.58491123 0.59493542\n",
      " 0.60584509 0.61615652]\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.62604564]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[0.54359466 0.55387592 0.56367493 0.5740853  0.58491123 0.59493542\n",
      "  0.60584509 0.61615652]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.025379309430718422\n",
      "Predicción post entrenamiento : [[0.62702286]]\n",
      "PERDIDAAAA despues: 0.02506890520453453\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "[[[0.55387592]\n",
      "  [0.56367493]\n",
      "  [0.5740853 ]\n",
      "  [0.58491123]\n",
      "  [0.59493542]\n",
      "  [0.60584509]\n",
      "  [0.61615652]\n",
      "  [0.62604564]]]\n",
      "ejemplar: [0.55387592 0.56367493 0.5740853  0.58491123 0.59493542 0.60584509\n",
      " 0.61615652 0.62604564]\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.6357404]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[0.55387592 0.56367493 0.5740853  0.58491123 0.59493542 0.60584509\n",
      "  0.61615652 0.62604564]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02355874329805374\n",
      "Predicción post entrenamiento : [[0.63605636]]\n",
      "PERDIDAAAA despues: 0.023461848497390747\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "[[[0.56367493]\n",
      "  [0.5740853 ]\n",
      "  [0.58491123]\n",
      "  [0.59493542]\n",
      "  [0.60584509]\n",
      "  [0.61615652]\n",
      "  [0.62604564]\n",
      "  [0.6357404 ]]]\n",
      "ejemplar: [0.56367493 0.5740853  0.58491123 0.59493542 0.60584509 0.61615652\n",
      " 0.62604564 0.6357404 ]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.6448195]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[0.56367493 0.5740853  0.58491123 0.59493542 0.60584509 0.61615652\n",
      "  0.62604564 0.6357404 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03585466742515564\n",
      "Predicción post entrenamiento : [[0.6469605]]\n",
      "PERDIDAAAA despues: 0.03504844009876251\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "[[[0.5740853 ]\n",
      "  [0.58491123]\n",
      "  [0.59493542]\n",
      "  [0.60584509]\n",
      "  [0.61615652]\n",
      "  [0.62604564]\n",
      "  [0.6357404 ]\n",
      "  [0.6448195 ]]]\n",
      "ejemplar: [0.5740853  0.58491123 0.59493542 0.60584509 0.61615652 0.62604564\n",
      " 0.6357404  0.6448195 ]\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.6559024]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[0.5740853  0.58491123 0.59493542 0.60584509 0.61615652 0.62604564\n",
      "  0.6357404  0.6448195 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02451523393392563\n",
      "Predicción post entrenamiento : [[0.65735495]]\n",
      "PERDIDAAAA despues: 0.02406247705221176\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "[[[0.58491123]\n",
      "  [0.59493542]\n",
      "  [0.60584509]\n",
      "  [0.61615652]\n",
      "  [0.62604564]\n",
      "  [0.6357404 ]\n",
      "  [0.6448195 ]\n",
      "  [0.65590239]]]\n",
      "ejemplar: [0.58491123 0.59493542 0.60584509 0.61615652 0.62604564 0.6357404\n",
      " 0.6448195  0.65590239]\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.66630703]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[0.58491123 0.59493542 0.60584509 0.61615652 0.62604564 0.6357404\n",
      "  0.6448195  0.65590239]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018206864595413208\n",
      "Predicción post entrenamiento : [[0.66726357]]\n",
      "PERDIDAAAA despues: 0.017949644476175308\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "[[[0.59493542]\n",
      "  [0.60584509]\n",
      "  [0.61615652]\n",
      "  [0.62604564]\n",
      "  [0.6357404 ]\n",
      "  [0.6448195 ]\n",
      "  [0.65590239]\n",
      "  [0.66630703]]]\n",
      "ejemplar: [0.59493542 0.60584509 0.61615652 0.62604564 0.6357404  0.6448195\n",
      " 0.65590239 0.66630703]\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.6760878]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[0.59493542 0.60584509 0.61615652 0.62604564 0.6357404  0.6448195\n",
      "  0.65590239 0.66630703]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016151679679751396\n",
      "Predicción post entrenamiento : [[0.677073]]\n",
      "PERDIDAAAA despues: 0.015902232378721237\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "[[[0.60584509]\n",
      "  [0.61615652]\n",
      "  [0.62604564]\n",
      "  [0.6357404 ]\n",
      "  [0.6448195 ]\n",
      "  [0.65590239]\n",
      "  [0.66630703]\n",
      "  [0.6760878 ]]]\n",
      "ejemplar: [0.60584509 0.61615652 0.62604564 0.6357404  0.6448195  0.65590239\n",
      " 0.66630703 0.6760878 ]\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.6859639]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[0.60584509 0.61615652 0.62604564 0.6357404  0.6448195  0.65590239\n",
      "  0.66630703 0.6760878 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011562046594917774\n",
      "Predicción post entrenamiento : [[0.6871173]]\n",
      "PERDIDAAAA despues: 0.011315344832837582\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "[[[0.61615652]\n",
      "  [0.62604564]\n",
      "  [0.6357404 ]\n",
      "  [0.6448195 ]\n",
      "  [0.65590239]\n",
      "  [0.66630703]\n",
      "  [0.6760878 ]\n",
      "  [0.68596393]]]\n",
      "ejemplar: [0.61615652 0.62604564 0.6357404  0.6448195  0.65590239 0.66630703\n",
      " 0.6760878  0.68596393]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.695819]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[0.61615652 0.62604564 0.6357404  0.6448195  0.65590239 0.66630703\n",
      "  0.6760878  0.68596393]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00414110766723752\n",
      "Predicción post entrenamiento : [[0.6955575]]\n",
      "PERDIDAAAA despues: 0.004174837842583656\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "[[[0.62604564]\n",
      "  [0.6357404 ]\n",
      "  [0.6448195 ]\n",
      "  [0.65590239]\n",
      "  [0.66630703]\n",
      "  [0.6760878 ]\n",
      "  [0.68596393]\n",
      "  [0.69581902]]]\n",
      "ejemplar: [0.62604564 0.6357404  0.6448195  0.65590239 0.66630703 0.6760878\n",
      " 0.68596393 0.69581902]\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.7041993]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[0.62604564 0.6357404  0.6448195  0.65590239 0.66630703 0.6760878\n",
      "  0.68596393 0.69581902]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009718557121232152\n",
      "Predicción post entrenamiento : [[0.7044761]]\n",
      "PERDIDAAAA despues: 0.0009546738001517951\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "[[[0.6357404 ]\n",
      "  [0.6448195 ]\n",
      "  [0.65590239]\n",
      "  [0.66630703]\n",
      "  [0.6760878 ]\n",
      "  [0.68596393]\n",
      "  [0.69581902]\n",
      "  [0.70419931]]]\n",
      "ejemplar: [0.6357404  0.6448195  0.65590239 0.66630703 0.6760878  0.68596393\n",
      " 0.69581902 0.70419931]\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.713161]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[0.6357404  0.6448195  0.65590239 0.66630703 0.6760878  0.68596393\n",
      "  0.69581902 0.70419931]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.827864803606644e-06\n",
      "Predicción post entrenamiento : [[0.7123472]]\n",
      "PERDIDAAAA despues: 4.654332315112697e-06\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "[[[0.6448195 ]\n",
      "  [0.65590239]\n",
      "  [0.66630703]\n",
      "  [0.6760878 ]\n",
      "  [0.68596393]\n",
      "  [0.69581902]\n",
      "  [0.70419931]\n",
      "  [0.71316099]]]\n",
      "ejemplar: [0.6448195  0.65590239 0.66630703 0.6760878  0.68596393 0.69581902\n",
      " 0.70419931 0.71316099]\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.72111315]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[0.6448195  0.65590239 0.66630703 0.6760878  0.68596393 0.69581902\n",
      "  0.70419931 0.71316099]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.074920333456248e-05\n",
      "Predicción post entrenamiento : [[0.7215103]]\n",
      "PERDIDAAAA despues: 8.804447134025395e-05\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "[[[0.65590239]\n",
      "  [0.66630703]\n",
      "  [0.6760878 ]\n",
      "  [0.68596393]\n",
      "  [0.69581902]\n",
      "  [0.70419931]\n",
      "  [0.71316099]\n",
      "  [0.72111315]]]\n",
      "ejemplar: [0.65590239 0.66630703 0.6760878  0.68596393 0.69581902 0.70419931\n",
      " 0.71316099 0.72111315]\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.73051596]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[0.65590239 0.66630703 0.6760878  0.68596393 0.69581902 0.70419931\n",
      "  0.71316099 0.72111315]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.317199535667896e-05\n",
      "Predicción post entrenamiento : [[0.73075205]]\n",
      "PERDIDAAAA despues: 7.892144640209153e-05\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "[[[0.66630703]\n",
      "  [0.6760878 ]\n",
      "  [0.68596393]\n",
      "  [0.69581902]\n",
      "  [0.70419931]\n",
      "  [0.71316099]\n",
      "  [0.72111315]\n",
      "  [0.73051596]]]\n",
      "ejemplar: [0.66630703 0.6760878  0.68596393 0.69581902 0.70419931 0.71316099\n",
      " 0.72111315 0.73051596]\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.7393997]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[0.66630703 0.6760878  0.68596393 0.69581902 0.70419931 0.71316099\n",
      "  0.72111315 0.73051596]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.0568331163085531e-05\n",
      "Predicción post entrenamiento : [[0.7394054]]\n",
      "PERDIDAAAA despues: 1.0605566785670817e-05\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "[[[0.6760878 ]\n",
      "  [0.68596393]\n",
      "  [0.69581902]\n",
      "  [0.70419931]\n",
      "  [0.71316099]\n",
      "  [0.72111315]\n",
      "  [0.73051596]\n",
      "  [0.73939967]]]\n",
      "ejemplar: [0.6760878  0.68596393 0.69581902 0.70419931 0.71316099 0.72111315\n",
      " 0.73051596 0.73939967]\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.7477911]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[0.6760878  0.68596393 0.69581902 0.70419931 0.71316099 0.72111315\n",
      "  0.73051596 0.73939967]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006435312796384096\n",
      "Predicción post entrenamiento : [[0.74690473]]\n",
      "PERDIDAAAA despues: 0.006293886806815863\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "[[[0.68596393]\n",
      "  [0.69581902]\n",
      "  [0.70419931]\n",
      "  [0.71316099]\n",
      "  [0.72111315]\n",
      "  [0.73051596]\n",
      "  [0.73939967]\n",
      "  [0.74779111]]]\n",
      "ejemplar: [0.68596393 0.69581902 0.70419931 0.71316099 0.72111315 0.73051596\n",
      " 0.73939967 0.74779111]\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.7551321]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[0.68596393 0.69581902 0.70419931 0.71316099 0.72111315 0.73051596\n",
      "  0.73939967 0.74779111]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007265289779752493\n",
      "Predicción post entrenamiento : [[0.75532764]]\n",
      "PERDIDAAAA despues: 0.007298666052520275\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "[[[0.69581902]\n",
      "  [0.70419931]\n",
      "  [0.71316099]\n",
      "  [0.72111315]\n",
      "  [0.73051596]\n",
      "  [0.73939967]\n",
      "  [0.74779111]\n",
      "  [0.75513208]]]\n",
      "ejemplar: [0.69581902 0.70419931 0.71316099 0.72111315 0.73051596 0.73939967\n",
      " 0.74779111 0.75513208]\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.7633125]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[0.69581902 0.70419931 0.71316099 0.72111315 0.73051596 0.73939967\n",
      "  0.74779111 0.75513208]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004446661565452814\n",
      "Predicción post entrenamiento : [[0.7622208]]\n",
      "PERDIDAAAA despues: 0.0043022544123232365\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "[[[0.70419931]\n",
      "  [0.71316099]\n",
      "  [0.72111315]\n",
      "  [0.73051596]\n",
      "  [0.73939967]\n",
      "  [0.74779111]\n",
      "  [0.75513208]\n",
      "  [0.76331252]]]\n",
      "ejemplar: [0.70419931 0.71316099 0.72111315 0.73051596 0.73939967 0.74779111\n",
      " 0.75513208 0.76331252]\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.7698968]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[0.70419931 0.71316099 0.72111315 0.73051596 0.73939967 0.74779111\n",
      "  0.75513208 0.76331252]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012984483502805233\n",
      "Predicción post entrenamiento : [[0.767937]]\n",
      "PERDIDAAAA despues: 0.012541688047349453\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "[[[0.71316099]\n",
      "  [0.72111315]\n",
      "  [0.73051596]\n",
      "  [0.73939967]\n",
      "  [0.74779111]\n",
      "  [0.75513208]\n",
      "  [0.76331252]\n",
      "  [0.76989681]]]\n",
      "ejemplar: [0.71316099 0.72111315 0.73051596 0.73939967 0.74779111 0.75513208\n",
      " 0.76331252 0.76989681]\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.7756575]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[0.71316099 0.72111315 0.73051596 0.73939967 0.74779111 0.75513208\n",
      "  0.76331252 0.76989681]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009380079805850983\n",
      "Predicción post entrenamiento : [[0.77602017]]\n",
      "PERDIDAAAA despues: 0.009450465440750122\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "[[[0.72111315]\n",
      "  [0.73051596]\n",
      "  [0.73939967]\n",
      "  [0.74779111]\n",
      "  [0.75513208]\n",
      "  [0.76331252]\n",
      "  [0.76989681]\n",
      "  [0.77565747]]]\n",
      "ejemplar: [0.72111315 0.73051596 0.73939967 0.74779111 0.75513208 0.76331252\n",
      " 0.76989681 0.77565747]\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.78358096]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[0.72111315 0.73051596 0.73939967 0.74779111 0.75513208 0.76331252\n",
      "  0.76989681 0.77565747]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011553332209587097\n",
      "Predicción post entrenamiento : [[0.7838431]]\n",
      "PERDIDAAAA despues: 0.011609753593802452\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "[[[0.73051596]\n",
      "  [0.73939967]\n",
      "  [0.74779111]\n",
      "  [0.75513208]\n",
      "  [0.76331252]\n",
      "  [0.76989681]\n",
      "  [0.77565747]\n",
      "  [0.78358096]]]\n",
      "ejemplar: [0.73051596 0.73939967 0.74779111 0.75513208 0.76331252 0.76989681\n",
      " 0.77565747 0.78358096]\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.7914662]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[0.73051596 0.73939967 0.74779111 0.75513208 0.76331252 0.76989681\n",
      "  0.77565747 0.78358096]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0038321069441735744\n",
      "Predicción post entrenamiento : [[0.79142296]]\n",
      "PERDIDAAAA despues: 0.0038267585914582014\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "[[[0.73939967]\n",
      "  [0.74779111]\n",
      "  [0.75513208]\n",
      "  [0.76331252]\n",
      "  [0.76989681]\n",
      "  [0.77565747]\n",
      "  [0.78358096]\n",
      "  [0.79146618]]]\n",
      "ejemplar: [0.73939967 0.74779111 0.75513208 0.76331252 0.76989681 0.77565747\n",
      " 0.78358096 0.79146618]\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.79863536]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[0.73939967 0.74779111 0.75513208 0.76331252 0.76989681 0.77565747\n",
      "  0.78358096 0.79146618]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009478345513343811\n",
      "Predicción post entrenamiento : [[0.7980136]]\n",
      "PERDIDAAAA despues: 0.009357672184705734\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "[[[0.74779111]\n",
      "  [0.75513208]\n",
      "  [0.76331252]\n",
      "  [0.76989681]\n",
      "  [0.77565747]\n",
      "  [0.78358096]\n",
      "  [0.79146618]\n",
      "  [0.79863536]]]\n",
      "ejemplar: [0.74779111 0.75513208 0.76331252 0.76989681 0.77565747 0.78358096\n",
      " 0.79146618 0.79863536]\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.8048657]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[0.74779111 0.75513208 0.76331252 0.76989681 0.77565747 0.78358096\n",
      "  0.79146618 0.79863536]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0013938071206212044\n",
      "Predicción post entrenamiento : [[0.8054381]]\n",
      "PERDIDAAAA despues: 0.0014368732227012515\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "[[[0.75513208]\n",
      "  [0.76331252]\n",
      "  [0.76989681]\n",
      "  [0.77565747]\n",
      "  [0.78358096]\n",
      "  [0.79146618]\n",
      "  [0.79863536]\n",
      "  [0.80486572]]]\n",
      "ejemplar: [0.75513208 0.76331252 0.76989681 0.77565747 0.78358096 0.79146618\n",
      " 0.79863536 0.80486572]\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.8119985]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[0.75513208 0.76331252 0.76989681 0.77565747 0.78358096 0.79146618\n",
      "  0.79863536 0.80486572]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003233605297282338\n",
      "Predicción post entrenamiento : [[0.81208134]]\n",
      "PERDIDAAAA despues: 0.003243034705519676\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "[[[0.76331252]\n",
      "  [0.76989681]\n",
      "  [0.77565747]\n",
      "  [0.78358096]\n",
      "  [0.79146618]\n",
      "  [0.79863536]\n",
      "  [0.80486572]\n",
      "  [0.81199849]]]\n",
      "ejemplar: [0.76331252 0.76989681 0.77565747 0.78358096 0.79146618 0.79863536\n",
      " 0.80486572 0.81199849]\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.8186035]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[0.76331252 0.76989681 0.77565747 0.78358096 0.79146618 0.79863536\n",
      "  0.80486572 0.81199849]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005408644676208496\n",
      "Predicción post entrenamiento : [[0.8179749]]\n",
      "PERDIDAAAA despues: 0.005316582508385181\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "[[[0.76989681]\n",
      "  [0.77565747]\n",
      "  [0.78358096]\n",
      "  [0.79146618]\n",
      "  [0.79863536]\n",
      "  [0.80486572]\n",
      "  [0.81199849]\n",
      "  [0.81860352]]]\n",
      "ejemplar: [0.76989681 0.77565747 0.78358096 0.79146618 0.79863536 0.80486572\n",
      " 0.81199849 0.81860352]\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.8241897]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[0.76989681 0.77565747 0.78358096 0.79146618 0.79863536 0.80486572\n",
      "  0.81199849 0.81860352]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00520643824711442\n",
      "Predicción post entrenamiento : [[0.82279736]]\n",
      "PERDIDAAAA despues: 0.005007443018257618\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "[[[0.77565747]\n",
      "  [0.78358096]\n",
      "  [0.79146618]\n",
      "  [0.79863536]\n",
      "  [0.80486572]\n",
      "  [0.81199849]\n",
      "  [0.81860352]\n",
      "  [0.82418972]]]\n",
      "ejemplar: [0.77565747 0.78358096 0.79146618 0.79863536 0.80486572 0.81199849\n",
      " 0.81860352 0.82418972]\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.82912266]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[0.77565747 0.78358096 0.79146618 0.79863536 0.80486572 0.81199849\n",
      "  0.81860352 0.82418972]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014237327501177788\n",
      "Predicción post entrenamiento : [[0.8289412]]\n",
      "PERDIDAAAA despues: 0.014194062910974026\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "[[[0.78358096]\n",
      "  [0.79146618]\n",
      "  [0.79863536]\n",
      "  [0.80486572]\n",
      "  [0.81199849]\n",
      "  [0.81860352]\n",
      "  [0.82418972]\n",
      "  [0.82912266]]]\n",
      "ejemplar: [0.78358096 0.79146618 0.79863536 0.80486572 0.81199849 0.81860352\n",
      " 0.82418972 0.82912266]\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.83561707]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[0.78358096 0.79146618 0.79863536 0.80486572 0.81199849 0.81860352\n",
      "  0.82418972 0.82912266]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02107927016913891\n",
      "Predicción post entrenamiento : [[0.8340689]]\n",
      "PERDIDAAAA despues: 0.020632119849324226\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "[[[0.79146618]\n",
      "  [0.79863536]\n",
      "  [0.80486572]\n",
      "  [0.81199849]\n",
      "  [0.81860352]\n",
      "  [0.82418972]\n",
      "  [0.82912266]\n",
      "  [0.83561707]]]\n",
      "ejemplar: [0.79146618 0.79863536 0.80486572 0.81199849 0.81860352 0.82418972\n",
      " 0.82912266 0.83561707]\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.84044844]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[0.79146618 0.79863536 0.80486572 0.81199849 0.81860352 0.82418972\n",
      "  0.82912266 0.83561707]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007411431521177292\n",
      "Predicción post entrenamiento : [[0.839732]]\n",
      "PERDIDAAAA despues: 0.007288587279617786\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "[[[0.79863536]\n",
      "  [0.80486572]\n",
      "  [0.81199849]\n",
      "  [0.81860352]\n",
      "  [0.82418972]\n",
      "  [0.82912266]\n",
      "  [0.83561707]\n",
      "  [0.84044844]]]\n",
      "ejemplar: [0.79863536 0.80486572 0.81199849 0.81860352 0.82418972 0.82912266\n",
      " 0.83561707 0.84044844]\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.84573156]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[0.79863536 0.80486572 0.81199849 0.81860352 0.82418972 0.82912266\n",
      "  0.83561707 0.84044844]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015259874984622002\n",
      "Predicción post entrenamiento : [[0.8436469]]\n",
      "PERDIDAAAA despues: 0.014749177731573582\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "[[[0.80486572]\n",
      "  [0.81199849]\n",
      "  [0.81860352]\n",
      "  [0.82418972]\n",
      "  [0.82912266]\n",
      "  [0.83561707]\n",
      "  [0.84044844]\n",
      "  [0.84573156]]]\n",
      "ejemplar: [0.80486572 0.81199849 0.81860352 0.82418972 0.82912266 0.83561707\n",
      " 0.84044844 0.84573156]\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.8493755]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[0.80486572 0.81199849 0.81860352 0.82418972 0.82912266 0.83561707\n",
      "  0.84044844 0.84573156]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.519116138610116e-07\n",
      "Predicción post entrenamiento : [[0.8493628]]\n",
      "PERDIDAAAA despues: 7.300550350919366e-07\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "[[[0.81199849]\n",
      "  [0.81860352]\n",
      "  [0.82418972]\n",
      "  [0.82912266]\n",
      "  [0.83561707]\n",
      "  [0.84044844]\n",
      "  [0.84573156]\n",
      "  [0.84937549]]]\n",
      "ejemplar: [0.81199849 0.81860352 0.82418972 0.82912266 0.83561707 0.84044844\n",
      " 0.84573156 0.84937549]\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.8550192]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[0.81199849 0.81860352 0.82418972 0.82912266 0.83561707 0.84044844\n",
      "  0.84573156 0.84937549]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0025445737410336733\n",
      "Predicción post entrenamiento : [[0.8555498]]\n",
      "PERDIDAAAA despues: 0.0024913244415074587\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "[[[0.81860352]\n",
      "  [0.82418972]\n",
      "  [0.82912266]\n",
      "  [0.83561707]\n",
      "  [0.84044844]\n",
      "  [0.84573156]\n",
      "  [0.84937549]\n",
      "  [0.85501921]]]\n",
      "ejemplar: [0.81860352 0.82418972 0.82912266 0.83561707 0.84044844 0.84573156\n",
      " 0.84937549 0.85501921]\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.86080486]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[0.81860352 0.82418972 0.82912266 0.83561707 0.84044844 0.84573156\n",
      "  0.84937549 0.85501921]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004584463022183627\n",
      "Predicción post entrenamiento : [[0.8617839]]\n",
      "PERDIDAAAA despues: 0.0004174786154180765\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "[[[0.82418972]\n",
      "  [0.82912266]\n",
      "  [0.83561707]\n",
      "  [0.84044844]\n",
      "  [0.84573156]\n",
      "  [0.84937549]\n",
      "  [0.85501921]\n",
      "  [0.86080486]]]\n",
      "ejemplar: [0.82418972 0.82912266 0.83561707 0.84044844 0.84573156 0.84937549\n",
      " 0.85501921 0.86080486]\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.8667052]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[0.82418972 0.82912266 0.83561707 0.84044844 0.84573156 0.84937549\n",
      "  0.85501921 0.86080486]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001687771873548627\n",
      "Predicción post entrenamiento : [[0.8669869]]\n",
      "PERDIDAAAA despues: 0.001664706040173769\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "[[[0.82912266]\n",
      "  [0.83561707]\n",
      "  [0.84044844]\n",
      "  [0.84573156]\n",
      "  [0.84937549]\n",
      "  [0.85501921]\n",
      "  [0.86080486]\n",
      "  [0.86670518]]]\n",
      "ejemplar: [0.82912266 0.83561707 0.84044844 0.84573156 0.84937549 0.85501921\n",
      " 0.86080486 0.86670518]\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.8718201]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[0.82912266 0.83561707 0.84044844 0.84573156 0.84937549 0.85501921\n",
      "  0.86080486 0.86670518]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003153321740683168\n",
      "Predicción post entrenamiento : [[0.8727847]]\n",
      "PERDIDAAAA despues: 0.0002820052613969892\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "[[[0.83561707]\n",
      "  [0.84044844]\n",
      "  [0.84573156]\n",
      "  [0.84937549]\n",
      "  [0.85501921]\n",
      "  [0.86080486]\n",
      "  [0.86670518]\n",
      "  [0.87182009]]]\n",
      "ejemplar: [0.83561707 0.84044844 0.84573156 0.84937549 0.85501921 0.86080486\n",
      " 0.86670518 0.87182009]\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.8777141]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[0.83561707 0.84044844 0.84573156 0.84937549 0.85501921 0.86080486\n",
      "  0.86670518 0.87182009]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.176246410585009e-06\n",
      "Predicción post entrenamiento : [[0.877373]]\n",
      "PERDIDAAAA despues: 6.341816060739802e-06\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "[[[0.84044844]\n",
      "  [0.84573156]\n",
      "  [0.84937549]\n",
      "  [0.85501921]\n",
      "  [0.86080486]\n",
      "  [0.86670518]\n",
      "  [0.87182009]\n",
      "  [0.8777141 ]]]\n",
      "ejemplar: [0.84044844 0.84573156 0.84937549 0.85501921 0.86080486 0.86670518\n",
      " 0.87182009 0.8777141 ]\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.88194185]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[0.84044844 0.84573156 0.84937549 0.85501921 0.86080486 0.86670518\n",
      "  0.87182009 0.8777141 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009778182720765471\n",
      "Predicción post entrenamiento : [[0.8825455]]\n",
      "PERDIDAAAA despues: 0.0009404324227944016\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "[[[0.84573156]\n",
      "  [0.84937549]\n",
      "  [0.85501921]\n",
      "  [0.86080486]\n",
      "  [0.86670518]\n",
      "  [0.87182009]\n",
      "  [0.8777141 ]\n",
      "  [0.88194185]]]\n",
      "ejemplar: [0.84573156 0.84937549 0.85501921 0.86080486 0.86670518 0.87182009\n",
      " 0.8777141  0.88194185]\n",
      "y: 1.0\n",
      "Predicción : [[0.887216]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[0.84573156 0.84937549 0.85501921 0.86080486 0.86670518 0.87182009\n",
      "  0.8777141  0.88194185]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01272023655474186\n",
      "Predicción post entrenamiento : [[0.8879108]]\n",
      "PERDIDAAAA despues: 0.012563992291688919\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "[[[0.84937549]\n",
      "  [0.85501921]\n",
      "  [0.86080486]\n",
      "  [0.86670518]\n",
      "  [0.87182009]\n",
      "  [0.8777141 ]\n",
      "  [0.88194185]\n",
      "  [0.88721597]]]\n",
      "ejemplar: [0.84937549 0.85501921 0.86080486 0.86670518 0.87182009 0.8777141\n",
      " 0.88194185 0.88721597]\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.89257085]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[0.84937549 0.85501921 0.86080486 0.86670518 0.87182009 0.8777141\n",
      "  0.88194185 0.88721597]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006081379484385252\n",
      "Predicción post entrenamiento : [[0.8920329]]\n",
      "PERDIDAAAA despues: 0.006165568251162767\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "[[[0.85501921]\n",
      "  [0.86080486]\n",
      "  [0.86670518]\n",
      "  [0.87182009]\n",
      "  [0.8777141 ]\n",
      "  [0.88194185]\n",
      "  [0.88721597]\n",
      "  [0.89257085]]]\n",
      "ejemplar: [0.85501921 0.86080486 0.86670518 0.87182009 0.8777141  0.88194185\n",
      " 0.88721597 0.89257085]\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.8971833]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[0.85501921 0.86080486 0.86670518 0.87182009 0.8777141  0.88194185\n",
      "  0.88721597 0.89257085]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.023332000244409e-05\n",
      "Predicción post entrenamiento : [[0.8981078]]\n",
      "PERDIDAAAA despues: 8.658414299134165e-05\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "[[[0.86080486]\n",
      "  [0.86670518]\n",
      "  [0.87182009]\n",
      "  [0.8777141 ]\n",
      "  [0.88194185]\n",
      "  [0.88721597]\n",
      "  [0.89257085]\n",
      "  [0.8971833 ]]]\n",
      "ejemplar: [0.86080486 0.86670518 0.87182009 0.8777141  0.88194185 0.88721597\n",
      " 0.89257085 0.8971833 ]\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.9032013]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[0.86080486 0.86670518 0.87182009 0.8777141  0.88194185 0.88721597\n",
      "  0.89257085 0.8971833 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006374098593369126\n",
      "Predicción post entrenamiento : [[0.90148264]]\n",
      "PERDIDAAAA despues: 0.0005535826785489917\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "[[[0.86670518]\n",
      "  [0.87182009]\n",
      "  [0.8777141 ]\n",
      "  [0.88194185]\n",
      "  [0.88721597]\n",
      "  [0.89257085]\n",
      "  [0.8971833 ]\n",
      "  [0.90320128]]]\n",
      "ejemplar: [0.86670518 0.87182009 0.8777141  0.88194185 0.88721597 0.89257085\n",
      " 0.8971833  0.90320128]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.906446]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[0.86670518 0.87182009 0.8777141  0.88194185 0.88721597 0.89257085\n",
      "  0.8971833  0.90320128]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0033120245207101107\n",
      "Predicción post entrenamiento : [[0.90549165]]\n",
      "PERDIDAAAA despues: 0.0032030916772782803\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "[[[0.87182009]\n",
      "  [0.8777141 ]\n",
      "  [0.88194185]\n",
      "  [0.88721597]\n",
      "  [0.89257085]\n",
      "  [0.8971833 ]\n",
      "  [0.90320128]\n",
      "  [0.90644598]]]\n",
      "ejemplar: [0.87182009 0.8777141  0.88194185 0.88721597 0.89257085 0.8971833\n",
      " 0.90320128 0.90644598]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.9102511]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[0.87182009 0.8777141  0.88194185 0.88721597 0.89257085 0.8971833\n",
      "  0.90320128 0.90644598]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005787907168269157\n",
      "Predicción post entrenamiento : [[0.90926266]]\n",
      "PERDIDAAAA despues: 0.005638489034026861\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "[[[0.8777141 ]\n",
      "  [0.88194185]\n",
      "  [0.88721597]\n",
      "  [0.89257085]\n",
      "  [0.8971833 ]\n",
      "  [0.90320128]\n",
      "  [0.90644598]\n",
      "  [0.91025108]]]\n",
      "ejemplar: [0.8777141  0.88194185 0.88721597 0.89257085 0.8971833  0.90320128\n",
      " 0.90644598 0.91025108]\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.9140038]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[0.8777141  0.88194185 0.88721597 0.89257085 0.8971833  0.90320128\n",
      "  0.90644598 0.91025108]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0034702562261372805\n",
      "Predicción post entrenamiento : [[0.9136]]\n",
      "PERDIDAAAA despues: 0.003422848880290985\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "[[[0.88194185]\n",
      "  [0.88721597]\n",
      "  [0.89257085]\n",
      "  [0.8971833 ]\n",
      "  [0.90320128]\n",
      "  [0.90644598]\n",
      "  [0.91025108]\n",
      "  [0.91400379]]]\n",
      "ejemplar: [0.88194185 0.88721597 0.89257085 0.8971833  0.90320128 0.90644598\n",
      " 0.91025108 0.91400379]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.9180525]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[0.88194185 0.88721597 0.89257085 0.8971833  0.90320128 0.90644598\n",
      "  0.91025108 0.91400379]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001832723617553711\n",
      "Predicción post entrenamiento : [[0.9183947]]\n",
      "PERDIDAAAA despues: 0.0018621392082422972\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "[[[0.88721597]\n",
      "  [0.89257085]\n",
      "  [0.8971833 ]\n",
      "  [0.90320128]\n",
      "  [0.90644598]\n",
      "  [0.91025108]\n",
      "  [0.91400379]\n",
      "  [0.91805249]]]\n",
      "ejemplar: [0.88721597 0.89257085 0.8971833  0.90320128 0.90644598 0.91025108\n",
      " 0.91400379 0.91805249]\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.92299503]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[0.88721597 0.89257085 0.8971833  0.90320128 0.90644598 0.91025108\n",
      "  0.91400379 0.91805249]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004351097624748945\n",
      "Predicción post entrenamiento : [[0.9229729]]\n",
      "PERDIDAAAA despues: 0.0043481807224452496\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "[[[0.89257085]\n",
      "  [0.8971833 ]\n",
      "  [0.90320128]\n",
      "  [0.90644598]\n",
      "  [0.91025108]\n",
      "  [0.91400379]\n",
      "  [0.91805249]\n",
      "  [0.92299503]]]\n",
      "ejemplar: [0.89257085 0.8971833  0.90320128 0.90644598 0.91025108 0.91400379\n",
      " 0.91805249 0.92299503]\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.9273896]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[0.89257085 0.8971833  0.90320128 0.90644598 0.91025108 0.91400379\n",
      "  0.91805249 0.92299503]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005980158224701881\n",
      "Predicción post entrenamiento : [[0.9258803]]\n",
      "PERDIDAAAA despues: 0.00574900209903717\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "[[[0.8971833 ]\n",
      "  [0.90320128]\n",
      "  [0.90644598]\n",
      "  [0.91025108]\n",
      "  [0.91400379]\n",
      "  [0.91805249]\n",
      "  [0.92299503]\n",
      "  [0.92738962]]]\n",
      "ejemplar: [0.8971833  0.90320128 0.90644598 0.91025108 0.91400379 0.91805249\n",
      " 0.92299503 0.92738962]\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.93003196]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[0.8971833  0.90320128 0.90644598 0.91025108 0.91400379 0.91805249\n",
      "  0.92299503 0.92738962]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0076274629682302475\n",
      "Predicción post entrenamiento : [[0.92855114]]\n",
      "PERDIDAAAA despues: 0.007371000479906797\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "[[[0.90320128]\n",
      "  [0.90644598]\n",
      "  [0.91025108]\n",
      "  [0.91400379]\n",
      "  [0.91805249]\n",
      "  [0.92299503]\n",
      "  [0.92738962]\n",
      "  [0.93003196]]]\n",
      "ejemplar: [0.90320128 0.90644598 0.91025108 0.91400379 0.91805249 0.92299503\n",
      " 0.92738962 0.93003196]\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.9326012]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[0.90320128 0.90644598 0.91025108 0.91400379 0.91805249 0.92299503\n",
      "  0.92738962 0.93003196]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01202627643942833\n",
      "Predicción post entrenamiento : [[0.9303053]]\n",
      "PERDIDAAAA despues: 0.011527988128364086\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "[[[0.90644598]\n",
      "  [0.91025108]\n",
      "  [0.91400379]\n",
      "  [0.91805249]\n",
      "  [0.92299503]\n",
      "  [0.92738962]\n",
      "  [0.93003196]\n",
      "  [0.93260121]]]\n",
      "ejemplar: [0.90644598 0.91025108 0.91400379 0.91805249 0.92299503 0.92738962\n",
      " 0.93003196 0.93260121]\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.93378097]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[0.90644598 0.91025108 0.91400379 0.91805249 0.92299503 0.92738962\n",
      "  0.93003196 0.93260121]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.025368504226207733\n",
      "Predicción post entrenamiento : [[0.93143]]\n",
      "PERDIDAAAA despues: 0.024625126272439957\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "[[[0.91025108]\n",
      "  [0.91400379]\n",
      "  [0.91805249]\n",
      "  [0.92299503]\n",
      "  [0.92738962]\n",
      "  [0.93003196]\n",
      "  [0.93260121]\n",
      "  [0.93378097]]]\n",
      "ejemplar: [0.91025108 0.91400379 0.91805249 0.92299503 0.92738962 0.93003196\n",
      " 0.93260121 0.93378097]\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.9350647]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[0.91025108 0.91400379 0.91805249 0.92299503 0.92738962 0.93003196\n",
      "  0.93260121 0.93378097]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022762520238757133\n",
      "Predicción post entrenamiento : [[0.9350115]]\n",
      "PERDIDAAAA despues: 0.022746479138731956\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "[[[0.91400379]\n",
      "  [0.91805249]\n",
      "  [0.92299503]\n",
      "  [0.92738962]\n",
      "  [0.93003196]\n",
      "  [0.93260121]\n",
      "  [0.93378097]\n",
      "  [0.93506467]]]\n",
      "ejemplar: [0.91400379 0.91805249 0.92299503 0.92738962 0.93003196 0.93260121\n",
      " 0.93378097 0.93506467]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.93861103]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[0.91400379 0.91805249 0.92299503 0.92738962 0.93003196 0.93260121\n",
      "  0.93378097 0.93506467]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006219959352165461\n",
      "Predicción post entrenamiento : [[0.9380271]]\n",
      "PERDIDAAAA despues: 0.006128192413598299\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "[[[0.91805249]\n",
      "  [0.92299503]\n",
      "  [0.92738962]\n",
      "  [0.93003196]\n",
      "  [0.93260121]\n",
      "  [0.93378097]\n",
      "  [0.93506467]\n",
      "  [0.93861103]]]\n",
      "ejemplar: [0.91805249 0.92299503 0.92738962 0.93003196 0.93260121 0.93378097\n",
      " 0.93506467 0.93861103]\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.94154096]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[0.91805249 0.92299503 0.92738962 0.93003196 0.93260121 0.93378097\n",
      "  0.93506467 0.93861103]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007607486564666033\n",
      "Predicción post entrenamiento : [[0.9411604]]\n",
      "PERDIDAAAA despues: 0.007541242986917496\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "[[[0.92299503]\n",
      "  [0.92738962]\n",
      "  [0.93003196]\n",
      "  [0.93260121]\n",
      "  [0.93378097]\n",
      "  [0.93506467]\n",
      "  [0.93861103]\n",
      "  [0.94154096]]]\n",
      "ejemplar: [0.92299503 0.92738962 0.93003196 0.93260121 0.93378097 0.93506467\n",
      " 0.93861103 0.94154096]\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.9444249]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[0.92299503 0.92738962 0.93003196 0.93260121 0.93378097 0.93506467\n",
      "  0.93861103 0.94154096]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011564853601157665\n",
      "Predicción post entrenamiento : [[0.9430058]]\n",
      "PERDIDAAAA despues: 0.01126164197921753\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "[[[0.92738962]\n",
      "  [0.93003196]\n",
      "  [0.93260121]\n",
      "  [0.93378097]\n",
      "  [0.93506467]\n",
      "  [0.93861103]\n",
      "  [0.94154096]\n",
      "  [0.94442493]]]\n",
      "ejemplar: [0.92738962 0.93003196 0.93260121 0.93378097 0.93506467 0.93861103\n",
      " 0.94154096 0.94442493]\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.9456612]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[0.92738962 0.93003196 0.93260121 0.93378097 0.93506467 0.93861103\n",
      "  0.94154096 0.94442493]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01339813508093357\n",
      "Predicción post entrenamiento : [[0.94464636]]\n",
      "PERDIDAAAA despues: 0.013164231553673744\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "[[[0.93003196]\n",
      "  [0.93260121]\n",
      "  [0.93378097]\n",
      "  [0.93506467]\n",
      "  [0.93861103]\n",
      "  [0.94154096]\n",
      "  [0.94442493]\n",
      "  [0.94566119]]]\n",
      "ejemplar: [0.93003196 0.93260121 0.93378097 0.93506467 0.93861103 0.94154096\n",
      " 0.94442493 0.94566119]\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.9467427]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[0.93003196 0.93260121 0.93378097 0.93506467 0.93861103 0.94154096\n",
      "  0.94442493 0.94566119]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0035390276461839676\n",
      "Predicción post entrenamiento : [[0.9459923]]\n",
      "PERDIDAAAA despues: 0.003450305899605155\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "[[[0.93260121]\n",
      "  [0.93378097]\n",
      "  [0.93506467]\n",
      "  [0.93861103]\n",
      "  [0.94154096]\n",
      "  [0.94442493]\n",
      "  [0.94566119]\n",
      "  [0.94674271]]]\n",
      "ejemplar: [0.93260121 0.93378097 0.93506467 0.93861103 0.94154096 0.94442493\n",
      " 0.94566119 0.94674271]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.9479736]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[0.93260121 0.93378097 0.93506467 0.93861103 0.94154096 0.94442493\n",
      "  0.94566119 0.94674271]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007784408982843161\n",
      "Predicción post entrenamiento : [[0.9468948]]\n",
      "PERDIDAAAA despues: 0.007595212198793888\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "[[[0.93378097]\n",
      "  [0.93506467]\n",
      "  [0.93861103]\n",
      "  [0.94154096]\n",
      "  [0.94442493]\n",
      "  [0.94566119]\n",
      "  [0.94674271]\n",
      "  [0.94797361]]]\n",
      "ejemplar: [0.93378097 0.93506467 0.93861103 0.94154096 0.94442493 0.94566119\n",
      " 0.94674271 0.94797361]\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.94875705]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[0.93378097 0.93506467 0.93861103 0.94154096 0.94442493 0.94566119\n",
      "  0.94674271 0.94797361]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011915907263755798\n",
      "Predicción post entrenamiento : [[0.94810516]]\n",
      "PERDIDAAAA despues: 0.01177401002496481\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "[[[0.93506467]\n",
      "  [0.93861103]\n",
      "  [0.94154096]\n",
      "  [0.94442493]\n",
      "  [0.94566119]\n",
      "  [0.94674271]\n",
      "  [0.94797361]\n",
      "  [0.94875705]]]\n",
      "ejemplar: [0.93506467 0.93861103 0.94154096 0.94442493 0.94566119 0.94674271\n",
      " 0.94797361 0.94875705]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.9502391]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[0.93506467 0.93861103 0.94154096 0.94442493 0.94566119 0.94674271\n",
      "  0.94797361 0.94875705]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.027700411155819893\n",
      "Predicción post entrenamiento : [[0.9486208]]\n",
      "PERDIDAAAA despues: 0.027164340019226074\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "[[[0.93861103]\n",
      "  [0.94154096]\n",
      "  [0.94442493]\n",
      "  [0.94566119]\n",
      "  [0.94674271]\n",
      "  [0.94797361]\n",
      "  [0.94875705]\n",
      "  [0.95023912]]]\n",
      "ejemplar: [0.93861103 0.94154096 0.94442493 0.94566119 0.94674271 0.94797361\n",
      " 0.94875705 0.95023912]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.95099837]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[0.93861103 0.94154096 0.94442493 0.94566119 0.94674271 0.94797361\n",
      "  0.94875705 0.95023912]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01761217601597309\n",
      "Predicción post entrenamiento : [[0.9508229]]\n",
      "PERDIDAAAA despues: 0.017565632238984108\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "[[[0.94154096]\n",
      "  [0.94442493]\n",
      "  [0.94566119]\n",
      "  [0.94674271]\n",
      "  [0.94797361]\n",
      "  [0.94875705]\n",
      "  [0.95023912]\n",
      "  [0.95099837]]]\n",
      "ejemplar: [0.94154096 0.94442493 0.94566119 0.94674271 0.94797361 0.94875705\n",
      " 0.95023912 0.95099837]\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.9527331]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[0.94154096 0.94442493 0.94566119 0.94674271 0.94797361 0.94875705\n",
      "  0.95023912 0.95099837]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02610386721789837\n",
      "Predicción post entrenamiento : [[0.9499273]]\n",
      "PERDIDAAAA despues: 0.025205081328749657\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "[[[0.94442493]\n",
      "  [0.94566119]\n",
      "  [0.94674271]\n",
      "  [0.94797361]\n",
      "  [0.94875705]\n",
      "  [0.95023912]\n",
      "  [0.95099837]\n",
      "  [0.9527331 ]]]\n",
      "ejemplar: [0.94442493 0.94566119 0.94674271 0.94797361 0.94875705 0.95023912\n",
      " 0.95099837 0.9527331 ]\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.95144504]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[0.94442493 0.94566119 0.94674271 0.94797361 0.94875705 0.95023912\n",
      "  0.95099837 0.9527331 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03643788397312164\n",
      "Predicción post entrenamiento : [[0.9512565]]\n",
      "PERDIDAAAA despues: 0.03636594116687775\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "[[[0.94566119]\n",
      "  [0.94674271]\n",
      "  [0.94797361]\n",
      "  [0.94875705]\n",
      "  [0.95023912]\n",
      "  [0.95099837]\n",
      "  [0.9527331 ]\n",
      "  [0.95144504]]]\n",
      "ejemplar: [0.94566119 0.94674271 0.94797361 0.94875705 0.95023912 0.95099837\n",
      " 0.9527331  0.95144504]\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.95230144]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[0.94566119 0.94674271 0.94797361 0.94875705 0.95023912 0.95099837\n",
      "  0.9527331  0.95144504]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.025839844718575478\n",
      "Predicción post entrenamiento : [[0.95150244]]\n",
      "PERDIDAAAA despues: 0.025583608075976372\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "[[[0.94674271]\n",
      "  [0.94797361]\n",
      "  [0.94875705]\n",
      "  [0.95023912]\n",
      "  [0.95099837]\n",
      "  [0.9527331 ]\n",
      "  [0.95144504]\n",
      "  [0.95230144]]]\n",
      "ejemplar: [0.94674271 0.94797361 0.94875705 0.95023912 0.95099837 0.9527331\n",
      " 0.95144504 0.95230144]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9524852]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[0.94674271 0.94797361 0.94875705 0.95023912 0.95099837 0.9527331\n",
      "  0.95144504 0.95230144]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03377910330891609\n",
      "Predicción post entrenamiento : [[0.95153517]]\n",
      "PERDIDAAAA despues: 0.0334307886660099\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "[[[0.94797361]\n",
      "  [0.94875705]\n",
      "  [0.95023912]\n",
      "  [0.95099837]\n",
      "  [0.9527331 ]\n",
      "  [0.95144504]\n",
      "  [0.95230144]\n",
      "  [0.9524852 ]]]\n",
      "ejemplar: [0.94797361 0.94875705 0.95023912 0.95099837 0.9527331  0.95144504\n",
      " 0.95230144 0.9524852 ]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.95247036]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[0.94797361 0.94875705 0.95023912 0.95099837 0.9527331  0.95144504\n",
      "  0.95230144 0.9524852 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.033773649483919144\n",
      "Predicción post entrenamiento : [[0.9514742]]\n",
      "PERDIDAAAA despues: 0.03340849652886391\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "[[[0.94875705]\n",
      "  [0.95023912]\n",
      "  [0.95099837]\n",
      "  [0.9527331 ]\n",
      "  [0.95144504]\n",
      "  [0.95230144]\n",
      "  [0.9524852 ]\n",
      "  [0.95247036]]]\n",
      "ejemplar: [0.94875705 0.95023912 0.95099837 0.9527331  0.95144504 0.95230144\n",
      " 0.9524852  0.95247036]\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.95228124]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[0.94875705 0.95023912 0.95099837 0.9527331  0.95144504 0.95230144\n",
      "  0.9524852  0.95247036]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02352115698158741\n",
      "Predicción post entrenamiento : [[0.95244855]]\n",
      "PERDIDAAAA despues: 0.02357250452041626\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "[[[0.95023912]\n",
      "  [0.95099837]\n",
      "  [0.9527331 ]\n",
      "  [0.95144504]\n",
      "  [0.95230144]\n",
      "  [0.9524852 ]\n",
      "  [0.95247036]\n",
      "  [0.95228124]]]\n",
      "ejemplar: [0.95023912 0.95099837 0.9527331  0.95144504 0.95230144 0.9524852\n",
      " 0.95247036 0.95228124]\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.95321506]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[0.95023912 0.95099837 0.9527331  0.95144504 0.95230144 0.9524852\n",
      "  0.95247036 0.95228124]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.026637885719537735\n",
      "Predicción post entrenamiento : [[0.9503208]]\n",
      "PERDIDAAAA despues: 0.025701504200696945\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "[[[0.95099837]\n",
      "  [0.9527331 ]\n",
      "  [0.95144504]\n",
      "  [0.95230144]\n",
      "  [0.9524852 ]\n",
      "  [0.95247036]\n",
      "  [0.95228124]\n",
      "  [0.95321506]]]\n",
      "ejemplar: [0.95099837 0.9527331  0.95144504 0.95230144 0.9524852  0.95247036\n",
      " 0.95228124 0.95321506]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.9507998]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[0.95099837 0.9527331  0.95144504 0.95230144 0.9524852  0.95247036\n",
      "  0.95228124 0.95321506]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03633955493569374\n",
      "Predicción post entrenamiento : [[0.9488788]]\n",
      "PERDIDAAAA despues: 0.03561084717512131\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "[[[0.9527331 ]\n",
      "  [0.95144504]\n",
      "  [0.95230144]\n",
      "  [0.9524852 ]\n",
      "  [0.95247036]\n",
      "  [0.95228124]\n",
      "  [0.95321506]\n",
      "  [0.95079982]]]\n",
      "ejemplar: [0.9527331  0.95144504 0.95230144 0.9524852  0.95247036 0.95228124\n",
      " 0.95321506 0.95079982]\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.94921756]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[0.9527331  0.95144504 0.95230144 0.9524852  0.95247036 0.95228124\n",
      "  0.95321506 0.95079982]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06960324943065643\n",
      "Predicción post entrenamiento : [[0.9485153]]\n",
      "PERDIDAAAA despues: 0.06923320144414902\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "[[[0.95144504]\n",
      "  [0.95230144]\n",
      "  [0.9524852 ]\n",
      "  [0.95247036]\n",
      "  [0.95228124]\n",
      "  [0.95321506]\n",
      "  [0.95079982]\n",
      "  [0.94921756]]]\n",
      "ejemplar: [0.95144504 0.95230144 0.9524852  0.95247036 0.95228124 0.95321506\n",
      " 0.95079982 0.94921756]\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.9483584]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[0.95144504 0.95230144 0.9524852  0.95247036 0.95228124 0.95321506\n",
      "  0.95079982 0.94921756]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11776334792375565\n",
      "Predicción post entrenamiento : [[0.9471341]]\n",
      "PERDIDAAAA despues: 0.11692454665899277\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "[[[0.95230144]\n",
      "  [0.9524852 ]\n",
      "  [0.95247036]\n",
      "  [0.95228124]\n",
      "  [0.95321506]\n",
      "  [0.95079982]\n",
      "  [0.94921756]\n",
      "  [0.94835842]]]\n",
      "ejemplar: [0.95230144 0.9524852  0.95247036 0.95228124 0.95321506 0.95079982\n",
      " 0.94921756 0.94835842]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.9472998]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[0.95230144 0.9524852  0.95247036 0.95228124 0.95321506 0.95079982\n",
      "  0.94921756 0.94835842]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07977303117513657\n",
      "Predicción post entrenamiento : [[0.94535863]]\n",
      "PERDIDAAAA despues: 0.07868027687072754\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "[[[0.9524852 ]\n",
      "  [0.95247036]\n",
      "  [0.95228124]\n",
      "  [0.95321506]\n",
      "  [0.95079982]\n",
      "  [0.94921756]\n",
      "  [0.94835842]\n",
      "  [0.94729978]]]\n",
      "ejemplar: [0.9524852  0.95247036 0.95228124 0.95321506 0.95079982 0.94921756\n",
      " 0.94835842 0.94729978]\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.9451972]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[0.9524852  0.95247036 0.95228124 0.95321506 0.95079982 0.94921756\n",
      "  0.94835842 0.94729978]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.056326501071453094\n",
      "Predicción post entrenamiento : [[0.94447404]]\n",
      "PERDIDAAAA despues: 0.055983755737543106\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "[[[0.95247036]\n",
      "  [0.95228124]\n",
      "  [0.95321506]\n",
      "  [0.95079982]\n",
      "  [0.94921756]\n",
      "  [0.94835842]\n",
      "  [0.94729978]\n",
      "  [0.94519722]]]\n",
      "ejemplar: [0.95247036 0.95228124 0.95321506 0.95079982 0.94921756 0.94835842\n",
      " 0.94729978 0.94519722]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.94409424]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[0.95247036 0.95228124 0.95321506 0.95079982 0.94921756 0.94835842\n",
      "  0.94729978 0.94519722]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07797255367040634\n",
      "Predicción post entrenamiento : [[0.94221675]]\n",
      "PERDIDAAAA despues: 0.0769275575876236\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "[[[0.95228124]\n",
      "  [0.95321506]\n",
      "  [0.95079982]\n",
      "  [0.94921756]\n",
      "  [0.94835842]\n",
      "  [0.94729978]\n",
      "  [0.94519722]\n",
      "  [0.94409424]]]\n",
      "ejemplar: [0.95228124 0.95321506 0.95079982 0.94921756 0.94835842 0.94729978\n",
      " 0.94519722 0.94409424]\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.94160545]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[0.95228124 0.95321506 0.95079982 0.94921756 0.94835842 0.94729978\n",
      "  0.94519722 0.94409424]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05301657319068909\n",
      "Predicción post entrenamiento : [[0.9407656]]\n",
      "PERDIDAAAA despues: 0.052630532532930374\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "[[[0.95321506]\n",
      "  [0.95079982]\n",
      "  [0.94921756]\n",
      "  [0.94835842]\n",
      "  [0.94729978]\n",
      "  [0.94519722]\n",
      "  [0.94409424]\n",
      "  [0.94160545]]]\n",
      "ejemplar: [0.95321506 0.95079982 0.94921756 0.94835842 0.94729978 0.94519722\n",
      " 0.94409424 0.94160545]\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.939902]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[0.95321506 0.95079982 0.94921756 0.94835842 0.94729978 0.94519722\n",
      "  0.94409424 0.94160545]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06898245960474014\n",
      "Predicción post entrenamiento : [[0.9392373]]\n",
      "PERDIDAAAA despues: 0.06863373517990112\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "[[[0.95079982]\n",
      "  [0.94921756]\n",
      "  [0.94835842]\n",
      "  [0.94729978]\n",
      "  [0.94519722]\n",
      "  [0.94409424]\n",
      "  [0.94160545]\n",
      "  [0.93990201]]]\n",
      "ejemplar: [0.95079982 0.94921756 0.94835842 0.94729978 0.94519722 0.94409424\n",
      " 0.94160545 0.93990201]\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.9377113]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[0.95079982 0.94921756 0.94835842 0.94729978 0.94519722 0.94409424\n",
      "  0.94160545 0.93990201]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.030836613848805428\n",
      "Predicción post entrenamiento : [[0.93643594]]\n",
      "PERDIDAAAA despues: 0.03039032407104969\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "[[[0.94921756]\n",
      "  [0.94835842]\n",
      "  [0.94729978]\n",
      "  [0.94519722]\n",
      "  [0.94409424]\n",
      "  [0.94160545]\n",
      "  [0.93990201]\n",
      "  [0.9377113 ]]]\n",
      "ejemplar: [0.94921756 0.94835842 0.94729978 0.94519722 0.94409424 0.94160545\n",
      " 0.93990201 0.9377113 ]\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.9351552]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[0.94921756 0.94835842 0.94729978 0.94519722 0.94409424 0.94160545\n",
      "  0.93990201 0.9377113 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016410551965236664\n",
      "Predicción post entrenamiento : [[0.93514574]]\n",
      "PERDIDAAAA despues: 0.016408123075962067\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "[[[0.94835842]\n",
      "  [0.94729978]\n",
      "  [0.94519722]\n",
      "  [0.94409424]\n",
      "  [0.94160545]\n",
      "  [0.93990201]\n",
      "  [0.9377113 ]\n",
      "  [0.93515521]]]\n",
      "ejemplar: [0.94835842 0.94729978 0.94519722 0.94409424 0.94160545 0.93990201\n",
      " 0.9377113  0.93515521]\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.9338712]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[0.94835842 0.94729978 0.94519722 0.94409424 0.94160545 0.93990201\n",
      "  0.9377113  0.93515521]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014085720293223858\n",
      "Predicción post entrenamiento : [[0.93267334]]\n",
      "PERDIDAAAA despues: 0.013802819885313511\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "[[[0.94729978]\n",
      "  [0.94519722]\n",
      "  [0.94409424]\n",
      "  [0.94160545]\n",
      "  [0.93990201]\n",
      "  [0.9377113 ]\n",
      "  [0.93515521]\n",
      "  [0.93387121]]]\n",
      "ejemplar: [0.94729978 0.94519722 0.94409424 0.94160545 0.93990201 0.9377113\n",
      " 0.93515521 0.93387121]\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.9311624]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[0.94729978 0.94519722 0.94409424 0.94160545 0.93990201 0.9377113\n",
      "  0.93515521 0.93387121]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006212315056473017\n",
      "Predicción post entrenamiento : [[0.9310002]]\n",
      "PERDIDAAAA despues: 0.0006131701520644128\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "[[[0.94519722]\n",
      "  [0.94409424]\n",
      "  [0.94160545]\n",
      "  [0.93990201]\n",
      "  [0.9377113 ]\n",
      "  [0.93515521]\n",
      "  [0.93387121]\n",
      "  [0.93116242]]]\n",
      "ejemplar: [0.94519722 0.94409424 0.94160545 0.93990201 0.9377113  0.93515521\n",
      " 0.93387121 0.93116242]\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.92925775]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[0.94519722 0.94409424 0.94160545 0.93990201 0.9377113  0.93515521\n",
      "  0.93387121 0.93116242]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009270673617720604\n",
      "Predicción post entrenamiento : [[0.9295449]]\n",
      "PERDIDAAAA despues: 0.0009096621652133763\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "[[[0.94409424]\n",
      "  [0.94160545]\n",
      "  [0.93990201]\n",
      "  [0.9377113 ]\n",
      "  [0.93515521]\n",
      "  [0.93387121]\n",
      "  [0.93116242]\n",
      "  [0.92925775]]]\n",
      "ejemplar: [0.94409424 0.94160545 0.93990201 0.9377113  0.93515521 0.93387121\n",
      " 0.93116242 0.92925775]\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.92784184]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[0.94409424 0.94160545 0.93990201 0.9377113  0.93515521 0.93387121\n",
      "  0.93116242 0.92925775]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001333201420493424\n",
      "Predicción post entrenamiento : [[0.9277956]]\n",
      "PERDIDAAAA despues: 0.0013365811901167035\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "[[[0.94160545]\n",
      "  [0.93990201]\n",
      "  [0.9377113 ]\n",
      "  [0.93515521]\n",
      "  [0.93387121]\n",
      "  [0.93116242]\n",
      "  [0.92925775]\n",
      "  [0.92784184]]]\n",
      "ejemplar: [0.94160545 0.93990201 0.9377113  0.93515521 0.93387121 0.93116242\n",
      " 0.92925775 0.92784184]\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.92583025]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[0.94160545 0.93990201 0.9377113  0.93515521 0.93387121 0.93116242\n",
      "  0.92925775 0.92784184]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001429016818292439\n",
      "Predicción post entrenamiento : [[0.92533714]]\n",
      "PERDIDAAAA despues: 0.0013919785851612687\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "[[[0.93990201]\n",
      "  [0.9377113 ]\n",
      "  [0.93515521]\n",
      "  [0.93387121]\n",
      "  [0.93116242]\n",
      "  [0.92925775]\n",
      "  [0.92784184]\n",
      "  [0.92583025]]]\n",
      "ejemplar: [0.93990201 0.9377113  0.93515521 0.93387121 0.93116242 0.92925775\n",
      " 0.92784184 0.92583025]\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.92349523]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[0.93990201 0.9377113  0.93515521 0.93387121 0.93116242 0.92925775\n",
      "  0.92784184 0.92583025]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009497482096776366\n",
      "Predicción post entrenamiento : [[0.923482]]\n",
      "PERDIDAAAA despues: 0.0009489328367635608\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "[[[0.9377113 ]\n",
      "  [0.93515521]\n",
      "  [0.93387121]\n",
      "  [0.93116242]\n",
      "  [0.92925775]\n",
      "  [0.92784184]\n",
      "  [0.92583025]\n",
      "  [0.92349523]]]\n",
      "ejemplar: [0.9377113  0.93515521 0.93387121 0.93116242 0.92925775 0.92784184\n",
      " 0.92583025 0.92349523]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.921547]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[0.9377113  0.93515521 0.93387121 0.93116242 0.92925775 0.92784184\n",
      "  0.92583025 0.92349523]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002144136466085911\n",
      "Predicción post entrenamiento : [[0.92137665]]\n",
      "PERDIDAAAA despues: 0.0021283894311636686\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "[[[0.93515521]\n",
      "  [0.93387121]\n",
      "  [0.93116242]\n",
      "  [0.92925775]\n",
      "  [0.92784184]\n",
      "  [0.92583025]\n",
      "  [0.92349523]\n",
      "  [0.921547  ]]]\n",
      "ejemplar: [0.93515521 0.93387121 0.93116242 0.92925775 0.92784184 0.92583025\n",
      " 0.92349523 0.921547  ]\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.91948676]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[0.93515521 0.93387121 0.93116242 0.92925775 0.92784184 0.92583025\n",
      "  0.92349523 0.921547  ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004713339265435934\n",
      "Predicción post entrenamiento : [[0.9197316]]\n",
      "PERDIDAAAA despues: 0.004747019615024328\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "[[[0.93387121]\n",
      "  [0.93116242]\n",
      "  [0.92925775]\n",
      "  [0.92784184]\n",
      "  [0.92583025]\n",
      "  [0.92349523]\n",
      "  [0.921547  ]\n",
      "  [0.91948676]]]\n",
      "ejemplar: [0.93387121 0.93116242 0.92925775 0.92784184 0.92583025 0.92349523\n",
      " 0.921547   0.91948676]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.91800636]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[0.93387121 0.93116242 0.92925775 0.92784184 0.92583025 0.92349523\n",
      "  0.921547   0.91948676]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0047762710601091385\n",
      "Predicción post entrenamiento : [[0.91699815]]\n",
      "PERDIDAAAA despues: 0.004637931473553181\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "[[[0.93116242]\n",
      "  [0.92925775]\n",
      "  [0.92784184]\n",
      "  [0.92583025]\n",
      "  [0.92349523]\n",
      "  [0.921547  ]\n",
      "  [0.91948676]\n",
      "  [0.91800636]]]\n",
      "ejemplar: [0.93116242 0.92925775 0.92784184 0.92583025 0.92349523 0.921547\n",
      " 0.91948676 0.91800636]\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.91507816]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[0.93116242 0.92925775 0.92784184 0.92583025 0.92349523 0.921547\n",
      "  0.91948676 0.91800636]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0022410282399505377\n",
      "Predicción post entrenamiento : [[0.9148421]]\n",
      "PERDIDAAAA despues: 0.0022634314373135567\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "[[[0.92925775]\n",
      "  [0.92784184]\n",
      "  [0.92583025]\n",
      "  [0.92349523]\n",
      "  [0.921547  ]\n",
      "  [0.91948676]\n",
      "  [0.91800636]\n",
      "  [0.91507816]]]\n",
      "ejemplar: [0.92925775 0.92784184 0.92583025 0.92349523 0.921547   0.91948676\n",
      " 0.91800636 0.91507816]\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.91312784]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[0.92925775 0.92784184 0.92583025 0.92349523 0.921547   0.91948676\n",
      "  0.91800636 0.91507816]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029936309438198805\n",
      "Predicción post entrenamiento : [[0.9126782]]\n",
      "PERDIDAAAA despues: 0.0030430383048951626\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "[[[0.92784184]\n",
      "  [0.92583025]\n",
      "  [0.92349523]\n",
      "  [0.921547  ]\n",
      "  [0.91948676]\n",
      "  [0.91800636]\n",
      "  [0.91507816]\n",
      "  [0.91312784]]]\n",
      "ejemplar: [0.92784184 0.92583025 0.92349523 0.921547   0.91948676 0.91800636\n",
      " 0.91507816 0.91312784]\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.91095006]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[0.92784184 0.92583025 0.92349523 0.921547   0.91948676 0.91800636\n",
      "  0.91507816 0.91312784]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0008862894028425217\n",
      "Predicción post entrenamiento : [[0.91055655]]\n",
      "PERDIDAAAA despues: 0.000909874273929745\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "[[[0.92583025]\n",
      "  [0.92349523]\n",
      "  [0.921547  ]\n",
      "  [0.91948676]\n",
      "  [0.91800636]\n",
      "  [0.91507816]\n",
      "  [0.91312784]\n",
      "  [0.91095006]]]\n",
      "ejemplar: [0.92583025 0.92349523 0.921547   0.91948676 0.91800636 0.91507816\n",
      " 0.91312784 0.91095006]\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.9086548]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[0.92583025 0.92349523 0.921547   0.91948676 0.91800636 0.91507816\n",
      "  0.91312784 0.91095006]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0040750931948423386\n",
      "Predicción post entrenamiento : [[0.909776]]\n",
      "PERDIDAAAA despues: 0.00393320806324482\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "[[[0.92349523]\n",
      "  [0.921547  ]\n",
      "  [0.91948676]\n",
      "  [0.91800636]\n",
      "  [0.91507816]\n",
      "  [0.91312784]\n",
      "  [0.91095006]\n",
      "  [0.90865481]]]\n",
      "ejemplar: [0.92349523 0.921547   0.91948676 0.91800636 0.91507816 0.91312784\n",
      " 0.91095006 0.90865481]\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.9078481]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[0.92349523 0.921547   0.91948676 0.91800636 0.91507816 0.91312784\n",
      "  0.91095006 0.90865481]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007930316030979156\n",
      "Predicción post entrenamiento : [[0.9080687]]\n",
      "PERDIDAAAA despues: 0.007891074754297733\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "[[[0.921547  ]\n",
      "  [0.91948676]\n",
      "  [0.91800636]\n",
      "  [0.91507816]\n",
      "  [0.91312784]\n",
      "  [0.91095006]\n",
      "  [0.90865481]\n",
      "  [0.90784812]]]\n",
      "ejemplar: [0.921547   0.91948676 0.91800636 0.91507816 0.91312784 0.91095006\n",
      " 0.90865481 0.90784812]\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.9062141]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[0.921547   0.91948676 0.91800636 0.91507816 0.91312784 0.91095006\n",
      "  0.90865481 0.90784812]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002022084314376116\n",
      "Predicción post entrenamiento : [[0.90625083]]\n",
      "PERDIDAAAA despues: 0.002018783474341035\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "[[[0.91948676]\n",
      "  [0.91800636]\n",
      "  [0.91507816]\n",
      "  [0.91312784]\n",
      "  [0.91095006]\n",
      "  [0.90865481]\n",
      "  [0.90784812]\n",
      "  [0.90621412]]]\n",
      "ejemplar: [0.91948676 0.91800636 0.91507816 0.91312784 0.91095006 0.90865481\n",
      " 0.90784812 0.90621412]\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.9043709]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[0.91948676 0.91800636 0.91507816 0.91312784 0.91095006 0.90865481\n",
      "  0.90784812 0.90621412]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.385847857221961e-05\n",
      "Predicción post entrenamiento : [[0.90418136]]\n",
      "PERDIDAAAA despues: 7.063650991767645e-05\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "[[[0.91800636]\n",
      "  [0.91507816]\n",
      "  [0.91312784]\n",
      "  [0.91095006]\n",
      "  [0.90865481]\n",
      "  [0.90784812]\n",
      "  [0.90621412]\n",
      "  [0.9043709 ]]]\n",
      "ejemplar: [0.91800636 0.91507816 0.91312784 0.91095006 0.90865481 0.90784812\n",
      " 0.90621412 0.9043709 ]\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.9023174]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[0.91800636 0.91507816 0.91312784 0.91095006 0.90865481 0.90784812\n",
      "  0.90621412 0.9043709 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0004358119622338563\n",
      "Predicción post entrenamiento : [[0.90274954]]\n",
      "PERDIDAAAA despues: 0.00045404123375192285\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "[[[0.91507816]\n",
      "  [0.91312784]\n",
      "  [0.91095006]\n",
      "  [0.90865481]\n",
      "  [0.90784812]\n",
      "  [0.90621412]\n",
      "  [0.9043709 ]\n",
      "  [0.9023174 ]]]\n",
      "ejemplar: [0.91507816 0.91312784 0.91095006 0.90865481 0.90784812 0.90621412\n",
      " 0.9043709  0.9023174 ]\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.90074176]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[0.91507816 0.91312784 0.91095006 0.90865481 0.90784812 0.90621412\n",
      "  0.9043709  0.9023174 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002671481342986226\n",
      "Predicción post entrenamiento : [[0.90026414]]\n",
      "PERDIDAAAA despues: 0.0002829890581779182\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "[[[0.91312784]\n",
      "  [0.91095006]\n",
      "  [0.90865481]\n",
      "  [0.90784812]\n",
      "  [0.90621412]\n",
      "  [0.9043709 ]\n",
      "  [0.9023174 ]\n",
      "  [0.90074176]]]\n",
      "ejemplar: [0.91312784 0.91095006 0.90865481 0.90784812 0.90621412 0.9043709\n",
      " 0.9023174  0.90074176]\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.8985463]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[0.91312784 0.91095006 0.90865481 0.90784812 0.90621412 0.9043709\n",
      "  0.9023174  0.90074176]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00045165917254053056\n",
      "Predicción post entrenamiento : [[0.8981625]]\n",
      "PERDIDAAAA despues: 0.00046811948413960636\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "[[[0.91095006]\n",
      "  [0.90865481]\n",
      "  [0.90784812]\n",
      "  [0.90621412]\n",
      "  [0.9043709 ]\n",
      "  [0.9023174 ]\n",
      "  [0.90074176]\n",
      "  [0.89854628]]]\n",
      "ejemplar: [0.91095006 0.90865481 0.90784812 0.90621412 0.9043709  0.9023174\n",
      " 0.90074176 0.89854628]\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.8964895]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[0.91095006 0.90865481 0.90784812 0.90621412 0.9043709  0.9023174\n",
      "  0.90074176 0.89854628]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004244952462613583\n",
      "Predicción post entrenamiento : [[0.8966423]]\n",
      "PERDIDAAAA despues: 0.0042250617407262325\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "[[[0.90865481]\n",
      "  [0.90784812]\n",
      "  [0.90621412]\n",
      "  [0.9043709 ]\n",
      "  [0.9023174 ]\n",
      "  [0.90074176]\n",
      "  [0.89854628]\n",
      "  [0.8964895 ]]]\n",
      "ejemplar: [0.90865481 0.90784812 0.90621412 0.9043709  0.9023174  0.90074176\n",
      " 0.89854628 0.8964895 ]\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.89508784]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[0.90865481 0.90784812 0.90621412 0.9043709  0.9023174  0.90074176\n",
      "  0.89854628 0.8964895 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005349681247025728\n",
      "Predicción post entrenamiento : [[0.8943616]]\n",
      "PERDIDAAAA despues: 0.005456442944705486\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "[[[0.90784812]\n",
      "  [0.90621412]\n",
      "  [0.9043709 ]\n",
      "  [0.9023174 ]\n",
      "  [0.90074176]\n",
      "  [0.89854628]\n",
      "  [0.8964895 ]\n",
      "  [0.89508784]]]\n",
      "ejemplar: [0.90784812 0.90621412 0.9043709  0.9023174  0.90074176 0.89854628\n",
      " 0.8964895  0.89508784]\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.8929738]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[0.90784812 0.90621412 0.9043709  0.9023174  0.90074176 0.89854628\n",
      "  0.8964895  0.89508784]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004198332317173481\n",
      "Predicción post entrenamiento : [[0.89338285]]\n",
      "PERDIDAAAA despues: 0.004145489074289799\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n",
      "0\n",
      "[[[0.12010849]\n",
      "  [0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]]]\n",
      "ejemplar: [0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      " 0.03448276 0.04223169]\n",
      "y: 0.04610616040294452\n",
      "Predicción : [[0.21939534]]\n",
      "Lr que voy a aplicar en el lote: 1 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.12010849 0.01975978 0.         0.01859744 0.05656722 0.02595893\n",
      "  0.03448276 0.04223169]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.030029140412807465\n",
      "Predicción post entrenamiento : [[0.18792008]]\n",
      "PERDIDAAAA despues: 0.020111188292503357\n",
      "lr: 0.01, batch: 1\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "1\n",
      "[[[0.01975978]\n",
      "  [0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21939534]]]\n",
      "ejemplar: [0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      " 0.04223169 0.21939534]\n",
      "y: 0.10422316931421921\n",
      "Predicción : [[0.17186661]]\n",
      "Lr que voy a aplicar en el lote: 2 es 0.009999999776482582\n",
      "lote que voy a entrenar: [[0.01975978 0.         0.01859744 0.05656722 0.02595893 0.03448276\n",
      "  0.04223169 0.21939534]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004575635306537151\n",
      "Predicción post entrenamiento : [[0.15929498]]\n",
      "PERDIDAAAA despues: 0.0030329041182994843\n",
      "lr: 0.006666666666666667, batch: 2\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "2\n",
      "[[[0.        ]\n",
      "  [0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21939534]\n",
      "  [0.17186661]]]\n",
      "ejemplar: [0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      " 0.21939534 0.17186661]\n",
      "y: 0.15420379697791559\n",
      "Predicción : [[0.16303825]]\n",
      "Lr que voy a aplicar en el lote: 3 es 0.006666666828095913\n",
      "lote que voy a entrenar: [[0.         0.01859744 0.05656722 0.02595893 0.03448276 0.04223169\n",
      "  0.21939534 0.17186661]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 7.804753113305196e-05\n",
      "Predicción post entrenamiento : [[0.1608893]]\n",
      "PERDIDAAAA despues: 4.469584746402688e-05\n",
      "lr: 0.005, batch: 3\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "3\n",
      "[[[0.01859744]\n",
      "  [0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21939534]\n",
      "  [0.17186661]\n",
      "  [0.16303825]]]\n",
      "ejemplar: [0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.21939534\n",
      " 0.17186661 0.16303825]\n",
      "y: 0.1557535838822161\n",
      "Predicción : [[0.17182736]]\n",
      "Lr que voy a aplicar en el lote: 4 es 0.004999999888241291\n",
      "lote que voy a entrenar: [[0.01859744 0.05656722 0.02595893 0.03448276 0.04223169 0.21939534\n",
      "  0.17186661 0.16303825]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0002583663444966078\n",
      "Predicción post entrenamiento : [[0.17060792]]\n",
      "PERDIDAAAA despues: 0.00022065146185923368\n",
      "lr: 0.004, batch: 4\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "4\n",
      "[[[0.05656722]\n",
      "  [0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21939534]\n",
      "  [0.17186661]\n",
      "  [0.16303825]\n",
      "  [0.17182736]]]\n",
      "ejemplar: [0.05656722 0.02595893 0.03448276 0.04223169 0.21939534 0.17186661\n",
      " 0.16303825 0.17182736]\n",
      "y: 0.12553273924835334\n",
      "Predicción : [[0.18227002]]\n",
      "Lr que voy a aplicar en el lote: 5 es 0.004000000189989805\n",
      "lote que voy a entrenar: [[0.05656722 0.02595893 0.03448276 0.04223169 0.21939534 0.17186661\n",
      "  0.16303825 0.17182736]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0032191183418035507\n",
      "Predicción post entrenamiento : [[0.17815067]]\n",
      "PERDIDAAAA despues: 0.0027686457615345716\n",
      "lr: 0.0033333333333333335, batch: 5\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "5\n",
      "[[[0.02595893]\n",
      "  [0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21939534]\n",
      "  [0.17186661]\n",
      "  [0.16303825]\n",
      "  [0.17182736]\n",
      "  [0.18227002]]]\n",
      "ejemplar: [0.02595893 0.03448276 0.04223169 0.21939534 0.17186661 0.16303825\n",
      " 0.17182736 0.18227002]\n",
      "y: 0.1456799690042619\n",
      "Predicción : [[0.18644458]]\n",
      "Lr que voy a aplicar en el lote: 6 es 0.0033333334140479565\n",
      "lote que voy a entrenar: [[0.02595893 0.03448276 0.04223169 0.21939534 0.17186661 0.16303825\n",
      "  0.17182736 0.18227002]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016617538640275598\n",
      "Predicción post entrenamiento : [[0.18499511]]\n",
      "PERDIDAAAA despues: 0.001545680919662118\n",
      "lr: 0.002857142857142857, batch: 6\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "6\n",
      "[[[0.03448276]\n",
      "  [0.04223169]\n",
      "  [0.21939534]\n",
      "  [0.17186661]\n",
      "  [0.16303825]\n",
      "  [0.17182736]\n",
      "  [0.18227002]\n",
      "  [0.18644458]]]\n",
      "ejemplar: [0.03448276 0.04223169 0.21939534 0.17186661 0.16303825 0.17182736\n",
      " 0.18227002 0.18644458]\n",
      "y: 0.1464548624564122\n",
      "Predicción : [[0.20387673]]\n",
      "Lr que voy a aplicar en el lote: 7 es 0.0028571428265422583\n",
      "lote que voy a entrenar: [[0.03448276 0.04223169 0.21939534 0.17186661 0.16303825 0.17182736\n",
      "  0.18227002 0.18644458]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003297272138297558\n",
      "Predicción post entrenamiento : [[0.20047404]]\n",
      "PERDIDAAAA despues: 0.0029180720448493958\n",
      "lr: 0.0025, batch: 7\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "7\n",
      "[[[0.04223169]\n",
      "  [0.21939534]\n",
      "  [0.17186661]\n",
      "  [0.16303825]\n",
      "  [0.17182736]\n",
      "  [0.18227002]\n",
      "  [0.18644458]\n",
      "  [0.20387673]]]\n",
      "ejemplar: [0.04223169 0.21939534 0.17186661 0.16303825 0.17182736 0.18227002\n",
      " 0.18644458 0.20387673]\n",
      "y: 0.1960480433940332\n",
      "Predicción : [[0.22320403]]\n",
      "Lr que voy a aplicar en el lote: 8 es 0.0024999999441206455\n",
      "lote que voy a entrenar: [[0.04223169 0.21939534 0.17186661 0.16303825 0.17182736 0.18227002\n",
      "  0.18644458 0.20387673]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007374481065198779\n",
      "Predicción post entrenamiento : [[0.22082031]]\n",
      "PERDIDAAAA despues: 0.0006136654410511255\n",
      "lr: 0.0022222222222222222, batch: 8\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "8\n",
      "[[[0.21939534]\n",
      "  [0.17186661]\n",
      "  [0.16303825]\n",
      "  [0.17182736]\n",
      "  [0.18227002]\n",
      "  [0.18644458]\n",
      "  [0.20387673]\n",
      "  [0.22320403]]]\n",
      "ejemplar: [0.21939534 0.17186661 0.16303825 0.17182736 0.18227002 0.18644458\n",
      " 0.20387673 0.22320403]\n",
      "y: 0.23053080201472292\n",
      "Predicción : [[0.2477278]]\n",
      "Lr que voy a aplicar en el lote: 9 es 0.002222222276031971\n",
      "lote que voy a entrenar: [[0.21939534 0.17186661 0.16303825 0.17182736 0.18227002 0.18644458\n",
      "  0.20387673 0.22320403]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00029573673964478076\n",
      "Predicción post entrenamiento : [[0.24597995]]\n",
      "PERDIDAAAA despues: 0.00023867627896834165\n",
      "lr: 0.002, batch: 9\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "9\n",
      "[[[0.17186661]\n",
      "  [0.16303825]\n",
      "  [0.17182736]\n",
      "  [0.18227002]\n",
      "  [0.18644458]\n",
      "  [0.20387673]\n",
      "  [0.22320403]\n",
      "  [0.2477278 ]]]\n",
      "ejemplar: [0.17186661 0.16303825 0.17182736 0.18227002 0.18644458 0.20387673\n",
      " 0.22320403 0.2477278 ]\n",
      "y: 0.20844633862843848\n",
      "Predicción : [[0.23873462]]\n",
      "Lr que voy a aplicar en el lote: 10 es 0.0020000000949949026\n",
      "lote que voy a entrenar: [[0.17186661 0.16303825 0.17182736 0.18227002 0.18644458 0.20387673\n",
      "  0.22320403 0.2477278 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000917379860766232\n",
      "Predicción post entrenamiento : [[0.23504622]]\n",
      "PERDIDAAAA despues: 0.0007075538160279393\n",
      "lr: 0.0018181818181818182, batch: 10\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "10\n",
      "[[[0.16303825]\n",
      "  [0.17182736]\n",
      "  [0.18227002]\n",
      "  [0.18644458]\n",
      "  [0.20387673]\n",
      "  [0.22320403]\n",
      "  [0.2477278 ]\n",
      "  [0.23873462]]]\n",
      "ejemplar: [0.16303825 0.17182736 0.18227002 0.18644458 0.20387673 0.22320403\n",
      " 0.2477278  0.23873462]\n",
      "y: 0.211933359163115\n",
      "Predicción : [[0.23828675]]\n",
      "Lr que voy a aplicar en el lote: 11 es 0.001818181830458343\n",
      "lote que voy a entrenar: [[0.16303825 0.17182736 0.18227002 0.18644458 0.20387673 0.22320403\n",
      "  0.2477278  0.23873462]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006945010973140597\n",
      "Predicción post entrenamiento : [[0.23798965]]\n",
      "PERDIDAAAA despues: 0.0006789302569814026\n",
      "lr: 0.0016666666666666668, batch: 11\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "11\n",
      "[[[0.17182736]\n",
      "  [0.18227002]\n",
      "  [0.18644458]\n",
      "  [0.20387673]\n",
      "  [0.22320403]\n",
      "  [0.2477278 ]\n",
      "  [0.23873462]\n",
      "  [0.23828675]]]\n",
      "ejemplar: [0.17182736 0.18227002 0.18644458 0.20387673 0.22320403 0.2477278\n",
      " 0.23873462 0.23828675]\n",
      "y: 0.2072839984502131\n",
      "Predicción : [[0.24506848]]\n",
      "Lr que voy a aplicar en el lote: 12 es 0.0016666667070239782\n",
      "lote que voy a entrenar: [[0.17182736 0.18227002 0.18644458 0.20387673 0.22320403 0.2477278\n",
      "  0.23873462 0.23828675]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0014276662841439247\n",
      "Predicción post entrenamiento : [[0.24313973]]\n",
      "PERDIDAAAA despues: 0.001285633072257042\n",
      "lr: 0.0015384615384615385, batch: 12\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "12\n",
      "[[[0.18227002]\n",
      "  [0.18644458]\n",
      "  [0.20387673]\n",
      "  [0.22320403]\n",
      "  [0.2477278 ]\n",
      "  [0.23873462]\n",
      "  [0.23828675]\n",
      "  [0.24506848]]]\n",
      "ejemplar: [0.18227002 0.18644458 0.20387673 0.22320403 0.2477278  0.23873462\n",
      " 0.23828675 0.24506848]\n",
      "y: 0.19294846958543205\n",
      "Predicción : [[0.2507198]]\n",
      "Lr que voy a aplicar en el lote: 13 es 0.0015384615398943424\n",
      "lote que voy a entrenar: [[0.18227002 0.18644458 0.20387673 0.22320403 0.2477278  0.23873462\n",
      "  0.23828675 0.24506848]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003337524365633726\n",
      "Predicción post entrenamiento : [[0.24783981]]\n",
      "PERDIDAAAA despues: 0.0030130583327263594\n",
      "lr: 0.0014285714285714286, batch: 13\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "13\n",
      "[[[0.18644458]\n",
      "  [0.20387673]\n",
      "  [0.22320403]\n",
      "  [0.2477278 ]\n",
      "  [0.23873462]\n",
      "  [0.23828675]\n",
      "  [0.24506848]\n",
      "  [0.25071979]]]\n",
      "ejemplar: [0.18644458 0.20387673 0.22320403 0.2477278  0.23873462 0.23828675\n",
      " 0.24506848 0.25071979]\n",
      "y: 0.19682293684618352\n",
      "Predicción : [[0.2554752]]\n",
      "Lr que voy a aplicar en el lote: 14 es 0.0014285714132711291\n",
      "lote que voy a entrenar: [[0.18644458 0.20387673 0.22320403 0.2477278  0.23873462 0.23828675\n",
      "  0.24506848 0.25071979]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003440086729824543\n",
      "Predicción post entrenamiento : [[0.2548131]]\n",
      "PERDIDAAAA despues: 0.003362859133630991\n",
      "lr: 0.0013333333333333333, batch: 14\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "14\n",
      "[[[0.20387673]\n",
      "  [0.22320403]\n",
      "  [0.2477278 ]\n",
      "  [0.23873462]\n",
      "  [0.23828675]\n",
      "  [0.24506848]\n",
      "  [0.25071979]\n",
      "  [0.25547519]]]\n",
      "ejemplar: [0.20387673 0.22320403 0.2477278  0.23873462 0.23828675 0.24506848\n",
      " 0.25071979 0.25547519]\n",
      "y: 0.21425803951956607\n",
      "Predicción : [[0.2637605]]\n",
      "Lr que voy a aplicar en el lote: 15 es 0.0013333333190530539\n",
      "lote que voy a entrenar: [[0.20387673 0.22320403 0.2477278  0.23873462 0.23828675 0.24506848\n",
      "  0.25071979 0.25547519]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002450493862852454\n",
      "Predicción post entrenamiento : [[0.2609936]]\n",
      "PERDIDAAAA despues: 0.0021842122077941895\n",
      "lr: 0.00125, batch: 15\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "15\n",
      "[[[0.22320403]\n",
      "  [0.2477278 ]\n",
      "  [0.23873462]\n",
      "  [0.23828675]\n",
      "  [0.24506848]\n",
      "  [0.25071979]\n",
      "  [0.25547519]\n",
      "  [0.26376051]]]\n",
      "ejemplar: [0.22320403 0.2477278  0.23873462 0.23828675 0.24506848 0.25071979\n",
      " 0.25547519 0.26376051]\n",
      "y: 0.18132506780317698\n",
      "Predicción : [[0.26821023]]\n",
      "Lr que voy a aplicar en el lote: 16 es 0.0012499999720603228\n",
      "lote que voy a entrenar: [[0.22320403 0.2477278  0.23873462 0.23828675 0.24506848 0.25071979\n",
      "  0.25547519 0.26376051]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00754903256893158\n",
      "Predicción post entrenamiento : [[0.26450744]]\n",
      "PERDIDAAAA despues: 0.006919308099895716\n",
      "lr: 0.0011764705882352942, batch: 16\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "16\n",
      "[[[0.2477278 ]\n",
      "  [0.23873462]\n",
      "  [0.23828675]\n",
      "  [0.24506848]\n",
      "  [0.25071979]\n",
      "  [0.25547519]\n",
      "  [0.26376051]\n",
      "  [0.26821023]]]\n",
      "ejemplar: [0.2477278  0.23873462 0.23828675 0.24506848 0.25071979 0.25547519\n",
      " 0.26376051 0.26821023]\n",
      "y: 0.17512592018597434\n",
      "Predicción : [[0.26905912]]\n",
      "Lr que voy a aplicar en el lote: 17 es 0.001176470541395247\n",
      "lote que voy a entrenar: [[0.2477278  0.23873462 0.23828675 0.24506848 0.25071979 0.25547519\n",
      "  0.26376051 0.26821023]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008823445066809654\n",
      "Predicción post entrenamiento : [[0.26766822]]\n",
      "PERDIDAAAA despues: 0.008564075455069542\n",
      "lr: 0.0011111111111111111, batch: 17\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "17\n",
      "[[[0.23873462]\n",
      "  [0.23828675]\n",
      "  [0.24506848]\n",
      "  [0.25071979]\n",
      "  [0.25547519]\n",
      "  [0.26376051]\n",
      "  [0.26821023]\n",
      "  [0.26905912]]]\n",
      "ejemplar: [0.23873462 0.23828675 0.24506848 0.25071979 0.25547519 0.26376051\n",
      " 0.26821023 0.26905912]\n",
      "y: 0.14800464936071295\n",
      "Predicción : [[0.26781982]]\n",
      "Lr que voy a aplicar en el lote: 18 es 0.0011111111380159855\n",
      "lote que voy a entrenar: [[0.23873462 0.23828675 0.24506848 0.25071979 0.25547519 0.26376051\n",
      "  0.26821023 0.26905912]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01435567531734705\n",
      "Predicción post entrenamiento : [[0.26381895]]\n",
      "PERDIDAAAA despues: 0.013412951491773129\n",
      "lr: 0.0010526315789473684, batch: 18\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "18\n",
      "[[[0.23828675]\n",
      "  [0.24506848]\n",
      "  [0.25071979]\n",
      "  [0.25547519]\n",
      "  [0.26376051]\n",
      "  [0.26821023]\n",
      "  [0.26905912]\n",
      "  [0.26781982]]]\n",
      "ejemplar: [0.23828675 0.24506848 0.25071979 0.25547519 0.26376051 0.26821023\n",
      " 0.26905912 0.26781982]\n",
      "y: 0.1588531576908176\n",
      "Predicción : [[0.26658747]]\n",
      "Lr que voy a aplicar en el lote: 19 es 0.0010526315309107304\n",
      "lote que voy a entrenar: [[0.23828675 0.24506848 0.25071979 0.25547519 0.26376051 0.26821023\n",
      "  0.26905912 0.26781982]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011606681160628796\n",
      "Predicción post entrenamiento : [[0.26414746]]\n",
      "PERDIDAAAA despues: 0.01108689047396183\n",
      "lr: 0.001, batch: 19\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "19\n",
      "[[[0.24506848]\n",
      "  [0.25071979]\n",
      "  [0.25547519]\n",
      "  [0.26376051]\n",
      "  [0.26821023]\n",
      "  [0.26905912]\n",
      "  [0.26781982]\n",
      "  [0.26658747]]]\n",
      "ejemplar: [0.24506848 0.25071979 0.25547519 0.26376051 0.26821023 0.26905912\n",
      " 0.26781982 0.26658747]\n",
      "y: 0.19217357613328173\n",
      "Predicción : [[0.26797888]]\n",
      "Lr que voy a aplicar en el lote: 20 es 0.0010000000474974513\n",
      "lote que voy a entrenar: [[0.24506848 0.25071979 0.25547519 0.26376051 0.26821023 0.26905912\n",
      "  0.26781982 0.26658747]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005746444687247276\n",
      "Predicción post entrenamiento : [[0.26659477]]\n",
      "PERDIDAAAA despues: 0.005538514815270901\n",
      "lr: 0.0009523809523809524, batch: 20\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "20\n",
      "[[[0.25071979]\n",
      "  [0.25547519]\n",
      "  [0.26376051]\n",
      "  [0.26821023]\n",
      "  [0.26905912]\n",
      "  [0.26781982]\n",
      "  [0.26658747]\n",
      "  [0.26797888]]]\n",
      "ejemplar: [0.25071979 0.25547519 0.26376051 0.26821023 0.26905912 0.26781982\n",
      " 0.26658747 0.26797888]\n",
      "y: 0.1859744285160791\n",
      "Predicción : [[0.26989052]]\n",
      "Lr que voy a aplicar en el lote: 21 es 0.0009523809421807528\n",
      "lote que voy a entrenar: [[0.25071979 0.25547519 0.26376051 0.26821023 0.26905912 0.26781982\n",
      "  0.26658747 0.26797888]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007041908800601959\n",
      "Predicción post entrenamiento : [[0.26834846]]\n",
      "PERDIDAAAA despues: 0.006785479374229908\n",
      "lr: 0.0009090909090909091, batch: 21\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "21\n",
      "[[[0.25547519]\n",
      "  [0.26376051]\n",
      "  [0.26821023]\n",
      "  [0.26905912]\n",
      "  [0.26781982]\n",
      "  [0.26658747]\n",
      "  [0.26797888]\n",
      "  [0.26989052]]]\n",
      "ejemplar: [0.25547519 0.26376051 0.26821023 0.26905912 0.26781982 0.26658747\n",
      " 0.26797888 0.26989052]\n",
      "y: 0.26695079426578844\n",
      "Predicción : [[0.27115893]]\n",
      "Lr que voy a aplicar en el lote: 22 es 0.0009090909152291715\n",
      "lote que voy a entrenar: [[0.25547519 0.26376051 0.26821023 0.26905912 0.26781982 0.26658747\n",
      "  0.26797888 0.26989052]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.7708505765767768e-05\n",
      "Predicción post entrenamiento : [[0.27148792]]\n",
      "PERDIDAAAA despues: 2.0585597667377442e-05\n",
      "lr: 0.0008695652173913044, batch: 22\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "22\n",
      "[[[0.26376051]\n",
      "  [0.26821023]\n",
      "  [0.26905912]\n",
      "  [0.26781982]\n",
      "  [0.26658747]\n",
      "  [0.26797888]\n",
      "  [0.26989052]\n",
      "  [0.27115893]]]\n",
      "ejemplar: [0.26376051 0.26821023 0.26905912 0.26781982 0.26658747 0.26797888\n",
      " 0.26989052 0.27115893]\n",
      "y: 0.2925222781867493\n",
      "Predicción : [[0.27384058]]\n",
      "Lr que voy a aplicar en el lote: 23 es 0.0008695652359165251\n",
      "lote que voy a entrenar: [[0.26376051 0.26821023 0.26905912 0.26781982 0.26658747 0.26797888\n",
      "  0.26989052 0.27115893]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00034900609171018004\n",
      "Predicción post entrenamiento : [[0.2746455]]\n",
      "PERDIDAAAA despues: 0.0003195790632162243\n",
      "lr: 0.0008333333333333334, batch: 23\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "23\n",
      "[[[0.26821023]\n",
      "  [0.26905912]\n",
      "  [0.26781982]\n",
      "  [0.26658747]\n",
      "  [0.26797888]\n",
      "  [0.26989052]\n",
      "  [0.27115893]\n",
      "  [0.27384058]]]\n",
      "ejemplar: [0.26821023 0.26905912 0.26781982 0.26658747 0.26797888 0.26989052\n",
      " 0.27115893 0.27384058]\n",
      "y: 0.3177063153816349\n",
      "Predicción : [[0.27557516]]\n",
      "Lr que voy a aplicar en el lote: 24 es 0.0008333333535119891\n",
      "lote que voy a entrenar: [[0.26821023 0.26905912 0.26781982 0.26658747 0.26797888 0.26989052\n",
      "  0.27115893 0.27384058]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001775034237653017\n",
      "Predicción post entrenamiento : [[0.27678716]]\n",
      "PERDIDAAAA despues: 0.0016743772430345416\n",
      "lr: 0.0008, batch: 24\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "24\n",
      "[[[0.26905912]\n",
      "  [0.26781982]\n",
      "  [0.26658747]\n",
      "  [0.26797888]\n",
      "  [0.26989052]\n",
      "  [0.27115893]\n",
      "  [0.27384058]\n",
      "  [0.27557516]]]\n",
      "ejemplar: [0.26905912 0.26781982 0.26658747 0.26797888 0.26989052 0.27115893\n",
      " 0.27384058 0.27557516]\n",
      "y: 0.31266950794265785\n",
      "Predicción : [[0.27693516]]\n",
      "Lr que voy a aplicar en el lote: 25 es 0.0007999999797903001\n",
      "lote que voy a entrenar: [[0.26905912 0.26781982 0.26658747 0.26797888 0.26989052 0.27115893\n",
      "  0.27384058 0.27557516]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001276944181881845\n",
      "Predicción post entrenamiento : [[0.27795243]]\n",
      "PERDIDAAAA despues: 0.0012052758829668164\n",
      "lr: 0.0007692307692307692, batch: 25\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "25\n",
      "[[[0.26781982]\n",
      "  [0.26658747]\n",
      "  [0.26797888]\n",
      "  [0.26989052]\n",
      "  [0.27115893]\n",
      "  [0.27384058]\n",
      "  [0.27557516]\n",
      "  [0.27693516]]]\n",
      "ejemplar: [0.26781982 0.26658747 0.26797888 0.26989052 0.27115893 0.27384058\n",
      " 0.27557516 0.27693516]\n",
      "y: 0.2890352576520729\n",
      "Predicción : [[0.27805832]]\n",
      "Lr que voy a aplicar en el lote: 26 es 0.0007692307699471712\n",
      "lote que voy a entrenar: [[0.26781982 0.26658747 0.26797888 0.26989052 0.27115893 0.27384058\n",
      "  0.27557516 0.27693516]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00012049321958329529\n",
      "Predicción post entrenamiento : [[0.27899516]]\n",
      "PERDIDAAAA despues: 0.00010080369975185022\n",
      "lr: 0.0007407407407407407, batch: 26\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "26\n",
      "[[[0.26658747]\n",
      "  [0.26797888]\n",
      "  [0.26989052]\n",
      "  [0.27115893]\n",
      "  [0.27384058]\n",
      "  [0.27557516]\n",
      "  [0.27693516]\n",
      "  [0.27805832]]]\n",
      "ejemplar: [0.26658747 0.26797888 0.26989052 0.27115893 0.27384058 0.27557516\n",
      " 0.27693516 0.27805832]\n",
      "y: 0.28283611003487025\n",
      "Predicción : [[0.27957845]]\n",
      "Lr que voy a aplicar en el lote: 27 es 0.00074074073927477\n",
      "lote que voy a entrenar: [[0.26658747 0.26797888 0.26989052 0.27115893 0.27384058 0.27557516\n",
      "  0.27693516 0.27805832]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.0612362530082464e-05\n",
      "Predicción post entrenamiento : [[0.27844155]]\n",
      "PERDIDAAAA despues: 1.9312166841700673e-05\n",
      "lr: 0.0007142857142857143, batch: 27\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "27\n",
      "[[[0.26797888]\n",
      "  [0.26989052]\n",
      "  [0.27115893]\n",
      "  [0.27384058]\n",
      "  [0.27557516]\n",
      "  [0.27693516]\n",
      "  [0.27805832]\n",
      "  [0.27957845]]]\n",
      "ejemplar: [0.26797888 0.26989052 0.27115893 0.27384058 0.27557516 0.27693516\n",
      " 0.27805832 0.27957845]\n",
      "y: 0.29949631925610226\n",
      "Predicción : [[0.27960426]]\n",
      "Lr que voy a aplicar en el lote: 28 es 0.0007142857066355646\n",
      "lote que voy a entrenar: [[0.26797888 0.26989052 0.27115893 0.27384058 0.27557516 0.27693516\n",
      "  0.27805832 0.27957845]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00039569431100971997\n",
      "Predicción post entrenamiento : [[0.27983013]]\n",
      "PERDIDAAAA despues: 0.0003867592313326895\n",
      "lr: 0.0006896551724137932, batch: 28\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "28\n",
      "[[[0.26989052]\n",
      "  [0.27115893]\n",
      "  [0.27384058]\n",
      "  [0.27557516]\n",
      "  [0.27693516]\n",
      "  [0.27805832]\n",
      "  [0.27957845]\n",
      "  [0.27960426]]]\n",
      "ejemplar: [0.26989052 0.27115893 0.27384058 0.27557516 0.27693516 0.27805832\n",
      " 0.27957845 0.27960426]\n",
      "y: 0.2758620689655173\n",
      "Predicción : [[0.28105313]]\n",
      "Lr que voy a aplicar en el lote: 29 es 0.0006896551931276917\n",
      "lote que voy a entrenar: [[0.26989052 0.27115893 0.27384058 0.27557516 0.27693516 0.27805832\n",
      "  0.27957845 0.27960426]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 2.6947082005790435e-05\n",
      "Predicción post entrenamiento : [[0.28100908]]\n",
      "PERDIDAAAA despues: 2.6491712560527958e-05\n",
      "lr: 0.0006666666666666666, batch: 29\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "29\n",
      "[[[0.27115893]\n",
      "  [0.27384058]\n",
      "  [0.27557516]\n",
      "  [0.27693516]\n",
      "  [0.27805832]\n",
      "  [0.27957845]\n",
      "  [0.27960426]\n",
      "  [0.28105313]]]\n",
      "ejemplar: [0.27115893 0.27384058 0.27557516 0.27693516 0.27805832 0.27957845\n",
      " 0.27960426 0.28105313]\n",
      "y: 0.2746997287872917\n",
      "Predicción : [[0.282164]]\n",
      "Lr que voy a aplicar en el lote: 30 es 0.0006666666595265269\n",
      "lote que voy a entrenar: [[0.27115893 0.27384058 0.27557516 0.27693516 0.27805832 0.27957845\n",
      "  0.27960426 0.28105313]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 5.5715619964757934e-05\n",
      "Predicción post entrenamiento : [[0.28204232]]\n",
      "PERDIDAAAA despues: 5.391387458075769e-05\n",
      "lr: 0.0006451612903225806, batch: 30\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "30\n",
      "[[[0.27384058]\n",
      "  [0.27557516]\n",
      "  [0.27693516]\n",
      "  [0.27805832]\n",
      "  [0.27957845]\n",
      "  [0.27960426]\n",
      "  [0.28105313]\n",
      "  [0.28216401]]]\n",
      "ejemplar: [0.27384058 0.27557516 0.27693516 0.27805832 0.27957845 0.27960426\n",
      " 0.28105313 0.28216401]\n",
      "y: 0.275474622239442\n",
      "Predicción : [[0.28324962]]\n",
      "Lr que voy a aplicar en el lote: 31 es 0.0006451613153330982\n",
      "lote que voy a entrenar: [[0.27384058 0.27557516 0.27693516 0.27805832 0.27957845 0.27960426\n",
      "  0.28105313 0.28216401]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 6.04507586103864e-05\n",
      "Predicción post entrenamiento : [[0.2833132]]\n",
      "PERDIDAAAA despues: 6.144375947769731e-05\n",
      "lr: 0.000625, batch: 31\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "31\n",
      "[[[0.27557516]\n",
      "  [0.27693516]\n",
      "  [0.27805832]\n",
      "  [0.27957845]\n",
      "  [0.27960426]\n",
      "  [0.28105313]\n",
      "  [0.28216401]\n",
      "  [0.28324962]]]\n",
      "ejemplar: [0.27557516 0.27693516 0.27805832 0.27957845 0.27960426 0.28105313\n",
      " 0.28216401 0.28324962]\n",
      "y: 0.3347539713289423\n",
      "Predicción : [[0.28423315]]\n",
      "Lr que voy a aplicar en el lote: 32 es 0.0006249999860301614\n",
      "lote que voy a entrenar: [[0.27557516 0.27693516 0.27805832 0.27957845 0.27960426 0.28105313\n",
      "  0.28216401 0.28324962]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002552351914346218\n",
      "Predicción post entrenamiento : [[0.28483418]]\n",
      "PERDIDAAAA despues: 0.002491984749212861\n",
      "lr: 0.0006060606060606061, batch: 32\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "32\n",
      "[[[0.27693516]\n",
      "  [0.27805832]\n",
      "  [0.27957845]\n",
      "  [0.27960426]\n",
      "  [0.28105313]\n",
      "  [0.28216401]\n",
      "  [0.28324962]\n",
      "  [0.28423315]]]\n",
      "ejemplar: [0.27693516 0.27805832 0.27957845 0.27960426 0.28105313 0.28216401\n",
      " 0.28324962 0.28423315]\n",
      "y: 0.35567609453700116\n",
      "Predicción : [[0.2856288]]\n",
      "Lr que voy a aplicar en el lote: 33 es 0.000606060610152781\n",
      "lote que voy a entrenar: [[0.27693516 0.27805832 0.27957845 0.27960426 0.28105313 0.28216401\n",
      "  0.28324962 0.28423315]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004906622692942619\n",
      "Predicción post entrenamiento : [[0.28684175]]\n",
      "PERDIDAAAA despues: 0.004738165531307459\n",
      "lr: 0.0005882352941176471, batch: 33\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "33\n",
      "[[[0.27805832]\n",
      "  [0.27957845]\n",
      "  [0.27960426]\n",
      "  [0.28105313]\n",
      "  [0.28216401]\n",
      "  [0.28324962]\n",
      "  [0.28423315]\n",
      "  [0.2856288 ]]]\n",
      "ejemplar: [0.27805832 0.27957845 0.27960426 0.28105313 0.28216401 0.28324962\n",
      " 0.28423315 0.2856288 ]\n",
      "y: 0.3366912049593181\n",
      "Predicción : [[0.28757548]]\n",
      "Lr que voy a aplicar en el lote: 34 es 0.0005882352706976235\n",
      "lote que voy a entrenar: [[0.27805832 0.27957845 0.27960426 0.28105313 0.28216401 0.28324962\n",
      "  0.28423315 0.2856288 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00241235364228487\n",
      "Predicción post entrenamiento : [[0.2878479]]\n",
      "PERDIDAAAA despues: 0.0023856672924011946\n",
      "lr: 0.0005714285714285715, batch: 34\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "34\n",
      "[[[0.27957845]\n",
      "  [0.27960426]\n",
      "  [0.28105313]\n",
      "  [0.28216401]\n",
      "  [0.28324962]\n",
      "  [0.28423315]\n",
      "  [0.2856288 ]\n",
      "  [0.28757548]]]\n",
      "ejemplar: [0.27957845 0.27960426 0.28105313 0.28216401 0.28324962 0.28423315\n",
      " 0.2856288  0.28757548]\n",
      "y: 0.3335916311507167\n",
      "Predicción : [[0.28857076]]\n",
      "Lr que voy a aplicar en el lote: 35 es 0.0005714285653084517\n",
      "lote que voy a entrenar: [[0.27957845 0.27960426 0.28105313 0.28216401 0.28324962 0.28423315\n",
      "  0.2856288  0.28757548]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0020268794614821672\n",
      "Predicción post entrenamiento : [[0.28947204]]\n",
      "PERDIDAAAA despues: 0.0019465388031676412\n",
      "lr: 0.0005555555555555556, batch: 35\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "35\n",
      "[[[0.27960426]\n",
      "  [0.28105313]\n",
      "  [0.28216401]\n",
      "  [0.28324962]\n",
      "  [0.28423315]\n",
      "  [0.2856288 ]\n",
      "  [0.28757548]\n",
      "  [0.28857076]]]\n",
      "ejemplar: [0.27960426 0.28105313 0.28216401 0.28324962 0.28423315 0.2856288\n",
      " 0.28757548 0.28857076]\n",
      "y: 0.38473459899263845\n",
      "Predicción : [[0.29009727]]\n",
      "Lr que voy a aplicar en el lote: 36 es 0.0005555555690079927\n",
      "lote que voy a entrenar: [[0.27960426 0.28105313 0.28216401 0.28324962 0.28423315 0.2856288\n",
      "  0.28757548 0.28857076]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.008956224657595158\n",
      "Predicción post entrenamiento : [[0.2913994]]\n",
      "PERDIDAAAA despues: 0.008711461909115314\n",
      "lr: 0.0005405405405405405, batch: 36\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "36\n",
      "[[[0.28105313]\n",
      "  [0.28216401]\n",
      "  [0.28324962]\n",
      "  [0.28423315]\n",
      "  [0.2856288 ]\n",
      "  [0.28757548]\n",
      "  [0.28857076]\n",
      "  [0.29009727]]]\n",
      "ejemplar: [0.28105313 0.28216401 0.28324962 0.28423315 0.2856288  0.28757548\n",
      " 0.28857076 0.29009727]\n",
      "y: 0.5710964742347926\n",
      "Predicción : [[0.2922731]]\n",
      "Lr que voy a aplicar en el lote: 37 es 0.0005405405536293983\n",
      "lote que voy a entrenar: [[0.28105313 0.28216401 0.28324962 0.28423315 0.2856288  0.28757548\n",
      "  0.28857076 0.29009727]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07774247229099274\n",
      "Predicción post entrenamiento : [[0.29594088]]\n",
      "PERDIDAAAA despues: 0.07571060955524445\n",
      "lr: 0.0005263157894736842, batch: 37\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "37\n",
      "[[[0.28216401]\n",
      "  [0.28324962]\n",
      "  [0.28423315]\n",
      "  [0.2856288 ]\n",
      "  [0.28757548]\n",
      "  [0.28857076]\n",
      "  [0.29009727]\n",
      "  [0.2922731 ]]]\n",
      "ejemplar: [0.28216401 0.28324962 0.28423315 0.2856288  0.28757548 0.28857076\n",
      " 0.29009727 0.2922731 ]\n",
      "y: 0.5962805114296785\n",
      "Predicción : [[0.29678202]]\n",
      "Lr que voy a aplicar en el lote: 38 es 0.0005263157654553652\n",
      "lote que voy a entrenar: [[0.28216401 0.28324962 0.28423315 0.2856288  0.28757548 0.28857076\n",
      "  0.29009727 0.2922731 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08969935029745102\n",
      "Predicción post entrenamiento : [[0.30062333]]\n",
      "PERDIDAAAA despues: 0.08741316944360733\n",
      "lr: 0.0005128205128205128, batch: 38\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "38\n",
      "[[[0.28324962]\n",
      "  [0.28423315]\n",
      "  [0.2856288 ]\n",
      "  [0.28757548]\n",
      "  [0.28857076]\n",
      "  [0.29009727]\n",
      "  [0.2922731 ]\n",
      "  [0.29678202]]]\n",
      "ejemplar: [0.28324962 0.28423315 0.2856288  0.28757548 0.28857076 0.29009727\n",
      " 0.2922731  0.29678202]\n",
      "y: 0.574583494769469\n",
      "Predicción : [[0.3015303]]\n",
      "Lr que voy a aplicar en el lote: 39 es 0.0005128204938955605\n",
      "lote que voy a entrenar: [[0.28324962 0.28423315 0.2856288  0.28757548 0.28857076 0.29009727\n",
      "  0.2922731  0.29678202]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07455803453922272\n",
      "Predicción post entrenamiento : [[0.30516964]]\n",
      "PERDIDAAAA despues: 0.07258380949497223\n",
      "lr: 0.0005, batch: 39\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "39\n",
      "[[[0.28423315]\n",
      "  [0.2856288 ]\n",
      "  [0.28757548]\n",
      "  [0.28857076]\n",
      "  [0.29009727]\n",
      "  [0.2922731 ]\n",
      "  [0.29678202]\n",
      "  [0.3015303 ]]]\n",
      "ejemplar: [0.28423315 0.2856288  0.28757548 0.28857076 0.29009727 0.2922731\n",
      " 0.29678202 0.3015303 ]\n",
      "y: 0.6063541263076326\n",
      "Predicción : [[0.30620298]]\n",
      "Lr que voy a aplicar en el lote: 40 es 0.0005000000237487257\n",
      "lote que voy a entrenar: [[0.28423315 0.2856288  0.28757548 0.28857076 0.29009727 0.2922731\n",
      "  0.29678202 0.3015303 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09009070694446564\n",
      "Predicción post entrenamiento : [[0.30989626]]\n",
      "PERDIDAAAA despues: 0.08788725733757019\n",
      "lr: 0.0004878048780487805, batch: 40\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "40\n",
      "[[[0.2856288 ]\n",
      "  [0.28757548]\n",
      "  [0.28857076]\n",
      "  [0.29009727]\n",
      "  [0.2922731 ]\n",
      "  [0.29678202]\n",
      "  [0.3015303 ]\n",
      "  [0.30620298]]]\n",
      "ejemplar: [0.2856288  0.28757548 0.28857076 0.29009727 0.2922731  0.29678202\n",
      " 0.3015303  0.30620298]\n",
      "y: 0.5846571096474236\n",
      "Predicción : [[0.31115994]]\n",
      "Lr que voy a aplicar en el lote: 41 es 0.0004878048785030842\n",
      "lote que voy a entrenar: [[0.2856288  0.28757548 0.28857076 0.29009727 0.2922731  0.29678202\n",
      "  0.3015303  0.30620298]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07480071485042572\n",
      "Predicción post entrenamiento : [[0.3146276]]\n",
      "PERDIDAAAA despues: 0.0729159563779831\n",
      "lr: 0.0004761904761904762, batch: 41\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "41\n",
      "[[[0.28757548]\n",
      "  [0.28857076]\n",
      "  [0.29009727]\n",
      "  [0.2922731 ]\n",
      "  [0.29678202]\n",
      "  [0.3015303 ]\n",
      "  [0.30620298]\n",
      "  [0.31115994]]]\n",
      "ejemplar: [0.28757548 0.28857076 0.29009727 0.2922731  0.29678202 0.3015303\n",
      " 0.30620298 0.31115994]\n",
      "y: 0.5687717938783416\n",
      "Predicción : [[0.3161298]]\n",
      "Lr que voy a aplicar en el lote: 42 es 0.0004761904710903764\n",
      "lote que voy a entrenar: [[0.28757548 0.28857076 0.29009727 0.2922731  0.29678202 0.3015303\n",
      "  0.30620298 0.31115994]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06382796913385391\n",
      "Predicción post entrenamiento : [[0.3189994]]\n",
      "PERDIDAAAA despues: 0.06238623708486557\n",
      "lr: 0.00046511627906976747, batch: 42\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "42\n",
      "[[[0.28857076]\n",
      "  [0.29009727]\n",
      "  [0.2922731 ]\n",
      "  [0.29678202]\n",
      "  [0.3015303 ]\n",
      "  [0.30620298]\n",
      "  [0.31115994]\n",
      "  [0.3161298 ]]]\n",
      "ejemplar: [0.28857076 0.29009727 0.2922731  0.29678202 0.3015303  0.30620298\n",
      " 0.31115994 0.3161298 ]\n",
      "y: 0.6427741185586981\n",
      "Predicción : [[0.3207196]]\n",
      "Lr que voy a aplicar en el lote: 43 es 0.00046511628897860646\n",
      "lote que voy a entrenar: [[0.28857076 0.29009727 0.2922731  0.29678202 0.3015303  0.30620298\n",
      "  0.31115994 0.3161298 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10371910780668259\n",
      "Predicción post entrenamiento : [[0.3246996]]\n",
      "PERDIDAAAA despues: 0.10117138177156448\n",
      "lr: 0.00045454545454545455, batch: 43\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "43\n",
      "[[[0.29009727]\n",
      "  [0.2922731 ]\n",
      "  [0.29678202]\n",
      "  [0.3015303 ]\n",
      "  [0.30620298]\n",
      "  [0.31115994]\n",
      "  [0.3161298 ]\n",
      "  [0.3207196 ]]]\n",
      "ejemplar: [0.29009727 0.2922731  0.29678202 0.3015303  0.30620298 0.31115994\n",
      " 0.3161298  0.3207196 ]\n",
      "y: 0.6617590081363811\n",
      "Predicción : [[0.32697076]]\n",
      "Lr que voy a aplicar en el lote: 44 es 0.00045454545761458576\n",
      "lote que voy a entrenar: [[0.29009727 0.2922731  0.29678202 0.3015303  0.30620298 0.31115994\n",
      "  0.3161298  0.3207196 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11208318173885345\n",
      "Predicción post entrenamiento : [[0.3310689]]\n",
      "PERDIDAAAA despues: 0.10935595631599426\n",
      "lr: 0.00044444444444444447, batch: 44\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "44\n",
      "[[[0.2922731 ]\n",
      "  [0.29678202]\n",
      "  [0.3015303 ]\n",
      "  [0.30620298]\n",
      "  [0.31115994]\n",
      "  [0.3161298 ]\n",
      "  [0.3207196 ]\n",
      "  [0.32697076]]]\n",
      "ejemplar: [0.2922731  0.29678202 0.3015303  0.30620298 0.31115994 0.3161298\n",
      " 0.3207196  0.32697076]\n",
      "y: 0.6729949631925611\n",
      "Predicción : [[0.3339164]]\n",
      "Lr que voy a aplicar en el lote: 45 es 0.0004444444493856281\n",
      "lote que voy a entrenar: [[0.2922731  0.29678202 0.3015303  0.30620298 0.31115994 0.3161298\n",
      "  0.3207196  0.32697076]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11497428268194199\n",
      "Predicción post entrenamiento : [[0.33795732]]\n",
      "PERDIDAAAA despues: 0.11225022375583649\n",
      "lr: 0.0004347826086956522, batch: 45\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "45\n",
      "[[[0.29678202]\n",
      "  [0.3015303 ]\n",
      "  [0.30620298]\n",
      "  [0.31115994]\n",
      "  [0.3161298 ]\n",
      "  [0.3207196 ]\n",
      "  [0.32697076]\n",
      "  [0.3339164 ]]]\n",
      "ejemplar: [0.29678202 0.3015303  0.30620298 0.31115994 0.3161298  0.3207196\n",
      " 0.32697076 0.3339164 ]\n",
      "y: 0.7105772956218519\n",
      "Predicción : [[0.3413723]]\n",
      "Lr que voy a aplicar en el lote: 46 es 0.00043478261795826256\n",
      "lote que voy a entrenar: [[0.29678202 0.3015303  0.30620298 0.31115994 0.3161298  0.3207196\n",
      "  0.32697076 0.3339164 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.136312335729599\n",
      "Predicción post entrenamiento : [[0.34562665]]\n",
      "PERDIDAAAA despues: 0.13318897783756256\n",
      "lr: 0.000425531914893617, batch: 46\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "46\n",
      "[[[0.3015303 ]\n",
      "  [0.30620298]\n",
      "  [0.31115994]\n",
      "  [0.3161298 ]\n",
      "  [0.3207196 ]\n",
      "  [0.32697076]\n",
      "  [0.3339164 ]\n",
      "  [0.34137231]]]\n",
      "ejemplar: [0.3015303  0.30620298 0.31115994 0.3161298  0.3207196  0.32697076\n",
      " 0.3339164  0.34137231]\n",
      "y: 0.703990701278574\n",
      "Predicción : [[0.34918413]]\n",
      "Lr que voy a aplicar en el lote: 47 es 0.00042553190723992884\n",
      "lote que voy a entrenar: [[0.3015303  0.30620298 0.31115994 0.3161298  0.3207196  0.32697076\n",
      "  0.3339164  0.34137231]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1258877068758011\n",
      "Predicción post entrenamiento : [[0.35309798]]\n",
      "PERDIDAAAA despues: 0.12312570214271545\n",
      "lr: 0.0004166666666666667, batch: 47\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "47\n",
      "[[[0.30620298]\n",
      "  [0.31115994]\n",
      "  [0.3161298 ]\n",
      "  [0.3207196 ]\n",
      "  [0.32697076]\n",
      "  [0.3339164 ]\n",
      "  [0.34137231]\n",
      "  [0.34918413]]]\n",
      "ejemplar: [0.30620298 0.31115994 0.3161298  0.3207196  0.32697076 0.3339164\n",
      " 0.34137231 0.34918413]\n",
      "y: 0.7272375048430839\n",
      "Predicción : [[0.35681173]]\n",
      "Lr que voy a aplicar en el lote: 48 es 0.00041666667675599456\n",
      "lote que voy a entrenar: [[0.30620298 0.31115994 0.3161298  0.3207196  0.32697076 0.3339164\n",
      "  0.34137231 0.34918413]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1372152715921402\n",
      "Predicción post entrenamiento : [[0.36095026]]\n",
      "PERDIDAAAA despues: 0.13416635990142822\n",
      "lr: 0.00040816326530612246, batch: 48\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "48\n",
      "[[[0.31115994]\n",
      "  [0.3161298 ]\n",
      "  [0.3207196 ]\n",
      "  [0.32697076]\n",
      "  [0.3339164 ]\n",
      "  [0.34137231]\n",
      "  [0.34918413]\n",
      "  [0.35681173]]]\n",
      "ejemplar: [0.31115994 0.3161298  0.3207196  0.32697076 0.3339164  0.34137231\n",
      " 0.34918413 0.35681173]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.36492196]]\n",
      "Lr que voy a aplicar en el lote: 49 es 0.0004081632650922984\n",
      "lote que voy a entrenar: [[0.31115994 0.3161298  0.3207196  0.32697076 0.3339164  0.34137231\n",
      "  0.34918413 0.35681173]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.1279250830411911\n",
      "Predicción post entrenamiento : [[0.36898923]]\n",
      "PERDIDAAAA despues: 0.12503217160701752\n",
      "lr: 0.0004, batch: 49\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "49\n",
      "[[[0.3161298 ]\n",
      "  [0.3207196 ]\n",
      "  [0.32697076]\n",
      "  [0.3339164 ]\n",
      "  [0.34137231]\n",
      "  [0.34918413]\n",
      "  [0.35681173]\n",
      "  [0.36492196]]]\n",
      "ejemplar: [0.3161298  0.3207196  0.32697076 0.3339164  0.34137231 0.34918413\n",
      " 0.35681173 0.36492196]\n",
      "y: 0.771793878341728\n",
      "Predicción : [[0.37325284]]\n",
      "Lr que voy a aplicar en el lote: 50 es 0.00039999998989515007\n",
      "lote que voy a entrenar: [[0.3161298  0.3207196  0.32697076 0.3339164  0.34137231 0.34918413\n",
      "  0.35681173 0.36492196]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.15883497893810272\n",
      "Predicción post entrenamiento : [[0.3777385]]\n",
      "PERDIDAAAA despues: 0.15527965128421783\n",
      "lr: 0.000392156862745098, batch: 50\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "50\n",
      "[[[0.3207196 ]\n",
      "  [0.32697076]\n",
      "  [0.3339164 ]\n",
      "  [0.34137231]\n",
      "  [0.34918413]\n",
      "  [0.35681173]\n",
      "  [0.36492196]\n",
      "  [0.37325284]]]\n",
      "ejemplar: [0.3207196  0.32697076 0.3339164  0.34137231 0.34918413 0.35681173\n",
      " 0.36492196 0.37325284]\n",
      "y: 0.7245253777605578\n",
      "Predicción : [[0.38240105]]\n",
      "Lr que voy a aplicar en el lote: 51 es 0.0003921568568330258\n",
      "lote que voy a entrenar: [[0.3207196  0.32697076 0.3339164  0.34137231 0.34918413 0.35681173\n",
      "  0.36492196 0.37325284]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11704906821250916\n",
      "Predicción post entrenamiento : [[0.38572237]]\n",
      "PERDIDAAAA despues: 0.11478748917579651\n",
      "lr: 0.0003846153846153846, batch: 51\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "51\n",
      "[[[0.32697076]\n",
      "  [0.3339164 ]\n",
      "  [0.34137231]\n",
      "  [0.34918413]\n",
      "  [0.35681173]\n",
      "  [0.36492196]\n",
      "  [0.37325284]\n",
      "  [0.38240105]]]\n",
      "ejemplar: [0.32697076 0.3339164  0.34137231 0.34918413 0.35681173 0.36492196\n",
      " 0.37325284 0.38240105]\n",
      "y: 0.6710577295621851\n",
      "Predicción : [[0.39099976]]\n",
      "Lr que voy a aplicar en el lote: 52 es 0.0003846153849735856\n",
      "lote que voy a entrenar: [[0.32697076 0.3339164  0.34137231 0.34918413 0.35681173 0.36492196\n",
      "  0.37325284 0.38240105]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07843244820833206\n",
      "Predicción post entrenamiento : [[0.39378777]]\n",
      "PERDIDAAAA despues: 0.0768786147236824\n",
      "lr: 0.0003773584905660377, batch: 52\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "52\n",
      "[[[0.3339164 ]\n",
      "  [0.34137231]\n",
      "  [0.34918413]\n",
      "  [0.35681173]\n",
      "  [0.36492196]\n",
      "  [0.37325284]\n",
      "  [0.38240105]\n",
      "  [0.39099976]]]\n",
      "ejemplar: [0.3339164  0.34137231 0.34918413 0.35681173 0.36492196 0.37325284\n",
      " 0.38240105 0.39099976]\n",
      "y: 0.6737698566447115\n",
      "Predicción : [[0.3994121]]\n",
      "Lr que voy a aplicar en el lote: 53 es 0.00037735849036835134\n",
      "lote que voy a entrenar: [[0.3339164  0.34137231 0.34918413 0.35681173 0.36492196 0.37325284\n",
      "  0.38240105 0.39099976]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07527216523885727\n",
      "Predicción post entrenamiento : [[0.40184844]]\n",
      "PERDIDAAAA despues: 0.07394124567508698\n",
      "lr: 0.00037037037037037035, batch: 53\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "53\n",
      "[[[0.34137231]\n",
      "  [0.34918413]\n",
      "  [0.35681173]\n",
      "  [0.36492196]\n",
      "  [0.37325284]\n",
      "  [0.38240105]\n",
      "  [0.39099976]\n",
      "  [0.3994121 ]]]\n",
      "ejemplar: [0.34137231 0.34918413 0.35681173 0.36492196 0.37325284 0.38240105\n",
      " 0.39099976 0.3994121 ]\n",
      "y: 0.7144517628826037\n",
      "Predicción : [[0.4077329]]\n",
      "Lr que voy a aplicar en el lote: 54 es 0.000370370369637385\n",
      "lote que voy a entrenar: [[0.34137231 0.34918413 0.35681173 0.36492196 0.37325284 0.38240105\n",
      "  0.39099976 0.3994121 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0940764769911766\n",
      "Predicción post entrenamiento : [[0.41068164]]\n",
      "PERDIDAAAA despues: 0.09227630496025085\n",
      "lr: 0.00036363636363636367, batch: 54\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "54\n",
      "[[[0.34918413]\n",
      "  [0.35681173]\n",
      "  [0.36492196]\n",
      "  [0.37325284]\n",
      "  [0.38240105]\n",
      "  [0.39099976]\n",
      "  [0.3994121 ]\n",
      "  [0.4077329 ]]]\n",
      "ejemplar: [0.34918413 0.35681173 0.36492196 0.37325284 0.38240105 0.39099976\n",
      " 0.3994121  0.4077329 ]\n",
      "y: 0.7438977140643162\n",
      "Predicción : [[0.41676202]]\n",
      "Lr que voy a aplicar en el lote: 55 es 0.0003636363544501364\n",
      "lote que voy a entrenar: [[0.34918413 0.35681173 0.36492196 0.37325284 0.38240105 0.39099976\n",
      "  0.3994121  0.4077329 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.10701777040958405\n",
      "Predicción post entrenamiento : [[0.42011026]]\n",
      "PERDIDAAAA despues: 0.10483833402395248\n",
      "lr: 0.00035714285714285714, batch: 55\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "55\n",
      "[[[0.35681173]\n",
      "  [0.36492196]\n",
      "  [0.37325284]\n",
      "  [0.38240105]\n",
      "  [0.39099976]\n",
      "  [0.3994121 ]\n",
      "  [0.4077329 ]\n",
      "  [0.41676202]]]\n",
      "ejemplar: [0.35681173 0.36492196 0.37325284 0.38240105 0.39099976 0.3994121\n",
      " 0.4077329  0.41676202]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.42634416]]\n",
      "Lr que voy a aplicar en el lote: 56 es 0.0003571428533177823\n",
      "lote que voy a entrenar: [[0.35681173 0.36492196 0.37325284 0.38240105 0.39099976 0.3994121\n",
      "  0.4077329  0.41676202]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08776048570871353\n",
      "Predicción post entrenamiento : [[0.42945215]]\n",
      "PERDIDAAAA despues: 0.08592870086431503\n",
      "lr: 0.00035087719298245617, batch: 56\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "56\n",
      "[[[0.36492196]\n",
      "  [0.37325284]\n",
      "  [0.38240105]\n",
      "  [0.39099976]\n",
      "  [0.3994121 ]\n",
      "  [0.4077329 ]\n",
      "  [0.41676202]\n",
      "  [0.42634416]]]\n",
      "ejemplar: [0.36492196 0.37325284 0.38240105 0.39099976 0.3994121  0.4077329\n",
      " 0.41676202 0.42634416]\n",
      "y: 0.6993413405656723\n",
      "Predicción : [[0.43592516]]\n",
      "Lr que voy a aplicar en el lote: 57 es 0.0003508772060740739\n",
      "lote que voy a entrenar: [[0.36492196 0.37325284 0.38240105 0.39099976 0.3994121  0.4077329\n",
      "  0.41676202 0.42634416]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06938809156417847\n",
      "Predicción post entrenamiento : [[0.43808153]]\n",
      "PERDIDAAAA despues: 0.06825669854879379\n",
      "lr: 0.0003448275862068966, batch: 57\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "57\n",
      "[[[0.37325284]\n",
      "  [0.38240105]\n",
      "  [0.39099976]\n",
      "  [0.3994121 ]\n",
      "  [0.4077329 ]\n",
      "  [0.41676202]\n",
      "  [0.42634416]\n",
      "  [0.43592516]]]\n",
      "ejemplar: [0.37325284 0.38240105 0.39099976 0.3994121  0.4077329  0.41676202\n",
      " 0.42634416 0.43592516]\n",
      "y: 0.7373111197210385\n",
      "Predicción : [[0.44472155]]\n",
      "Lr que voy a aplicar en el lote: 58 es 0.00034482759656384587\n",
      "lote que voy a entrenar: [[0.37325284 0.38240105 0.39099976 0.3994121  0.4077329  0.41676202\n",
      "  0.42634416 0.43592516]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08560866117477417\n",
      "Predicción post entrenamiento : [[0.4476177]]\n",
      "PERDIDAAAA despues: 0.08392227441072464\n",
      "lr: 0.00033898305084745765, batch: 58\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "58\n",
      "[[[0.38240105]\n",
      "  [0.39099976]\n",
      "  [0.3994121 ]\n",
      "  [0.4077329 ]\n",
      "  [0.41676202]\n",
      "  [0.42634416]\n",
      "  [0.43592516]\n",
      "  [0.44472155]]]\n",
      "ejemplar: [0.38240105 0.39099976 0.3994121  0.4077329  0.41676202 0.42634416\n",
      " 0.43592516 0.44472155]\n",
      "y: 0.7214258039519565\n",
      "Predicción : [[0.45440745]]\n",
      "Lr que voy a aplicar en el lote: 59 es 0.000338983052643016\n",
      "lote que voy a entrenar: [[0.38240105 0.39099976 0.3994121  0.4077329  0.41676202 0.42634416\n",
      "  0.43592516 0.44472155]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07129881531000137\n",
      "Predicción post entrenamiento : [[0.4570413]]\n",
      "PERDIDAAAA despues: 0.06989918649196625\n",
      "lr: 0.0003333333333333333, batch: 59\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "59\n",
      "[[[0.39099976]\n",
      "  [0.3994121 ]\n",
      "  [0.4077329 ]\n",
      "  [0.41676202]\n",
      "  [0.42634416]\n",
      "  [0.43592516]\n",
      "  [0.44472155]\n",
      "  [0.45440745]]]\n",
      "ejemplar: [0.39099976 0.3994121  0.4077329  0.41676202 0.42634416 0.43592516\n",
      " 0.44472155 0.45440745]\n",
      "y: 0.7187136768694304\n",
      "Predicción : [[0.46380326]]\n",
      "Lr que voy a aplicar en el lote: 60 es 0.00033333332976326346\n",
      "lote que voy a entrenar: [[0.39099976 0.3994121  0.4077329  0.41676202 0.42634416 0.43592516\n",
      "  0.44472155 0.45440745]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06497932970523834\n",
      "Predicción post entrenamiento : [[0.46611628]]\n",
      "PERDIDAAAA despues: 0.0638054609298706\n",
      "lr: 0.0003278688524590164, batch: 60\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "60\n",
      "[[[0.3994121 ]\n",
      "  [0.4077329 ]\n",
      "  [0.41676202]\n",
      "  [0.42634416]\n",
      "  [0.43592516]\n",
      "  [0.44472155]\n",
      "  [0.45440745]\n",
      "  [0.46380326]]]\n",
      "ejemplar: [0.3994121  0.4077329  0.41676202 0.42634416 0.43592516 0.44472155\n",
      " 0.45440745 0.46380326]\n",
      "y: 0.6741573033707864\n",
      "Predicción : [[0.47299978]]\n",
      "Lr que voy a aplicar en el lote: 61 es 0.00032786885276436806\n",
      "lote que voy a entrenar: [[0.3994121  0.4077329  0.41676202 0.42634416 0.43592516 0.44472155\n",
      "  0.45440745 0.46380326]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.040464356541633606\n",
      "Predicción post entrenamiento : [[0.47510108]]\n",
      "PERDIDAAAA despues: 0.03962338715791702\n",
      "lr: 0.0003225806451612903, batch: 61\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "61\n",
      "[[[0.4077329 ]\n",
      "  [0.41676202]\n",
      "  [0.42634416]\n",
      "  [0.43592516]\n",
      "  [0.44472155]\n",
      "  [0.45440745]\n",
      "  [0.46380326]\n",
      "  [0.47299978]]]\n",
      "ejemplar: [0.4077329  0.41676202 0.42634416 0.43592516 0.44472155 0.45440745\n",
      " 0.46380326 0.47299978]\n",
      "y: 0.698566447113522\n",
      "Predicción : [[0.48218617]]\n",
      "Lr que voy a aplicar en el lote: 62 es 0.0003225806576665491\n",
      "lote que voy a entrenar: [[0.4077329  0.41676202 0.42634416 0.43592516 0.44472155 0.45440745\n",
      "  0.46380326 0.47299978]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.046820420771837234\n",
      "Predicción post entrenamiento : [[0.48443872]]\n",
      "PERDIDAAAA despues: 0.04585067927837372\n",
      "lr: 0.00031746031746031746, batch: 62\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "62\n",
      "[[[0.41676202]\n",
      "  [0.42634416]\n",
      "  [0.43592516]\n",
      "  [0.44472155]\n",
      "  [0.45440745]\n",
      "  [0.46380326]\n",
      "  [0.47299978]\n",
      "  [0.48218617]]]\n",
      "ejemplar: [0.41676202 0.42634416 0.43592516 0.44472155 0.45440745 0.46380326\n",
      " 0.47299978 0.48218617]\n",
      "y: 0.7210383572258814\n",
      "Predicción : [[0.49178854]]\n",
      "Lr que voy a aplicar en el lote: 63 es 0.0003174603043589741\n",
      "lote que voy a entrenar: [[0.41676202 0.42634416 0.43592516 0.44472155 0.45440745 0.46380326\n",
      "  0.47299978 0.48218617]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.052555471658706665\n",
      "Predicción post entrenamiento : [[0.49409488]]\n",
      "PERDIDAAAA despues: 0.05150333419442177\n",
      "lr: 0.0003125, batch: 63\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "63\n",
      "[[[0.42634416]\n",
      "  [0.43592516]\n",
      "  [0.44472155]\n",
      "  [0.45440745]\n",
      "  [0.46380326]\n",
      "  [0.47299978]\n",
      "  [0.48218617]\n",
      "  [0.49178854]]]\n",
      "ejemplar: [0.42634416 0.43592516 0.44472155 0.45440745 0.46380326 0.47299978\n",
      " 0.48218617 0.49178854]\n",
      "y: 0.722588144130182\n",
      "Predicción : [[0.50156516]]\n",
      "Lr que voy a aplicar en el lote: 64 es 0.0003124999930150807\n",
      "lote que voy a entrenar: [[0.42634416 0.43592516 0.44472155 0.45440745 0.46380326 0.47299978\n",
      "  0.48218617 0.49178854]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04885115101933479\n",
      "Predicción post entrenamiento : [[0.50406283]]\n",
      "PERDIDAAAA despues: 0.04775330424308777\n",
      "lr: 0.0003076923076923077, batch: 64\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "64\n",
      "[[[0.43592516]\n",
      "  [0.44472155]\n",
      "  [0.45440745]\n",
      "  [0.46380326]\n",
      "  [0.47299978]\n",
      "  [0.48218617]\n",
      "  [0.49178854]\n",
      "  [0.50156516]]]\n",
      "ejemplar: [0.43592516 0.44472155 0.45440745 0.46380326 0.47299978 0.48218617\n",
      " 0.49178854 0.50156516]\n",
      "y: 0.7562960092987214\n",
      "Predicción : [[0.51152176]]\n",
      "Lr que voy a aplicar en el lote: 65 es 0.0003076923021581024\n",
      "lote que voy a entrenar: [[0.43592516 0.44472155 0.45440745 0.46380326 0.47299978 0.48218617\n",
      "  0.49178854 0.50156516]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.059914447367191315\n",
      "Predicción post entrenamiento : [[0.51350456]]\n",
      "PERDIDAAAA despues: 0.05894770100712776\n",
      "lr: 0.00030303030303030303, batch: 65\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "65\n",
      "[[[0.44472155]\n",
      "  [0.45440745]\n",
      "  [0.46380326]\n",
      "  [0.47299978]\n",
      "  [0.48218617]\n",
      "  [0.49178854]\n",
      "  [0.50156516]\n",
      "  [0.51152176]]]\n",
      "ejemplar: [0.44472155 0.45440745 0.46380326 0.47299978 0.48218617 0.49178854\n",
      " 0.50156516 0.51152176]\n",
      "y: 0.8275862068965516\n",
      "Predicción : [[0.52094877]]\n",
      "Lr que voy a aplicar en el lote: 66 es 0.0003030303050763905\n",
      "lote que voy a entrenar: [[0.44472155 0.45440745 0.46380326 0.47299978 0.48218617 0.49178854\n",
      "  0.50156516 0.51152176]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09402653574943542\n",
      "Predicción post entrenamiento : [[0.52414536]]\n",
      "PERDIDAAAA despues: 0.0920763611793518\n",
      "lr: 0.00029850746268656717, batch: 66\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "66\n",
      "[[[0.45440745]\n",
      "  [0.46380326]\n",
      "  [0.47299978]\n",
      "  [0.48218617]\n",
      "  [0.49178854]\n",
      "  [0.50156516]\n",
      "  [0.51152176]\n",
      "  [0.52094877]]]\n",
      "ejemplar: [0.45440745 0.46380326 0.47299978 0.48218617 0.49178854 0.50156516\n",
      " 0.51152176 0.52094877]\n",
      "y: 0.8388221619527314\n",
      "Predicción : [[0.53178895]]\n",
      "Lr que voy a aplicar en el lote: 67 es 0.00029850745340809226\n",
      "lote que voy a entrenar: [[0.45440745 0.46380326 0.47299978 0.48218617 0.49178854 0.50156516\n",
      "  0.51152176 0.52094877]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.09426940977573395\n",
      "Predicción post entrenamiento : [[0.5343625]]\n",
      "PERDIDAAAA despues: 0.0926957055926323\n",
      "lr: 0.00029411764705882356, batch: 67\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "67\n",
      "[[[0.46380326]\n",
      "  [0.47299978]\n",
      "  [0.48218617]\n",
      "  [0.49178854]\n",
      "  [0.50156516]\n",
      "  [0.51152176]\n",
      "  [0.52094877]\n",
      "  [0.53178895]]]\n",
      "ejemplar: [0.46380326 0.47299978 0.48218617 0.49178854 0.50156516 0.51152176\n",
      " 0.52094877 0.53178895]\n",
      "y: 0.7942657884540876\n",
      "Predicción : [[0.54200506]]\n",
      "Lr que voy a aplicar en el lote: 68 es 0.00029411763534881175\n",
      "lote que voy a entrenar: [[0.46380326 0.47299978 0.48218617 0.49178854 0.50156516 0.51152176\n",
      "  0.52094877 0.53178895]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.06363548338413239\n",
      "Predicción post entrenamiento : [[0.5445077]]\n",
      "PERDIDAAAA despues: 0.06237912178039551\n",
      "lr: 0.0002898550724637681, batch: 68\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "68\n",
      "[[[0.47299978]\n",
      "  [0.48218617]\n",
      "  [0.49178854]\n",
      "  [0.50156516]\n",
      "  [0.51152176]\n",
      "  [0.52094877]\n",
      "  [0.53178895]\n",
      "  [0.54200506]]]\n",
      "ejemplar: [0.47299978 0.48218617 0.49178854 0.50156516 0.51152176 0.52094877\n",
      " 0.53178895 0.54200506]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.55223936]]\n",
      "Lr que voy a aplicar en el lote: 69 es 0.00028985505923628807\n",
      "lote que voy a entrenar: [[0.47299978 0.48218617 0.49178854 0.50156516 0.51152176 0.52094877\n",
      "  0.53178895 0.54200506]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05362251400947571\n",
      "Predicción post entrenamiento : [[0.55462664]]\n",
      "PERDIDAAAA despues: 0.05252258852124214\n",
      "lr: 0.00028571428571428574, batch: 69\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "69\n",
      "[[[0.48218617]\n",
      "  [0.49178854]\n",
      "  [0.50156516]\n",
      "  [0.51152176]\n",
      "  [0.52094877]\n",
      "  [0.53178895]\n",
      "  [0.54200506]\n",
      "  [0.55223936]]]\n",
      "ejemplar: [0.48218617 0.49178854 0.50156516 0.51152176 0.52094877 0.53178895\n",
      " 0.54200506 0.55223936]\n",
      "y: 0.7679194110809764\n",
      "Predicción : [[0.56253153]]\n",
      "Lr que voy a aplicar en el lote: 70 es 0.0002857142826542258\n",
      "lote que voy a entrenar: [[0.48218617 0.49178854 0.50156516 0.51152176 0.52094877 0.53178895\n",
      "  0.54200506 0.55223936]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04218418523669243\n",
      "Predicción post entrenamiento : [[0.56471854]]\n",
      "PERDIDAAAA despues: 0.04129059612751007\n",
      "lr: 0.00028169014084507044, batch: 70\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "70\n",
      "[[[0.49178854]\n",
      "  [0.50156516]\n",
      "  [0.51152176]\n",
      "  [0.52094877]\n",
      "  [0.53178895]\n",
      "  [0.54200506]\n",
      "  [0.55223936]\n",
      "  [0.56253153]]]\n",
      "ejemplar: [0.49178854 0.50156516 0.51152176 0.52094877 0.53178895 0.54200506\n",
      " 0.55223936 0.56253153]\n",
      "y: 0.7845796203022084\n",
      "Predicción : [[0.57284194]]\n",
      "Lr que voy a aplicar en el lote: 71 es 0.00028169015422463417\n",
      "lote que voy a entrenar: [[0.49178854 0.50156516 0.51152176 0.52094877 0.53178895 0.54200506\n",
      "  0.55223936 0.56253153]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.044832851737737656\n",
      "Predicción post entrenamiento : [[0.5748874]]\n",
      "PERDIDAAAA despues: 0.04397083446383476\n",
      "lr: 0.0002777777777777778, batch: 71\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "71\n",
      "[[[0.50156516]\n",
      "  [0.51152176]\n",
      "  [0.52094877]\n",
      "  [0.53178895]\n",
      "  [0.54200506]\n",
      "  [0.55223936]\n",
      "  [0.56253153]\n",
      "  [0.57284194]]]\n",
      "ejemplar: [0.50156516 0.51152176 0.52094877 0.53178895 0.54200506 0.55223936\n",
      " 0.56253153 0.57284194]\n",
      "y: 0.8787291747384733\n",
      "Predicción : [[0.58316106]]\n",
      "Lr que voy a aplicar en el lote: 72 es 0.00027777778450399637\n",
      "lote que voy a entrenar: [[0.50156516 0.51152176 0.52094877 0.53178895 0.54200506 0.55223936\n",
      "  0.56253153 0.57284194]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.08736050873994827\n",
      "Predicción post entrenamiento : [[0.5858773]]\n",
      "PERDIDAAAA despues: 0.08576221764087677\n",
      "lr: 0.000273972602739726, batch: 72\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "72\n",
      "[[[0.51152176]\n",
      "  [0.52094877]\n",
      "  [0.53178895]\n",
      "  [0.54200506]\n",
      "  [0.55223936]\n",
      "  [0.56253153]\n",
      "  [0.57284194]\n",
      "  [0.58316106]]]\n",
      "ejemplar: [0.51152176 0.52094877 0.53178895 0.54200506 0.55223936 0.56253153\n",
      " 0.57284194 0.58316106]\n",
      "y: 0.8756296009298721\n",
      "Predicción : [[0.59428585]]\n",
      "Lr que voy a aplicar en el lote: 73 es 0.0002739726041909307\n",
      "lote que voy a entrenar: [[0.51152176 0.52094877 0.53178895 0.54200506 0.55223936 0.56253153\n",
      "  0.57284194 0.58316106]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07915431261062622\n",
      "Predicción post entrenamiento : [[0.59723485]]\n",
      "PERDIDAAAA despues: 0.07750364392995834\n",
      "lr: 0.0002702702702702703, batch: 73\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "73\n",
      "[[[0.52094877]\n",
      "  [0.53178895]\n",
      "  [0.54200506]\n",
      "  [0.55223936]\n",
      "  [0.56253153]\n",
      "  [0.57284194]\n",
      "  [0.58316106]\n",
      "  [0.59428585]]]\n",
      "ejemplar: [0.52094877 0.53178895 0.54200506 0.55223936 0.56253153 0.57284194\n",
      " 0.58316106 0.59428585]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.60575736]]\n",
      "Lr que voy a aplicar en el lote: 74 es 0.0002702702768146992\n",
      "lote que voy a entrenar: [[0.52094877 0.53178895 0.54200506 0.55223936 0.56253153 0.57284194\n",
      "  0.58316106 0.59428585]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05911629647016525\n",
      "Predicción post entrenamiento : [[0.60803556]]\n",
      "PERDIDAAAA despues: 0.05801364779472351\n",
      "lr: 0.0002666666666666667, batch: 74\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "74\n",
      "[[[0.53178895]\n",
      "  [0.54200506]\n",
      "  [0.55223936]\n",
      "  [0.56253153]\n",
      "  [0.57284194]\n",
      "  [0.58316106]\n",
      "  [0.59428585]\n",
      "  [0.60575736]]]\n",
      "ejemplar: [0.53178895 0.54200506 0.55223936 0.56253153 0.57284194 0.58316106\n",
      " 0.59428585 0.60575736]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.6168463]]\n",
      "Lr que voy a aplicar en el lote: 75 es 0.00026666666963137686\n",
      "lote que voy a entrenar: [[0.53178895 0.54200506 0.55223936 0.56253153 0.57284194 0.58316106\n",
      "  0.59428585 0.60575736]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04057854413986206\n",
      "Predicción post entrenamiento : [[0.61862165]]\n",
      "PERDIDAAAA despues: 0.03986645117402077\n",
      "lr: 0.0002631578947368421, batch: 75\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "75\n",
      "[[[0.54200506]\n",
      "  [0.55223936]\n",
      "  [0.56253153]\n",
      "  [0.57284194]\n",
      "  [0.58316106]\n",
      "  [0.59428585]\n",
      "  [0.60575736]\n",
      "  [0.61684632]]]\n",
      "ejemplar: [0.54200506 0.55223936 0.56253153 0.57284194 0.58316106 0.59428585\n",
      " 0.60575736 0.61684632]\n",
      "y: 0.8268113134444013\n",
      "Predicción : [[0.6273807]]\n",
      "Lr que voy a aplicar en el lote: 76 es 0.0002631578827276826\n",
      "lote que voy a entrenar: [[0.54200506 0.55223936 0.56253153 0.57284194 0.58316106 0.59428585\n",
      "  0.60575736 0.61684632]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03977255895733833\n",
      "Predicción post entrenamiento : [[0.6298105]]\n",
      "PERDIDAAAA despues: 0.038809314370155334\n",
      "lr: 0.00025974025974025974, batch: 76\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "76\n",
      "[[[0.55223936]\n",
      "  [0.56253153]\n",
      "  [0.57284194]\n",
      "  [0.58316106]\n",
      "  [0.59428585]\n",
      "  [0.60575736]\n",
      "  [0.61684632]\n",
      "  [0.62738073]]]\n",
      "ejemplar: [0.55223936 0.56253153 0.57284194 0.58316106 0.59428585 0.60575736\n",
      " 0.61684632 0.62738073]\n",
      "y: 0.7853545137543589\n",
      "Predicción : [[0.6386985]]\n",
      "Lr que voy a aplicar en el lote: 77 es 0.0002597402490209788\n",
      "lote que voy a entrenar: [[0.55223936 0.56253153 0.57284194 0.58316106 0.59428585 0.60575736\n",
      "  0.61684632 0.62738073]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.021507974714040756\n",
      "Predicción post entrenamiento : [[0.6405632]]\n",
      "PERDIDAAAA despues: 0.020964521914720535\n",
      "lr: 0.0002564102564102564, batch: 77\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "77\n",
      "[[[0.56253153]\n",
      "  [0.57284194]\n",
      "  [0.58316106]\n",
      "  [0.59428585]\n",
      "  [0.60575736]\n",
      "  [0.61684632]\n",
      "  [0.62738073]\n",
      "  [0.63869852]]]\n",
      "ejemplar: [0.56253153 0.57284194 0.58316106 0.59428585 0.60575736 0.61684632\n",
      " 0.62738073 0.63869852]\n",
      "y: 0.7892289810151103\n",
      "Predicción : [[0.64960724]]\n",
      "Lr que voy a aplicar en el lote: 78 es 0.00025641024694778025\n",
      "lote que voy a entrenar: [[0.56253153 0.57284194 0.58316106 0.59428585 0.60575736 0.61684632\n",
      "  0.62738073 0.63869852]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019494228065013885\n",
      "Predicción post entrenamiento : [[0.65088075]]\n",
      "PERDIDAAAA despues: 0.019140230491757393\n",
      "lr: 0.00025316455696202533, batch: 78\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "78\n",
      "[[[0.57284194]\n",
      "  [0.58316106]\n",
      "  [0.59428585]\n",
      "  [0.60575736]\n",
      "  [0.61684632]\n",
      "  [0.62738073]\n",
      "  [0.63869852]\n",
      "  [0.64960724]]]\n",
      "ejemplar: [0.57284194 0.58316106 0.59428585 0.60575736 0.61684632 0.62738073\n",
      " 0.63869852 0.64960724]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.6600985]]\n",
      "Lr que voy a aplicar en el lote: 79 es 0.00025316455867141485\n",
      "lote que voy a entrenar: [[0.57284194 0.58316106 0.59428585 0.60575736 0.61684632 0.62738073\n",
      "  0.63869852 0.64960724]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.030301859602332115\n",
      "Predicción post entrenamiento : [[0.6617493]]\n",
      "PERDIDAAAA despues: 0.02972985804080963\n",
      "lr: 0.00025, batch: 79\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "79\n",
      "[[[0.58316106]\n",
      "  [0.59428585]\n",
      "  [0.60575736]\n",
      "  [0.61684632]\n",
      "  [0.62738073]\n",
      "  [0.63869852]\n",
      "  [0.64960724]\n",
      "  [0.66009849]]]\n",
      "ejemplar: [0.58316106 0.59428585 0.60575736 0.61684632 0.62738073 0.63869852\n",
      " 0.64960724 0.66009849]\n",
      "y: 0.8124757845796202\n",
      "Predicción : [[0.6711671]]\n",
      "Lr que voy a aplicar en el lote: 80 es 0.0002500000118743628\n",
      "lote que voy a entrenar: [[0.58316106 0.59428585 0.60575736 0.61684632 0.62738073 0.63869852\n",
      "  0.64960724 0.66009849]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.019968155771493912\n",
      "Predicción post entrenamiento : [[0.6725606]]\n",
      "PERDIDAAAA despues: 0.019576270133256912\n",
      "lr: 0.0002469135802469136, batch: 80\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "80\n",
      "[[[0.59428585]\n",
      "  [0.60575736]\n",
      "  [0.61684632]\n",
      "  [0.62738073]\n",
      "  [0.63869852]\n",
      "  [0.64960724]\n",
      "  [0.66009849]\n",
      "  [0.67116708]]]\n",
      "ejemplar: [0.59428585 0.60575736 0.61684632 0.62738073 0.63869852 0.64960724\n",
      " 0.66009849 0.67116708]\n",
      "y: 0.8012398295234404\n",
      "Predicción : [[0.68220186]]\n",
      "Lr que voy a aplicar en el lote: 81 es 0.0002469135797582567\n",
      "lote que voy a entrenar: [[0.59428585 0.60575736 0.61684632 0.62738073 0.63869852 0.64960724\n",
      "  0.66009849 0.67116708]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014170042239129543\n",
      "Predicción post entrenamiento : [[0.68343437]]\n",
      "PERDIDAAAA despues: 0.013878131285309792\n",
      "lr: 0.00024390243902439024, batch: 81\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "81\n",
      "[[[0.60575736]\n",
      "  [0.61684632]\n",
      "  [0.62738073]\n",
      "  [0.63869852]\n",
      "  [0.64960724]\n",
      "  [0.66009849]\n",
      "  [0.67116708]\n",
      "  [0.68220186]]]\n",
      "ejemplar: [0.60575736 0.61684632 0.62738073 0.63869852 0.64960724 0.66009849\n",
      " 0.67116708 0.68220186]\n",
      "y: 0.8031770631538162\n",
      "Predicción : [[0.6930899]]\n",
      "Lr que voy a aplicar en el lote: 82 es 0.0002439024392515421\n",
      "lote que voy a entrenar: [[0.60575736 0.61684632 0.62738073 0.63869852 0.64960724 0.66009849\n",
      "  0.67116708 0.68220186]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012119182385504246\n",
      "Predicción post entrenamiento : [[0.69423616]]\n",
      "PERDIDAAAA despues: 0.011868119239807129\n",
      "lr: 0.00024096385542168676, batch: 82\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "82\n",
      "[[[0.61684632]\n",
      "  [0.62738073]\n",
      "  [0.63869852]\n",
      "  [0.64960724]\n",
      "  [0.66009849]\n",
      "  [0.67116708]\n",
      "  [0.68220186]\n",
      "  [0.6930899 ]]]\n",
      "ejemplar: [0.61684632 0.62738073 0.63869852 0.64960724 0.66009849 0.67116708\n",
      " 0.68220186 0.6930899 ]\n",
      "y: 0.793490895001937\n",
      "Predicción : [[0.70379364]]\n",
      "Lr que voy a aplicar en el lote: 83 es 0.00024096385459415615\n",
      "lote que voy a entrenar: [[0.61684632 0.62738073 0.63869852 0.64960724 0.66009849 0.67116708\n",
      "  0.68220186 0.6930899 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00804559513926506\n",
      "Predicción post entrenamiento : [[0.70435756]]\n",
      "PERDIDAAAA despues: 0.007944748736917973\n",
      "lr: 0.0002380952380952381, batch: 83\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "83\n",
      "[[[0.62738073]\n",
      "  [0.63869852]\n",
      "  [0.64960724]\n",
      "  [0.66009849]\n",
      "  [0.67116708]\n",
      "  [0.68220186]\n",
      "  [0.6930899 ]\n",
      "  [0.70379364]]]\n",
      "ejemplar: [0.62738073 0.63869852 0.64960724 0.66009849 0.67116708 0.68220186\n",
      " 0.6930899  0.70379364]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.7138995]]\n",
      "Lr que voy a aplicar en el lote: 84 es 0.0002380952355451882\n",
      "lote que voy a entrenar: [[0.62738073 0.63869852 0.64960724 0.66009849 0.67116708 0.68220186\n",
      "  0.6930899  0.70379364]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002141002332791686\n",
      "Predicción post entrenamiento : [[0.7143011]]\n",
      "PERDIDAAAA despues: 0.0021039973944425583\n",
      "lr: 0.00023529411764705883, batch: 84\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "84\n",
      "[[[0.63869852]\n",
      "  [0.64960724]\n",
      "  [0.66009849]\n",
      "  [0.67116708]\n",
      "  [0.68220186]\n",
      "  [0.6930899 ]\n",
      "  [0.70379364]\n",
      "  [0.71389949]]]\n",
      "ejemplar: [0.63869852 0.64960724 0.66009849 0.67116708 0.68220186 0.6930899\n",
      " 0.70379364 0.71389949]\n",
      "y: 0.7353738860906625\n",
      "Predicción : [[0.7239733]]\n",
      "Lr que voy a aplicar en el lote: 85 es 0.00023529412283096462\n",
      "lote que voy a entrenar: [[0.63869852 0.64960724 0.66009849 0.67116708 0.68220186 0.6930899\n",
      "  0.70379364 0.71389949]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00012997459270991385\n",
      "Predicción post entrenamiento : [[0.7244144]]\n",
      "PERDIDAAAA despues: 0.00012011077342322096\n",
      "lr: 0.00023255813953488373, batch: 85\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "85\n",
      "[[[0.64960724]\n",
      "  [0.66009849]\n",
      "  [0.67116708]\n",
      "  [0.68220186]\n",
      "  [0.6930899 ]\n",
      "  [0.70379364]\n",
      "  [0.71389949]\n",
      "  [0.72397327]]]\n",
      "ejemplar: [0.64960724 0.66009849 0.67116708 0.68220186 0.6930899  0.70379364\n",
      " 0.71389949 0.72397327]\n",
      "y: 0.7101898488957767\n",
      "Predicción : [[0.73398936]]\n",
      "Lr que voy a aplicar en el lote: 86 es 0.00023255814448930323\n",
      "lote que voy a entrenar: [[0.64960724 0.66009849 0.67116708 0.68220186 0.6930899  0.70379364\n",
      "  0.71389949 0.72397327]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005664180498570204\n",
      "Predicción post entrenamiento : [[0.7329281]]\n",
      "PERDIDAAAA despues: 0.0005170292570255697\n",
      "lr: 0.00022988505747126436, batch: 86\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "86\n",
      "[[[0.66009849]\n",
      "  [0.67116708]\n",
      "  [0.68220186]\n",
      "  [0.6930899 ]\n",
      "  [0.70379364]\n",
      "  [0.71389949]\n",
      "  [0.72397327]\n",
      "  [0.73398936]]]\n",
      "ejemplar: [0.66009849 0.67116708 0.68220186 0.6930899  0.70379364 0.71389949\n",
      " 0.72397327 0.73398936]\n",
      "y: 0.7121270825261525\n",
      "Predicción : [[0.7424798]]\n",
      "Lr que voy a aplicar en el lote: 87 es 0.00022988505952525884\n",
      "lote que voy a entrenar: [[0.66009849 0.67116708 0.68220186 0.6930899  0.70379364 0.71389949\n",
      "  0.72397327 0.73398936]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009212871082127094\n",
      "Predicción post entrenamiento : [[0.74123824]]\n",
      "PERDIDAAAA despues: 0.0008474588976241648\n",
      "lr: 0.00022727272727272727, batch: 87\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "87\n",
      "[[[0.67116708]\n",
      "  [0.68220186]\n",
      "  [0.6930899 ]\n",
      "  [0.70379364]\n",
      "  [0.71389949]\n",
      "  [0.72397327]\n",
      "  [0.73398936]\n",
      "  [0.7424798 ]]]\n",
      "ejemplar: [0.67116708 0.68220186 0.6930899  0.70379364 0.71389949 0.72397327\n",
      " 0.73398936 0.7424798 ]\n",
      "y: 0.7396358000774894\n",
      "Predicción : [[0.7508502]]\n",
      "Lr que voy a aplicar en el lote: 88 es 0.00022727272880729288\n",
      "lote que voy a entrenar: [[0.67116708 0.68220186 0.6930899  0.70379364 0.71389949 0.72397327\n",
      "  0.73398936 0.7424798 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00012576222070492804\n",
      "Predicción post entrenamiento : [[0.75136226]]\n",
      "PERDIDAAAA despues: 0.000137509370688349\n",
      "lr: 0.00022471910112359551, batch: 88\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "88\n",
      "[[[0.68220186]\n",
      "  [0.6930899 ]\n",
      "  [0.70379364]\n",
      "  [0.71389949]\n",
      "  [0.72397327]\n",
      "  [0.73398936]\n",
      "  [0.7424798 ]\n",
      "  [0.7508502 ]]]\n",
      "ejemplar: [0.68220186 0.6930899  0.70379364 0.71389949 0.72397327 0.73398936\n",
      " 0.7424798  0.7508502 ]\n",
      "y: 0.7361487795428128\n",
      "Predicción : [[0.7608287]]\n",
      "Lr que voy a aplicar en el lote: 89 es 0.00022471910051535815\n",
      "lote que voy a entrenar: [[0.68220186 0.6930899  0.70379364 0.71389949 0.72397327 0.73398936\n",
      "  0.7424798  0.7508502 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006090974202379584\n",
      "Predicción post entrenamiento : [[0.7592648]]\n",
      "PERDIDAAAA despues: 0.0005343518569134176\n",
      "lr: 0.00022222222222222223, batch: 89\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "89\n",
      "[[[0.6930899 ]\n",
      "  [0.70379364]\n",
      "  [0.71389949]\n",
      "  [0.72397327]\n",
      "  [0.73398936]\n",
      "  [0.7424798 ]\n",
      "  [0.7508502 ]\n",
      "  [0.76082867]]]\n",
      "ejemplar: [0.6930899  0.70379364 0.71389949 0.72397327 0.73398936 0.7424798\n",
      " 0.7508502  0.76082867]\n",
      "y: 0.6675707090275087\n",
      "Predicción : [[0.76850975]]\n",
      "Lr que voy a aplicar en el lote: 90 es 0.00022222222469281405\n",
      "lote que voy a entrenar: [[0.6930899  0.70379364 0.71389949 0.72397327 0.73398936 0.7424798\n",
      "  0.7508502  0.76082867]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010188688524067402\n",
      "Predicción post entrenamiento : [[0.7677407]]\n",
      "PERDIDAAAA despues: 0.010034032166004181\n",
      "lr: 0.00021978021978021978, batch: 90\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "90\n",
      "[[[0.70379364]\n",
      "  [0.71389949]\n",
      "  [0.72397327]\n",
      "  [0.73398936]\n",
      "  [0.7424798 ]\n",
      "  [0.7508502 ]\n",
      "  [0.76082867]\n",
      "  [0.76850975]]]\n",
      "ejemplar: [0.70379364 0.71389949 0.72397327 0.73398936 0.7424798  0.7508502\n",
      " 0.76082867 0.76850975]\n",
      "y: 0.6698953893839596\n",
      "Predicción : [[0.7767185]]\n",
      "Lr que voy a aplicar en el lote: 91 es 0.00021978022414259613\n",
      "lote que voy a entrenar: [[0.70379364 0.71389949 0.72397327 0.73398936 0.7424798  0.7508502\n",
      "  0.76082867 0.76850975]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011411171406507492\n",
      "Predicción post entrenamiento : [[0.77529293]]\n",
      "PERDIDAAAA despues: 0.011108637787401676\n",
      "lr: 0.0002173913043478261, batch: 91\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "91\n",
      "[[[0.71389949]\n",
      "  [0.72397327]\n",
      "  [0.73398936]\n",
      "  [0.7424798 ]\n",
      "  [0.7508502 ]\n",
      "  [0.76082867]\n",
      "  [0.76850975]\n",
      "  [0.7767185 ]]]\n",
      "ejemplar: [0.71389949 0.72397327 0.73398936 0.7424798  0.7508502  0.76082867\n",
      " 0.76850975 0.7767185 ]\n",
      "y: 0.696629213483146\n",
      "Predicción : [[0.7839571]]\n",
      "Lr que voy a aplicar en el lote: 92 es 0.00021739130897913128\n",
      "lote que voy a entrenar: [[0.71389949 0.72397327 0.73398936 0.7424798  0.7508502  0.76082867\n",
      "  0.76850975 0.7767185 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00762616191059351\n",
      "Predicción post entrenamiento : [[0.78228974]]\n",
      "PERDIDAAAA despues: 0.007337724324315786\n",
      "lr: 0.00021505376344086021, batch: 92\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "92\n",
      "[[[0.72397327]\n",
      "  [0.73398936]\n",
      "  [0.7424798 ]\n",
      "  [0.7508502 ]\n",
      "  [0.76082867]\n",
      "  [0.76850975]\n",
      "  [0.7767185 ]\n",
      "  [0.78395712]]]\n",
      "ejemplar: [0.72397327 0.73398936 0.7424798  0.7508502  0.76082867 0.76850975\n",
      " 0.7767185  0.78395712]\n",
      "y: 0.6559473072452537\n",
      "Predicción : [[0.7907117]]\n",
      "Lr que voy a aplicar en el lote: 93 es 0.00021505376207642257\n",
      "lote que voy a entrenar: [[0.72397327 0.73398936 0.7424798  0.7508502  0.76082867 0.76850975\n",
      "  0.7767185  0.78395712]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018161436542868614\n",
      "Predicción post entrenamiento : [[0.7891445]]\n",
      "PERDIDAAAA despues: 0.01774149015545845\n",
      "lr: 0.0002127659574468085, batch: 93\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "93\n",
      "[[[0.73398936]\n",
      "  [0.7424798 ]\n",
      "  [0.7508502 ]\n",
      "  [0.76082867]\n",
      "  [0.76850975]\n",
      "  [0.7767185 ]\n",
      "  [0.78395712]\n",
      "  [0.7907117 ]]]\n",
      "ejemplar: [0.73398936 0.7424798  0.7508502  0.76082867 0.76850975 0.7767185\n",
      " 0.78395712 0.7907117 ]\n",
      "y: 0.6788066640836885\n",
      "Predicción : [[0.7972355]]\n",
      "Lr que voy a aplicar en el lote: 94 es 0.00021276595361996442\n",
      "lote que voy a entrenar: [[0.73398936 0.7424798  0.7508502  0.76082867 0.76850975 0.7767185\n",
      "  0.78395712 0.7907117 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.014025387354195118\n",
      "Predicción post entrenamiento : [[0.7953446]]\n",
      "PERDIDAAAA despues: 0.013581088744103909\n",
      "lr: 0.0002105263157894737, batch: 94\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "94\n",
      "[[[0.7424798 ]\n",
      "  [0.7508502 ]\n",
      "  [0.76082867]\n",
      "  [0.76850975]\n",
      "  [0.7767185 ]\n",
      "  [0.78395712]\n",
      "  [0.7907117 ]\n",
      "  [0.79723549]]]\n",
      "ejemplar: [0.7424798  0.7508502  0.76082867 0.76850975 0.7767185  0.78395712\n",
      " 0.7907117  0.79723549]\n",
      "y: 0.6760945370011622\n",
      "Predicción : [[0.8030068]]\n",
      "Lr que voy a aplicar en el lote: 95 es 0.00021052631200291216\n",
      "lote que voy a entrenar: [[0.7424798  0.7508502  0.76082867 0.76850975 0.7767185  0.78395712\n",
      "  0.7907117  0.79723549]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.016106730327010155\n",
      "Predicción post entrenamiento : [[0.8019421]]\n",
      "PERDIDAAAA despues: 0.015837613493204117\n",
      "lr: 0.00020833333333333335, batch: 95\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "95\n",
      "[[[0.7508502 ]\n",
      "  [0.76082867]\n",
      "  [0.76850975]\n",
      "  [0.7767185 ]\n",
      "  [0.78395712]\n",
      "  [0.7907117 ]\n",
      "  [0.79723549]\n",
      "  [0.80300683]]]\n",
      "ejemplar: [0.7508502  0.76082867 0.76850975 0.7767185  0.78395712 0.7907117\n",
      " 0.79723549 0.80300683]\n",
      "y: 0.7295621851995349\n",
      "Predicción : [[0.8095024]]\n",
      "Lr que voy a aplicar en el lote: 96 es 0.00020833333837799728\n",
      "lote que voy a entrenar: [[0.7508502  0.76082867 0.76850975 0.7767185  0.78395712 0.7907117\n",
      "  0.79723549 0.80300683]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0063904449343681335\n",
      "Predicción post entrenamiento : [[0.8086962]]\n",
      "PERDIDAAAA despues: 0.006262197624891996\n",
      "lr: 0.0002061855670103093, batch: 96\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "96\n",
      "[[[0.76082867]\n",
      "  [0.76850975]\n",
      "  [0.7767185 ]\n",
      "  [0.78395712]\n",
      "  [0.7907117 ]\n",
      "  [0.79723549]\n",
      "  [0.80300683]\n",
      "  [0.80950242]]]\n",
      "ejemplar: [0.76082867 0.76850975 0.7767185  0.78395712 0.7907117  0.79723549\n",
      " 0.80300683 0.80950242]\n",
      "y: 0.7012785741960481\n",
      "Predicción : [[0.8161061]]\n",
      "Lr que voy a aplicar en el lote: 97 es 0.0002061855630017817\n",
      "lote que voy a entrenar: [[0.76082867 0.76850975 0.7767185  0.78395712 0.7907117  0.79723549\n",
      "  0.80300683 0.80950242]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013185357674956322\n",
      "Predicción post entrenamiento : [[0.8148586]]\n",
      "PERDIDAAAA despues: 0.012900426983833313\n",
      "lr: 0.00020408163265306123, batch: 97\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "97\n",
      "[[[0.76850975]\n",
      "  [0.7767185 ]\n",
      "  [0.78395712]\n",
      "  [0.7907117 ]\n",
      "  [0.79723549]\n",
      "  [0.80300683]\n",
      "  [0.80950242]\n",
      "  [0.81610608]]]\n",
      "ejemplar: [0.76850975 0.7767185  0.78395712 0.7907117  0.79723549 0.80300683\n",
      " 0.80950242 0.81610608]\n",
      "y: 0.767531964354901\n",
      "Predicción : [[0.82154363]]\n",
      "Lr que voy a aplicar en el lote: 98 es 0.0002040816325461492\n",
      "lote que voy a entrenar: [[0.76850975 0.7767185  0.78395712 0.7907117  0.79723549 0.80300683\n",
      "  0.80950242 0.81610608]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0029172576032578945\n",
      "Predicción post entrenamiento : [[0.82193106]]\n",
      "PERDIDAAAA despues: 0.0029592590872198343\n",
      "lr: 0.00020202020202020202, batch: 98\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "98\n",
      "[[[0.7767185 ]\n",
      "  [0.78395712]\n",
      "  [0.7907117 ]\n",
      "  [0.79723549]\n",
      "  [0.80300683]\n",
      "  [0.80950242]\n",
      "  [0.81610608]\n",
      "  [0.82154363]]]\n",
      "ejemplar: [0.7767185  0.78395712 0.7907117  0.79723549 0.80300683 0.80950242\n",
      " 0.81610608 0.82154363]\n",
      "y: 0.7551336691204957\n",
      "Predicción : [[0.82841814]]\n",
      "Lr que voy a aplicar en el lote: 99 es 0.00020202020823489875\n",
      "lote que voy a entrenar: [[0.7767185  0.78395712 0.7907117  0.79723549 0.80300683 0.80950242\n",
      "  0.81610608 0.82154363]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005370610393583775\n",
      "Predicción post entrenamiento : [[0.8280382]]\n",
      "PERDIDAAAA despues: 0.005315070040524006\n",
      "lr: 0.0002, batch: 99\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "99\n",
      "[[[0.78395712]\n",
      "  [0.7907117 ]\n",
      "  [0.79723549]\n",
      "  [0.80300683]\n",
      "  [0.80950242]\n",
      "  [0.81610608]\n",
      "  [0.82154363]\n",
      "  [0.82841814]]]\n",
      "ejemplar: [0.78395712 0.7907117  0.79723549 0.80300683 0.80950242 0.81610608\n",
      " 0.82154363 0.82841814]\n",
      "y: 0.7450600542425416\n",
      "Predicción : [[0.8340978]]\n",
      "Lr que voy a aplicar en el lote: 100 es 0.00019999999494757503\n",
      "lote que voy a entrenar: [[0.78395712 0.7907117  0.79723549 0.80300683 0.80950242 0.81610608\n",
      "  0.82154363 0.82841814]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.007927725091576576\n",
      "Predicción post entrenamiento : [[0.83390737]]\n",
      "PERDIDAAAA despues: 0.007893850095570087\n",
      "lr: 0.00019801980198019803, batch: 100\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "100\n",
      "[[[0.7907117 ]\n",
      "  [0.79723549]\n",
      "  [0.80300683]\n",
      "  [0.80950242]\n",
      "  [0.81610608]\n",
      "  [0.82154363]\n",
      "  [0.82841814]\n",
      "  [0.8340978 ]]]\n",
      "ejemplar: [0.7907117  0.79723549 0.80300683 0.80950242 0.81610608 0.82154363\n",
      " 0.82841814 0.8340978 ]\n",
      "y: 0.7520340953118947\n",
      "Predicción : [[0.8397409]]\n",
      "Lr que voy a aplicar en el lote: 101 es 0.00019801979942712933\n",
      "lote que voy a entrenar: [[0.7907117  0.79723549 0.80300683 0.80950242 0.81610608 0.82154363\n",
      "  0.82841814 0.8340978 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0076924837194383144\n",
      "Predicción post entrenamiento : [[0.8385711]]\n",
      "PERDIDAAAA despues: 0.007488653063774109\n",
      "lr: 0.000196078431372549, batch: 101\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "101\n",
      "[[[0.79723549]\n",
      "  [0.80300683]\n",
      "  [0.80950242]\n",
      "  [0.81610608]\n",
      "  [0.82154363]\n",
      "  [0.82841814]\n",
      "  [0.8340978 ]\n",
      "  [0.83974087]]]\n",
      "ejemplar: [0.79723549 0.80300683 0.80950242 0.81610608 0.82154363 0.82841814\n",
      " 0.8340978  0.83974087]\n",
      "y: 0.7098024021697016\n",
      "Predicción : [[0.84426993]]\n",
      "Lr que voy a aplicar en el lote: 102 es 0.0001960784284165129\n",
      "lote que voy a entrenar: [[0.79723549 0.80300683 0.80950242 0.81610608 0.82154363 0.82841814\n",
      "  0.8340978  0.83974087]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01808151975274086\n",
      "Predicción post entrenamiento : [[0.84296733]]\n",
      "PERDIDAAAA despues: 0.017732901498675346\n",
      "lr: 0.0001941747572815534, batch: 102\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "102\n",
      "[[[0.80300683]\n",
      "  [0.80950242]\n",
      "  [0.81610608]\n",
      "  [0.82154363]\n",
      "  [0.82841814]\n",
      "  [0.8340978 ]\n",
      "  [0.83974087]\n",
      "  [0.84426993]]]\n",
      "ejemplar: [0.80300683 0.80950242 0.81610608 0.82154363 0.82841814 0.8340978\n",
      " 0.83974087 0.84426993]\n",
      "y: 0.6904300658659435\n",
      "Predicción : [[0.84856004]]\n",
      "Lr que voy a aplicar en el lote: 103 es 0.00019417476141825318\n",
      "lote que voy a entrenar: [[0.80300683 0.80950242 0.81610608 0.82154363 0.82841814 0.8340978\n",
      "  0.83974087 0.84426993]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.025005092844367027\n",
      "Predicción post entrenamiento : [[0.8477956]]\n",
      "PERDIDAAAA despues: 0.024763919413089752\n",
      "lr: 0.0001923076923076923, batch: 103\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "103\n",
      "[[[0.80950242]\n",
      "  [0.81610608]\n",
      "  [0.82154363]\n",
      "  [0.82841814]\n",
      "  [0.8340978 ]\n",
      "  [0.83974087]\n",
      "  [0.84426993]\n",
      "  [0.84856004]]]\n",
      "ejemplar: [0.80950242 0.81610608 0.82154363 0.82841814 0.8340978  0.83974087\n",
      " 0.84426993 0.84856004]\n",
      "y: 0.7543587756683454\n",
      "Predicción : [[0.8534622]]\n",
      "Lr que voy a aplicar en el lote: 104 es 0.0001923076924867928\n",
      "lote que voy a entrenar: [[0.80950242 0.81610608 0.82154363 0.82841814 0.8340978  0.83974087\n",
      "  0.84426993 0.84856004]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009821494109928608\n",
      "Predicción post entrenamiento : [[0.85117465]]\n",
      "PERDIDAAAA despues: 0.00937331560999155\n",
      "lr: 0.00019047619047619048, batch: 104\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "104\n",
      "[[[0.81610608]\n",
      "  [0.82154363]\n",
      "  [0.82841814]\n",
      "  [0.8340978 ]\n",
      "  [0.83974087]\n",
      "  [0.84426993]\n",
      "  [0.84856004]\n",
      "  [0.85346222]]]\n",
      "ejemplar: [0.81610608 0.82154363 0.82841814 0.8340978  0.83974087 0.84426993\n",
      " 0.84856004 0.85346222]\n",
      "y: 0.7222006974041069\n",
      "Predicción : [[0.85666096]]\n",
      "Lr que voy a aplicar en el lote: 105 es 0.00019047618843615055\n",
      "lote que voy a entrenar: [[0.81610608 0.82154363 0.82841814 0.8340978  0.83974087 0.84426993\n",
      "  0.84856004 0.85346222]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.018079563975334167\n",
      "Predicción post entrenamiento : [[0.855874]]\n",
      "PERDIDAAAA despues: 0.01786855421960354\n",
      "lr: 0.00018867924528301886, batch: 105\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "105\n",
      "[[[0.82154363]\n",
      "  [0.82841814]\n",
      "  [0.8340978 ]\n",
      "  [0.83974087]\n",
      "  [0.84426993]\n",
      "  [0.84856004]\n",
      "  [0.85346222]\n",
      "  [0.85666096]]]\n",
      "ejemplar: [0.82154363 0.82841814 0.8340978  0.83974087 0.84426993 0.84856004\n",
      " 0.85346222 0.85666096]\n",
      "y: 0.8485083301046106\n",
      "Predicción : [[0.8610691]]\n",
      "Lr que voy a aplicar en el lote: 106 es 0.00018867924518417567\n",
      "lote que voy a entrenar: [[0.82154363 0.82841814 0.8340978  0.83974087 0.84426993 0.84856004\n",
      "  0.85346222 0.85666096]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00015777182125020772\n",
      "Predicción post entrenamiento : [[0.8606999]]\n",
      "PERDIDAAAA despues: 0.0001486335095250979\n",
      "lr: 0.00018691588785046728, batch: 106\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "106\n",
      "[[[0.82841814]\n",
      "  [0.8340978 ]\n",
      "  [0.83974087]\n",
      "  [0.84426993]\n",
      "  [0.84856004]\n",
      "  [0.85346222]\n",
      "  [0.85666096]\n",
      "  [0.86106908]]]\n",
      "ejemplar: [0.82841814 0.8340978  0.83974087 0.84426993 0.84856004 0.85346222\n",
      " 0.85666096 0.86106908]\n",
      "y: 0.9054629988376597\n",
      "Predicción : [[0.8658573]]\n",
      "Lr que voy a aplicar en el lote: 107 es 0.00018691588775254786\n",
      "lote que voy a entrenar: [[0.82841814 0.8340978  0.83974087 0.84426993 0.84856004 0.85346222\n",
      "  0.85666096 0.86106908]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0015686096157878637\n",
      "Predicción post entrenamiento : [[0.8664422]]\n",
      "PERDIDAAAA despues: 0.0015226210234686732\n",
      "lr: 0.00018518518518518518, batch: 107\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "107\n",
      "[[[0.8340978 ]\n",
      "  [0.83974087]\n",
      "  [0.84426993]\n",
      "  [0.84856004]\n",
      "  [0.85346222]\n",
      "  [0.85666096]\n",
      "  [0.86106908]\n",
      "  [0.8658573 ]]]\n",
      "ejemplar: [0.8340978  0.83974087 0.84426993 0.84856004 0.85346222 0.85666096\n",
      " 0.86106908 0.8658573 ]\n",
      "y: 0.88221619527315\n",
      "Predicción : [[0.8710703]]\n",
      "Lr que voy a aplicar en el lote: 108 es 0.0001851851848186925\n",
      "lote que voy a entrenar: [[0.8340978  0.83974087 0.84426993 0.84856004 0.85346222 0.85666096\n",
      "  0.86106908 0.8658573 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00012423086445778608\n",
      "Predicción post entrenamiento : [[0.8711738]]\n",
      "PERDIDAAAA despues: 0.00012193495058454573\n",
      "lr: 0.0001834862385321101, batch: 108\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "108\n",
      "[[[0.83974087]\n",
      "  [0.84426993]\n",
      "  [0.84856004]\n",
      "  [0.85346222]\n",
      "  [0.85666096]\n",
      "  [0.86106908]\n",
      "  [0.8658573 ]\n",
      "  [0.87107033]]]\n",
      "ejemplar: [0.83974087 0.84426993 0.84856004 0.85346222 0.85666096 0.86106908\n",
      " 0.8658573  0.87107033]\n",
      "y: 0.9077876791941106\n",
      "Predicción : [[0.8755217]]\n",
      "Lr que voy a aplicar en el lote: 109 es 0.00018348623416386545\n",
      "lote que voy a entrenar: [[0.83974087 0.84426993 0.84856004 0.85346222 0.85666096 0.86106908\n",
      "  0.8658573  0.87107033]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.001041092211380601\n",
      "Predicción post entrenamiento : [[0.8758339]]\n",
      "PERDIDAAAA despues: 0.0010210422333329916\n",
      "lr: 0.00018181818181818183, batch: 109\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "109\n",
      "[[[0.84426993]\n",
      "  [0.84856004]\n",
      "  [0.85346222]\n",
      "  [0.85666096]\n",
      "  [0.86106908]\n",
      "  [0.8658573 ]\n",
      "  [0.87107033]\n",
      "  [0.87552172]]]\n",
      "ejemplar: [0.84426993 0.84856004 0.85346222 0.85666096 0.86106908 0.8658573\n",
      " 0.87107033 0.87552172]\n",
      "y: 0.889577683068578\n",
      "Predicción : [[0.8798572]]\n",
      "Lr que voy a aplicar en el lote: 110 es 0.0001818181772250682\n",
      "lote que voy a entrenar: [[0.84426993 0.84856004 0.85346222 0.85666096 0.86106908 0.8658573\n",
      "  0.87107033 0.87552172]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 9.448820492252707e-05\n",
      "Predicción post entrenamiento : [[0.88012147]]\n",
      "PERDIDAAAA despues: 8.942004205891863e-05\n",
      "lr: 0.00018018018018018018, batch: 110\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "110\n",
      "[[[0.84856004]\n",
      "  [0.85346222]\n",
      "  [0.85666096]\n",
      "  [0.86106908]\n",
      "  [0.8658573 ]\n",
      "  [0.87107033]\n",
      "  [0.87552172]\n",
      "  [0.87985718]]]\n",
      "ejemplar: [0.84856004 0.85346222 0.85666096 0.86106908 0.8658573  0.87107033\n",
      " 0.87552172 0.87985718]\n",
      "y: 0.8748547074777218\n",
      "Predicción : [[0.88411164]]\n",
      "Lr que voy a aplicar en el lote: 111 es 0.00018018018454313278\n",
      "lote que voy a entrenar: [[0.84856004 0.85346222 0.85666096 0.86106908 0.8658573  0.87107033\n",
      "  0.87552172 0.87985718]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.569128840463236e-05\n",
      "Predicción post entrenamiento : [[0.8827449]]\n",
      "PERDIDAAAA despues: 6.225563993211836e-05\n",
      "lr: 0.00017857142857142857, batch: 111\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "111\n",
      "[[[0.85346222]\n",
      "  [0.85666096]\n",
      "  [0.86106908]\n",
      "  [0.8658573 ]\n",
      "  [0.87107033]\n",
      "  [0.87552172]\n",
      "  [0.87985718]\n",
      "  [0.88411164]]]\n",
      "ejemplar: [0.85346222 0.85666096 0.86106908 0.8658573  0.87107033 0.87552172\n",
      " 0.87985718 0.88411164]\n",
      "y: 0.9132119333591631\n",
      "Predicción : [[0.8867735]]\n",
      "Lr que voy a aplicar en el lote: 112 es 0.00017857142665889114\n",
      "lote que voy a entrenar: [[0.85346222 0.85666096 0.86106908 0.8658573  0.87107033 0.87552172\n",
      "  0.87985718 0.88411164]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0006989897810854018\n",
      "Predicción post entrenamiento : [[0.88607687]]\n",
      "PERDIDAAAA despues: 0.0007363122422248125\n",
      "lr: 0.00017699115044247788, batch: 112\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "112\n",
      "[[[0.85666096]\n",
      "  [0.86106908]\n",
      "  [0.8658573 ]\n",
      "  [0.87107033]\n",
      "  [0.87552172]\n",
      "  [0.87985718]\n",
      "  [0.88411164]\n",
      "  [0.88677353]]]\n",
      "ejemplar: [0.85666096 0.86106908 0.8658573  0.87107033 0.87552172 0.87985718\n",
      " 0.88411164 0.88677353]\n",
      "y: 1.0\n",
      "Predicción : [[0.8899601]]\n",
      "Lr que voy a aplicar en el lote: 113 es 0.00017699114687275141\n",
      "lote que voy a entrenar: [[0.85666096 0.86106908 0.8658573  0.87107033 0.87552172 0.87985718\n",
      "  0.88411164 0.88677353]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.012108777649700642\n",
      "Predicción post entrenamiento : [[0.89022833]]\n",
      "PERDIDAAAA despues: 0.012049819342792034\n",
      "lr: 0.00017543859649122808, batch: 113\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "113\n",
      "[[[0.86106908]\n",
      "  [0.8658573 ]\n",
      "  [0.87107033]\n",
      "  [0.87552172]\n",
      "  [0.87985718]\n",
      "  [0.88411164]\n",
      "  [0.88677353]\n",
      "  [0.88996011]]]\n",
      "ejemplar: [0.86106908 0.8658573  0.87107033 0.87552172 0.87985718 0.88411164\n",
      " 0.88677353 0.88996011]\n",
      "y: 0.9705540488182873\n",
      "Predicción : [[0.89444906]]\n",
      "Lr que voy a aplicar en el lote: 114 es 0.00017543860303703696\n",
      "lote que voy a entrenar: [[0.86106908 0.8658573  0.87107033 0.87552172 0.87985718 0.88411164\n",
      "  0.88677353 0.88996011]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005791970994323492\n",
      "Predicción post entrenamiento : [[0.8940043]]\n",
      "PERDIDAAAA despues: 0.005859867203980684\n",
      "lr: 0.00017391304347826088, batch: 114\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "114\n",
      "[[[0.8658573 ]\n",
      "  [0.87107033]\n",
      "  [0.87552172]\n",
      "  [0.87985718]\n",
      "  [0.88411164]\n",
      "  [0.88677353]\n",
      "  [0.88996011]\n",
      "  [0.89444906]]]\n",
      "ejemplar: [0.8658573  0.87107033 0.87552172 0.87985718 0.88411164 0.88677353\n",
      " 0.88996011 0.89444906]\n",
      "y: 0.8888027896164277\n",
      "Predicción : [[0.8982167]]\n",
      "Lr que voy a aplicar en el lote: 115 es 0.0001739130384521559\n",
      "lote que voy a entrenar: [[0.8658573  0.87107033 0.87552172 0.87985718 0.88411164 0.88677353\n",
      "  0.88996011 0.89444906]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.862259710440412e-05\n",
      "Predicción post entrenamiento : [[0.8987204]]\n",
      "PERDIDAAAA despues: 9.835912351263687e-05\n",
      "lr: 0.0001724137931034483, batch: 115\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "115\n",
      "[[[0.87107033]\n",
      "  [0.87552172]\n",
      "  [0.87985718]\n",
      "  [0.88411164]\n",
      "  [0.88677353]\n",
      "  [0.88996011]\n",
      "  [0.89444906]\n",
      "  [0.89821672]]]\n",
      "ejemplar: [0.87107033 0.87552172 0.87985718 0.88411164 0.88677353 0.88996011\n",
      " 0.89444906 0.89821672]\n",
      "y: 0.877954281286323\n",
      "Predicción : [[0.902774]]\n",
      "Lr que voy a aplicar en el lote: 116 es 0.00017241379828192294\n",
      "lote que voy a entrenar: [[0.87107033 0.87552172 0.87985718 0.88411164 0.88677353 0.88996011\n",
      "  0.89444906 0.89821672]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.000616016099229455\n",
      "Predicción post entrenamiento : [[0.90334743]]\n",
      "PERDIDAAAA despues: 0.00064481096342206\n",
      "lr: 0.00017094017094017094, batch: 116\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "116\n",
      "[[[0.87552172]\n",
      "  [0.87985718]\n",
      "  [0.88411164]\n",
      "  [0.88677353]\n",
      "  [0.88996011]\n",
      "  [0.89444906]\n",
      "  [0.89821672]\n",
      "  [0.90277398]]]\n",
      "ejemplar: [0.87552172 0.87985718 0.88411164 0.88677353 0.88996011 0.89444906\n",
      " 0.89821672 0.90277398]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.9070635]]\n",
      "Lr que voy a aplicar en el lote: 117 es 0.0001709401694824919\n",
      "lote que voy a entrenar: [[0.87552172 0.87985718 0.88411164 0.88677353 0.88996011 0.89444906\n",
      "  0.89821672 0.90277398]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.003383480943739414\n",
      "Predicción post entrenamiento : [[0.9080577]]\n",
      "PERDIDAAAA despues: 0.003500130493193865\n",
      "lr: 0.00016949152542372882, batch: 117\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "117\n",
      "[[[0.87985718]\n",
      "  [0.88411164]\n",
      "  [0.88677353]\n",
      "  [0.88996011]\n",
      "  [0.89444906]\n",
      "  [0.89821672]\n",
      "  [0.90277398]\n",
      "  [0.90706348]]]\n",
      "ejemplar: [0.87985718 0.88411164 0.88677353 0.88996011 0.89444906 0.89821672\n",
      " 0.90277398 0.90706348]\n",
      "y: 0.8341728012398295\n",
      "Predicción : [[0.9116107]]\n",
      "Lr que voy a aplicar en el lote: 118 es 0.000169491526321508\n",
      "lote que voy a entrenar: [[0.87985718 0.88411164 0.88677353 0.88996011 0.89444906 0.89821672\n",
      "  0.90277398 0.90706348]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005996634252369404\n",
      "Predicción post entrenamiento : [[0.90927225]]\n",
      "PERDIDAAAA despues: 0.005639930255711079\n",
      "lr: 0.0001680672268907563, batch: 118\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "118\n",
      "[[[0.88411164]\n",
      "  [0.88677353]\n",
      "  [0.88996011]\n",
      "  [0.89444906]\n",
      "  [0.89821672]\n",
      "  [0.90277398]\n",
      "  [0.90706348]\n",
      "  [0.91161072]]]\n",
      "ejemplar: [0.88411164 0.88677353 0.88996011 0.89444906 0.89821672 0.90277398\n",
      " 0.90706348 0.91161072]\n",
      "y: 0.8550949244478885\n",
      "Predicción : [[0.9126788]]\n",
      "Lr que voy a aplicar en el lote: 119 es 0.00016806722851470113\n",
      "lote que voy a entrenar: [[0.88411164 0.88677353 0.88996011 0.89444906 0.89821672 0.90277398\n",
      "  0.90706348 0.91161072]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0033159018494188786\n",
      "Predicción post entrenamiento : [[0.91198754]]\n",
      "PERDIDAAAA despues: 0.0032367717940360308\n",
      "lr: 0.00016666666666666666, batch: 119\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "119\n",
      "[[[0.88677353]\n",
      "  [0.88996011]\n",
      "  [0.89444906]\n",
      "  [0.89821672]\n",
      "  [0.90277398]\n",
      "  [0.90706348]\n",
      "  [0.91161072]\n",
      "  [0.91267878]]]\n",
      "ejemplar: [0.88677353 0.88996011 0.89444906 0.89821672 0.90277398 0.90706348\n",
      " 0.91161072 0.91267878]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.9152556]]\n",
      "Lr que voy a aplicar en el lote: 120 es 0.00016666666488163173\n",
      "lote que voy a entrenar: [[0.88677353 0.88996011 0.89444906 0.89821672 0.90277398 0.90706348\n",
      "  0.91161072 0.91267878]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0016010748222470284\n",
      "Predicción post entrenamiento : [[0.91559315]]\n",
      "PERDIDAAAA despues: 0.001628201105631888\n",
      "lr: 0.00016528925619834712, batch: 120\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "120\n",
      "[[[0.88996011]\n",
      "  [0.89444906]\n",
      "  [0.89821672]\n",
      "  [0.90277398]\n",
      "  [0.90706348]\n",
      "  [0.91161072]\n",
      "  [0.91267878]\n",
      "  [0.91525561]]]\n",
      "ejemplar: [0.88996011 0.89444906 0.89821672 0.90277398 0.90706348 0.91161072\n",
      " 0.91267878 0.91525561]\n",
      "y: 0.857032158078264\n",
      "Predicción : [[0.9191851]]\n",
      "Lr que voy a aplicar en el lote: 121 es 0.00016528925334569067\n",
      "lote que voy a entrenar: [[0.88996011 0.89444906 0.89821672 0.90277398 0.90706348 0.91161072\n",
      "  0.91267878 0.91525561]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0038629856426268816\n",
      "Predicción post entrenamiento : [[0.9194578]]\n",
      "PERDIDAAAA despues: 0.0038969572633504868\n",
      "lr: 0.0001639344262295082, batch: 121\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "121\n",
      "[[[0.89444906]\n",
      "  [0.89821672]\n",
      "  [0.90277398]\n",
      "  [0.90706348]\n",
      "  [0.91161072]\n",
      "  [0.91267878]\n",
      "  [0.91525561]\n",
      "  [0.9191851 ]]]\n",
      "ejemplar: [0.89444906 0.89821672 0.90277398 0.90706348 0.91161072 0.91267878\n",
      " 0.91525561 0.9191851 ]\n",
      "y: 0.8500581170089112\n",
      "Predicción : [[0.9232409]]\n",
      "Lr que voy a aplicar en el lote: 122 es 0.00016393442638218403\n",
      "lote que voy a entrenar: [[0.89444906 0.89821672 0.90277398 0.90706348 0.91161072 0.91267878\n",
      "  0.91525561 0.9191851 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005355716682970524\n",
      "Predicción post entrenamiento : [[0.9217945]]\n",
      "PERDIDAAAA despues: 0.005146102048456669\n",
      "lr: 0.00016260162601626016, batch: 122\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "122\n",
      "[[[0.89821672]\n",
      "  [0.90277398]\n",
      "  [0.90706348]\n",
      "  [0.91161072]\n",
      "  [0.91267878]\n",
      "  [0.91525561]\n",
      "  [0.9191851 ]\n",
      "  [0.9232409 ]]]\n",
      "ejemplar: [0.89821672 0.90277398 0.90706348 0.91161072 0.91267878 0.91525561\n",
      " 0.9191851  0.9232409 ]\n",
      "y: 0.8426966292134832\n",
      "Predicción : [[0.9253654]]\n",
      "Lr que voy a aplicar en el lote: 123 es 0.00016260163101833314\n",
      "lote que voy a entrenar: [[0.89821672 0.90277398 0.90706348 0.91161072 0.91267878 0.91525561\n",
      "  0.9191851  0.9232409 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006834127474576235\n",
      "Predicción post entrenamiento : [[0.9244499]]\n",
      "PERDIDAAAA despues: 0.006683604326099157\n",
      "lr: 0.00016129032258064516, batch: 123\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "123\n",
      "[[[0.90277398]\n",
      "  [0.90706348]\n",
      "  [0.91161072]\n",
      "  [0.91267878]\n",
      "  [0.91525561]\n",
      "  [0.9191851 ]\n",
      "  [0.9232409 ]\n",
      "  [0.92536539]]]\n",
      "ejemplar: [0.90277398 0.90706348 0.91161072 0.91267878 0.91525561 0.9191851\n",
      " 0.9232409  0.92536539]\n",
      "y: 0.8229368461836497\n",
      "Predicción : [[0.92796427]]\n",
      "Lr que voy a aplicar en el lote: 124 es 0.00016129032883327454\n",
      "lote que voy a entrenar: [[0.90277398 0.90706348 0.91161072 0.91267878 0.91525561 0.9191851\n",
      "  0.9232409  0.92536539]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011030762456357479\n",
      "Predicción post entrenamiento : [[0.92806053]]\n",
      "PERDIDAAAA despues: 0.011050991714000702\n",
      "lr: 0.00016, batch: 124\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "124\n",
      "[[[0.90706348]\n",
      "  [0.91161072]\n",
      "  [0.91267878]\n",
      "  [0.91525561]\n",
      "  [0.9191851 ]\n",
      "  [0.9232409 ]\n",
      "  [0.92536539]\n",
      "  [0.92796427]]]\n",
      "ejemplar: [0.90706348 0.91161072 0.91267878 0.91525561 0.9191851  0.9232409\n",
      " 0.92536539 0.92796427]\n",
      "y: 0.7745060054242543\n",
      "Predicción : [[0.93123513]]\n",
      "Lr que voy a aplicar en el lote: 125 es 0.00015999999595806003\n",
      "lote que voy a entrenar: [[0.90706348 0.91161072 0.91267878 0.91525561 0.9191851  0.9232409\n",
      "  0.92536539 0.92796427]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02456401102244854\n",
      "Predicción post entrenamiento : [[0.92961234]]\n",
      "PERDIDAAAA despues: 0.024057965725660324\n",
      "lr: 0.00015873015873015873, batch: 125\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "125\n",
      "[[[0.91161072]\n",
      "  [0.91267878]\n",
      "  [0.91525561]\n",
      "  [0.9191851 ]\n",
      "  [0.9232409 ]\n",
      "  [0.92536539]\n",
      "  [0.92796427]\n",
      "  [0.93123513]]]\n",
      "ejemplar: [0.91161072 0.91267878 0.91525561 0.9191851  0.9232409  0.92536539\n",
      " 0.92796427 0.93123513]\n",
      "y: 0.7841921735761332\n",
      "Predicción : [[0.93245345]]\n",
      "Lr que voy a aplicar en el lote: 126 es 0.00015873015217948705\n",
      "lote que voy a entrenar: [[0.91161072 0.91267878 0.91525561 0.9191851  0.9232409  0.92536539\n",
      "  0.92796427 0.93123513]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.021981416270136833\n",
      "Predicción post entrenamiento : [[0.931082]]\n",
      "PERDIDAAAA despues: 0.02157663181424141\n",
      "lr: 0.00015748031496062991, batch: 126\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "126\n",
      "[[[0.91267878]\n",
      "  [0.91525561]\n",
      "  [0.9191851 ]\n",
      "  [0.9232409 ]\n",
      "  [0.92536539]\n",
      "  [0.92796427]\n",
      "  [0.93123513]\n",
      "  [0.93245345]]]\n",
      "ejemplar: [0.91267878 0.91525561 0.9191851  0.9232409  0.92536539 0.92796427\n",
      " 0.93123513 0.93245345]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.9334455]]\n",
      "Lr que voy a aplicar en el lote: 127 es 0.00015748031728435308\n",
      "lote que voy a entrenar: [[0.91267878 0.91525561 0.9191851  0.9232409  0.92536539 0.92796427\n",
      "  0.93123513 0.93245345]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005431867204606533\n",
      "Predicción post entrenamiento : [[0.93075836]]\n",
      "PERDIDAAAA despues: 0.005042994860559702\n",
      "lr: 0.00015625, batch: 127\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "127\n",
      "[[[0.91525561]\n",
      "  [0.9191851 ]\n",
      "  [0.9232409 ]\n",
      "  [0.92536539]\n",
      "  [0.92796427]\n",
      "  [0.93123513]\n",
      "  [0.93245345]\n",
      "  [0.93344551]]]\n",
      "ejemplar: [0.91525561 0.9191851  0.9232409  0.92536539 0.92796427 0.93123513\n",
      " 0.93245345 0.93344551]\n",
      "y: 0.854320030995738\n",
      "Predicción : [[0.93362147]]\n",
      "Lr que voy a aplicar en el lote: 128 es 0.00015624999650754035\n",
      "lote que voy a entrenar: [[0.91525561 0.9191851  0.9232409  0.92536539 0.92796427 0.93123513\n",
      "  0.93245345 0.93344551]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006288714706897736\n",
      "Predicción post entrenamiento : [[0.9329599]]\n",
      "PERDIDAAAA despues: 0.006184228230267763\n",
      "lr: 0.0001550387596899225, batch: 128\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "128\n",
      "[[[0.9191851 ]\n",
      "  [0.9232409 ]\n",
      "  [0.92536539]\n",
      "  [0.92796427]\n",
      "  [0.93123513]\n",
      "  [0.93245345]\n",
      "  [0.93344551]\n",
      "  [0.93362147]]]\n",
      "ejemplar: [0.9191851  0.9232409  0.92536539 0.92796427 0.93123513 0.93245345\n",
      " 0.93344551 0.93362147]\n",
      "y: 0.8368849283223556\n",
      "Predicción : [[0.93588996]]\n",
      "Lr que voy a aplicar en el lote: 129 es 0.000155038753291592\n",
      "lote que voy a entrenar: [[0.9191851  0.9232409  0.92536539 0.92796427 0.93123513 0.93245345\n",
      "  0.93344551 0.93362147]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.009801998734474182\n",
      "Predicción post entrenamiento : [[0.9352627]]\n",
      "PERDIDAAAA despues: 0.009678184054791927\n",
      "lr: 0.00015384615384615385, batch: 129\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "129\n",
      "[[[0.9232409 ]\n",
      "  [0.92536539]\n",
      "  [0.92796427]\n",
      "  [0.93123513]\n",
      "  [0.93245345]\n",
      "  [0.93344551]\n",
      "  [0.93362147]\n",
      "  [0.93588996]]]\n",
      "ejemplar: [0.9232409  0.92536539 0.92796427 0.93123513 0.93245345 0.93344551\n",
      " 0.93362147 0.93588996]\n",
      "y: 0.8299108872530028\n",
      "Predicción : [[0.9377903]]\n",
      "Lr que voy a aplicar en el lote: 130 es 0.0001538461510790512\n",
      "lote que voy a entrenar: [[0.9232409  0.92536539 0.92796427 0.93123513 0.93245345 0.93344551\n",
      "  0.93362147 0.93588996]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.011637965217232704\n",
      "Predicción post entrenamiento : [[0.9368592]]\n",
      "PERDIDAAAA despues: 0.011437942273914814\n",
      "lr: 0.00015267175572519084, batch: 130\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "130\n",
      "[[[0.92536539]\n",
      "  [0.92796427]\n",
      "  [0.93123513]\n",
      "  [0.93245345]\n",
      "  [0.93344551]\n",
      "  [0.93362147]\n",
      "  [0.93588996]\n",
      "  [0.93779027]]]\n",
      "ejemplar: [0.92536539 0.92796427 0.93123513 0.93245345 0.93344551 0.93362147\n",
      " 0.93588996 0.93779027]\n",
      "y: 0.887253002712127\n",
      "Predicción : [[0.9388305]]\n",
      "Lr que voy a aplicar en el lote: 131 es 0.00015267175331246108\n",
      "lote que voy a entrenar: [[0.92536539 0.92796427 0.93123513 0.93245345 0.93344551 0.93362147\n",
      "  0.93588996 0.93779027]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0026602393481880426\n",
      "Predicción post entrenamiento : [[0.93820584]]\n",
      "PERDIDAAAA despues: 0.002596192993223667\n",
      "lr: 0.00015151515151515152, batch: 131\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "131\n",
      "[[[0.92796427]\n",
      "  [0.93123513]\n",
      "  [0.93245345]\n",
      "  [0.93344551]\n",
      "  [0.93362147]\n",
      "  [0.93588996]\n",
      "  [0.93779027]\n",
      "  [0.93883049]]]\n",
      "ejemplar: [0.92796427 0.93123513 0.93245345 0.93344551 0.93362147 0.93588996\n",
      " 0.93779027 0.93883049]\n",
      "y: 0.8597442851607902\n",
      "Predicción : [[0.94009197]]\n",
      "Lr que voy a aplicar en el lote: 132 es 0.00015151515253819525\n",
      "lote que voy a entrenar: [[0.92796427 0.93123513 0.93245345 0.93344551 0.93362147 0.93588996\n",
      "  0.93779027 0.93883049]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00645574601367116\n",
      "Predicción post entrenamiento : [[0.93813413]]\n",
      "PERDIDAAAA despues: 0.006144964601844549\n",
      "lr: 0.00015037593984962405, batch: 132\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "132\n",
      "[[[0.93123513]\n",
      "  [0.93245345]\n",
      "  [0.93344551]\n",
      "  [0.93362147]\n",
      "  [0.93588996]\n",
      "  [0.93779027]\n",
      "  [0.93883049]\n",
      "  [0.94009197]]]\n",
      "ejemplar: [0.93123513 0.93245345 0.93344551 0.93362147 0.93588996 0.93779027\n",
      " 0.93883049 0.94009197]\n",
      "y: 0.8395970554048819\n",
      "Predicción : [[0.93974626]]\n",
      "Lr que voy a aplicar en el lote: 133 es 0.00015037594130262733\n",
      "lote que voy a entrenar: [[0.93123513 0.93245345 0.93344551 0.93362147 0.93588996 0.93779027\n",
      "  0.93883049 0.94009197]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010029865428805351\n",
      "Predicción post entrenamiento : [[0.9392927]]\n",
      "PERDIDAAAA despues: 0.009939229115843773\n",
      "lr: 0.00014925373134328358, batch: 133\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "133\n",
      "[[[0.93245345]\n",
      "  [0.93344551]\n",
      "  [0.93362147]\n",
      "  [0.93588996]\n",
      "  [0.93779027]\n",
      "  [0.93883049]\n",
      "  [0.94009197]\n",
      "  [0.93974626]]]\n",
      "ejemplar: [0.93245345 0.93344551 0.93362147 0.93588996 0.93779027 0.93883049\n",
      " 0.94009197 0.93974626]\n",
      "y: 0.7838047268500579\n",
      "Predicción : [[0.9403579]]\n",
      "Lr que voy a aplicar en el lote: 134 es 0.00014925372670404613\n",
      "lote que voy a entrenar: [[0.93245345 0.93344551 0.93362147 0.93588996 0.93779027 0.93883049\n",
      "  0.94009197 0.93974626]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.02450890652835369\n",
      "Predicción post entrenamiento : [[0.9402343]]\n",
      "PERDIDAAAA despues: 0.024470215663313866\n",
      "lr: 0.00014814814814814815, batch: 134\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "134\n",
      "[[[0.93344551]\n",
      "  [0.93362147]\n",
      "  [0.93588996]\n",
      "  [0.93779027]\n",
      "  [0.93883049]\n",
      "  [0.94009197]\n",
      "  [0.93974626]\n",
      "  [0.94035792]]]\n",
      "ejemplar: [0.93344551 0.93362147 0.93588996 0.93779027 0.93883049 0.94009197\n",
      " 0.93974626 0.94035792]\n",
      "y: 0.8182874854707476\n",
      "Predicción : [[0.9412845]]\n",
      "Lr que voy a aplicar en el lote: 135 es 0.00014814814494457096\n",
      "lote que voy a entrenar: [[0.93344551 0.93362147 0.93588996 0.93779027 0.93883049 0.94009197\n",
      "  0.93974626 0.94035792]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.015128258615732193\n",
      "Predicción post entrenamiento : [[0.9405136]]\n",
      "PERDIDAAAA despues: 0.01493922434747219\n",
      "lr: 0.00014705882352941178, batch: 135\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "135\n",
      "[[[0.93362147]\n",
      "  [0.93588996]\n",
      "  [0.93779027]\n",
      "  [0.93883049]\n",
      "  [0.94009197]\n",
      "  [0.93974626]\n",
      "  [0.94035792]\n",
      "  [0.94128448]]]\n",
      "ejemplar: [0.93362147 0.93588996 0.93779027 0.93883049 0.94009197 0.93974626\n",
      " 0.94035792 0.94128448]\n",
      "y: 0.7911662146454863\n",
      "Predicción : [[0.94160277]]\n",
      "Lr que voy a aplicar en el lote: 136 es 0.00014705881767440587\n",
      "lote que voy a entrenar: [[0.93362147 0.93588996 0.93779027 0.93883049 0.94009197 0.93974626\n",
      "  0.94035792 0.94128448]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022631164640188217\n",
      "Predicción post entrenamiento : [[0.9406042]]\n",
      "PERDIDAAAA despues: 0.02233172208070755\n",
      "lr: 0.00014598540145985403, batch: 136\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "136\n",
      "[[[0.93588996]\n",
      "  [0.93779027]\n",
      "  [0.93883049]\n",
      "  [0.94009197]\n",
      "  [0.93974626]\n",
      "  [0.94035792]\n",
      "  [0.94128448]\n",
      "  [0.94160277]]]\n",
      "ejemplar: [0.93588996 0.93779027 0.93883049 0.94009197 0.93974626 0.94035792\n",
      " 0.94128448 0.94160277]\n",
      "y: 0.7605579232855482\n",
      "Predicción : [[0.94196504]]\n",
      "Lr que voy a aplicar en el lote: 137 es 0.0001459853956475854\n",
      "lote que voy a entrenar: [[0.93588996 0.93779027 0.93883049 0.94009197 0.93974626 0.94035792\n",
      "  0.94128448 0.94160277]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.03290853276848793\n",
      "Predicción post entrenamiento : [[0.9412503]]\n",
      "PERDIDAAAA despues: 0.03264973312616348\n",
      "lr: 0.00014492753623188405, batch: 137\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "137\n",
      "[[[0.93779027]\n",
      "  [0.93883049]\n",
      "  [0.94009197]\n",
      "  [0.93974626]\n",
      "  [0.94035792]\n",
      "  [0.94128448]\n",
      "  [0.94160277]\n",
      "  [0.94196504]]]\n",
      "ejemplar: [0.93779027 0.93883049 0.94009197 0.93974626 0.94035792 0.94128448\n",
      " 0.94160277 0.94196504]\n",
      "y: 0.7915536613715615\n",
      "Predicción : [[0.9422473]]\n",
      "Lr que voy a aplicar en el lote: 138 es 0.00014492752961814404\n",
      "lote que voy a entrenar: [[0.93779027 0.93883049 0.94009197 0.93974626 0.94035792 0.94128448\n",
      "  0.94160277 0.94196504]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022708559408783913\n",
      "Predicción post entrenamiento : [[0.941623]]\n",
      "PERDIDAAAA despues: 0.022520793601870537\n",
      "lr: 0.00014388489208633093, batch: 138\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "138\n",
      "[[[0.93883049]\n",
      "  [0.94009197]\n",
      "  [0.93974626]\n",
      "  [0.94035792]\n",
      "  [0.94128448]\n",
      "  [0.94160277]\n",
      "  [0.94196504]\n",
      "  [0.94224727]]]\n",
      "ejemplar: [0.93883049 0.94009197 0.93974626 0.94035792 0.94128448 0.94160277\n",
      " 0.94196504 0.94224727]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.94228446]]\n",
      "Lr que voy a aplicar en el lote: 139 es 0.00014388488489203155\n",
      "lote que voy a entrenar: [[0.93883049 0.94009197 0.93974626 0.94035792 0.94128448 0.94160277\n",
      "  0.94196504 0.94224727]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.030133550986647606\n",
      "Predicción post entrenamiento : [[0.9401221]]\n",
      "PERDIDAAAA despues: 0.02938750572502613\n",
      "lr: 0.00014285714285714287, batch: 139\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "139\n",
      "[[[0.94009197]\n",
      "  [0.93974626]\n",
      "  [0.94035792]\n",
      "  [0.94128448]\n",
      "  [0.94160277]\n",
      "  [0.94196504]\n",
      "  [0.94224727]\n",
      "  [0.94228446]]]\n",
      "ejemplar: [0.94009197 0.93974626 0.94035792 0.94128448 0.94160277 0.94196504\n",
      " 0.94224727 0.94228446]\n",
      "y: 0.7686943045331267\n",
      "Predicción : [[0.9406426]]\n",
      "Lr que voy a aplicar en el lote: 140 es 0.0001428571413271129\n",
      "lote que voy a entrenar: [[0.94009197 0.93974626 0.94035792 0.94128448 0.94160277 0.94196504\n",
      "  0.94224727 0.94228446]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.029566222801804543\n",
      "Predicción post entrenamiento : [[0.93920296]]\n",
      "PERDIDAAAA despues: 0.029073210433125496\n",
      "lr: 0.00014184397163120567, batch: 140\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "140\n",
      "[[[0.93974626]\n",
      "  [0.94035792]\n",
      "  [0.94128448]\n",
      "  [0.94160277]\n",
      "  [0.94196504]\n",
      "  [0.94224727]\n",
      "  [0.94228446]\n",
      "  [0.9406426 ]]]\n",
      "ejemplar: [0.93974626 0.94035792 0.94128448 0.94160277 0.94196504 0.94224727\n",
      " 0.94228446 0.9406426 ]\n",
      "y: 0.7989151491669895\n",
      "Predicción : [[0.9394715]]\n",
      "Lr que voy a aplicar en el lote: 141 es 0.0001418439787812531\n",
      "lote que voy a entrenar: [[0.93974626 0.94035792 0.94128448 0.94160277 0.94196504 0.94224727\n",
      "  0.94228446 0.9406426 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.01975608430802822\n",
      "Predicción post entrenamiento : [[0.9395265]]\n",
      "PERDIDAAAA despues: 0.019771551713347435\n",
      "lr: 0.00014084507042253522, batch: 141\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "141\n",
      "[[[0.94035792]\n",
      "  [0.94128448]\n",
      "  [0.94160277]\n",
      "  [0.94196504]\n",
      "  [0.94224727]\n",
      "  [0.94228446]\n",
      "  [0.9406426 ]\n",
      "  [0.93947148]]]\n",
      "ejemplar: [0.94035792 0.94128448 0.94160277 0.94196504 0.94224727 0.94228446\n",
      " 0.9406426  0.93947148]\n",
      "y: 0.7900038744672608\n",
      "Predicción : [[0.9399683]]\n",
      "Lr que voy a aplicar en el lote: 142 es 0.00014084507711231709\n",
      "lote que voy a entrenar: [[0.94035792 0.94128448 0.94160277 0.94196504 0.94224727 0.94228446\n",
      "  0.9406426  0.93947148]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.022489318624138832\n",
      "Predicción post entrenamiento : [[0.9389962]]\n",
      "PERDIDAAAA despues: 0.02219870500266552\n",
      "lr: 0.00013986013986013986, batch: 142\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "142\n",
      "[[[0.94128448]\n",
      "  [0.94160277]\n",
      "  [0.94196504]\n",
      "  [0.94224727]\n",
      "  [0.94228446]\n",
      "  [0.9406426 ]\n",
      "  [0.93947148]\n",
      "  [0.93996829]]]\n",
      "ejemplar: [0.94128448 0.94160277 0.94196504 0.94224727 0.94228446 0.9406426\n",
      " 0.93947148 0.93996829]\n",
      "y: 0.760170476559473\n",
      "Predicción : [[0.93931085]]\n",
      "Lr que voy a aplicar en el lote: 143 es 0.0001398601452820003\n",
      "lote que voy a entrenar: [[0.94128448 0.94160277 0.94196504 0.94224727 0.94228446 0.9406426\n",
      "  0.93947148 0.93996829]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.032091278582811356\n",
      "Predicción post entrenamiento : [[0.9386792]]\n",
      "PERDIDAAAA despues: 0.031865376979112625\n",
      "lr: 0.0001388888888888889, batch: 143\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "143\n",
      "[[[0.94160277]\n",
      "  [0.94196504]\n",
      "  [0.94224727]\n",
      "  [0.94228446]\n",
      "  [0.9406426 ]\n",
      "  [0.93947148]\n",
      "  [0.93996829]\n",
      "  [0.93931085]]]\n",
      "ejemplar: [0.94160277 0.94196504 0.94224727 0.94228446 0.9406426  0.93947148\n",
      " 0.93996829 0.93931085]\n",
      "y: 0.6853932584269664\n",
      "Predicción : [[0.938716]]\n",
      "Lr que voy a aplicar en el lote: 144 es 0.00013888889225199819\n",
      "lote que voy a entrenar: [[0.94160277 0.94196504 0.94224727 0.94228446 0.9406426  0.93947148\n",
      "  0.93996829 0.93931085]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0641724020242691\n",
      "Predicción post entrenamiento : [[0.93734235]]\n",
      "PERDIDAAAA despues: 0.06347833573818207\n",
      "lr: 0.00013793103448275863, batch: 144\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "144\n",
      "[[[0.94196504]\n",
      "  [0.94224727]\n",
      "  [0.94228446]\n",
      "  [0.9406426 ]\n",
      "  [0.93947148]\n",
      "  [0.93996829]\n",
      "  [0.93931085]\n",
      "  [0.93871599]]]\n",
      "ejemplar: [0.94196504 0.94224727 0.94228446 0.9406426  0.93947148 0.93996829\n",
      " 0.93931085 0.93871599]\n",
      "y: 0.6051917861294072\n",
      "Predicción : [[0.93721807]]\n",
      "Lr que voy a aplicar en el lote: 145 es 0.0001379310415359214\n",
      "lote que voy a entrenar: [[0.94196504 0.94224727 0.94228446 0.9406426  0.93947148 0.93996829\n",
      "  0.93931085 0.93871599]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.11024146527051926\n",
      "Predicción post entrenamiento : [[0.9351129]]\n",
      "PERDIDAAAA despues: 0.10884794592857361\n",
      "lr: 0.000136986301369863, batch: 145\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "145\n",
      "[[[0.94224727]\n",
      "  [0.94228446]\n",
      "  [0.9406426 ]\n",
      "  [0.93947148]\n",
      "  [0.93996829]\n",
      "  [0.93931085]\n",
      "  [0.93871599]\n",
      "  [0.93721807]]]\n",
      "ejemplar: [0.94224727 0.94228446 0.9406426  0.93947148 0.93996829 0.93931085\n",
      " 0.93871599 0.93721807]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.93476534]]\n",
      "Lr que voy a aplicar en el lote: 146 es 0.00013698630209546536\n",
      "lote que voy a entrenar: [[0.94224727 0.94228446 0.9406426  0.93947148 0.93996829 0.93931085\n",
      "  0.93871599 0.93721807]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07284966111183167\n",
      "Predicción post entrenamiento : [[0.93370247]]\n",
      "PERDIDAAAA despues: 0.07227703928947449\n",
      "lr: 0.00013605442176870748, batch: 146\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "146\n",
      "[[[0.94228446]\n",
      "  [0.9406426 ]\n",
      "  [0.93947148]\n",
      "  [0.93996829]\n",
      "  [0.93931085]\n",
      "  [0.93871599]\n",
      "  [0.93721807]\n",
      "  [0.93476534]]]\n",
      "ejemplar: [0.94228446 0.9406426  0.93947148 0.93996829 0.93931085 0.93871599\n",
      " 0.93721807 0.93476534]\n",
      "y: 0.7078651685393258\n",
      "Predicción : [[0.93309516]]\n",
      "Lr que voy a aplicar en el lote: 147 es 0.0001360544265480712\n",
      "lote que voy a entrenar: [[0.94228446 0.9406426  0.93947148 0.93996829 0.93931085 0.93871599\n",
      "  0.93721807 0.93476534]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.05072854459285736\n",
      "Predicción post entrenamiento : [[0.9322628]]\n",
      "PERDIDAAAA despues: 0.050354283303022385\n",
      "lr: 0.00013513513513513514, batch: 147\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "147\n",
      "[[[0.9406426 ]\n",
      "  [0.93947148]\n",
      "  [0.93996829]\n",
      "  [0.93931085]\n",
      "  [0.93871599]\n",
      "  [0.93721807]\n",
      "  [0.93476534]\n",
      "  [0.93309516]]]\n",
      "ejemplar: [0.9406426  0.93947148 0.93996829 0.93931085 0.93871599 0.93721807\n",
      " 0.93476534 0.93309516]\n",
      "y: 0.6648585819449826\n",
      "Predicción : [[0.93140596]]\n",
      "Lr que voy a aplicar en el lote: 148 es 0.0001351351384073496\n",
      "lote que voy a entrenar: [[0.9406426  0.93947148 0.93996829 0.93931085 0.93871599 0.93721807\n",
      "  0.93476534 0.93309516]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.07104750722646713\n",
      "Predicción post entrenamiento : [[0.9302126]]\n",
      "PERDIDAAAA despues: 0.0704127624630928\n",
      "lr: 0.0001342281879194631, batch: 148\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "148\n",
      "[[[0.93947148]\n",
      "  [0.93996829]\n",
      "  [0.93931085]\n",
      "  [0.93871599]\n",
      "  [0.93721807]\n",
      "  [0.93476534]\n",
      "  [0.93309516]\n",
      "  [0.93140596]]]\n",
      "ejemplar: [0.93947148 0.93996829 0.93931085 0.93871599 0.93721807 0.93476534\n",
      " 0.93309516 0.93140596]\n",
      "y: 0.7113521890740022\n",
      "Predicción : [[0.92955524]]\n",
      "Lr que voy a aplicar en el lote: 149 es 0.00013422819029074162\n",
      "lote que voy a entrenar: [[0.93947148 0.93996829 0.93931085 0.93871599 0.93721807 0.93476534\n",
      "  0.93309516 0.93140596]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.04761257767677307\n",
      "Predicción post entrenamiento : [[0.927374]]\n",
      "PERDIDAAAA despues: 0.046665433794260025\n",
      "lr: 0.00013333333333333334, batch: 149\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "149\n",
      "[[[0.93996829]\n",
      "  [0.93931085]\n",
      "  [0.93871599]\n",
      "  [0.93721807]\n",
      "  [0.93476534]\n",
      "  [0.93309516]\n",
      "  [0.93140596]\n",
      "  [0.92955524]]]\n",
      "ejemplar: [0.93996829 0.93931085 0.93871599 0.93721807 0.93476534 0.93309516\n",
      " 0.93140596 0.92955524]\n",
      "y: 0.6772568771793879\n",
      "Predicción : [[0.9267646]]\n",
      "Lr que voy a aplicar en el lote: 150 es 0.00013333333481568843\n",
      "lote que voy a entrenar: [[0.93996829 0.93931085 0.93871599 0.93721807 0.93476534 0.93309516\n",
      "  0.93140596 0.92955524]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.062254104763269424\n",
      "Predicción post entrenamiento : [[0.92632115]]\n",
      "PERDIDAAAA despues: 0.06203300878405571\n",
      "lr: 0.00013245033112582781, batch: 150\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "150\n",
      "[[[0.93931085]\n",
      "  [0.93871599]\n",
      "  [0.93721807]\n",
      "  [0.93476534]\n",
      "  [0.93309516]\n",
      "  [0.93140596]\n",
      "  [0.92955524]\n",
      "  [0.92676461]]]\n",
      "ejemplar: [0.93931085 0.93871599 0.93721807 0.93476534 0.93309516 0.93140596\n",
      " 0.92955524 0.92676461]\n",
      "y: 0.7621077101898488\n",
      "Predicción : [[0.92520875]]\n",
      "Lr que voy a aplicar en el lote: 151 es 0.00013245032459963113\n",
      "lote que voy a entrenar: [[0.93931085 0.93871599 0.93721807 0.93476534 0.93309516 0.93140596\n",
      "  0.92955524 0.92676461]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.026601942256093025\n",
      "Predicción post entrenamiento : [[0.9226945]]\n",
      "PERDIDAAAA despues: 0.025788111612200737\n",
      "lr: 0.00013157894736842105, batch: 151\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "151\n",
      "[[[0.93871599]\n",
      "  [0.93721807]\n",
      "  [0.93476534]\n",
      "  [0.93309516]\n",
      "  [0.93140596]\n",
      "  [0.92955524]\n",
      "  [0.92676461]\n",
      "  [0.92520875]]]\n",
      "ejemplar: [0.93871599 0.93721807 0.93476534 0.93309516 0.93140596 0.92955524\n",
      " 0.92676461 0.92520875]\n",
      "y: 0.8070515304145678\n",
      "Predicción : [[0.92131877]]\n",
      "Lr que voy a aplicar en el lote: 152 es 0.0001315789413638413\n",
      "lote que voy a entrenar: [[0.93871599 0.93721807 0.93476534 0.93309516 0.93140596 0.92955524\n",
      "  0.92676461 0.92520875]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.013057000003755093\n",
      "Predicción post entrenamiento : [[0.9199021]]\n",
      "PERDIDAAAA despues: 0.012735245749354362\n",
      "lr: 0.00013071895424836603, batch: 152\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "152\n",
      "[[[0.93721807]\n",
      "  [0.93476534]\n",
      "  [0.93309516]\n",
      "  [0.93140596]\n",
      "  [0.92955524]\n",
      "  [0.92676461]\n",
      "  [0.92520875]\n",
      "  [0.92131877]]]\n",
      "ejemplar: [0.93721807 0.93476534 0.93309516 0.93140596 0.92955524 0.92676461\n",
      " 0.92520875 0.92131877]\n",
      "y: 0.8151879116621463\n",
      "Predicción : [[0.91817045]]\n",
      "Lr que voy a aplicar en el lote: 153 es 0.00013071895227767527\n",
      "lote que voy a entrenar: [[0.93721807 0.93476534 0.93309516 0.93140596 0.92955524 0.92676461\n",
      "  0.92520875 0.92131877]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010605399496853352\n",
      "Predicción post entrenamiento : [[0.91767263]]\n",
      "PERDIDAAAA despues: 0.010503114201128483\n",
      "lr: 0.00012987012987012987, batch: 153\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "153\n",
      "[[[0.93476534]\n",
      "  [0.93309516]\n",
      "  [0.93140596]\n",
      "  [0.92955524]\n",
      "  [0.92676461]\n",
      "  [0.92520875]\n",
      "  [0.92131877]\n",
      "  [0.91817045]]]\n",
      "ejemplar: [0.93476534 0.93309516 0.93140596 0.92955524 0.92676461 0.92520875\n",
      " 0.92131877 0.91817045]\n",
      "y: 0.9062378922898102\n",
      "Predicción : [[0.9157757]]\n",
      "Lr que voy a aplicar en el lote: 154 es 0.0001298701245104894\n",
      "lote que voy a entrenar: [[0.93476534 0.93309516 0.93140596 0.92955524 0.92676461 0.92520875\n",
      "  0.92131877 0.91817045]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 9.096993744606152e-05\n",
      "Predicción post entrenamiento : [[0.91628456]]\n",
      "PERDIDAAAA despues: 0.00010093539458466694\n",
      "lr: 0.00012903225806451613, batch: 154\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "154\n",
      "[[[0.93309516]\n",
      "  [0.93140596]\n",
      "  [0.92955524]\n",
      "  [0.92676461]\n",
      "  [0.92520875]\n",
      "  [0.92131877]\n",
      "  [0.91817045]\n",
      "  [0.91577572]]]\n",
      "ejemplar: [0.93309516 0.93140596 0.92955524 0.92676461 0.92520875 0.92131877\n",
      " 0.91817045 0.91577572]\n",
      "y: 0.9597055404881829\n",
      "Predicción : [[0.91445947]]\n",
      "Lr que voy a aplicar en el lote: 155 es 0.0001290322543354705\n",
      "lote que voy a entrenar: [[0.93309516 0.93140596 0.92955524 0.92676461 0.92520875 0.92131877\n",
      "  0.91817045 0.91577572]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002047206275165081\n",
      "Predicción post entrenamiento : [[0.91524965]]\n",
      "PERDIDAAAA despues: 0.001976325875148177\n",
      "lr: 0.0001282051282051282, batch: 155\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "155\n",
      "[[[0.93140596]\n",
      "  [0.92955524]\n",
      "  [0.92676461]\n",
      "  [0.92520875]\n",
      "  [0.92131877]\n",
      "  [0.91817045]\n",
      "  [0.91577572]\n",
      "  [0.91445947]]]\n",
      "ejemplar: [0.93140596 0.92955524 0.92676461 0.92520875 0.92131877 0.91817045\n",
      " 0.91577572 0.91445947]\n",
      "y: 0.9643549012010848\n",
      "Predicción : [[0.91324794]]\n",
      "Lr que voy a aplicar en el lote: 156 es 0.00012820512347389013\n",
      "lote que voy a entrenar: [[0.93140596 0.92955524 0.92676461 0.92520875 0.92131877 0.91817045\n",
      "  0.91577572 0.91445947]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0026119183748960495\n",
      "Predicción post entrenamiento : [[0.91407186]]\n",
      "PERDIDAAAA despues: 0.002528381533920765\n",
      "lr: 0.00012738853503184715, batch: 156\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "156\n",
      "[[[0.92955524]\n",
      "  [0.92676461]\n",
      "  [0.92520875]\n",
      "  [0.92131877]\n",
      "  [0.91817045]\n",
      "  [0.91577572]\n",
      "  [0.91445947]\n",
      "  [0.91324794]]]\n",
      "ejemplar: [0.92955524 0.92676461 0.92520875 0.92131877 0.91817045 0.91577572\n",
      " 0.91445947 0.91324794]\n",
      "y: 0.8880278961642774\n",
      "Predicción : [[0.9118662]]\n",
      "Lr que voy a aplicar en el lote: 157 es 0.0001273885281989351\n",
      "lote que voy a entrenar: [[0.92955524 0.92676461 0.92520875 0.92131877 0.91817045 0.91577572\n",
      "  0.91445947 0.91324794]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0005682636983692646\n",
      "Predicción post entrenamiento : [[0.9123997]]\n",
      "PERDIDAAAA despues: 0.0005939847906120121\n",
      "lr: 0.00012658227848101267, batch: 157\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "157\n",
      "[[[0.92676461]\n",
      "  [0.92520875]\n",
      "  [0.92131877]\n",
      "  [0.91817045]\n",
      "  [0.91577572]\n",
      "  [0.91445947]\n",
      "  [0.91324794]\n",
      "  [0.91186619]]]\n",
      "ejemplar: [0.92676461 0.92520875 0.92131877 0.91817045 0.91577572 0.91445947\n",
      " 0.91324794 0.91186619]\n",
      "y: 0.8926772568771792\n",
      "Predicción : [[0.91002375]]\n",
      "Lr que voy a aplicar en el lote: 158 es 0.00012658227933570743\n",
      "lote que voy a entrenar: [[0.92676461 0.92520875 0.92131877 0.91817045 0.91577572 0.91445947\n",
      "  0.91324794 0.91186619]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0003009010979440063\n",
      "Predicción post entrenamiento : [[0.90902525]]\n",
      "PERDIDAAAA despues: 0.0002672572445590049\n",
      "lr: 0.00012578616352201257, batch: 158\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "158\n",
      "[[[0.92520875]\n",
      "  [0.92131877]\n",
      "  [0.91817045]\n",
      "  [0.91577572]\n",
      "  [0.91445947]\n",
      "  [0.91324794]\n",
      "  [0.91186619]\n",
      "  [0.91002375]]]\n",
      "ejemplar: [0.92520875 0.92131877 0.91817045 0.91577572 0.91445947 0.91324794\n",
      " 0.91186619 0.91002375]\n",
      "y: 0.8752421542037967\n",
      "Predicción : [[0.9067699]]\n",
      "Lr que voy a aplicar en el lote: 159 es 0.0001257861586054787\n",
      "lote que voy a entrenar: [[0.92520875 0.92131877 0.91817045 0.91577572 0.91445947 0.91324794\n",
      "  0.91186619 0.91002375]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009939956944435835\n",
      "Predicción post entrenamiento : [[0.90704846]]\n",
      "PERDIDAAAA despues: 0.001011640066280961\n",
      "lr: 0.000125, batch: 159\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "159\n",
      "[[[0.92131877]\n",
      "  [0.91817045]\n",
      "  [0.91577572]\n",
      "  [0.91445947]\n",
      "  [0.91324794]\n",
      "  [0.91186619]\n",
      "  [0.91002375]\n",
      "  [0.90676987]]]\n",
      "ejemplar: [0.92131877 0.91817045 0.91577572 0.91445947 0.91324794 0.91186619\n",
      " 0.91002375 0.90676987]\n",
      "y: 0.8508330104610615\n",
      "Predicción : [[0.9045827]]\n",
      "Lr que voy a aplicar en el lote: 160 es 0.0001250000059371814\n",
      "lote que voy a entrenar: [[0.92131877 0.91817045 0.91577572 0.91445947 0.91324794 0.91186619\n",
      "  0.91002375 0.90676987]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002889028051868081\n",
      "Predicción post entrenamiento : [[0.904655]]\n",
      "PERDIDAAAA despues: 0.002896805526688695\n",
      "lr: 0.00012422360248447205, batch: 160\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "160\n",
      "[[[0.91817045]\n",
      "  [0.91577572]\n",
      "  [0.91445947]\n",
      "  [0.91324794]\n",
      "  [0.91186619]\n",
      "  [0.91002375]\n",
      "  [0.90676987]\n",
      "  [0.90458268]]]\n",
      "ejemplar: [0.91817045 0.91577572 0.91445947 0.91324794 0.91186619 0.91002375\n",
      " 0.90676987 0.90458268]\n",
      "y: 0.8488957768306855\n",
      "Predicción : [[0.90268075]]\n",
      "Lr que voy a aplicar en el lote: 161 es 0.00012422360305208713\n",
      "lote que voy a entrenar: [[0.91817045 0.91577572 0.91445947 0.91324794 0.91186619 0.91002375\n",
      "  0.90676987 0.90458268]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.002892822725698352\n",
      "Predicción post entrenamiento : [[0.90234053]]\n",
      "PERDIDAAAA despues: 0.002856340492144227\n",
      "lr: 0.0001234567901234568, batch: 161\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "161\n",
      "[[[0.91577572]\n",
      "  [0.91445947]\n",
      "  [0.91324794]\n",
      "  [0.91186619]\n",
      "  [0.91002375]\n",
      "  [0.90676987]\n",
      "  [0.90458268]\n",
      "  [0.90268075]]]\n",
      "ejemplar: [0.91577572 0.91445947 0.91324794 0.91186619 0.91002375 0.90676987\n",
      " 0.90458268 0.90268075]\n",
      "y: 0.9624176675707088\n",
      "Predicción : [[0.90071535]]\n",
      "Lr que voy a aplicar en el lote: 162 es 0.00012345678987912834\n",
      "lote que voy a entrenar: [[0.91577572 0.91445947 0.91324794 0.91186619 0.91002375 0.90676987\n",
      "  0.90458268 0.90268075]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0038071752060204744\n",
      "Predicción post entrenamiento : [[0.9009955]]\n",
      "PERDIDAAAA despues: 0.0037726829759776592\n",
      "lr: 0.0001226993865030675, batch: 162\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "162\n",
      "[[[0.91445947]\n",
      "  [0.91324794]\n",
      "  [0.91186619]\n",
      "  [0.91002375]\n",
      "  [0.90676987]\n",
      "  [0.90458268]\n",
      "  [0.90268075]\n",
      "  [0.90071535]]]\n",
      "ejemplar: [0.91445947 0.91324794 0.91186619 0.91002375 0.90676987 0.90458268\n",
      " 0.90268075 0.90071535]\n",
      "y: 0.9678419217357612\n",
      "Predicción : [[0.8995322]]\n",
      "Lr que voy a aplicar en el lote: 163 es 0.0001226993917953223\n",
      "lote que voy a entrenar: [[0.91445947 0.91324794 0.91186619 0.91002375 0.90676987 0.90458268\n",
      "  0.90268075 0.90071535]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.004666218534111977\n",
      "Predicción post entrenamiento : [[0.9002155]]\n",
      "PERDIDAAAA despues: 0.004573332145810127\n",
      "lr: 0.00012195121951219512, batch: 163\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "163\n",
      "[[[0.91324794]\n",
      "  [0.91186619]\n",
      "  [0.91002375]\n",
      "  [0.90676987]\n",
      "  [0.90458268]\n",
      "  [0.90268075]\n",
      "  [0.90071535]\n",
      "  [0.8995322 ]]]\n",
      "ejemplar: [0.91324794 0.91186619 0.91002375 0.90676987 0.90458268 0.90268075\n",
      " 0.90071535 0.8995322 ]\n",
      "y: 0.9407206509104997\n",
      "Predicción : [[0.89859647]]\n",
      "Lr que voy a aplicar en el lote: 164 es 0.00012195121962577105\n",
      "lote que voy a entrenar: [[0.91324794 0.91186619 0.91002375 0.90676987 0.90458268 0.90268075\n",
      "  0.90071535 0.8995322 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0017744492506608367\n",
      "Predicción post entrenamiento : [[0.8986515]]\n",
      "PERDIDAAAA despues: 0.0017698173178359866\n",
      "lr: 0.00012121212121212121, batch: 164\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "164\n",
      "[[[0.91186619]\n",
      "  [0.91002375]\n",
      "  [0.90676987]\n",
      "  [0.90458268]\n",
      "  [0.90268075]\n",
      "  [0.90071535]\n",
      "  [0.8995322 ]\n",
      "  [0.89859647]]]\n",
      "ejemplar: [0.91186619 0.91002375 0.90676987 0.90458268 0.90268075 0.90071535\n",
      " 0.8995322  0.89859647]\n",
      "y: 0.9724912824486633\n",
      "Predicción : [[0.8968206]]\n",
      "Lr que voy a aplicar en el lote: 165 es 0.00012121212057536468\n",
      "lote que voy a entrenar: [[0.91186619 0.91002375 0.90676987 0.90458268 0.90268075 0.90071535\n",
      "  0.8995322  0.89859647]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005726048722863197\n",
      "Predicción post entrenamiento : [[0.8971545]]\n",
      "PERDIDAAAA despues: 0.005675626453012228\n",
      "lr: 0.00012048192771084338, batch: 165\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "165\n",
      "[[[0.91002375]\n",
      "  [0.90676987]\n",
      "  [0.90458268]\n",
      "  [0.90268075]\n",
      "  [0.90071535]\n",
      "  [0.8995322 ]\n",
      "  [0.89859647]\n",
      "  [0.8968206 ]]]\n",
      "ejemplar: [0.91002375 0.90676987 0.90458268 0.90268075 0.90071535 0.8995322\n",
      " 0.89859647 0.8968206 ]\n",
      "y: 0.9969004261913985\n",
      "Predicción : [[0.8951438]]\n",
      "Lr que voy a aplicar en el lote: 166 es 0.00012048192729707807\n",
      "lote que voy a entrenar: [[0.91002375 0.90676987 0.90458268 0.90268075 0.90071535 0.8995322\n",
      "  0.89859647 0.8968206 ]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.010354411788284779\n",
      "Predicción post entrenamiento : [[0.89577985]]\n",
      "PERDIDAAAA despues: 0.01022537425160408\n",
      "lr: 0.00011976047904191617, batch: 166\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "166\n",
      "[[[0.90676987]\n",
      "  [0.90458268]\n",
      "  [0.90268075]\n",
      "  [0.90071535]\n",
      "  [0.8995322 ]\n",
      "  [0.89859647]\n",
      "  [0.8968206 ]\n",
      "  [0.89514381]]]\n",
      "ejemplar: [0.90676987 0.90458268 0.90268075 0.90071535 0.8995322  0.89859647\n",
      " 0.8968206  0.89514381]\n",
      "y: 0.951181712514529\n",
      "Predicción : [[0.89372706]]\n",
      "Lr que voy a aplicar en el lote: 167 es 0.00011976047971984372\n",
      "lote que voy a entrenar: [[0.90676987 0.90458268 0.90268075 0.90071535 0.8995322  0.89859647\n",
      "  0.8968206  0.89514381]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.00330103631131351\n",
      "Predicción post entrenamiento : [[0.89375824]]\n",
      "PERDIDAAAA despues: 0.0032974551431834698\n",
      "lr: 0.00011904761904761905, batch: 167\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "167\n",
      "[[[0.90458268]\n",
      "  [0.90268075]\n",
      "  [0.90071535]\n",
      "  [0.8995322 ]\n",
      "  [0.89859647]\n",
      "  [0.8968206 ]\n",
      "  [0.89514381]\n",
      "  [0.89372706]]]\n",
      "ejemplar: [0.90458268 0.90268075 0.90071535 0.8995322  0.89859647 0.8968206\n",
      " 0.89514381 0.89372706]\n",
      "y: 0.8957768306857805\n",
      "Predicción : [[0.89211327]]\n",
      "Lr que voy a aplicar en el lote: 168 es 0.0001190476177725941\n",
      "lote que voy a entrenar: [[0.90458268 0.90268075 0.90071535 0.8995322  0.89859647 0.8968206\n",
      "  0.89514381 0.89372706]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 1.3421524272416718e-05\n",
      "Predicción post entrenamiento : [[0.89224005]]\n",
      "PERDIDAAAA despues: 1.2508677173173055e-05\n",
      "lr: 0.00011834319526627219, batch: 168\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "168\n",
      "[[[0.90268075]\n",
      "  [0.90071535]\n",
      "  [0.8995322 ]\n",
      "  [0.89859647]\n",
      "  [0.8968206 ]\n",
      "  [0.89514381]\n",
      "  [0.89372706]\n",
      "  [0.89211327]]]\n",
      "ejemplar: [0.90268075 0.90071535 0.8995322  0.89859647 0.8968206  0.89514381\n",
      " 0.89372706 0.89211327]\n",
      "y: 0.8814413018209997\n",
      "Predicción : [[0.89075845]]\n",
      "Lr que voy a aplicar en el lote: 169 es 0.00011834319593617693\n",
      "lote que voy a entrenar: [[0.90268075 0.90071535 0.8995322  0.89859647 0.8968206  0.89514381\n",
      "  0.89372706 0.89211327]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 8.680946484673768e-05\n",
      "Predicción post entrenamiento : [[0.8903539]]\n",
      "PERDIDAAAA despues: 7.943484524730593e-05\n",
      "lr: 0.00011764705882352942, batch: 169\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "169\n",
      "[[[0.90071535]\n",
      "  [0.8995322 ]\n",
      "  [0.89859647]\n",
      "  [0.8968206 ]\n",
      "  [0.89514381]\n",
      "  [0.89372706]\n",
      "  [0.89211327]\n",
      "  [0.89075845]]]\n",
      "ejemplar: [0.90071535 0.8995322  0.89859647 0.8968206  0.89514381 0.89372706\n",
      " 0.89211327 0.89075845]\n",
      "y: 0.9170864006199149\n",
      "Predicción : [[0.88898134]]\n",
      "Lr que voy a aplicar en el lote: 170 es 0.00011764706141548231\n",
      "lote que voy a entrenar: [[0.90071535 0.8995322  0.89859647 0.8968206  0.89514381 0.89372706\n",
      "  0.89211327 0.89075845]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0007898955373093486\n",
      "Predicción post entrenamiento : [[0.88972104]]\n",
      "PERDIDAAAA despues: 0.0007488643750548363\n",
      "lr: 0.00011695906432748539, batch: 170\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "170\n",
      "[[[0.8995322 ]\n",
      "  [0.89859647]\n",
      "  [0.8968206 ]\n",
      "  [0.89514381]\n",
      "  [0.89372706]\n",
      "  [0.89211327]\n",
      "  [0.89075845]\n",
      "  [0.88898134]]]\n",
      "ejemplar: [0.8995322  0.89859647 0.8968206  0.89514381 0.89372706 0.89211327\n",
      " 0.89075845 0.88898134]\n",
      "y: 0.919798527702441\n",
      "Predicción : [[0.8884914]]\n",
      "Lr que voy a aplicar en el lote: 171 es 0.00011695906141540036\n",
      "lote que voy a entrenar: [[0.8995322  0.89859647 0.8968206  0.89514381 0.89372706 0.89211327\n",
      "  0.89075845 0.88898134]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0009801383130252361\n",
      "Predicción post entrenamiento : [[0.888704]]\n",
      "PERDIDAAAA despues: 0.0009668710990808904\n",
      "lr: 0.00011627906976744187, batch: 171\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "171\n",
      "[[[0.89859647]\n",
      "  [0.8968206 ]\n",
      "  [0.89514381]\n",
      "  [0.89372706]\n",
      "  [0.89211327]\n",
      "  [0.89075845]\n",
      "  [0.88898134]\n",
      "  [0.88849139]]]\n",
      "ejemplar: [0.89859647 0.8968206  0.89514381 0.89372706 0.89211327 0.89075845\n",
      " 0.88898134 0.88849139]\n",
      "y: 0.9616427741185587\n",
      "Predicción : [[0.8874015]]\n",
      "Lr que voy a aplicar en el lote: 172 es 0.00011627907224465162\n",
      "lote que voy a entrenar: [[0.89859647 0.8968206  0.89514381 0.89372706 0.89211327 0.89075845\n",
      "  0.88898134 0.88849139]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.0055117676965892315\n",
      "Predicción post entrenamiento : [[0.88717496]]\n",
      "PERDIDAAAA despues: 0.005545458756387234\n",
      "lr: 0.00011560693641618497, batch: 172\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "172\n",
      "[[[0.8968206 ]\n",
      "  [0.89514381]\n",
      "  [0.89372706]\n",
      "  [0.89211327]\n",
      "  [0.89075845]\n",
      "  [0.88898134]\n",
      "  [0.88849139]\n",
      "  [0.88740152]]]\n",
      "ejemplar: [0.8968206  0.89514381 0.89372706 0.89211327 0.89075845 0.88898134\n",
      " 0.88849139 0.88740152]\n",
      "y: 0.9682293684618366\n",
      "Predicción : [[0.88572013]]\n",
      "Lr que voy a aplicar en el lote: 173 es 0.00011560693383216858\n",
      "lote que voy a entrenar: [[0.8968206  0.89514381 0.89372706 0.89211327 0.89075845 0.88898134\n",
      "  0.88849139 0.88740152]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.006807771511375904\n",
      "Predicción post entrenamiento : [[0.88601637]]\n",
      "PERDIDAAAA despues: 0.006758974865078926\n",
      "lr: 0.00011494252873563218, batch: 173\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "173\n",
      "[[[0.89514381]\n",
      "  [0.89372706]\n",
      "  [0.89211327]\n",
      "  [0.89075845]\n",
      "  [0.88898134]\n",
      "  [0.88849139]\n",
      "  [0.88740152]\n",
      "  [0.88572013]]]\n",
      "ejemplar: [0.89514381 0.89372706 0.89211327 0.89075845 0.88898134 0.88849139\n",
      " 0.88740152 0.88572013]\n",
      "y: 0.9577683068578069\n",
      "Predicción : [[0.88465]]\n",
      "Lr que voy a aplicar en el lote: 174 es 0.00011494252976262942\n",
      "lote que voy a entrenar: [[0.89514381 0.89372706 0.89211327 0.89075845 0.88898134 0.88849139\n",
      "  0.88740152 0.88572013]]\n",
      "verdaderas salidas: (1, 1)\n",
      "PERDIDAAAA antes: 0.005346289835870266\n",
      "Predicción post entrenamiento : [[0.8842503]]\n",
      "PERDIDAAAA despues: 0.0054049016907811165\n",
      "lr: 0.00011428571428571428, batch: 174\n",
      ">>>>>>>>>>>>>>>Fin lote \n",
      "Se resetea\n"
     ]
    }
   ],
   "source": [
    "red.compile(optimizer=SGD(learning_rate=0.01),loss='mean_squared_error')#SGD(learning_rate=1e-3)\n",
    "\n",
    "# Definir el callback con la función de la tasa de aprendizaje\n",
    "lr_callback = CustomLearningRateScheduler(initial_lr=0.01, decay_factor=0.5)#0.9\n",
    "lr_callback.reset()\n",
    "ts_cierre_s_pred = c_entrenamiento_n\n",
    "sub_epocas = 1\n",
    "t_lote = 1\n",
    "\n",
    "loss_m = []\n",
    "print(f\"y_entrenamiento: {y_entrenamiento}\")\n",
    "for epoca in range(10):  # Número de épocas\n",
    "    ts_cierre_s_pred = c_entrenamiento_n[:time_steps] #:8 se toman los primeros 8 elementos del conjunto de entrenamiendo predictivo \n",
    "    ts_cierre_s_pred_post_entreno = c_entrenamiento_n[:time_steps]\n",
    "    loss = []\n",
    "    n_ejemplar = 1\n",
    "    n_lote = 1\n",
    "    x_lote = []\n",
    "    # print(f\"grtrt: {ts_cierre_s_pred}\")\n",
    "    for i in range(0,len(y_entrenamiento)):#time_steps+1\n",
    "        print(i)\n",
    "        # Obtener las características y la etiqueta actual\n",
    "        ejemplar = ts_cierre_s_pred[i:i+time_steps,0]\n",
    "        print(ejemplar.reshape(1,time_steps,1))\n",
    "\n",
    "        x_lote.append(ejemplar)\n",
    "\n",
    "        # Predicción del modelo \n",
    "        #prediccion = red.predict(x_actual)#.reshape(1,1,1)\n",
    "        prediccion = red(ejemplar.reshape(1,time_steps,1))\n",
    "        \n",
    "        # Agregar la predicción a las características para el siguiente paso\n",
    "        # print(ts_cierre_s_pred)\n",
    "        print(f\"ejemplar: {ejemplar}\")\n",
    "        print(f\"y: {np.array( y_entrenamiento[i])}\")\n",
    "        print(f\"Predicción : { prediccion}\")\n",
    "        ts_cierre_s_pred = np.concatenate([ts_cierre_s_pred, prediccion])\n",
    "        \n",
    "\n",
    "        if(n_ejemplar == t_lote):\n",
    "            \n",
    "            #print(f\"y: {np.array( y_entrenamiento[i-t_lote+1:i+1]).reshape(t_lote,1)}\")\n",
    "            \n",
    "            #print(f\"x_lote: {x_lote}\")\n",
    "            lr = float(red.optimizer.lr)\n",
    "            print(f\"Lr que voy a aplicar en el lote: {n_lote} es {lr}\")\n",
    "            print(f\"lote que voy a entrenar: {np.array(x_lote)}\")\n",
    "            print(f\"verdaderas salidas: {np.array( [y_entrenamiento[i-t_lote+1:i+1]]).shape}\")\n",
    "            print(f\"PERDIDAAAA antes: {red.test_on_batch(np.array(x_lote),np.array( [y_entrenamiento[i-t_lote+1:i+1]]))}\")\n",
    "            train = red.train_on_batch(np.array(x_lote), np.array( [y_entrenamiento[i-t_lote+1:i+1]]))\n",
    "            \n",
    "            # print(f\"train: {train}\")\n",
    "            loss.append(train)#np.array(y_entrenamiento[i:i+t_lote])\n",
    "            prediccion_post_entrenamiento = red(ejemplar.reshape(1,time_steps,1))\n",
    "            print(f\"Predicción post entrenamiento : { prediccion_post_entrenamiento}\")\n",
    "            print(f\"PERDIDAAAA despues: {red.test_on_batch(np.array(x_lote),np.array( [y_entrenamiento[i-t_lote+1:i+1]]))}\")\n",
    "            #ts_cierre_s_pred_post_entreno = np.concatenate([ts_cierre_s_pred_post_entreno, prediccion])\n",
    "            lr_callback.on_batch_begin(n_lote, logs={'loss': loss, 'epoca': epoca+1})  # Llamada al callback en cada lote\n",
    "            #red.optimizer.lr =\n",
    "            x_lote = []\n",
    "            n_ejemplar = 0\n",
    "            \n",
    "            n_lote = n_lote + 1\n",
    "            \n",
    "        n_ejemplar = n_ejemplar+1\n",
    "        print(\">>>>>>>>>>>>>>>Fin lote \")\n",
    "\n",
    "        # Entrenar el modelo con las nuevas características y la etiqueta real\n",
    "        # for sub_epoca in range(sub_epocas):\n",
    "        #     red.train_on_batch(x_actual, y_actual)\n",
    "        #     if(sub_epoca == sub_epocas - 1):\n",
    "        #         loss.append(red.train_on_batch(x_actual, y_actual))\n",
    "        \n",
    "\n",
    "        \n",
    "    #print(f\"mean: {np.mean(np.array(loss))}\")\n",
    "    #loss_m.append(np.mean(np.array(loss)))\n",
    "    mse = np.mean(np.array(mean_squared_error(c_entrenamiento_n,ts_cierre_s_pred[:,0])))\n",
    "    loss_m.append(mse)\n",
    "    writer.add_scalar(f'Perdida de entrenamiento predictivo de la red: ', mse, epoca+1)\n",
    "    \n",
    "    \n",
    "    plot_buf = utls.gen_plot(c_entrenamiento_n,ts_cierre_s_pred,mse)\n",
    "\n",
    "    image = PIL.Image.open(plot_buf)\n",
    "    image = ToTensor()(image).unsqueeze(0)\n",
    "    writer.add_image(f'Comportamiento de la serie de tiempo para la red: {0} durante el entrenamiento predictivo', image, epoca+1,dataformats='NCHW')\n",
    "    lr_callback.reset()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15615066090387228, 0.15914212276033582, 0.15798754344023805, 0.16257290455487527, 0.16480305718026814, 0.16937690531048216, 0.17235197943402333, 0.16941805904841362, 0.16568820891974054, 0.16416835980402322]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(loss_m)\n",
    "plt.plot(range(len(loss_m)),loss_m)\n",
    "plt.show()\n",
    "# losses = history.history['loss']\n",
    "# print(losses)\n",
    "# plt.plot(range(len(losses)),losses)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "shape: (78, 1)\n",
      "[0.54539295 0.44850949 0.42344173 0.48577236 0.49051491 0.56368564\n",
      " 0.57520325 0.55691057]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "shape: (86,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# for i in range(time_steps, N):\n",
    "#     X_entrenamiento.append(c_entrenamiento_n[i-time_steps:i, 0])#toma paquetes de 8 en 8\n",
    "#     y_entrenamiento.append(c_entrenamiento_n[i, 0])#se toma el elemento 8+1\n",
    "\n",
    "# Ahora, el modelo ha sido entrenado de manera iterativa\n",
    "\n",
    "# print(X_entrenamiento.shape)\n",
    "# print(X_entrenamiento[0,:].shape)\n",
    "f_X_test_cierre = np.reshape(X_entrenamiento[0,:], (1, X_entrenamiento[0,:].shape[0], 1))\n",
    "# print(f_X_test_cierre)\n",
    "f_predicted_sp_cierre = red.predict(f_X_test_cierre)\n",
    "print(f\"shape: {precios_predichos.shape}\")\n",
    "f_predicted_sp_cierre = m_m_s.inverse_transform(f_predicted_sp_cierre)\n",
    "print(f_X_test_cierre.reshape(8))\n",
    "\n",
    "# Predice el conjunto de prueba usando la prediccion predictiva (ñps datos que va prediciendo)\n",
    "\n",
    "predicted_stock_price_cierre_pred = utls.genera_prediccion_predictiva(f_X_test_cierre.reshape(8),8,78,red)\n",
    "print(f\"shape: {predicted_stock_price_cierre_pred.shape}\")\n",
    "temp = predicted_stock_price_cierre_pred\n",
    "predicted_stock_price_cierre_pred = m_m_s.inverse_transform(predicted_stock_price_cierre_pred.reshape(86,1))\n",
    "# input_shape_primera_capa = red.layers[0].input_shape\n",
    "# print(input_shape_primera_capa[1:])\n",
    "\n",
    "# arreglo_una_dimension = np.random.rand(8)  # Completa con tus valores reales\n",
    "\n",
    "# # Utilizar input_shape_primera_capa en la función reshape\n",
    "# arreglo_reshape = arreglo_una_dimension.reshape(1, *input_shape_primera_capa[1:])\n",
    "# print(arreglo_reshape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predice el conjunto de entrenamiento usando la prediccion predictiva (usando los datos que predice)\n",
    "\n",
    "#f_X_train_cierre = np.reshape(X_entrenamiento[0,:], (1, X_entrenamiento[0,:].shape[0], 1))\n",
    "f_X_train_cierre = c_entrenamiento_n[:time_steps].reshape(8)\n",
    "# # print(f_X_test_cierre)\n",
    "# f_predicted_t_sp_cierre = red.predict(f_X_train_cierre)\n",
    "# print(f\"shape: {precios_predichos.shape}\")\n",
    "# f_predicted_sp_cierre = m_m_s.inverse_transform(f_predicted_t_sp_cierre)\n",
    "# print(f_X_test_cierre.reshape(8))\n",
    "\n",
    "predicted_stock_price_cierre_pred_t = utls.genera_prediccion_predictiva(f_X_train_cierre,8,182,red)\n",
    "# print(f\"shape: {predicted_stock_price_cierre_pred_t.shape}\")\n",
    "# temp_t = predicted_stock_price_cierre_pred_t\n",
    "# predicted_stock_price_cierre_pred = m_m_s.inverse_transform(predicted_stock_price_cierre_pred.reshape(86,1))\n",
    "\n",
    "#Sin normalizar\n",
    "plt.plot(c_entrenamiento_n, color = 'black', label = 'COMI original Stock prices')\n",
    "plt.plot(predicted_stock_price_cierre_pred_t, color = 'green', label = 'Predicted COMI closing Stock prices') #ts_cierre_s_pred[:,0]\n",
    "plt.title('COMI Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('COMI Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Sin normalizar\n",
    "plt.plot(inputs_cierre, color = 'black', label = 'COMI original Stock prices')\n",
    "plt.plot(temp, color = 'green', label = 'Predicted COMI closing Stock prices')\n",
    "plt.title('COMI Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('COMI Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Sin normalizar\n",
    "# plt.plot(inputs_cierre, color = 'black', label = 'COMI original Stock prices')\n",
    "# plt.plot(temp, color = 'green', label = 'Predicted COMI closing Stock prices')\n",
    "# plt.title('COMI Stock Price Prediction')\n",
    "# plt.xlabel('Time')\n",
    "# plt.ylabel('COMI Stock Price')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.plot(precios_reales, color = 'black', label = 'COMI original Stock prices')\n",
    "# plt.plot(predicted_stock_price_cierre_pred, color = 'green', label = 'Predicted COMI closing Stock prices')\n",
    "# plt.title('COMI Stock Price Prediction')\n",
    "# plt.xlabel('Time')\n",
    "# plt.ylabel('COMI Stock Price')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.9232, dtype=torch.float64)\n",
      "tensor(76.7141, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "criterion = nn.MSELoss()\n",
    "perdida = criterion(torch.tensor(precios_reales),torch.tensor(precios_predichos))\n",
    "print(perdida)\n",
    "perdida = criterion(torch.tensor(precios_reales),torch.tensor(predicted_stock_price_cierre_pred[:78]))\n",
    "print(perdida)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
