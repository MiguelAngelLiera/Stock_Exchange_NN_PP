{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se analizaran los datos de Grupo Financiero Inbursa, desde el 7-02-2001 hasta 4-02-2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, pywt, csv, numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import reader1 as rd\n",
    "import utilerias as utls\n",
    "import signal_procesing.multilevel_dwt as m_dwt\n",
    "# Llamamos a la funci√≥n antes de ejecutar el script\n",
    "#utls.eliminar_archivos_registro()\n",
    "#utls.clear_tensorboard_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "utls.eliminar_archivos_registro()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import entrenamiento.entrenamientos as entr\n",
    "from NARNN import NARNN \n",
    "criterion = nn.MSELoss()\n",
    "redes = {\"red_A1\" : 'models/red_A1.pth',\n",
    "         \"red_D1\" : 'models/red_D1.pth',\n",
    "         \"red_D2\" : 'models/red_D2.pth',\n",
    "         \"red_D3\" : 'models/red_D3.pth',\n",
    "         \"red_D4\" : 'models/red_D4.pth',\n",
    "         \"red_D5\" : 'models/red_D5.pth'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud de la entrada: 260\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Abrir el archivo CSV en modo lectura\n",
    "\n",
    "# DATOS = 'cierre.csv'#Grupo Financiero Inbursa\n",
    "# DATOS = 'Datos hist√≥ricos COMI 03012016_27122020.csv' #Datos originales\n",
    "DATOS = 'Datos hist√≥ricos COMI 3ene16-31dic2020 semanal.csv' #Datos semanales\n",
    "# DATOS = 'Datos hist√≥ricos COMI_prueba 30jun19-31dic2020.csv' #Datos semanales de prueba\n",
    "# DATOS = 'Datos hist√≥ricos COMI3ene2016_27dic2020_diario.csv' #Datos originales diarios de prueba\n",
    "# DATOS = 'Datos hist√≥ricos COMI_prueba 30jun19-31dic2020_DIARIO.csv' #Datos diarios de prueba\n",
    "\n",
    "cierre = rd.leer_archivo(DATOS)\n",
    "#se convierten todos los valores a flotantes\n",
    "cierre = cierre.astype(float)\n",
    "\n",
    "# Crear un gr√°fico de l√≠nea con los valores de x, y\n",
    "print(f\"Longitud de la entrada: {len(cierre)}\")\n",
    "plt.figure(figsize=(18, 3))\n",
    "plt.plot(range(len(cierre)), cierre, label=f\"Datos de Analisis: {DATOS}\", color='#176B87')\n",
    "plt.xlabel('D√≠as')\n",
    "plt.ylabel('Precios de cierre diario')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eleccion de Mother Wavelet\n",
    "\n",
    "Se elige las mother wavelets dependiendo de las caracteristicas de la serie de tiempo que se va a analizar. Para series que impliquen cambios no smoothos y repentinos es recomendable usar Haar ya que responde bien a estos cambios repentinos.\n",
    "\n",
    "Se elige bior3.5 debido a las caracteristicas de las fluctuaciones entre periodos con altas cantidades de inversiones y periodos en los que no.\n",
    "\n",
    "En general, el mother wavelet debe de ser una funcion de las caracteristicas de la serie original para que esta pueda ser reconstruida o analizada "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud de la entrada de cA: 135\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2400x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Se descompone la lista de precios de cierre del intervalo mencionado anteriormente a partir de la dwt con la funci√≥n bior3.5\n",
    "# print(pywt.wavelist()) imprime la lista de wavelets de la biblioteca\n",
    "wavelet = 'bior3.5'\n",
    "mode = pywt.Modes.constant #antireflect, smooth\n",
    "wavelet = pywt.Wavelet(wavelet)\n",
    "(cA, cD) = pywt.dwt(cierre.tolist(), wavelet, mode=mode)\n",
    "print(f\"Longitud de la entrada de cA: {len(cA)}\")\n",
    "\n",
    "plt.figure(figsize=(24, 3))\n",
    "aprox_coef = True\n",
    "index = 1\n",
    "\n",
    "for _ in [cA, cD]:\n",
    "    plt.subplot(1, 2, index)\n",
    "    plt.plot(range(len(_)), _, color='#1363DF' if aprox_coef else '#256D85')\n",
    "    plt.title('Coeficientes de Aproximaci√≥n' if aprox_coef else 'Coeficientes de Detalle')\n",
    "    aprox_coef = False\n",
    "    index = index + 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Divide the weekly closing stock prices into a training dataset (70%) and a testing dataset (30%). \n",
    "Se realiza la separacion del conjunto de entrenamiento y el de prueba\n",
    "<img src=\"/imagenes/DWT-NARNN_step1.png\" alt=\"Descripci√≥n de la imagen\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2400x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Se realiza el proceso 5 veces\n",
    "cierre_e = cierre[:int(len(cierre) * 0.7)]#cierre entrenamiento\n",
    "cierre_p = cierre[int(len(cierre) * 0.7):]#cierre prueba\n",
    "\n",
    "plt.figure(figsize=(24, 3))\n",
    "index = 1\n",
    "\n",
    "for _ in [cierre_e, cierre_p]:\n",
    "    plt.subplot(1, 2, index)\n",
    "    plt.plot(range(len(_)), _, color='#1363DF' if aprox_coef else '#256D85')\n",
    "    plt.title('Coeficientes de Aproximaci√≥n' if aprox_coef else 'Coeficientes de Detalle')\n",
    "    aprox_coef = False\n",
    "    index = index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decompose the training dataset by the DWT, \n",
    "utilizing the biorthogonal 3.5 mother wavelet, into \n",
    "approximation coefficients A(t) and detail coefficients D(t), as \n",
    "discussed  in  section  2.1.  Set  the  decomposition  level  to  five \n",
    "[12] and extract six components D1, D2, D3, D4, D5, and A5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #mode = pywt.Modes.constant\n",
    "# mode = 'reflect'\n",
    "# # coeffs = pywt.wavedec(cierre, wavelet, level=5, mode=mode)\n",
    "# # coeffs_e = pywt.wavedec(cierre_e, wavelet, level=5, mode=mode)\n",
    "# # components_p = pywt.wavedec(cierre_p, wavelet, level=5,mode=mode)\n",
    "# components = m_dwt.multilevel_dwt(cierre, wavelet, 5, mode)\n",
    "# components_e = m_dwt.multilevel_dwt(cierre_e, wavelet, 5, mode)\n",
    "# components_p = m_dwt.multilevel_dwt(cierre_p, wavelet, 5, mode)\n",
    "\n",
    "# # coeffs_rec = []\n",
    "# # coeffs_rec.append(pywt.upcoef('a', coeffs[0], wavelet, level = 5, take=len(cierre)))#, take=len(cierre)))\n",
    "# # coeffs_rec.append(pywt.upcoef('d', coeffs[1], wavelet, level = 5, take=len(cierre)))#, take=len(cierre)))\n",
    "# # coeffs_rec.append(pywt.upcoef('d', coeffs[2], wavelet, level = 4, take=len(cierre)))#, take=len(cierre)))\n",
    "# # coeffs_rec.append(pywt.upcoef('d', coeffs[3], wavelet, level = 3, take=len(cierre)))#, take=len(cierre)))\n",
    "# # coeffs_rec.append(pywt.upcoef('d', coeffs[4], wavelet, level = 2, take=len(cierre)))#, take=len(cierre)))\n",
    "# # coeffs_rec.append(pywt.upcoef('d', coeffs[5], wavelet, level = 1, take=len(cierre)))#, take=len(cierre)))\n",
    "\n",
    "# N = len(cierre_p)\n",
    "# print(N)\n",
    "# #print(pywt.upcoef('a', components_p[0], wavelet, level = 5))\n",
    "# # components_p_rec = []\n",
    "# # components_p_rec.append(pywt.upcoef('a', components_p[0], wavelet, level = 5))#, take = 98\n",
    "# # components_p_rec.append(pywt.upcoef('d', components_p[1], wavelet, level = 5))\n",
    "# # components_p_rec.append(pywt.upcoef('d', components_p[2], wavelet, level = 4))\n",
    "# # components_p_rec.append(pywt.upcoef('d', components_p[3], wavelet, level = 3))\n",
    "# # components_p_rec.append(pywt.upcoef('d', components_p[4], wavelet, level = 2))\n",
    "# # components_p_rec.append(pywt.upcoef('d', components_p[5], wavelet, level = 1))\n",
    "# #print(len(cierre_p))\n",
    "\n",
    "# for uc in components_p:\n",
    "#     print(len(uc))\n",
    "#     #print(uc)\n",
    "\n",
    "# # cA_5 = components_p[0]\n",
    "# # cD_5 = components_p[1]\n",
    "# # cD_4 = components_p[2]\n",
    "# # cD_3 = components_p[3]\n",
    "# # cD_2 = components_p[4]\n",
    "# # cD_1 = components_p[5]\n",
    "# print(f\"Longitud de la entrada de A_5: {len(components_p[0])}\")\n",
    "\n",
    "# plt.figure(figsize=(32, 8))\n",
    "# aprox_coef = True\n",
    "# index = 1\n",
    "\n",
    "# for _ in components_p:\n",
    "#     plt.subplot(2, 3, index)\n",
    "#     plt.plot(range(len(_)), _, color='#DA0C81' if aprox_coef else '#610C9F')\n",
    "#     plt.title('Coeficientes de Aproximaci√≥n' if aprox_coef else 'Coeficientes de Detalle')\n",
    "#     aprox_coef = False\n",
    "#     index = index + 1\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# o_data = 0\n",
    "# components_p.reverse()\n",
    "# for c in components_p:\n",
    "#     o_data =  o_data + c\n",
    "\n",
    "# plt.plot(range(len(o_data)),o_data)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3200x800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mode = 'constant'\n",
    "components = m_dwt.multilevel_dwt(cierre, wavelet, 5, mode)\n",
    "components_e = m_dwt.multilevel_dwt(cierre_e, wavelet, 5, mode) # componentes de entrenamiento \n",
    "components_p = m_dwt.multilevel_dwt(cierre_p, wavelet, 5, mode) #componentes de prueba\n",
    "# N = len(cierre_p)\n",
    "# print(f\"Longitud de la entrada de A_5: {len(components_p[0])}\")\n",
    "\n",
    "plt.figure(figsize=(32, 8))\n",
    "aprox_coef = True\n",
    "index = 1\n",
    "\n",
    "for _ in components_p:\n",
    "    plt.subplot(2, 3, index)\n",
    "    plt.plot(range(len(_)), _, color='#DA0C81' if aprox_coef else '#610C9F')\n",
    "    plt.title('Componentes de Aproximaci√≥n' if aprox_coef else 'Componentes de Detalle')\n",
    "    aprox_coef = False\n",
    "    index = index + 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "o_data = 0 #original data\n",
    "for c in components_p:\n",
    "    o_data =  o_data + c\n",
    "\n",
    "plt.plot(range(len(o_data)),o_data, color='#DA0C81')\n",
    "plt.plot(range(len(cierre_p)),o_data, color='#610C9F')\n",
    "plt.title('Reconstrucci√≥n a partir de los componentes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coeffs_p_rec_dec = []\n",
    "# components_p_rec_dec.append(pywt.downcoef('a',components_p_rec[0], wavelet, mode=mode,level=5))\n",
    "# coeffs_p_rec_dec.append(pywt.downcoef('d',coeffs_p_rec[1], wavelet, mode=mode,level=5))\n",
    "# coeffs_p_rec_dec.append(pywt.downcoef('d',coeffs_p_rec[2], wavelet, mode=mode,level=4))\n",
    "# coeffs_p_rec_dec.append(pywt.downcoef('d',coeffs_p_rec[3], wavelet, mode=mode,level=3))\n",
    "# coeffs_p_rec_dec.append(pywt.downcoef('d',coeffs_p_rec[4], wavelet, mode=mode,level=2))\n",
    "# coeffs_p_rec_dec.append(pywt.downcoef('d',coeffs_p_rec[5], wavelet, mode=mode,level=1))\n",
    "\n",
    "# plt.figure(figsize=(32, 8))\n",
    "# aprox_coef = True\n",
    "# index = 1\n",
    "\n",
    "# for _ in coeffs_p_rec_dec:\n",
    "#     plt.subplot(2, 3, index)\n",
    "#     plt.plot(range(len(_)), _, color='#DA0C81' if aprox_coef else '#610C9F')\n",
    "#     plt.title('Coeficientes de Aproximaci√≥n' if aprox_coef else 'Coeficientes de Detalle')\n",
    "#     aprox_coef = False\n",
    "#     index = index + 1\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def take(rec, take=0):\n",
    "#     rec_len = len(rec)\n",
    "#     if take > 0 and take < rec_len:\n",
    "#         left_bound = right_bound = (rec_len-take) // 2\n",
    "#         if (rec_len-take) % 2:\n",
    "#             # right_bound must never be zero for indexing to work\n",
    "#             right_bound = right_bound + 1\n",
    "\n",
    "#         return rec[left_bound:-right_bound]\n",
    "    \n",
    "# #print(take([0,1,2,3,4,5,6,7,8,9],take = 2))\n",
    "\n",
    "# A4 = pywt.upcoef('a', coeffs_p[0], wavelet, level = 5, take = 390) + pywt.upcoef('d', coeffs_p[1], wavelet, level = 5, take = 390)\n",
    "# A3 = take(A4, take = 222) + pywt.upcoef('d', coeffs_p[2], wavelet, level = 4, take = 222)\n",
    "# A2 = take(A3, take = 138) + pywt.upcoef('d', coeffs_p[3], wavelet, level = 3, take = 138)\n",
    "# A1 = take(A2, take = 98) + pywt.upcoef('d', coeffs_p[4], wavelet, level = 2, take = 98)\n",
    "# c_final = take(A1, take = 78) + pywt.upcoef('d', coeffs_p[5], wavelet, level = 1, take = 78)\n",
    "# #c_final = coeffs_p_rec[0]+ coeffs_p_rec[1] + coeffs_p_rec[2] + coeffs_p_rec[3] + coeffs_p_rec[4] + coeffs_p_rec[5]\n",
    "# print(c_final)\n",
    "# plt.figure(figsize=(32, 8))\n",
    "# aprox_coef = True\n",
    "# index = 1\n",
    "\n",
    "\n",
    "# plt.plot(range(len(c_final)), c_final, color='#DA0C81' if aprox_coef else '#610C9F')\n",
    "# aprox_coef = False\n",
    "# #plt.plot(range(len(cierre_p)), cierre_p, color='#DA0C81' if aprox_coef else '#610C9F')\n",
    "# plt.title('Coeficientes de Aproximaci√≥n' if aprox_coef else 'Coeficientes de Detalle')\n",
    "\n",
    "# index = index + 1\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Normalize the decomposed components using the Min-Max normalization method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se normalizan cada uno de los elementos de los vectores contenidos en las descomposicion de la serie de tiempo original\n",
    "components_e_n = [utls.normalizar(vect) for vect in components_e] # componentes de entrenamiento normalizados\n",
    "components_p_n = [utls.normalizar(vect) for vect in components_p] # componentes de prueba normalizados\n",
    "\n",
    "#Se concatenan los ultimo 8 elementos del conjunto de entrenamiento para predecir el primero del conjunto de prueba\n",
    "for i in range(len(components_p_n)):\n",
    "    components_p_n[i] = np.concatenate((components_e_n[i][-8:],components_p_n[i]))\n",
    "\n",
    "#Estos 6 arreglos representan la descomposici√≥n de la se√±al original. Se tendr√°n que armar 6 redes que predigan cada una de estas\n",
    "#componentes, Las entradas correspondientes a cada una son las 8 semanas anteriores para calcular la novena\n",
    "\n",
    "#entrenamiento,prueba,validacion = utls.generar_conjuntos(coeffs_n,False,5)\n",
    "#la de abajo es una prueba\n",
    "#entrenamiento,prueba,validacion = utls.generar_conjuntos([[1,2,3,4,5,6,7,8,9,10],[1,2,3,4,5,6,7,8,9,10]],False,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Build  six  NARNNs,  with  the  topology  shown  in Figure 3, to forecast each decomposed component. The number of feedback delays in the TDL is set to eight, i.e., the preceding  eight  weeks'  closing  prices  are  utilized  to  forecast the ninth-week closing price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_A5 = NARNN(input_dim=8, hidden_dim=0, output_dim=1, num_layers=0)\n",
    "red_A5.load_state_dict(torch.load('models/red_A5.pth'))\n",
    "red_A5.eval()\n",
    "\n",
    "red_D5 = NARNN(input_dim=8, hidden_dim=0, output_dim=1, num_layers=0)\n",
    "# red_D1.load_state_dict(torch.load('models/red_D1_n.pth'))\n",
    "# red_D1.eval()\n",
    "\n",
    "red_D4 = NARNN(input_dim=8, hidden_dim=0, output_dim=1, num_layers=0)\n",
    "# red_D2.load_state_dict(torch.load('models/red_D2_n.pth'))\n",
    "# red_D2.eval()\n",
    "\n",
    "red_D3 = NARNN(input_dim=8, hidden_dim=0, output_dim=1, num_layers=0)\n",
    "# red_D3.load_state_dict(torch.load('models/red_D3_n1.pth'))\n",
    "# red_D3.eval()\n",
    "\n",
    "red_D2= NARNN(input_dim=8, hidden_dim=0, output_dim=1, num_layers=0)\n",
    "# red_D4.load_state_dict(torch.load('models/red_D4_n1.pth'))\n",
    "# red_D4.eval()\n",
    "\n",
    "red_D1 = NARNN(input_dim=8, hidden_dim=0, output_dim=1, num_layers=0)\n",
    "# red_D5.load_state_dict(torch.load(redes[\"red_D5\"]))\n",
    "# red_D5.eval()\n",
    "\n",
    "networks = [red_A5,red_D5,red_D4,red_D3,red_D2,red_D1]\n",
    "\n",
    "#entradas ya procesadas\n",
    "entrenamiento_8_1 = [[],[],[],[],[],[]]\n",
    "prueba_8_1 = [[],[],[],[],[],[]]\n",
    "serie_c = [[],[],[],[],[],[]]\n",
    "coeffs_n_prueba_8_1 = [[],[],[],[],[],[]]\n",
    "\n",
    "# A cada uno de los conjuntos de entrenamiento se les da una forma de entrada en especifico,\n",
    "# que es un arreglo de 8 y uno de un solo elemento para representar la salida\n",
    "for e in range(6):\n",
    "    # entrenamiento_8_1[e] = utls.corrimiento_t_1(entrenamiento[e],9)\n",
    "    # prueba_8_1[e] = utls.corrimiento_t_1(prueba[e],9)\n",
    "    # serie_c[e] = utls.corrimiento_t_1(coeffs_n[e],9)\n",
    "    # coeffs_n_prueba_8_1[e] = utls.corrimiento_t_1(coeffs_n_prueba[e],9)\n",
    "\n",
    "    entrenamiento_8_1[e] = utls.corrimiento_t_1(components_e_n[e],9)\n",
    "    prueba_8_1[e] = utls.corrimiento_t_1(components_p_n[e],9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Divide the training dataset into three parts: 70% for training, 15% for validation, and 15% as test data. Then train the six NARNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se define el n√∫mero de epocas\n",
    "EPOCAS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entr.entrena_LM(networks[0],0,entrenamiento_8_1,EPOCAS,lr=0.01,Œª =0.1)\n",
    "# torch.save(red_A5.state_dict(), 'models/red_A5_datos_originales.pth') #Salvamos el estado actual del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entr.entrena_LM(red_D5,1,entrenamiento_8_1,EPOCAS)\n",
    "#torch.save(red_D5.state_dict(), 'models/red_D5_datos_originales.pth') \n",
    "#entr.entrena_LM(red_D4,2,entrenamiento_8_1,EPOCAS)\n",
    "#torch.save(red_D4.state_dict(), 'models/red_D4_datos_originales.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entr.entrena_LM(red_D3,3,entrenamiento_8_1,EPOCAS)\n",
    "# torch.save(red_D3.state_dict(), 'models/red_D3_datos_originales.pth') \n",
    "\n",
    "# entr.entrena_LM(red_D2,4,entrenamiento_8_1,EPOCAS)\n",
    "# torch.save(red_D2.state_dict(), 'models/red_D2_datos_originales.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entr.entrena_LM(red_D5,5,entrenamiento_8_1,EPOCAS)\n",
    "# torch.save(red_D2.state_dict(), 'models/red_D1_datos_originales.pth')\n",
    "#entradas ya procesadas\n",
    "# entrenamiento_8_1 = [[],[],[],[],[],[]]\n",
    "\n",
    "# A cada uno de los conjuntos de entrenamiento se les da una forma de entrada en especifico,\n",
    "# que es un arreglo de 8 y uno de un solo elemento para representar la salida\n",
    "# for e in range(6):\n",
    "#     entrenamiento_8_1[e] = utls.corrimiento_t_1(entrenamiento[e],9)\n",
    "\n",
    "#pruebas_ordenadas = []\n",
    "\n",
    "# for e in range(6):\n",
    "#     entrenamiento_8_1[e] = utls.corrimiento_t_1(entrenamiento[e],9)\n",
    "\n",
    "#for c_pruebas in entrenamiento:#entre\n",
    "    #print(\"corrimiento: \" + str(utls.corrimiento_t_1(c_pruebas,9)))\n",
    " #   pruebas_ordenadas.append(utls.corrimiento_t_1(c_pruebas,9))#prueba[0] es el conjunto de prueba para cada red\n",
    "#pruebas = forma_entrada(prueba[0],9)#prueba[0] es el conjunto de prueba para A1\n",
    "#print(utls.genera_prediccion_1(pruebas_ordenadas[0],red_A1))\n",
    "#print(len(utls.genera_prediccion(pruebas_ordenadas[0],red_A1).detach().numpy().tolist()[0]))\n",
    "#print(entrenamiento[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicci√≥n del conjunto de entrenamiento\n",
    "usando los datos originales para la recurrencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perdidas: [tensor(0.0045, dtype=torch.float64, grad_fn=<MseLossBackward0>), tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward0>), tensor(0.3593, dtype=torch.float64, grad_fn=<MseLossBackward0>), tensor(0.1887, dtype=torch.float64, grad_fn=<MseLossBackward0>), tensor(0.0247, dtype=torch.float64, grad_fn=<MseLossBackward0>), tensor(1.3980, dtype=torch.float64, grad_fn=<MseLossBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "#Se grafica el conjunto de entrenamiento\n",
    "perdidas = []\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "aprox_coef = True\n",
    "index = 1\n",
    "\n",
    "for _ in range(len(components_e_n)):\n",
    "    prediccion = utls.genera_prediccion_1(entrenamiento_8_1[_],networks[_],8)\n",
    "    perdidas.append(criterion(prediccion, torch.tensor(components_e_n[_])))\n",
    "    plt.subplot(2, 3, index)\n",
    "    plt.plot(range(len(components_e_n[_])), components_e_n[_], color = '#451952') #color='#DA0C81' if aprox_coef else '#610C9F')\n",
    "    plt.plot(range(len(components_e_n[_])), prediccion.detach().numpy(), label = f\"Perdida: {float(perdidas[_])}\", color='#AE445A')#label=f\"Datos de Analisis: {DATOS}\",\n",
    "    plt.title('Coeficientes de Aproximaci√≥n' if aprox_coef else 'Coeficientes de Detalle')\n",
    "    aprox_coef = False\n",
    "    plt.legend()\n",
    "    index = index + 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Perdidas: \" + str(perdidas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicci√≥n del conjunto de prueba\n",
    "usando los datos originales para la recurrencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perdidas: [tensor(0.0437, dtype=torch.float64, grad_fn=<MseLossBackward0>), tensor(0.4264, dtype=torch.float64, grad_fn=<MseLossBackward0>), tensor(0.8578, dtype=torch.float64, grad_fn=<MseLossBackward0>), tensor(0.5874, dtype=torch.float64, grad_fn=<MseLossBackward0>), tensor(0.0423, dtype=torch.float64, grad_fn=<MseLossBackward0>), tensor(1.3861, dtype=torch.float64, grad_fn=<MseLossBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "perdidas = []\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "aprox_coef = True\n",
    "index = 1\n",
    "\n",
    "for _ in range(len(components_p_n)):\n",
    "    prediccion = utls.genera_prediccion_1(prueba_8_1[_],networks[_],8)\n",
    "    perdidas.append(criterion(prediccion, torch.tensor(components_p_n[_])))\n",
    "    plt.subplot(2, 3, index)\n",
    "    plt.plot(range(len(components_p_n[_])), components_p_n[_]) #color='#DA0C81' if aprox_coef else '#610C9F')\n",
    "    plt.plot(range(len(components_p_n[_])), prediccion.detach().numpy(), label = f\"Perdida: {float(perdidas[_])}\" ,color='#DA0C81')#label=f\"Datos de Analisis: {DATOS}\",\n",
    "    \n",
    "    plt.title('Coeficientes de Aproximaci√≥n' if aprox_coef else 'Coeficientes de Detalle')\n",
    "    aprox_coef = False\n",
    "    plt.legend()\n",
    "    index = index + 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Perdidas: \" + str(perdidas))\n",
    "\n",
    "#Se grafica el conjunto de pruebas\n",
    "# plt.plot(range(len(prueba[0])), prueba[0])\n",
    "# plt.plot(range(len(prueba[0])), utls.genera_prediccion_1(prueba_8_1[0],red_A1,8).detach().numpy())\n",
    "# plt.show(\n",
    "\n",
    "#plt.plot(range(108), entrenamiento[0][:-8])\n",
    "#plt.plot(range(108), [utls.desnormalizar(vect) for vect in utls.genera_prediccion(pruebas_ordenadas[0],red_A1).detach().numpy().tolist()[0]])\n",
    "# Mostrar el gr√°fico\n",
    "#plt.show()\n",
    "#investigar bien la dwt y predecir la red con los corrimientos de 1, usando los datos que predice o solo los datos que le doy\n",
    "#Lo que hace es generar una prediccion cada noveno d√≠a, con los datos que ya se le dan del entrenamiento, es preciso ajustar los parametros hasta que ambas series\n",
    "#sean iguales\n",
    "#print(prueba[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generamos el entrenamiento predictivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05029815 0.00860651 0.         0.02447862 0.03269448 0.02464758\n",
      " 0.02051585 0.0202993  0.04942463 0.10789186 0.1371961  0.13733737\n",
      " 0.1338857  0.1268411  0.14756061 0.19604423 0.21688968 0.21009695\n",
      " 0.20267785 0.19463237 0.19407352 0.2010013  0.19663821 0.18098423\n",
      " 0.16539041 0.14985674 0.15043111 0.16711353 0.20227035 0.2559016\n",
      " 0.2926882  0.31263018 0.31093888 0.28761432 0.28016165 0.28858086\n",
      " 0.28246282 0.26180754 0.28012129 0.33740406 0.34822982 0.31259855\n",
      " 0.3435871  0.44119547 0.52109532 0.58328665 0.60892345 0.59800572\n",
      " 0.59453019 0.59849685 0.62135434 0.66310268 0.69287243 0.71066362\n",
      " 0.72168206 0.72592776 0.74043182 0.76519426 0.7447891  0.67921634\n",
      " 0.67460177 0.73094536 0.74672101 0.72192869 0.71992867 0.74072095\n",
      " 0.7362455  0.70650233 0.69794515 0.71057397 0.72096215 0.7291097\n",
      " 0.76742596 0.83591094 0.85101034 0.81272415 0.78639403 0.77201997\n",
      " 0.80331706 0.88028528 0.89870517 0.85857672 0.83087626 0.81560377\n",
      " 0.81169921 0.81916255 0.82182756 0.81969424 0.81786284 0.81633338\n",
      " 0.80055561 0.77052952 0.74265868 0.7169431  0.71970513 0.75094478\n",
      " 0.74027814 0.68770522 0.66876956 0.68347116 0.68770522 0.68147172\n",
      " 0.68926184 0.71107557 0.73491086 0.76076771 0.77111708 0.76595899\n",
      " 0.74833235 0.71823718 0.70894166 0.7204458  0.77061548 0.8594507\n",
      " 0.90654108 0.91188662 0.90433557 0.88388791 0.90321535 0.96231788\n",
      " 0.98205882 0.96243818 0.93025121 0.8854979  0.85970257 0.85286521\n",
      " 0.85858545 0.8768633  0.8806464  0.86993474 0.84651354 0.81038281\n",
      " 0.80261112 0.82319849 0.83972043 0.85217693 0.86156268 0.86787767\n",
      " 0.87019631 0.8685186  0.85298804 0.82360463 0.80325089 0.79192683\n",
      " 0.78650231 0.78697733 0.78743624 0.78787905 0.7954532  0.81015868\n",
      " 0.76684732 0.66551912 0.6360738  0.67851138 0.69659673 0.69032987\n",
      " 0.69704731 0.71674905 0.74905071 0.79395226 0.85474473 0.93142809\n",
      " 0.9627244  0.94863365 0.93071459 0.90896722 0.88163797 0.84872682\n",
      " 0.87526069 0.96123957 0.99250211 0.96904832 0.97154761 1.\n",
      " 0.98006365 0.91173857 0.89108579 0.91810533 0.94501652 0.97181936\n",
      " 0.98290672 0.97827858]\n",
      "---INICIO DE ENTRENAMIENTO: entrena_LM_pred---\n",
      "---Inicio de epoca: 1--\n",
      ">>Entradas: tensor([0.0503, 0.0086, 0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203])\n",
      ">>Salida: tensor([0.0494])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0327], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.0494])\n",
      ">>Entradas: tensor([0.0086, 0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203, 0.0327],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1079])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0549], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1079])\n",
      ">>Entradas: tensor([0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203, 0.0327, 0.0549],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1372])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0841], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1372])\n",
      ">>Entradas: tensor([0.0245, 0.0327, 0.0246, 0.0205, 0.0203, 0.0327, 0.0549, 0.0841],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1373])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1068], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1373])\n",
      ">>Entradas: tensor([0.0327, 0.0246, 0.0205, 0.0203, 0.0327, 0.0549, 0.0841, 0.1068],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1339])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1223], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1339])\n",
      ">>Entradas: tensor([0.0246, 0.0205, 0.0203, 0.0327, 0.0549, 0.0841, 0.1068, 0.1223],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1268])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1324], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1268])\n",
      ">>Entradas: tensor([0.0205, 0.0203, 0.0327, 0.0549, 0.0841, 0.1068, 0.1223, 0.1324],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1476])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1471], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1476])\n",
      ">>Entradas: tensor([0.0203, 0.0327, 0.0549, 0.0841, 0.1068, 0.1223, 0.1324, 0.1471],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1960])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1733], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1960])\n",
      ">>Entradas: tensor([0.0327, 0.0549, 0.0841, 0.1068, 0.1223, 0.1324, 0.1471, 0.1733],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2000], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2169])\n",
      ">>Entradas: tensor([0.0549, 0.0841, 0.1068, 0.1223, 0.1324, 0.1471, 0.1733, 0.2000],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2101])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2185], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2101])\n",
      ">>Entradas: tensor([0.0841, 0.1068, 0.1223, 0.1324, 0.1471, 0.1733, 0.2000, 0.2185],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2027])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2297], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2027])\n",
      ">>Entradas: tensor([0.1068, 0.1223, 0.1324, 0.1471, 0.1733, 0.2000, 0.2185, 0.2297],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1946])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2328], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1946])\n",
      ">>Entradas: tensor([0.1223, 0.1324, 0.1471, 0.1733, 0.2000, 0.2185, 0.2297, 0.2328],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1941])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2307], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1941])\n",
      ">>Entradas: tensor([0.1324, 0.1471, 0.1733, 0.2000, 0.2185, 0.2297, 0.2328, 0.2307],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2010])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2326], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2010])\n",
      ">>Entradas: tensor([0.1471, 0.1733, 0.2000, 0.2185, 0.2297, 0.2328, 0.2307, 0.2326],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2316], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1966])\n",
      ">>Entradas: tensor([0.1733, 0.2000, 0.2185, 0.2297, 0.2328, 0.2307, 0.2326, 0.2316],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1810])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2241], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1810])\n",
      ">>Entradas: tensor([0.2000, 0.2185, 0.2297, 0.2328, 0.2307, 0.2326, 0.2316, 0.2241],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1654])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1965], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1654])\n",
      ">>Entradas: tensor([0.2185, 0.2297, 0.2328, 0.2307, 0.2326, 0.2316, 0.2241, 0.1965],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1499])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1836], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1499])\n",
      ">>Entradas: tensor([0.2297, 0.2328, 0.2307, 0.2326, 0.2316, 0.2241, 0.1965, 0.1836],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1504])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1702], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1504])\n",
      ">>Entradas: tensor([0.2328, 0.2307, 0.2326, 0.2316, 0.2241, 0.1965, 0.1836, 0.1702],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1671])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1626], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1671])\n",
      ">>Entradas: tensor([0.2307, 0.2326, 0.2316, 0.2241, 0.1965, 0.1836, 0.1702, 0.1626],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2023])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1687], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2023])\n",
      ">>Entradas: tensor([0.2326, 0.2316, 0.2241, 0.1965, 0.1836, 0.1702, 0.1626, 0.1687],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2559])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1889], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2559])\n",
      ">>Entradas: tensor([0.2316, 0.2241, 0.1965, 0.1836, 0.1702, 0.1626, 0.1687, 0.1889],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2927])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2146], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2927])\n",
      ">>Entradas: tensor([0.2241, 0.1965, 0.1836, 0.1702, 0.1626, 0.1687, 0.1889, 0.2146],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2420], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.1965, 0.1836, 0.1702, 0.1626, 0.1687, 0.1889, 0.2146, 0.2420],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3109])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2644], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3109])\n",
      ">>Entradas: tensor([0.1836, 0.1702, 0.1626, 0.1687, 0.1889, 0.2146, 0.2420, 0.2644],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2876])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2777], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2876])\n",
      ">>Entradas: tensor([0.1702, 0.1626, 0.1687, 0.1889, 0.2146, 0.2420, 0.2644, 0.2777],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2802])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2879], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2802])\n",
      ">>Entradas: tensor([0.1626, 0.1687, 0.1889, 0.2146, 0.2420, 0.2644, 0.2777, 0.2879],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2886])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2999], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2886])\n",
      ">>Entradas: tensor([0.1687, 0.1889, 0.2146, 0.2420, 0.2644, 0.2777, 0.2879, 0.2999],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2825])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3079], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2825])\n",
      ">>Entradas: tensor([0.1889, 0.2146, 0.2420, 0.2644, 0.2777, 0.2879, 0.2999, 0.3079],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2618])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2574], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2618])\n",
      ">>Entradas: tensor([0.2146, 0.2420, 0.2644, 0.2777, 0.2879, 0.2999, 0.3079, 0.2574],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2745], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2801])\n",
      ">>Entradas: tensor([0.2420, 0.2644, 0.2777, 0.2879, 0.2999, 0.3079, 0.2574, 0.2745],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3374])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2983], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3374])\n",
      ">>Entradas: tensor([0.2644, 0.2777, 0.2879, 0.2999, 0.3079, 0.2574, 0.2745, 0.2983],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3482])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3131], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3482])\n",
      ">>Entradas: tensor([0.2777, 0.2879, 0.2999, 0.3079, 0.2574, 0.2745, 0.2983, 0.3131],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3202], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2879, 0.2999, 0.3079, 0.2574, 0.2745, 0.2983, 0.3131, 0.3202],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3436])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3338], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3436])\n",
      ">>Entradas: tensor([0.2999, 0.3079, 0.2574, 0.2745, 0.2983, 0.3131, 0.3202, 0.3338],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.4412])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3676], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.4412])\n",
      ">>Entradas: tensor([0.3079, 0.2574, 0.2745, 0.2983, 0.3131, 0.3202, 0.3338, 0.3676],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5211])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4193], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5211])\n",
      ">>Entradas: tensor([0.2574, 0.2745, 0.2983, 0.3131, 0.3202, 0.3338, 0.3676, 0.4193],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5833])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4812], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5833])\n",
      ">>Entradas: tensor([0.2745, 0.2983, 0.3131, 0.3202, 0.3338, 0.3676, 0.4193, 0.4812],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5410], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6089])\n",
      ">>Entradas: tensor([0.2983, 0.3131, 0.3202, 0.3338, 0.3676, 0.4193, 0.4812, 0.5410],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5980])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5836], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5980])\n",
      ">>Entradas: tensor([0.3131, 0.3202, 0.3338, 0.3676, 0.4193, 0.4812, 0.5410, 0.5836],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5945])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6149], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5945])\n",
      ">>Entradas: tensor([0.3202, 0.3338, 0.3676, 0.4193, 0.4812, 0.5410, 0.5836, 0.6149],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5985])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6387], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5985])\n",
      ">>Entradas: tensor([0.3338, 0.3676, 0.4193, 0.4812, 0.5410, 0.5836, 0.6149, 0.6387],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6214])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6608], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6214])\n",
      ">>Entradas: tensor([0.3676, 0.4193, 0.4812, 0.5410, 0.5836, 0.6149, 0.6387, 0.6608],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6631])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6930], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6631])\n",
      ">>Entradas: tensor([0.4193, 0.4812, 0.5410, 0.5836, 0.6149, 0.6387, 0.6608, 0.6930],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6929])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7232], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6929])\n",
      ">>Entradas: tensor([0.4812, 0.5410, 0.5836, 0.6149, 0.6387, 0.6608, 0.6930, 0.7232],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7107])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7468], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7107])\n",
      ">>Entradas: tensor([0.5410, 0.5836, 0.6149, 0.6387, 0.6608, 0.6930, 0.7232, 0.7468],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7217])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7555], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7217])\n",
      ">>Entradas: tensor([0.5836, 0.6149, 0.6387, 0.6608, 0.6930, 0.7232, 0.7468, 0.7555],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7259])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7660], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7259])\n",
      ">>Entradas: tensor([0.6149, 0.6387, 0.6608, 0.6930, 0.7232, 0.7468, 0.7555, 0.7660],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7404])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7739], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7404])\n",
      ">>Entradas: tensor([0.6387, 0.6608, 0.6930, 0.7232, 0.7468, 0.7555, 0.7660, 0.7739],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7652])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7847], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7652])\n",
      ">>Entradas: tensor([0.6608, 0.6930, 0.7232, 0.7468, 0.7555, 0.7660, 0.7739, 0.7847],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7448])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7855], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7448])\n",
      ">>Entradas: tensor([0.6930, 0.7232, 0.7468, 0.7555, 0.7660, 0.7739, 0.7847, 0.7855],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6792])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7653], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6792])\n",
      ">>Entradas: tensor([0.7232, 0.7468, 0.7555, 0.7660, 0.7739, 0.7847, 0.7855, 0.7653],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6746])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1686], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6746])\n",
      "ERROR: la modificacion de los pesos di√≥ un error mayor: 0.2560102343559265, se regresa al estado anterior de la red\n",
      ">>Entradas: tensor([0.7468, 0.7555, 0.7660, 0.7739, 0.7847, 0.7855, 0.7653, 0.7761],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7666], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7309])\n",
      ">>Entradas: tensor([0.7555, 0.7660, 0.7739, 0.7847, 0.7855, 0.7653, 0.7761, 0.7666],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7467])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7614], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7467])\n",
      ">>Entradas: tensor([0.7660, 0.7739, 0.7847, 0.7855, 0.7653, 0.7761, 0.7666, 0.7614],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7219])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7520], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7219])\n",
      ">>Entradas: tensor([0.7739, 0.7847, 0.7855, 0.7653, 0.7761, 0.7666, 0.7614, 0.7520],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7199])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7416], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7199])\n",
      ">>Entradas: tensor([0.7847, 0.7855, 0.7653, 0.7761, 0.7666, 0.7614, 0.7520, 0.7416],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7407])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7382], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7407])\n",
      ">>Entradas: tensor([0.7855, 0.7653, 0.7761, 0.7666, 0.7614, 0.7520, 0.7416, 0.7382],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7362])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7342], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7362])\n",
      ">>Entradas: tensor([0.7653, 0.7761, 0.7666, 0.7614, 0.7520, 0.7416, 0.7382, 0.7342],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7217], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7065])\n",
      ">>Entradas: tensor([0.7761, 0.7666, 0.7614, 0.7520, 0.7416, 0.7382, 0.7342, 0.7217],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6979])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7117], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6979])\n",
      ">>Entradas: tensor([0.7666, 0.7614, 0.7520, 0.7416, 0.7382, 0.7342, 0.7217, 0.7117],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7106])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7066], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7106])\n",
      ">>Entradas: tensor([0.7614, 0.7520, 0.7416, 0.7382, 0.7342, 0.7217, 0.7117, 0.7066],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7210])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7053], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7210])\n",
      ">>Entradas: tensor([0.7520, 0.7416, 0.7382, 0.7342, 0.7217, 0.7117, 0.7066, 0.7053],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7291])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7076], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7291])\n",
      ">>Entradas: tensor([0.7416, 0.7382, 0.7342, 0.7217, 0.7117, 0.7066, 0.7053, 0.7076],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7674])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7220], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7674])\n",
      ">>Entradas: tensor([0.7382, 0.7342, 0.7217, 0.7117, 0.7066, 0.7053, 0.7076, 0.7220],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8359])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7541], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8359])\n",
      ">>Entradas: tensor([0.7342, 0.7217, 0.7117, 0.7066, 0.7053, 0.7076, 0.7220, 0.7541],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8510])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7827], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8510])\n",
      ">>Entradas: tensor([0.7217, 0.7117, 0.7066, 0.7053, 0.7076, 0.7220, 0.7541, 0.7827],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8127])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7945], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8127])\n",
      ">>Entradas: tensor([0.7117, 0.7066, 0.7053, 0.7076, 0.7220, 0.7541, 0.7827, 0.7945],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7864])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7987], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7864])\n",
      ">>Entradas: tensor([0.7066, 0.7053, 0.7076, 0.7220, 0.7541, 0.7827, 0.7945, 0.7987],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7720])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7983], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7720])\n",
      ">>Entradas: tensor([0.7053, 0.7076, 0.7220, 0.7541, 0.7827, 0.7945, 0.7987, 0.7983],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8071], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.7076, 0.7220, 0.7541, 0.7827, 0.7945, 0.7987, 0.7983, 0.8071],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8803])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8377], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8803])\n",
      ">>Entradas: tensor([0.7220, 0.7541, 0.7827, 0.7945, 0.7987, 0.7983, 0.8071, 0.8377],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8987])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8659], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8987])\n",
      ">>Entradas: tensor([0.7541, 0.7827, 0.7945, 0.7987, 0.7983, 0.8071, 0.8377, 0.8659],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8745], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.7827, 0.7945, 0.7987, 0.7983, 0.8071, 0.8377, 0.8659, 0.8745],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8719], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8309])\n",
      ">>Entradas: tensor([0.7945, 0.7987, 0.7983, 0.8071, 0.8377, 0.8659, 0.8745, 0.8719],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8156])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8371], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8156])\n",
      ">>Entradas: tensor([0.7987, 0.7983, 0.8071, 0.8377, 0.8659, 0.8745, 0.8719, 0.8371],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8339], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8117])\n",
      ">>Entradas: tensor([0.7983, 0.8071, 0.8377, 0.8659, 0.8745, 0.8719, 0.8371, 0.8339],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8192])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8334], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8192])\n",
      ">>Entradas: tensor([0.8071, 0.8377, 0.8659, 0.8745, 0.8719, 0.8371, 0.8339, 0.8334],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8218])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8321], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8218])\n",
      ">>Entradas: tensor([0.8377, 0.8659, 0.8745, 0.8719, 0.8371, 0.8339, 0.8334, 0.8321],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8315], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8197])\n",
      ">>Entradas: tensor([0.8659, 0.8745, 0.8719, 0.8371, 0.8339, 0.8334, 0.8321, 0.8315],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8179])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8274], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8179])\n",
      ">>Entradas: tensor([0.8745, 0.8719, 0.8371, 0.8339, 0.8334, 0.8321, 0.8315, 0.8274],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8163])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8198], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8163])\n",
      ">>Entradas: tensor([0.8719, 0.8371, 0.8339, 0.8334, 0.8321, 0.8315, 0.8274, 0.8198],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8006])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8100], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8006])\n",
      ">>Entradas: tensor([0.8371, 0.8339, 0.8334, 0.8321, 0.8315, 0.8274, 0.8198, 0.8100],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7705])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7944], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7705])\n",
      ">>Entradas: tensor([0.8339, 0.8334, 0.8321, 0.8315, 0.8274, 0.8198, 0.8100, 0.7944],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7427])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7762], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7427])\n",
      ">>Entradas: tensor([0.8334, 0.8321, 0.8315, 0.8274, 0.8198, 0.8100, 0.7944, 0.7762],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7440], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7169])\n",
      ">>Entradas: tensor([0.8321, 0.8315, 0.8274, 0.8198, 0.8100, 0.7944, 0.7762, 0.7440],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7314], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7197])\n",
      ">>Entradas: tensor([0.8315, 0.8274, 0.8198, 0.8100, 0.7944, 0.7762, 0.7440, 0.7314],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7509])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7301], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7509])\n",
      ">>Entradas: tensor([0.8274, 0.8198, 0.8100, 0.7944, 0.7762, 0.7440, 0.7314, 0.7301],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7403])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7243], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7403])\n",
      ">>Entradas: tensor([0.8198, 0.8100, 0.7944, 0.7762, 0.7440, 0.7314, 0.7301, 0.7243],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7057], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.8100, 0.7944, 0.7762, 0.7440, 0.7314, 0.7301, 0.7243, 0.7057],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6688])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6870], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6688])\n",
      ">>Entradas: tensor([0.7944, 0.7762, 0.7440, 0.7314, 0.7301, 0.7243, 0.7057, 0.6870],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6835])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6761], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6835])\n",
      ">>Entradas: tensor([0.7762, 0.7440, 0.7314, 0.7301, 0.7243, 0.7057, 0.6870, 0.6761],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6696], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.7440, 0.7314, 0.7301, 0.7243, 0.7057, 0.6870, 0.6761, 0.6696],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6815])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6651], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6815])\n",
      ">>Entradas: tensor([0.7314, 0.7301, 0.7243, 0.7057, 0.6870, 0.6761, 0.6696, 0.6651],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6893])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6667], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6893])\n",
      ">>Entradas: tensor([0.7301, 0.7243, 0.7057, 0.6870, 0.6761, 0.6696, 0.6651, 0.6667],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7111])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6742], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7111])\n",
      ">>Entradas: tensor([0.7243, 0.7057, 0.6870, 0.6761, 0.6696, 0.6651, 0.6667, 0.6742],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7349])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6868], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7349])\n",
      ">>Entradas: tensor([0.7057, 0.6870, 0.6761, 0.6696, 0.6651, 0.6667, 0.6742, 0.6868],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7608])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7053], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7608])\n",
      ">>Entradas: tensor([0.6870, 0.6761, 0.6696, 0.6651, 0.6667, 0.6742, 0.6868, 0.7053],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7711])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7243], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7711])\n",
      ">>Entradas: tensor([0.6761, 0.6696, 0.6651, 0.6667, 0.6742, 0.6868, 0.7053, 0.7243],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7660])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7873], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7660])\n",
      ">>Entradas: tensor([0.6696, 0.6651, 0.6667, 0.6742, 0.6868, 0.7053, 0.7243, 0.7873],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7483])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7817], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7483])\n",
      ">>Entradas: tensor([0.6651, 0.6667, 0.6742, 0.6868, 0.7053, 0.7243, 0.7873, 0.7817],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7182])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7713], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7182])\n",
      ">>Entradas: tensor([0.6667, 0.6742, 0.6868, 0.7053, 0.7243, 0.7873, 0.7817, 0.7713],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7646], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7089])\n",
      ">>Entradas: tensor([0.6742, 0.6868, 0.7053, 0.7243, 0.7873, 0.7817, 0.7713, 0.7646],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7204])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7581], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7204])\n",
      ">>Entradas: tensor([0.6868, 0.7053, 0.7243, 0.7873, 0.7817, 0.7713, 0.7646, 0.7581],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7706])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7681], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7706])\n",
      ">>Entradas: tensor([0.7053, 0.7243, 0.7873, 0.7817, 0.7713, 0.7646, 0.7581, 0.7681],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8595])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8049], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8595])\n",
      ">>Entradas: tensor([0.7243, 0.7873, 0.7817, 0.7713, 0.7646, 0.7581, 0.7681, 0.8049],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8415], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9065])\n",
      ">>Entradas: tensor([0.7873, 0.7817, 0.7713, 0.7646, 0.7581, 0.7681, 0.8049, 0.8415],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9119])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8688], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9119])\n",
      ">>Entradas: tensor([0.7817, 0.7713, 0.7646, 0.7581, 0.7681, 0.8049, 0.8415, 0.8688],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9043])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8858], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9043])\n",
      ">>Entradas: tensor([0.7713, 0.7646, 0.7581, 0.7681, 0.8049, 0.8415, 0.8688, 0.8858],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8839])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8929], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8839])\n",
      ">>Entradas: tensor([0.7646, 0.7581, 0.7681, 0.8049, 0.8415, 0.8688, 0.8858, 0.8929],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9032])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9052], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9032])\n",
      ">>Entradas: tensor([0.7581, 0.7681, 0.8049, 0.8415, 0.8688, 0.8858, 0.8929, 0.9052],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9623])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9421], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9623])\n",
      ">>Entradas: tensor([0.7681, 0.8049, 0.8415, 0.8688, 0.8858, 0.8929, 0.9052, 0.9421],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9821])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9675], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9821])\n",
      ">>Entradas: tensor([0.8049, 0.8415, 0.8688, 0.8858, 0.8929, 0.9052, 0.9421, 0.9675],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9624])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9804], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9624])\n",
      ">>Entradas: tensor([0.8415, 0.8688, 0.8858, 0.8929, 0.9052, 0.9421, 0.9675, 0.9804],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9303])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9730], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9303])\n",
      ">>Entradas: tensor([0.8688, 0.8858, 0.8929, 0.9052, 0.9421, 0.9675, 0.9804, 0.9730],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8855])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9557], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8855])\n",
      ">>Entradas: tensor([0.8858, 0.8929, 0.9052, 0.9421, 0.9675, 0.9804, 0.9730, 0.9557],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8597])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9338], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8597])\n",
      ">>Entradas: tensor([0.8929, 0.9052, 0.9421, 0.9675, 0.9804, 0.9730, 0.9557, 0.9338],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8529])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9150], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8529])\n",
      ">>Entradas: tensor([0.9052, 0.9421, 0.9675, 0.9804, 0.9730, 0.9557, 0.9338, 0.9150],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9014], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.9421, 0.9675, 0.9804, 0.9730, 0.9557, 0.9338, 0.9150, 0.9014],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8769])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8945], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8769])\n",
      ">>Entradas: tensor([0.9675, 0.9804, 0.9730, 0.9557, 0.9338, 0.9150, 0.9014, 0.8945],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8806])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8869], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8806])\n",
      ">>Entradas: tensor([0.9804, 0.9730, 0.9557, 0.9338, 0.9150, 0.9014, 0.8945, 0.8869],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8699])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8759], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8699])\n",
      ">>Entradas: tensor([0.9730, 0.9557, 0.9338, 0.9150, 0.9014, 0.8945, 0.8869, 0.8759],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8465])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8599], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8465])\n",
      ">>Entradas: tensor([0.9557, 0.9338, 0.9150, 0.9014, 0.8945, 0.8869, 0.8759, 0.8599],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8104])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8376], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8104])\n",
      ">>Entradas: tensor([0.9338, 0.9150, 0.9014, 0.8945, 0.8869, 0.8759, 0.8599, 0.8376],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8026])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8197], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8026])\n",
      ">>Entradas: tensor([0.9150, 0.9014, 0.8945, 0.8869, 0.8759, 0.8599, 0.8376, 0.8197],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8232])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8135], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8232])\n",
      ">>Entradas: tensor([0.9014, 0.8945, 0.8869, 0.8759, 0.8599, 0.8376, 0.8197, 0.8135],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8397])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8140], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8397])\n",
      ">>Entradas: tensor([0.8945, 0.8869, 0.8759, 0.8599, 0.8376, 0.8197, 0.8135, 0.8140],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8522])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8186], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8522])\n",
      ">>Entradas: tensor([0.8869, 0.8759, 0.8599, 0.8376, 0.8197, 0.8135, 0.8140, 0.8186],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8616])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8256], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8616])\n",
      ">>Entradas: tensor([0.8759, 0.8599, 0.8376, 0.8197, 0.8135, 0.8140, 0.8186, 0.8256],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8679])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8328], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8679])\n",
      ">>Entradas: tensor([0.8599, 0.8376, 0.8197, 0.8135, 0.8140, 0.8186, 0.8256, 0.8328],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8702])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8399], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8702])\n",
      ">>Entradas: tensor([0.8376, 0.8197, 0.8135, 0.8140, 0.8186, 0.8256, 0.8328, 0.8399],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8685])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8467], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8685])\n",
      ">>Entradas: tensor([0.8197, 0.8135, 0.8140, 0.8186, 0.8256, 0.8328, 0.8399, 0.8467],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8530])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8492], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8530])\n",
      ">>Entradas: tensor([0.8135, 0.8140, 0.8186, 0.8256, 0.8328, 0.8399, 0.8467, 0.8492],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8236])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8440], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8236])\n",
      ">>Entradas: tensor([0.8140, 0.8186, 0.8256, 0.8328, 0.8399, 0.8467, 0.8492, 0.8440],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8346], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.8186, 0.8256, 0.8328, 0.8399, 0.8467, 0.8492, 0.8440, 0.8346],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7919])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8242], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7919])\n",
      ">>Entradas: tensor([0.8256, 0.8328, 0.8399, 0.8467, 0.8492, 0.8440, 0.8346, 0.8242],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7865])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8139], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7865])\n",
      ">>Entradas: tensor([0.8328, 0.8399, 0.8467, 0.8492, 0.8440, 0.8346, 0.8242, 0.8139],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7870])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8056], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7870])\n",
      ">>Entradas: tensor([0.8399, 0.8467, 0.8492, 0.8440, 0.8346, 0.8242, 0.8139, 0.8056],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7874])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7986], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7874])\n",
      ">>Entradas: tensor([0.8467, 0.8492, 0.8440, 0.8346, 0.8242, 0.8139, 0.8056, 0.7986],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7879])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7924], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7879])\n",
      ">>Entradas: tensor([0.8492, 0.8440, 0.8346, 0.8242, 0.8139, 0.8056, 0.7986, 0.7924],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7955])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7891], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7955])\n",
      ">>Entradas: tensor([0.8440, 0.8346, 0.8242, 0.8139, 0.8056, 0.7986, 0.7924, 0.7891],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8102])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7907], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8102])\n",
      ">>Entradas: tensor([0.8346, 0.8242, 0.8139, 0.8056, 0.7986, 0.7924, 0.7891, 0.7907],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7668])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7791], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7668])\n",
      ">>Entradas: tensor([0.8242, 0.8139, 0.8056, 0.7986, 0.7924, 0.7891, 0.7907, 0.7791],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6655])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7401], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6655])\n",
      ">>Entradas: tensor([0.8139, 0.8056, 0.7986, 0.7924, 0.7891, 0.7907, 0.7791, 0.7401],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6361])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7048], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6361])\n",
      ">>Entradas: tensor([0.8056, 0.7986, 0.7924, 0.7891, 0.7907, 0.7791, 0.7401, 0.7048],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6785])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6904], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6785])\n",
      ">>Entradas: tensor([0.7986, 0.7924, 0.7891, 0.7907, 0.7791, 0.7401, 0.7048, 0.6904],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6825], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6966])\n",
      ">>Entradas: tensor([0.7924, 0.7891, 0.7907, 0.7791, 0.7401, 0.7048, 0.6904, 0.6825],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6903])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6757], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6903])\n",
      ">>Entradas: tensor([0.7891, 0.7907, 0.7791, 0.7401, 0.7048, 0.6904, 0.6825, 0.6757],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6970])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6740], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6970])\n",
      ">>Entradas: tensor([0.7907, 0.7791, 0.7401, 0.7048, 0.6904, 0.6825, 0.6757, 0.6740],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7167])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6764], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7167])\n",
      ">>Entradas: tensor([0.7791, 0.7401, 0.7048, 0.6904, 0.6825, 0.6757, 0.6740, 0.6764],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7491])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6955], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7491])\n",
      ">>Entradas: tensor([0.7401, 0.7048, 0.6904, 0.6825, 0.6757, 0.6740, 0.6764, 0.6955],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7940])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7176], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7940])\n",
      ">>Entradas: tensor([0.7048, 0.6904, 0.6825, 0.6757, 0.6740, 0.6764, 0.6955, 0.7176],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8547])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7568], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8547])\n",
      ">>Entradas: tensor([0.6904, 0.6825, 0.6757, 0.6740, 0.6764, 0.6955, 0.7176, 0.7568],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9314])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8138], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9314])\n",
      ">>Entradas: tensor([0.6825, 0.6757, 0.6740, 0.6764, 0.6955, 0.7176, 0.7568, 0.8138],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9627])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8665], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9627])\n",
      ">>Entradas: tensor([0.6757, 0.6740, 0.6764, 0.6955, 0.7176, 0.7568, 0.8138, 0.8665],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9486])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9044], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9486])\n",
      ">>Entradas: tensor([0.6740, 0.6764, 0.6955, 0.7176, 0.7568, 0.8138, 0.8665, 0.9044],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9307])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9309], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9307])\n",
      ">>Entradas: tensor([0.6764, 0.6955, 0.7176, 0.7568, 0.8138, 0.8665, 0.9044, 0.9309],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9090])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9445], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9090])\n",
      ">>Entradas: tensor([0.6955, 0.7176, 0.7568, 0.8138, 0.8665, 0.9044, 0.9309, 0.9445],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8816])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9461], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8816])\n",
      ">>Entradas: tensor([0.7176, 0.7568, 0.8138, 0.8665, 0.9044, 0.9309, 0.9445, 0.9461],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8487])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9379], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8487])\n",
      ">>Entradas: tensor([0.7568, 0.8138, 0.8665, 0.9044, 0.9309, 0.9445, 0.9461, 0.9379],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8753])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9367], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8753])\n",
      ">>Entradas: tensor([0.8138, 0.8665, 0.9044, 0.9309, 0.9445, 0.9461, 0.9379, 0.9367],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9612])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9575], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9612])\n",
      ">>Entradas: tensor([0.8665, 0.9044, 0.9309, 0.9445, 0.9461, 0.9379, 0.9367, 0.9575],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9925])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9770], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9925])\n",
      ">>Entradas: tensor([0.9044, 0.9309, 0.9445, 0.9461, 0.9379, 0.9367, 0.9575, 0.9770],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9690])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9815], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9690])\n",
      ">>Entradas: tensor([0.9309, 0.9445, 0.9461, 0.9379, 0.9367, 0.9575, 0.9770, 0.9815],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9715])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9843], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9715])\n",
      ">>Entradas: tensor([0.9445, 0.9461, 0.9379, 0.9367, 0.9575, 0.9770, 0.9815, 0.9843],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([1.])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9921], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([1.])\n",
      ">>Entradas: tensor([0.9461, 0.9379, 0.9367, 0.9575, 0.9770, 0.9815, 0.9843, 0.9921],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9904], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9801])\n",
      ">>Entradas: tensor([0.9379, 0.9367, 0.9575, 0.9770, 0.9815, 0.9843, 0.9921, 0.9904],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9702], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9117])\n",
      ">>Entradas: tensor([0.9367, 0.9575, 0.9770, 0.9815, 0.9843, 0.9921, 0.9904, 0.9702],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8911])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9490], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8911])\n",
      ">>Entradas: tensor([0.9575, 0.9770, 0.9815, 0.9843, 0.9921, 0.9904, 0.9702, 0.9490],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9181])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9415], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9181])\n",
      ">>Entradas: tensor([0.9770, 0.9815, 0.9843, 0.9921, 0.9904, 0.9702, 0.9490, 0.9415],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9450])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9409], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9450])\n",
      ">>Entradas: tensor([0.9815, 0.9843, 0.9921, 0.9904, 0.9702, 0.9490, 0.9415, 0.9409],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9718])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9480], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9718])\n",
      ">>Entradas: tensor([0.9843, 0.9921, 0.9904, 0.9702, 0.9490, 0.9415, 0.9409, 0.9480],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9829])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9613], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9829])\n",
      ">>Entradas: tensor([0.9921, 0.9904, 0.9702, 0.9490, 0.9415, 0.9409, 0.9480, 0.9613],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9783])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9636], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9783])\n",
      ">>s_original: [0.049424633383750916, 0.10789185762405396, 0.13719609379768372, 0.13733737170696259, 0.1338856965303421, 0.12684109807014465, 0.14756061136722565, 0.19604423642158508, 0.21688967943191528, 0.21009695529937744, 0.20267784595489502, 0.1946323662996292, 0.19407351315021515, 0.20100130140781403, 0.19663821160793304, 0.180984228849411, 0.16539041697978973, 0.14985674619674683, 0.15043111145496368, 0.1671135276556015, 0.20227035880088806, 0.25590160489082336, 0.29268819093704224, 0.31263017654418945, 0.31093889474868774, 0.2876143157482147, 0.28016164898872375, 0.28858086466789246, 0.28246283531188965, 0.26180753111839294, 0.2801212966442108, 0.3374040722846985, 0.3482298254966736, 0.3125985562801361, 0.34358710050582886, 0.44119545817375183, 0.521095335483551, 0.5832866430282593, 0.6089234352111816, 0.5980057120323181, 0.5945301651954651, 0.5984968543052673, 0.621354341506958, 0.6631026864051819, 0.6928724050521851, 0.7106636166572571, 0.721682071685791, 0.7259277701377869, 0.7404318451881409, 0.7651942372322083, 0.7447891235351562, 0.6792163252830505, 0.6746017932891846, 0.730945348739624, 0.7467210292816162, 0.7219287157058716, 0.7199286818504333, 0.7407209277153015, 0.7362455129623413, 0.7065023183822632, 0.6979451775550842, 0.7105739712715149, 0.7209621667861938, 0.7291097044944763, 0.7674259543418884, 0.8359109163284302, 0.8510103225708008, 0.8127241730690002, 0.7863940000534058, 0.7720199823379517, 0.8033170700073242, 0.8802852630615234, 0.8987051844596863, 0.8585767149925232, 0.8308762311935425, 0.8156037926673889, 0.8116992115974426, 0.8191625475883484, 0.8218275904655457, 0.8196942210197449, 0.817862868309021, 0.8163333535194397, 0.8005555868148804, 0.7705295085906982, 0.7426586747169495, 0.716943085193634, 0.7197051048278809, 0.7509447932243347, 0.7402781248092651, 0.6877052187919617, 0.6687695384025574, 0.683471143245697, 0.6877052187919617, 0.6814717054367065, 0.6892618536949158, 0.7110756039619446, 0.7349108457565308, 0.7607676982879639, 0.771117091178894, 0.7659589648246765, 0.7483323812484741, 0.7182371616363525, 0.708941638469696, 0.7204458117485046, 0.7706154584884644, 0.8594506978988647, 0.906541109085083, 0.9118866324424744, 0.9043355584144592, 0.8838878870010376, 0.9032153487205505, 0.9623178839683533, 0.9820588231086731, 0.96243816614151, 0.9302511811256409, 0.8854979276657104, 0.8597025871276855, 0.8528652191162109, 0.8585854768753052, 0.8768633008003235, 0.8806464076042175, 0.8699347376823425, 0.846513569355011, 0.8103827834129333, 0.8026111125946045, 0.8231984972953796, 0.8397204279899597, 0.8521769046783447, 0.8615626692771912, 0.8678776621818542, 0.8701963424682617, 0.868518590927124, 0.852988064289093, 0.8236046433448792, 0.8032509088516235, 0.7919268012046814, 0.7865023016929626, 0.7869773507118225, 0.7874362468719482, 0.7878790497779846, 0.7954531908035278, 0.8101586699485779, 0.7668473124504089, 0.665519118309021, 0.6360738277435303, 0.678511381149292, 0.6965967416763306, 0.6903298497200012, 0.6970472931861877, 0.7167490720748901, 0.7490506768226624, 0.7939522862434387, 0.8547447323799133, 0.931428074836731, 0.9627243876457214, 0.9486336708068848, 0.9307146072387695, 0.9089671969413757, 0.8816379904747009, 0.8487268090248108, 0.8752607107162476, 0.9612395763397217, 0.9925020933151245, 0.9690483212471008, 0.9715476036071777, 1.0, 0.9800636768341064, 0.9117385745048523, 0.8910858035087585, 0.9181053042411804, 0.9450165033340454, 0.9718193411827087, 0.982906699180603, 0.9782785773277283]\n",
      ">>s_pred: [0.0326838493347168, 0.05490875244140625, 0.08408212661743164, 0.1067514419555664, 0.12226581573486328, 0.13241291046142578, 0.14707088470458984, 0.17332029342651367, 0.2000288963317871, 0.21846818923950195, 0.2297043800354004, 0.2327728271484375, 0.23067283630371094, 0.23262405395507812, 0.2315988540649414, 0.22413110733032227, 0.19654464721679688, 0.18355941772460938, 0.1702122688293457, 0.16264772415161133, 0.1686549186706543, 0.18892955780029297, 0.214569091796875, 0.2419734001159668, 0.26443052291870117, 0.27765417098999023, 0.28786277770996094, 0.29994821548461914, 0.3079342842102051, 0.25742244720458984, 0.27446556091308594, 0.2983431816101074, 0.3131065368652344, 0.3201737403869629, 0.3337669372558594, 0.36759519577026367, 0.4193434715270996, 0.4812040328979492, 0.5410428047180176, 0.5835890769958496, 0.6149272918701172, 0.6387181282043457, 0.6608257293701172, 0.6929636001586914, 0.7232437133789062, 0.7468013763427734, 0.7554740905761719, 0.7660064697265625, 0.7739229202270508, 0.7846899032592773, 0.7855029106140137, 0.7653326988220215, 0.7761073112487793, 0.7665543556213379, 0.7613840103149414, 0.752049446105957, 0.7416486740112305, 0.7382020950317383, 0.7341957092285156, 0.7216801643371582, 0.7116584777832031, 0.7065539360046387, 0.7052798271179199, 0.7075791358947754, 0.7220253944396973, 0.7540712356567383, 0.7826991081237793, 0.7944779396057129, 0.7987332344055176, 0.7983083724975586, 0.8071045875549316, 0.8377389907836914, 0.8659491539001465, 0.8744797706604004, 0.8719286918640137, 0.8370962142944336, 0.8339014053344727, 0.8334455490112305, 0.832085132598877, 0.8315367698669434, 0.8274388313293457, 0.8197836875915527, 0.8099508285522461, 0.7943582534790039, 0.7762413024902344, 0.7440090179443359, 0.7314057350158691, 0.7301216125488281, 0.7242717742919922, 0.7057194709777832, 0.6870250701904297, 0.6761355400085449, 0.6696429252624512, 0.6651153564453125, 0.6666650772094727, 0.6742024421691895, 0.6867504119873047, 0.7052984237670898, 0.7243289947509766, 0.7872800827026367, 0.7816562652587891, 0.7712769508361816, 0.7646021842956543, 0.7581329345703125, 0.7680516242980957, 0.8049349784851074, 0.8415226936340332, 0.8688435554504395, 0.885767936706543, 0.8928713798522949, 0.9051823616027832, 0.9420528411865234, 0.9674587249755859, 0.9803662300109863, 0.9729862213134766, 0.9557065963745117, 0.9337644577026367, 0.9150066375732422, 0.9013671875, 0.8944807052612305, 0.8869147300720215, 0.8758583068847656, 0.8598804473876953, 0.8375535011291504, 0.819666862487793, 0.8135027885437012, 0.8140196800231934, 0.8186469078063965, 0.8255548477172852, 0.8327713012695312, 0.839902400970459, 0.8466792106628418, 0.8491897583007812, 0.8439526557922363, 0.8345732688903809, 0.8241581916809082, 0.8138847351074219, 0.8055853843688965, 0.7986211776733398, 0.7923831939697266, 0.7891454696655273, 0.7907290458679199, 0.7790508270263672, 0.7400860786437988, 0.7048430442810059, 0.6904177665710449, 0.6824855804443359, 0.675656795501709, 0.6740069389343262, 0.6764287948608398, 0.6955184936523438, 0.71759033203125, 0.7567667961120605, 0.8137526512145996, 0.8665366172790527, 0.9044222831726074, 0.9309110641479492, 0.9444708824157715, 0.9460678100585938, 0.9378628730773926, 0.9367198944091797, 0.957496166229248, 0.9770169258117676, 0.9814724922180176, 0.9842743873596191, 0.9921021461486816, 0.9904055595397949, 0.9701700210571289, 0.9490189552307129, 0.9414920806884766, 0.9409112930297852, 0.9479541778564453, 0.9613189697265625, 0.9636216163635254]\n",
      "<<Perdida: 0.0015684955287724733 epoca: 1\n",
      "---Inicio de epoca: 2--\n",
      ">>Entradas: tensor([0.0503, 0.0086, 0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203])\n",
      ">>Salida: tensor([0.0494])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0385], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.0494])\n",
      ">>Entradas: tensor([0.0086, 0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203, 0.0385],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1079])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0592], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1079])\n",
      ">>Entradas: tensor([0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203, 0.0385, 0.0592],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1372])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0880], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1372])\n",
      ">>Entradas: tensor([0.0245, 0.0327, 0.0246, 0.0205, 0.0203, 0.0385, 0.0592, 0.0880],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1373])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1109], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1373])\n",
      ">>Entradas: tensor([0.0327, 0.0246, 0.0205, 0.0203, 0.0385, 0.0592, 0.0880, 0.1109],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1339])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1257], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1339])\n",
      ">>Entradas: tensor([0.0246, 0.0205, 0.0203, 0.0385, 0.0592, 0.0880, 0.1109, 0.1257],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1268])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1358], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1268])\n",
      ">>Entradas: tensor([0.0205, 0.0203, 0.0385, 0.0592, 0.0880, 0.1109, 0.1257, 0.1358],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1476])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1509], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1476])\n",
      ">>Entradas: tensor([0.0203, 0.0385, 0.0592, 0.0880, 0.1109, 0.1257, 0.1358, 0.1509],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1960])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1771], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1960])\n",
      ">>Entradas: tensor([0.0385, 0.0592, 0.0880, 0.1109, 0.1257, 0.1358, 0.1509, 0.1771],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2038], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2169])\n",
      ">>Entradas: tensor([0.0592, 0.0880, 0.1109, 0.1257, 0.1358, 0.1509, 0.1771, 0.2038],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2101])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2221], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2101])\n",
      ">>Entradas: tensor([0.0880, 0.1109, 0.1257, 0.1358, 0.1509, 0.1771, 0.2038, 0.2221],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2027])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2331], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2027])\n",
      ">>Entradas: tensor([0.1109, 0.1257, 0.1358, 0.1509, 0.1771, 0.2038, 0.2221, 0.2331],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1946])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2347], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1946])\n",
      ">>Entradas: tensor([0.1257, 0.1358, 0.1509, 0.1771, 0.2038, 0.2221, 0.2331, 0.2347],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1941])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2339], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1941])\n",
      ">>Entradas: tensor([0.1358, 0.1509, 0.1771, 0.2038, 0.2221, 0.2331, 0.2347, 0.2339],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2010])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2354], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2010])\n",
      ">>Entradas: tensor([0.1509, 0.1771, 0.2038, 0.2221, 0.2331, 0.2347, 0.2339, 0.2354],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2337], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1966])\n",
      ">>Entradas: tensor([0.1771, 0.2038, 0.2221, 0.2331, 0.2347, 0.2339, 0.2354, 0.2337],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1810])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2224], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1810])\n",
      ">>Entradas: tensor([0.2038, 0.2221, 0.2331, 0.2347, 0.2339, 0.2354, 0.2337, 0.2224],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1654])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2107], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1654])\n",
      ">>Entradas: tensor([0.2221, 0.2331, 0.2347, 0.2339, 0.2354, 0.2337, 0.2224, 0.2107],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1499])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1918], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1499])\n",
      ">>Entradas: tensor([0.2331, 0.2347, 0.2339, 0.2354, 0.2337, 0.2224, 0.2107, 0.1918],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1504])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1765], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1504])\n",
      ">>Entradas: tensor([0.2347, 0.2339, 0.2354, 0.2337, 0.2224, 0.2107, 0.1918, 0.1765],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1671])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1687], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1671])\n",
      ">>Entradas: tensor([0.2339, 0.2354, 0.2337, 0.2224, 0.2107, 0.1918, 0.1765, 0.1687],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2023])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1743], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2023])\n",
      ">>Entradas: tensor([0.2354, 0.2337, 0.2224, 0.2107, 0.1918, 0.1765, 0.1687, 0.1743],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2559])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1921], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2559])\n",
      ">>Entradas: tensor([0.2337, 0.2224, 0.2107, 0.1918, 0.1765, 0.1687, 0.1743, 0.1921],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2927])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2172], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2927])\n",
      ">>Entradas: tensor([0.2224, 0.2107, 0.1918, 0.1765, 0.1687, 0.1743, 0.1921, 0.2172],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2435], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2107, 0.1918, 0.1765, 0.1687, 0.1743, 0.1921, 0.2172, 0.2435],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3109])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2652], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3109])\n",
      ">>Entradas: tensor([0.1918, 0.1765, 0.1687, 0.1743, 0.1921, 0.2172, 0.2435, 0.2652],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2876])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2773], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2876])\n",
      ">>Entradas: tensor([0.1765, 0.1687, 0.1743, 0.1921, 0.2172, 0.2435, 0.2652, 0.2773],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2802])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2873], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2802])\n",
      ">>Entradas: tensor([0.1687, 0.1743, 0.1921, 0.2172, 0.2435, 0.2652, 0.2773, 0.2873],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2886])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2993], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2886])\n",
      ">>Entradas: tensor([0.1743, 0.1921, 0.2172, 0.2435, 0.2652, 0.2773, 0.2873, 0.2993],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2825])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3073], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2825])\n",
      ">>Entradas: tensor([0.1921, 0.2172, 0.2435, 0.2652, 0.2773, 0.2873, 0.2993, 0.3073],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2618])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3061], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2618])\n",
      ">>Entradas: tensor([0.2172, 0.2435, 0.2652, 0.2773, 0.2873, 0.2993, 0.3073, 0.3061],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3110], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2801])\n",
      ">>Entradas: tensor([0.2435, 0.2652, 0.2773, 0.2873, 0.2993, 0.3073, 0.3061, 0.3110],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3374])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3281], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3374])\n",
      ">>Entradas: tensor([0.2652, 0.2773, 0.2873, 0.2993, 0.3073, 0.3061, 0.3110, 0.3281],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3482])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3408], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3482])\n",
      ">>Entradas: tensor([0.2773, 0.2873, 0.2993, 0.3073, 0.3061, 0.3110, 0.3281, 0.3408],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3398], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2873, 0.2993, 0.3073, 0.3061, 0.3110, 0.3281, 0.3408, 0.3398],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3436])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3488], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3436])\n",
      ">>Entradas: tensor([0.2993, 0.3073, 0.3061, 0.3110, 0.3281, 0.3408, 0.3398, 0.3488],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.4412])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3822], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.4412])\n",
      ">>Entradas: tensor([0.3073, 0.3061, 0.3110, 0.3281, 0.3408, 0.3398, 0.3488, 0.3822],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5211])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4479], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5211])\n",
      ">>Entradas: tensor([0.3061, 0.3110, 0.3281, 0.3408, 0.3398, 0.3488, 0.3822, 0.4479],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5833])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5012], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5833])\n",
      ">>Entradas: tensor([0.3110, 0.3281, 0.3408, 0.3398, 0.3488, 0.3822, 0.4479, 0.5012],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5546], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6089])\n",
      ">>Entradas: tensor([0.3281, 0.3408, 0.3398, 0.3488, 0.3822, 0.4479, 0.5012, 0.5546],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5980])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5940], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5980])\n",
      ">>Entradas: tensor([0.3408, 0.3398, 0.3488, 0.3822, 0.4479, 0.5012, 0.5546, 0.5940],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5945])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6211], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5945])\n",
      ">>Entradas: tensor([0.3398, 0.3488, 0.3822, 0.4479, 0.5012, 0.5546, 0.5940, 0.6211],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5985])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6443], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5985])\n",
      ">>Entradas: tensor([0.3488, 0.3822, 0.4479, 0.5012, 0.5546, 0.5940, 0.6211, 0.6443],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6214])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6710], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6214])\n",
      ">>Entradas: tensor([0.3822, 0.4479, 0.5012, 0.5546, 0.5940, 0.6211, 0.6443, 0.6710],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6631])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7012], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6631])\n",
      ">>Entradas: tensor([0.4479, 0.5012, 0.5546, 0.5940, 0.6211, 0.6443, 0.6710, 0.7012],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6929])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7296], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6929])\n",
      ">>Entradas: tensor([0.5012, 0.5546, 0.5940, 0.6211, 0.6443, 0.6710, 0.7012, 0.7296],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7107])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7403], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7107])\n",
      ">>Entradas: tensor([0.5546, 0.5940, 0.6211, 0.6443, 0.6710, 0.7012, 0.7296, 0.7403],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7217])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7564], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7217])\n",
      ">>Entradas: tensor([0.5940, 0.6211, 0.6443, 0.6710, 0.7012, 0.7296, 0.7403, 0.7564],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7259])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7659], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7259])\n",
      ">>Entradas: tensor([0.6211, 0.6443, 0.6710, 0.7012, 0.7296, 0.7403, 0.7564, 0.7659],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7404])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7733], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7404])\n",
      ">>Entradas: tensor([0.6443, 0.6710, 0.7012, 0.7296, 0.7403, 0.7564, 0.7659, 0.7733],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7652])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7855], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7652])\n",
      ">>Entradas: tensor([0.6710, 0.7012, 0.7296, 0.7403, 0.7564, 0.7659, 0.7733, 0.7855],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7448])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7723], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7448])\n",
      ">>Entradas: tensor([0.7012, 0.7296, 0.7403, 0.7564, 0.7659, 0.7733, 0.7855, 0.7723],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6792])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([-12.6365], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6792])\n",
      "ERROR: la modificacion de los pesos di√≥ un error mayor: 177.30813598632812, se regresa al estado anterior de la red\n",
      ">>Entradas: tensor([0.7296, 0.7403, 0.7564, 0.7659, 0.7733, 0.7855, 0.7723, 0.7854],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6746])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7600], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6746])\n",
      ">>Entradas: tensor([0.7403, 0.7564, 0.7659, 0.7733, 0.7855, 0.7723, 0.7854, 0.7600],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7539], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7309])\n",
      ">>Entradas: tensor([0.7564, 0.7659, 0.7733, 0.7855, 0.7723, 0.7854, 0.7600, 0.7539],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7467])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7549], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7467])\n",
      ">>Entradas: tensor([0.7659, 0.7733, 0.7855, 0.7723, 0.7854, 0.7600, 0.7539, 0.7549],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7219])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7437], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7219])\n",
      ">>Entradas: tensor([0.7733, 0.7855, 0.7723, 0.7854, 0.7600, 0.7539, 0.7549, 0.7437],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7199])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7347], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7199])\n",
      ">>Entradas: tensor([0.7855, 0.7723, 0.7854, 0.7600, 0.7539, 0.7549, 0.7437, 0.7347],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7407])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7352], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7407])\n",
      ">>Entradas: tensor([0.7723, 0.7854, 0.7600, 0.7539, 0.7549, 0.7437, 0.7347, 0.7352],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7362])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7301], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7362])\n",
      ">>Entradas: tensor([0.7854, 0.7600, 0.7539, 0.7549, 0.7437, 0.7347, 0.7352, 0.7301],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7181], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7065])\n",
      ">>Entradas: tensor([0.7600, 0.7539, 0.7549, 0.7437, 0.7347, 0.7352, 0.7301, 0.7181],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6979])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7085], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6979])\n",
      ">>Entradas: tensor([0.7539, 0.7549, 0.7437, 0.7347, 0.7352, 0.7301, 0.7181, 0.7085],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7106])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7050], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7106])\n",
      ">>Entradas: tensor([0.7549, 0.7437, 0.7347, 0.7352, 0.7301, 0.7181, 0.7085, 0.7050],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7210])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7045], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7210])\n",
      ">>Entradas: tensor([0.7437, 0.7347, 0.7352, 0.7301, 0.7181, 0.7085, 0.7050, 0.7045],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7291])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7078], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7291])\n",
      ">>Entradas: tensor([0.7347, 0.7352, 0.7301, 0.7181, 0.7085, 0.7050, 0.7045, 0.7078],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7674])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7230], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7674])\n",
      ">>Entradas: tensor([0.7352, 0.7301, 0.7181, 0.7085, 0.7050, 0.7045, 0.7078, 0.7230],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8359])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7551], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8359])\n",
      ">>Entradas: tensor([0.7301, 0.7181, 0.7085, 0.7050, 0.7045, 0.7078, 0.7230, 0.7551],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8510])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7836], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8510])\n",
      ">>Entradas: tensor([0.7181, 0.7085, 0.7050, 0.7045, 0.7078, 0.7230, 0.7551, 0.7836],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8127])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7959], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8127])\n",
      ">>Entradas: tensor([0.7085, 0.7050, 0.7045, 0.7078, 0.7230, 0.7551, 0.7836, 0.7959],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7864])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8006], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7864])\n",
      ">>Entradas: tensor([0.7050, 0.7045, 0.7078, 0.7230, 0.7551, 0.7836, 0.7959, 0.8006],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7720])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8003], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7720])\n",
      ">>Entradas: tensor([0.7045, 0.7078, 0.7230, 0.7551, 0.7836, 0.7959, 0.8006, 0.8003],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8090], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.7078, 0.7230, 0.7551, 0.7836, 0.7959, 0.8006, 0.8003, 0.8090],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8803])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8398], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8803])\n",
      ">>Entradas: tensor([0.7230, 0.7551, 0.7836, 0.7959, 0.8006, 0.8003, 0.8090, 0.8398],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8987])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8683], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8987])\n",
      ">>Entradas: tensor([0.7551, 0.7836, 0.7959, 0.8006, 0.8003, 0.8090, 0.8398, 0.8683],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8764], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.7836, 0.7959, 0.8006, 0.8003, 0.8090, 0.8398, 0.8683, 0.8764],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8734], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8309])\n",
      ">>Entradas: tensor([0.7959, 0.8006, 0.8003, 0.8090, 0.8398, 0.8683, 0.8764, 0.8734],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8156])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8549], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8156])\n",
      ">>Entradas: tensor([0.8006, 0.8003, 0.8090, 0.8398, 0.8683, 0.8764, 0.8734, 0.8549],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8463], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8117])\n",
      ">>Entradas: tensor([0.8003, 0.8090, 0.8398, 0.8683, 0.8764, 0.8734, 0.8549, 0.8463],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8192])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8431], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8192])\n",
      ">>Entradas: tensor([0.8090, 0.8398, 0.8683, 0.8764, 0.8734, 0.8549, 0.8463, 0.8431],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8218])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8412], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8218])\n",
      ">>Entradas: tensor([0.8398, 0.8683, 0.8764, 0.8734, 0.8549, 0.8463, 0.8431, 0.8412],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8379], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8197])\n",
      ">>Entradas: tensor([0.8683, 0.8764, 0.8734, 0.8549, 0.8463, 0.8431, 0.8412, 0.8379],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8179])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8319], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8179])\n",
      ">>Entradas: tensor([0.8764, 0.8734, 0.8549, 0.8463, 0.8431, 0.8412, 0.8379, 0.8319],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8163])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8237], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8163])\n",
      ">>Entradas: tensor([0.8734, 0.8549, 0.8463, 0.8431, 0.8412, 0.8379, 0.8319, 0.8237],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8006])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8124], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8006])\n",
      ">>Entradas: tensor([0.8549, 0.8463, 0.8431, 0.8412, 0.8379, 0.8319, 0.8237, 0.8124],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7705])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7959], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7705])\n",
      ">>Entradas: tensor([0.8463, 0.8431, 0.8412, 0.8379, 0.8319, 0.8237, 0.8124, 0.7959],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7427])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7762], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7427])\n",
      ">>Entradas: tensor([0.8431, 0.8412, 0.8379, 0.8319, 0.8237, 0.8124, 0.7959, 0.7762],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7530], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7169])\n",
      ">>Entradas: tensor([0.8412, 0.8379, 0.8319, 0.8237, 0.8124, 0.7959, 0.7762, 0.7530],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7369], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7197])\n",
      ">>Entradas: tensor([0.8379, 0.8319, 0.8237, 0.8124, 0.7959, 0.7762, 0.7530, 0.7369],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7509])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7335], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7509])\n",
      ">>Entradas: tensor([0.8319, 0.8237, 0.8124, 0.7959, 0.7762, 0.7530, 0.7369, 0.7335],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7403])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7267], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7403])\n",
      ">>Entradas: tensor([0.8237, 0.8124, 0.7959, 0.7762, 0.7530, 0.7369, 0.7335, 0.7267],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7065], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.8124, 0.7959, 0.7762, 0.7530, 0.7369, 0.7335, 0.7267, 0.7065],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6688])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6869], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6688])\n",
      ">>Entradas: tensor([0.7959, 0.7762, 0.7530, 0.7369, 0.7335, 0.7267, 0.7065, 0.6869],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6835])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6761], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6835])\n",
      ">>Entradas: tensor([0.7762, 0.7530, 0.7369, 0.7335, 0.7267, 0.7065, 0.6869, 0.6761],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6686], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.7530, 0.7369, 0.7335, 0.7267, 0.7065, 0.6869, 0.6761, 0.6686],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6815])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6637], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6815])\n",
      ">>Entradas: tensor([0.7369, 0.7335, 0.7267, 0.7065, 0.6869, 0.6761, 0.6686, 0.6637],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6893])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6649], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6893])\n",
      ">>Entradas: tensor([0.7335, 0.7267, 0.7065, 0.6869, 0.6761, 0.6686, 0.6637, 0.6649],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7111])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6721], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7111])\n",
      ">>Entradas: tensor([0.7267, 0.7065, 0.6869, 0.6761, 0.6686, 0.6637, 0.6649, 0.6721],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7349])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6842], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7349])\n",
      ">>Entradas: tensor([0.7065, 0.6869, 0.6761, 0.6686, 0.6637, 0.6649, 0.6721, 0.6842],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7608])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7034], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7608])\n",
      ">>Entradas: tensor([0.6869, 0.6761, 0.6686, 0.6637, 0.6649, 0.6721, 0.6842, 0.7034],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7711])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7228], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7711])\n",
      ">>Entradas: tensor([0.6761, 0.6686, 0.6637, 0.6649, 0.6721, 0.6842, 0.7034, 0.7228],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7660])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7381], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7660])\n",
      ">>Entradas: tensor([0.6686, 0.6637, 0.6649, 0.6721, 0.6842, 0.7034, 0.7228, 0.7381],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7483])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7462], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7483])\n",
      ">>Entradas: tensor([0.6637, 0.6649, 0.6721, 0.6842, 0.7034, 0.7228, 0.7381, 0.7462],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7182])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7447], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7182])\n",
      ">>Entradas: tensor([0.6649, 0.6721, 0.6842, 0.7034, 0.7228, 0.7381, 0.7462, 0.7447],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7415], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7089])\n",
      ">>Entradas: tensor([0.6721, 0.6842, 0.7034, 0.7228, 0.7381, 0.7462, 0.7447, 0.7415],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7204])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7425], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7204])\n",
      ">>Entradas: tensor([0.6842, 0.7034, 0.7228, 0.7381, 0.7462, 0.7447, 0.7415, 0.7425],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7706])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7572], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7706])\n",
      ">>Entradas: tensor([0.7034, 0.7228, 0.7381, 0.7462, 0.7447, 0.7415, 0.7425, 0.7572],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8595])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7937], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8595])\n",
      ">>Entradas: tensor([0.7228, 0.7381, 0.7462, 0.7447, 0.7415, 0.7425, 0.7572, 0.7937],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8336], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9065])\n",
      ">>Entradas: tensor([0.7381, 0.7462, 0.7447, 0.7415, 0.7425, 0.7572, 0.7937, 0.8336],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9119])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8642], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9119])\n",
      ">>Entradas: tensor([0.7462, 0.7447, 0.7415, 0.7425, 0.7572, 0.7937, 0.8336, 0.8642],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9043])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8856], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9043])\n",
      ">>Entradas: tensor([0.7447, 0.7415, 0.7425, 0.7572, 0.7937, 0.8336, 0.8642, 0.8856],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8839])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8957], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8839])\n",
      ">>Entradas: tensor([0.7415, 0.7425, 0.7572, 0.7937, 0.8336, 0.8642, 0.8856, 0.8957],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9032])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9095], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9032])\n",
      ">>Entradas: tensor([0.7425, 0.7572, 0.7937, 0.8336, 0.8642, 0.8856, 0.8957, 0.9095],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9623])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9392], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9623])\n",
      ">>Entradas: tensor([0.7572, 0.7937, 0.8336, 0.8642, 0.8856, 0.8957, 0.9095, 0.9392],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9821])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9672], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9821])\n",
      ">>Entradas: tensor([0.7937, 0.8336, 0.8642, 0.8856, 0.8957, 0.9095, 0.9392, 0.9672],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9624])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9811], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9624])\n",
      ">>Entradas: tensor([0.8336, 0.8642, 0.8856, 0.8957, 0.9095, 0.9392, 0.9672, 0.9811],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9303])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9116], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9303])\n",
      ">>Entradas: tensor([0.8642, 0.8856, 0.8957, 0.9095, 0.9392, 0.9672, 0.9811, 0.9116],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8855])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9130], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8855])\n",
      ">>Entradas: tensor([0.8856, 0.8957, 0.9095, 0.9392, 0.9672, 0.9811, 0.9116, 0.9130],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8597])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9008], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8597])\n",
      ">>Entradas: tensor([0.8957, 0.9095, 0.9392, 0.9672, 0.9811, 0.9116, 0.9130, 0.9008],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8529])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8845], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8529])\n",
      ">>Entradas: tensor([0.9095, 0.9392, 0.9672, 0.9811, 0.9116, 0.9130, 0.9008, 0.8845],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8805], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.9392, 0.9672, 0.9811, 0.9116, 0.9130, 0.9008, 0.8845, 0.8805],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8769])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8794], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8769])\n",
      ">>Entradas: tensor([0.9672, 0.9811, 0.9116, 0.9130, 0.9008, 0.8845, 0.8805, 0.8794],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8806])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8704], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8806])\n",
      ">>Entradas: tensor([0.9811, 0.9116, 0.9130, 0.9008, 0.8845, 0.8805, 0.8794, 0.8704],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8699])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8608], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8699])\n",
      ">>Entradas: tensor([0.9116, 0.9130, 0.9008, 0.8845, 0.8805, 0.8794, 0.8704, 0.8608],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8465])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8490], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8465])\n",
      ">>Entradas: tensor([0.9130, 0.9008, 0.8845, 0.8805, 0.8794, 0.8704, 0.8608, 0.8490],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8104])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8310], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8104])\n",
      ">>Entradas: tensor([0.9008, 0.8845, 0.8805, 0.8794, 0.8704, 0.8608, 0.8490, 0.8310],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8026])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8157], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8026])\n",
      ">>Entradas: tensor([0.8845, 0.8805, 0.8794, 0.8704, 0.8608, 0.8490, 0.8310, 0.8157],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8232])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8116], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8232])\n",
      ">>Entradas: tensor([0.8805, 0.8794, 0.8704, 0.8608, 0.8490, 0.8310, 0.8157, 0.8116],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8397])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8134], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8397])\n",
      ">>Entradas: tensor([0.8794, 0.8704, 0.8608, 0.8490, 0.8310, 0.8157, 0.8116, 0.8134],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8522])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8185], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8522])\n",
      ">>Entradas: tensor([0.8704, 0.8608, 0.8490, 0.8310, 0.8157, 0.8116, 0.8134, 0.8185],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8616])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8261], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8616])\n",
      ">>Entradas: tensor([0.8608, 0.8490, 0.8310, 0.8157, 0.8116, 0.8134, 0.8185, 0.8261],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8679])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8342], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8679])\n",
      ">>Entradas: tensor([0.8490, 0.8310, 0.8157, 0.8116, 0.8134, 0.8185, 0.8261, 0.8342],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8702])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8417], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8702])\n",
      ">>Entradas: tensor([0.8310, 0.8157, 0.8116, 0.8134, 0.8185, 0.8261, 0.8342, 0.8417],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8685])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8489], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8685])\n",
      ">>Entradas: tensor([0.8157, 0.8116, 0.8134, 0.8185, 0.8261, 0.8342, 0.8417, 0.8489],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8530])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8519], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8530])\n",
      ">>Entradas: tensor([0.8116, 0.8134, 0.8185, 0.8261, 0.8342, 0.8417, 0.8489, 0.8519],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8236])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8469], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8236])\n",
      ">>Entradas: tensor([0.8134, 0.8185, 0.8261, 0.8342, 0.8417, 0.8489, 0.8519, 0.8469],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8375], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.8185, 0.8261, 0.8342, 0.8417, 0.8489, 0.8519, 0.8469, 0.8375],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7919])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8265], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7919])\n",
      ">>Entradas: tensor([0.8261, 0.8342, 0.8417, 0.8489, 0.8519, 0.8469, 0.8375, 0.8265],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7865])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8154], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7865])\n",
      ">>Entradas: tensor([0.8342, 0.8417, 0.8489, 0.8519, 0.8469, 0.8375, 0.8265, 0.8154],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7870])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8063], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7870])\n",
      ">>Entradas: tensor([0.8417, 0.8489, 0.8519, 0.8469, 0.8375, 0.8265, 0.8154, 0.8063],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7874])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7986], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7874])\n",
      ">>Entradas: tensor([0.8489, 0.8519, 0.8469, 0.8375, 0.8265, 0.8154, 0.8063, 0.7986],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7879])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7916], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7879])\n",
      ">>Entradas: tensor([0.8519, 0.8469, 0.8375, 0.8265, 0.8154, 0.8063, 0.7986, 0.7916],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7955])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7875], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7955])\n",
      ">>Entradas: tensor([0.8469, 0.8375, 0.8265, 0.8154, 0.8063, 0.7986, 0.7916, 0.7875],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8102])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7883], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8102])\n",
      ">>Entradas: tensor([0.8375, 0.8265, 0.8154, 0.8063, 0.7986, 0.7916, 0.7875, 0.7883],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7668])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7761], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7668])\n",
      ">>Entradas: tensor([0.8265, 0.8154, 0.8063, 0.7986, 0.7916, 0.7875, 0.7883, 0.7761],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6655])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7370], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6655])\n",
      ">>Entradas: tensor([0.8154, 0.8063, 0.7986, 0.7916, 0.7875, 0.7883, 0.7761, 0.7370],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6361])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6514], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6361])\n",
      ">>Entradas: tensor([0.8063, 0.7986, 0.7916, 0.7875, 0.7883, 0.7761, 0.7370, 0.6514],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6785])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6478], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6785])\n",
      ">>Entradas: tensor([0.7986, 0.7916, 0.7875, 0.7883, 0.7761, 0.7370, 0.6514, 0.6478],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6468], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6966])\n",
      ">>Entradas: tensor([0.7916, 0.7875, 0.7883, 0.7761, 0.7370, 0.6514, 0.6478, 0.6468],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6903])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6417], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6903])\n",
      ">>Entradas: tensor([0.7875, 0.7883, 0.7761, 0.7370, 0.6514, 0.6478, 0.6468, 0.6417],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6970])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6477], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6970])\n",
      ">>Entradas: tensor([0.7883, 0.7761, 0.7370, 0.6514, 0.6478, 0.6468, 0.6417, 0.6477],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7167])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6788], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7167])\n",
      ">>Entradas: tensor([0.7761, 0.7370, 0.6514, 0.6478, 0.6468, 0.6417, 0.6477, 0.6788],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7491])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6828], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7491])\n",
      ">>Entradas: tensor([0.7370, 0.6514, 0.6478, 0.6468, 0.6417, 0.6477, 0.6788, 0.6828],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7940])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7064], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7940])\n",
      ">>Entradas: tensor([0.6514, 0.6478, 0.6468, 0.6417, 0.6477, 0.6788, 0.6828, 0.7064],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8547])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7520], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8547])\n",
      ">>Entradas: tensor([0.6478, 0.6468, 0.6417, 0.6477, 0.6788, 0.6828, 0.7064, 0.7520],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9314])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8150], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9314])\n",
      ">>Entradas: tensor([0.6468, 0.6417, 0.6477, 0.6788, 0.6828, 0.7064, 0.7520, 0.8150],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9627])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8761], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9627])\n",
      ">>Entradas: tensor([0.6417, 0.6477, 0.6788, 0.6828, 0.7064, 0.7520, 0.8150, 0.8761],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9486])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9241], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9486])\n",
      ">>Entradas: tensor([0.6477, 0.6788, 0.6828, 0.7064, 0.7520, 0.8150, 0.8761, 0.9241],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9307])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9560], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9307])\n",
      ">>Entradas: tensor([0.6788, 0.6828, 0.7064, 0.7520, 0.8150, 0.8761, 0.9241, 0.9560],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9090])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9408], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9090])\n",
      ">>Entradas: tensor([0.6828, 0.7064, 0.7520, 0.8150, 0.8761, 0.9241, 0.9560, 0.9408],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8816])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9507], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8816])\n",
      ">>Entradas: tensor([0.7064, 0.7520, 0.8150, 0.8761, 0.9241, 0.9560, 0.9408, 0.9507],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8487])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9476], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8487])\n",
      ">>Entradas: tensor([0.7520, 0.8150, 0.8761, 0.9241, 0.9560, 0.9408, 0.9507, 0.9476],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8753])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9487], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8753])\n",
      ">>Entradas: tensor([0.8150, 0.8761, 0.9241, 0.9560, 0.9408, 0.9507, 0.9476, 0.9487],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9612])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9727], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9612])\n",
      ">>Entradas: tensor([0.8761, 0.9241, 0.9560, 0.9408, 0.9507, 0.9476, 0.9487, 0.9727],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9925])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9931], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9925])\n",
      ">>Entradas: tensor([0.9241, 0.9560, 0.9408, 0.9507, 0.9476, 0.9487, 0.9727, 0.9931],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9690])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9944], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9690])\n",
      ">>Entradas: tensor([0.9560, 0.9408, 0.9507, 0.9476, 0.9487, 0.9727, 0.9931, 0.9944],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9715])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9940], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9715])\n",
      ">>Entradas: tensor([0.9408, 0.9507, 0.9476, 0.9487, 0.9727, 0.9931, 0.9944, 0.9940],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([1.])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9996], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([1.])\n",
      ">>Entradas: tensor([0.9507, 0.9476, 0.9487, 0.9727, 0.9931, 0.9944, 0.9940, 0.9996],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9969], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9801])\n",
      ">>Entradas: tensor([0.9476, 0.9487, 0.9727, 0.9931, 0.9944, 0.9940, 0.9996, 0.9969],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9762], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9117])\n",
      ">>Entradas: tensor([0.9487, 0.9727, 0.9931, 0.9944, 0.9940, 0.9996, 0.9969, 0.9762],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8911])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9557], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8911])\n",
      ">>Entradas: tensor([0.9727, 0.9931, 0.9944, 0.9940, 0.9996, 0.9969, 0.9762, 0.9557],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9181])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9453], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9181])\n",
      ">>Entradas: tensor([0.9931, 0.9944, 0.9940, 0.9996, 0.9969, 0.9762, 0.9557, 0.9453],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9450])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9417], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9450])\n",
      ">>Entradas: tensor([0.9944, 0.9940, 0.9996, 0.9969, 0.9762, 0.9557, 0.9453, 0.9417],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9718])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9467], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9718])\n",
      ">>Entradas: tensor([0.9940, 0.9996, 0.9969, 0.9762, 0.9557, 0.9453, 0.9417, 0.9467],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9829])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9544], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9829])\n",
      ">>Entradas: tensor([0.9996, 0.9969, 0.9762, 0.9557, 0.9453, 0.9417, 0.9467, 0.9544],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9783])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9576], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9783])\n",
      ">>s_original: [0.049424633383750916, 0.10789185762405396, 0.13719609379768372, 0.13733737170696259, 0.1338856965303421, 0.12684109807014465, 0.14756061136722565, 0.19604423642158508, 0.21688967943191528, 0.21009695529937744, 0.20267784595489502, 0.1946323662996292, 0.19407351315021515, 0.20100130140781403, 0.19663821160793304, 0.180984228849411, 0.16539041697978973, 0.14985674619674683, 0.15043111145496368, 0.1671135276556015, 0.20227035880088806, 0.25590160489082336, 0.29268819093704224, 0.31263017654418945, 0.31093889474868774, 0.2876143157482147, 0.28016164898872375, 0.28858086466789246, 0.28246283531188965, 0.26180753111839294, 0.2801212966442108, 0.3374040722846985, 0.3482298254966736, 0.3125985562801361, 0.34358710050582886, 0.44119545817375183, 0.521095335483551, 0.5832866430282593, 0.6089234352111816, 0.5980057120323181, 0.5945301651954651, 0.5984968543052673, 0.621354341506958, 0.6631026864051819, 0.6928724050521851, 0.7106636166572571, 0.721682071685791, 0.7259277701377869, 0.7404318451881409, 0.7651942372322083, 0.7447891235351562, 0.6792163252830505, 0.6746017932891846, 0.730945348739624, 0.7467210292816162, 0.7219287157058716, 0.7199286818504333, 0.7407209277153015, 0.7362455129623413, 0.7065023183822632, 0.6979451775550842, 0.7105739712715149, 0.7209621667861938, 0.7291097044944763, 0.7674259543418884, 0.8359109163284302, 0.8510103225708008, 0.8127241730690002, 0.7863940000534058, 0.7720199823379517, 0.8033170700073242, 0.8802852630615234, 0.8987051844596863, 0.8585767149925232, 0.8308762311935425, 0.8156037926673889, 0.8116992115974426, 0.8191625475883484, 0.8218275904655457, 0.8196942210197449, 0.817862868309021, 0.8163333535194397, 0.8005555868148804, 0.7705295085906982, 0.7426586747169495, 0.716943085193634, 0.7197051048278809, 0.7509447932243347, 0.7402781248092651, 0.6877052187919617, 0.6687695384025574, 0.683471143245697, 0.6877052187919617, 0.6814717054367065, 0.6892618536949158, 0.7110756039619446, 0.7349108457565308, 0.7607676982879639, 0.771117091178894, 0.7659589648246765, 0.7483323812484741, 0.7182371616363525, 0.708941638469696, 0.7204458117485046, 0.7706154584884644, 0.8594506978988647, 0.906541109085083, 0.9118866324424744, 0.9043355584144592, 0.8838878870010376, 0.9032153487205505, 0.9623178839683533, 0.9820588231086731, 0.96243816614151, 0.9302511811256409, 0.8854979276657104, 0.8597025871276855, 0.8528652191162109, 0.8585854768753052, 0.8768633008003235, 0.8806464076042175, 0.8699347376823425, 0.846513569355011, 0.8103827834129333, 0.8026111125946045, 0.8231984972953796, 0.8397204279899597, 0.8521769046783447, 0.8615626692771912, 0.8678776621818542, 0.8701963424682617, 0.868518590927124, 0.852988064289093, 0.8236046433448792, 0.8032509088516235, 0.7919268012046814, 0.7865023016929626, 0.7869773507118225, 0.7874362468719482, 0.7878790497779846, 0.7954531908035278, 0.8101586699485779, 0.7668473124504089, 0.665519118309021, 0.6360738277435303, 0.678511381149292, 0.6965967416763306, 0.6903298497200012, 0.6970472931861877, 0.7167490720748901, 0.7490506768226624, 0.7939522862434387, 0.8547447323799133, 0.931428074836731, 0.9627243876457214, 0.9486336708068848, 0.9307146072387695, 0.9089671969413757, 0.8816379904747009, 0.8487268090248108, 0.8752607107162476, 0.9612395763397217, 0.9925020933151245, 0.9690483212471008, 0.9715476036071777, 1.0, 0.9800636768341064, 0.9117385745048523, 0.8910858035087585, 0.9181053042411804, 0.9450165033340454, 0.9718193411827087, 0.982906699180603, 0.9782785773277283]\n",
      ">>s_pred: [0.038483619689941406, 0.05920600891113281, 0.08799362182617188, 0.11087989807128906, 0.1256852149963379, 0.1357593536376953, 0.15090084075927734, 0.17711496353149414, 0.20382165908813477, 0.22206544876098633, 0.23313665390014648, 0.23466825485229492, 0.23389816284179688, 0.2353682518005371, 0.23373746871948242, 0.22240734100341797, 0.21067142486572266, 0.1917881965637207, 0.17649507522583008, 0.1686997413635254, 0.17429876327514648, 0.1920604705810547, 0.21724176406860352, 0.24352312088012695, 0.26523923873901367, 0.2772822380065918, 0.2872920036315918, 0.29933929443359375, 0.3073287010192871, 0.30614566802978516, 0.31099653244018555, 0.3280677795410156, 0.3407626152038574, 0.3397660255432129, 0.3488273620605469, 0.38224315643310547, 0.44793272018432617, 0.5012321472167969, 0.5546326637268066, 0.5940065383911133, 0.6210575103759766, 0.6443343162536621, 0.6709914207458496, 0.701228141784668, 0.729607105255127, 0.7403326034545898, 0.756413459777832, 0.7658991813659668, 0.7733154296875, 0.7855143547058105, 0.7723112106323242, 0.7854037284851074, 0.7599539756774902, 0.7538900375366211, 0.7548766136169434, 0.7437057495117188, 0.7346997261047363, 0.7351608276367188, 0.7301421165466309, 0.7180905342102051, 0.7085156440734863, 0.7050471305847168, 0.704470157623291, 0.7077798843383789, 0.7230238914489746, 0.7550978660583496, 0.7835812568664551, 0.7958650588989258, 0.800590991973877, 0.8002724647521973, 0.8089818954467773, 0.8398427963256836, 0.8682613372802734, 0.8764114379882812, 0.8734226226806641, 0.854893684387207, 0.8462638854980469, 0.8431282043457031, 0.8411846160888672, 0.8378782272338867, 0.831881046295166, 0.823737621307373, 0.8123641014099121, 0.7958545684814453, 0.7762336730957031, 0.753018856048584, 0.7369365692138672, 0.7334709167480469, 0.7267422676086426, 0.7064523696899414, 0.6869287490844727, 0.6760978698730469, 0.6686406135559082, 0.6637005805969238, 0.6649370193481445, 0.6720700263977051, 0.6841855049133301, 0.7034244537353516, 0.7227535247802734, 0.7381038665771484, 0.746182918548584, 0.7447080612182617, 0.7414817810058594, 0.7425446510314941, 0.757235050201416, 0.7937483787536621, 0.833582878112793, 0.8641724586486816, 0.8855991363525391, 0.8956799507141113, 0.9094886779785156, 0.9391779899597168, 0.9671597480773926, 0.9811139106750488, 0.9115681648254395, 0.9129772186279297, 0.9008355140686035, 0.8844690322875977, 0.8805136680603027, 0.8794112205505371, 0.8703594207763672, 0.8608112335205078, 0.8489522933959961, 0.8310031890869141, 0.815730094909668, 0.8115968704223633, 0.8134255409240723, 0.8185310363769531, 0.8261499404907227, 0.8342056274414062, 0.8417191505432129, 0.8488645553588867, 0.851862907409668, 0.8468747138977051, 0.837522029876709, 0.8265419006347656, 0.8153681755065918, 0.8063201904296875, 0.7986302375793457, 0.7915968894958496, 0.7874650955200195, 0.7882747650146484, 0.7760744094848633, 0.7369732856750488, 0.6514496803283691, 0.6477775573730469, 0.6468005180358887, 0.6417489051818848, 0.6476926803588867, 0.6788120269775391, 0.6827855110168457, 0.7064437866210938, 0.7519712448120117, 0.8150286674499512, 0.8761405944824219, 0.9240541458129883, 0.9560446739196777, 0.9407792091369629, 0.9507055282592773, 0.9475545883178711, 0.9487409591674805, 0.9726920127868652, 0.993095874786377, 0.9943680763244629, 0.9939846992492676, 0.9995579719543457, 0.9969215393066406, 0.9762310981750488, 0.9557147026062012, 0.9452996253967285, 0.9417424201965332, 0.9467206001281738, 0.9543814659118652, 0.9576091766357422]\n",
      "<<Perdida: 0.00149190379306674 epoca: 2\n",
      "---Inicio de epoca: 3--\n",
      ">>Entradas: tensor([0.0503, 0.0086, 0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203])\n",
      ">>Salida: tensor([0.0494])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0115], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.0494])\n",
      ">>Entradas: tensor([0.0086, 0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203, 0.0115],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1079])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0400], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1079])\n",
      ">>Entradas: tensor([0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203, 0.0115, 0.0400],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1372])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0725], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1372])\n",
      ">>Entradas: tensor([0.0245, 0.0327, 0.0246, 0.0205, 0.0203, 0.0115, 0.0400, 0.0725],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1373])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1002], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1373])\n",
      ">>Entradas: tensor([0.0327, 0.0246, 0.0205, 0.0203, 0.0115, 0.0400, 0.0725, 0.1002],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1339])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1168], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1339])\n",
      ">>Entradas: tensor([0.0246, 0.0205, 0.0203, 0.0115, 0.0400, 0.0725, 0.1002, 0.1168],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1268])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1265], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1268])\n",
      ">>Entradas: tensor([0.0205, 0.0203, 0.0115, 0.0400, 0.0725, 0.1002, 0.1168, 0.1265],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1476])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1393], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1476])\n",
      ">>Entradas: tensor([0.0203, 0.0115, 0.0400, 0.0725, 0.1002, 0.1168, 0.1265, 0.1393],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1960])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1642], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1960])\n",
      ">>Entradas: tensor([0.0115, 0.0400, 0.0725, 0.1002, 0.1168, 0.1265, 0.1393, 0.1642],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1913], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2169])\n",
      ">>Entradas: tensor([0.0400, 0.0725, 0.1002, 0.1168, 0.1265, 0.1393, 0.1642, 0.1913],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2101])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2108], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2101])\n",
      ">>Entradas: tensor([0.0725, 0.1002, 0.1168, 0.1265, 0.1393, 0.1642, 0.1913, 0.2108],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2027])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2224], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2027])\n",
      ">>Entradas: tensor([0.1002, 0.1168, 0.1265, 0.1393, 0.1642, 0.1913, 0.2108, 0.2224],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1946])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2259], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1946])\n",
      ">>Entradas: tensor([0.1168, 0.1265, 0.1393, 0.1642, 0.1913, 0.2108, 0.2224, 0.2259],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1941])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2259], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1941])\n",
      ">>Entradas: tensor([0.1265, 0.1393, 0.1642, 0.1913, 0.2108, 0.2224, 0.2259, 0.2259],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2010])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2272], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2010])\n",
      ">>Entradas: tensor([0.1393, 0.1642, 0.1913, 0.2108, 0.2224, 0.2259, 0.2259, 0.2272],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2266], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1966])\n",
      ">>Entradas: tensor([0.1642, 0.1913, 0.2108, 0.2224, 0.2259, 0.2259, 0.2272, 0.2266],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1810])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2205], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1810])\n",
      ">>Entradas: tensor([0.1913, 0.2108, 0.2224, 0.2259, 0.2259, 0.2272, 0.2266, 0.2205],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1654])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2090], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1654])\n",
      ">>Entradas: tensor([0.2108, 0.2224, 0.2259, 0.2259, 0.2272, 0.2266, 0.2205, 0.2090],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1499])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1928], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1499])\n",
      ">>Entradas: tensor([0.2224, 0.2259, 0.2259, 0.2272, 0.2266, 0.2205, 0.2090, 0.1928],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1504])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1784], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1504])\n",
      ">>Entradas: tensor([0.2259, 0.2259, 0.2272, 0.2266, 0.2205, 0.2090, 0.1928, 0.1784],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1671])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1712], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1671])\n",
      ">>Entradas: tensor([0.2259, 0.2272, 0.2266, 0.2205, 0.2090, 0.1928, 0.1784, 0.1712],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2023])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1759], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2023])\n",
      ">>Entradas: tensor([0.2272, 0.2266, 0.2205, 0.2090, 0.1928, 0.1784, 0.1712, 0.1759],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2559])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1959], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2559])\n",
      ">>Entradas: tensor([0.2266, 0.2205, 0.2090, 0.1928, 0.1784, 0.1712, 0.1759, 0.1959],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2927])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2226], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2927])\n",
      ">>Entradas: tensor([0.2205, 0.2090, 0.1928, 0.1784, 0.1712, 0.1759, 0.1959, 0.2226],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2494], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2090, 0.1928, 0.1784, 0.1712, 0.1759, 0.1959, 0.2226, 0.2494],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3109])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2707], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3109])\n",
      ">>Entradas: tensor([0.1928, 0.1784, 0.1712, 0.1759, 0.1959, 0.2226, 0.2494, 0.2707],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2876])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2810], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2876])\n",
      ">>Entradas: tensor([0.1784, 0.1712, 0.1759, 0.1959, 0.2226, 0.2494, 0.2707, 0.2810],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2802])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2883], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2802])\n",
      ">>Entradas: tensor([0.1712, 0.1759, 0.1959, 0.2226, 0.2494, 0.2707, 0.2810, 0.2883],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2886])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2980], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2886])\n",
      ">>Entradas: tensor([0.1759, 0.1959, 0.2226, 0.2494, 0.2707, 0.2810, 0.2883, 0.2980],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2825])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3043], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2825])\n",
      ">>Entradas: tensor([0.1959, 0.2226, 0.2494, 0.2707, 0.2810, 0.2883, 0.2980, 0.3043],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2618])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3033], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2618])\n",
      ">>Entradas: tensor([0.2226, 0.2494, 0.2707, 0.2810, 0.2883, 0.2980, 0.3043, 0.3033],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3066], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2801])\n",
      ">>Entradas: tensor([0.2494, 0.2707, 0.2810, 0.2883, 0.2980, 0.3043, 0.3033, 0.3066],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3374])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3231], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3374])\n",
      ">>Entradas: tensor([0.2707, 0.2810, 0.2883, 0.2980, 0.3043, 0.3033, 0.3066, 0.3231],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3482])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3362], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3482])\n",
      ">>Entradas: tensor([0.2810, 0.2883, 0.2980, 0.3043, 0.3033, 0.3066, 0.3231, 0.3362],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3352], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2883, 0.2980, 0.3043, 0.3033, 0.3066, 0.3231, 0.3362, 0.3352],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3436])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3439], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3436])\n",
      ">>Entradas: tensor([0.2980, 0.3043, 0.3033, 0.3066, 0.3231, 0.3362, 0.3352, 0.3439],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.4412])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3779], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.4412])\n",
      ">>Entradas: tensor([0.3043, 0.3033, 0.3066, 0.3231, 0.3362, 0.3352, 0.3439, 0.3779],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5211])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4275], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5211])\n",
      ">>Entradas: tensor([0.3033, 0.3066, 0.3231, 0.3362, 0.3352, 0.3439, 0.3779, 0.4275],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5833])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4875], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5833])\n",
      ">>Entradas: tensor([0.3066, 0.3231, 0.3362, 0.3352, 0.3439, 0.3779, 0.4275, 0.4875],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5429], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6089])\n",
      ">>Entradas: tensor([0.3231, 0.3362, 0.3352, 0.3439, 0.3779, 0.4275, 0.4875, 0.5429],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5980])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5820], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5980])\n",
      ">>Entradas: tensor([0.3362, 0.3352, 0.3439, 0.3779, 0.4275, 0.4875, 0.5429, 0.5820],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5945])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6102], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5945])\n",
      ">>Entradas: tensor([0.3352, 0.3439, 0.3779, 0.4275, 0.4875, 0.5429, 0.5820, 0.6102],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5985])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6332], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5985])\n",
      ">>Entradas: tensor([0.3439, 0.3779, 0.4275, 0.4875, 0.5429, 0.5820, 0.6102, 0.6332],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6214])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6584], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6214])\n",
      ">>Entradas: tensor([0.3779, 0.4275, 0.4875, 0.5429, 0.5820, 0.6102, 0.6332, 0.6584],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6631])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6905], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6631])\n",
      ">>Entradas: tensor([0.4275, 0.4875, 0.5429, 0.5820, 0.6102, 0.6332, 0.6584, 0.6905],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6929])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7218], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6929])\n",
      ">>Entradas: tensor([0.4875, 0.5429, 0.5820, 0.6102, 0.6332, 0.6584, 0.6905, 0.7218],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7107])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7467], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7107])\n",
      ">>Entradas: tensor([0.5429, 0.5820, 0.6102, 0.6332, 0.6584, 0.6905, 0.7218, 0.7467],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7217])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7620], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7217])\n",
      ">>Entradas: tensor([0.5820, 0.6102, 0.6332, 0.6584, 0.6905, 0.7218, 0.7467, 0.7620],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7259])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7706], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7259])\n",
      ">>Entradas: tensor([0.6102, 0.6332, 0.6584, 0.6905, 0.7218, 0.7467, 0.7620, 0.7706],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7404])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7772], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7404])\n",
      ">>Entradas: tensor([0.6332, 0.6584, 0.6905, 0.7218, 0.7467, 0.7620, 0.7706, 0.7772],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7652])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7886], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7652])\n",
      ">>Entradas: tensor([0.6584, 0.6905, 0.7218, 0.7467, 0.7620, 0.7706, 0.7772, 0.7886],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7448])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7813], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7448])\n",
      ">>Entradas: tensor([0.6905, 0.7218, 0.7467, 0.7620, 0.7706, 0.7772, 0.7886, 0.7813],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6792])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7628], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6792])\n",
      ">>Entradas: tensor([0.7218, 0.7467, 0.7620, 0.7706, 0.7772, 0.7886, 0.7813, 0.7628],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6746])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7420], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6746])\n",
      ">>Entradas: tensor([0.7467, 0.7620, 0.7706, 0.7772, 0.7886, 0.7813, 0.7628, 0.7420],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7397], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7309])\n",
      ">>Entradas: tensor([0.7620, 0.7706, 0.7772, 0.7886, 0.7813, 0.7628, 0.7420, 0.7397],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7467])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7405], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7467])\n",
      ">>Entradas: tensor([0.7706, 0.7772, 0.7886, 0.7813, 0.7628, 0.7420, 0.7397, 0.7405],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7219])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7339], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7219])\n",
      ">>Entradas: tensor([0.7772, 0.7886, 0.7813, 0.7628, 0.7420, 0.7397, 0.7405, 0.7339],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7199])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7280], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7199])\n",
      ">>Entradas: tensor([0.7886, 0.7813, 0.7628, 0.7420, 0.7397, 0.7405, 0.7339, 0.7280],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7407])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7272], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7407])\n",
      ">>Entradas: tensor([0.7813, 0.7628, 0.7420, 0.7397, 0.7405, 0.7339, 0.7280, 0.7272],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7362])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7231], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7362])\n",
      ">>Entradas: tensor([0.7628, 0.7420, 0.7397, 0.7405, 0.7339, 0.7280, 0.7272, 0.7231],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7129], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7065])\n",
      ">>Entradas: tensor([0.7420, 0.7397, 0.7405, 0.7339, 0.7280, 0.7272, 0.7231, 0.7129],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6979])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7050], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6979])\n",
      ">>Entradas: tensor([0.7397, 0.7405, 0.7339, 0.7280, 0.7272, 0.7231, 0.7129, 0.7050],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7106])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7033], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7106])\n",
      ">>Entradas: tensor([0.7405, 0.7339, 0.7280, 0.7272, 0.7231, 0.7129, 0.7050, 0.7033],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7210])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7047], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7210])\n",
      ">>Entradas: tensor([0.7339, 0.7280, 0.7272, 0.7231, 0.7129, 0.7050, 0.7033, 0.7047],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7291])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7090], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7291])\n",
      ">>Entradas: tensor([0.7280, 0.7272, 0.7231, 0.7129, 0.7050, 0.7033, 0.7047, 0.7090],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7674])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7249], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7674])\n",
      ">>Entradas: tensor([0.7272, 0.7231, 0.7129, 0.7050, 0.7033, 0.7047, 0.7090, 0.7249],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8359])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7596], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8359])\n",
      ">>Entradas: tensor([0.7231, 0.7129, 0.7050, 0.7033, 0.7047, 0.7090, 0.7249, 0.7596],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8510])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7894], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8510])\n",
      ">>Entradas: tensor([0.7129, 0.7050, 0.7033, 0.7047, 0.7090, 0.7249, 0.7596, 0.7894],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8127])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8026], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8127])\n",
      ">>Entradas: tensor([0.7050, 0.7033, 0.7047, 0.7090, 0.7249, 0.7596, 0.7894, 0.8026],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7864])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8066], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7864])\n",
      ">>Entradas: tensor([0.7033, 0.7047, 0.7090, 0.7249, 0.7596, 0.7894, 0.8026, 0.8066],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7720])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8046], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7720])\n",
      ">>Entradas: tensor([0.7047, 0.7090, 0.7249, 0.7596, 0.7894, 0.8026, 0.8066, 0.8046],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8119], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.7090, 0.7249, 0.7596, 0.7894, 0.8026, 0.8066, 0.8046, 0.8119],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8803])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8418], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8803])\n",
      ">>Entradas: tensor([0.7249, 0.7596, 0.7894, 0.8026, 0.8066, 0.8046, 0.8119, 0.8418],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8987])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8711], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8987])\n",
      ">>Entradas: tensor([0.7596, 0.7894, 0.8026, 0.8066, 0.8046, 0.8119, 0.8418, 0.8711],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8806], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.7894, 0.8026, 0.8066, 0.8046, 0.8119, 0.8418, 0.8711, 0.8806],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8745], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8309])\n",
      ">>Entradas: tensor([0.8026, 0.8066, 0.8046, 0.8119, 0.8418, 0.8711, 0.8806, 0.8745],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8156])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7709], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8156])\n",
      ">>Entradas: tensor([0.8066, 0.8046, 0.8119, 0.8418, 0.8711, 0.8806, 0.8745, 0.7709],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7797], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8117])\n",
      ">>Entradas: tensor([0.8046, 0.8119, 0.8418, 0.8711, 0.8806, 0.8745, 0.7709, 0.7797],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8192])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7873], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8192])\n",
      ">>Entradas: tensor([0.8119, 0.8418, 0.8711, 0.8806, 0.8745, 0.7709, 0.7797, 0.7873],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8218])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7923], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8218])\n",
      ">>Entradas: tensor([0.8418, 0.8711, 0.8806, 0.8745, 0.7709, 0.7797, 0.7873, 0.7923],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8048], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8197])\n",
      ">>Entradas: tensor([0.8711, 0.8806, 0.8745, 0.7709, 0.7797, 0.7873, 0.7923, 0.8048],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8179])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8085], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8179])\n",
      ">>Entradas: tensor([0.8806, 0.8745, 0.7709, 0.7797, 0.7873, 0.7923, 0.8048, 0.8085],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8163])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8053], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8163])\n",
      ">>Entradas: tensor([0.8745, 0.7709, 0.7797, 0.7873, 0.7923, 0.8048, 0.8085, 0.8053],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8006])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7930], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8006])\n",
      ">>Entradas: tensor([0.7709, 0.7797, 0.7873, 0.7923, 0.8048, 0.8085, 0.8053, 0.7930],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7705])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7823], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7705])\n",
      ">>Entradas: tensor([0.7797, 0.7873, 0.7923, 0.8048, 0.8085, 0.8053, 0.7930, 0.7823],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7427])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7709], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7427])\n",
      ">>Entradas: tensor([0.7873, 0.7923, 0.8048, 0.8085, 0.8053, 0.7930, 0.7823, 0.7709],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7534], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7169])\n",
      ">>Entradas: tensor([0.7923, 0.8048, 0.8085, 0.8053, 0.7930, 0.7823, 0.7709, 0.7534],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7412], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7197])\n",
      ">>Entradas: tensor([0.8048, 0.8085, 0.8053, 0.7930, 0.7823, 0.7709, 0.7534, 0.7412],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7509])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7401], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7509])\n",
      ">>Entradas: tensor([0.8085, 0.8053, 0.7930, 0.7823, 0.7709, 0.7534, 0.7412, 0.7401],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7403])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7344], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7403])\n",
      ">>Entradas: tensor([0.8053, 0.7930, 0.7823, 0.7709, 0.7534, 0.7412, 0.7401, 0.7344],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7144], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.7930, 0.7823, 0.7709, 0.7534, 0.7412, 0.7401, 0.7344, 0.7144],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6688])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6943], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6688])\n",
      ">>Entradas: tensor([0.7823, 0.7709, 0.7534, 0.7412, 0.7401, 0.7344, 0.7144, 0.6943],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6835])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6828], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6835])\n",
      ">>Entradas: tensor([0.7709, 0.7534, 0.7412, 0.7401, 0.7344, 0.7144, 0.6943, 0.6828],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6746], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.7534, 0.7412, 0.7401, 0.7344, 0.7144, 0.6943, 0.6828, 0.6746],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6815])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6684], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6815])\n",
      ">>Entradas: tensor([0.7412, 0.7401, 0.7344, 0.7144, 0.6943, 0.6828, 0.6746, 0.6684],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6893])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6687], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6893])\n",
      ">>Entradas: tensor([0.7401, 0.7344, 0.7144, 0.6943, 0.6828, 0.6746, 0.6684, 0.6687],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7111])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6758], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7111])\n",
      ">>Entradas: tensor([0.7344, 0.7144, 0.6943, 0.6828, 0.6746, 0.6684, 0.6687, 0.6758],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7349])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6877], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7349])\n",
      ">>Entradas: tensor([0.7144, 0.6943, 0.6828, 0.6746, 0.6684, 0.6687, 0.6758, 0.6877],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7608])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7058], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7608])\n",
      ">>Entradas: tensor([0.6943, 0.6828, 0.6746, 0.6684, 0.6687, 0.6758, 0.6877, 0.7058],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7711])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7252], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7711])\n",
      ">>Entradas: tensor([0.6828, 0.6746, 0.6684, 0.6687, 0.6758, 0.6877, 0.7058, 0.7252],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7660])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7403], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7660])\n",
      ">>Entradas: tensor([0.6746, 0.6684, 0.6687, 0.6758, 0.6877, 0.7058, 0.7252, 0.7403],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7483])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7478], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7483])\n",
      ">>Entradas: tensor([0.6684, 0.6687, 0.6758, 0.6877, 0.7058, 0.7252, 0.7403, 0.7478],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7182])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7454], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7182])\n",
      ">>Entradas: tensor([0.6687, 0.6758, 0.6877, 0.7058, 0.7252, 0.7403, 0.7478, 0.7454],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7409], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7089])\n",
      ">>Entradas: tensor([0.6758, 0.6877, 0.7058, 0.7252, 0.7403, 0.7478, 0.7454, 0.7409],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7204])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7405], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7204])\n",
      ">>Entradas: tensor([0.6877, 0.7058, 0.7252, 0.7403, 0.7478, 0.7454, 0.7409, 0.7405],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7706])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7546], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7706])\n",
      ">>Entradas: tensor([0.7058, 0.7252, 0.7403, 0.7478, 0.7454, 0.7409, 0.7405, 0.7546],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8595])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7928], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8595])\n",
      ">>Entradas: tensor([0.7252, 0.7403, 0.7478, 0.7454, 0.7409, 0.7405, 0.7546, 0.7928],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8347], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9065])\n",
      ">>Entradas: tensor([0.7403, 0.7478, 0.7454, 0.7409, 0.7405, 0.7546, 0.7928, 0.8347],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9119])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8678], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9119])\n",
      ">>Entradas: tensor([0.7478, 0.7454, 0.7409, 0.7405, 0.7546, 0.7928, 0.8347, 0.8678],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9043])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8904], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9043])\n",
      ">>Entradas: tensor([0.7454, 0.7409, 0.7405, 0.7546, 0.7928, 0.8347, 0.8678, 0.8904],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8839])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9003], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8839])\n",
      ">>Entradas: tensor([0.7409, 0.7405, 0.7546, 0.7928, 0.8347, 0.8678, 0.8904, 0.9003],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9032])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9127], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9032])\n",
      ">>Entradas: tensor([0.7405, 0.7546, 0.7928, 0.8347, 0.8678, 0.8904, 0.9003, 0.9127],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9623])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9405], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9623])\n",
      ">>Entradas: tensor([0.7546, 0.7928, 0.8347, 0.8678, 0.8904, 0.9003, 0.9127, 0.9405],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9821])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9687], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9821])\n",
      ">>Entradas: tensor([0.7928, 0.8347, 0.8678, 0.8904, 0.9003, 0.9127, 0.9405, 0.9687],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9624])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9843], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9624])\n",
      ">>Entradas: tensor([0.8347, 0.8678, 0.8904, 0.9003, 0.9127, 0.9405, 0.9687, 0.9843],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9303])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9761], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9303])\n",
      ">>Entradas: tensor([0.8678, 0.8904, 0.9003, 0.9127, 0.9405, 0.9687, 0.9843, 0.9761],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8855])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9602], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8855])\n",
      ">>Entradas: tensor([0.8904, 0.9003, 0.9127, 0.9405, 0.9687, 0.9843, 0.9761, 0.9602],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8597])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9361], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8597])\n",
      ">>Entradas: tensor([0.9003, 0.9127, 0.9405, 0.9687, 0.9843, 0.9761, 0.9602, 0.9361],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8529])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9114], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8529])\n",
      ">>Entradas: tensor([0.9127, 0.9405, 0.9687, 0.9843, 0.9761, 0.9602, 0.9361, 0.9114],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8964], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.9405, 0.9687, 0.9843, 0.9761, 0.9602, 0.9361, 0.9114, 0.8964],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8769])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8898], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8769])\n",
      ">>Entradas: tensor([0.9687, 0.9843, 0.9761, 0.9602, 0.9361, 0.9114, 0.8964, 0.8898],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8806])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8837], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8806])\n",
      ">>Entradas: tensor([0.9843, 0.9761, 0.9602, 0.9361, 0.9114, 0.8964, 0.8898, 0.8837],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8699])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8735], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8699])\n",
      ">>Entradas: tensor([0.9761, 0.9602, 0.9361, 0.9114, 0.8964, 0.8898, 0.8837, 0.8735],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8465])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8578], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8465])\n",
      ">>Entradas: tensor([0.9602, 0.9361, 0.9114, 0.8964, 0.8898, 0.8837, 0.8735, 0.8578],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8104])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8346], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8104])\n",
      ">>Entradas: tensor([0.9361, 0.9114, 0.8964, 0.8898, 0.8837, 0.8735, 0.8578, 0.8346],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8026])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8152], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8026])\n",
      ">>Entradas: tensor([0.9114, 0.8964, 0.8898, 0.8837, 0.8735, 0.8578, 0.8346, 0.8152],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8232])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8082], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8232])\n",
      ">>Entradas: tensor([0.8964, 0.8898, 0.8837, 0.8735, 0.8578, 0.8346, 0.8152, 0.8082],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8397])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8099], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8397])\n",
      ">>Entradas: tensor([0.8898, 0.8837, 0.8735, 0.8578, 0.8346, 0.8152, 0.8082, 0.8099],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8522])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8161], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8522])\n",
      ">>Entradas: tensor([0.8837, 0.8735, 0.8578, 0.8346, 0.8152, 0.8082, 0.8099, 0.8161],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8616])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8247], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8616])\n",
      ">>Entradas: tensor([0.8735, 0.8578, 0.8346, 0.8152, 0.8082, 0.8099, 0.8161, 0.8247],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8679])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8336], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8679])\n",
      ">>Entradas: tensor([0.8578, 0.8346, 0.8152, 0.8082, 0.8099, 0.8161, 0.8247, 0.8336],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8702])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8412], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8702])\n",
      ">>Entradas: tensor([0.8346, 0.8152, 0.8082, 0.8099, 0.8161, 0.8247, 0.8336, 0.8412],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8685])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8478], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8685])\n",
      ">>Entradas: tensor([0.8152, 0.8082, 0.8099, 0.8161, 0.8247, 0.8336, 0.8412, 0.8478],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8530])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8504], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8530])\n",
      ">>Entradas: tensor([0.8082, 0.8099, 0.8161, 0.8247, 0.8336, 0.8412, 0.8478, 0.8504],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8236])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8452], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8236])\n",
      ">>Entradas: tensor([0.8099, 0.8161, 0.8247, 0.8336, 0.8412, 0.8478, 0.8504, 0.8452],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8356], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.8161, 0.8247, 0.8336, 0.8412, 0.8478, 0.8504, 0.8452, 0.8356],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7919])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8239], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7919])\n",
      ">>Entradas: tensor([0.8247, 0.8336, 0.8412, 0.8478, 0.8504, 0.8452, 0.8356, 0.8239],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7865])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8131], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7865])\n",
      ">>Entradas: tensor([0.8336, 0.8412, 0.8478, 0.8504, 0.8452, 0.8356, 0.8239, 0.8131],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7870])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8043], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7870])\n",
      ">>Entradas: tensor([0.8412, 0.8478, 0.8504, 0.8452, 0.8356, 0.8239, 0.8131, 0.8043],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7874])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7970], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7874])\n",
      ">>Entradas: tensor([0.8478, 0.8504, 0.8452, 0.8356, 0.8239, 0.8131, 0.8043, 0.7970],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7879])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7911], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7879])\n",
      ">>Entradas: tensor([0.8504, 0.8452, 0.8356, 0.8239, 0.8131, 0.8043, 0.7970, 0.7911],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7955])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7880], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7955])\n",
      ">>Entradas: tensor([0.8452, 0.8356, 0.8239, 0.8131, 0.8043, 0.7970, 0.7911, 0.7880],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8102])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7897], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8102])\n",
      ">>Entradas: tensor([0.8356, 0.8239, 0.8131, 0.8043, 0.7970, 0.7911, 0.7880, 0.7897],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7668])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7784], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7668])\n",
      ">>Entradas: tensor([0.8239, 0.8131, 0.8043, 0.7970, 0.7911, 0.7880, 0.7897, 0.7784],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6655])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7406], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6655])\n",
      ">>Entradas: tensor([0.8131, 0.8043, 0.7970, 0.7911, 0.7880, 0.7897, 0.7784, 0.7406],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6361])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6763], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6361])\n",
      ">>Entradas: tensor([0.8043, 0.7970, 0.7911, 0.7880, 0.7897, 0.7784, 0.7406, 0.6763],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6785])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6661], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6785])\n",
      ">>Entradas: tensor([0.7970, 0.7911, 0.7880, 0.7897, 0.7784, 0.7406, 0.6763, 0.6661],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6616], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6966])\n",
      ">>Entradas: tensor([0.7911, 0.7880, 0.7897, 0.7784, 0.7406, 0.6763, 0.6661, 0.6616],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6903])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6572], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6903])\n",
      ">>Entradas: tensor([0.7880, 0.7897, 0.7784, 0.7406, 0.6763, 0.6661, 0.6616, 0.6572],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6970])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6614], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6970])\n",
      ">>Entradas: tensor([0.7897, 0.7784, 0.7406, 0.6763, 0.6661, 0.6616, 0.6572, 0.6614],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7167])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6690], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7167])\n",
      ">>Entradas: tensor([0.7784, 0.7406, 0.6763, 0.6661, 0.6616, 0.6572, 0.6614, 0.6690],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7491])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.3200], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7491])\n",
      "ERROR: la modificacion de los pesos di√≥ un error mayor: 0.32596373558044434, se regresa al estado anterior de la red\n",
      ">>Entradas: tensor([0.7406, 0.6763, 0.6661, 0.6616, 0.6572, 0.6614, 0.6690, 0.6520],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7940])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6843], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7940])\n",
      ">>Entradas: tensor([0.6763, 0.6661, 0.6616, 0.6572, 0.6614, 0.6690, 0.6520, 0.6843],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8547])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7332], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8547])\n",
      ">>Entradas: tensor([0.6661, 0.6616, 0.6572, 0.6614, 0.6690, 0.6520, 0.6843, 0.7332],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9314])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7983], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9314])\n",
      ">>Entradas: tensor([0.6616, 0.6572, 0.6614, 0.6690, 0.6520, 0.6843, 0.7332, 0.7983],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9627])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8620], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9627])\n",
      ">>Entradas: tensor([0.6572, 0.6614, 0.6690, 0.6520, 0.6843, 0.7332, 0.7983, 0.8620],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9486])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9084], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9486])\n",
      ">>Entradas: tensor([0.6614, 0.6690, 0.6520, 0.6843, 0.7332, 0.7983, 0.8620, 0.9084],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9307])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9385], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9307])\n",
      ">>Entradas: tensor([0.6690, 0.6520, 0.6843, 0.7332, 0.7983, 0.8620, 0.9084, 0.9385],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9090])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9503], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9090])\n",
      ">>Entradas: tensor([0.6520, 0.6843, 0.7332, 0.7983, 0.8620, 0.9084, 0.9385, 0.9503],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8816])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9546], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8816])\n",
      ">>Entradas: tensor([0.6843, 0.7332, 0.7983, 0.8620, 0.9084, 0.9385, 0.9503, 0.9546],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8487])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9486], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8487])\n",
      ">>Entradas: tensor([0.7332, 0.7983, 0.8620, 0.9084, 0.9385, 0.9503, 0.9546, 0.9486],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8753])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9490], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8753])\n",
      ">>Entradas: tensor([0.7983, 0.8620, 0.9084, 0.9385, 0.9503, 0.9546, 0.9486, 0.9490],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9612])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9704], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9612])\n",
      ">>Entradas: tensor([0.8620, 0.9084, 0.9385, 0.9503, 0.9546, 0.9486, 0.9490, 0.9704],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9925])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9901], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9925])\n",
      ">>Entradas: tensor([0.9084, 0.9385, 0.9503, 0.9546, 0.9486, 0.9490, 0.9704, 0.9901],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9690])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9940], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9690])\n",
      ">>Entradas: tensor([0.9385, 0.9503, 0.9546, 0.9486, 0.9490, 0.9704, 0.9901, 0.9940],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9715])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9950], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9715])\n",
      ">>Entradas: tensor([0.9503, 0.9546, 0.9486, 0.9490, 0.9704, 0.9901, 0.9940, 0.9950],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([1.])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0010], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([1.])\n",
      ">>Entradas: tensor([0.9546, 0.9486, 0.9490, 0.9704, 0.9901, 0.9940, 0.9950, 1.0010],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9970], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9801])\n",
      ">>Entradas: tensor([0.9486, 0.9490, 0.9704, 0.9901, 0.9940, 0.9950, 1.0010, 0.9970],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9737], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9117])\n",
      ">>Entradas: tensor([0.9490, 0.9704, 0.9901, 0.9940, 0.9950, 1.0010, 0.9970, 0.9737],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8911])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9463], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8911])\n",
      ">>Entradas: tensor([0.9704, 0.9901, 0.9940, 0.9950, 1.0010, 0.9970, 0.9737, 0.9463],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9181])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9380], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9181])\n",
      ">>Entradas: tensor([0.9901, 0.9940, 0.9950, 1.0010, 0.9970, 0.9737, 0.9463, 0.9380],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9450])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9362], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9450])\n",
      ">>Entradas: tensor([0.9940, 0.9950, 1.0010, 0.9970, 0.9737, 0.9463, 0.9380, 0.9362],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9718])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9814], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9718])\n",
      ">>Entradas: tensor([0.9950, 1.0010, 0.9970, 0.9737, 0.9463, 0.9380, 0.9362, 0.9814],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9829])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9817], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9829])\n",
      ">>Entradas: tensor([1.0010, 0.9970, 0.9737, 0.9463, 0.9380, 0.9362, 0.9814, 0.9817],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9783])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9805], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9783])\n",
      ">>s_original: [0.049424633383750916, 0.10789185762405396, 0.13719609379768372, 0.13733737170696259, 0.1338856965303421, 0.12684109807014465, 0.14756061136722565, 0.19604423642158508, 0.21688967943191528, 0.21009695529937744, 0.20267784595489502, 0.1946323662996292, 0.19407351315021515, 0.20100130140781403, 0.19663821160793304, 0.180984228849411, 0.16539041697978973, 0.14985674619674683, 0.15043111145496368, 0.1671135276556015, 0.20227035880088806, 0.25590160489082336, 0.29268819093704224, 0.31263017654418945, 0.31093889474868774, 0.2876143157482147, 0.28016164898872375, 0.28858086466789246, 0.28246283531188965, 0.26180753111839294, 0.2801212966442108, 0.3374040722846985, 0.3482298254966736, 0.3125985562801361, 0.34358710050582886, 0.44119545817375183, 0.521095335483551, 0.5832866430282593, 0.6089234352111816, 0.5980057120323181, 0.5945301651954651, 0.5984968543052673, 0.621354341506958, 0.6631026864051819, 0.6928724050521851, 0.7106636166572571, 0.721682071685791, 0.7259277701377869, 0.7404318451881409, 0.7651942372322083, 0.7447891235351562, 0.6792163252830505, 0.6746017932891846, 0.730945348739624, 0.7467210292816162, 0.7219287157058716, 0.7199286818504333, 0.7407209277153015, 0.7362455129623413, 0.7065023183822632, 0.6979451775550842, 0.7105739712715149, 0.7209621667861938, 0.7291097044944763, 0.7674259543418884, 0.8359109163284302, 0.8510103225708008, 0.8127241730690002, 0.7863940000534058, 0.7720199823379517, 0.8033170700073242, 0.8802852630615234, 0.8987051844596863, 0.8585767149925232, 0.8308762311935425, 0.8156037926673889, 0.8116992115974426, 0.8191625475883484, 0.8218275904655457, 0.8196942210197449, 0.817862868309021, 0.8163333535194397, 0.8005555868148804, 0.7705295085906982, 0.7426586747169495, 0.716943085193634, 0.7197051048278809, 0.7509447932243347, 0.7402781248092651, 0.6877052187919617, 0.6687695384025574, 0.683471143245697, 0.6877052187919617, 0.6814717054367065, 0.6892618536949158, 0.7110756039619446, 0.7349108457565308, 0.7607676982879639, 0.771117091178894, 0.7659589648246765, 0.7483323812484741, 0.7182371616363525, 0.708941638469696, 0.7204458117485046, 0.7706154584884644, 0.8594506978988647, 0.906541109085083, 0.9118866324424744, 0.9043355584144592, 0.8838878870010376, 0.9032153487205505, 0.9623178839683533, 0.9820588231086731, 0.96243816614151, 0.9302511811256409, 0.8854979276657104, 0.8597025871276855, 0.8528652191162109, 0.8585854768753052, 0.8768633008003235, 0.8806464076042175, 0.8699347376823425, 0.846513569355011, 0.8103827834129333, 0.8026111125946045, 0.8231984972953796, 0.8397204279899597, 0.8521769046783447, 0.8615626692771912, 0.8678776621818542, 0.8701963424682617, 0.868518590927124, 0.852988064289093, 0.8236046433448792, 0.8032509088516235, 0.7919268012046814, 0.7865023016929626, 0.7869773507118225, 0.7874362468719482, 0.7878790497779846, 0.7954531908035278, 0.8101586699485779, 0.7668473124504089, 0.665519118309021, 0.6360738277435303, 0.678511381149292, 0.6965967416763306, 0.6903298497200012, 0.6970472931861877, 0.7167490720748901, 0.7490506768226624, 0.7939522862434387, 0.8547447323799133, 0.931428074836731, 0.9627243876457214, 0.9486336708068848, 0.9307146072387695, 0.9089671969413757, 0.8816379904747009, 0.8487268090248108, 0.8752607107162476, 0.9612395763397217, 0.9925020933151245, 0.9690483212471008, 0.9715476036071777, 1.0, 0.9800636768341064, 0.9117385745048523, 0.8910858035087585, 0.9181053042411804, 0.9450165033340454, 0.9718193411827087, 0.982906699180603, 0.9782785773277283]\n",
      ">>s_pred: [0.011524200439453125, 0.039989471435546875, 0.07245349884033203, 0.10018682479858398, 0.11681604385375977, 0.12647008895874023, 0.13928556442260742, 0.16423845291137695, 0.1912827491760254, 0.210845947265625, 0.22239446640014648, 0.22589349746704102, 0.22588062286376953, 0.22723054885864258, 0.22664833068847656, 0.22046947479248047, 0.20897197723388672, 0.1928114891052246, 0.17840814590454102, 0.17122507095336914, 0.17593812942504883, 0.19593524932861328, 0.2225661277770996, 0.24940919876098633, 0.27072668075561523, 0.2810072898864746, 0.2883262634277344, 0.2979912757873535, 0.30434274673461914, 0.30325984954833984, 0.30661582946777344, 0.3231015205383301, 0.33616065979003906, 0.3352241516113281, 0.3438749313354492, 0.3779129981994629, 0.42746400833129883, 0.48747968673706055, 0.5428948402404785, 0.5819969177246094, 0.6102495193481445, 0.633211612701416, 0.658414363861084, 0.6904659271240234, 0.7217617034912109, 0.7467279434204102, 0.7620029449462891, 0.7705554962158203, 0.7772231101989746, 0.7886371612548828, 0.781308650970459, 0.7627816200256348, 0.7419819831848145, 0.7397475242614746, 0.7405261993408203, 0.733851432800293, 0.7279906272888184, 0.7271695137023926, 0.7230935096740723, 0.7128810882568359, 0.7049798965454102, 0.7032637596130371, 0.7046799659729004, 0.7090411186218262, 0.7249484062194824, 0.7595610618591309, 0.7894258499145508, 0.8025641441345215, 0.8065700531005859, 0.8046059608459473, 0.8118600845336914, 0.8418416976928711, 0.8710904121398926, 0.8806490898132324, 0.8744807243347168, 0.7708635330200195, 0.7796902656555176, 0.7872982025146484, 0.7923445701599121, 0.8048014640808105, 0.8085145950317383, 0.8053245544433594, 0.7929525375366211, 0.7823390960693359, 0.770869255065918, 0.7533845901489258, 0.7412352561950684, 0.7400808334350586, 0.7344398498535156, 0.7144198417663574, 0.6943020820617676, 0.6828041076660156, 0.6745853424072266, 0.6683974266052246, 0.6686849594116211, 0.6758103370666504, 0.6876640319824219, 0.7057862281799316, 0.7251720428466797, 0.740264892578125, 0.7477827072143555, 0.745389461517334, 0.7408952713012695, 0.7404942512512207, 0.7545919418334961, 0.7928104400634766, 0.8347005844116211, 0.8677849769592285, 0.8904356956481934, 0.9002528190612793, 0.912663459777832, 0.9404854774475098, 0.9687232971191406, 0.9842643737792969, 0.9760599136352539, 0.9601554870605469, 0.9360852241516113, 0.9113926887512207, 0.896367073059082, 0.8898138999938965, 0.8836870193481445, 0.8735427856445312, 0.8578190803527832, 0.834648609161377, 0.8151874542236328, 0.8082280158996582, 0.8098526000976562, 0.8160815238952637, 0.8247232437133789, 0.8335866928100586, 0.8411679267883301, 0.8477582931518555, 0.8503503799438477, 0.8451685905456543, 0.8355803489685059, 0.8239245414733887, 0.8131346702575684, 0.8042621612548828, 0.7970438003540039, 0.7910566329956055, 0.7879929542541504, 0.7897434234619141, 0.7783975601196289, 0.7406134605407715, 0.6762938499450684, 0.6660542488098145, 0.66162109375, 0.6572294235229492, 0.661353588104248, 0.6690168380737305, 0.6519937515258789, 0.6842970848083496, 0.7332453727722168, 0.7983455657958984, 0.8619837760925293, 0.9084177017211914, 0.9384884834289551, 0.9503107070922852, 0.9546360969543457, 0.9485635757446289, 0.9490418434143066, 0.9703812599182129, 0.9900870323181152, 0.9940028190612793, 0.9950342178344727, 1.0010185241699219, 0.9969696998596191, 0.9736781120300293, 0.9463472366333008, 0.9380135536193848, 0.9361896514892578, 0.9814028739929199, 0.9817066192626953, 0.9805374145507812]\n",
      "<<Perdida: 0.0016555443871766329 epoca: 3\n",
      "---Inicio de epoca: 4--\n",
      ">>Entradas: tensor([0.0503, 0.0086, 0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203])\n",
      ">>Salida: tensor([0.0494])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0467], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.0494])\n",
      ">>Entradas: tensor([0.0086, 0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203, 0.0467],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1079])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0652], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1079])\n",
      ">>Entradas: tensor([0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203, 0.0467, 0.0652],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1372])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0922], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1372])\n",
      ">>Entradas: tensor([0.0245, 0.0327, 0.0246, 0.0205, 0.0203, 0.0467, 0.0652, 0.0922],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1373])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1135], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1373])\n",
      ">>Entradas: tensor([0.0327, 0.0246, 0.0205, 0.0203, 0.0467, 0.0652, 0.0922, 0.1135],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1339])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1256], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1339])\n",
      ">>Entradas: tensor([0.0246, 0.0205, 0.0203, 0.0467, 0.0652, 0.0922, 0.1135, 0.1256],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1268])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1336], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1268])\n",
      ">>Entradas: tensor([0.0205, 0.0203, 0.0467, 0.0652, 0.0922, 0.1135, 0.1256, 0.1336],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1476])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1467], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1476])\n",
      ">>Entradas: tensor([0.0203, 0.0467, 0.0652, 0.0922, 0.1135, 0.1256, 0.1336, 0.1467],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1960])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1716], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1960])\n",
      ">>Entradas: tensor([0.0467, 0.0652, 0.0922, 0.1135, 0.1256, 0.1336, 0.1467, 0.1716],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1964], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2169])\n",
      ">>Entradas: tensor([0.0652, 0.0922, 0.1135, 0.1256, 0.1336, 0.1467, 0.1716, 0.1964],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2101])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2131], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2101])\n",
      ">>Entradas: tensor([0.0922, 0.1135, 0.1256, 0.1336, 0.1467, 0.1716, 0.1964, 0.2131],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2027])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2232], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2027])\n",
      ">>Entradas: tensor([0.1135, 0.1256, 0.1336, 0.1467, 0.1716, 0.1964, 0.2131, 0.2232],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1946])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2259], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1946])\n",
      ">>Entradas: tensor([0.1256, 0.1336, 0.1467, 0.1716, 0.1964, 0.2131, 0.2232, 0.2259],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1941])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2255], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1941])\n",
      ">>Entradas: tensor([0.1336, 0.1467, 0.1716, 0.1964, 0.2131, 0.2232, 0.2259, 0.2255],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2010])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2267], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2010])\n",
      ">>Entradas: tensor([0.1467, 0.1716, 0.1964, 0.2131, 0.2232, 0.2259, 0.2255, 0.2267],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2258], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1966])\n",
      ">>Entradas: tensor([0.1716, 0.1964, 0.2131, 0.2232, 0.2259, 0.2255, 0.2267, 0.2258],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1810])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2189], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1810])\n",
      ">>Entradas: tensor([0.1964, 0.2131, 0.2232, 0.2259, 0.2255, 0.2267, 0.2258, 0.2189],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1654])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2071], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1654])\n",
      ">>Entradas: tensor([0.2131, 0.2232, 0.2259, 0.2255, 0.2267, 0.2258, 0.2189, 0.2071],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1499])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1909], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1499])\n",
      ">>Entradas: tensor([0.2232, 0.2259, 0.2255, 0.2267, 0.2258, 0.2189, 0.2071, 0.1909],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1504])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1767], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1504])\n",
      ">>Entradas: tensor([0.2259, 0.2255, 0.2267, 0.2258, 0.2189, 0.2071, 0.1909, 0.1767],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1671])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1695], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1671])\n",
      ">>Entradas: tensor([0.2255, 0.2267, 0.2258, 0.2189, 0.2071, 0.1909, 0.1767, 0.1695],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2023])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1745], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2023])\n",
      ">>Entradas: tensor([0.2267, 0.2258, 0.2189, 0.2071, 0.1909, 0.1767, 0.1695, 0.1745],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2559])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1944], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2559])\n",
      ">>Entradas: tensor([0.2258, 0.2189, 0.2071, 0.1909, 0.1767, 0.1695, 0.1745, 0.1944],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2927])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2211], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2927])\n",
      ">>Entradas: tensor([0.2189, 0.2071, 0.1909, 0.1767, 0.1695, 0.1745, 0.1944, 0.2211],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2484], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2071, 0.1909, 0.1767, 0.1695, 0.1745, 0.1944, 0.2211, 0.2484],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3109])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2702], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3109])\n",
      ">>Entradas: tensor([0.1909, 0.1767, 0.1695, 0.1745, 0.1944, 0.2211, 0.2484, 0.2702],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2876])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2813], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2876])\n",
      ">>Entradas: tensor([0.1767, 0.1695, 0.1745, 0.1944, 0.2211, 0.2484, 0.2702, 0.2813],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2802])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2894], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2802])\n",
      ">>Entradas: tensor([0.1695, 0.1745, 0.1944, 0.2211, 0.2484, 0.2702, 0.2813, 0.2894],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2886])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2995], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2886])\n",
      ">>Entradas: tensor([0.1745, 0.1944, 0.2211, 0.2484, 0.2702, 0.2813, 0.2894, 0.2995],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2825])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3059], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2825])\n",
      ">>Entradas: tensor([0.1944, 0.2211, 0.2484, 0.2702, 0.2813, 0.2894, 0.2995, 0.3059],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2618])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3031], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2618])\n",
      ">>Entradas: tensor([0.2211, 0.2484, 0.2702, 0.2813, 0.2894, 0.2995, 0.3059, 0.3031],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3069], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2801])\n",
      ">>Entradas: tensor([0.2484, 0.2702, 0.2813, 0.2894, 0.2995, 0.3059, 0.3031, 0.3069],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3374])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3237], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3374])\n",
      ">>Entradas: tensor([0.2702, 0.2813, 0.2894, 0.2995, 0.3059, 0.3031, 0.3069, 0.3237],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3482])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3366], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3482])\n",
      ">>Entradas: tensor([0.2813, 0.2894, 0.2995, 0.3059, 0.3031, 0.3069, 0.3237, 0.3366],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3356], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2894, 0.2995, 0.3059, 0.3031, 0.3069, 0.3237, 0.3366, 0.3356],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3436])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3445], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3436])\n",
      ">>Entradas: tensor([0.2995, 0.3059, 0.3031, 0.3069, 0.3237, 0.3366, 0.3356, 0.3445],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.4412])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3787], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.4412])\n",
      ">>Entradas: tensor([0.3059, 0.3031, 0.3069, 0.3237, 0.3366, 0.3356, 0.3445, 0.3787],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5211])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4278], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5211])\n",
      ">>Entradas: tensor([0.3031, 0.3069, 0.3237, 0.3366, 0.3356, 0.3445, 0.3787, 0.4278],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5833])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4906], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5833])\n",
      ">>Entradas: tensor([0.3069, 0.3237, 0.3366, 0.3356, 0.3445, 0.3787, 0.4278, 0.4906],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5470], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6089])\n",
      ">>Entradas: tensor([0.3237, 0.3366, 0.3356, 0.3445, 0.3787, 0.4278, 0.4906, 0.5470],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5980])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5878], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5980])\n",
      ">>Entradas: tensor([0.3366, 0.3356, 0.3445, 0.3787, 0.4278, 0.4906, 0.5470, 0.5878],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5945])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6172], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5945])\n",
      ">>Entradas: tensor([0.3356, 0.3445, 0.3787, 0.4278, 0.4906, 0.5470, 0.5878, 0.6172],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5985])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6363], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5985])\n",
      ">>Entradas: tensor([0.3445, 0.3787, 0.4278, 0.4906, 0.5470, 0.5878, 0.6172, 0.6363],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6214])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6608], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6214])\n",
      ">>Entradas: tensor([0.3787, 0.4278, 0.4906, 0.5470, 0.5878, 0.6172, 0.6363, 0.6608],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6631])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6923], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6631])\n",
      ">>Entradas: tensor([0.4278, 0.4906, 0.5470, 0.5878, 0.6172, 0.6363, 0.6608, 0.6923],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6929])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7232], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6929])\n",
      ">>Entradas: tensor([0.4906, 0.5470, 0.5878, 0.6172, 0.6363, 0.6608, 0.6923, 0.7232],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7107])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7480], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7107])\n",
      ">>Entradas: tensor([0.5470, 0.5878, 0.6172, 0.6363, 0.6608, 0.6923, 0.7232, 0.7480],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7217])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7651], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7217])\n",
      ">>Entradas: tensor([0.5878, 0.6172, 0.6363, 0.6608, 0.6923, 0.7232, 0.7480, 0.7651],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7259])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5085], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7259])\n",
      "ERROR: la modificacion de los pesos di√≥ un error mayor: 0.04727458581328392, se regresa al estado anterior de la red\n",
      ">>Entradas: tensor([0.6172, 0.6363, 0.6608, 0.6923, 0.7232, 0.7480, 0.7651, 0.7942],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7404])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7958], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7404])\n",
      ">>Entradas: tensor([0.6363, 0.6608, 0.6923, 0.7232, 0.7480, 0.7651, 0.7942, 0.7958],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7652])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8014], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7652])\n",
      ">>Entradas: tensor([0.6608, 0.6923, 0.7232, 0.7480, 0.7651, 0.7942, 0.7958, 0.8014],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7448])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8003], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7448])\n",
      ">>Entradas: tensor([0.6923, 0.7232, 0.7480, 0.7651, 0.7942, 0.7958, 0.8014, 0.8003],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6792])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7751], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6792])\n",
      ">>Entradas: tensor([0.7232, 0.7480, 0.7651, 0.7942, 0.7958, 0.8014, 0.8003, 0.7751],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6746])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7525], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6746])\n",
      ">>Entradas: tensor([0.7480, 0.7651, 0.7942, 0.7958, 0.8014, 0.8003, 0.7751, 0.7525],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7489], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7309])\n",
      ">>Entradas: tensor([0.7651, 0.7942, 0.7958, 0.8014, 0.8003, 0.7751, 0.7525, 0.7489],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7467])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7479], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7467])\n",
      ">>Entradas: tensor([0.7942, 0.7958, 0.8014, 0.8003, 0.7751, 0.7525, 0.7489, 0.7479],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7219])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7378], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7219])\n",
      ">>Entradas: tensor([0.7958, 0.8014, 0.8003, 0.7751, 0.7525, 0.7489, 0.7479, 0.7378],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7199])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7296], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7199])\n",
      ">>Entradas: tensor([0.8014, 0.8003, 0.7751, 0.7525, 0.7489, 0.7479, 0.7378, 0.7296],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7407])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7279], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7407])\n",
      ">>Entradas: tensor([0.8003, 0.7751, 0.7525, 0.7489, 0.7479, 0.7378, 0.7296, 0.7279],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7362])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7223], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7362])\n",
      ">>Entradas: tensor([0.7751, 0.7525, 0.7489, 0.7479, 0.7378, 0.7296, 0.7279, 0.7223],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7104], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7065])\n",
      ">>Entradas: tensor([0.7525, 0.7489, 0.7479, 0.7378, 0.7296, 0.7279, 0.7223, 0.7104],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6979])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7022], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6979])\n",
      ">>Entradas: tensor([0.7489, 0.7479, 0.7378, 0.7296, 0.7279, 0.7223, 0.7104, 0.7022],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7106])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7005], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7106])\n",
      ">>Entradas: tensor([0.7479, 0.7378, 0.7296, 0.7279, 0.7223, 0.7104, 0.7022, 0.7005],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7210])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7014], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7210])\n",
      ">>Entradas: tensor([0.7378, 0.7296, 0.7279, 0.7223, 0.7104, 0.7022, 0.7005, 0.7014],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7291])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7057], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7291])\n",
      ">>Entradas: tensor([0.7296, 0.7279, 0.7223, 0.7104, 0.7022, 0.7005, 0.7014, 0.7057],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7674])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7222], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7674])\n",
      ">>Entradas: tensor([0.7279, 0.7223, 0.7104, 0.7022, 0.7005, 0.7014, 0.7057, 0.7222],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8359])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7561], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8359])\n",
      ">>Entradas: tensor([0.7223, 0.7104, 0.7022, 0.7005, 0.7014, 0.7057, 0.7222, 0.7561],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8510])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7866], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8510])\n",
      ">>Entradas: tensor([0.7104, 0.7022, 0.7005, 0.7014, 0.7057, 0.7222, 0.7561, 0.7866],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8127])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8004], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8127])\n",
      ">>Entradas: tensor([0.7022, 0.7005, 0.7014, 0.7057, 0.7222, 0.7561, 0.7866, 0.8004],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7864])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8054], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7864])\n",
      ">>Entradas: tensor([0.7005, 0.7014, 0.7057, 0.7222, 0.7561, 0.7866, 0.8004, 0.8054],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7720])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8044], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7720])\n",
      ">>Entradas: tensor([0.7014, 0.7057, 0.7222, 0.7561, 0.7866, 0.8004, 0.8054, 0.8044],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8118], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.7057, 0.7222, 0.7561, 0.7866, 0.8004, 0.8054, 0.8044, 0.8118],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8803])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8415], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8803])\n",
      ">>Entradas: tensor([0.7222, 0.7561, 0.7866, 0.8004, 0.8054, 0.8044, 0.8118, 0.8415],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8987])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8708], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8987])\n",
      ">>Entradas: tensor([0.7561, 0.7866, 0.8004, 0.8054, 0.8044, 0.8118, 0.8415, 0.8708],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8807], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.7866, 0.8004, 0.8054, 0.8044, 0.8118, 0.8415, 0.8708, 0.8807],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8737], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8309])\n",
      ">>Entradas: tensor([0.8004, 0.8054, 0.8044, 0.8118, 0.8415, 0.8708, 0.8807, 0.8737],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8156])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8640], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8156])\n",
      ">>Entradas: tensor([0.8054, 0.8044, 0.8118, 0.8415, 0.8708, 0.8807, 0.8737, 0.8640],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8519], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8117])\n",
      ">>Entradas: tensor([0.8044, 0.8118, 0.8415, 0.8708, 0.8807, 0.8737, 0.8640, 0.8519],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8192])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8451], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8192])\n",
      ">>Entradas: tensor([0.8118, 0.8415, 0.8708, 0.8807, 0.8737, 0.8640, 0.8519, 0.8451],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8218])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8426], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8218])\n",
      ">>Entradas: tensor([0.8415, 0.8708, 0.8807, 0.8737, 0.8640, 0.8519, 0.8451, 0.8426],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8392], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8197])\n",
      ">>Entradas: tensor([0.8708, 0.8807, 0.8737, 0.8640, 0.8519, 0.8451, 0.8426, 0.8392],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8179])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8328], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8179])\n",
      ">>Entradas: tensor([0.8807, 0.8737, 0.8640, 0.8519, 0.8451, 0.8426, 0.8392, 0.8328],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8163])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8247], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8163])\n",
      ">>Entradas: tensor([0.8737, 0.8640, 0.8519, 0.8451, 0.8426, 0.8392, 0.8328, 0.8247],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8006])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8127], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8006])\n",
      ">>Entradas: tensor([0.8640, 0.8519, 0.8451, 0.8426, 0.8392, 0.8328, 0.8247, 0.8127],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7705])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7946], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7705])\n",
      ">>Entradas: tensor([0.8519, 0.8451, 0.8426, 0.8392, 0.8328, 0.8247, 0.8127, 0.7946],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7427])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7734], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7427])\n",
      ">>Entradas: tensor([0.8451, 0.8426, 0.8392, 0.8328, 0.8247, 0.8127, 0.7946, 0.7734],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7478], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7169])\n",
      ">>Entradas: tensor([0.8426, 0.8392, 0.8328, 0.8247, 0.8127, 0.7946, 0.7734, 0.7478],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7312], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7197])\n",
      ">>Entradas: tensor([0.8392, 0.8328, 0.8247, 0.8127, 0.7946, 0.7734, 0.7478, 0.7312],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7509])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7276], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7509])\n",
      ">>Entradas: tensor([0.8328, 0.8247, 0.8127, 0.7946, 0.7734, 0.7478, 0.7312, 0.7276],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7403])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7215], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7403])\n",
      ">>Entradas: tensor([0.8247, 0.8127, 0.7946, 0.7734, 0.7478, 0.7312, 0.7276, 0.7215],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7022], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.8127, 0.7946, 0.7734, 0.7478, 0.7312, 0.7276, 0.7215, 0.7022],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6688])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6825], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6688])\n",
      ">>Entradas: tensor([0.7946, 0.7734, 0.7478, 0.7312, 0.7276, 0.7215, 0.7022, 0.6825],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6835])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6713], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6835])\n",
      ">>Entradas: tensor([0.7734, 0.7478, 0.7312, 0.7276, 0.7215, 0.7022, 0.6825, 0.6713],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6638], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.7478, 0.7312, 0.7276, 0.7215, 0.7022, 0.6825, 0.6713, 0.6638],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6815])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6592], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6815])\n",
      ">>Entradas: tensor([0.7312, 0.7276, 0.7215, 0.7022, 0.6825, 0.6713, 0.6638, 0.6592],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6893])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6615], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6893])\n",
      ">>Entradas: tensor([0.7276, 0.7215, 0.7022, 0.6825, 0.6713, 0.6638, 0.6592, 0.6615],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7111])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6704], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7111])\n",
      ">>Entradas: tensor([0.7215, 0.7022, 0.6825, 0.6713, 0.6638, 0.6592, 0.6615, 0.6704],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7349])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6839], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7349])\n",
      ">>Entradas: tensor([0.7022, 0.6825, 0.6713, 0.6638, 0.6592, 0.6615, 0.6704, 0.6839],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7608])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7034], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7608])\n",
      ">>Entradas: tensor([0.6825, 0.6713, 0.6638, 0.6592, 0.6615, 0.6704, 0.6839, 0.7034],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7711])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7240], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7711])\n",
      ">>Entradas: tensor([0.6713, 0.6638, 0.6592, 0.6615, 0.6704, 0.6839, 0.7034, 0.7240],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7660])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7403], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7660])\n",
      ">>Entradas: tensor([0.6638, 0.6592, 0.6615, 0.6704, 0.6839, 0.7034, 0.7240, 0.7403],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7483])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7491], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7483])\n",
      ">>Entradas: tensor([0.6592, 0.6615, 0.6704, 0.6839, 0.7034, 0.7240, 0.7403, 0.7491],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7182])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7478], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7182])\n",
      ">>Entradas: tensor([0.6615, 0.6704, 0.6839, 0.7034, 0.7240, 0.7403, 0.7491, 0.7478],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7443], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7089])\n",
      ">>Entradas: tensor([0.6704, 0.6839, 0.7034, 0.7240, 0.7403, 0.7491, 0.7478, 0.7443],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7204])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7445], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7204])\n",
      ">>Entradas: tensor([0.6839, 0.7034, 0.7240, 0.7403, 0.7491, 0.7478, 0.7443, 0.7445],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7706])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7587], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7706])\n",
      ">>Entradas: tensor([0.7034, 0.7240, 0.7403, 0.7491, 0.7478, 0.7443, 0.7445, 0.7587],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8595])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7958], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8595])\n",
      ">>Entradas: tensor([0.7240, 0.7403, 0.7491, 0.7478, 0.7443, 0.7445, 0.7587, 0.7958],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8377], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9065])\n",
      ">>Entradas: tensor([0.7403, 0.7491, 0.7478, 0.7443, 0.7445, 0.7587, 0.7958, 0.8377],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9119])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8703], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9119])\n",
      ">>Entradas: tensor([0.7491, 0.7478, 0.7443, 0.7445, 0.7587, 0.7958, 0.8377, 0.8703],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9043])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8926], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9043])\n",
      ">>Entradas: tensor([0.7478, 0.7443, 0.7445, 0.7587, 0.7958, 0.8377, 0.8703, 0.8926],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8839])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9025], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8839])\n",
      ">>Entradas: tensor([0.7443, 0.7445, 0.7587, 0.7958, 0.8377, 0.8703, 0.8926, 0.9025],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9032])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9150], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9032])\n",
      ">>Entradas: tensor([0.7445, 0.7587, 0.7958, 0.8377, 0.8703, 0.8926, 0.9025, 0.9150],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9623])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9430], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9623])\n",
      ">>Entradas: tensor([0.7587, 0.7958, 0.8377, 0.8703, 0.8926, 0.9025, 0.9150, 0.9430],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9821])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9714], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9821])\n",
      ">>Entradas: tensor([0.7958, 0.8377, 0.8703, 0.8926, 0.9025, 0.9150, 0.9430, 0.9714],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9624])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9871], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9624])\n",
      ">>Entradas: tensor([0.8377, 0.8703, 0.8926, 0.9025, 0.9150, 0.9430, 0.9714, 0.9871],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9303])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9861], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9303])\n",
      ">>Entradas: tensor([0.8703, 0.8926, 0.9025, 0.9150, 0.9430, 0.9714, 0.9871, 0.9861],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8855])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9690], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8855])\n",
      ">>Entradas: tensor([0.8926, 0.9025, 0.9150, 0.9430, 0.9714, 0.9871, 0.9861, 0.9690],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8597])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9436], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8597])\n",
      ">>Entradas: tensor([0.9025, 0.9150, 0.9430, 0.9714, 0.9871, 0.9861, 0.9690, 0.9436],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8529])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9200], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8529])\n",
      ">>Entradas: tensor([0.9150, 0.9430, 0.9714, 0.9871, 0.9861, 0.9690, 0.9436, 0.9200],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9030], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.9430, 0.9714, 0.9871, 0.9861, 0.9690, 0.9436, 0.9200, 0.9030],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8769])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8948], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8769])\n",
      ">>Entradas: tensor([0.9714, 0.9871, 0.9861, 0.9690, 0.9436, 0.9200, 0.9030, 0.8948],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8806])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8874], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8806])\n",
      ">>Entradas: tensor([0.9871, 0.9861, 0.9690, 0.9436, 0.9200, 0.9030, 0.8948, 0.8874],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8699])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8759], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8699])\n",
      ">>Entradas: tensor([0.9861, 0.9690, 0.9436, 0.9200, 0.9030, 0.8948, 0.8874, 0.8759],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8465])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8584], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8465])\n",
      ">>Entradas: tensor([0.9690, 0.9436, 0.9200, 0.9030, 0.8948, 0.8874, 0.8759, 0.8584],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8104])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8335], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8104])\n",
      ">>Entradas: tensor([0.9436, 0.9200, 0.9030, 0.8948, 0.8874, 0.8759, 0.8584, 0.8335],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8026])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8128], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8026])\n",
      ">>Entradas: tensor([0.9200, 0.9030, 0.8948, 0.8874, 0.8759, 0.8584, 0.8335, 0.8128],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8232])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8049], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8232])\n",
      ">>Entradas: tensor([0.9030, 0.8948, 0.8874, 0.8759, 0.8584, 0.8335, 0.8128, 0.8049],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8397])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8057], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8397])\n",
      ">>Entradas: tensor([0.8948, 0.8874, 0.8759, 0.8584, 0.8335, 0.8128, 0.8049, 0.8057],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8522])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8117], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8522])\n",
      ">>Entradas: tensor([0.8874, 0.8759, 0.8584, 0.8335, 0.8128, 0.8049, 0.8057, 0.8117],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8616])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8204], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8616])\n",
      ">>Entradas: tensor([0.8759, 0.8584, 0.8335, 0.8128, 0.8049, 0.8057, 0.8117, 0.8204],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8679])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8291], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8679])\n",
      ">>Entradas: tensor([0.8584, 0.8335, 0.8128, 0.8049, 0.8057, 0.8117, 0.8204, 0.8291],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8702])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8369], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8702])\n",
      ">>Entradas: tensor([0.8335, 0.8128, 0.8049, 0.8057, 0.8117, 0.8204, 0.8291, 0.8369],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8685])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8445], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8685])\n",
      ">>Entradas: tensor([0.8128, 0.8049, 0.8057, 0.8117, 0.8204, 0.8291, 0.8369, 0.8445],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8530])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8479], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8530])\n",
      ">>Entradas: tensor([0.8049, 0.8057, 0.8117, 0.8204, 0.8291, 0.8369, 0.8445, 0.8479],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8236])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8436], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8236])\n",
      ">>Entradas: tensor([0.8057, 0.8117, 0.8204, 0.8291, 0.8369, 0.8445, 0.8479, 0.8436],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8349], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.8117, 0.8204, 0.8291, 0.8369, 0.8445, 0.8479, 0.8436, 0.8349],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7919])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8246], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7919])\n",
      ">>Entradas: tensor([0.8204, 0.8291, 0.8369, 0.8445, 0.8479, 0.8436, 0.8349, 0.8246],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7865])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8142], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7865])\n",
      ">>Entradas: tensor([0.8291, 0.8369, 0.8445, 0.8479, 0.8436, 0.8349, 0.8246, 0.8142],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7870])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8055], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7870])\n",
      ">>Entradas: tensor([0.8369, 0.8445, 0.8479, 0.8436, 0.8349, 0.8246, 0.8142, 0.8055],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7874])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7984], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7874])\n",
      ">>Entradas: tensor([0.8445, 0.8479, 0.8436, 0.8349, 0.8246, 0.8142, 0.8055, 0.7984],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7879])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7922], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7879])\n",
      ">>Entradas: tensor([0.8479, 0.8436, 0.8349, 0.8246, 0.8142, 0.8055, 0.7984, 0.7922],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7955])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7888], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7955])\n",
      ">>Entradas: tensor([0.8436, 0.8349, 0.8246, 0.8142, 0.8055, 0.7984, 0.7922, 0.7888],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8102])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7901], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8102])\n",
      ">>Entradas: tensor([0.8349, 0.8246, 0.8142, 0.8055, 0.7984, 0.7922, 0.7888, 0.7901],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7668])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7784], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7668])\n",
      ">>Entradas: tensor([0.8246, 0.8142, 0.8055, 0.7984, 0.7922, 0.7888, 0.7901, 0.7784],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6655])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7402], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6655])\n",
      ">>Entradas: tensor([0.8142, 0.8055, 0.7984, 0.7922, 0.7888, 0.7901, 0.7784, 0.7402],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6361])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4891], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6361])\n",
      "ERROR: la modificacion de los pesos di√≥ un error mayor: 0.021599769592285156, se regresa al estado anterior de la red\n",
      ">>Entradas: tensor([0.8055, 0.7984, 0.7922, 0.7888, 0.7901, 0.7784, 0.7402, 0.7313],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6785])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7076], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6785])\n",
      ">>Entradas: tensor([0.7984, 0.7922, 0.7888, 0.7901, 0.7784, 0.7402, 0.7313, 0.7076],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6945], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6966])\n",
      ">>Entradas: tensor([0.7922, 0.7888, 0.7901, 0.7784, 0.7402, 0.7313, 0.7076, 0.6945],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6903])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6856], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6903])\n",
      ">>Entradas: tensor([0.7888, 0.7901, 0.7784, 0.7402, 0.7313, 0.7076, 0.6945, 0.6856],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6970])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6806], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6970])\n",
      ">>Entradas: tensor([0.7901, 0.7784, 0.7402, 0.7313, 0.7076, 0.6945, 0.6856, 0.6806],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7167])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6814], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7167])\n",
      ">>Entradas: tensor([0.7784, 0.7402, 0.7313, 0.7076, 0.6945, 0.6856, 0.6806, 0.6814],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7491])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6914], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7491])\n",
      ">>Entradas: tensor([0.7402, 0.7313, 0.7076, 0.6945, 0.6856, 0.6806, 0.6814, 0.6914],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7940])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7155], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7940])\n",
      ">>Entradas: tensor([0.7313, 0.7076, 0.6945, 0.6856, 0.6806, 0.6814, 0.6914, 0.7155],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8547])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7550], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8547])\n",
      ">>Entradas: tensor([0.7076, 0.6945, 0.6856, 0.6806, 0.6814, 0.6914, 0.7155, 0.7550],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9314])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8116], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9314])\n",
      ">>Entradas: tensor([0.6945, 0.6856, 0.6806, 0.6814, 0.6914, 0.7155, 0.7550, 0.8116],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9627])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8671], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9627])\n",
      ">>Entradas: tensor([0.6856, 0.6806, 0.6814, 0.6914, 0.7155, 0.7550, 0.8116, 0.8671],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9486])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9078], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9486])\n",
      ">>Entradas: tensor([0.6806, 0.6814, 0.6914, 0.7155, 0.7550, 0.8116, 0.8671, 0.9078],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9307])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9356], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9307])\n",
      ">>Entradas: tensor([0.6814, 0.6914, 0.7155, 0.7550, 0.8116, 0.8671, 0.9078, 0.9356],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9090])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9496], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9090])\n",
      ">>Entradas: tensor([0.6914, 0.7155, 0.7550, 0.8116, 0.8671, 0.9078, 0.9356, 0.9496],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8816])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9524], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8816])\n",
      ">>Entradas: tensor([0.7155, 0.7550, 0.8116, 0.8671, 0.9078, 0.9356, 0.9496, 0.9524],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8487])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9444], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8487])\n",
      ">>Entradas: tensor([0.7550, 0.8116, 0.8671, 0.9078, 0.9356, 0.9496, 0.9524, 0.9444],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8753])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9442], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8753])\n",
      ">>Entradas: tensor([0.8116, 0.8671, 0.9078, 0.9356, 0.9496, 0.9524, 0.9444, 0.9442],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9612])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9654], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9612])\n",
      ">>Entradas: tensor([0.8671, 0.9078, 0.9356, 0.9496, 0.9524, 0.9444, 0.9442, 0.9654],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9925])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9857], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9925])\n",
      ">>Entradas: tensor([0.9078, 0.9356, 0.9496, 0.9524, 0.9444, 0.9442, 0.9654, 0.9857],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9690])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9908], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9690])\n",
      ">>Entradas: tensor([0.9356, 0.9496, 0.9524, 0.9444, 0.9442, 0.9654, 0.9857, 0.9908],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9715])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9932], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9715])\n",
      ">>Entradas: tensor([0.9496, 0.9524, 0.9444, 0.9442, 0.9654, 0.9857, 0.9908, 0.9932],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([1.])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9998], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([1.])\n",
      ">>Entradas: tensor([0.9524, 0.9444, 0.9442, 0.9654, 0.9857, 0.9908, 0.9932, 0.9998],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9960], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9801])\n",
      ">>Entradas: tensor([0.9444, 0.9442, 0.9654, 0.9857, 0.9908, 0.9932, 0.9998, 0.9960],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9738], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9117])\n",
      ">>Entradas: tensor([0.9442, 0.9654, 0.9857, 0.9908, 0.9932, 0.9998, 0.9960, 0.9738],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8911])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9501], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8911])\n",
      ">>Entradas: tensor([0.9654, 0.9857, 0.9908, 0.9932, 0.9998, 0.9960, 0.9738, 0.9501],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9181])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9414], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9181])\n",
      ">>Entradas: tensor([0.9857, 0.9908, 0.9932, 0.9998, 0.9960, 0.9738, 0.9501, 0.9414],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9450])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9391], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9450])\n",
      ">>Entradas: tensor([0.9908, 0.9932, 0.9998, 0.9960, 0.9738, 0.9501, 0.9414, 0.9391],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9718])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9451], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9718])\n",
      ">>Entradas: tensor([0.9932, 0.9998, 0.9960, 0.9738, 0.9501, 0.9414, 0.9391, 0.9451],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9829])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9545], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9829])\n",
      ">>Entradas: tensor([0.9998, 0.9960, 0.9738, 0.9501, 0.9414, 0.9391, 0.9451, 0.9545],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9783])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9590], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9783])\n",
      ">>s_original: [0.049424633383750916, 0.10789185762405396, 0.13719609379768372, 0.13733737170696259, 0.1338856965303421, 0.12684109807014465, 0.14756061136722565, 0.19604423642158508, 0.21688967943191528, 0.21009695529937744, 0.20267784595489502, 0.1946323662996292, 0.19407351315021515, 0.20100130140781403, 0.19663821160793304, 0.180984228849411, 0.16539041697978973, 0.14985674619674683, 0.15043111145496368, 0.1671135276556015, 0.20227035880088806, 0.25590160489082336, 0.29268819093704224, 0.31263017654418945, 0.31093889474868774, 0.2876143157482147, 0.28016164898872375, 0.28858086466789246, 0.28246283531188965, 0.26180753111839294, 0.2801212966442108, 0.3374040722846985, 0.3482298254966736, 0.3125985562801361, 0.34358710050582886, 0.44119545817375183, 0.521095335483551, 0.5832866430282593, 0.6089234352111816, 0.5980057120323181, 0.5945301651954651, 0.5984968543052673, 0.621354341506958, 0.6631026864051819, 0.6928724050521851, 0.7106636166572571, 0.721682071685791, 0.7259277701377869, 0.7404318451881409, 0.7651942372322083, 0.7447891235351562, 0.6792163252830505, 0.6746017932891846, 0.730945348739624, 0.7467210292816162, 0.7219287157058716, 0.7199286818504333, 0.7407209277153015, 0.7362455129623413, 0.7065023183822632, 0.6979451775550842, 0.7105739712715149, 0.7209621667861938, 0.7291097044944763, 0.7674259543418884, 0.8359109163284302, 0.8510103225708008, 0.8127241730690002, 0.7863940000534058, 0.7720199823379517, 0.8033170700073242, 0.8802852630615234, 0.8987051844596863, 0.8585767149925232, 0.8308762311935425, 0.8156037926673889, 0.8116992115974426, 0.8191625475883484, 0.8218275904655457, 0.8196942210197449, 0.817862868309021, 0.8163333535194397, 0.8005555868148804, 0.7705295085906982, 0.7426586747169495, 0.716943085193634, 0.7197051048278809, 0.7509447932243347, 0.7402781248092651, 0.6877052187919617, 0.6687695384025574, 0.683471143245697, 0.6877052187919617, 0.6814717054367065, 0.6892618536949158, 0.7110756039619446, 0.7349108457565308, 0.7607676982879639, 0.771117091178894, 0.7659589648246765, 0.7483323812484741, 0.7182371616363525, 0.708941638469696, 0.7204458117485046, 0.7706154584884644, 0.8594506978988647, 0.906541109085083, 0.9118866324424744, 0.9043355584144592, 0.8838878870010376, 0.9032153487205505, 0.9623178839683533, 0.9820588231086731, 0.96243816614151, 0.9302511811256409, 0.8854979276657104, 0.8597025871276855, 0.8528652191162109, 0.8585854768753052, 0.8768633008003235, 0.8806464076042175, 0.8699347376823425, 0.846513569355011, 0.8103827834129333, 0.8026111125946045, 0.8231984972953796, 0.8397204279899597, 0.8521769046783447, 0.8615626692771912, 0.8678776621818542, 0.8701963424682617, 0.868518590927124, 0.852988064289093, 0.8236046433448792, 0.8032509088516235, 0.7919268012046814, 0.7865023016929626, 0.7869773507118225, 0.7874362468719482, 0.7878790497779846, 0.7954531908035278, 0.8101586699485779, 0.7668473124504089, 0.665519118309021, 0.6360738277435303, 0.678511381149292, 0.6965967416763306, 0.6903298497200012, 0.6970472931861877, 0.7167490720748901, 0.7490506768226624, 0.7939522862434387, 0.8547447323799133, 0.931428074836731, 0.9627243876457214, 0.9486336708068848, 0.9307146072387695, 0.9089671969413757, 0.8816379904747009, 0.8487268090248108, 0.8752607107162476, 0.9612395763397217, 0.9925020933151245, 0.9690483212471008, 0.9715476036071777, 1.0, 0.9800636768341064, 0.9117385745048523, 0.8910858035087585, 0.9181053042411804, 0.9450165033340454, 0.9718193411827087, 0.982906699180603, 0.9782785773277283]\n",
      ">>s_pred: [0.046652793884277344, 0.06515979766845703, 0.09218549728393555, 0.11352872848510742, 0.12561511993408203, 0.1335887908935547, 0.1466517448425293, 0.17160272598266602, 0.19635391235351562, 0.21311712265014648, 0.22319316864013672, 0.2258596420288086, 0.22548532485961914, 0.22666120529174805, 0.22584915161132812, 0.2189016342163086, 0.20712995529174805, 0.19093561172485352, 0.17666292190551758, 0.16952276229858398, 0.17450332641601562, 0.19444894790649414, 0.2211308479309082, 0.2483816146850586, 0.2701554298400879, 0.2813429832458496, 0.2894172668457031, 0.2994718551635742, 0.3059401512145996, 0.30306196212768555, 0.3068885803222656, 0.3237323760986328, 0.336578369140625, 0.33556079864501953, 0.34451913833618164, 0.3787064552307129, 0.42778587341308594, 0.4905986785888672, 0.5470132827758789, 0.587836742401123, 0.6171994209289551, 0.6363286972045898, 0.660759449005127, 0.6922988891601562, 0.7231683731079102, 0.7480483055114746, 0.7650594711303711, 0.7941622734069824, 0.7957944869995117, 0.8013753890991211, 0.800262451171875, 0.7750945091247559, 0.752474308013916, 0.7488899230957031, 0.7478542327880859, 0.7377781867980957, 0.7296404838562012, 0.7279276847839355, 0.7222776412963867, 0.7103605270385742, 0.7022242546081543, 0.7004580497741699, 0.7014336585998535, 0.7057247161865234, 0.7221927642822266, 0.7560596466064453, 0.7865667343139648, 0.8004274368286133, 0.8054451942443848, 0.8043560981750488, 0.8118305206298828, 0.841461181640625, 0.8707618713378906, 0.8806953430175781, 0.8737373352050781, 0.8640103340148926, 0.8519210815429688, 0.8451237678527832, 0.8426127433776855, 0.8392014503479004, 0.8328251838684082, 0.8247060775756836, 0.8126611709594727, 0.794588565826416, 0.7733654975891113, 0.7477679252624512, 0.7312054634094238, 0.7275733947753906, 0.7215409278869629, 0.7021784782409668, 0.6825428009033203, 0.6713118553161621, 0.6638422012329102, 0.6591997146606445, 0.6614656448364258, 0.6704025268554688, 0.6838865280151367, 0.7034130096435547, 0.724027156829834, 0.7403488159179688, 0.7490534782409668, 0.7478246688842773, 0.7442665100097656, 0.7444510459899902, 0.7587456703186035, 0.7958269119262695, 0.837745189666748, 0.8702726364135742, 0.8926000595092773, 0.9024815559387207, 0.9149565696716309, 0.9430055618286133, 0.9714498519897461, 0.9871330261230469, 0.9860653877258301, 0.9689607620239258, 0.9436488151550293, 0.920018196105957, 0.9029521942138672, 0.8948116302490234, 0.8873686790466309, 0.8759469985961914, 0.8584094047546387, 0.8334794044494629, 0.8128299713134766, 0.8049092292785645, 0.8056507110595703, 0.8117227554321289, 0.8203916549682617, 0.8291497230529785, 0.8368844985961914, 0.8444666862487793, 0.8478550910949707, 0.843635082244873, 0.8348674774169922, 0.8246078491210938, 0.8141589164733887, 0.805488109588623, 0.7984070777893066, 0.7922282218933105, 0.7887954711914062, 0.7901325225830078, 0.7784056663513184, 0.7402434349060059, 0.731292724609375, 0.7075910568237305, 0.6944513320922852, 0.685575008392334, 0.6805896759033203, 0.6813526153564453, 0.6914191246032715, 0.715517520904541, 0.7549757957458496, 0.8115983009338379, 0.8671307563781738, 0.907752513885498, 0.9356021881103516, 0.9496316909790039, 0.9524178504943848, 0.9444456100463867, 0.9441671371459961, 0.9654150009155273, 0.9856915473937988, 0.9907851219177246, 0.993159294128418, 0.9998092651367188, 0.9959969520568848, 0.973759651184082, 0.9500646591186523, 0.9413890838623047, 0.9391446113586426, 0.9450640678405762, 0.9545426368713379, 0.9589781761169434]\n",
      "<<Perdida: 0.0016333017265424132 epoca: 4\n",
      "---Inicio de epoca: 5--\n",
      ">>Entradas: tensor([0.0503, 0.0086, 0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203])\n",
      ">>Salida: tensor([0.0494])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([-0.0264], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.0494])\n",
      ">>Entradas: tensor([ 0.0086,  0.0000,  0.0245,  0.0327,  0.0246,  0.0205,  0.0203, -0.0264],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1079])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0109], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1079])\n",
      ">>Entradas: tensor([ 0.0000,  0.0245,  0.0327,  0.0246,  0.0205,  0.0203, -0.0264,  0.0109],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1372])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0497], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1372])\n",
      ">>Entradas: tensor([ 0.0245,  0.0327,  0.0246,  0.0205,  0.0203, -0.0264,  0.0109,  0.0497],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1373])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0756], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1373])\n",
      ">>Entradas: tensor([ 0.0327,  0.0246,  0.0205,  0.0203, -0.0264,  0.0109,  0.0497,  0.0756],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1339])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1017], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1339])\n",
      ">>Entradas: tensor([ 0.0246,  0.0205,  0.0203, -0.0264,  0.0109,  0.0497,  0.0756,  0.1017],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1268])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1191], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1268])\n",
      ">>Entradas: tensor([ 0.0205,  0.0203, -0.0264,  0.0109,  0.0497,  0.0756,  0.1017,  0.1191],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1476])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1349], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1476])\n",
      ">>Entradas: tensor([ 0.0203, -0.0264,  0.0109,  0.0497,  0.0756,  0.1017,  0.1191,  0.1349],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1960])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1630], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1960])\n",
      ">>Entradas: tensor([-0.0264,  0.0109,  0.0497,  0.0756,  0.1017,  0.1191,  0.1349,  0.1630],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1957], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2169])\n",
      ">>Entradas: tensor([0.0109, 0.0497, 0.0756, 0.1017, 0.1191, 0.1349, 0.1630, 0.1957],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2101])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2222], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2101])\n",
      ">>Entradas: tensor([0.0497, 0.0756, 0.1017, 0.1191, 0.1349, 0.1630, 0.1957, 0.2222],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2027])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2387], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2027])\n",
      ">>Entradas: tensor([0.0756, 0.1017, 0.1191, 0.1349, 0.1630, 0.1957, 0.2222, 0.2387],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1946])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2384], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1946])\n",
      ">>Entradas: tensor([0.1017, 0.1191, 0.1349, 0.1630, 0.1957, 0.2222, 0.2387, 0.2384],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1941])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2406], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1941])\n",
      ">>Entradas: tensor([0.1191, 0.1349, 0.1630, 0.1957, 0.2222, 0.2387, 0.2384, 0.2406],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2010])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2427], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2010])\n",
      ">>Entradas: tensor([0.1349, 0.1630, 0.1957, 0.2222, 0.2387, 0.2384, 0.2406, 0.2427],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2327], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1966])\n",
      ">>Entradas: tensor([0.1630, 0.1957, 0.2222, 0.2387, 0.2384, 0.2406, 0.2427, 0.2327],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1810])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2217], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1810])\n",
      ">>Entradas: tensor([0.1957, 0.2222, 0.2387, 0.2384, 0.2406, 0.2427, 0.2327, 0.2217],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1654])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1920], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1654])\n",
      ">>Entradas: tensor([0.2222, 0.2387, 0.2384, 0.2406, 0.2427, 0.2327, 0.2217, 0.1920],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1499])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1790], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1499])\n",
      ">>Entradas: tensor([0.2387, 0.2384, 0.2406, 0.2427, 0.2327, 0.2217, 0.1920, 0.1790],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1504])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1650], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1504])\n",
      ">>Entradas: tensor([0.2384, 0.2406, 0.2427, 0.2327, 0.2217, 0.1920, 0.1790, 0.1650],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1671])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1571], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1671])\n",
      ">>Entradas: tensor([0.2406, 0.2427, 0.2327, 0.2217, 0.1920, 0.1790, 0.1650, 0.1571],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2023])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1628], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2023])\n",
      ">>Entradas: tensor([0.2427, 0.2327, 0.2217, 0.1920, 0.1790, 0.1650, 0.1571, 0.1628],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2559])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1829], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2559])\n",
      ">>Entradas: tensor([0.2327, 0.2217, 0.1920, 0.1790, 0.1650, 0.1571, 0.1628, 0.1829],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2927])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2093], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2927])\n",
      ">>Entradas: tensor([0.2217, 0.1920, 0.1790, 0.1650, 0.1571, 0.1628, 0.1829, 0.2093],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2377], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.1920, 0.1790, 0.1650, 0.1571, 0.1628, 0.1829, 0.2093, 0.2377],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3109])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2626], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3109])\n",
      ">>Entradas: tensor([0.1790, 0.1650, 0.1571, 0.1628, 0.1829, 0.2093, 0.2377, 0.2626],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2876])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2779], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2876])\n",
      ">>Entradas: tensor([0.1650, 0.1571, 0.1628, 0.1829, 0.2093, 0.2377, 0.2626, 0.2779],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2802])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2896], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2802])\n",
      ">>Entradas: tensor([0.1571, 0.1628, 0.1829, 0.2093, 0.2377, 0.2626, 0.2779, 0.2896],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2886])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3031], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2886])\n",
      ">>Entradas: tensor([0.1628, 0.1829, 0.2093, 0.2377, 0.2626, 0.2779, 0.2896, 0.3031],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2825])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3126], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2825])\n",
      ">>Entradas: tensor([0.1829, 0.2093, 0.2377, 0.2626, 0.2779, 0.2896, 0.3031, 0.3126],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2618])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3138], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2618])\n",
      ">>Entradas: tensor([0.2093, 0.2377, 0.2626, 0.2779, 0.2896, 0.3031, 0.3126, 0.3138],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3184], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2801])\n",
      ">>Entradas: tensor([0.2377, 0.2626, 0.2779, 0.2896, 0.3031, 0.3126, 0.3138, 0.3184],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3374])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3359], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3374])\n",
      ">>Entradas: tensor([0.2626, 0.2779, 0.2896, 0.3031, 0.3126, 0.3138, 0.3184, 0.3359],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3482])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3488], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3482])\n",
      ">>Entradas: tensor([0.2779, 0.2896, 0.3031, 0.3126, 0.3138, 0.3184, 0.3359, 0.3488],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3472], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2896, 0.3031, 0.3126, 0.3138, 0.3184, 0.3359, 0.3488, 0.3472],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3436])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3553], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3436])\n",
      ">>Entradas: tensor([0.3031, 0.3126, 0.3138, 0.3184, 0.3359, 0.3488, 0.3472, 0.3553],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.4412])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3880], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.4412])\n",
      ">>Entradas: tensor([0.3126, 0.3138, 0.3184, 0.3359, 0.3488, 0.3472, 0.3553, 0.3880],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5211])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4353], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5211])\n",
      ">>Entradas: tensor([0.3138, 0.3184, 0.3359, 0.3488, 0.3472, 0.3553, 0.3880, 0.4353],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5833])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4941], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5833])\n",
      ">>Entradas: tensor([0.3184, 0.3359, 0.3488, 0.3472, 0.3553, 0.3880, 0.4353, 0.4941],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5505], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6089])\n",
      ">>Entradas: tensor([0.3359, 0.3488, 0.3472, 0.3553, 0.3880, 0.4353, 0.4941, 0.5505],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5980])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5912], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5980])\n",
      ">>Entradas: tensor([0.3488, 0.3472, 0.3553, 0.3880, 0.4353, 0.4941, 0.5505, 0.5912],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5945])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6202], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5945])\n",
      ">>Entradas: tensor([0.3472, 0.3553, 0.3880, 0.4353, 0.4941, 0.5505, 0.5912, 0.6202],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5985])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5990], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5985])\n",
      ">>Entradas: tensor([0.3553, 0.3880, 0.4353, 0.4941, 0.5505, 0.5912, 0.6202, 0.5990],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6214])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6320], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6214])\n",
      ">>Entradas: tensor([0.3880, 0.4353, 0.4941, 0.5505, 0.5912, 0.6202, 0.5990, 0.6320],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6631])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6676], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6631])\n",
      ">>Entradas: tensor([0.4353, 0.4941, 0.5505, 0.5912, 0.6202, 0.5990, 0.6320, 0.6676],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6929])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7002], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6929])\n",
      ">>Entradas: tensor([0.4941, 0.5505, 0.5912, 0.6202, 0.5990, 0.6320, 0.6676, 0.7002],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7107])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7321], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7107])\n",
      ">>Entradas: tensor([0.5505, 0.5912, 0.6202, 0.5990, 0.6320, 0.6676, 0.7002, 0.7321],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7217])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7540], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7217])\n",
      ">>Entradas: tensor([0.5912, 0.6202, 0.5990, 0.6320, 0.6676, 0.7002, 0.7321, 0.7540],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7259])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7585], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7259])\n",
      ">>Entradas: tensor([0.6202, 0.5990, 0.6320, 0.6676, 0.7002, 0.7321, 0.7540, 0.7585],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7404])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7664], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7404])\n",
      ">>Entradas: tensor([0.5990, 0.6320, 0.6676, 0.7002, 0.7321, 0.7540, 0.7585, 0.7664],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7652])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7809], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7652])\n",
      ">>Entradas: tensor([0.6320, 0.6676, 0.7002, 0.7321, 0.7540, 0.7585, 0.7664, 0.7809],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7448])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7855], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7448])\n",
      ">>Entradas: tensor([0.6676, 0.7002, 0.7321, 0.7540, 0.7585, 0.7664, 0.7809, 0.7855],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6792])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7686], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6792])\n",
      ">>Entradas: tensor([0.7002, 0.7321, 0.7540, 0.7585, 0.7664, 0.7809, 0.7855, 0.7686],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6746])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7486], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6746])\n",
      ">>Entradas: tensor([0.7321, 0.7540, 0.7585, 0.7664, 0.7809, 0.7855, 0.7686, 0.7486],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7479], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7309])\n",
      ">>Entradas: tensor([0.7540, 0.7585, 0.7664, 0.7809, 0.7855, 0.7686, 0.7486, 0.7479],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7467])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7468], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7467])\n",
      ">>Entradas: tensor([0.7585, 0.7664, 0.7809, 0.7855, 0.7686, 0.7486, 0.7479, 0.7468],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7219])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7383], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7219])\n",
      ">>Entradas: tensor([0.7664, 0.7809, 0.7855, 0.7686, 0.7486, 0.7479, 0.7468, 0.7383],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7199])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7333], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7199])\n",
      ">>Entradas: tensor([0.7809, 0.7855, 0.7686, 0.7486, 0.7479, 0.7468, 0.7383, 0.7333],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7407])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7334], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7407])\n",
      ">>Entradas: tensor([0.7855, 0.7686, 0.7486, 0.7479, 0.7468, 0.7383, 0.7333, 0.7334],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7362])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7284], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7362])\n",
      ">>Entradas: tensor([0.7686, 0.7486, 0.7479, 0.7468, 0.7383, 0.7333, 0.7334, 0.7284],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7162], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7065])\n",
      ">>Entradas: tensor([0.7486, 0.7479, 0.7468, 0.7383, 0.7333, 0.7334, 0.7284, 0.7162],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6979])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7074], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6979])\n",
      ">>Entradas: tensor([0.7479, 0.7468, 0.7383, 0.7333, 0.7334, 0.7284, 0.7162, 0.7074],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7106])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7046], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7106])\n",
      ">>Entradas: tensor([0.7468, 0.7383, 0.7333, 0.7334, 0.7284, 0.7162, 0.7074, 0.7046],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7210])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7046], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7210])\n",
      ">>Entradas: tensor([0.7383, 0.7333, 0.7334, 0.7284, 0.7162, 0.7074, 0.7046, 0.7046],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7291])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7082], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7291])\n",
      ">>Entradas: tensor([0.7333, 0.7334, 0.7284, 0.7162, 0.7074, 0.7046, 0.7046, 0.7082],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7674])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7241], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7674])\n",
      ">>Entradas: tensor([0.7334, 0.7284, 0.7162, 0.7074, 0.7046, 0.7046, 0.7082, 0.7241],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8359])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7571], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8359])\n",
      ">>Entradas: tensor([0.7284, 0.7162, 0.7074, 0.7046, 0.7046, 0.7082, 0.7241, 0.7571],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8510])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7868], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8510])\n",
      ">>Entradas: tensor([0.7162, 0.7074, 0.7046, 0.7046, 0.7082, 0.7241, 0.7571, 0.7868],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8127])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8000], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8127])\n",
      ">>Entradas: tensor([0.7074, 0.7046, 0.7046, 0.7082, 0.7241, 0.7571, 0.7868, 0.8000],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7864])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8048], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7864])\n",
      ">>Entradas: tensor([0.7046, 0.7046, 0.7082, 0.7241, 0.7571, 0.7868, 0.8000, 0.8048],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7720])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8038], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7720])\n",
      ">>Entradas: tensor([0.7046, 0.7082, 0.7241, 0.7571, 0.7868, 0.8000, 0.8048, 0.8038],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8111], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.7082, 0.7241, 0.7571, 0.7868, 0.8000, 0.8048, 0.8038, 0.8111],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8803])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8407], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8803])\n",
      ">>Entradas: tensor([0.7241, 0.7571, 0.7868, 0.8000, 0.8048, 0.8038, 0.8111, 0.8407],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8987])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([54.2049], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8987])\n",
      "ERROR: la modificacion de los pesos di√≥ un error mayor: 2841.551513671875, se regresa al estado anterior de la red\n",
      ">>Entradas: tensor([0.7571, 0.7868, 0.8000, 0.8048, 0.8038, 0.8111, 0.8407, 0.8576],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8707], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.7868, 0.8000, 0.8048, 0.8038, 0.8111, 0.8407, 0.8576, 0.8707],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8698], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8309])\n",
      ">>Entradas: tensor([0.8000, 0.8048, 0.8038, 0.8111, 0.8407, 0.8576, 0.8707, 0.8698],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8156])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8591], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8156])\n",
      ">>Entradas: tensor([0.8048, 0.8038, 0.8111, 0.8407, 0.8576, 0.8707, 0.8698, 0.8591],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8487], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8117])\n",
      ">>Entradas: tensor([0.8038, 0.8111, 0.8407, 0.8576, 0.8707, 0.8698, 0.8591, 0.8487],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8192])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8431], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8192])\n",
      ">>Entradas: tensor([0.8111, 0.8407, 0.8576, 0.8707, 0.8698, 0.8591, 0.8487, 0.8431],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8218])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8406], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8218])\n",
      ">>Entradas: tensor([0.8407, 0.8576, 0.8707, 0.8698, 0.8591, 0.8487, 0.8431, 0.8406],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8369], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8197])\n",
      ">>Entradas: tensor([0.8576, 0.8707, 0.8698, 0.8591, 0.8487, 0.8431, 0.8406, 0.8369],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8179])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8318], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8179])\n",
      ">>Entradas: tensor([0.8707, 0.8698, 0.8591, 0.8487, 0.8431, 0.8406, 0.8369, 0.8318],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8163])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8252], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8163])\n",
      ">>Entradas: tensor([0.8698, 0.8591, 0.8487, 0.8431, 0.8406, 0.8369, 0.8318, 0.8252],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8006])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8137], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8006])\n",
      ">>Entradas: tensor([0.8591, 0.8487, 0.8431, 0.8406, 0.8369, 0.8318, 0.8252, 0.8137],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7705])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7958], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7705])\n",
      ">>Entradas: tensor([0.8487, 0.8431, 0.8406, 0.8369, 0.8318, 0.8252, 0.8137, 0.7958],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7427])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7748], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7427])\n",
      ">>Entradas: tensor([0.8431, 0.8406, 0.8369, 0.8318, 0.8252, 0.8137, 0.7958, 0.7748],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7512], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7169])\n",
      ">>Entradas: tensor([0.8406, 0.8369, 0.8318, 0.8252, 0.8137, 0.7958, 0.7748, 0.7512],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7339], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7197])\n",
      ">>Entradas: tensor([0.8369, 0.8318, 0.8252, 0.8137, 0.7958, 0.7748, 0.7512, 0.7339],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7509])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7299], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7509])\n",
      ">>Entradas: tensor([0.8318, 0.8252, 0.8137, 0.7958, 0.7748, 0.7512, 0.7339, 0.7299],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7403])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7236], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7403])\n",
      ">>Entradas: tensor([0.8252, 0.8137, 0.7958, 0.7748, 0.7512, 0.7339, 0.7299, 0.7236],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7038], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.8137, 0.7958, 0.7748, 0.7512, 0.7339, 0.7299, 0.7236, 0.7038],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6688])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6838], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6688])\n",
      ">>Entradas: tensor([0.7958, 0.7748, 0.7512, 0.7339, 0.7299, 0.7236, 0.7038, 0.6838],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6835])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6724], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6835])\n",
      ">>Entradas: tensor([0.7748, 0.7512, 0.7339, 0.7299, 0.7236, 0.7038, 0.6838, 0.6724],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6646], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.7512, 0.7339, 0.7299, 0.7236, 0.7038, 0.6838, 0.6724, 0.6646],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6815])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6596], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6815])\n",
      ">>Entradas: tensor([0.7339, 0.7299, 0.7236, 0.7038, 0.6838, 0.6724, 0.6646, 0.6596],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6893])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6621], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6893])\n",
      ">>Entradas: tensor([0.7299, 0.7236, 0.7038, 0.6838, 0.6724, 0.6646, 0.6596, 0.6621],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7111])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6708], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7111])\n",
      ">>Entradas: tensor([0.7236, 0.7038, 0.6838, 0.6724, 0.6646, 0.6596, 0.6621, 0.6708],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7349])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6840], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7349])\n",
      ">>Entradas: tensor([0.7038, 0.6838, 0.6724, 0.6646, 0.6596, 0.6621, 0.6708, 0.6840],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7608])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7033], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7608])\n",
      ">>Entradas: tensor([0.6838, 0.6724, 0.6646, 0.6596, 0.6621, 0.6708, 0.6840, 0.7033],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7711])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7238], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7711])\n",
      ">>Entradas: tensor([0.6724, 0.6646, 0.6596, 0.6621, 0.6708, 0.6840, 0.7033, 0.7238],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7660])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7400], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7660])\n",
      ">>Entradas: tensor([0.6646, 0.6596, 0.6621, 0.6708, 0.6840, 0.7033, 0.7238, 0.7400],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7483])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7487], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7483])\n",
      ">>Entradas: tensor([0.6596, 0.6621, 0.6708, 0.6840, 0.7033, 0.7238, 0.7400, 0.7487],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7182])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7475], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7182])\n",
      ">>Entradas: tensor([0.6621, 0.6708, 0.6840, 0.7033, 0.7238, 0.7400, 0.7487, 0.7475],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7422], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7089])\n",
      ">>Entradas: tensor([0.6708, 0.6840, 0.7033, 0.7238, 0.7400, 0.7487, 0.7475, 0.7422],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7204])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7428], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7204])\n",
      ">>Entradas: tensor([0.6840, 0.7033, 0.7238, 0.7400, 0.7487, 0.7475, 0.7422, 0.7428],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7706])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7573], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7706])\n",
      ">>Entradas: tensor([0.7033, 0.7238, 0.7400, 0.7487, 0.7475, 0.7422, 0.7428, 0.7573],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8595])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8084], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8595])\n",
      ">>Entradas: tensor([0.7238, 0.7400, 0.7487, 0.7475, 0.7422, 0.7428, 0.7573, 0.8084],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8460], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9065])\n",
      ">>Entradas: tensor([0.7400, 0.7487, 0.7475, 0.7422, 0.7428, 0.7573, 0.8084, 0.8460],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9119])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8761], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9119])\n",
      ">>Entradas: tensor([0.7487, 0.7475, 0.7422, 0.7428, 0.7573, 0.8084, 0.8460, 0.8761],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9043])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8976], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9043])\n",
      ">>Entradas: tensor([0.7475, 0.7422, 0.7428, 0.7573, 0.8084, 0.8460, 0.8761, 0.8976],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8839])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9052], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8839])\n",
      ">>Entradas: tensor([0.7422, 0.7428, 0.7573, 0.8084, 0.8460, 0.8761, 0.8976, 0.9052],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9032])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9162], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9032])\n",
      ">>Entradas: tensor([0.7428, 0.7573, 0.8084, 0.8460, 0.8761, 0.8976, 0.9052, 0.9162],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9623])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9436], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9623])\n",
      ">>Entradas: tensor([0.7573, 0.8084, 0.8460, 0.8761, 0.8976, 0.9052, 0.9162, 0.9436],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9821])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9718], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9821])\n",
      ">>Entradas: tensor([0.8084, 0.8460, 0.8761, 0.8976, 0.9052, 0.9162, 0.9436, 0.9718],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9624])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9857], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9624])\n",
      ">>Entradas: tensor([0.8460, 0.8761, 0.8976, 0.9052, 0.9162, 0.9436, 0.9718, 0.9857],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9303])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9841], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9303])\n",
      ">>Entradas: tensor([0.8761, 0.8976, 0.9052, 0.9162, 0.9436, 0.9718, 0.9857, 0.9841],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8855])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9666], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8855])\n",
      ">>Entradas: tensor([0.8976, 0.9052, 0.9162, 0.9436, 0.9718, 0.9857, 0.9841, 0.9666],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8597])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9410], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8597])\n",
      ">>Entradas: tensor([0.9052, 0.9162, 0.9436, 0.9718, 0.9857, 0.9841, 0.9666, 0.9410],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8529])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9176], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8529])\n",
      ">>Entradas: tensor([0.9162, 0.9436, 0.9718, 0.9857, 0.9841, 0.9666, 0.9410, 0.9176],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8984], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.9436, 0.9718, 0.9857, 0.9841, 0.9666, 0.9410, 0.9176, 0.8984],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8769])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8912], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8769])\n",
      ">>Entradas: tensor([0.9718, 0.9857, 0.9841, 0.9666, 0.9410, 0.9176, 0.8984, 0.8912],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8806])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8845], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8806])\n",
      ">>Entradas: tensor([0.9857, 0.9841, 0.9666, 0.9410, 0.9176, 0.8984, 0.8912, 0.8845],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8699])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8739], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8699])\n",
      ">>Entradas: tensor([0.9841, 0.9666, 0.9410, 0.9176, 0.8984, 0.8912, 0.8845, 0.8739],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8465])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8576], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8465])\n",
      ">>Entradas: tensor([0.9666, 0.9410, 0.9176, 0.8984, 0.8912, 0.8845, 0.8739, 0.8576],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8104])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8337], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8104])\n",
      ">>Entradas: tensor([0.9410, 0.9176, 0.8984, 0.8912, 0.8845, 0.8739, 0.8576, 0.8337],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8026])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8139], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8026])\n",
      ">>Entradas: tensor([0.9176, 0.8984, 0.8912, 0.8845, 0.8739, 0.8576, 0.8337, 0.8139],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8232])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8064], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8232])\n",
      ">>Entradas: tensor([0.8984, 0.8912, 0.8845, 0.8739, 0.8576, 0.8337, 0.8139, 0.8064],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8397])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8075], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8397])\n",
      ">>Entradas: tensor([0.8912, 0.8845, 0.8739, 0.8576, 0.8337, 0.8139, 0.8064, 0.8075],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8522])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8137], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8522])\n",
      ">>Entradas: tensor([0.8845, 0.8739, 0.8576, 0.8337, 0.8139, 0.8064, 0.8075, 0.8137],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8616])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8225], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8616])\n",
      ">>Entradas: tensor([0.8739, 0.8576, 0.8337, 0.8139, 0.8064, 0.8075, 0.8137, 0.8225],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8679])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8314], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8679])\n",
      ">>Entradas: tensor([0.8576, 0.8337, 0.8139, 0.8064, 0.8075, 0.8137, 0.8225, 0.8314],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8702])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8391], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8702])\n",
      ">>Entradas: tensor([0.8337, 0.8139, 0.8064, 0.8075, 0.8137, 0.8225, 0.8314, 0.8391],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8685])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8460], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8685])\n",
      ">>Entradas: tensor([0.8139, 0.8064, 0.8075, 0.8137, 0.8225, 0.8314, 0.8391, 0.8460],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8530])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8490], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8530])\n",
      ">>Entradas: tensor([0.8064, 0.8075, 0.8137, 0.8225, 0.8314, 0.8391, 0.8460, 0.8490],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8236])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8442], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8236])\n",
      ">>Entradas: tensor([0.8075, 0.8137, 0.8225, 0.8314, 0.8391, 0.8460, 0.8490, 0.8442],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8353], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.8137, 0.8225, 0.8314, 0.8391, 0.8460, 0.8490, 0.8442, 0.8353],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7919])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8247], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7919])\n",
      ">>Entradas: tensor([0.8225, 0.8314, 0.8391, 0.8460, 0.8490, 0.8442, 0.8353, 0.8247],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7865])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8141], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7865])\n",
      ">>Entradas: tensor([0.8314, 0.8391, 0.8460, 0.8490, 0.8442, 0.8353, 0.8247, 0.8141],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7870])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8053], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7870])\n",
      ">>Entradas: tensor([0.8391, 0.8460, 0.8490, 0.8442, 0.8353, 0.8247, 0.8141, 0.8053],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7874])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7982], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7874])\n",
      ">>Entradas: tensor([0.8460, 0.8490, 0.8442, 0.8353, 0.8247, 0.8141, 0.8053, 0.7982],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7879])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7921], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7879])\n",
      ">>Entradas: tensor([0.8490, 0.8442, 0.8353, 0.8247, 0.8141, 0.8053, 0.7982, 0.7921],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7955])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7888], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7955])\n",
      ">>Entradas: tensor([0.8442, 0.8353, 0.8247, 0.8141, 0.8053, 0.7982, 0.7921, 0.7888],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8102])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7903], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8102])\n",
      ">>Entradas: tensor([0.8353, 0.8247, 0.8141, 0.8053, 0.7982, 0.7921, 0.7888, 0.7903],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7668])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7787], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7668])\n",
      ">>Entradas: tensor([0.8247, 0.8141, 0.8053, 0.7982, 0.7921, 0.7888, 0.7903, 0.7787],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6655])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7407], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6655])\n",
      ">>Entradas: tensor([0.8141, 0.8053, 0.7982, 0.7921, 0.7888, 0.7903, 0.7787, 0.7407],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6361])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7029], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6361])\n",
      ">>Entradas: tensor([0.8053, 0.7982, 0.7921, 0.7888, 0.7903, 0.7787, 0.7407, 0.7029],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6785])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6868], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6785])\n",
      ">>Entradas: tensor([0.7982, 0.7921, 0.7888, 0.7903, 0.7787, 0.7407, 0.7029, 0.6868],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6782], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6966])\n",
      ">>Entradas: tensor([0.7921, 0.7888, 0.7903, 0.7787, 0.7407, 0.7029, 0.6868, 0.6782],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6903])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6713], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6903])\n",
      ">>Entradas: tensor([0.7888, 0.7903, 0.7787, 0.7407, 0.7029, 0.6868, 0.6782, 0.6713],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6970])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6711], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6970])\n",
      ">>Entradas: tensor([0.7903, 0.7787, 0.7407, 0.7029, 0.6868, 0.6782, 0.6713, 0.6711],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7167])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6759], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7167])\n",
      ">>Entradas: tensor([0.7787, 0.7407, 0.7029, 0.6868, 0.6782, 0.6713, 0.6711, 0.6759],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7491])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6867], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7491])\n",
      ">>Entradas: tensor([0.7407, 0.7029, 0.6868, 0.6782, 0.6713, 0.6711, 0.6759, 0.6867],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7940])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7105], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7940])\n",
      ">>Entradas: tensor([0.7029, 0.6868, 0.6782, 0.6713, 0.6711, 0.6759, 0.6867, 0.7105],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8547])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7520], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8547])\n",
      ">>Entradas: tensor([0.6868, 0.6782, 0.6713, 0.6711, 0.6759, 0.6867, 0.7105, 0.7520],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9314])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8109], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9314])\n",
      ">>Entradas: tensor([0.6782, 0.6713, 0.6711, 0.6759, 0.6867, 0.7105, 0.7520, 0.8109],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9627])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8674], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9627])\n",
      ">>Entradas: tensor([0.6713, 0.6711, 0.6759, 0.6867, 0.7105, 0.7520, 0.8109, 0.8674],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9486])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9089], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9486])\n",
      ">>Entradas: tensor([0.6711, 0.6759, 0.6867, 0.7105, 0.7520, 0.8109, 0.8674, 0.9089],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9307])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9373], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9307])\n",
      ">>Entradas: tensor([0.6759, 0.6867, 0.7105, 0.7520, 0.8109, 0.8674, 0.9089, 0.9373],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9090])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9505], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9090])\n",
      ">>Entradas: tensor([0.6867, 0.7105, 0.7520, 0.8109, 0.8674, 0.9089, 0.9373, 0.9505],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8816])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9527], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8816])\n",
      ">>Entradas: tensor([0.7105, 0.7520, 0.8109, 0.8674, 0.9089, 0.9373, 0.9505, 0.9527],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8487])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9442], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8487])\n",
      ">>Entradas: tensor([0.7520, 0.8109, 0.8674, 0.9089, 0.9373, 0.9505, 0.9527, 0.9442],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8753])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9437], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8753])\n",
      ">>Entradas: tensor([0.8109, 0.8674, 0.9089, 0.9373, 0.9505, 0.9527, 0.9442, 0.9437],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9612])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9649], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9612])\n",
      ">>Entradas: tensor([0.8674, 0.9089, 0.9373, 0.9505, 0.9527, 0.9442, 0.9437, 0.9649],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9925])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9849], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9925])\n",
      ">>Entradas: tensor([0.9089, 0.9373, 0.9505, 0.9527, 0.9442, 0.9437, 0.9649, 0.9849],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9690])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9897], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9690])\n",
      ">>Entradas: tensor([0.9373, 0.9505, 0.9527, 0.9442, 0.9437, 0.9649, 0.9849, 0.9897],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9715])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9921], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9715])\n",
      ">>Entradas: tensor([0.9505, 0.9527, 0.9442, 0.9437, 0.9649, 0.9849, 0.9897, 0.9921],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([1.])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9991], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([1.])\n",
      ">>Entradas: tensor([0.9527, 0.9442, 0.9437, 0.9649, 0.9849, 0.9897, 0.9921, 0.9991],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9953], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9801])\n",
      ">>Entradas: tensor([0.9442, 0.9437, 0.9649, 0.9849, 0.9897, 0.9921, 0.9991, 0.9953],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9729], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9117])\n",
      ">>Entradas: tensor([0.9437, 0.9649, 0.9849, 0.9897, 0.9921, 0.9991, 0.9953, 0.9729],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8911])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9525], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8911])\n",
      ">>Entradas: tensor([0.9649, 0.9849, 0.9897, 0.9921, 0.9991, 0.9953, 0.9729, 0.9525],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9181])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9436], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9181])\n",
      ">>Entradas: tensor([0.9849, 0.9897, 0.9921, 0.9991, 0.9953, 0.9729, 0.9525, 0.9436],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9450])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9411], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9450])\n",
      ">>Entradas: tensor([0.9897, 0.9921, 0.9991, 0.9953, 0.9729, 0.9525, 0.9436, 0.9411],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9718])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9544], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9718])\n",
      ">>Entradas: tensor([0.9921, 0.9991, 0.9953, 0.9729, 0.9525, 0.9436, 0.9411, 0.9544],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9829])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9613], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9829])\n",
      ">>Entradas: tensor([0.9991, 0.9953, 0.9729, 0.9525, 0.9436, 0.9411, 0.9544, 0.9613],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9783])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9645], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9783])\n",
      ">>s_original: [0.049424633383750916, 0.10789185762405396, 0.13719609379768372, 0.13733737170696259, 0.1338856965303421, 0.12684109807014465, 0.14756061136722565, 0.19604423642158508, 0.21688967943191528, 0.21009695529937744, 0.20267784595489502, 0.1946323662996292, 0.19407351315021515, 0.20100130140781403, 0.19663821160793304, 0.180984228849411, 0.16539041697978973, 0.14985674619674683, 0.15043111145496368, 0.1671135276556015, 0.20227035880088806, 0.25590160489082336, 0.29268819093704224, 0.31263017654418945, 0.31093889474868774, 0.2876143157482147, 0.28016164898872375, 0.28858086466789246, 0.28246283531188965, 0.26180753111839294, 0.2801212966442108, 0.3374040722846985, 0.3482298254966736, 0.3125985562801361, 0.34358710050582886, 0.44119545817375183, 0.521095335483551, 0.5832866430282593, 0.6089234352111816, 0.5980057120323181, 0.5945301651954651, 0.5984968543052673, 0.621354341506958, 0.6631026864051819, 0.6928724050521851, 0.7106636166572571, 0.721682071685791, 0.7259277701377869, 0.7404318451881409, 0.7651942372322083, 0.7447891235351562, 0.6792163252830505, 0.6746017932891846, 0.730945348739624, 0.7467210292816162, 0.7219287157058716, 0.7199286818504333, 0.7407209277153015, 0.7362455129623413, 0.7065023183822632, 0.6979451775550842, 0.7105739712715149, 0.7209621667861938, 0.7291097044944763, 0.7674259543418884, 0.8359109163284302, 0.8510103225708008, 0.8127241730690002, 0.7863940000534058, 0.7720199823379517, 0.8033170700073242, 0.8802852630615234, 0.8987051844596863, 0.8585767149925232, 0.8308762311935425, 0.8156037926673889, 0.8116992115974426, 0.8191625475883484, 0.8218275904655457, 0.8196942210197449, 0.817862868309021, 0.8163333535194397, 0.8005555868148804, 0.7705295085906982, 0.7426586747169495, 0.716943085193634, 0.7197051048278809, 0.7509447932243347, 0.7402781248092651, 0.6877052187919617, 0.6687695384025574, 0.683471143245697, 0.6877052187919617, 0.6814717054367065, 0.6892618536949158, 0.7110756039619446, 0.7349108457565308, 0.7607676982879639, 0.771117091178894, 0.7659589648246765, 0.7483323812484741, 0.7182371616363525, 0.708941638469696, 0.7204458117485046, 0.7706154584884644, 0.8594506978988647, 0.906541109085083, 0.9118866324424744, 0.9043355584144592, 0.8838878870010376, 0.9032153487205505, 0.9623178839683533, 0.9820588231086731, 0.96243816614151, 0.9302511811256409, 0.8854979276657104, 0.8597025871276855, 0.8528652191162109, 0.8585854768753052, 0.8768633008003235, 0.8806464076042175, 0.8699347376823425, 0.846513569355011, 0.8103827834129333, 0.8026111125946045, 0.8231984972953796, 0.8397204279899597, 0.8521769046783447, 0.8615626692771912, 0.8678776621818542, 0.8701963424682617, 0.868518590927124, 0.852988064289093, 0.8236046433448792, 0.8032509088516235, 0.7919268012046814, 0.7865023016929626, 0.7869773507118225, 0.7874362468719482, 0.7878790497779846, 0.7954531908035278, 0.8101586699485779, 0.7668473124504089, 0.665519118309021, 0.6360738277435303, 0.678511381149292, 0.6965967416763306, 0.6903298497200012, 0.6970472931861877, 0.7167490720748901, 0.7490506768226624, 0.7939522862434387, 0.8547447323799133, 0.931428074836731, 0.9627243876457214, 0.9486336708068848, 0.9307146072387695, 0.9089671969413757, 0.8816379904747009, 0.8487268090248108, 0.8752607107162476, 0.9612395763397217, 0.9925020933151245, 0.9690483212471008, 0.9715476036071777, 1.0, 0.9800636768341064, 0.9117385745048523, 0.8910858035087585, 0.9181053042411804, 0.9450165033340454, 0.9718193411827087, 0.982906699180603, 0.9782785773277283]\n",
      ">>s_pred: [-0.026368141174316406, 0.010857105255126953, 0.04973459243774414, 0.07562732696533203, 0.10172128677368164, 0.11913728713989258, 0.13490009307861328, 0.16298961639404297, 0.19571256637573242, 0.2221508026123047, 0.23871088027954102, 0.23841238021850586, 0.24056720733642578, 0.2426586151123047, 0.23273754119873047, 0.2216944694519043, 0.19197940826416016, 0.17897653579711914, 0.16497516632080078, 0.15710067749023438, 0.16283226013183594, 0.18287181854248047, 0.20928716659545898, 0.23772048950195312, 0.262601375579834, 0.2778744697570801, 0.28957033157348633, 0.30310535430908203, 0.3126044273376465, 0.3137636184692383, 0.31841516494750977, 0.3358621597290039, 0.3487687110900879, 0.3471541404724121, 0.35526037216186523, 0.38804054260253906, 0.43530797958374023, 0.49406003952026367, 0.5504722595214844, 0.5912365913391113, 0.6201601028442383, 0.599027156829834, 0.6319928169250488, 0.6675677299499512, 0.700171947479248, 0.7321000099182129, 0.7539749145507812, 0.7585430145263672, 0.7664422988891602, 0.780881404876709, 0.7855167388916016, 0.7686047554016113, 0.7486405372619629, 0.7479238510131836, 0.7467947006225586, 0.7383475303649902, 0.7333130836486816, 0.7333846092224121, 0.7284445762634277, 0.7162284851074219, 0.7073574066162109, 0.7046232223510742, 0.7046198844909668, 0.7082037925720215, 0.724057674407959, 0.7570815086364746, 0.786797046661377, 0.8000154495239258, 0.8048305511474609, 0.8037600517272949, 0.8111209869384766, 0.8406519889831543, 0.8576369285583496, 0.8707304000854492, 0.8697547912597656, 0.8590822219848633, 0.8487334251403809, 0.843050479888916, 0.8405780792236328, 0.836937427520752, 0.8318338394165039, 0.8252310752868652, 0.813652515411377, 0.7958498001098633, 0.7747917175292969, 0.751220703125, 0.7339210510253906, 0.7298932075500488, 0.7236433029174805, 0.703819751739502, 0.6838045120239258, 0.6723771095275879, 0.664604663848877, 0.6596245765686035, 0.6621189117431641, 0.6707916259765625, 0.6839942932128906, 0.7032909393310547, 0.7237825393676758, 0.7399883270263672, 0.7487068176269531, 0.7475285530090332, 0.7422170639038086, 0.7427911758422852, 0.7573122978210449, 0.8083715438842773, 0.8459792137145996, 0.876103401184082, 0.8976364135742188, 0.9052348136901855, 0.9161591529846191, 0.9435853958129883, 0.9718031883239746, 0.9857277870178223, 0.9841136932373047, 0.9665985107421875, 0.9410247802734375, 0.9175505638122559, 0.8983783721923828, 0.8911638259887695, 0.8844976425170898, 0.8738913536071777, 0.8576087951660156, 0.8337163925170898, 0.8139405250549316, 0.8064408302307129, 0.8075003623962402, 0.8137331008911133, 0.8224935531616211, 0.8314080238342285, 0.8390884399414062, 0.8459749221801758, 0.8489646911621094, 0.844240665435791, 0.8353085517883301, 0.824699878692627, 0.8140816688537598, 0.8053016662597656, 0.7981524467468262, 0.7920656204223633, 0.7888073921203613, 0.7903361320495605, 0.7787179946899414, 0.7407221794128418, 0.7029056549072266, 0.6868338584899902, 0.6782288551330566, 0.6713204383850098, 0.6711215972900391, 0.6758651733398438, 0.6867451667785645, 0.7104578018188477, 0.751950740814209, 0.8109250068664551, 0.8674168586730957, 0.9089088439941406, 0.9372797012329102, 0.9504556655883789, 0.9526681900024414, 0.944218635559082, 0.9437074661254883, 0.9649128913879395, 0.9848999977111816, 0.9897222518920898, 0.9921364784240723, 0.9990606307983398, 0.9952597618103027, 0.9729433059692383, 0.9525008201599121, 0.9435830116271973, 0.941072940826416, 0.954404354095459, 0.9613227844238281, 0.964454174041748]\n",
      "<<Perdida: 0.0016673177015036345 epoca: 5\n",
      "---Inicio de epoca: 6--\n",
      ">>Entradas: tensor([0.0503, 0.0086, 0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203])\n",
      ">>Salida: tensor([0.0494])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([-0.0075], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.0494])\n",
      ">>Entradas: tensor([ 0.0086,  0.0000,  0.0245,  0.0327,  0.0246,  0.0205,  0.0203, -0.0075],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1079])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0244], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1079])\n",
      ">>Entradas: tensor([ 0.0000,  0.0245,  0.0327,  0.0246,  0.0205,  0.0203, -0.0075,  0.0244],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1372])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0606], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1372])\n",
      ">>Entradas: tensor([ 0.0245,  0.0327,  0.0246,  0.0205,  0.0203, -0.0075,  0.0244,  0.0606],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1373])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0848], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1373])\n",
      ">>Entradas: tensor([ 0.0327,  0.0246,  0.0205,  0.0203, -0.0075,  0.0244,  0.0606,  0.0848],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1339])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1076], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1339])\n",
      ">>Entradas: tensor([ 0.0246,  0.0205,  0.0203, -0.0075,  0.0244,  0.0606,  0.0848,  0.1076],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1268])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1227], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1268])\n",
      ">>Entradas: tensor([ 0.0205,  0.0203, -0.0075,  0.0244,  0.0606,  0.0848,  0.1076,  0.1227],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1476])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1385], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1476])\n",
      ">>Entradas: tensor([ 0.0203, -0.0075,  0.0244,  0.0606,  0.0848,  0.1076,  0.1227,  0.1385],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1960])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1659], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1960])\n",
      ">>Entradas: tensor([-0.0075,  0.0244,  0.0606,  0.0848,  0.1076,  0.1227,  0.1385,  0.1659],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1965], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2169])\n",
      ">>Entradas: tensor([0.0244, 0.0606, 0.0848, 0.1076, 0.1227, 0.1385, 0.1659, 0.1965],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2101])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2206], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2101])\n",
      ">>Entradas: tensor([0.0606, 0.0848, 0.1076, 0.1227, 0.1385, 0.1659, 0.1965, 0.2206],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2027])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2356], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2027])\n",
      ">>Entradas: tensor([0.0848, 0.1076, 0.1227, 0.1385, 0.1659, 0.1965, 0.2206, 0.2356],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1946])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2422], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1946])\n",
      ">>Entradas: tensor([0.1076, 0.1227, 0.1385, 0.1659, 0.1965, 0.2206, 0.2356, 0.2422],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1941])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2435], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1941])\n",
      ">>Entradas: tensor([0.1227, 0.1385, 0.1659, 0.1965, 0.2206, 0.2356, 0.2422, 0.2435],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2010])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2442], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2010])\n",
      ">>Entradas: tensor([0.1385, 0.1659, 0.1965, 0.2206, 0.2356, 0.2422, 0.2435, 0.2442],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2426], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1966])\n",
      ">>Entradas: tensor([0.1659, 0.1965, 0.2206, 0.2356, 0.2422, 0.2435, 0.2442, 0.2426],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1810])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2352], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1810])\n",
      ">>Entradas: tensor([0.1965, 0.2206, 0.2356, 0.2422, 0.2435, 0.2442, 0.2426, 0.2352],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1654])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2219], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1654])\n",
      ">>Entradas: tensor([0.2206, 0.2356, 0.2422, 0.2435, 0.2442, 0.2426, 0.2352, 0.2219],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1499])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2035], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1499])\n",
      ">>Entradas: tensor([0.2356, 0.2422, 0.2435, 0.2442, 0.2426, 0.2352, 0.2219, 0.2035],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1504])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1861], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1504])\n",
      ">>Entradas: tensor([0.2422, 0.2435, 0.2442, 0.2426, 0.2352, 0.2219, 0.2035, 0.1861],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1671])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1754], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1671])\n",
      ">>Entradas: tensor([0.2435, 0.2442, 0.2426, 0.2352, 0.2219, 0.2035, 0.1861, 0.1754],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2023])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1784], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2023])\n",
      ">>Entradas: tensor([0.2442, 0.2426, 0.2352, 0.2219, 0.2035, 0.1861, 0.1754, 0.1784],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2559])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1948], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2559])\n",
      ">>Entradas: tensor([0.2426, 0.2352, 0.2219, 0.2035, 0.1861, 0.1754, 0.1784, 0.1948],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2927])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2188], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2927])\n",
      ">>Entradas: tensor([0.2352, 0.2219, 0.2035, 0.1861, 0.1754, 0.1784, 0.1948, 0.2188],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2444], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2219, 0.2035, 0.1861, 0.1754, 0.1784, 0.1948, 0.2188, 0.2444],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3109])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2652], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3109])\n",
      ">>Entradas: tensor([0.2035, 0.1861, 0.1754, 0.1784, 0.1948, 0.2188, 0.2444, 0.2652],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2876])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2764], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2876])\n",
      ">>Entradas: tensor([0.1861, 0.1754, 0.1784, 0.1948, 0.2188, 0.2444, 0.2652, 0.2764],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2802])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2853], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2802])\n",
      ">>Entradas: tensor([0.1754, 0.1784, 0.1948, 0.2188, 0.2444, 0.2652, 0.2764, 0.2853],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2886])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2967], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2886])\n",
      ">>Entradas: tensor([0.1784, 0.1948, 0.2188, 0.2444, 0.2652, 0.2764, 0.2853, 0.2967],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2825])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3046], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2825])\n",
      ">>Entradas: tensor([0.1948, 0.2188, 0.2444, 0.2652, 0.2764, 0.2853, 0.2967, 0.3046],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2618])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3049], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2618])\n",
      ">>Entradas: tensor([0.2188, 0.2444, 0.2652, 0.2764, 0.2853, 0.2967, 0.3046, 0.3049],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3100], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2801])\n",
      ">>Entradas: tensor([0.2444, 0.2652, 0.2764, 0.2853, 0.2967, 0.3046, 0.3049, 0.3100],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3374])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3278], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3374])\n",
      ">>Entradas: tensor([0.2652, 0.2764, 0.2853, 0.2967, 0.3046, 0.3049, 0.3100, 0.3278],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3482])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3410], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3482])\n",
      ">>Entradas: tensor([0.2764, 0.2853, 0.2967, 0.3046, 0.3049, 0.3100, 0.3278, 0.3410],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3401], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2853, 0.2967, 0.3046, 0.3049, 0.3100, 0.3278, 0.3410, 0.3401],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3436])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3496], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3436])\n",
      ">>Entradas: tensor([0.2967, 0.3046, 0.3049, 0.3100, 0.3278, 0.3410, 0.3401, 0.3496],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.4412])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3839], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.4412])\n",
      ">>Entradas: tensor([0.3046, 0.3049, 0.3100, 0.3278, 0.3410, 0.3401, 0.3496, 0.3839],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5211])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4445], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5211])\n",
      ">>Entradas: tensor([0.3049, 0.3100, 0.3278, 0.3410, 0.3401, 0.3496, 0.3839, 0.4445],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5833])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5015], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5833])\n",
      ">>Entradas: tensor([0.3100, 0.3278, 0.3410, 0.3401, 0.3496, 0.3839, 0.4445, 0.5015],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5572], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6089])\n",
      ">>Entradas: tensor([0.3278, 0.3410, 0.3401, 0.3496, 0.3839, 0.4445, 0.5015, 0.5572],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5980])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5984], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5980])\n",
      ">>Entradas: tensor([0.3410, 0.3401, 0.3496, 0.3839, 0.4445, 0.5015, 0.5572, 0.5984],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5945])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6260], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5945])\n",
      ">>Entradas: tensor([0.3401, 0.3496, 0.3839, 0.4445, 0.5015, 0.5572, 0.5984, 0.6260],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5985])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6476], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5985])\n",
      ">>Entradas: tensor([0.3496, 0.3839, 0.4445, 0.5015, 0.5572, 0.5984, 0.6260, 0.6476],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6214])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6713], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6214])\n",
      ">>Entradas: tensor([0.3839, 0.4445, 0.5015, 0.5572, 0.5984, 0.6260, 0.6476, 0.6713],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6631])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7024], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6631])\n",
      ">>Entradas: tensor([0.4445, 0.5015, 0.5572, 0.5984, 0.6260, 0.6476, 0.6713, 0.7024],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6929])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7315], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6929])\n",
      ">>Entradas: tensor([0.5015, 0.5572, 0.5984, 0.6260, 0.6476, 0.6713, 0.7024, 0.7315],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7107])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7548], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7107])\n",
      ">>Entradas: tensor([0.5572, 0.5984, 0.6260, 0.6476, 0.6713, 0.7024, 0.7315, 0.7548],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7217])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7684], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7217])\n",
      ">>Entradas: tensor([0.5984, 0.6260, 0.6476, 0.6713, 0.7024, 0.7315, 0.7548, 0.7684],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7259])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7649], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7259])\n",
      ">>Entradas: tensor([0.6260, 0.6476, 0.6713, 0.7024, 0.7315, 0.7548, 0.7684, 0.7649],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7404])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7738], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7404])\n",
      ">>Entradas: tensor([0.6476, 0.6713, 0.7024, 0.7315, 0.7548, 0.7684, 0.7649, 0.7738],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7652])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7848], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7652])\n",
      ">>Entradas: tensor([0.6713, 0.7024, 0.7315, 0.7548, 0.7684, 0.7649, 0.7738, 0.7848],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7448])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7839], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7448])\n",
      ">>Entradas: tensor([0.7024, 0.7315, 0.7548, 0.7684, 0.7649, 0.7738, 0.7848, 0.7839],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6792])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7649], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6792])\n",
      ">>Entradas: tensor([0.7315, 0.7548, 0.7684, 0.7649, 0.7738, 0.7848, 0.7839, 0.7649],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6746])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7234], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6746])\n",
      ">>Entradas: tensor([0.7548, 0.7684, 0.7649, 0.7738, 0.7848, 0.7839, 0.7649, 0.7234],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7255], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7309])\n",
      ">>Entradas: tensor([0.7684, 0.7649, 0.7738, 0.7848, 0.7839, 0.7649, 0.7234, 0.7255],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7467])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7266], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7467])\n",
      ">>Entradas: tensor([0.7649, 0.7738, 0.7848, 0.7839, 0.7649, 0.7234, 0.7255, 0.7266],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7219])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7197], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7219])\n",
      ">>Entradas: tensor([0.7738, 0.7848, 0.7839, 0.7649, 0.7234, 0.7255, 0.7266, 0.7197],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7199])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7184], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7199])\n",
      ">>Entradas: tensor([0.7848, 0.7839, 0.7649, 0.7234, 0.7255, 0.7266, 0.7197, 0.7184],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7407])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7218], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7407])\n",
      ">>Entradas: tensor([0.7839, 0.7649, 0.7234, 0.7255, 0.7266, 0.7197, 0.7184, 0.7218],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7362])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7184], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7362])\n",
      ">>Entradas: tensor([0.7649, 0.7234, 0.7255, 0.7266, 0.7197, 0.7184, 0.7218, 0.7184],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7068], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7065])\n",
      ">>Entradas: tensor([0.7234, 0.7255, 0.7266, 0.7197, 0.7184, 0.7218, 0.7184, 0.7068],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6979])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7007], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6979])\n",
      ">>Entradas: tensor([0.7255, 0.7266, 0.7197, 0.7184, 0.7218, 0.7184, 0.7068, 0.7007],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7106])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7014], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7106])\n",
      ">>Entradas: tensor([0.7266, 0.7197, 0.7184, 0.7218, 0.7184, 0.7068, 0.7007, 0.7014],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7210])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7037], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7210])\n",
      ">>Entradas: tensor([0.7197, 0.7184, 0.7218, 0.7184, 0.7068, 0.7007, 0.7014, 0.7037],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7291])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7092], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7291])\n",
      ">>Entradas: tensor([0.7184, 0.7218, 0.7184, 0.7068, 0.7007, 0.7014, 0.7037, 0.7092],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7674])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7266], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7674])\n",
      ">>Entradas: tensor([0.7218, 0.7184, 0.7068, 0.7007, 0.7014, 0.7037, 0.7092, 0.7266],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8359])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7602], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8359])\n",
      ">>Entradas: tensor([0.7184, 0.7068, 0.7007, 0.7014, 0.7037, 0.7092, 0.7266, 0.7602],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8510])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7914], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8510])\n",
      ">>Entradas: tensor([0.7068, 0.7007, 0.7014, 0.7037, 0.7092, 0.7266, 0.7602, 0.7914],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8127])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8046], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8127])\n",
      ">>Entradas: tensor([0.7007, 0.7014, 0.7037, 0.7092, 0.7266, 0.7602, 0.7914, 0.8046],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7864])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8098], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7864])\n",
      ">>Entradas: tensor([0.7014, 0.7037, 0.7092, 0.7266, 0.7602, 0.7914, 0.8046, 0.8098],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7720])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8091], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7720])\n",
      ">>Entradas: tensor([0.7037, 0.7092, 0.7266, 0.7602, 0.7914, 0.8046, 0.8098, 0.8091],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8160], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.7092, 0.7266, 0.7602, 0.7914, 0.8046, 0.8098, 0.8091, 0.8160],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8803])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8448], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8803])\n",
      ">>Entradas: tensor([0.7266, 0.7602, 0.7914, 0.8046, 0.8098, 0.8091, 0.8160, 0.8448],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8987])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8733], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8987])\n",
      ">>Entradas: tensor([0.7602, 0.7914, 0.8046, 0.8098, 0.8091, 0.8160, 0.8448, 0.8733],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8827], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.7914, 0.8046, 0.8098, 0.8091, 0.8160, 0.8448, 0.8733, 0.8827],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5582], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8309])\n",
      "ERROR: la modificacion de los pesos di√≥ un error mayor: 0.07436851412057877, se regresa al estado anterior de la red\n",
      ">>Entradas: tensor([0.8046, 0.8098, 0.8091, 0.8160, 0.8448, 0.8733, 0.8827, 0.9007],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8156])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8855], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8156])\n",
      ">>Entradas: tensor([0.8098, 0.8091, 0.8160, 0.8448, 0.8733, 0.8827, 0.9007, 0.8855],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8669], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8117])\n",
      ">>Entradas: tensor([0.8091, 0.8160, 0.8448, 0.8733, 0.8827, 0.9007, 0.8855, 0.8669],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8192])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8579], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8192])\n",
      ">>Entradas: tensor([0.8160, 0.8448, 0.8733, 0.8827, 0.9007, 0.8855, 0.8669, 0.8579],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8218])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8513], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8218])\n",
      ">>Entradas: tensor([0.8448, 0.8733, 0.8827, 0.9007, 0.8855, 0.8669, 0.8579, 0.8513],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8029], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8197])\n",
      ">>Entradas: tensor([0.8733, 0.8827, 0.9007, 0.8855, 0.8669, 0.8579, 0.8513, 0.8029],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8179])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8061], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8179])\n",
      ">>Entradas: tensor([0.8827, 0.9007, 0.8855, 0.8669, 0.8579, 0.8513, 0.8029, 0.8061],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8163])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8045], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8163])\n",
      ">>Entradas: tensor([0.9007, 0.8855, 0.8669, 0.8579, 0.8513, 0.8029, 0.8061, 0.8045],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8006])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7934], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8006])\n",
      ">>Entradas: tensor([0.8855, 0.8669, 0.8579, 0.8513, 0.8029, 0.8061, 0.8045, 0.7934],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7705])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7780], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7705])\n",
      ">>Entradas: tensor([0.8669, 0.8579, 0.8513, 0.8029, 0.8061, 0.8045, 0.7934, 0.7780],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7427])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7607], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7427])\n",
      ">>Entradas: tensor([0.8579, 0.8513, 0.8029, 0.8061, 0.8045, 0.7934, 0.7780, 0.7607],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7367], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7169])\n",
      ">>Entradas: tensor([0.8513, 0.8029, 0.8061, 0.8045, 0.7934, 0.7780, 0.7607, 0.7367],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7188], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7197])\n",
      ">>Entradas: tensor([0.8029, 0.8061, 0.8045, 0.7934, 0.7780, 0.7607, 0.7367, 0.7188],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7509])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7183], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7509])\n",
      ">>Entradas: tensor([0.8061, 0.8045, 0.7934, 0.7780, 0.7607, 0.7367, 0.7188, 0.7183],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7403])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7168], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7403])\n",
      ">>Entradas: tensor([0.8045, 0.7934, 0.7780, 0.7607, 0.7367, 0.7188, 0.7183, 0.7168],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6996], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.7934, 0.7780, 0.7607, 0.7367, 0.7188, 0.7183, 0.7168, 0.6996],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6688])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6818], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6688])\n",
      ">>Entradas: tensor([0.7780, 0.7607, 0.7367, 0.7188, 0.7183, 0.7168, 0.6996, 0.6818],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6835])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6722], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6835])\n",
      ">>Entradas: tensor([0.7607, 0.7367, 0.7188, 0.7183, 0.7168, 0.6996, 0.6818, 0.6722],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6687], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.7367, 0.7188, 0.7183, 0.7168, 0.6996, 0.6818, 0.6722, 0.6687],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6815])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6630], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6815])\n",
      ">>Entradas: tensor([0.7188, 0.7183, 0.7168, 0.6996, 0.6818, 0.6722, 0.6687, 0.6630],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6893])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6651], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6893])\n",
      ">>Entradas: tensor([0.7183, 0.7168, 0.6996, 0.6818, 0.6722, 0.6687, 0.6630, 0.6651],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7111])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6742], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7111])\n",
      ">>Entradas: tensor([0.7168, 0.6996, 0.6818, 0.6722, 0.6687, 0.6630, 0.6651, 0.6742],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7349])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6870], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7349])\n",
      ">>Entradas: tensor([0.6996, 0.6818, 0.6722, 0.6687, 0.6630, 0.6651, 0.6742, 0.6870],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7608])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7056], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7608])\n",
      ">>Entradas: tensor([0.6818, 0.6722, 0.6687, 0.6630, 0.6651, 0.6742, 0.6870, 0.7056],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7711])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7259], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7711])\n",
      ">>Entradas: tensor([0.6722, 0.6687, 0.6630, 0.6651, 0.6742, 0.6870, 0.7056, 0.7259],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7660])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7419], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7660])\n",
      ">>Entradas: tensor([0.6687, 0.6630, 0.6651, 0.6742, 0.6870, 0.7056, 0.7259, 0.7419],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7483])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7502], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7483])\n",
      ">>Entradas: tensor([0.6630, 0.6651, 0.6742, 0.6870, 0.7056, 0.7259, 0.7419, 0.7502],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7182])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7488], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7182])\n",
      ">>Entradas: tensor([0.6651, 0.6742, 0.6870, 0.7056, 0.7259, 0.7419, 0.7502, 0.7488],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7454], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7089])\n",
      ">>Entradas: tensor([0.6742, 0.6870, 0.7056, 0.7259, 0.7419, 0.7502, 0.7488, 0.7454],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7204])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7456], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7204])\n",
      ">>Entradas: tensor([0.6870, 0.7056, 0.7259, 0.7419, 0.7502, 0.7488, 0.7454, 0.7456],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7706])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7600], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7706])\n",
      ">>Entradas: tensor([0.7056, 0.7259, 0.7419, 0.7502, 0.7488, 0.7454, 0.7456, 0.7600],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8595])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7969], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8595])\n",
      ">>Entradas: tensor([0.7259, 0.7419, 0.7502, 0.7488, 0.7454, 0.7456, 0.7600, 0.7969],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8384], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9065])\n",
      ">>Entradas: tensor([0.7419, 0.7502, 0.7488, 0.7454, 0.7456, 0.7600, 0.7969, 0.8384],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9119])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8708], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9119])\n",
      ">>Entradas: tensor([0.7502, 0.7488, 0.7454, 0.7456, 0.7600, 0.7969, 0.8384, 0.8708],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9043])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8932], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9043])\n",
      ">>Entradas: tensor([0.7488, 0.7454, 0.7456, 0.7600, 0.7969, 0.8384, 0.8708, 0.8932],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8839])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9034], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8839])\n",
      ">>Entradas: tensor([0.7454, 0.7456, 0.7600, 0.7969, 0.8384, 0.8708, 0.8932, 0.9034],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9032])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9164], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9032])\n",
      ">>Entradas: tensor([0.7456, 0.7600, 0.7969, 0.8384, 0.8708, 0.8932, 0.9034, 0.9164],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9623])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9451], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9623])\n",
      ">>Entradas: tensor([0.7600, 0.7969, 0.8384, 0.8708, 0.8932, 0.9034, 0.9164, 0.9451],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9821])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9740], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9821])\n",
      ">>Entradas: tensor([0.7969, 0.8384, 0.8708, 0.8932, 0.9034, 0.9164, 0.9451, 0.9740],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9624])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9897], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9624])\n",
      ">>Entradas: tensor([0.8384, 0.8708, 0.8932, 0.9034, 0.9164, 0.9451, 0.9740, 0.9897],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9303])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9894], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9303])\n",
      ">>Entradas: tensor([0.8708, 0.8932, 0.9034, 0.9164, 0.9451, 0.9740, 0.9897, 0.9894],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8855])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9721], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8855])\n",
      ">>Entradas: tensor([0.8932, 0.9034, 0.9164, 0.9451, 0.9740, 0.9897, 0.9894, 0.9721],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8597])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9466], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8597])\n",
      ">>Entradas: tensor([0.9034, 0.9164, 0.9451, 0.9740, 0.9897, 0.9894, 0.9721, 0.9466],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8529])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9232], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8529])\n",
      ">>Entradas: tensor([0.9164, 0.9451, 0.9740, 0.9897, 0.9894, 0.9721, 0.9466, 0.9232],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9043], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.9451, 0.9740, 0.9897, 0.9894, 0.9721, 0.9466, 0.9232, 0.9043],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8769])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8961], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8769])\n",
      ">>Entradas: tensor([0.9740, 0.9897, 0.9894, 0.9721, 0.9466, 0.9232, 0.9043, 0.8961],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8806])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8883], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8806])\n",
      ">>Entradas: tensor([0.9897, 0.9894, 0.9721, 0.9466, 0.9232, 0.9043, 0.8961, 0.8883],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8699])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8761], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8699])\n",
      ">>Entradas: tensor([0.9894, 0.9721, 0.9466, 0.9232, 0.9043, 0.8961, 0.8883, 0.8761],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8465])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8579], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8465])\n",
      ">>Entradas: tensor([0.9721, 0.9466, 0.9232, 0.9043, 0.8961, 0.8883, 0.8761, 0.8579],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8104])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8325], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8104])\n",
      ">>Entradas: tensor([0.9466, 0.9232, 0.9043, 0.8961, 0.8883, 0.8761, 0.8579, 0.8325],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8026])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8113], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8026])\n",
      ">>Entradas: tensor([0.9232, 0.9043, 0.8961, 0.8883, 0.8761, 0.8579, 0.8325, 0.8113],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8232])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8031], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8232])\n",
      ">>Entradas: tensor([0.9043, 0.8961, 0.8883, 0.8761, 0.8579, 0.8325, 0.8113, 0.8031],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8397])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8037], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8397])\n",
      ">>Entradas: tensor([0.8961, 0.8883, 0.8761, 0.8579, 0.8325, 0.8113, 0.8031, 0.8037],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8522])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8095], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8522])\n",
      ">>Entradas: tensor([0.8883, 0.8761, 0.8579, 0.8325, 0.8113, 0.8031, 0.8037, 0.8095],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8616])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8179], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8616])\n",
      ">>Entradas: tensor([0.8761, 0.8579, 0.8325, 0.8113, 0.8031, 0.8037, 0.8095, 0.8179],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8679])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8265], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8679])\n",
      ">>Entradas: tensor([0.8579, 0.8325, 0.8113, 0.8031, 0.8037, 0.8095, 0.8179, 0.8265],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8702])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8343], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8702])\n",
      ">>Entradas: tensor([0.8325, 0.8113, 0.8031, 0.8037, 0.8095, 0.8179, 0.8265, 0.8343],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8685])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8418], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8685])\n",
      ">>Entradas: tensor([0.8113, 0.8031, 0.8037, 0.8095, 0.8179, 0.8265, 0.8343, 0.8418],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8530])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8458], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8530])\n",
      ">>Entradas: tensor([0.8031, 0.8037, 0.8095, 0.8179, 0.8265, 0.8343, 0.8418, 0.8458],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8236])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8423], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8236])\n",
      ">>Entradas: tensor([0.8037, 0.8095, 0.8179, 0.8265, 0.8343, 0.8418, 0.8458, 0.8423],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8345], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.8095, 0.8179, 0.8265, 0.8343, 0.8418, 0.8458, 0.8423, 0.8345],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7919])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8249], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7919])\n",
      ">>Entradas: tensor([0.8179, 0.8265, 0.8343, 0.8418, 0.8458, 0.8423, 0.8345, 0.8249],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7865])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8148], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7865])\n",
      ">>Entradas: tensor([0.8265, 0.8343, 0.8418, 0.8458, 0.8423, 0.8345, 0.8249, 0.8148],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7870])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8064], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7870])\n",
      ">>Entradas: tensor([0.8343, 0.8418, 0.8458, 0.8423, 0.8345, 0.8249, 0.8148, 0.8064],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7874])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7994], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7874])\n",
      ">>Entradas: tensor([0.8418, 0.8458, 0.8423, 0.8345, 0.8249, 0.8148, 0.8064, 0.7994],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7879])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7931], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7879])\n",
      ">>Entradas: tensor([0.8458, 0.8423, 0.8345, 0.8249, 0.8148, 0.8064, 0.7994, 0.7931],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7955])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7895], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7955])\n",
      ">>Entradas: tensor([0.8423, 0.8345, 0.8249, 0.8148, 0.8064, 0.7994, 0.7931, 0.7895],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8102])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7906], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8102])\n",
      ">>Entradas: tensor([0.8345, 0.8249, 0.8148, 0.8064, 0.7994, 0.7931, 0.7895, 0.7906],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7668])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7785], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7668])\n",
      ">>Entradas: tensor([0.8249, 0.8148, 0.8064, 0.7994, 0.7931, 0.7895, 0.7906, 0.7785],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6655])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7401], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6655])\n",
      ">>Entradas: tensor([0.8148, 0.8064, 0.7994, 0.7931, 0.7895, 0.7906, 0.7785, 0.7401],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6361])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7023], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6361])\n",
      ">>Entradas: tensor([0.8064, 0.7994, 0.7931, 0.7895, 0.7906, 0.7785, 0.7401, 0.7023],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6785])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6853], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6785])\n",
      ">>Entradas: tensor([0.7994, 0.7931, 0.7895, 0.7906, 0.7785, 0.7401, 0.7023, 0.6853],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6762], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6966])\n",
      ">>Entradas: tensor([0.7931, 0.7895, 0.7906, 0.7785, 0.7401, 0.7023, 0.6853, 0.6762],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6903])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6688], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6903])\n",
      ">>Entradas: tensor([0.7895, 0.7906, 0.7785, 0.7401, 0.7023, 0.6853, 0.6762, 0.6688],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6970])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6677], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6970])\n",
      ">>Entradas: tensor([0.7906, 0.7785, 0.7401, 0.7023, 0.6853, 0.6762, 0.6688, 0.6677],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7167])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6713], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7167])\n",
      ">>Entradas: tensor([0.7785, 0.7401, 0.7023, 0.6853, 0.6762, 0.6688, 0.6677, 0.6713],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7491])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6816], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7491])\n",
      ">>Entradas: tensor([0.7401, 0.7023, 0.6853, 0.6762, 0.6688, 0.6677, 0.6713, 0.6816],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7940])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7053], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7940])\n",
      ">>Entradas: tensor([0.7023, 0.6853, 0.6762, 0.6688, 0.6677, 0.6713, 0.6816, 0.7053],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8547])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7474], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8547])\n",
      ">>Entradas: tensor([0.6853, 0.6762, 0.6688, 0.6677, 0.6713, 0.6816, 0.7053, 0.7474],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9314])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8076], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9314])\n",
      ">>Entradas: tensor([0.6762, 0.6688, 0.6677, 0.6713, 0.6816, 0.7053, 0.7474, 0.8076],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9627])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8660], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9627])\n",
      ">>Entradas: tensor([0.6688, 0.6677, 0.6713, 0.6816, 0.7053, 0.7474, 0.8076, 0.8660],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9486])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9094], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9486])\n",
      ">>Entradas: tensor([0.6677, 0.6713, 0.6816, 0.7053, 0.7474, 0.8076, 0.8660, 0.9094],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9307])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9396], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9307])\n",
      ">>Entradas: tensor([0.6713, 0.6816, 0.7053, 0.7474, 0.8076, 0.8660, 0.9094, 0.9396],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9090])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9543], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9090])\n",
      ">>Entradas: tensor([0.6816, 0.7053, 0.7474, 0.8076, 0.8660, 0.9094, 0.9396, 0.9543],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8816])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9589], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8816])\n",
      ">>Entradas: tensor([0.7053, 0.7474, 0.8076, 0.8660, 0.9094, 0.9396, 0.9543, 0.9589],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8487])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9523], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8487])\n",
      ">>Entradas: tensor([0.7474, 0.8076, 0.8660, 0.9094, 0.9396, 0.9543, 0.9589, 0.9523],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8753])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9531], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8753])\n",
      ">>Entradas: tensor([0.8076, 0.8660, 0.9094, 0.9396, 0.9543, 0.9589, 0.9523, 0.9531],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9612])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9744], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9612])\n",
      ">>Entradas: tensor([0.8660, 0.9094, 0.9396, 0.9543, 0.9589, 0.9523, 0.9531, 0.9744],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9925])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9941], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9925])\n",
      ">>Entradas: tensor([0.9094, 0.9396, 0.9543, 0.9589, 0.9523, 0.9531, 0.9744, 0.9941],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9690])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9978], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9690])\n",
      ">>Entradas: tensor([0.9396, 0.9543, 0.9589, 0.9523, 0.9531, 0.9744, 0.9941, 0.9978],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9715])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9987], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9715])\n",
      ">>Entradas: tensor([0.9543, 0.9589, 0.9523, 0.9531, 0.9744, 0.9941, 0.9978, 0.9987],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([1.])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0040], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([1.])\n",
      ">>Entradas: tensor([0.9589, 0.9523, 0.9531, 0.9744, 0.9941, 0.9978, 0.9987, 1.0040],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9991], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9801])\n",
      ">>Entradas: tensor([0.9523, 0.9531, 0.9744, 0.9941, 0.9978, 0.9987, 1.0040, 0.9991],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9762], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9117])\n",
      ">>Entradas: tensor([0.9531, 0.9744, 0.9941, 0.9978, 0.9987, 1.0040, 0.9991, 0.9762],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8911])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9549], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8911])\n",
      ">>Entradas: tensor([0.9744, 0.9941, 0.9978, 0.9987, 1.0040, 0.9991, 0.9762, 0.9549],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9181])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9447], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9181])\n",
      ">>Entradas: tensor([0.9941, 0.9978, 0.9987, 1.0040, 0.9991, 0.9762, 0.9549, 0.9447],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9450])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9413], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9450])\n",
      ">>Entradas: tensor([0.9978, 0.9987, 1.0040, 0.9991, 0.9762, 0.9549, 0.9447, 0.9413],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9718])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9465], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9718])\n",
      ">>Entradas: tensor([0.9987, 1.0040, 0.9991, 0.9762, 0.9549, 0.9447, 0.9413, 0.9465],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9829])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9545], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9829])\n",
      ">>Entradas: tensor([1.0040, 0.9991, 0.9762, 0.9549, 0.9447, 0.9413, 0.9465, 0.9545],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9783])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9581], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9783])\n",
      ">>s_original: [0.049424633383750916, 0.10789185762405396, 0.13719609379768372, 0.13733737170696259, 0.1338856965303421, 0.12684109807014465, 0.14756061136722565, 0.19604423642158508, 0.21688967943191528, 0.21009695529937744, 0.20267784595489502, 0.1946323662996292, 0.19407351315021515, 0.20100130140781403, 0.19663821160793304, 0.180984228849411, 0.16539041697978973, 0.14985674619674683, 0.15043111145496368, 0.1671135276556015, 0.20227035880088806, 0.25590160489082336, 0.29268819093704224, 0.31263017654418945, 0.31093889474868774, 0.2876143157482147, 0.28016164898872375, 0.28858086466789246, 0.28246283531188965, 0.26180753111839294, 0.2801212966442108, 0.3374040722846985, 0.3482298254966736, 0.3125985562801361, 0.34358710050582886, 0.44119545817375183, 0.521095335483551, 0.5832866430282593, 0.6089234352111816, 0.5980057120323181, 0.5945301651954651, 0.5984968543052673, 0.621354341506958, 0.6631026864051819, 0.6928724050521851, 0.7106636166572571, 0.721682071685791, 0.7259277701377869, 0.7404318451881409, 0.7651942372322083, 0.7447891235351562, 0.6792163252830505, 0.6746017932891846, 0.730945348739624, 0.7467210292816162, 0.7219287157058716, 0.7199286818504333, 0.7407209277153015, 0.7362455129623413, 0.7065023183822632, 0.6979451775550842, 0.7105739712715149, 0.7209621667861938, 0.7291097044944763, 0.7674259543418884, 0.8359109163284302, 0.8510103225708008, 0.8127241730690002, 0.7863940000534058, 0.7720199823379517, 0.8033170700073242, 0.8802852630615234, 0.8987051844596863, 0.8585767149925232, 0.8308762311935425, 0.8156037926673889, 0.8116992115974426, 0.8191625475883484, 0.8218275904655457, 0.8196942210197449, 0.817862868309021, 0.8163333535194397, 0.8005555868148804, 0.7705295085906982, 0.7426586747169495, 0.716943085193634, 0.7197051048278809, 0.7509447932243347, 0.7402781248092651, 0.6877052187919617, 0.6687695384025574, 0.683471143245697, 0.6877052187919617, 0.6814717054367065, 0.6892618536949158, 0.7110756039619446, 0.7349108457565308, 0.7607676982879639, 0.771117091178894, 0.7659589648246765, 0.7483323812484741, 0.7182371616363525, 0.708941638469696, 0.7204458117485046, 0.7706154584884644, 0.8594506978988647, 0.906541109085083, 0.9118866324424744, 0.9043355584144592, 0.8838878870010376, 0.9032153487205505, 0.9623178839683533, 0.9820588231086731, 0.96243816614151, 0.9302511811256409, 0.8854979276657104, 0.8597025871276855, 0.8528652191162109, 0.8585854768753052, 0.8768633008003235, 0.8806464076042175, 0.8699347376823425, 0.846513569355011, 0.8103827834129333, 0.8026111125946045, 0.8231984972953796, 0.8397204279899597, 0.8521769046783447, 0.8615626692771912, 0.8678776621818542, 0.8701963424682617, 0.868518590927124, 0.852988064289093, 0.8236046433448792, 0.8032509088516235, 0.7919268012046814, 0.7865023016929626, 0.7869773507118225, 0.7874362468719482, 0.7878790497779846, 0.7954531908035278, 0.8101586699485779, 0.7668473124504089, 0.665519118309021, 0.6360738277435303, 0.678511381149292, 0.6965967416763306, 0.6903298497200012, 0.6970472931861877, 0.7167490720748901, 0.7490506768226624, 0.7939522862434387, 0.8547447323799133, 0.931428074836731, 0.9627243876457214, 0.9486336708068848, 0.9307146072387695, 0.9089671969413757, 0.8816379904747009, 0.8487268090248108, 0.8752607107162476, 0.9612395763397217, 0.9925020933151245, 0.9690483212471008, 0.9715476036071777, 1.0, 0.9800636768341064, 0.9117385745048523, 0.8910858035087585, 0.9181053042411804, 0.9450165033340454, 0.9718193411827087, 0.982906699180603, 0.9782785773277283]\n",
      ">>s_pred: [-0.007548809051513672, 0.024390697479248047, 0.06059741973876953, 0.08480501174926758, 0.10764646530151367, 0.12274360656738281, 0.13852357864379883, 0.1658768653869629, 0.1965012550354004, 0.2205829620361328, 0.2356109619140625, 0.24217557907104492, 0.2434978485107422, 0.24419784545898438, 0.2425694465637207, 0.2351675033569336, 0.22187423706054688, 0.20349788665771484, 0.18613004684448242, 0.1753854751586914, 0.17843961715698242, 0.19477319717407227, 0.21878480911254883, 0.24442005157470703, 0.2652468681335449, 0.2763848304748535, 0.28525590896606445, 0.2966599464416504, 0.3046283721923828, 0.30486154556274414, 0.30996227264404297, 0.3277897834777832, 0.341036319732666, 0.3401041030883789, 0.34955883026123047, 0.3838992118835449, 0.44449853897094727, 0.5014615058898926, 0.5571894645690918, 0.5983834266662598, 0.6260032653808594, 0.647648811340332, 0.6713156700134277, 0.7023944854736328, 0.7314548492431641, 0.7548427581787109, 0.768364429473877, 0.7649083137512207, 0.7737956047058105, 0.7847938537597656, 0.7839212417602539, 0.7648582458496094, 0.7233948707580566, 0.7255206108093262, 0.7265834808349609, 0.7197265625, 0.7183866500854492, 0.7217545509338379, 0.7184486389160156, 0.7068219184875488, 0.7007417678833008, 0.701446533203125, 0.7036666870117188, 0.7091960906982422, 0.7266011238098145, 0.7602400779724121, 0.7913556098937988, 0.8045654296875, 0.8097982406616211, 0.8090720176696777, 0.8160486221313477, 0.844792366027832, 0.8732824325561523, 0.8827023506164551, 0.9006719589233398, 0.8855352401733398, 0.8668637275695801, 0.857947826385498, 0.8513379096984863, 0.8028650283813477, 0.8060708045959473, 0.8045024871826172, 0.7934069633483887, 0.7780485153198242, 0.7607464790344238, 0.7366542816162109, 0.7188315391540527, 0.7182960510253906, 0.7168383598327637, 0.6995830535888672, 0.6818313598632812, 0.6722226142883301, 0.6687192916870117, 0.6629934310913086, 0.6651082038879395, 0.6741700172424316, 0.68695068359375, 0.7056317329406738, 0.7259402275085449, 0.7418985366821289, 0.7502083778381348, 0.7487897872924805, 0.7453508377075195, 0.7456302642822266, 0.7599611282348633, 0.7969303131103516, 0.8383746147155762, 0.8708138465881348, 0.8931708335876465, 0.9033932685852051, 0.9163661003112793, 0.9450569152832031, 0.9740209579467773, 0.98974609375, 0.989410400390625, 0.9720931053161621, 0.9466395378112793, 0.9232335090637207, 0.9043326377868652, 0.8961057662963867, 0.8882522583007812, 0.8760991096496582, 0.8578672409057617, 0.832465648651123, 0.8113455772399902, 0.8031277656555176, 0.8036837577819824, 0.809506893157959, 0.817901611328125, 0.8264937400817871, 0.8342599868774414, 0.8418326377868652, 0.8458080291748047, 0.8422846794128418, 0.834475040435791, 0.824854850769043, 0.8148293495178223, 0.806401252746582, 0.7993860244750977, 0.793114185333252, 0.7894902229309082, 0.7905616760253906, 0.7785110473632812, 0.7400908470153809, 0.7022981643676758, 0.6852731704711914, 0.6761817932128906, 0.6688456535339355, 0.6676840782165527, 0.6713352203369141, 0.6815633773803711, 0.705291748046875, 0.7473645210266113, 0.8075904846191406, 0.8659605979919434, 0.9093976020812988, 0.9395585060119629, 0.9543042182922363, 0.9589123725891113, 0.9523463249206543, 0.9530558586120605, 0.9743895530700684, 0.9941082000732422, 0.9978313446044922, 0.9986605644226074, 1.0040316581726074, 0.9991254806518555, 0.9762463569641113, 0.9548683166503906, 0.9447097778320312, 0.9412927627563477, 0.9465203285217285, 0.9544801712036133, 0.9580721855163574]\n",
      "<<Perdida: 0.0017916992073878646 epoca: 6\n",
      "---Inicio de epoca: 7--\n",
      ">>Entradas: tensor([0.0503, 0.0086, 0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203])\n",
      ">>Salida: tensor([0.0494])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.6231], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.0494])\n",
      "ERROR: la modificacion de los pesos di√≥ un error mayor: 2.476327419281006, se regresa al estado anterior de la red\n",
      ">>Entradas: tensor([ 0.0086,  0.0000,  0.0245,  0.0327,  0.0246,  0.0205,  0.0203, -0.1897],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1079])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([-0.1101], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1079])\n",
      ">>Entradas: tensor([ 0.0000,  0.0245,  0.0327,  0.0246,  0.0205,  0.0203, -0.1897, -0.1101],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1372])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([-0.0469], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1372])\n",
      ">>Entradas: tensor([ 0.0245,  0.0327,  0.0246,  0.0205,  0.0203, -0.1897, -0.1101, -0.0469],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1373])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([-0.0094], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1373])\n",
      ">>Entradas: tensor([ 0.0327,  0.0246,  0.0205,  0.0203, -0.1897, -0.1101, -0.0469, -0.0094],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1339])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0441], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1339])\n",
      ">>Entradas: tensor([ 0.0246,  0.0205,  0.0203, -0.1897, -0.1101, -0.0469, -0.0094,  0.0441],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1268])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0762], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1268])\n",
      ">>Entradas: tensor([ 0.0205,  0.0203, -0.1897, -0.1101, -0.0469, -0.0094,  0.0441,  0.0762],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1476])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0929], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1476])\n",
      ">>Entradas: tensor([ 0.0203, -0.1897, -0.1101, -0.0469, -0.0094,  0.0441,  0.0762,  0.0929],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1960])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1229], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1960])\n",
      ">>Entradas: tensor([-0.1897, -0.1101, -0.0469, -0.0094,  0.0441,  0.0762,  0.0929,  0.1229],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1689], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2169])\n",
      ">>Entradas: tensor([-0.1101, -0.0469, -0.0094,  0.0441,  0.0762,  0.0929,  0.1229,  0.1689],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2101])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2118], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2101])\n",
      ">>Entradas: tensor([-0.0469, -0.0094,  0.0441,  0.0762,  0.0929,  0.1229,  0.1689,  0.2118],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2027])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2393], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2027])\n",
      ">>Entradas: tensor([-0.0094,  0.0441,  0.0762,  0.0929,  0.1229,  0.1689,  0.2118,  0.2393],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1946])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2564], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1946])\n",
      ">>Entradas: tensor([0.0441, 0.0762, 0.0929, 0.1229, 0.1689, 0.2118, 0.2393, 0.2564],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1941])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2639], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1941])\n",
      ">>Entradas: tensor([0.0762, 0.0929, 0.1229, 0.1689, 0.2118, 0.2393, 0.2564, 0.2639],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2010])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2657], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2010])\n",
      ">>Entradas: tensor([0.0929, 0.1229, 0.1689, 0.2118, 0.2393, 0.2564, 0.2639, 0.2657],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2648], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1966])\n",
      ">>Entradas: tensor([0.1229, 0.1689, 0.2118, 0.2393, 0.2564, 0.2639, 0.2657, 0.2648],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1810])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2584], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1810])\n",
      ">>Entradas: tensor([0.1689, 0.2118, 0.2393, 0.2564, 0.2639, 0.2657, 0.2648, 0.2584],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1654])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2457], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1654])\n",
      ">>Entradas: tensor([0.2118, 0.2393, 0.2564, 0.2639, 0.2657, 0.2648, 0.2584, 0.2457],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1499])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2260], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1499])\n",
      ">>Entradas: tensor([0.2393, 0.2564, 0.2639, 0.2657, 0.2648, 0.2584, 0.2457, 0.2260],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1504])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2045], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1504])\n",
      ">>Entradas: tensor([0.2564, 0.2639, 0.2657, 0.2648, 0.2584, 0.2457, 0.2260, 0.2045],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1671])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1902], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1671])\n",
      ">>Entradas: tensor([0.2639, 0.2657, 0.2648, 0.2584, 0.2457, 0.2260, 0.2045, 0.1902],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2023])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1873], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2023])\n",
      ">>Entradas: tensor([0.2657, 0.2648, 0.2584, 0.2457, 0.2260, 0.2045, 0.1902, 0.1873],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2559])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2002], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2559])\n",
      ">>Entradas: tensor([0.2648, 0.2584, 0.2457, 0.2260, 0.2045, 0.1902, 0.1873, 0.2002],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2927])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2214], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2927])\n",
      ">>Entradas: tensor([0.2584, 0.2457, 0.2260, 0.2045, 0.1902, 0.1873, 0.2002, 0.2214],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2442], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2457, 0.2260, 0.2045, 0.1902, 0.1873, 0.2002, 0.2214, 0.2442],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3109])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2622], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3109])\n",
      ">>Entradas: tensor([0.2260, 0.2045, 0.1902, 0.1873, 0.2002, 0.2214, 0.2442, 0.2622],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2876])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2708], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2876])\n",
      ">>Entradas: tensor([0.2045, 0.1902, 0.1873, 0.2002, 0.2214, 0.2442, 0.2622, 0.2708],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2802])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2777], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2802])\n",
      ">>Entradas: tensor([0.1902, 0.1873, 0.2002, 0.2214, 0.2442, 0.2622, 0.2708, 0.2777],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2886])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2881], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2886])\n",
      ">>Entradas: tensor([0.1873, 0.2002, 0.2214, 0.2442, 0.2622, 0.2708, 0.2777, 0.2881],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2825])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2962], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2825])\n",
      ">>Entradas: tensor([0.2002, 0.2214, 0.2442, 0.2622, 0.2708, 0.2777, 0.2881, 0.2962],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2618])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2976], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2618])\n",
      ">>Entradas: tensor([0.2214, 0.2442, 0.2622, 0.2708, 0.2777, 0.2881, 0.2962, 0.2976],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3036], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2801])\n",
      ">>Entradas: tensor([0.2442, 0.2622, 0.2708, 0.2777, 0.2881, 0.2962, 0.2976, 0.3036],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3374])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3225], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3374])\n",
      ">>Entradas: tensor([0.2622, 0.2708, 0.2777, 0.2881, 0.2962, 0.2976, 0.3036, 0.3225],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3482])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3371], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3482])\n",
      ">>Entradas: tensor([0.2708, 0.2777, 0.2881, 0.2962, 0.2976, 0.3036, 0.3225, 0.3371],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3375], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2777, 0.2881, 0.2962, 0.2976, 0.3036, 0.3225, 0.3371, 0.3375],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3436])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3479], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3436])\n",
      ">>Entradas: tensor([0.2881, 0.2962, 0.2976, 0.3036, 0.3225, 0.3371, 0.3375, 0.3479],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.4412])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3832], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.4412])\n",
      ">>Entradas: tensor([0.2962, 0.2976, 0.3036, 0.3225, 0.3371, 0.3375, 0.3479, 0.3832],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5211])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4329], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5211])\n",
      ">>Entradas: tensor([0.2976, 0.3036, 0.3225, 0.3371, 0.3375, 0.3479, 0.3832, 0.4329],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5833])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4923], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5833])\n",
      ">>Entradas: tensor([0.3036, 0.3225, 0.3371, 0.3375, 0.3479, 0.3832, 0.4329, 0.4923],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5498], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6089])\n",
      ">>Entradas: tensor([0.3225, 0.3371, 0.3375, 0.3479, 0.3832, 0.4329, 0.4923, 0.5498],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5980])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5912], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5980])\n",
      ">>Entradas: tensor([0.3371, 0.3375, 0.3479, 0.3832, 0.4329, 0.4923, 0.5498, 0.5912],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5945])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6208], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5945])\n",
      ">>Entradas: tensor([0.3375, 0.3479, 0.3832, 0.4329, 0.4923, 0.5498, 0.5912, 0.6208],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5985])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6451], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5985])\n",
      ">>Entradas: tensor([0.3479, 0.3832, 0.4329, 0.4923, 0.5498, 0.5912, 0.6208, 0.6451],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6214])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6715], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6214])\n",
      ">>Entradas: tensor([0.3832, 0.4329, 0.4923, 0.5498, 0.5912, 0.6208, 0.6451, 0.6715],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6631])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6976], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6631])\n",
      ">>Entradas: tensor([0.4329, 0.4923, 0.5498, 0.5912, 0.6208, 0.6451, 0.6715, 0.6976],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6929])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7311], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6929])\n",
      ">>Entradas: tensor([0.4923, 0.5498, 0.5912, 0.6208, 0.6451, 0.6715, 0.6976, 0.7311],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7107])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7563], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7107])\n",
      ">>Entradas: tensor([0.5498, 0.5912, 0.6208, 0.6451, 0.6715, 0.6976, 0.7311, 0.7563],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7217])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7607], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7217])\n",
      ">>Entradas: tensor([0.5912, 0.6208, 0.6451, 0.6715, 0.6976, 0.7311, 0.7563, 0.7607],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7259])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7729], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7259])\n",
      ">>Entradas: tensor([0.6208, 0.6451, 0.6715, 0.6976, 0.7311, 0.7563, 0.7607, 0.7729],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7404])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7816], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7404])\n",
      ">>Entradas: tensor([0.6451, 0.6715, 0.6976, 0.7311, 0.7563, 0.7607, 0.7729, 0.7816],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7652])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7923], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7652])\n",
      ">>Entradas: tensor([0.6715, 0.6976, 0.7311, 0.7563, 0.7607, 0.7729, 0.7816, 0.7923],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7448])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7880], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7448])\n",
      ">>Entradas: tensor([0.6976, 0.7311, 0.7563, 0.7607, 0.7729, 0.7816, 0.7923, 0.7880],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6792])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7697], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6792])\n",
      ">>Entradas: tensor([0.7311, 0.7563, 0.7607, 0.7729, 0.7816, 0.7923, 0.7880, 0.7697],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6746])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7493], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6746])\n",
      ">>Entradas: tensor([0.7563, 0.7607, 0.7729, 0.7816, 0.7923, 0.7880, 0.7697, 0.7493],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7451], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7309])\n",
      ">>Entradas: tensor([0.7607, 0.7729, 0.7816, 0.7923, 0.7880, 0.7697, 0.7493, 0.7451],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7467])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7441], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7467])\n",
      ">>Entradas: tensor([0.7729, 0.7816, 0.7923, 0.7880, 0.7697, 0.7493, 0.7451, 0.7441],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7219])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7364], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7219])\n",
      ">>Entradas: tensor([0.7816, 0.7923, 0.7880, 0.7697, 0.7493, 0.7451, 0.7441, 0.7364],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7199])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7299], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7199])\n",
      ">>Entradas: tensor([0.7923, 0.7880, 0.7697, 0.7493, 0.7451, 0.7441, 0.7364, 0.7299],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7407])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7283], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7407])\n",
      ">>Entradas: tensor([0.7880, 0.7697, 0.7493, 0.7451, 0.7441, 0.7364, 0.7299, 0.7283],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7362])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7227], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7362])\n",
      ">>Entradas: tensor([0.7697, 0.7493, 0.7451, 0.7441, 0.7364, 0.7299, 0.7283, 0.7227],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7108], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7065])\n",
      ">>Entradas: tensor([0.7493, 0.7451, 0.7441, 0.7364, 0.7299, 0.7283, 0.7227, 0.7108],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6979])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7022], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6979])\n",
      ">>Entradas: tensor([0.7451, 0.7441, 0.7364, 0.7299, 0.7283, 0.7227, 0.7108, 0.7022],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7106])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7001], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7106])\n",
      ">>Entradas: tensor([0.7441, 0.7364, 0.7299, 0.7283, 0.7227, 0.7108, 0.7022, 0.7001],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7210])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7010], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7210])\n",
      ">>Entradas: tensor([0.7364, 0.7299, 0.7283, 0.7227, 0.7108, 0.7022, 0.7001, 0.7010],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7291])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7052], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7291])\n",
      ">>Entradas: tensor([0.7299, 0.7283, 0.7227, 0.7108, 0.7022, 0.7001, 0.7010, 0.7052],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7674])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7215], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7674])\n",
      ">>Entradas: tensor([0.7283, 0.7227, 0.7108, 0.7022, 0.7001, 0.7010, 0.7052, 0.7215],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8359])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7549], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8359])\n",
      ">>Entradas: tensor([0.7227, 0.7108, 0.7022, 0.7001, 0.7010, 0.7052, 0.7215, 0.7549],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8510])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7853], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8510])\n",
      ">>Entradas: tensor([0.7108, 0.7022, 0.7001, 0.7010, 0.7052, 0.7215, 0.7549, 0.7853],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8127])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7996], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8127])\n",
      ">>Entradas: tensor([0.7022, 0.7001, 0.7010, 0.7052, 0.7215, 0.7549, 0.7853, 0.7996],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7864])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8054], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7864])\n",
      ">>Entradas: tensor([0.7001, 0.7010, 0.7052, 0.7215, 0.7549, 0.7853, 0.7996, 0.8054],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7720])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8054], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7720])\n",
      ">>Entradas: tensor([0.7010, 0.7052, 0.7215, 0.7549, 0.7853, 0.7996, 0.8054, 0.8054],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8140], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.7052, 0.7215, 0.7549, 0.7853, 0.7996, 0.8054, 0.8054, 0.8140],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8803])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8450], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8803])\n",
      ">>Entradas: tensor([0.7215, 0.7549, 0.7853, 0.7996, 0.8054, 0.8054, 0.8140, 0.8450],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8987])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8792], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8987])\n",
      ">>Entradas: tensor([0.7549, 0.7853, 0.7996, 0.8054, 0.8054, 0.8140, 0.8450, 0.8792],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8894], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.7853, 0.7996, 0.8054, 0.8054, 0.8140, 0.8450, 0.8792, 0.8894],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8857], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8309])\n",
      ">>Entradas: tensor([0.7996, 0.8054, 0.8054, 0.8140, 0.8450, 0.8792, 0.8894, 0.8857],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8156])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8656], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8156])\n",
      ">>Entradas: tensor([0.8054, 0.8054, 0.8140, 0.8450, 0.8792, 0.8894, 0.8857, 0.8656],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8538], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8117])\n",
      ">>Entradas: tensor([0.8054, 0.8140, 0.8450, 0.8792, 0.8894, 0.8857, 0.8656, 0.8538],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8192])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8473], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8192])\n",
      ">>Entradas: tensor([0.8140, 0.8450, 0.8792, 0.8894, 0.8857, 0.8656, 0.8538, 0.8473],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8218])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8454], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8218])\n",
      ">>Entradas: tensor([0.8450, 0.8792, 0.8894, 0.8857, 0.8656, 0.8538, 0.8473, 0.8454],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8426], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8197])\n",
      ">>Entradas: tensor([0.8792, 0.8894, 0.8857, 0.8656, 0.8538, 0.8473, 0.8454, 0.8426],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8179])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8360], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8179])\n",
      ">>Entradas: tensor([0.8894, 0.8857, 0.8656, 0.8538, 0.8473, 0.8454, 0.8426, 0.8360],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8163])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8258], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8163])\n",
      ">>Entradas: tensor([0.8857, 0.8656, 0.8538, 0.8473, 0.8454, 0.8426, 0.8360, 0.8258],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8006])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8113], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8006])\n",
      ">>Entradas: tensor([0.8656, 0.8538, 0.8473, 0.8454, 0.8426, 0.8360, 0.8258, 0.8113],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7705])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7919], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7705])\n",
      ">>Entradas: tensor([0.8538, 0.8473, 0.8454, 0.8426, 0.8360, 0.8258, 0.8113, 0.7919],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7427])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7704], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7427])\n",
      ">>Entradas: tensor([0.8473, 0.8454, 0.8426, 0.8360, 0.8258, 0.8113, 0.7919, 0.7704],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7470], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7169])\n",
      ">>Entradas: tensor([0.8454, 0.8426, 0.8360, 0.8258, 0.8113, 0.7919, 0.7704, 0.7470],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7297], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7197])\n",
      ">>Entradas: tensor([0.8426, 0.8360, 0.8258, 0.8113, 0.7919, 0.7704, 0.7470, 0.7297],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7509])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7256], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7509])\n",
      ">>Entradas: tensor([0.8360, 0.8258, 0.8113, 0.7919, 0.7704, 0.7470, 0.7297, 0.7256],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7403])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7191], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7403])\n",
      ">>Entradas: tensor([0.8258, 0.8113, 0.7919, 0.7704, 0.7470, 0.7297, 0.7256, 0.7191],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6984], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.8113, 0.7919, 0.7704, 0.7470, 0.7297, 0.7256, 0.7191, 0.6984],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6688])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6777], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6688])\n",
      ">>Entradas: tensor([0.7919, 0.7704, 0.7470, 0.7297, 0.7256, 0.7191, 0.6984, 0.6777],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6835])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6658], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6835])\n",
      ">>Entradas: tensor([0.7704, 0.7470, 0.7297, 0.7256, 0.7191, 0.6984, 0.6777, 0.6658],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6581], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.7470, 0.7297, 0.7256, 0.7191, 0.6984, 0.6777, 0.6658, 0.6581],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6815])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6535], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6815])\n",
      ">>Entradas: tensor([0.7297, 0.7256, 0.7191, 0.6984, 0.6777, 0.6658, 0.6581, 0.6535],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6893])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6561], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6893])\n",
      ">>Entradas: tensor([0.7256, 0.7191, 0.6984, 0.6777, 0.6658, 0.6581, 0.6535, 0.6561],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7111])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6653], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7111])\n",
      ">>Entradas: tensor([0.7191, 0.6984, 0.6777, 0.6658, 0.6581, 0.6535, 0.6561, 0.6653],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7349])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6791], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7349])\n",
      ">>Entradas: tensor([0.6984, 0.6777, 0.6658, 0.6581, 0.6535, 0.6561, 0.6653, 0.6791],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7608])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6988], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7608])\n",
      ">>Entradas: tensor([0.6777, 0.6658, 0.6581, 0.6535, 0.6561, 0.6653, 0.6791, 0.6988],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7711])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7204], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7711])\n",
      ">>Entradas: tensor([0.6658, 0.6581, 0.6535, 0.6561, 0.6653, 0.6791, 0.6988, 0.7204],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7660])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7379], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7660])\n",
      ">>Entradas: tensor([0.6581, 0.6535, 0.6561, 0.6653, 0.6791, 0.6988, 0.7204, 0.7379],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7483])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7482], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7483])\n",
      ">>Entradas: tensor([0.6535, 0.6561, 0.6653, 0.6791, 0.6988, 0.7204, 0.7379, 0.7482],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7182])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7487], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7182])\n",
      ">>Entradas: tensor([0.6561, 0.6653, 0.6791, 0.6988, 0.7204, 0.7379, 0.7482, 0.7487],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7461], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7089])\n",
      ">>Entradas: tensor([0.6653, 0.6791, 0.6988, 0.7204, 0.7379, 0.7482, 0.7487, 0.7461],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7204])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7478], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7204])\n",
      ">>Entradas: tensor([0.6791, 0.6988, 0.7204, 0.7379, 0.7482, 0.7487, 0.7461, 0.7478],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7706])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7633], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7706])\n",
      ">>Entradas: tensor([0.6988, 0.7204, 0.7379, 0.7482, 0.7487, 0.7461, 0.7478, 0.7633],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8595])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8012], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8595])\n",
      ">>Entradas: tensor([0.7204, 0.7379, 0.7482, 0.7487, 0.7461, 0.7478, 0.7633, 0.8012],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8437], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9065])\n",
      ">>Entradas: tensor([0.7379, 0.7482, 0.7487, 0.7461, 0.7478, 0.7633, 0.8012, 0.8437],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9119])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8769], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9119])\n",
      ">>Entradas: tensor([0.7482, 0.7487, 0.7461, 0.7478, 0.7633, 0.8012, 0.8437, 0.8769],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9043])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8993], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9043])\n",
      ">>Entradas: tensor([0.7487, 0.7461, 0.7478, 0.7633, 0.8012, 0.8437, 0.8769, 0.8993],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8839])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9091], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8839])\n",
      ">>Entradas: tensor([0.7461, 0.7478, 0.7633, 0.8012, 0.8437, 0.8769, 0.8993, 0.9091],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9032])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9216], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9032])\n",
      ">>Entradas: tensor([0.7478, 0.7633, 0.8012, 0.8437, 0.8769, 0.8993, 0.9091, 0.9216],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9623])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9502], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9623])\n",
      ">>Entradas: tensor([0.7633, 0.8012, 0.8437, 0.8769, 0.8993, 0.9091, 0.9216, 0.9502],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9821])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9798], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9821])\n",
      ">>Entradas: tensor([0.8012, 0.8437, 0.8769, 0.8993, 0.9091, 0.9216, 0.9502, 0.9798],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9624])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9965], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9624])\n",
      ">>Entradas: tensor([0.8437, 0.8769, 0.8993, 0.9091, 0.9216, 0.9502, 0.9798, 0.9965],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9303])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9967], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9303])\n",
      ">>Entradas: tensor([0.8769, 0.8993, 0.9091, 0.9216, 0.9502, 0.9798, 0.9965, 0.9967],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8855])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9783], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8855])\n",
      ">>Entradas: tensor([0.8993, 0.9091, 0.9216, 0.9502, 0.9798, 0.9965, 0.9967, 0.9783],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8597])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9513], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8597])\n",
      ">>Entradas: tensor([0.9091, 0.9216, 0.9502, 0.9798, 0.9965, 0.9967, 0.9783, 0.9513],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8529])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9265], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8529])\n",
      ">>Entradas: tensor([0.9216, 0.9502, 0.9798, 0.9965, 0.9967, 0.9783, 0.9513, 0.9265],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7476], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      "ERROR: la modificacion de los pesos di√≥ un error mayor: 0.012318710796535015, se regresa al estado anterior de la red\n",
      ">>Entradas: tensor([0.9502, 0.9798, 0.9965, 0.9967, 0.9783, 0.9513, 0.9265, 0.9304],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8769])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9157], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8769])\n",
      ">>Entradas: tensor([0.9798, 0.9965, 0.9967, 0.9783, 0.9513, 0.9265, 0.9304, 0.9157],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8806])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9039], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8806])\n",
      ">>Entradas: tensor([0.9965, 0.9967, 0.9783, 0.9513, 0.9265, 0.9304, 0.9157, 0.9039],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8699])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8882], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8699])\n",
      ">>Entradas: tensor([0.9967, 0.9783, 0.9513, 0.9265, 0.9304, 0.9157, 0.9039, 0.8882],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8465])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8653], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8465])\n",
      ">>Entradas: tensor([0.9783, 0.9513, 0.9265, 0.9304, 0.9157, 0.9039, 0.8882, 0.8653],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8104])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8350], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8104])\n",
      ">>Entradas: tensor([0.9513, 0.9265, 0.9304, 0.9157, 0.9039, 0.8882, 0.8653, 0.8350],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8026])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8128], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8026])\n",
      ">>Entradas: tensor([0.9265, 0.9304, 0.9157, 0.9039, 0.8882, 0.8653, 0.8350, 0.8128],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8232])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8040], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8232])\n",
      ">>Entradas: tensor([0.9304, 0.9157, 0.9039, 0.8882, 0.8653, 0.8350, 0.8128, 0.8040],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8397])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8026], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8397])\n",
      ">>Entradas: tensor([0.9157, 0.9039, 0.8882, 0.8653, 0.8350, 0.8128, 0.8040, 0.8026],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8522])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8061], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8522])\n",
      ">>Entradas: tensor([0.9039, 0.8882, 0.8653, 0.8350, 0.8128, 0.8040, 0.8026, 0.8061],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8616])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8131], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8616])\n",
      ">>Entradas: tensor([0.8882, 0.8653, 0.8350, 0.8128, 0.8040, 0.8026, 0.8061, 0.8131],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8679])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8203], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8679])\n",
      ">>Entradas: tensor([0.8653, 0.8350, 0.8128, 0.8040, 0.8026, 0.8061, 0.8131, 0.8203],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8702])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8274], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8702])\n",
      ">>Entradas: tensor([0.8350, 0.8128, 0.8040, 0.8026, 0.8061, 0.8131, 0.8203, 0.8274],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8685])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8353], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8685])\n",
      ">>Entradas: tensor([0.8128, 0.8040, 0.8026, 0.8061, 0.8131, 0.8203, 0.8274, 0.8353],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8530])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8403], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8530])\n",
      ">>Entradas: tensor([0.8040, 0.8026, 0.8061, 0.8131, 0.8203, 0.8274, 0.8353, 0.8403],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8236])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8378], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8236])\n",
      ">>Entradas: tensor([0.8026, 0.8061, 0.8131, 0.8203, 0.8274, 0.8353, 0.8403, 0.8378],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8310], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.8061, 0.8131, 0.8203, 0.8274, 0.8353, 0.8403, 0.8378, 0.8310],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7919])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8223], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7919])\n",
      ">>Entradas: tensor([0.8131, 0.8203, 0.8274, 0.8353, 0.8403, 0.8378, 0.8310, 0.8223],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7865])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8131], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7865])\n",
      ">>Entradas: tensor([0.8203, 0.8274, 0.8353, 0.8403, 0.8378, 0.8310, 0.8223, 0.8131],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7870])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8055], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7870])\n",
      ">>Entradas: tensor([0.8274, 0.8353, 0.8403, 0.8378, 0.8310, 0.8223, 0.8131, 0.8055],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7874])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7993], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7874])\n",
      ">>Entradas: tensor([0.8353, 0.8403, 0.8378, 0.8310, 0.8223, 0.8131, 0.8055, 0.7993],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7879])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7936], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7879])\n",
      ">>Entradas: tensor([0.8403, 0.8378, 0.8310, 0.8223, 0.8131, 0.8055, 0.7993, 0.7936],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7955])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7903], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7955])\n",
      ">>Entradas: tensor([0.8378, 0.8310, 0.8223, 0.8131, 0.8055, 0.7993, 0.7936, 0.7903],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8102])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7913], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8102])\n",
      ">>Entradas: tensor([0.8310, 0.8223, 0.8131, 0.8055, 0.7993, 0.7936, 0.7903, 0.7913],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7668])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7792], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7668])\n",
      ">>Entradas: tensor([0.8223, 0.8131, 0.8055, 0.7993, 0.7936, 0.7903, 0.7913, 0.7792],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6655])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7406], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6655])\n",
      ">>Entradas: tensor([0.8131, 0.8055, 0.7993, 0.7936, 0.7903, 0.7913, 0.7792, 0.7406],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6361])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7024], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6361])\n",
      ">>Entradas: tensor([0.8055, 0.7993, 0.7936, 0.7903, 0.7913, 0.7792, 0.7406, 0.7024],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6785])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6843], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6785])\n",
      ">>Entradas: tensor([0.7993, 0.7936, 0.7903, 0.7913, 0.7792, 0.7406, 0.7024, 0.6843],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6755], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6966])\n",
      ">>Entradas: tensor([0.7936, 0.7903, 0.7913, 0.7792, 0.7406, 0.7024, 0.6843, 0.6755],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6903])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6682], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6903])\n",
      ">>Entradas: tensor([0.7903, 0.7913, 0.7792, 0.7406, 0.7024, 0.6843, 0.6755, 0.6682],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6970])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6670], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6970])\n",
      ">>Entradas: tensor([0.7913, 0.7792, 0.7406, 0.7024, 0.6843, 0.6755, 0.6682, 0.6670],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7167])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6700], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7167])\n",
      ">>Entradas: tensor([0.7792, 0.7406, 0.7024, 0.6843, 0.6755, 0.6682, 0.6670, 0.6700],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7491])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6794], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7491])\n",
      ">>Entradas: tensor([0.7406, 0.7024, 0.6843, 0.6755, 0.6682, 0.6670, 0.6700, 0.6794],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7940])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7027], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7940])\n",
      ">>Entradas: tensor([0.7024, 0.6843, 0.6755, 0.6682, 0.6670, 0.6700, 0.6794, 0.7027],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8547])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7449], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8547])\n",
      ">>Entradas: tensor([0.6843, 0.6755, 0.6682, 0.6670, 0.6700, 0.6794, 0.7027, 0.7449],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9314])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8058], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9314])\n",
      ">>Entradas: tensor([0.6755, 0.6682, 0.6670, 0.6700, 0.6794, 0.7027, 0.7449, 0.8058],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9627])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8653], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9627])\n",
      ">>Entradas: tensor([0.6682, 0.6670, 0.6700, 0.6794, 0.7027, 0.7449, 0.8058, 0.8653],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9486])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9100], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9486])\n",
      ">>Entradas: tensor([0.6670, 0.6700, 0.6794, 0.7027, 0.7449, 0.8058, 0.8653, 0.9100],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9307])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9411], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9307])\n",
      ">>Entradas: tensor([0.6700, 0.6794, 0.7027, 0.7449, 0.8058, 0.8653, 0.9100, 0.9411],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9090])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9582], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9090])\n",
      ">>Entradas: tensor([0.6794, 0.7027, 0.7449, 0.8058, 0.8653, 0.9100, 0.9411, 0.9582],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8816])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9633], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8816])\n",
      ">>Entradas: tensor([0.7027, 0.7449, 0.8058, 0.8653, 0.9100, 0.9411, 0.9582, 0.9633],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8487])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9579], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8487])\n",
      ">>Entradas: tensor([0.7449, 0.8058, 0.8653, 0.9100, 0.9411, 0.9582, 0.9633, 0.9579],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8753])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9599], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8753])\n",
      ">>Entradas: tensor([0.8058, 0.8653, 0.9100, 0.9411, 0.9582, 0.9633, 0.9579, 0.9599],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9612])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9819], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9612])\n",
      ">>Entradas: tensor([0.8653, 0.9100, 0.9411, 0.9582, 0.9633, 0.9579, 0.9599, 0.9819],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9925])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0019], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9925])\n",
      ">>Entradas: tensor([0.9100, 0.9411, 0.9582, 0.9633, 0.9579, 0.9599, 0.9819, 1.0019],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9690])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0053], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9690])\n",
      ">>Entradas: tensor([0.9411, 0.9582, 0.9633, 0.9579, 0.9599, 0.9819, 1.0019, 1.0053],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9715])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0053], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9715])\n",
      ">>Entradas: tensor([0.9582, 0.9633, 0.9579, 0.9599, 0.9819, 1.0019, 1.0053, 1.0053],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([1.])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0090], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([1.])\n",
      ">>Entradas: tensor([0.9633, 0.9579, 0.9599, 0.9819, 1.0019, 1.0053, 1.0053, 1.0090],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9917], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9801])\n",
      ">>Entradas: tensor([0.9579, 0.9599, 0.9819, 1.0019, 1.0053, 1.0053, 1.0090, 0.9917],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9709], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9117])\n",
      ">>Entradas: tensor([0.9599, 0.9819, 1.0019, 1.0053, 1.0053, 1.0090, 0.9917, 0.9709],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8911])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9501], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8911])\n",
      ">>Entradas: tensor([0.9819, 1.0019, 1.0053, 1.0053, 1.0090, 0.9917, 0.9709, 0.9501],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9181])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9400], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9181])\n",
      ">>Entradas: tensor([1.0019, 1.0053, 1.0053, 1.0090, 0.9917, 0.9709, 0.9501, 0.9400],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9450])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9370], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9450])\n",
      ">>Entradas: tensor([1.0053, 1.0053, 1.0090, 0.9917, 0.9709, 0.9501, 0.9400, 0.9370],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9718])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9425], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9718])\n",
      ">>Entradas: tensor([1.0053, 1.0090, 0.9917, 0.9709, 0.9501, 0.9400, 0.9370, 0.9425],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9829])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9497], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9829])\n",
      ">>Entradas: tensor([1.0090, 0.9917, 0.9709, 0.9501, 0.9400, 0.9370, 0.9425, 0.9497],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9783])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9528], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9783])\n",
      ">>s_original: [0.049424633383750916, 0.10789185762405396, 0.13719609379768372, 0.13733737170696259, 0.1338856965303421, 0.12684109807014465, 0.14756061136722565, 0.19604423642158508, 0.21688967943191528, 0.21009695529937744, 0.20267784595489502, 0.1946323662996292, 0.19407351315021515, 0.20100130140781403, 0.19663821160793304, 0.180984228849411, 0.16539041697978973, 0.14985674619674683, 0.15043111145496368, 0.1671135276556015, 0.20227035880088806, 0.25590160489082336, 0.29268819093704224, 0.31263017654418945, 0.31093889474868774, 0.2876143157482147, 0.28016164898872375, 0.28858086466789246, 0.28246283531188965, 0.26180753111839294, 0.2801212966442108, 0.3374040722846985, 0.3482298254966736, 0.3125985562801361, 0.34358710050582886, 0.44119545817375183, 0.521095335483551, 0.5832866430282593, 0.6089234352111816, 0.5980057120323181, 0.5945301651954651, 0.5984968543052673, 0.621354341506958, 0.6631026864051819, 0.6928724050521851, 0.7106636166572571, 0.721682071685791, 0.7259277701377869, 0.7404318451881409, 0.7651942372322083, 0.7447891235351562, 0.6792163252830505, 0.6746017932891846, 0.730945348739624, 0.7467210292816162, 0.7219287157058716, 0.7199286818504333, 0.7407209277153015, 0.7362455129623413, 0.7065023183822632, 0.6979451775550842, 0.7105739712715149, 0.7209621667861938, 0.7291097044944763, 0.7674259543418884, 0.8359109163284302, 0.8510103225708008, 0.8127241730690002, 0.7863940000534058, 0.7720199823379517, 0.8033170700073242, 0.8802852630615234, 0.8987051844596863, 0.8585767149925232, 0.8308762311935425, 0.8156037926673889, 0.8116992115974426, 0.8191625475883484, 0.8218275904655457, 0.8196942210197449, 0.817862868309021, 0.8163333535194397, 0.8005555868148804, 0.7705295085906982, 0.7426586747169495, 0.716943085193634, 0.7197051048278809, 0.7509447932243347, 0.7402781248092651, 0.6877052187919617, 0.6687695384025574, 0.683471143245697, 0.6877052187919617, 0.6814717054367065, 0.6892618536949158, 0.7110756039619446, 0.7349108457565308, 0.7607676982879639, 0.771117091178894, 0.7659589648246765, 0.7483323812484741, 0.7182371616363525, 0.708941638469696, 0.7204458117485046, 0.7706154584884644, 0.8594506978988647, 0.906541109085083, 0.9118866324424744, 0.9043355584144592, 0.8838878870010376, 0.9032153487205505, 0.9623178839683533, 0.9820588231086731, 0.96243816614151, 0.9302511811256409, 0.8854979276657104, 0.8597025871276855, 0.8528652191162109, 0.8585854768753052, 0.8768633008003235, 0.8806464076042175, 0.8699347376823425, 0.846513569355011, 0.8103827834129333, 0.8026111125946045, 0.8231984972953796, 0.8397204279899597, 0.8521769046783447, 0.8615626692771912, 0.8678776621818542, 0.8701963424682617, 0.868518590927124, 0.852988064289093, 0.8236046433448792, 0.8032509088516235, 0.7919268012046814, 0.7865023016929626, 0.7869773507118225, 0.7874362468719482, 0.7878790497779846, 0.7954531908035278, 0.8101586699485779, 0.7668473124504089, 0.665519118309021, 0.6360738277435303, 0.678511381149292, 0.6965967416763306, 0.6903298497200012, 0.6970472931861877, 0.7167490720748901, 0.7490506768226624, 0.7939522862434387, 0.8547447323799133, 0.931428074836731, 0.9627243876457214, 0.9486336708068848, 0.9307146072387695, 0.9089671969413757, 0.8816379904747009, 0.8487268090248108, 0.8752607107162476, 0.9612395763397217, 0.9925020933151245, 0.9690483212471008, 0.9715476036071777, 1.0, 0.9800636768341064, 0.9117385745048523, 0.8910858035087585, 0.9181053042411804, 0.9450165033340454, 0.9718193411827087, 0.982906699180603, 0.9782785773277283]\n",
      ">>s_pred: [-0.18967771530151367, -0.11007499694824219, -0.046912193298339844, -0.009407997131347656, 0.04406881332397461, 0.0762476921081543, 0.09293889999389648, 0.12288188934326172, 0.16894149780273438, 0.21184921264648438, 0.2393498420715332, 0.25642871856689453, 0.2638583183288574, 0.2657341957092285, 0.2647838592529297, 0.258392333984375, 0.24573278427124023, 0.22597694396972656, 0.20452356338500977, 0.1902456283569336, 0.1872577667236328, 0.20023488998413086, 0.22142362594604492, 0.24415016174316406, 0.26223039627075195, 0.2708125114440918, 0.27766895294189453, 0.2880859375, 0.29621171951293945, 0.29755115509033203, 0.3035888671875, 0.3224630355834961, 0.3371005058288574, 0.33748769760131836, 0.3478727340698242, 0.38324880599975586, 0.43287038803100586, 0.49231576919555664, 0.5498347282409668, 0.5912322998046875, 0.620844841003418, 0.6451339721679688, 0.6715259552001953, 0.6975927352905273, 0.7311439514160156, 0.7562828063964844, 0.760683536529541, 0.7729158401489258, 0.7815952301025391, 0.7922954559326172, 0.788048267364502, 0.7697329521179199, 0.7492728233337402, 0.7451272010803223, 0.7440848350524902, 0.7364406585693359, 0.7298612594604492, 0.7283425331115723, 0.7227487564086914, 0.7107515335083008, 0.7021527290344238, 0.7001118659973145, 0.7010159492492676, 0.7051920890808105, 0.7214570045471191, 0.7549481391906738, 0.7853131294250488, 0.7996058464050293, 0.8053913116455078, 0.8054366111755371, 0.8139595985412598, 0.8449640274047852, 0.8792219161987305, 0.8893604278564453, 0.8857288360595703, 0.8656048774719238, 0.8537607192993164, 0.8472814559936523, 0.8454246520996094, 0.8425807952880859, 0.8359808921813965, 0.8257746696472168, 0.8113069534301758, 0.7919158935546875, 0.7704315185546875, 0.7470293045043945, 0.72967529296875, 0.7255516052246094, 0.7191166877746582, 0.6984286308288574, 0.6776838302612305, 0.6658110618591309, 0.6580691337585449, 0.6534543037414551, 0.6560864448547363, 0.6652612686157227, 0.6790504455566406, 0.6988496780395508, 0.720362663269043, 0.7379484176635742, 0.748232364654541, 0.7486801147460938, 0.7461404800415039, 0.7477631568908691, 0.7632813453674316, 0.801201343536377, 0.8437104225158691, 0.8769497871398926, 0.8993315696716309, 0.909055233001709, 0.9215502738952637, 0.9501895904541016, 0.9798183441162109, 0.9964504241943359, 0.9966716766357422, 0.9783105850219727, 0.9513044357299805, 0.9265303611755371, 0.9303679466247559, 0.9156761169433594, 0.9038591384887695, 0.8882455825805664, 0.8652586936950684, 0.8349790573120117, 0.8127946853637695, 0.8039951324462891, 0.8026094436645508, 0.8061237335205078, 0.8130874633789062, 0.8202929496765137, 0.8273506164550781, 0.8352789878845215, 0.8402786254882812, 0.8378028869628906, 0.8310146331787109, 0.8223276138305664, 0.8131365776062012, 0.8055233955383301, 0.7993173599243164, 0.7936372756958008, 0.7902688980102539, 0.7913408279418945, 0.7792015075683594, 0.7405991554260254, 0.702427864074707, 0.684333324432373, 0.6754508018493652, 0.6681714057922363, 0.6669740676879883, 0.6700277328491211, 0.6794381141662598, 0.7026987075805664, 0.7449235916137695, 0.8057794570922852, 0.8652777671813965, 0.910003662109375, 0.941126823425293, 0.9581942558288574, 0.9632692337036133, 0.9578580856323242, 0.9599113464355469, 0.9818863868713379, 1.0019011497497559, 1.005298137664795, 1.0052838325500488, 1.0090265274047852, 0.9917349815368652, 0.9708700180053711, 0.9501490592956543, 0.9399752616882324, 0.9369997978210449, 0.9425234794616699, 0.9497051239013672, 0.9527812004089355]\n",
      "<<Perdida: 0.0029650048818439245 epoca: 7\n",
      "---Inicio de epoca: 8--\n",
      ">>Entradas: tensor([0.0503, 0.0086, 0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203])\n",
      ">>Salida: tensor([0.0494])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([-0.1393], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.0494])\n",
      ">>Entradas: tensor([ 0.0086,  0.0000,  0.0245,  0.0327,  0.0246,  0.0205,  0.0203, -0.1393],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1079])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([-0.0732], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1079])\n",
      ">>Entradas: tensor([ 0.0000,  0.0245,  0.0327,  0.0246,  0.0205,  0.0203, -0.1393, -0.0732],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1372])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0056], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1372])\n",
      ">>Entradas: tensor([ 0.0245,  0.0327,  0.0246,  0.0205,  0.0203, -0.1393, -0.0732,  0.0056],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1373])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0541], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1373])\n",
      ">>Entradas: tensor([ 0.0327,  0.0246,  0.0205,  0.0203, -0.1393, -0.0732,  0.0056,  0.0541],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1339])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0898], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1339])\n",
      ">>Entradas: tensor([ 0.0246,  0.0205,  0.0203, -0.1393, -0.0732,  0.0056,  0.0541,  0.0898],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1268])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1140], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1268])\n",
      ">>Entradas: tensor([ 0.0205,  0.0203, -0.1393, -0.0732,  0.0056,  0.0541,  0.0898,  0.1140],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1476])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1291], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1476])\n",
      ">>Entradas: tensor([ 0.0203, -0.1393, -0.0732,  0.0056,  0.0541,  0.0898,  0.1140,  0.1291],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1960])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1541], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1960])\n",
      ">>Entradas: tensor([-0.1393, -0.0732,  0.0056,  0.0541,  0.0898,  0.1140,  0.1291,  0.1541],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1942], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2169])\n",
      ">>Entradas: tensor([-0.0732,  0.0056,  0.0541,  0.0898,  0.1140,  0.1291,  0.1541,  0.1942],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2101])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2415], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2101])\n",
      ">>Entradas: tensor([0.0056, 0.0541, 0.0898, 0.1140, 0.1291, 0.1541, 0.1942, 0.2415],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2027])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2696], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2027])\n",
      ">>Entradas: tensor([0.0541, 0.0898, 0.1140, 0.1291, 0.1541, 0.1942, 0.2415, 0.2696],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1946])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2815], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1946])\n",
      ">>Entradas: tensor([0.0898, 0.1140, 0.1291, 0.1541, 0.1942, 0.2415, 0.2696, 0.2815],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1941])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2857], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1941])\n",
      ">>Entradas: tensor([0.1140, 0.1291, 0.1541, 0.1942, 0.2415, 0.2696, 0.2815, 0.2857],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2010])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2851], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2010])\n",
      ">>Entradas: tensor([0.1291, 0.1541, 0.1942, 0.2415, 0.2696, 0.2815, 0.2857, 0.2851],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2808], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1966])\n",
      ">>Entradas: tensor([0.1541, 0.1942, 0.2415, 0.2696, 0.2815, 0.2857, 0.2851, 0.2808],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1810])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2721], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1810])\n",
      ">>Entradas: tensor([0.1942, 0.2415, 0.2696, 0.2815, 0.2857, 0.2851, 0.2808, 0.2721],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1654])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2561], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1654])\n",
      ">>Entradas: tensor([0.2415, 0.2696, 0.2815, 0.2857, 0.2851, 0.2808, 0.2721, 0.2561],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1499])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2327], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1499])\n",
      ">>Entradas: tensor([0.2696, 0.2815, 0.2857, 0.2851, 0.2808, 0.2721, 0.2561, 0.2327],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1504])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2020], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1504])\n",
      ">>Entradas: tensor([0.2815, 0.2857, 0.2851, 0.2808, 0.2721, 0.2561, 0.2327, 0.2020],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1671])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1839], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1671])\n",
      ">>Entradas: tensor([0.2857, 0.2851, 0.2808, 0.2721, 0.2561, 0.2327, 0.2020, 0.1839],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2023])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1771], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2023])\n",
      ">>Entradas: tensor([0.2851, 0.2808, 0.2721, 0.2561, 0.2327, 0.2020, 0.1839, 0.1771],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2559])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1863], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2559])\n",
      ">>Entradas: tensor([0.2808, 0.2721, 0.2561, 0.2327, 0.2020, 0.1839, 0.1771, 0.1863],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2927])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2055], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2927])\n",
      ">>Entradas: tensor([0.2721, 0.2561, 0.2327, 0.2020, 0.1839, 0.1771, 0.1863, 0.2055],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2273], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2561, 0.2327, 0.2020, 0.1839, 0.1771, 0.1863, 0.2055, 0.2273],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3109])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2451], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3109])\n",
      ">>Entradas: tensor([0.2327, 0.2020, 0.1839, 0.1771, 0.1863, 0.2055, 0.2273, 0.2451],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2876])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2548], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2876])\n",
      ">>Entradas: tensor([0.2020, 0.1839, 0.1771, 0.1863, 0.2055, 0.2273, 0.2451, 0.2548],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2802])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2646], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2802])\n",
      ">>Entradas: tensor([0.1839, 0.1771, 0.1863, 0.2055, 0.2273, 0.2451, 0.2548, 0.2646],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2886])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2795], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2886])\n",
      ">>Entradas: tensor([0.1771, 0.1863, 0.2055, 0.2273, 0.2451, 0.2548, 0.2646, 0.2795],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2825])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2928], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2825])\n",
      ">>Entradas: tensor([0.1863, 0.2055, 0.2273, 0.2451, 0.2548, 0.2646, 0.2795, 0.2928],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2618])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2994], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2618])\n",
      ">>Entradas: tensor([0.2055, 0.2273, 0.2451, 0.2548, 0.2646, 0.2795, 0.2928, 0.2994],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3104], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2801])\n",
      ">>Entradas: tensor([0.2273, 0.2451, 0.2548, 0.2646, 0.2795, 0.2928, 0.2994, 0.3104],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3374])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3329], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3374])\n",
      ">>Entradas: tensor([0.2451, 0.2548, 0.2646, 0.2795, 0.2928, 0.2994, 0.3104, 0.3329],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3482])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3502], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3482])\n",
      ">>Entradas: tensor([0.2548, 0.2646, 0.2795, 0.2928, 0.2994, 0.3104, 0.3329, 0.3502],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3525], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2646, 0.2795, 0.2928, 0.2994, 0.3104, 0.3329, 0.3502, 0.3525],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3436])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3648], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3436])\n",
      ">>Entradas: tensor([0.2795, 0.2928, 0.2994, 0.3104, 0.3329, 0.3502, 0.3525, 0.3648],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.4412])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4010], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.4412])\n",
      ">>Entradas: tensor([0.2928, 0.2994, 0.3104, 0.3329, 0.3502, 0.3525, 0.3648, 0.4010],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5211])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4504], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5211])\n",
      ">>Entradas: tensor([0.2994, 0.3104, 0.3329, 0.3502, 0.3525, 0.3648, 0.4010, 0.4504],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5833])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5101], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5833])\n",
      ">>Entradas: tensor([0.3104, 0.3329, 0.3502, 0.3525, 0.3648, 0.4010, 0.4504, 0.5101],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5683], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6089])\n",
      ">>Entradas: tensor([0.3329, 0.3502, 0.3525, 0.3648, 0.4010, 0.4504, 0.5101, 0.5683],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5980])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6103], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5980])\n",
      ">>Entradas: tensor([0.3502, 0.3525, 0.3648, 0.4010, 0.4504, 0.5101, 0.5683, 0.6103],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5945])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6400], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5945])\n",
      ">>Entradas: tensor([0.3525, 0.3648, 0.4010, 0.4504, 0.5101, 0.5683, 0.6103, 0.6400],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5985])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6643], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5985])\n",
      ">>Entradas: tensor([0.3648, 0.4010, 0.4504, 0.5101, 0.5683, 0.6103, 0.6400, 0.6643],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6214])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6904], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6214])\n",
      ">>Entradas: tensor([0.4010, 0.4504, 0.5101, 0.5683, 0.6103, 0.6400, 0.6643, 0.6904],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6631])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7231], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6631])\n",
      ">>Entradas: tensor([0.4504, 0.5101, 0.5683, 0.6103, 0.6400, 0.6643, 0.6904, 0.7231],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6929])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7548], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6929])\n",
      ">>Entradas: tensor([0.5101, 0.5683, 0.6103, 0.6400, 0.6643, 0.6904, 0.7231, 0.7548],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7107])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7796], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7107])\n",
      ">>Entradas: tensor([0.5683, 0.6103, 0.6400, 0.6643, 0.6904, 0.7231, 0.7548, 0.7796],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7217])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7949], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7217])\n",
      ">>Entradas: tensor([0.6103, 0.6400, 0.6643, 0.6904, 0.7231, 0.7548, 0.7796, 0.7949],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7259])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8008], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7259])\n",
      ">>Entradas: tensor([0.6400, 0.6643, 0.6904, 0.7231, 0.7548, 0.7796, 0.7949, 0.8008],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7404])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8036], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7404])\n",
      ">>Entradas: tensor([0.6643, 0.6904, 0.7231, 0.7548, 0.7796, 0.7949, 0.8008, 0.8036],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7652])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8105], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7652])\n",
      ">>Entradas: tensor([0.6904, 0.7231, 0.7548, 0.7796, 0.7949, 0.8008, 0.8036, 0.8105],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7448])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8070], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7448])\n",
      ">>Entradas: tensor([0.7231, 0.7548, 0.7796, 0.7949, 0.8008, 0.8036, 0.8105, 0.8070],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6792])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7833], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6792])\n",
      ">>Entradas: tensor([0.7548, 0.7796, 0.7949, 0.8008, 0.8036, 0.8105, 0.8070, 0.7833],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6746])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7597], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6746])\n",
      ">>Entradas: tensor([0.7796, 0.7949, 0.8008, 0.8036, 0.8105, 0.8070, 0.7833, 0.7597],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7525], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7309])\n",
      ">>Entradas: tensor([0.7949, 0.8008, 0.8036, 0.8105, 0.8070, 0.7833, 0.7597, 0.7525],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7467])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7470], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7467])\n",
      ">>Entradas: tensor([0.8008, 0.8036, 0.8105, 0.8070, 0.7833, 0.7597, 0.7525, 0.7470],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7219])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7349], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7219])\n",
      ">>Entradas: tensor([0.8036, 0.8105, 0.8070, 0.7833, 0.7597, 0.7525, 0.7470, 0.7349],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7199])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7257], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7199])\n",
      ">>Entradas: tensor([0.8105, 0.8070, 0.7833, 0.7597, 0.7525, 0.7470, 0.7349, 0.7257],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7407])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7222], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7407])\n",
      ">>Entradas: tensor([0.8070, 0.7833, 0.7597, 0.7525, 0.7470, 0.7349, 0.7257, 0.7222],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7362])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7148], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7362])\n",
      ">>Entradas: tensor([0.7833, 0.7597, 0.7525, 0.7470, 0.7349, 0.7257, 0.7222, 0.7148],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7017], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7065])\n",
      ">>Entradas: tensor([0.7597, 0.7525, 0.7470, 0.7349, 0.7257, 0.7222, 0.7148, 0.7017],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6979])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6929], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6979])\n",
      ">>Entradas: tensor([0.7525, 0.7470, 0.7349, 0.7257, 0.7222, 0.7148, 0.7017, 0.6929],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7106])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6909], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7106])\n",
      ">>Entradas: tensor([0.7470, 0.7349, 0.7257, 0.7222, 0.7148, 0.7017, 0.6929, 0.6909],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7210])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6921], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7210])\n",
      ">>Entradas: tensor([0.7349, 0.7257, 0.7222, 0.7148, 0.7017, 0.6929, 0.6909, 0.6921],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7291])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6971], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7291])\n",
      ">>Entradas: tensor([0.7257, 0.7222, 0.7148, 0.7017, 0.6929, 0.6909, 0.6921, 0.6971],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7674])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7145], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7674])\n",
      ">>Entradas: tensor([0.7222, 0.7148, 0.7017, 0.6929, 0.6909, 0.6921, 0.6971, 0.7145],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8359])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7492], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8359])\n",
      ">>Entradas: tensor([0.7148, 0.7017, 0.6929, 0.6909, 0.6921, 0.6971, 0.7145, 0.7492],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8510])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7809], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8510])\n",
      ">>Entradas: tensor([0.7017, 0.6929, 0.6909, 0.6921, 0.6971, 0.7145, 0.7492, 0.7809],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8127])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7969], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8127])\n",
      ">>Entradas: tensor([0.6929, 0.6909, 0.6921, 0.6971, 0.7145, 0.7492, 0.7809, 0.7969],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7864])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8047], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7864])\n",
      ">>Entradas: tensor([0.6909, 0.6921, 0.6971, 0.7145, 0.7492, 0.7809, 0.7969, 0.8047],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7720])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8068], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7720])\n",
      ">>Entradas: tensor([0.6921, 0.6971, 0.7145, 0.7492, 0.7809, 0.7969, 0.8047, 0.8068],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8173], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.6971, 0.7145, 0.7492, 0.7809, 0.7969, 0.8047, 0.8068, 0.8173],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8803])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8500], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8803])\n",
      ">>Entradas: tensor([0.7145, 0.7492, 0.7809, 0.7969, 0.8047, 0.8068, 0.8173, 0.8500],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8987])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8821], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8987])\n",
      ">>Entradas: tensor([0.7492, 0.7809, 0.7969, 0.8047, 0.8068, 0.8173, 0.8500, 0.8821],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8937], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.7809, 0.7969, 0.8047, 0.8068, 0.8173, 0.8500, 0.8821, 0.8937],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8861], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8309])\n",
      ">>Entradas: tensor([0.7969, 0.8047, 0.8068, 0.8173, 0.8500, 0.8821, 0.8937, 0.8861],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8156])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8761], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8156])\n",
      ">>Entradas: tensor([0.8047, 0.8068, 0.8173, 0.8500, 0.8821, 0.8937, 0.8861, 0.8761],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8602], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8117])\n",
      ">>Entradas: tensor([0.8068, 0.8173, 0.8500, 0.8821, 0.8937, 0.8861, 0.8761, 0.8602],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8192])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8538], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8192])\n",
      ">>Entradas: tensor([0.8173, 0.8500, 0.8821, 0.8937, 0.8861, 0.8761, 0.8602, 0.8538],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8218])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8514], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8218])\n",
      ">>Entradas: tensor([0.8500, 0.8821, 0.8937, 0.8861, 0.8761, 0.8602, 0.8538, 0.8514],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8473], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8197])\n",
      ">>Entradas: tensor([0.8821, 0.8937, 0.8861, 0.8761, 0.8602, 0.8538, 0.8514, 0.8473],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8179])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8387], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8179])\n",
      ">>Entradas: tensor([0.8937, 0.8861, 0.8761, 0.8602, 0.8538, 0.8514, 0.8473, 0.8387],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8163])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8277], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8163])\n",
      ">>Entradas: tensor([0.8861, 0.8761, 0.8602, 0.8538, 0.8514, 0.8473, 0.8387, 0.8277],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8006])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8124], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8006])\n",
      ">>Entradas: tensor([0.8761, 0.8602, 0.8538, 0.8514, 0.8473, 0.8387, 0.8277, 0.8124],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7705])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7918], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7705])\n",
      ">>Entradas: tensor([0.8602, 0.8538, 0.8514, 0.8473, 0.8387, 0.8277, 0.8124, 0.7918],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7427])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7691], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7427])\n",
      ">>Entradas: tensor([0.8538, 0.8514, 0.8473, 0.8387, 0.8277, 0.8124, 0.7918, 0.7691],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7449], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7169])\n",
      ">>Entradas: tensor([0.8514, 0.8473, 0.8387, 0.8277, 0.8124, 0.7918, 0.7691, 0.7449],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7266], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7197])\n",
      ">>Entradas: tensor([0.8473, 0.8387, 0.8277, 0.8124, 0.7918, 0.7691, 0.7449, 0.7266],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7509])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7211], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7509])\n",
      ">>Entradas: tensor([0.8387, 0.8277, 0.8124, 0.7918, 0.7691, 0.7449, 0.7266, 0.7211],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7403])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7139], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7403])\n",
      ">>Entradas: tensor([0.8277, 0.8124, 0.7918, 0.7691, 0.7449, 0.7266, 0.7211, 0.7139],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6928], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.8124, 0.7918, 0.7691, 0.7449, 0.7266, 0.7211, 0.7139, 0.6928],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6688])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6716], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6688])\n",
      ">>Entradas: tensor([0.7918, 0.7691, 0.7449, 0.7266, 0.7211, 0.7139, 0.6928, 0.6716],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6835])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6597], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6835])\n",
      ">>Entradas: tensor([0.7691, 0.7449, 0.7266, 0.7211, 0.7139, 0.6928, 0.6716, 0.6597],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6520], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.7449, 0.7266, 0.7211, 0.7139, 0.6928, 0.6716, 0.6597, 0.6520],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6815])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6475], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6815])\n",
      ">>Entradas: tensor([0.7266, 0.7211, 0.7139, 0.6928, 0.6716, 0.6597, 0.6520, 0.6475],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6893])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6505], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6893])\n",
      ">>Entradas: tensor([0.7211, 0.7139, 0.6928, 0.6716, 0.6597, 0.6520, 0.6475, 0.6505],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7111])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6601], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7111])\n",
      ">>Entradas: tensor([0.7139, 0.6928, 0.6716, 0.6597, 0.6520, 0.6475, 0.6505, 0.6601],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7349])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6742], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7349])\n",
      ">>Entradas: tensor([0.6928, 0.6716, 0.6597, 0.6520, 0.6475, 0.6505, 0.6601, 0.6742],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7608])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6946], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7608])\n",
      ">>Entradas: tensor([0.6716, 0.6597, 0.6520, 0.6475, 0.6505, 0.6601, 0.6742, 0.6946],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7711])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7171], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7711])\n",
      ">>Entradas: tensor([0.6597, 0.6520, 0.6475, 0.6505, 0.6601, 0.6742, 0.6946, 0.7171],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7660])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7360], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7660])\n",
      ">>Entradas: tensor([0.6520, 0.6475, 0.6505, 0.6601, 0.6742, 0.6946, 0.7171, 0.7360],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7483])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7477], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7483])\n",
      ">>Entradas: tensor([0.6475, 0.6505, 0.6601, 0.6742, 0.6946, 0.7171, 0.7360, 0.7477],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7182])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7497], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7182])\n",
      ">>Entradas: tensor([0.6505, 0.6601, 0.6742, 0.6946, 0.7171, 0.7360, 0.7477, 0.7497],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7485], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7089])\n",
      ">>Entradas: tensor([0.6601, 0.6742, 0.6946, 0.7171, 0.7360, 0.7477, 0.7497, 0.7485],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7204])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7514], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7204])\n",
      ">>Entradas: tensor([0.6742, 0.6946, 0.7171, 0.7360, 0.7477, 0.7497, 0.7485, 0.7514],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7706])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7678], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7706])\n",
      ">>Entradas: tensor([0.6946, 0.7171, 0.7360, 0.7477, 0.7497, 0.7485, 0.7514, 0.7678],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8595])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8061], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8595])\n",
      ">>Entradas: tensor([0.7171, 0.7360, 0.7477, 0.7497, 0.7485, 0.7514, 0.7678, 0.8061],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8484], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9065])\n",
      ">>Entradas: tensor([0.7360, 0.7477, 0.7497, 0.7485, 0.7514, 0.7678, 0.8061, 0.8484],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9119])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8813], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9119])\n",
      ">>Entradas: tensor([0.7477, 0.7497, 0.7485, 0.7514, 0.7678, 0.8061, 0.8484, 0.8813],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9043])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9035], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9043])\n",
      ">>Entradas: tensor([0.7497, 0.7485, 0.7514, 0.7678, 0.8061, 0.8484, 0.8813, 0.9035],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8839])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9134], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8839])\n",
      ">>Entradas: tensor([0.7485, 0.7514, 0.7678, 0.8061, 0.8484, 0.8813, 0.9035, 0.9134],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9032])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9263], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9032])\n",
      ">>Entradas: tensor([0.7514, 0.7678, 0.8061, 0.8484, 0.8813, 0.9035, 0.9134, 0.9263],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9623])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9554], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9623])\n",
      ">>Entradas: tensor([0.7678, 0.8061, 0.8484, 0.8813, 0.9035, 0.9134, 0.9263, 0.9554],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9821])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9853], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9821])\n",
      ">>Entradas: tensor([0.8061, 0.8484, 0.8813, 0.9035, 0.9134, 0.9263, 0.9554, 0.9853],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9624])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0000], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9624])\n",
      ">>Entradas: tensor([0.8484, 0.8813, 0.9035, 0.9134, 0.9263, 0.9554, 0.9853, 1.0000],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9303])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0005], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9303])\n",
      ">>Entradas: tensor([0.8813, 0.9035, 0.9134, 0.9263, 0.9554, 0.9853, 1.0000, 1.0005],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8855])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9820], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8855])\n",
      ">>Entradas: tensor([0.9035, 0.9134, 0.9263, 0.9554, 0.9853, 1.0000, 1.0005, 0.9820],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8597])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9549], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8597])\n",
      ">>Entradas: tensor([0.9134, 0.9263, 0.9554, 0.9853, 1.0000, 1.0005, 0.9820, 0.9549],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8529])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9302], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8529])\n",
      ">>Entradas: tensor([0.9263, 0.9554, 0.9853, 1.0000, 1.0005, 0.9820, 0.9549, 0.9302],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9121], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.9554, 0.9853, 1.0000, 1.0005, 0.9820, 0.9549, 0.9302, 0.9121],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8769])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9020], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8769])\n",
      ">>Entradas: tensor([0.9853, 1.0000, 1.0005, 0.9820, 0.9549, 0.9302, 0.9121, 0.9020],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8806])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8918], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8806])\n",
      ">>Entradas: tensor([1.0000, 1.0005, 0.9820, 0.9549, 0.9302, 0.9121, 0.9020, 0.8918],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8699])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8770], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8699])\n",
      ">>Entradas: tensor([1.0005, 0.9820, 0.9549, 0.9302, 0.9121, 0.9020, 0.8918, 0.8770],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8465])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8556], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8465])\n",
      ">>Entradas: tensor([0.9820, 0.9549, 0.9302, 0.9121, 0.9020, 0.8918, 0.8770, 0.8556],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8104])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8273], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8104])\n",
      ">>Entradas: tensor([0.9549, 0.9302, 0.9121, 0.9020, 0.8918, 0.8770, 0.8556, 0.8273],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8026])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8043], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8026])\n",
      ">>Entradas: tensor([0.9302, 0.9121, 0.9020, 0.8918, 0.8770, 0.8556, 0.8273, 0.8043],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8232])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7950], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8232])\n",
      ">>Entradas: tensor([0.9121, 0.9020, 0.8918, 0.8770, 0.8556, 0.8273, 0.8043, 0.7950],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8397])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7950], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8397])\n",
      ">>Entradas: tensor([0.9020, 0.8918, 0.8770, 0.8556, 0.8273, 0.8043, 0.7950, 0.7950],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8522])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8004], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8522])\n",
      ">>Entradas: tensor([0.8918, 0.8770, 0.8556, 0.8273, 0.8043, 0.7950, 0.7950, 0.8004],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8616])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8085], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8616])\n",
      ">>Entradas: tensor([0.8770, 0.8556, 0.8273, 0.8043, 0.7950, 0.7950, 0.8004, 0.8085],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8679])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8168], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8679])\n",
      ">>Entradas: tensor([0.8556, 0.8273, 0.8043, 0.7950, 0.7950, 0.8004, 0.8085, 0.8168],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8702])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8248], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8702])\n",
      ">>Entradas: tensor([0.8273, 0.8043, 0.7950, 0.7950, 0.8004, 0.8085, 0.8168, 0.8248],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8685])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8335], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8685])\n",
      ">>Entradas: tensor([0.8043, 0.7950, 0.7950, 0.8004, 0.8085, 0.8168, 0.8248, 0.8335],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8530])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8395], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8530])\n",
      ">>Entradas: tensor([0.7950, 0.7950, 0.8004, 0.8085, 0.8168, 0.8248, 0.8335, 0.8395],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8236])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8383], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8236])\n",
      ">>Entradas: tensor([0.7950, 0.8004, 0.8085, 0.8168, 0.8248, 0.8335, 0.8395, 0.8383],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8328], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.8004, 0.8085, 0.8168, 0.8248, 0.8335, 0.8395, 0.8383, 0.8328],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7919])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8246], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7919])\n",
      ">>Entradas: tensor([0.8085, 0.8168, 0.8248, 0.8335, 0.8395, 0.8383, 0.8328, 0.8246],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7865])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8161], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7865])\n",
      ">>Entradas: tensor([0.8168, 0.8248, 0.8335, 0.8395, 0.8383, 0.8328, 0.8246, 0.8161],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7870])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8086], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7870])\n",
      ">>Entradas: tensor([0.8248, 0.8335, 0.8395, 0.8383, 0.8328, 0.8246, 0.8161, 0.8086],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7874])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8022], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7874])\n",
      ">>Entradas: tensor([0.8335, 0.8395, 0.8383, 0.8328, 0.8246, 0.8161, 0.8086, 0.8022],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7879])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7961], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7879])\n",
      ">>Entradas: tensor([0.8395, 0.8383, 0.8328, 0.8246, 0.8161, 0.8086, 0.8022, 0.7961],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7955])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7922], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7955])\n",
      ">>Entradas: tensor([0.8383, 0.8328, 0.8246, 0.8161, 0.8086, 0.8022, 0.7961, 0.7922],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8102])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7926], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8102])\n",
      ">>Entradas: tensor([0.8328, 0.8246, 0.8161, 0.8086, 0.8022, 0.7961, 0.7922, 0.7926],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7668])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7797], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7668])\n",
      ">>Entradas: tensor([0.8246, 0.8161, 0.8086, 0.8022, 0.7961, 0.7922, 0.7926, 0.7797],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6655])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7405], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6655])\n",
      ">>Entradas: tensor([0.8161, 0.8086, 0.8022, 0.7961, 0.7922, 0.7926, 0.7797, 0.7405],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6361])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7019], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6361])\n",
      ">>Entradas: tensor([0.8086, 0.8022, 0.7961, 0.7922, 0.7926, 0.7797, 0.7405, 0.7019],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6785])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6834], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6785])\n",
      ">>Entradas: tensor([0.8022, 0.7961, 0.7922, 0.7926, 0.7797, 0.7405, 0.7019, 0.6834],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6732], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6966])\n",
      ">>Entradas: tensor([0.7961, 0.7922, 0.7926, 0.7797, 0.7405, 0.7019, 0.6834, 0.6732],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6903])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6651], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6903])\n",
      ">>Entradas: tensor([0.7922, 0.7926, 0.7797, 0.7405, 0.7019, 0.6834, 0.6732, 0.6651],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6970])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6629], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6970])\n",
      ">>Entradas: tensor([0.7926, 0.7797, 0.7405, 0.7019, 0.6834, 0.6732, 0.6651, 0.6629],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7167])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6649], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7167])\n",
      ">>Entradas: tensor([0.7797, 0.7405, 0.7019, 0.6834, 0.6732, 0.6651, 0.6629, 0.6649],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7491])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6734], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7491])\n",
      ">>Entradas: tensor([0.7405, 0.7019, 0.6834, 0.6732, 0.6651, 0.6629, 0.6649, 0.6734],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7940])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6964], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7940])\n",
      ">>Entradas: tensor([0.7019, 0.6834, 0.6732, 0.6651, 0.6629, 0.6649, 0.6734, 0.6964],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8547])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7389], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8547])\n",
      ">>Entradas: tensor([0.6834, 0.6732, 0.6651, 0.6629, 0.6649, 0.6734, 0.6964, 0.7389],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9314])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8005], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9314])\n",
      ">>Entradas: tensor([0.6732, 0.6651, 0.6629, 0.6649, 0.6734, 0.6964, 0.7389, 0.8005],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9627])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8612], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9627])\n",
      ">>Entradas: tensor([0.6651, 0.6629, 0.6649, 0.6734, 0.6964, 0.7389, 0.8005, 0.8612],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9486])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9078], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9486])\n",
      ">>Entradas: tensor([0.6629, 0.6649, 0.6734, 0.6964, 0.7389, 0.8005, 0.8612, 0.9078],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9307])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9413], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9307])\n",
      ">>Entradas: tensor([0.6649, 0.6734, 0.6964, 0.7389, 0.8005, 0.8612, 0.9078, 0.9413],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9090])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9554], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9090])\n",
      ">>Entradas: tensor([0.6734, 0.6964, 0.7389, 0.8005, 0.8612, 0.9078, 0.9413, 0.9554],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8816])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9648], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8816])\n",
      ">>Entradas: tensor([0.6964, 0.7389, 0.8005, 0.8612, 0.9078, 0.9413, 0.9554, 0.9648],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8487])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9629], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8487])\n",
      ">>Entradas: tensor([0.7389, 0.8005, 0.8612, 0.9078, 0.9413, 0.9554, 0.9648, 0.9629],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8753])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9676], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8753])\n",
      ">>Entradas: tensor([0.8005, 0.8612, 0.9078, 0.9413, 0.9554, 0.9648, 0.9629, 0.9676],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9612])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9912], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9612])\n",
      ">>Entradas: tensor([0.8612, 0.9078, 0.9413, 0.9554, 0.9648, 0.9629, 0.9676, 0.9912],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9925])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0118], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9925])\n",
      ">>Entradas: tensor([0.9078, 0.9413, 0.9554, 0.9648, 0.9629, 0.9676, 0.9912, 1.0118],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9690])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0056], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9690])\n",
      ">>Entradas: tensor([0.9413, 0.9554, 0.9648, 0.9629, 0.9676, 0.9912, 1.0118, 1.0056],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9715])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0060], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9715])\n",
      ">>Entradas: tensor([0.9554, 0.9648, 0.9629, 0.9676, 0.9912, 1.0118, 1.0056, 1.0060],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([1.])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0101], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([1.])\n",
      ">>Entradas: tensor([0.9648, 0.9629, 0.9676, 0.9912, 1.0118, 1.0056, 1.0060, 1.0101],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0042], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9801])\n",
      ">>Entradas: tensor([0.9629, 0.9676, 0.9912, 1.0118, 1.0056, 1.0060, 1.0101, 1.0042],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9812], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9117])\n",
      ">>Entradas: tensor([0.9676, 0.9912, 1.0118, 1.0056, 1.0060, 1.0101, 1.0042, 0.9812],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8911])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9597], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8911])\n",
      ">>Entradas: tensor([0.9912, 1.0118, 1.0056, 1.0060, 1.0101, 1.0042, 0.9812, 0.9597],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9181])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9470], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9181])\n",
      ">>Entradas: tensor([1.0118, 1.0056, 1.0060, 1.0101, 1.0042, 0.9812, 0.9597, 0.9470],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9450])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9410], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9450])\n",
      ">>Entradas: tensor([1.0056, 1.0060, 1.0101, 1.0042, 0.9812, 0.9597, 0.9470, 0.9410],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9718])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9445], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9718])\n",
      ">>Entradas: tensor([1.0060, 1.0101, 1.0042, 0.9812, 0.9597, 0.9470, 0.9410, 0.9445],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9829])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9515], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9829])\n",
      ">>Entradas: tensor([1.0101, 1.0042, 0.9812, 0.9597, 0.9470, 0.9410, 0.9445, 0.9515],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9783])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9540], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9783])\n",
      ">>s_original: [0.049424633383750916, 0.10789185762405396, 0.13719609379768372, 0.13733737170696259, 0.1338856965303421, 0.12684109807014465, 0.14756061136722565, 0.19604423642158508, 0.21688967943191528, 0.21009695529937744, 0.20267784595489502, 0.1946323662996292, 0.19407351315021515, 0.20100130140781403, 0.19663821160793304, 0.180984228849411, 0.16539041697978973, 0.14985674619674683, 0.15043111145496368, 0.1671135276556015, 0.20227035880088806, 0.25590160489082336, 0.29268819093704224, 0.31263017654418945, 0.31093889474868774, 0.2876143157482147, 0.28016164898872375, 0.28858086466789246, 0.28246283531188965, 0.26180753111839294, 0.2801212966442108, 0.3374040722846985, 0.3482298254966736, 0.3125985562801361, 0.34358710050582886, 0.44119545817375183, 0.521095335483551, 0.5832866430282593, 0.6089234352111816, 0.5980057120323181, 0.5945301651954651, 0.5984968543052673, 0.621354341506958, 0.6631026864051819, 0.6928724050521851, 0.7106636166572571, 0.721682071685791, 0.7259277701377869, 0.7404318451881409, 0.7651942372322083, 0.7447891235351562, 0.6792163252830505, 0.6746017932891846, 0.730945348739624, 0.7467210292816162, 0.7219287157058716, 0.7199286818504333, 0.7407209277153015, 0.7362455129623413, 0.7065023183822632, 0.6979451775550842, 0.7105739712715149, 0.7209621667861938, 0.7291097044944763, 0.7674259543418884, 0.8359109163284302, 0.8510103225708008, 0.8127241730690002, 0.7863940000534058, 0.7720199823379517, 0.8033170700073242, 0.8802852630615234, 0.8987051844596863, 0.8585767149925232, 0.8308762311935425, 0.8156037926673889, 0.8116992115974426, 0.8191625475883484, 0.8218275904655457, 0.8196942210197449, 0.817862868309021, 0.8163333535194397, 0.8005555868148804, 0.7705295085906982, 0.7426586747169495, 0.716943085193634, 0.7197051048278809, 0.7509447932243347, 0.7402781248092651, 0.6877052187919617, 0.6687695384025574, 0.683471143245697, 0.6877052187919617, 0.6814717054367065, 0.6892618536949158, 0.7110756039619446, 0.7349108457565308, 0.7607676982879639, 0.771117091178894, 0.7659589648246765, 0.7483323812484741, 0.7182371616363525, 0.708941638469696, 0.7204458117485046, 0.7706154584884644, 0.8594506978988647, 0.906541109085083, 0.9118866324424744, 0.9043355584144592, 0.8838878870010376, 0.9032153487205505, 0.9623178839683533, 0.9820588231086731, 0.96243816614151, 0.9302511811256409, 0.8854979276657104, 0.8597025871276855, 0.8528652191162109, 0.8585854768753052, 0.8768633008003235, 0.8806464076042175, 0.8699347376823425, 0.846513569355011, 0.8103827834129333, 0.8026111125946045, 0.8231984972953796, 0.8397204279899597, 0.8521769046783447, 0.8615626692771912, 0.8678776621818542, 0.8701963424682617, 0.868518590927124, 0.852988064289093, 0.8236046433448792, 0.8032509088516235, 0.7919268012046814, 0.7865023016929626, 0.7869773507118225, 0.7874362468719482, 0.7878790497779846, 0.7954531908035278, 0.8101586699485779, 0.7668473124504089, 0.665519118309021, 0.6360738277435303, 0.678511381149292, 0.6965967416763306, 0.6903298497200012, 0.6970472931861877, 0.7167490720748901, 0.7490506768226624, 0.7939522862434387, 0.8547447323799133, 0.931428074836731, 0.9627243876457214, 0.9486336708068848, 0.9307146072387695, 0.9089671969413757, 0.8816379904747009, 0.8487268090248108, 0.8752607107162476, 0.9612395763397217, 0.9925020933151245, 0.9690483212471008, 0.9715476036071777, 1.0, 0.9800636768341064, 0.9117385745048523, 0.8910858035087585, 0.9181053042411804, 0.9450165033340454, 0.9718193411827087, 0.982906699180603, 0.9782785773277283]\n",
      ">>s_pred: [-0.1392960548400879, -0.07317924499511719, 0.005607128143310547, 0.05409049987792969, 0.08980703353881836, 0.11401557922363281, 0.12914657592773438, 0.1541156768798828, 0.19423532485961914, 0.24146318435668945, 0.2695627212524414, 0.28151416778564453, 0.28567028045654297, 0.2850918769836426, 0.28075313568115234, 0.27213191986083984, 0.2561206817626953, 0.23267507553100586, 0.20196914672851562, 0.18393802642822266, 0.17712783813476562, 0.18631362915039062, 0.20546340942382812, 0.22728967666625977, 0.24507951736450195, 0.2548332214355469, 0.26462602615356445, 0.27953577041625977, 0.292783260345459, 0.29943132400512695, 0.31038522720336914, 0.33289527893066406, 0.35024547576904297, 0.35254716873168945, 0.3648347854614258, 0.40099239349365234, 0.4503793716430664, 0.5101146697998047, 0.5682592391967773, 0.6103477478027344, 0.6400065422058105, 0.6642632484436035, 0.6904053688049316, 0.7231097221374512, 0.7547907829284668, 0.779599666595459, 0.7949213981628418, 0.8007698059082031, 0.8035616874694824, 0.8104977607727051, 0.8070006370544434, 0.7833313941955566, 0.7596831321716309, 0.7524971961975098, 0.7470188140869141, 0.7348861694335938, 0.7257437705993652, 0.722224235534668, 0.7148284912109375, 0.701718807220459, 0.6928949356079102, 0.6908674240112305, 0.6920700073242188, 0.6970672607421875, 0.7145185470581055, 0.7491655349731445, 0.7809247970581055, 0.7969374656677246, 0.8047351837158203, 0.8068227767944336, 0.8173184394836426, 0.8499650955200195, 0.8820562362670898, 0.8937268257141113, 0.8860664367675781, 0.8760724067687988, 0.860166072845459, 0.8537535667419434, 0.851402759552002, 0.8473491668701172, 0.8386783599853516, 0.8276882171630859, 0.8123693466186523, 0.7917671203613281, 0.7690606117248535, 0.7448840141296387, 0.7265682220458984, 0.7211179733276367, 0.7139315605163574, 0.6927652359008789, 0.6716375350952148, 0.6596746444702148, 0.652012825012207, 0.6475200653076172, 0.6504807472229004, 0.6601319313049316, 0.6741504669189453, 0.6946392059326172, 0.7171492576599121, 0.7359819412231445, 0.747711181640625, 0.7497406005859375, 0.7485237121582031, 0.7514233589172363, 0.7678451538085938, 0.8061246871948242, 0.8483991622924805, 0.8813328742980957, 0.9035148620605469, 0.9133729934692383, 0.9262866973876953, 0.9554414749145508, 0.9853472709655762, 1.0000476837158203, 1.000473976135254, 0.9819793701171875, 0.9548707008361816, 0.9301776885986328, 0.9121208190917969, 0.9020161628723145, 0.8918309211730957, 0.8769865036010742, 0.8555688858032227, 0.8272862434387207, 0.8042964935302734, 0.7950191497802734, 0.7949934005737305, 0.8004155158996582, 0.8084983825683594, 0.8168478012084961, 0.8248176574707031, 0.8334650993347168, 0.8394503593444824, 0.8383255004882812, 0.8328118324279785, 0.8246407508850098, 0.8160567283630371, 0.8086061477661133, 0.8022136688232422, 0.7961239814758301, 0.7922039031982422, 0.7925620079040527, 0.779667854309082, 0.7404556274414062, 0.7018952369689941, 0.6834049224853516, 0.6731624603271484, 0.6650795936584473, 0.6629033088684082, 0.6649045944213867, 0.6734275817871094, 0.6963539123535156, 0.7388648986816406, 0.8004670143127441, 0.8611812591552734, 0.9077544212341309, 0.9413189888000488, 0.9553818702697754, 0.9647822380065918, 0.962867259979248, 0.9675955772399902, 0.9911541938781738, 1.0117688179016113, 1.0055599212646484, 1.0060482025146484, 1.0101170539855957, 1.0041866302490234, 0.9811649322509766, 0.9596638679504395, 0.9470219612121582, 0.9410305023193359, 0.9444680213928223, 0.9515256881713867, 0.9539661407470703]\n",
      "<<Perdida: 0.002935349242761731 epoca: 8\n",
      "---Inicio de epoca: 9--\n",
      ">>Entradas: tensor([0.0503, 0.0086, 0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203])\n",
      ">>Salida: tensor([0.0494])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([-0.2016], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.0494])\n",
      ">>Entradas: tensor([ 0.0086,  0.0000,  0.0245,  0.0327,  0.0246,  0.0205,  0.0203, -0.2016],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1079])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([-0.1178], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1079])\n",
      ">>Entradas: tensor([ 0.0000,  0.0245,  0.0327,  0.0246,  0.0205,  0.0203, -0.2016, -0.1178],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1372])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([-0.0513], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1372])\n",
      ">>Entradas: tensor([ 0.0245,  0.0327,  0.0246,  0.0205,  0.0203, -0.2016, -0.1178, -0.0513],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1373])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([-0.0271], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1373])\n",
      ">>Entradas: tensor([ 0.0327,  0.0246,  0.0205,  0.0203, -0.2016, -0.1178, -0.0513, -0.0271],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1339])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0307], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1339])\n",
      ">>Entradas: tensor([ 0.0246,  0.0205,  0.0203, -0.2016, -0.1178, -0.0513, -0.0271,  0.0307],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1268])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0643], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1268])\n",
      ">>Entradas: tensor([ 0.0205,  0.0203, -0.2016, -0.1178, -0.0513, -0.0271,  0.0307,  0.0643],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1476])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0836], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1476])\n",
      ">>Entradas: tensor([ 0.0203, -0.2016, -0.1178, -0.0513, -0.0271,  0.0307,  0.0643,  0.0836],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1960])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1154], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1960])\n",
      ">>Entradas: tensor([-0.2016, -0.1178, -0.0513, -0.0271,  0.0307,  0.0643,  0.0836,  0.1154],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1651], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2169])\n",
      ">>Entradas: tensor([-0.1178, -0.0513, -0.0271,  0.0307,  0.0643,  0.0836,  0.1154,  0.1651],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2101])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2242], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2101])\n",
      ">>Entradas: tensor([-0.0513, -0.0271,  0.0307,  0.0643,  0.0836,  0.1154,  0.1651,  0.2242],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2027])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2608], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2027])\n",
      ">>Entradas: tensor([-0.0271,  0.0307,  0.0643,  0.0836,  0.1154,  0.1651,  0.2242,  0.2608],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1946])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2847], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1946])\n",
      ">>Entradas: tensor([0.0307, 0.0643, 0.0836, 0.1154, 0.1651, 0.2242, 0.2608, 0.2847],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1941])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3016], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1941])\n",
      ">>Entradas: tensor([0.0643, 0.0836, 0.1154, 0.1651, 0.2242, 0.2608, 0.2847, 0.3016],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2010])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3078], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2010])\n",
      ">>Entradas: tensor([0.0836, 0.1154, 0.1651, 0.2242, 0.2608, 0.2847, 0.3016, 0.3078],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3084], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1966])\n",
      ">>Entradas: tensor([0.1154, 0.1651, 0.2242, 0.2608, 0.2847, 0.3016, 0.3078, 0.3084],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1810])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3034], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1810])\n",
      ">>Entradas: tensor([0.1651, 0.2242, 0.2608, 0.2847, 0.3016, 0.3078, 0.3084, 0.3034],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1654])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2908], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1654])\n",
      ">>Entradas: tensor([0.2242, 0.2608, 0.2847, 0.3016, 0.3078, 0.3084, 0.3034, 0.2908],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1499])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2678], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1499])\n",
      ">>Entradas: tensor([0.2608, 0.2847, 0.3016, 0.3078, 0.3084, 0.3034, 0.2908, 0.2678],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1504])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2405], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1504])\n",
      ">>Entradas: tensor([0.2847, 0.3016, 0.3078, 0.3084, 0.3034, 0.2908, 0.2678, 0.2405],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1671])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2186], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1671])\n",
      ">>Entradas: tensor([0.3016, 0.3078, 0.3084, 0.3034, 0.2908, 0.2678, 0.2405, 0.2186],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2023])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2067], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2023])\n",
      ">>Entradas: tensor([0.3078, 0.3084, 0.3034, 0.2908, 0.2678, 0.2405, 0.2186, 0.2067],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2559])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2102], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2559])\n",
      ">>Entradas: tensor([0.3084, 0.3034, 0.2908, 0.2678, 0.2405, 0.2186, 0.2067, 0.2102],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2927])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2227], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2927])\n",
      ">>Entradas: tensor([0.3034, 0.2908, 0.2678, 0.2405, 0.2186, 0.2067, 0.2102, 0.2227],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2379], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2908, 0.2678, 0.2405, 0.2186, 0.2067, 0.2102, 0.2227, 0.2379],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3109])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2500], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3109])\n",
      ">>Entradas: tensor([0.2678, 0.2405, 0.2186, 0.2067, 0.2102, 0.2227, 0.2379, 0.2500],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2876])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2543], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2876])\n",
      ">>Entradas: tensor([0.2405, 0.2186, 0.2067, 0.2102, 0.2227, 0.2379, 0.2500, 0.2543],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2802])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2591], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2802])\n",
      ">>Entradas: tensor([0.2186, 0.2067, 0.2102, 0.2227, 0.2379, 0.2500, 0.2543, 0.2591],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2886])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2695], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2886])\n",
      ">>Entradas: tensor([0.2067, 0.2102, 0.2227, 0.2379, 0.2500, 0.2543, 0.2591, 0.2695],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2825])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2790], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2825])\n",
      ">>Entradas: tensor([0.2102, 0.2227, 0.2379, 0.2500, 0.2543, 0.2591, 0.2695, 0.2790],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2618])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2831], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2618])\n",
      ">>Entradas: tensor([0.2227, 0.2379, 0.2500, 0.2543, 0.2591, 0.2695, 0.2790, 0.2831],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2926], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2801])\n",
      ">>Entradas: tensor([0.2379, 0.2500, 0.2543, 0.2591, 0.2695, 0.2790, 0.2831, 0.2926],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3374])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3151], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3374])\n",
      ">>Entradas: tensor([0.2500, 0.2543, 0.2591, 0.2695, 0.2790, 0.2831, 0.2926, 0.3151],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3482])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3329], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3482])\n",
      ">>Entradas: tensor([0.2543, 0.2591, 0.2695, 0.2790, 0.2831, 0.2926, 0.3151, 0.3329],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3365], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2591, 0.2695, 0.2790, 0.2831, 0.2926, 0.3151, 0.3329, 0.3365],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3436])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3507], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3436])\n",
      ">>Entradas: tensor([0.2695, 0.2790, 0.2831, 0.2926, 0.3151, 0.3329, 0.3365, 0.3507],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.4412])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3894], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.4412])\n",
      ">>Entradas: tensor([0.2790, 0.2831, 0.2926, 0.3151, 0.3329, 0.3365, 0.3507, 0.3894],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5211])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4409], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5211])\n",
      ">>Entradas: tensor([0.2831, 0.2926, 0.3151, 0.3329, 0.3365, 0.3507, 0.3894, 0.4409],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5833])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5025], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5833])\n",
      ">>Entradas: tensor([0.2926, 0.3151, 0.3329, 0.3365, 0.3507, 0.3894, 0.4409, 0.5025],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5628], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6089])\n",
      ">>Entradas: tensor([0.3151, 0.3329, 0.3365, 0.3507, 0.3894, 0.4409, 0.5025, 0.5628],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5980])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6070], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5980])\n",
      ">>Entradas: tensor([0.3329, 0.3365, 0.3507, 0.3894, 0.4409, 0.5025, 0.5628, 0.6070],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5945])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6389], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5945])\n",
      ">>Entradas: tensor([0.3365, 0.3507, 0.3894, 0.4409, 0.5025, 0.5628, 0.6070, 0.6389],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5985])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6650], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5985])\n",
      ">>Entradas: tensor([0.3507, 0.3894, 0.4409, 0.5025, 0.5628, 0.6070, 0.6389, 0.6650],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6214])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6946], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6214])\n",
      ">>Entradas: tensor([0.3894, 0.4409, 0.5025, 0.5628, 0.6070, 0.6389, 0.6650, 0.6946],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6631])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7286], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6631])\n",
      ">>Entradas: tensor([0.4409, 0.5025, 0.5628, 0.6070, 0.6389, 0.6650, 0.6946, 0.7286],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6929])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7616], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6929])\n",
      ">>Entradas: tensor([0.5025, 0.5628, 0.6070, 0.6389, 0.6650, 0.6946, 0.7286, 0.7616],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7107])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7869], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7107])\n",
      ">>Entradas: tensor([0.5628, 0.6070, 0.6389, 0.6650, 0.6946, 0.7286, 0.7616, 0.7869],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7217])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8021], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7217])\n",
      ">>Entradas: tensor([0.6070, 0.6389, 0.6650, 0.6946, 0.7286, 0.7616, 0.7869, 0.8021],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7259])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8076], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7259])\n",
      ">>Entradas: tensor([0.6389, 0.6650, 0.6946, 0.7286, 0.7616, 0.7869, 0.8021, 0.8076],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7404])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8110], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7404])\n",
      ">>Entradas: tensor([0.6650, 0.6946, 0.7286, 0.7616, 0.7869, 0.8021, 0.8076, 0.8110],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7652])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8174], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7652])\n",
      ">>Entradas: tensor([0.6946, 0.7286, 0.7616, 0.7869, 0.8021, 0.8076, 0.8110, 0.8174],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7448])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8140], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7448])\n",
      ">>Entradas: tensor([0.7286, 0.7616, 0.7869, 0.8021, 0.8076, 0.8110, 0.8174, 0.8140],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6792])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7889], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6792])\n",
      ">>Entradas: tensor([0.7616, 0.7869, 0.8021, 0.8076, 0.8110, 0.8174, 0.8140, 0.7889],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6746])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7641], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6746])\n",
      ">>Entradas: tensor([0.7869, 0.8021, 0.8076, 0.8110, 0.8174, 0.8140, 0.7889, 0.7641],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7558], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7309])\n",
      ">>Entradas: tensor([0.8021, 0.8076, 0.8110, 0.8174, 0.8140, 0.7889, 0.7641, 0.7558],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7467])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7492], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7467])\n",
      ">>Entradas: tensor([0.8076, 0.8110, 0.8174, 0.8140, 0.7889, 0.7641, 0.7558, 0.7492],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7219])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7359], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7219])\n",
      ">>Entradas: tensor([0.8110, 0.8174, 0.8140, 0.7889, 0.7641, 0.7558, 0.7492, 0.7359],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7199])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7257], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7199])\n",
      ">>Entradas: tensor([0.8174, 0.8140, 0.7889, 0.7641, 0.7558, 0.7492, 0.7359, 0.7257],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7407])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7213], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7407])\n",
      ">>Entradas: tensor([0.8140, 0.7889, 0.7641, 0.7558, 0.7492, 0.7359, 0.7257, 0.7213],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7362])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7131], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7362])\n",
      ">>Entradas: tensor([0.7889, 0.7641, 0.7558, 0.7492, 0.7359, 0.7257, 0.7213, 0.7131],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6993], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7065])\n",
      ">>Entradas: tensor([0.7641, 0.7558, 0.7492, 0.7359, 0.7257, 0.7213, 0.7131, 0.6993],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6979])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6903], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6979])\n",
      ">>Entradas: tensor([0.7558, 0.7492, 0.7359, 0.7257, 0.7213, 0.7131, 0.6993, 0.6903],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7106])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6897], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7106])\n",
      ">>Entradas: tensor([0.7492, 0.7359, 0.7257, 0.7213, 0.7131, 0.6993, 0.6903, 0.6897],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7210])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6905], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7210])\n",
      ">>Entradas: tensor([0.7359, 0.7257, 0.7213, 0.7131, 0.6993, 0.6903, 0.6897, 0.6905],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7291])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6954], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7291])\n",
      ">>Entradas: tensor([0.7257, 0.7213, 0.7131, 0.6993, 0.6903, 0.6897, 0.6905, 0.6954],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7674])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7325], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7674])\n",
      ">>Entradas: tensor([0.7213, 0.7131, 0.6993, 0.6903, 0.6897, 0.6905, 0.6954, 0.7325],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8359])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7618], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8359])\n",
      ">>Entradas: tensor([0.7131, 0.6993, 0.6903, 0.6897, 0.6905, 0.6954, 0.7325, 0.7618],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8510])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7900], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8510])\n",
      ">>Entradas: tensor([0.6993, 0.6903, 0.6897, 0.6905, 0.6954, 0.7325, 0.7618, 0.7900],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8127])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8042], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8127])\n",
      ">>Entradas: tensor([0.6903, 0.6897, 0.6905, 0.6954, 0.7325, 0.7618, 0.7900, 0.8042],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7864])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8097], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7864])\n",
      ">>Entradas: tensor([0.6897, 0.6905, 0.6954, 0.7325, 0.7618, 0.7900, 0.8042, 0.8097],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7720])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8091], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7720])\n",
      ">>Entradas: tensor([0.6905, 0.6954, 0.7325, 0.7618, 0.7900, 0.8042, 0.8097, 0.8091],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8205], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.6954, 0.7325, 0.7618, 0.7900, 0.8042, 0.8097, 0.8091, 0.8205],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8803])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8533], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8803])\n",
      ">>Entradas: tensor([0.7325, 0.7618, 0.7900, 0.8042, 0.8097, 0.8091, 0.8205, 0.8533],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8987])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8826], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8987])\n",
      ">>Entradas: tensor([0.7618, 0.7900, 0.8042, 0.8097, 0.8091, 0.8205, 0.8533, 0.8826],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8905], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.7900, 0.8042, 0.8097, 0.8091, 0.8205, 0.8533, 0.8826, 0.8905],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8819], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8309])\n",
      ">>Entradas: tensor([0.8042, 0.8097, 0.8091, 0.8205, 0.8533, 0.8826, 0.8905, 0.8819],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8156])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8716], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8156])\n",
      ">>Entradas: tensor([0.8097, 0.8091, 0.8205, 0.8533, 0.8826, 0.8905, 0.8819, 0.8716],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8590], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8117])\n",
      ">>Entradas: tensor([0.8091, 0.8205, 0.8533, 0.8826, 0.8905, 0.8819, 0.8716, 0.8590],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8192])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8529], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8192])\n",
      ">>Entradas: tensor([0.8205, 0.8533, 0.8826, 0.8905, 0.8819, 0.8716, 0.8590, 0.8529],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8218])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8508], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8218])\n",
      ">>Entradas: tensor([0.8533, 0.8826, 0.8905, 0.8819, 0.8716, 0.8590, 0.8529, 0.8508],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8461], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8197])\n",
      ">>Entradas: tensor([0.8826, 0.8905, 0.8819, 0.8716, 0.8590, 0.8529, 0.8508, 0.8461],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8179])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8370], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8179])\n",
      ">>Entradas: tensor([0.8905, 0.8819, 0.8716, 0.8590, 0.8529, 0.8508, 0.8461, 0.8370],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8163])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8264], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8163])\n",
      ">>Entradas: tensor([0.8819, 0.8716, 0.8590, 0.8529, 0.8508, 0.8461, 0.8370, 0.8264],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8006])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8122], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8006])\n",
      ">>Entradas: tensor([0.8716, 0.8590, 0.8529, 0.8508, 0.8461, 0.8370, 0.8264, 0.8122],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7705])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7929], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7705])\n",
      ">>Entradas: tensor([0.8590, 0.8529, 0.8508, 0.8461, 0.8370, 0.8264, 0.8122, 0.7929],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7427])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7688], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7427])\n",
      ">>Entradas: tensor([0.8529, 0.8508, 0.8461, 0.8370, 0.8264, 0.8122, 0.7929, 0.7688],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7431], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7169])\n",
      ">>Entradas: tensor([0.8508, 0.8461, 0.8370, 0.8264, 0.8122, 0.7929, 0.7688, 0.7431],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7265], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7197])\n",
      ">>Entradas: tensor([0.8461, 0.8370, 0.8264, 0.8122, 0.7929, 0.7688, 0.7431, 0.7265],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7509])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7221], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7509])\n",
      ">>Entradas: tensor([0.8370, 0.8264, 0.8122, 0.7929, 0.7688, 0.7431, 0.7265, 0.7221],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7403])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7151], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7403])\n",
      ">>Entradas: tensor([0.8264, 0.8122, 0.7929, 0.7688, 0.7431, 0.7265, 0.7221, 0.7151],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6946], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.8122, 0.7929, 0.7688, 0.7431, 0.7265, 0.7221, 0.7151, 0.6946],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6688])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6744], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6688])\n",
      ">>Entradas: tensor([0.7929, 0.7688, 0.7431, 0.7265, 0.7221, 0.7151, 0.6946, 0.6744],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6835])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6633], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6835])\n",
      ">>Entradas: tensor([0.7688, 0.7431, 0.7265, 0.7221, 0.7151, 0.6946, 0.6744, 0.6633],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6561], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.7431, 0.7265, 0.7221, 0.7151, 0.6946, 0.6744, 0.6633, 0.6561],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6815])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6520], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6815])\n",
      ">>Entradas: tensor([0.7265, 0.7221, 0.7151, 0.6946, 0.6744, 0.6633, 0.6561, 0.6520],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6893])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6549], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6893])\n",
      ">>Entradas: tensor([0.7221, 0.7151, 0.6946, 0.6744, 0.6633, 0.6561, 0.6520, 0.6549],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7111])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6650], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7111])\n",
      ">>Entradas: tensor([0.7151, 0.6946, 0.6744, 0.6633, 0.6561, 0.6520, 0.6549, 0.6650],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7349])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6777], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7349])\n",
      ">>Entradas: tensor([0.6946, 0.6744, 0.6633, 0.6561, 0.6520, 0.6549, 0.6650, 0.6777],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7608])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6972], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7608])\n",
      ">>Entradas: tensor([0.6744, 0.6633, 0.6561, 0.6520, 0.6549, 0.6650, 0.6777, 0.6972],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7711])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7186], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7711])\n",
      ">>Entradas: tensor([0.6633, 0.6561, 0.6520, 0.6549, 0.6650, 0.6777, 0.6972, 0.7186],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7660])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7360], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7660])\n",
      ">>Entradas: tensor([0.6561, 0.6520, 0.6549, 0.6650, 0.6777, 0.6972, 0.7186, 0.7360],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7483])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7465], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7483])\n",
      ">>Entradas: tensor([0.6520, 0.6549, 0.6650, 0.6777, 0.6972, 0.7186, 0.7360, 0.7465],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7182])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7478], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7182])\n",
      ">>Entradas: tensor([0.6549, 0.6650, 0.6777, 0.6972, 0.7186, 0.7360, 0.7465, 0.7478],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5553], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7089])\n",
      "ERROR: la modificacion de los pesos di√≥ un error mayor: 0.02359791472554207, se regresa al estado anterior de la red\n",
      ">>Entradas: tensor([0.6650, 0.6777, 0.6972, 0.7186, 0.7360, 0.7465, 0.7478, 0.7631],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7204])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7609], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7204])\n",
      ">>Entradas: tensor([0.6777, 0.6972, 0.7186, 0.7360, 0.7465, 0.7478, 0.7631, 0.7609],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7706])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7749], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7706])\n",
      ">>Entradas: tensor([0.6972, 0.7186, 0.7360, 0.7465, 0.7478, 0.7631, 0.7609, 0.7749],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8595])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8113], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8595])\n",
      ">>Entradas: tensor([0.7186, 0.7360, 0.7465, 0.7478, 0.7631, 0.7609, 0.7749, 0.8113],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8505], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9065])\n",
      ">>Entradas: tensor([0.7360, 0.7465, 0.7478, 0.7631, 0.7609, 0.7749, 0.8113, 0.8505],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9119])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8796], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9119])\n",
      ">>Entradas: tensor([0.7465, 0.7478, 0.7631, 0.7609, 0.7749, 0.8113, 0.8505, 0.8796],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9043])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9019], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9043])\n",
      ">>Entradas: tensor([0.7478, 0.7631, 0.7609, 0.7749, 0.8113, 0.8505, 0.8796, 0.9019],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8839])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9120], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8839])\n",
      ">>Entradas: tensor([0.7631, 0.7609, 0.7749, 0.8113, 0.8505, 0.8796, 0.9019, 0.9120],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9032])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9238], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9032])\n",
      ">>Entradas: tensor([0.7609, 0.7749, 0.8113, 0.8505, 0.8796, 0.9019, 0.9120, 0.9238],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9623])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9519], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9623])\n",
      ">>Entradas: tensor([0.7749, 0.8113, 0.8505, 0.8796, 0.9019, 0.9120, 0.9238, 0.9519],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9821])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9807], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9821])\n",
      ">>Entradas: tensor([0.8113, 0.8505, 0.8796, 0.9019, 0.9120, 0.9238, 0.9519, 0.9807],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9624])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9952], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9624])\n",
      ">>Entradas: tensor([0.8505, 0.8796, 0.9019, 0.9120, 0.9238, 0.9519, 0.9807, 0.9952],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9303])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9943], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9303])\n",
      ">>Entradas: tensor([0.8796, 0.9019, 0.9120, 0.9238, 0.9519, 0.9807, 0.9952, 0.9943],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8855])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9764], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8855])\n",
      ">>Entradas: tensor([0.9019, 0.9120, 0.9238, 0.9519, 0.9807, 0.9952, 0.9943, 0.9764],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8597])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9507], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8597])\n",
      ">>Entradas: tensor([0.9120, 0.9238, 0.9519, 0.9807, 0.9952, 0.9943, 0.9764, 0.9507],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8529])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9274], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8529])\n",
      ">>Entradas: tensor([0.9238, 0.9519, 0.9807, 0.9952, 0.9943, 0.9764, 0.9507, 0.9274],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8927], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.9519, 0.9807, 0.9952, 0.9943, 0.9764, 0.9507, 0.9274, 0.8927],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8769])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8881], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8769])\n",
      ">>Entradas: tensor([0.9807, 0.9952, 0.9943, 0.9764, 0.9507, 0.9274, 0.8927, 0.8881],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8806])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8808], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8806])\n",
      ">>Entradas: tensor([0.9952, 0.9943, 0.9764, 0.9507, 0.9274, 0.8927, 0.8881, 0.8808],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8699])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8681], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8699])\n",
      ">>Entradas: tensor([0.9943, 0.9764, 0.9507, 0.9274, 0.8927, 0.8881, 0.8808, 0.8681],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8465])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8494], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8465])\n",
      ">>Entradas: tensor([0.9764, 0.9507, 0.9274, 0.8927, 0.8881, 0.8808, 0.8681, 0.8494],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8104])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8252], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8104])\n",
      ">>Entradas: tensor([0.9507, 0.9274, 0.8927, 0.8881, 0.8808, 0.8681, 0.8494, 0.8252],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8026])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8031], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8026])\n",
      ">>Entradas: tensor([0.9274, 0.8927, 0.8881, 0.8808, 0.8681, 0.8494, 0.8252, 0.8031],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8232])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7949], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8232])\n",
      ">>Entradas: tensor([0.8927, 0.8881, 0.8808, 0.8681, 0.8494, 0.8252, 0.8031, 0.7949],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8397])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8031], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8397])\n",
      ">>Entradas: tensor([0.8881, 0.8808, 0.8681, 0.8494, 0.8252, 0.8031, 0.7949, 0.8031],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8522])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8085], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8522])\n",
      ">>Entradas: tensor([0.8808, 0.8681, 0.8494, 0.8252, 0.8031, 0.7949, 0.8031, 0.8085],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8616])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8162], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8616])\n",
      ">>Entradas: tensor([0.8681, 0.8494, 0.8252, 0.8031, 0.7949, 0.8031, 0.8085, 0.8162],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8679])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8246], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8679])\n",
      ">>Entradas: tensor([0.8494, 0.8252, 0.8031, 0.7949, 0.8031, 0.8085, 0.8162, 0.8246],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8702])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8321], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8702])\n",
      ">>Entradas: tensor([0.8252, 0.8031, 0.7949, 0.8031, 0.8085, 0.8162, 0.8246, 0.8321],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8685])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8395], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8685])\n",
      ">>Entradas: tensor([0.8031, 0.7949, 0.8031, 0.8085, 0.8162, 0.8246, 0.8321, 0.8395],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8530])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8451], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8530])\n",
      ">>Entradas: tensor([0.7949, 0.8031, 0.8085, 0.8162, 0.8246, 0.8321, 0.8395, 0.8451],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8236])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8433], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8236])\n",
      ">>Entradas: tensor([0.8031, 0.8085, 0.8162, 0.8246, 0.8321, 0.8395, 0.8451, 0.8433],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8362], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.8085, 0.8162, 0.8246, 0.8321, 0.8395, 0.8451, 0.8433, 0.8362],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7919])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8267], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7919])\n",
      ">>Entradas: tensor([0.8162, 0.8246, 0.8321, 0.8395, 0.8451, 0.8433, 0.8362, 0.8267],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7865])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8172], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7865])\n",
      ">>Entradas: tensor([0.8246, 0.8321, 0.8395, 0.8451, 0.8433, 0.8362, 0.8267, 0.8172],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7870])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8090], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7870])\n",
      ">>Entradas: tensor([0.8321, 0.8395, 0.8451, 0.8433, 0.8362, 0.8267, 0.8172, 0.8090],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7874])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8020], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7874])\n",
      ">>Entradas: tensor([0.8395, 0.8451, 0.8433, 0.8362, 0.8267, 0.8172, 0.8090, 0.8020],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7879])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7955], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7879])\n",
      ">>Entradas: tensor([0.8451, 0.8433, 0.8362, 0.8267, 0.8172, 0.8090, 0.8020, 0.7955],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7955])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7913], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7955])\n",
      ">>Entradas: tensor([0.8433, 0.8362, 0.8267, 0.8172, 0.8090, 0.8020, 0.7955, 0.7913],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8102])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7916], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8102])\n",
      ">>Entradas: tensor([0.8362, 0.8267, 0.8172, 0.8090, 0.8020, 0.7955, 0.7913, 0.7916],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7668])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7786], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7668])\n",
      ">>Entradas: tensor([0.8267, 0.8172, 0.8090, 0.8020, 0.7955, 0.7913, 0.7916, 0.7786],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6655])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7397], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6655])\n",
      ">>Entradas: tensor([0.8172, 0.8090, 0.8020, 0.7955, 0.7913, 0.7916, 0.7786, 0.7397],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6361])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7028], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6361])\n",
      ">>Entradas: tensor([0.8090, 0.8020, 0.7955, 0.7913, 0.7916, 0.7786, 0.7397, 0.7028],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6785])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6864], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6785])\n",
      ">>Entradas: tensor([0.8020, 0.7955, 0.7913, 0.7916, 0.7786, 0.7397, 0.7028, 0.6864],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6770], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6966])\n",
      ">>Entradas: tensor([0.7955, 0.7913, 0.7916, 0.7786, 0.7397, 0.7028, 0.6864, 0.6770],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6903])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6690], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6903])\n",
      ">>Entradas: tensor([0.7913, 0.7916, 0.7786, 0.7397, 0.7028, 0.6864, 0.6770, 0.6690],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6970])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6667], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6970])\n",
      ">>Entradas: tensor([0.7916, 0.7786, 0.7397, 0.7028, 0.6864, 0.6770, 0.6690, 0.6667],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7167])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6685], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7167])\n",
      ">>Entradas: tensor([0.7786, 0.7397, 0.7028, 0.6864, 0.6770, 0.6690, 0.6667, 0.6685],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7491])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6768], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7491])\n",
      ">>Entradas: tensor([0.7397, 0.7028, 0.6864, 0.6770, 0.6690, 0.6667, 0.6685, 0.6768],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7940])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6998], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7940])\n",
      ">>Entradas: tensor([0.7028, 0.6864, 0.6770, 0.6690, 0.6667, 0.6685, 0.6768, 0.6998],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8547])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7416], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8547])\n",
      ">>Entradas: tensor([0.6864, 0.6770, 0.6690, 0.6667, 0.6685, 0.6768, 0.6998, 0.7416],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9314])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8008], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9314])\n",
      ">>Entradas: tensor([0.6770, 0.6690, 0.6667, 0.6685, 0.6768, 0.6998, 0.7416, 0.8008],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9627])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8583], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9627])\n",
      ">>Entradas: tensor([0.6690, 0.6667, 0.6685, 0.6768, 0.6998, 0.7416, 0.8008, 0.8583],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9486])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9017], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9486])\n",
      ">>Entradas: tensor([0.6667, 0.6685, 0.6768, 0.6998, 0.7416, 0.8008, 0.8583, 0.9017],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9307])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9330], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9307])\n",
      ">>Entradas: tensor([0.6685, 0.6768, 0.6998, 0.7416, 0.8008, 0.8583, 0.9017, 0.9330],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9090])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9513], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9090])\n",
      ">>Entradas: tensor([0.6768, 0.6998, 0.7416, 0.8008, 0.8583, 0.9017, 0.9330, 0.9513],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8816])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9249], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8816])\n",
      ">>Entradas: tensor([0.6998, 0.7416, 0.8008, 0.8583, 0.9017, 0.9330, 0.9513, 0.9249],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8487])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9308], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8487])\n",
      ">>Entradas: tensor([0.7416, 0.8008, 0.8583, 0.9017, 0.9330, 0.9513, 0.9249, 0.9308],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8753])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9400], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8753])\n",
      ">>Entradas: tensor([0.8008, 0.8583, 0.9017, 0.9330, 0.9513, 0.9249, 0.9308, 0.9400],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9612])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9656], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9612])\n",
      ">>Entradas: tensor([0.8583, 0.9017, 0.9330, 0.9513, 0.9249, 0.9308, 0.9400, 0.9656],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9925])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9886], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9925])\n",
      ">>Entradas: tensor([0.9017, 0.9330, 0.9513, 0.9249, 0.9308, 0.9400, 0.9656, 0.9886],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9690])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9967], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9690])\n",
      ">>Entradas: tensor([0.9330, 0.9513, 0.9249, 0.9308, 0.9400, 0.9656, 0.9886, 0.9967],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9715])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9955], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9715])\n",
      ">>Entradas: tensor([0.9513, 0.9249, 0.9308, 0.9400, 0.9656, 0.9886, 0.9967, 0.9955],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([1.])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0006], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([1.])\n",
      ">>Entradas: tensor([0.9249, 0.9308, 0.9400, 0.9656, 0.9886, 0.9967, 0.9955, 1.0006],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9993], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9801])\n",
      ">>Entradas: tensor([0.9308, 0.9400, 0.9656, 0.9886, 0.9967, 0.9955, 1.0006, 0.9993],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9802], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9117])\n",
      ">>Entradas: tensor([0.9400, 0.9656, 0.9886, 0.9967, 0.9955, 1.0006, 0.9993, 0.9802],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8911])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9613], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8911])\n",
      ">>Entradas: tensor([0.9656, 0.9886, 0.9967, 0.9955, 1.0006, 0.9993, 0.9802, 0.9613],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9181])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9419], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9181])\n",
      ">>Entradas: tensor([0.9886, 0.9967, 0.9955, 1.0006, 0.9993, 0.9802, 0.9613, 0.9419],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9450])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9405], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9450])\n",
      ">>Entradas: tensor([0.9967, 0.9955, 1.0006, 0.9993, 0.9802, 0.9613, 0.9419, 0.9405],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9718])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9453], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9718])\n",
      ">>Entradas: tensor([0.9955, 1.0006, 0.9993, 0.9802, 0.9613, 0.9419, 0.9405, 0.9453],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9829])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9528], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9829])\n",
      ">>Entradas: tensor([1.0006, 0.9993, 0.9802, 0.9613, 0.9419, 0.9405, 0.9453, 0.9528],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9783])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9560], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9783])\n",
      ">>s_original: [0.049424633383750916, 0.10789185762405396, 0.13719609379768372, 0.13733737170696259, 0.1338856965303421, 0.12684109807014465, 0.14756061136722565, 0.19604423642158508, 0.21688967943191528, 0.21009695529937744, 0.20267784595489502, 0.1946323662996292, 0.19407351315021515, 0.20100130140781403, 0.19663821160793304, 0.180984228849411, 0.16539041697978973, 0.14985674619674683, 0.15043111145496368, 0.1671135276556015, 0.20227035880088806, 0.25590160489082336, 0.29268819093704224, 0.31263017654418945, 0.31093889474868774, 0.2876143157482147, 0.28016164898872375, 0.28858086466789246, 0.28246283531188965, 0.26180753111839294, 0.2801212966442108, 0.3374040722846985, 0.3482298254966736, 0.3125985562801361, 0.34358710050582886, 0.44119545817375183, 0.521095335483551, 0.5832866430282593, 0.6089234352111816, 0.5980057120323181, 0.5945301651954651, 0.5984968543052673, 0.621354341506958, 0.6631026864051819, 0.6928724050521851, 0.7106636166572571, 0.721682071685791, 0.7259277701377869, 0.7404318451881409, 0.7651942372322083, 0.7447891235351562, 0.6792163252830505, 0.6746017932891846, 0.730945348739624, 0.7467210292816162, 0.7219287157058716, 0.7199286818504333, 0.7407209277153015, 0.7362455129623413, 0.7065023183822632, 0.6979451775550842, 0.7105739712715149, 0.7209621667861938, 0.7291097044944763, 0.7674259543418884, 0.8359109163284302, 0.8510103225708008, 0.8127241730690002, 0.7863940000534058, 0.7720199823379517, 0.8033170700073242, 0.8802852630615234, 0.8987051844596863, 0.8585767149925232, 0.8308762311935425, 0.8156037926673889, 0.8116992115974426, 0.8191625475883484, 0.8218275904655457, 0.8196942210197449, 0.817862868309021, 0.8163333535194397, 0.8005555868148804, 0.7705295085906982, 0.7426586747169495, 0.716943085193634, 0.7197051048278809, 0.7509447932243347, 0.7402781248092651, 0.6877052187919617, 0.6687695384025574, 0.683471143245697, 0.6877052187919617, 0.6814717054367065, 0.6892618536949158, 0.7110756039619446, 0.7349108457565308, 0.7607676982879639, 0.771117091178894, 0.7659589648246765, 0.7483323812484741, 0.7182371616363525, 0.708941638469696, 0.7204458117485046, 0.7706154584884644, 0.8594506978988647, 0.906541109085083, 0.9118866324424744, 0.9043355584144592, 0.8838878870010376, 0.9032153487205505, 0.9623178839683533, 0.9820588231086731, 0.96243816614151, 0.9302511811256409, 0.8854979276657104, 0.8597025871276855, 0.8528652191162109, 0.8585854768753052, 0.8768633008003235, 0.8806464076042175, 0.8699347376823425, 0.846513569355011, 0.8103827834129333, 0.8026111125946045, 0.8231984972953796, 0.8397204279899597, 0.8521769046783447, 0.8615626692771912, 0.8678776621818542, 0.8701963424682617, 0.868518590927124, 0.852988064289093, 0.8236046433448792, 0.8032509088516235, 0.7919268012046814, 0.7865023016929626, 0.7869773507118225, 0.7874362468719482, 0.7878790497779846, 0.7954531908035278, 0.8101586699485779, 0.7668473124504089, 0.665519118309021, 0.6360738277435303, 0.678511381149292, 0.6965967416763306, 0.6903298497200012, 0.6970472931861877, 0.7167490720748901, 0.7490506768226624, 0.7939522862434387, 0.8547447323799133, 0.931428074836731, 0.9627243876457214, 0.9486336708068848, 0.9307146072387695, 0.9089671969413757, 0.8816379904747009, 0.8487268090248108, 0.8752607107162476, 0.9612395763397217, 0.9925020933151245, 0.9690483212471008, 0.9715476036071777, 1.0, 0.9800636768341064, 0.9117385745048523, 0.8910858035087585, 0.9181053042411804, 0.9450165033340454, 0.9718193411827087, 0.982906699180603, 0.9782785773277283]\n",
      ">>s_pred: [-0.2015552520751953, -0.11782264709472656, -0.051278114318847656, -0.027136802673339844, 0.030664443969726562, 0.0642538070678711, 0.08363008499145508, 0.11538124084472656, 0.16507911682128906, 0.2241663932800293, 0.2607569694519043, 0.28469276428222656, 0.30161619186401367, 0.30777645111083984, 0.30838584899902344, 0.3033738136291504, 0.2907891273498535, 0.26775550842285156, 0.24054765701293945, 0.21858501434326172, 0.2066798210144043, 0.21016502380371094, 0.22266674041748047, 0.23794889450073242, 0.2500033378601074, 0.25434160232543945, 0.2591285705566406, 0.26947593688964844, 0.27902698516845703, 0.2831106185913086, 0.2926487922668457, 0.3150906562805176, 0.3329010009765625, 0.33653831481933594, 0.3506956100463867, 0.38936948776245117, 0.4409298896789551, 0.5025153160095215, 0.5628166198730469, 0.6069951057434082, 0.6389250755310059, 0.665043830871582, 0.6946043968200684, 0.7285652160644531, 0.7615556716918945, 0.7868642807006836, 0.8020997047424316, 0.807640552520752, 0.8109579086303711, 0.8174047470092773, 0.8139500617980957, 0.7889299392700195, 0.7640552520751953, 0.7557520866394043, 0.7491755485534668, 0.7358732223510742, 0.725738525390625, 0.7213039398193359, 0.7130589485168457, 0.6993374824523926, 0.6902742385864258, 0.6896772384643555, 0.6905450820922852, 0.6954083442687988, 0.732506275177002, 0.761838436126709, 0.7899713516235352, 0.8042011260986328, 0.8096952438354492, 0.809105396270752, 0.8205361366271973, 0.8533487319946289, 0.8825764656066895, 0.8904657363891602, 0.881894588470459, 0.8715715408325195, 0.858954906463623, 0.8529458045959473, 0.8508038520812988, 0.8460979461669922, 0.8369641304016113, 0.8263535499572754, 0.812230110168457, 0.7928638458251953, 0.7688198089599609, 0.7430534362792969, 0.7265100479125977, 0.7221159934997559, 0.7150588035583496, 0.6945695877075195, 0.6744084358215332, 0.6632637977600098, 0.6561341285705566, 0.6520051956176758, 0.6549310684204102, 0.6650104522705078, 0.6777029037475586, 0.6972041130065918, 0.7186217308044434, 0.7360239028930664, 0.7464871406555176, 0.7478413581848145, 0.7631421089172363, 0.7609038352966309, 0.7748851776123047, 0.8113298416137695, 0.8504681587219238, 0.879643440246582, 0.9018592834472656, 0.9120039939880371, 0.9238061904907227, 0.951878547668457, 0.9806647300720215, 0.9951801300048828, 0.9942965507507324, 0.9763784408569336, 0.9506855010986328, 0.9274191856384277, 0.8927273750305176, 0.8880615234375, 0.8808341026306152, 0.8680596351623535, 0.849431037902832, 0.8251638412475586, 0.8031105995178223, 0.7949256896972656, 0.8030719757080078, 0.808499813079834, 0.816162109375, 0.8245987892150879, 0.8320965766906738, 0.8395280838012695, 0.8451476097106934, 0.843292236328125, 0.8362307548522949, 0.8267264366149902, 0.8172473907470703, 0.8089780807495117, 0.8019747734069824, 0.7955002784729004, 0.79132080078125, 0.7915530204772949, 0.7785940170288086, 0.7397446632385254, 0.7028155326843262, 0.6864047050476074, 0.6770248413085938, 0.6689858436584473, 0.6667079925537109, 0.6684579849243164, 0.676753044128418, 0.699824333190918, 0.7415881156921387, 0.8007864952087402, 0.858271598815918, 0.9016776084899902, 0.932990550994873, 0.9512524604797363, 0.9248666763305664, 0.9308462142944336, 0.9400053024291992, 0.9655647277832031, 0.9886341094970703, 0.9966630935668945, 0.9955167770385742, 1.0005922317504883, 0.9992713928222656, 0.9802465438842773, 0.9613265991210938, 0.9419374465942383, 0.9405441284179688, 0.9453239440917969, 0.9528055191040039, 0.9560003280639648]\n",
      "<<Perdida: 0.0035899959038943052 epoca: 9\n",
      "---Inicio de epoca: 10--\n",
      ">>Entradas: tensor([0.0503, 0.0086, 0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203])\n",
      ">>Salida: tensor([0.0494])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([-0.0924], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.0494])\n",
      ">>Entradas: tensor([ 0.0086,  0.0000,  0.0245,  0.0327,  0.0246,  0.0205,  0.0203, -0.0924],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1079])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([-0.0331], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1079])\n",
      ">>Entradas: tensor([ 0.0000,  0.0245,  0.0327,  0.0246,  0.0205,  0.0203, -0.0924, -0.0331],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1372])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1144], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1372])\n",
      ">>Entradas: tensor([ 0.0245,  0.0327,  0.0246,  0.0205,  0.0203, -0.0924, -0.0331,  0.1144],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1373])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0910], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1373])\n",
      ">>Entradas: tensor([ 0.0327,  0.0246,  0.0205,  0.0203, -0.0924, -0.0331,  0.1144,  0.0910],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1339])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0997], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1339])\n",
      ">>Entradas: tensor([ 0.0246,  0.0205,  0.0203, -0.0924, -0.0331,  0.1144,  0.0910,  0.0997],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1268])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1259], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1268])\n",
      ">>Entradas: tensor([ 0.0205,  0.0203, -0.0924, -0.0331,  0.1144,  0.0910,  0.0997,  0.1259],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1476])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1175], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1476])\n",
      ">>Entradas: tensor([ 0.0203, -0.0924, -0.0331,  0.1144,  0.0910,  0.0997,  0.1259,  0.1175],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1960])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1297], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1960])\n",
      ">>Entradas: tensor([-0.0924, -0.0331,  0.1144,  0.0910,  0.0997,  0.1259,  0.1175,  0.1297],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1719], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2169])\n",
      ">>Entradas: tensor([-0.0331,  0.1144,  0.0910,  0.0997,  0.1259,  0.1175,  0.1297,  0.1719],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2101])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1877], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2101])\n",
      ">>Entradas: tensor([0.1144, 0.0910, 0.0997, 0.1259, 0.1175, 0.1297, 0.1719, 0.1877],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2027])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1846], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2027])\n",
      ">>Entradas: tensor([0.0910, 0.0997, 0.1259, 0.1175, 0.1297, 0.1719, 0.1877, 0.1846],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1946])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1937], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1946])\n",
      ">>Entradas: tensor([0.0997, 0.1259, 0.1175, 0.1297, 0.1719, 0.1877, 0.1846, 0.1937],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1941])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1964], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1941])\n",
      ">>Entradas: tensor([0.1259, 0.1175, 0.1297, 0.1719, 0.1877, 0.1846, 0.1937, 0.1964],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2010])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1953], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2010])\n",
      ">>Entradas: tensor([0.1175, 0.1297, 0.1719, 0.1877, 0.1846, 0.1937, 0.1964, 0.1953],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2001], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1966])\n",
      ">>Entradas: tensor([0.1297, 0.1719, 0.1877, 0.1846, 0.1937, 0.1964, 0.1953, 0.2001],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1810])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1996], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1810])\n",
      ">>Entradas: tensor([0.1719, 0.1877, 0.1846, 0.1937, 0.1964, 0.1953, 0.2001, 0.1996],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1654])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1901], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1654])\n",
      ">>Entradas: tensor([0.1877, 0.1846, 0.1937, 0.1964, 0.1953, 0.2001, 0.1996, 0.1901],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1499])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1793], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1499])\n",
      ">>Entradas: tensor([0.1846, 0.1937, 0.1964, 0.1953, 0.2001, 0.1996, 0.1901, 0.1793],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1504])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1729], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1504])\n",
      ">>Entradas: tensor([0.1937, 0.1964, 0.1953, 0.2001, 0.1996, 0.1901, 0.1793, 0.1729],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1671])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1711], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1671])\n",
      ">>Entradas: tensor([0.1964, 0.1953, 0.2001, 0.1996, 0.1901, 0.1793, 0.1729, 0.1711],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2023])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1799], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2023])\n",
      ">>Entradas: tensor([0.1953, 0.2001, 0.1996, 0.1901, 0.1793, 0.1729, 0.1711, 0.1799],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2559])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2024], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2559])\n",
      ">>Entradas: tensor([0.2001, 0.1996, 0.1901, 0.1793, 0.1729, 0.1711, 0.1799, 0.2024],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2927])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2273], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2927])\n",
      ">>Entradas: tensor([0.1996, 0.1901, 0.1793, 0.1729, 0.1711, 0.1799, 0.2024, 0.2273],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2500], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.1901, 0.1793, 0.1729, 0.1711, 0.1799, 0.2024, 0.2273, 0.2500],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3109])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2670], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3109])\n",
      ">>Entradas: tensor([0.1793, 0.1729, 0.1711, 0.1799, 0.2024, 0.2273, 0.2500, 0.2670],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2876])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2735], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2876])\n",
      ">>Entradas: tensor([0.1729, 0.1711, 0.1799, 0.2024, 0.2273, 0.2500, 0.2670, 0.2735],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2802])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2777], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2802])\n",
      ">>Entradas: tensor([0.1711, 0.1799, 0.2024, 0.2273, 0.2500, 0.2670, 0.2735, 0.2777],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2886])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2855], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2886])\n",
      ">>Entradas: tensor([0.1799, 0.2024, 0.2273, 0.2500, 0.2670, 0.2735, 0.2777, 0.2855],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2825])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2899], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2825])\n",
      ">>Entradas: tensor([0.2024, 0.2273, 0.2500, 0.2670, 0.2735, 0.2777, 0.2855, 0.2899],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2618])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2869], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2618])\n",
      ">>Entradas: tensor([0.2273, 0.2500, 0.2670, 0.2735, 0.2777, 0.2855, 0.2899, 0.2869],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2905], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2801])\n",
      ">>Entradas: tensor([0.2500, 0.2670, 0.2735, 0.2777, 0.2855, 0.2899, 0.2869, 0.2905],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3374])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3084], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3374])\n",
      ">>Entradas: tensor([0.2670, 0.2735, 0.2777, 0.2855, 0.2899, 0.2869, 0.2905, 0.3084],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3482])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3211], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3482])\n",
      ">>Entradas: tensor([0.2735, 0.2777, 0.2855, 0.2899, 0.2869, 0.2905, 0.3084, 0.3211],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3197], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2777, 0.2855, 0.2899, 0.2869, 0.2905, 0.3084, 0.3211, 0.3197],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3436])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3307], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3436])\n",
      ">>Entradas: tensor([0.2855, 0.2899, 0.2869, 0.2905, 0.3084, 0.3211, 0.3197, 0.3307],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.4412])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3682], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.4412])\n",
      ">>Entradas: tensor([0.2899, 0.2869, 0.2905, 0.3084, 0.3211, 0.3197, 0.3307, 0.3682],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5211])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4175], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5211])\n",
      ">>Entradas: tensor([0.2869, 0.2905, 0.3084, 0.3211, 0.3197, 0.3307, 0.3682, 0.4175],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5833])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4700], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5833])\n",
      ">>Entradas: tensor([0.2905, 0.3084, 0.3211, 0.3197, 0.3307, 0.3682, 0.4175, 0.4700],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5201], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6089])\n",
      ">>Entradas: tensor([0.3084, 0.3211, 0.3197, 0.3307, 0.3682, 0.4175, 0.4700, 0.5201],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5980])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5543], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5980])\n",
      ">>Entradas: tensor([0.3211, 0.3197, 0.3307, 0.3682, 0.4175, 0.4700, 0.5201, 0.5543],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5945])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5792], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5945])\n",
      ">>Entradas: tensor([0.3197, 0.3307, 0.3682, 0.4175, 0.4700, 0.5201, 0.5543, 0.5792],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5985])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6032], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5985])\n",
      ">>Entradas: tensor([0.3307, 0.3682, 0.4175, 0.4700, 0.5201, 0.5543, 0.5792, 0.6032],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6214])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6315], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6214])\n",
      ">>Entradas: tensor([0.3682, 0.4175, 0.4700, 0.5201, 0.5543, 0.5792, 0.6032, 0.6315],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6631])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6657], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6631])\n",
      ">>Entradas: tensor([0.4175, 0.4700, 0.5201, 0.5543, 0.5792, 0.6032, 0.6315, 0.6657],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6929])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6995], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6929])\n",
      ">>Entradas: tensor([0.4700, 0.5201, 0.5543, 0.5792, 0.6032, 0.6315, 0.6657, 0.6995],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7107])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7273], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7107])\n",
      ">>Entradas: tensor([0.5201, 0.5543, 0.5792, 0.6032, 0.6315, 0.6657, 0.6995, 0.7273],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7217])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7475], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7217])\n",
      ">>Entradas: tensor([0.5543, 0.5792, 0.6032, 0.6315, 0.6657, 0.6995, 0.7273, 0.7475],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7259])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7552], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7259])\n",
      ">>Entradas: tensor([0.5792, 0.6032, 0.6315, 0.6657, 0.6995, 0.7273, 0.7475, 0.7552],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7404])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7694], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7404])\n",
      ">>Entradas: tensor([0.6032, 0.6315, 0.6657, 0.6995, 0.7273, 0.7475, 0.7552, 0.7694],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7652])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7861], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7652])\n",
      ">>Entradas: tensor([0.6315, 0.6657, 0.6995, 0.7273, 0.7475, 0.7552, 0.7694, 0.7861],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7448])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7901], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7448])\n",
      ">>Entradas: tensor([0.6657, 0.6995, 0.7273, 0.7475, 0.7552, 0.7694, 0.7861, 0.7901],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6792])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7731], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6792])\n",
      ">>Entradas: tensor([0.6995, 0.7273, 0.7475, 0.7552, 0.7694, 0.7861, 0.7901, 0.7731],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6746])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7565], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6746])\n",
      ">>Entradas: tensor([0.7273, 0.7475, 0.7552, 0.7694, 0.7861, 0.7901, 0.7731, 0.7565],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7552], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7309])\n",
      ">>Entradas: tensor([0.7475, 0.7552, 0.7694, 0.7861, 0.7901, 0.7731, 0.7565, 0.7552],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7467])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7544], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7467])\n",
      ">>Entradas: tensor([0.7552, 0.7694, 0.7861, 0.7901, 0.7731, 0.7565, 0.7552, 0.7544],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7219])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7462], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7219])\n",
      ">>Entradas: tensor([0.7694, 0.7861, 0.7901, 0.7731, 0.7565, 0.7552, 0.7544, 0.7462],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7199])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7400], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7199])\n",
      ">>Entradas: tensor([0.7861, 0.7901, 0.7731, 0.7565, 0.7552, 0.7544, 0.7462, 0.7400],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7407])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7380], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7407])\n",
      ">>Entradas: tensor([0.7901, 0.7731, 0.7565, 0.7552, 0.7544, 0.7462, 0.7400, 0.7380],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7362])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7310], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7362])\n",
      ">>Entradas: tensor([0.7731, 0.7565, 0.7552, 0.7544, 0.7462, 0.7400, 0.7380, 0.7310],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7180], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7065])\n",
      ">>Entradas: tensor([0.7565, 0.7552, 0.7544, 0.7462, 0.7400, 0.7380, 0.7310, 0.7180],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6979])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7089], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6979])\n",
      ">>Entradas: tensor([0.7552, 0.7544, 0.7462, 0.7400, 0.7380, 0.7310, 0.7180, 0.7089],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7106])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7056], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7106])\n",
      ">>Entradas: tensor([0.7544, 0.7462, 0.7400, 0.7380, 0.7310, 0.7180, 0.7089, 0.7056],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7210])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7050], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7210])\n",
      ">>Entradas: tensor([0.7462, 0.7400, 0.7380, 0.7310, 0.7180, 0.7089, 0.7056, 0.7050],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7291])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7078], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7291])\n",
      ">>Entradas: tensor([0.7400, 0.7380, 0.7310, 0.7180, 0.7089, 0.7056, 0.7050, 0.7078],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7674])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7227], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7674])\n",
      ">>Entradas: tensor([0.7380, 0.7310, 0.7180, 0.7089, 0.7056, 0.7050, 0.7078, 0.7227],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8359])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7541], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8359])\n",
      ">>Entradas: tensor([0.7310, 0.7180, 0.7089, 0.7056, 0.7050, 0.7078, 0.7227, 0.7541],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8510])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7819], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8510])\n",
      ">>Entradas: tensor([0.7180, 0.7089, 0.7056, 0.7050, 0.7078, 0.7227, 0.7541, 0.7819],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8127])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7938], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8127])\n",
      ">>Entradas: tensor([0.7089, 0.7056, 0.7050, 0.7078, 0.7227, 0.7541, 0.7819, 0.7938],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7864])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7983], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7864])\n",
      ">>Entradas: tensor([0.7056, 0.7050, 0.7078, 0.7227, 0.7541, 0.7819, 0.7938, 0.7983],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7720])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7983], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7720])\n",
      ">>Entradas: tensor([0.7050, 0.7078, 0.7227, 0.7541, 0.7819, 0.7938, 0.7983, 0.7983],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8075], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.7078, 0.7227, 0.7541, 0.7819, 0.7938, 0.7983, 0.7983, 0.8075],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8803])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8390], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8803])\n",
      ">>Entradas: tensor([0.7227, 0.7541, 0.7819, 0.7938, 0.7983, 0.7983, 0.8075, 0.8390],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8987])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8693], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8987])\n",
      ">>Entradas: tensor([0.7541, 0.7819, 0.7938, 0.7983, 0.7983, 0.8075, 0.8390, 0.8693],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8788], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.7819, 0.7938, 0.7983, 0.7983, 0.8075, 0.8390, 0.8693, 0.8788],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8374], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8309])\n",
      ">>Entradas: tensor([0.7938, 0.7983, 0.7983, 0.8075, 0.8390, 0.8693, 0.8788, 0.8374],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8156])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8384], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8156])\n",
      ">>Entradas: tensor([0.7983, 0.7983, 0.8075, 0.8390, 0.8693, 0.8788, 0.8374, 0.8384],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8332], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8117])\n",
      ">>Entradas: tensor([0.7983, 0.8075, 0.8390, 0.8693, 0.8788, 0.8374, 0.8384, 0.8332],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8192])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8312], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8192])\n",
      ">>Entradas: tensor([0.8075, 0.8390, 0.8693, 0.8788, 0.8374, 0.8384, 0.8332, 0.8312],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8218])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8342], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8218])\n",
      ">>Entradas: tensor([0.8390, 0.8693, 0.8788, 0.8374, 0.8384, 0.8332, 0.8312, 0.8342],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8365], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8197])\n",
      ">>Entradas: tensor([0.8693, 0.8788, 0.8374, 0.8384, 0.8332, 0.8312, 0.8342, 0.8365],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8179])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8275], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8179])\n",
      ">>Entradas: tensor([0.8788, 0.8374, 0.8384, 0.8332, 0.8312, 0.8342, 0.8365, 0.8275],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8163])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8182], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8163])\n",
      ">>Entradas: tensor([0.8374, 0.8384, 0.8332, 0.8312, 0.8342, 0.8365, 0.8275, 0.8182],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8006])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8099], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8006])\n",
      ">>Entradas: tensor([0.8384, 0.8332, 0.8312, 0.8342, 0.8365, 0.8275, 0.8182, 0.8099],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7705])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7952], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7705])\n",
      ">>Entradas: tensor([0.8332, 0.8312, 0.8342, 0.8365, 0.8275, 0.8182, 0.8099, 0.7952],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7427])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7763], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7427])\n",
      ">>Entradas: tensor([0.8312, 0.8342, 0.8365, 0.8275, 0.8182, 0.8099, 0.7952, 0.7763],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7554], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7169])\n",
      ">>Entradas: tensor([0.8342, 0.8365, 0.8275, 0.8182, 0.8099, 0.7952, 0.7763, 0.7554],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7392], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7197])\n",
      ">>Entradas: tensor([0.8365, 0.8275, 0.8182, 0.8099, 0.7952, 0.7763, 0.7554, 0.7392],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7509])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7343], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7509])\n",
      ">>Entradas: tensor([0.8275, 0.8182, 0.8099, 0.7952, 0.7763, 0.7554, 0.7392, 0.7343],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7403])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7272], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7403])\n",
      ">>Entradas: tensor([0.8182, 0.8099, 0.7952, 0.7763, 0.7554, 0.7392, 0.7343, 0.7272],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7068], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.8099, 0.7952, 0.7763, 0.7554, 0.7392, 0.7343, 0.7272, 0.7068],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6688])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6865], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6688])\n",
      ">>Entradas: tensor([0.7952, 0.7763, 0.7554, 0.7392, 0.7343, 0.7272, 0.7068, 0.6865],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6835])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6752], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6835])\n",
      ">>Entradas: tensor([0.7763, 0.7554, 0.7392, 0.7343, 0.7272, 0.7068, 0.6865, 0.6752],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6673], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.7554, 0.7392, 0.7343, 0.7272, 0.7068, 0.6865, 0.6752, 0.6673],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6815])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6617], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6815])\n",
      ">>Entradas: tensor([0.7392, 0.7343, 0.7272, 0.7068, 0.6865, 0.6752, 0.6673, 0.6617],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6893])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6631], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6893])\n",
      ">>Entradas: tensor([0.7343, 0.7272, 0.7068, 0.6865, 0.6752, 0.6673, 0.6617, 0.6631],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7111])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6705], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7111])\n",
      ">>Entradas: tensor([0.7272, 0.7068, 0.6865, 0.6752, 0.6673, 0.6617, 0.6631, 0.6705],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7349])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6821], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7349])\n",
      ">>Entradas: tensor([0.7068, 0.6865, 0.6752, 0.6673, 0.6617, 0.6631, 0.6705, 0.6821],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7608])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7002], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7608])\n",
      ">>Entradas: tensor([0.6865, 0.6752, 0.6673, 0.6617, 0.6631, 0.6705, 0.6821, 0.7002],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7711])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7198], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7711])\n",
      ">>Entradas: tensor([0.6752, 0.6673, 0.6617, 0.6631, 0.6705, 0.6821, 0.7002, 0.7198],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7660])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7350], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7660])\n",
      ">>Entradas: tensor([0.6673, 0.6617, 0.6631, 0.6705, 0.6821, 0.7002, 0.7198, 0.7350],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7483])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7432], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7483])\n",
      ">>Entradas: tensor([0.6617, 0.6631, 0.6705, 0.6821, 0.7002, 0.7198, 0.7350, 0.7432],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7182])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7426], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7182])\n",
      ">>Entradas: tensor([0.6631, 0.6705, 0.6821, 0.7002, 0.7198, 0.7350, 0.7432, 0.7426],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7400], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7089])\n",
      ">>Entradas: tensor([0.6705, 0.6821, 0.7002, 0.7198, 0.7350, 0.7432, 0.7426, 0.7400],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7204])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7418], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7204])\n",
      ">>Entradas: tensor([0.6821, 0.7002, 0.7198, 0.7350, 0.7432, 0.7426, 0.7400, 0.7418],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7706])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7576], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7706])\n",
      ">>Entradas: tensor([0.7002, 0.7198, 0.7350, 0.7432, 0.7426, 0.7400, 0.7418, 0.7576],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8595])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7950], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8595])\n",
      ">>Entradas: tensor([0.7198, 0.7350, 0.7432, 0.7426, 0.7400, 0.7418, 0.7576, 0.7950],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8357], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9065])\n",
      ">>Entradas: tensor([0.7350, 0.7432, 0.7426, 0.7400, 0.7418, 0.7576, 0.7950, 0.8357],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9119])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8687], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9119])\n",
      ">>Entradas: tensor([0.7432, 0.7426, 0.7400, 0.7418, 0.7576, 0.7950, 0.8357, 0.8687],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9043])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8902], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9043])\n",
      ">>Entradas: tensor([0.7426, 0.7400, 0.7418, 0.7576, 0.7950, 0.8357, 0.8687, 0.8902],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8839])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9008], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8839])\n",
      ">>Entradas: tensor([0.7400, 0.7418, 0.7576, 0.7950, 0.8357, 0.8687, 0.8902, 0.9008],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9032])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9149], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9032])\n",
      ">>Entradas: tensor([0.7418, 0.7576, 0.7950, 0.8357, 0.8687, 0.8902, 0.9008, 0.9149],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9623])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9454], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9623])\n",
      ">>Entradas: tensor([0.7576, 0.7950, 0.8357, 0.8687, 0.8902, 0.9008, 0.9149, 0.9454],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9821])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9758], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9821])\n",
      ">>Entradas: tensor([0.7950, 0.8357, 0.8687, 0.8902, 0.9008, 0.9149, 0.9454, 0.9758],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9624])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9921], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9624])\n",
      ">>Entradas: tensor([0.8357, 0.8687, 0.8902, 0.9008, 0.9149, 0.9454, 0.9758, 0.9921],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9303])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9927], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9303])\n",
      ">>Entradas: tensor([0.8687, 0.8902, 0.9008, 0.9149, 0.9454, 0.9758, 0.9921, 0.9927],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8855])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9755], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8855])\n",
      ">>Entradas: tensor([0.8902, 0.9008, 0.9149, 0.9454, 0.9758, 0.9921, 0.9927, 0.9755],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8597])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9504], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8597])\n",
      ">>Entradas: tensor([0.9008, 0.9149, 0.9454, 0.9758, 0.9921, 0.9927, 0.9755, 0.9504],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8529])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9282], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8529])\n",
      ">>Entradas: tensor([0.9149, 0.9454, 0.9758, 0.9921, 0.9927, 0.9755, 0.9504, 0.9282],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9123], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.9454, 0.9758, 0.9921, 0.9927, 0.9755, 0.9504, 0.9282, 0.9123],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8769])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9033], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8769])\n",
      ">>Entradas: tensor([0.9758, 0.9921, 0.9927, 0.9755, 0.9504, 0.9282, 0.9123, 0.9033],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8806])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8939], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8806])\n",
      ">>Entradas: tensor([0.9921, 0.9927, 0.9755, 0.9504, 0.9282, 0.9123, 0.9033, 0.8939],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8699])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8799], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8699])\n",
      ">>Entradas: tensor([0.9927, 0.9755, 0.9504, 0.9282, 0.9123, 0.9033, 0.8939, 0.8799],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8465])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8596], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8465])\n",
      ">>Entradas: tensor([0.9755, 0.9504, 0.9282, 0.9123, 0.9033, 0.8939, 0.8799, 0.8596],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8104])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8329], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8104])\n",
      ">>Entradas: tensor([0.9504, 0.9282, 0.9123, 0.9033, 0.8939, 0.8799, 0.8596, 0.8329],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8026])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8116], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8026])\n",
      ">>Entradas: tensor([0.9282, 0.9123, 0.9033, 0.8939, 0.8799, 0.8596, 0.8329, 0.8116],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8232])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8036], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8232])\n",
      ">>Entradas: tensor([0.9123, 0.9033, 0.8939, 0.8799, 0.8596, 0.8329, 0.8116, 0.8036],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8397])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8037], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8397])\n",
      ">>Entradas: tensor([0.9033, 0.8939, 0.8799, 0.8596, 0.8329, 0.8116, 0.8036, 0.8037],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8522])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8085], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8522])\n",
      ">>Entradas: tensor([0.8939, 0.8799, 0.8596, 0.8329, 0.8116, 0.8036, 0.8037, 0.8085],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8616])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8157], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8616])\n",
      ">>Entradas: tensor([0.8799, 0.8596, 0.8329, 0.8116, 0.8036, 0.8037, 0.8085, 0.8157],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8679])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8233], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8679])\n",
      ">>Entradas: tensor([0.8596, 0.8329, 0.8116, 0.8036, 0.8037, 0.8085, 0.8157, 0.8233],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8702])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8303], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8702])\n",
      ">>Entradas: tensor([0.8329, 0.8116, 0.8036, 0.8037, 0.8085, 0.8157, 0.8233, 0.8303],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8685])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8379], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8685])\n",
      ">>Entradas: tensor([0.8116, 0.8036, 0.8037, 0.8085, 0.8157, 0.8233, 0.8303, 0.8379],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8530])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8426], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8530])\n",
      ">>Entradas: tensor([0.8036, 0.8037, 0.8085, 0.8157, 0.8233, 0.8303, 0.8379, 0.8426],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8236])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8397], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8236])\n",
      ">>Entradas: tensor([0.8037, 0.8085, 0.8157, 0.8233, 0.8303, 0.8379, 0.8426, 0.8397],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8327], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.8085, 0.8157, 0.8233, 0.8303, 0.8379, 0.8426, 0.8397, 0.8327],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7919])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8239], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7919])\n",
      ">>Entradas: tensor([0.8157, 0.8233, 0.8303, 0.8379, 0.8426, 0.8397, 0.8327, 0.8239],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7865])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8147], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7865])\n",
      ">>Entradas: tensor([0.8233, 0.8303, 0.8379, 0.8426, 0.8397, 0.8327, 0.8239, 0.8147],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7870])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8069], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7870])\n",
      ">>Entradas: tensor([0.8303, 0.8379, 0.8426, 0.8397, 0.8327, 0.8239, 0.8147, 0.8069],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7874])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8006], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7874])\n",
      ">>Entradas: tensor([0.8379, 0.8426, 0.8397, 0.8327, 0.8239, 0.8147, 0.8069, 0.8006],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7879])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7946], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7879])\n",
      ">>Entradas: tensor([0.8426, 0.8397, 0.8327, 0.8239, 0.8147, 0.8069, 0.8006, 0.7946],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7955])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7910], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7955])\n",
      ">>Entradas: tensor([0.8397, 0.8327, 0.8239, 0.8147, 0.8069, 0.8006, 0.7946, 0.7910],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8102])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7919], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8102])\n",
      ">>Entradas: tensor([0.8327, 0.8239, 0.8147, 0.8069, 0.8006, 0.7946, 0.7910, 0.7919],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7668])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7796], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7668])\n",
      ">>Entradas: tensor([0.8239, 0.8147, 0.8069, 0.8006, 0.7946, 0.7910, 0.7919, 0.7796],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6655])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7412], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6655])\n",
      ">>Entradas: tensor([0.8147, 0.8069, 0.8006, 0.7946, 0.7910, 0.7919, 0.7796, 0.7412],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6361])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7047], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6361])\n",
      ">>Entradas: tensor([0.8069, 0.8006, 0.7946, 0.7910, 0.7919, 0.7796, 0.7412, 0.7047],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6785])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6888], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6785])\n",
      ">>Entradas: tensor([0.8006, 0.7946, 0.7910, 0.7919, 0.7796, 0.7412, 0.7047, 0.6888],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6800], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6966])\n",
      ">>Entradas: tensor([0.7946, 0.7910, 0.7919, 0.7796, 0.7412, 0.7047, 0.6888, 0.6800],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6903])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6725], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6903])\n",
      ">>Entradas: tensor([0.7910, 0.7919, 0.7796, 0.7412, 0.7047, 0.6888, 0.6800, 0.6725],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6970])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6712], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6970])\n",
      ">>Entradas: tensor([0.7919, 0.7796, 0.7412, 0.7047, 0.6888, 0.6800, 0.6725, 0.6712],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7167])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6737], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7167])\n",
      ">>Entradas: tensor([0.7796, 0.7412, 0.7047, 0.6888, 0.6800, 0.6725, 0.6712, 0.6737],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7491])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6822], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7491])\n",
      ">>Entradas: tensor([0.7412, 0.7047, 0.6888, 0.6800, 0.6725, 0.6712, 0.6737, 0.6822],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7940])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7052], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7940])\n",
      ">>Entradas: tensor([0.7047, 0.6888, 0.6800, 0.6725, 0.6712, 0.6737, 0.6822, 0.7052],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8547])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7463], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8547])\n",
      ">>Entradas: tensor([0.6888, 0.6800, 0.6725, 0.6712, 0.6737, 0.6822, 0.7052, 0.7463],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9314])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8040], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9314])\n",
      ">>Entradas: tensor([0.6800, 0.6725, 0.6712, 0.6737, 0.6822, 0.7052, 0.7463, 0.8040],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9627])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8595], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9627])\n",
      ">>Entradas: tensor([0.6725, 0.6712, 0.6737, 0.6822, 0.7052, 0.7463, 0.8040, 0.8595],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9486])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9008], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9486])\n",
      ">>Entradas: tensor([0.6712, 0.6737, 0.6822, 0.7052, 0.7463, 0.8040, 0.8595, 0.9008],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9307])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9301], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9307])\n",
      ">>Entradas: tensor([0.6737, 0.6822, 0.7052, 0.7463, 0.8040, 0.8595, 0.9008, 0.9301],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9090])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9475], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9090])\n",
      ">>Entradas: tensor([0.6822, 0.7052, 0.7463, 0.8040, 0.8595, 0.9008, 0.9301, 0.9475],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8816])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9539], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8816])\n",
      ">>Entradas: tensor([0.7052, 0.7463, 0.8040, 0.8595, 0.9008, 0.9301, 0.9475, 0.9539],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8487])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9504], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8487])\n",
      ">>Entradas: tensor([0.7463, 0.8040, 0.8595, 0.9008, 0.9301, 0.9475, 0.9539, 0.9504],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8753])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9545], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8753])\n",
      ">>Entradas: tensor([0.8040, 0.8595, 0.9008, 0.9301, 0.9475, 0.9539, 0.9504, 0.9545],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9612])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9775], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9612])\n",
      ">>Entradas: tensor([0.8595, 0.9008, 0.9301, 0.9475, 0.9539, 0.9504, 0.9545, 0.9775],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9925])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9975], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9925])\n",
      ">>Entradas: tensor([0.9008, 0.9301, 0.9475, 0.9539, 0.9504, 0.9545, 0.9775, 0.9975],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9690])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0012], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9690])\n",
      ">>Entradas: tensor([0.9301, 0.9475, 0.9539, 0.9504, 0.9545, 0.9775, 0.9975, 1.0012],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9715])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0023], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9715])\n",
      ">>Entradas: tensor([0.9475, 0.9539, 0.9504, 0.9545, 0.9775, 0.9975, 1.0012, 1.0023],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([1.])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0077], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([1.])\n",
      ">>Entradas: tensor([0.9539, 0.9504, 0.9545, 0.9775, 0.9975, 1.0012, 1.0023, 1.0077],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0026], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9801])\n",
      ">>Entradas: tensor([0.9504, 0.9545, 0.9775, 0.9975, 1.0012, 1.0023, 1.0077, 1.0026],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9804], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9117])\n",
      ">>Entradas: tensor([0.9545, 0.9775, 0.9975, 1.0012, 1.0023, 1.0077, 1.0026, 0.9804],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8911])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9599], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8911])\n",
      ">>Entradas: tensor([0.9775, 0.9975, 1.0012, 1.0023, 1.0077, 1.0026, 0.9804, 0.9599],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9181])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9493], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9181])\n",
      ">>Entradas: tensor([0.9975, 1.0012, 1.0023, 1.0077, 1.0026, 0.9804, 0.9599, 0.9493],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9450])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9446], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9450])\n",
      ">>Entradas: tensor([1.0012, 1.0023, 1.0077, 1.0026, 0.9804, 0.9599, 0.9493, 0.9446],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9718])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9485], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9718])\n",
      ">>Entradas: tensor([1.0023, 1.0077, 1.0026, 0.9804, 0.9599, 0.9493, 0.9446, 0.9485],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9829])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9554], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9829])\n",
      ">>Entradas: tensor([1.0077, 1.0026, 0.9804, 0.9599, 0.9493, 0.9446, 0.9485, 0.9554],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9783])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9574], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9783])\n",
      ">>s_original: [0.049424633383750916, 0.10789185762405396, 0.13719609379768372, 0.13733737170696259, 0.1338856965303421, 0.12684109807014465, 0.14756061136722565, 0.19604423642158508, 0.21688967943191528, 0.21009695529937744, 0.20267784595489502, 0.1946323662996292, 0.19407351315021515, 0.20100130140781403, 0.19663821160793304, 0.180984228849411, 0.16539041697978973, 0.14985674619674683, 0.15043111145496368, 0.1671135276556015, 0.20227035880088806, 0.25590160489082336, 0.29268819093704224, 0.31263017654418945, 0.31093889474868774, 0.2876143157482147, 0.28016164898872375, 0.28858086466789246, 0.28246283531188965, 0.26180753111839294, 0.2801212966442108, 0.3374040722846985, 0.3482298254966736, 0.3125985562801361, 0.34358710050582886, 0.44119545817375183, 0.521095335483551, 0.5832866430282593, 0.6089234352111816, 0.5980057120323181, 0.5945301651954651, 0.5984968543052673, 0.621354341506958, 0.6631026864051819, 0.6928724050521851, 0.7106636166572571, 0.721682071685791, 0.7259277701377869, 0.7404318451881409, 0.7651942372322083, 0.7447891235351562, 0.6792163252830505, 0.6746017932891846, 0.730945348739624, 0.7467210292816162, 0.7219287157058716, 0.7199286818504333, 0.7407209277153015, 0.7362455129623413, 0.7065023183822632, 0.6979451775550842, 0.7105739712715149, 0.7209621667861938, 0.7291097044944763, 0.7674259543418884, 0.8359109163284302, 0.8510103225708008, 0.8127241730690002, 0.7863940000534058, 0.7720199823379517, 0.8033170700073242, 0.8802852630615234, 0.8987051844596863, 0.8585767149925232, 0.8308762311935425, 0.8156037926673889, 0.8116992115974426, 0.8191625475883484, 0.8218275904655457, 0.8196942210197449, 0.817862868309021, 0.8163333535194397, 0.8005555868148804, 0.7705295085906982, 0.7426586747169495, 0.716943085193634, 0.7197051048278809, 0.7509447932243347, 0.7402781248092651, 0.6877052187919617, 0.6687695384025574, 0.683471143245697, 0.6877052187919617, 0.6814717054367065, 0.6892618536949158, 0.7110756039619446, 0.7349108457565308, 0.7607676982879639, 0.771117091178894, 0.7659589648246765, 0.7483323812484741, 0.7182371616363525, 0.708941638469696, 0.7204458117485046, 0.7706154584884644, 0.8594506978988647, 0.906541109085083, 0.9118866324424744, 0.9043355584144592, 0.8838878870010376, 0.9032153487205505, 0.9623178839683533, 0.9820588231086731, 0.96243816614151, 0.9302511811256409, 0.8854979276657104, 0.8597025871276855, 0.8528652191162109, 0.8585854768753052, 0.8768633008003235, 0.8806464076042175, 0.8699347376823425, 0.846513569355011, 0.8103827834129333, 0.8026111125946045, 0.8231984972953796, 0.8397204279899597, 0.8521769046783447, 0.8615626692771912, 0.8678776621818542, 0.8701963424682617, 0.868518590927124, 0.852988064289093, 0.8236046433448792, 0.8032509088516235, 0.7919268012046814, 0.7865023016929626, 0.7869773507118225, 0.7874362468719482, 0.7878790497779846, 0.7954531908035278, 0.8101586699485779, 0.7668473124504089, 0.665519118309021, 0.6360738277435303, 0.678511381149292, 0.6965967416763306, 0.6903298497200012, 0.6970472931861877, 0.7167490720748901, 0.7490506768226624, 0.7939522862434387, 0.8547447323799133, 0.931428074836731, 0.9627243876457214, 0.9486336708068848, 0.9307146072387695, 0.9089671969413757, 0.8816379904747009, 0.8487268090248108, 0.8752607107162476, 0.9612395763397217, 0.9925020933151245, 0.9690483212471008, 0.9715476036071777, 1.0, 0.9800636768341064, 0.9117385745048523, 0.8910858035087585, 0.9181053042411804, 0.9450165033340454, 0.9718193411827087, 0.982906699180603, 0.9782785773277283]\n",
      ">>s_pred: [-0.09240150451660156, -0.033102989196777344, 0.11436939239501953, 0.09100914001464844, 0.09970569610595703, 0.12592840194702148, 0.11753034591674805, 0.12974166870117188, 0.17190313339233398, 0.1876978874206543, 0.18456792831420898, 0.19367647171020508, 0.1963505744934082, 0.19534921646118164, 0.20011568069458008, 0.19959545135498047, 0.19006967544555664, 0.1793212890625, 0.17286920547485352, 0.1711258888244629, 0.17994976043701172, 0.20236682891845703, 0.227264404296875, 0.24996232986450195, 0.26702880859375, 0.27353334426879883, 0.27774477005004883, 0.2855234146118164, 0.2898716926574707, 0.2868986129760742, 0.29054975509643555, 0.3083963394165039, 0.32108163833618164, 0.31974077224731445, 0.3306889533996582, 0.3682131767272949, 0.41753053665161133, 0.47003793716430664, 0.5201082229614258, 0.5543084144592285, 0.5791850090026855, 0.6032190322875977, 0.6314606666564941, 0.6657285690307617, 0.699462890625, 0.727266788482666, 0.747464656829834, 0.7552309036254883, 0.7694239616394043, 0.78607177734375, 0.7900967597961426, 0.7730951309204102, 0.756500244140625, 0.7552285194396973, 0.7544031143188477, 0.7461614608764648, 0.7400126457214355, 0.7379975318908691, 0.7310042381286621, 0.7180390357971191, 0.7089109420776367, 0.7056422233581543, 0.7049765586853027, 0.7078285217285156, 0.7227015495300293, 0.754063606262207, 0.7818722724914551, 0.7937569618225098, 0.7983050346374512, 0.7983479499816895, 0.8074536323547363, 0.8390388488769531, 0.8693490028381348, 0.8788204193115234, 0.837369441986084, 0.838355541229248, 0.8331665992736816, 0.8311638832092285, 0.8342013359069824, 0.8364543914794922, 0.8275160789489746, 0.8182373046875, 0.8098564147949219, 0.7952136993408203, 0.7762694358825684, 0.7554111480712891, 0.7392458915710449, 0.7343449592590332, 0.7271938323974609, 0.706761360168457, 0.686467170715332, 0.6752324104309082, 0.6673202514648438, 0.6616606712341309, 0.6630630493164062, 0.6705446243286133, 0.6820688247680664, 0.7002067565917969, 0.7198171615600586, 0.7349777221679688, 0.7432165145874023, 0.7425613403320312, 0.7399969100952148, 0.7417516708374023, 0.7575998306274414, 0.7950344085693359, 0.8357267379760742, 0.8687028884887695, 0.8902359008789062, 0.9007568359375, 0.9149341583251953, 0.9454412460327148, 0.9757757186889648, 0.9921293258666992, 0.9926862716674805, 0.9755134582519531, 0.950413703918457, 0.928192138671875, 0.91229248046875, 0.9033336639404297, 0.8939409255981445, 0.8799314498901367, 0.8596277236938477, 0.8329153060913086, 0.8116464614868164, 0.8035726547241211, 0.8037109375, 0.8084726333618164, 0.8156862258911133, 0.8232994079589844, 0.8302621841430664, 0.8379459381103516, 0.8425960540771484, 0.8397073745727539, 0.8326501846313477, 0.82391357421875, 0.8146657943725586, 0.8069372177124023, 0.8006086349487305, 0.7946348190307617, 0.7909660339355469, 0.7919206619262695, 0.7795791625976562, 0.7411613464355469, 0.7046642303466797, 0.6888027191162109, 0.6800365447998047, 0.6725320816040039, 0.6712436676025391, 0.6736927032470703, 0.6821832656860352, 0.7051706314086914, 0.7462978363037109, 0.8039779663085938, 0.8594503402709961, 0.9008331298828125, 0.9301233291625977, 0.9474964141845703, 0.9539499282836914, 0.9504489898681641, 0.9544820785522461, 0.9774856567382812, 0.9975214004516602, 1.0012216567993164, 1.0022563934326172, 1.0076723098754883, 1.0026063919067383, 0.980433464050293, 0.9598684310913086, 0.9492559432983398, 0.9446306228637695, 0.9485177993774414, 0.9554386138916016, 0.9573945999145508]\n",
      "<<Perdida: 0.0019296349491924047 epoca: 10\n",
      "---Inicio de epoca: 11--\n",
      ">>Entradas: tensor([0.0503, 0.0086, 0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203])\n",
      ">>Salida: tensor([0.0494])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1453], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.0494])\n",
      ">>Entradas: tensor([0.0086, 0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203, 0.1453],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1079])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1266], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1079])\n",
      ">>Entradas: tensor([0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203, 0.1453, 0.1266],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1372])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1258], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1372])\n",
      ">>Entradas: tensor([0.0245, 0.0327, 0.0246, 0.0205, 0.0203, 0.1453, 0.1266, 0.1258],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1373])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1479], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1373])\n",
      ">>Entradas: tensor([0.0327, 0.0246, 0.0205, 0.0203, 0.1453, 0.1266, 0.1258, 0.1479],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1339])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1397], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1339])\n",
      ">>Entradas: tensor([0.0246, 0.0205, 0.0203, 0.1453, 0.1266, 0.1258, 0.1479, 0.1397],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1268])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1327], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1268])\n",
      ">>Entradas: tensor([0.0205, 0.0203, 0.1453, 0.1266, 0.1258, 0.1479, 0.1397, 0.1327],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1476])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1489], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1476])\n",
      ">>Entradas: tensor([0.0203, 0.1453, 0.1266, 0.1258, 0.1479, 0.1397, 0.1327, 0.1489],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1960])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1741], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1960])\n",
      ">>Entradas: tensor([0.1453, 0.1266, 0.1258, 0.1479, 0.1397, 0.1327, 0.1489, 0.1741],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1834], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2169])\n",
      ">>Entradas: tensor([0.1266, 0.1258, 0.1479, 0.1397, 0.1327, 0.1489, 0.1741, 0.1834],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2101])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1933], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2101])\n",
      ">>Entradas: tensor([0.1258, 0.1479, 0.1397, 0.1327, 0.1489, 0.1741, 0.1834, 0.1933],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2027])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2010], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2027])\n",
      ">>Entradas: tensor([0.1479, 0.1397, 0.1327, 0.1489, 0.1741, 0.1834, 0.1933, 0.2010],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1946])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1990], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1946])\n",
      ">>Entradas: tensor([0.1397, 0.1327, 0.1489, 0.1741, 0.1834, 0.1933, 0.2010, 0.1990],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1941])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1990], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1941])\n",
      ">>Entradas: tensor([0.1327, 0.1489, 0.1741, 0.1834, 0.1933, 0.2010, 0.1990, 0.1990],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2010])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2047], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2010])\n",
      ">>Entradas: tensor([0.1489, 0.1741, 0.1834, 0.1933, 0.2010, 0.1990, 0.1990, 0.2047],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2060], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1966])\n",
      ">>Entradas: tensor([0.1741, 0.1834, 0.1933, 0.2010, 0.1990, 0.1990, 0.2047, 0.2060],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1810])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2007], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1810])\n",
      ">>Entradas: tensor([0.1834, 0.1933, 0.2010, 0.1990, 0.1990, 0.2047, 0.2060, 0.2007],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1654])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1931], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1654])\n",
      ">>Entradas: tensor([0.1933, 0.2010, 0.1990, 0.1990, 0.2047, 0.2060, 0.2007, 0.1931],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1499])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1819], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1499])\n",
      ">>Entradas: tensor([0.2010, 0.1990, 0.1990, 0.2047, 0.2060, 0.2007, 0.1931, 0.1819],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1504])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1723], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1504])\n",
      ">>Entradas: tensor([0.1990, 0.1990, 0.2047, 0.2060, 0.2007, 0.1931, 0.1819, 0.1723],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1671])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1706], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1671])\n",
      ">>Entradas: tensor([0.1990, 0.2047, 0.2060, 0.2007, 0.1931, 0.1819, 0.1723, 0.1706],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2023])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1795], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2023])\n",
      ">>Entradas: tensor([0.2047, 0.2060, 0.2007, 0.1931, 0.1819, 0.1723, 0.1706, 0.1795],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2559])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2006], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2559])\n",
      ">>Entradas: tensor([0.2060, 0.2007, 0.1931, 0.1819, 0.1723, 0.1706, 0.1795, 0.2006],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2927])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2259], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2927])\n",
      ">>Entradas: tensor([0.2007, 0.1931, 0.1819, 0.1723, 0.1706, 0.1795, 0.2006, 0.2259],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2500], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.1931, 0.1819, 0.1723, 0.1706, 0.1795, 0.2006, 0.2259, 0.2500],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3109])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2679], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3109])\n",
      ">>Entradas: tensor([0.1819, 0.1723, 0.1706, 0.1795, 0.2006, 0.2259, 0.2500, 0.2679],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2876])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2755], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2876])\n",
      ">>Entradas: tensor([0.1723, 0.1706, 0.1795, 0.2006, 0.2259, 0.2500, 0.2679, 0.2755],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2802])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2812], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2802])\n",
      ">>Entradas: tensor([0.1706, 0.1795, 0.2006, 0.2259, 0.2500, 0.2679, 0.2755, 0.2812],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2886])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2898], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2886])\n",
      ">>Entradas: tensor([0.1795, 0.2006, 0.2259, 0.2500, 0.2679, 0.2755, 0.2812, 0.2898],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2825])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2949], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2825])\n",
      ">>Entradas: tensor([0.2006, 0.2259, 0.2500, 0.2679, 0.2755, 0.2812, 0.2898, 0.2949],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2618])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2927], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2618])\n",
      ">>Entradas: tensor([0.2259, 0.2500, 0.2679, 0.2755, 0.2812, 0.2898, 0.2949, 0.2927],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2966], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2801])\n",
      ">>Entradas: tensor([0.2500, 0.2679, 0.2755, 0.2812, 0.2898, 0.2949, 0.2927, 0.2966],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3374])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3142], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3374])\n",
      ">>Entradas: tensor([0.2679, 0.2755, 0.2812, 0.2898, 0.2949, 0.2927, 0.2966, 0.3142],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3482])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3266], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3482])\n",
      ">>Entradas: tensor([0.2755, 0.2812, 0.2898, 0.2949, 0.2927, 0.2966, 0.3142, 0.3266],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3250], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2812, 0.2898, 0.2949, 0.2927, 0.2966, 0.3142, 0.3266, 0.3250],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3436])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3356], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3436])\n",
      ">>Entradas: tensor([0.2898, 0.2949, 0.2927, 0.2966, 0.3142, 0.3266, 0.3250, 0.3356],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.4412])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3712], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.4412])\n",
      ">>Entradas: tensor([0.2949, 0.2927, 0.2966, 0.3142, 0.3266, 0.3250, 0.3356, 0.3712],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5211])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4994], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5211])\n",
      ">>Entradas: tensor([0.2927, 0.2966, 0.3142, 0.3266, 0.3250, 0.3356, 0.3712, 0.4994],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5833])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5377], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5833])\n",
      ">>Entradas: tensor([0.2966, 0.3142, 0.3266, 0.3250, 0.3356, 0.3712, 0.4994, 0.5377],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5873], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6089])\n",
      ">>Entradas: tensor([0.3142, 0.3266, 0.3250, 0.3356, 0.3712, 0.4994, 0.5377, 0.5873],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5980])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6295], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5980])\n",
      ">>Entradas: tensor([0.3266, 0.3250, 0.3356, 0.3712, 0.4994, 0.5377, 0.5873, 0.6295],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5945])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6536], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5945])\n",
      ">>Entradas: tensor([0.3250, 0.3356, 0.3712, 0.4994, 0.5377, 0.5873, 0.6295, 0.6536],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5985])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6705], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5985])\n",
      ">>Entradas: tensor([0.3356, 0.3712, 0.4994, 0.5377, 0.5873, 0.6295, 0.6536, 0.6705],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6214])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7057], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6214])\n",
      ">>Entradas: tensor([0.3712, 0.4994, 0.5377, 0.5873, 0.6295, 0.6536, 0.6705, 0.7057],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6631])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7428], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6631])\n",
      ">>Entradas: tensor([0.4994, 0.5377, 0.5873, 0.6295, 0.6536, 0.6705, 0.7057, 0.7428],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6929])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7672], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6929])\n",
      ">>Entradas: tensor([0.5377, 0.5873, 0.6295, 0.6536, 0.6705, 0.7057, 0.7428, 0.7672],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7107])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7835], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7107])\n",
      ">>Entradas: tensor([0.5873, 0.6295, 0.6536, 0.6705, 0.7057, 0.7428, 0.7672, 0.7835],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7217])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7942], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7217])\n",
      ">>Entradas: tensor([0.6295, 0.6536, 0.6705, 0.7057, 0.7428, 0.7672, 0.7835, 0.7942],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7259])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7951], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7259])\n",
      ">>Entradas: tensor([0.6536, 0.6705, 0.7057, 0.7428, 0.7672, 0.7835, 0.7942, 0.7951],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7404])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7963], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7404])\n",
      ">>Entradas: tensor([0.6705, 0.7057, 0.7428, 0.7672, 0.7835, 0.7942, 0.7951, 0.7963],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7652])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8043], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7652])\n",
      ">>Entradas: tensor([0.7057, 0.7428, 0.7672, 0.7835, 0.7942, 0.7951, 0.7963, 0.8043],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7448])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8013], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7448])\n",
      ">>Entradas: tensor([0.7428, 0.7672, 0.7835, 0.7942, 0.7951, 0.7963, 0.8043, 0.8013],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6792])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7755], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6792])\n",
      ">>Entradas: tensor([0.7672, 0.7835, 0.7942, 0.7951, 0.7963, 0.8043, 0.8013, 0.7755],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6746])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7510], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6746])\n",
      ">>Entradas: tensor([0.7835, 0.7942, 0.7951, 0.7963, 0.8043, 0.8013, 0.7755, 0.7510],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7444], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7309])\n",
      ">>Entradas: tensor([0.7942, 0.7951, 0.7963, 0.8043, 0.8013, 0.7755, 0.7510, 0.7444],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7467])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7399], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7467])\n",
      ">>Entradas: tensor([0.7951, 0.7963, 0.8043, 0.8013, 0.7755, 0.7510, 0.7444, 0.7399],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7219])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7293], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7219])\n",
      ">>Entradas: tensor([0.7963, 0.8043, 0.8013, 0.7755, 0.7510, 0.7444, 0.7399, 0.7293],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7199])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7224], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7199])\n",
      ">>Entradas: tensor([0.8043, 0.8013, 0.7755, 0.7510, 0.7444, 0.7399, 0.7293, 0.7224],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7407])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7204], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7407])\n",
      ">>Entradas: tensor([0.8013, 0.7755, 0.7510, 0.7444, 0.7399, 0.7293, 0.7224, 0.7204],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7362])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7138], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7362])\n",
      ">>Entradas: tensor([0.7755, 0.7510, 0.7444, 0.7399, 0.7293, 0.7224, 0.7204, 0.7138],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7019], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7065])\n",
      ">>Entradas: tensor([0.7510, 0.7444, 0.7399, 0.7293, 0.7224, 0.7204, 0.7138, 0.7019],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6979])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6946], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6979])\n",
      ">>Entradas: tensor([0.7444, 0.7399, 0.7293, 0.7224, 0.7204, 0.7138, 0.7019, 0.6946],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7106])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6935], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7106])\n",
      ">>Entradas: tensor([0.7399, 0.7293, 0.7224, 0.7204, 0.7138, 0.7019, 0.6946, 0.6935],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7210])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6953], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7210])\n",
      ">>Entradas: tensor([0.7293, 0.7224, 0.7204, 0.7138, 0.7019, 0.6946, 0.6935, 0.6953],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7291])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7007], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7291])\n",
      ">>Entradas: tensor([0.7224, 0.7204, 0.7138, 0.7019, 0.6946, 0.6935, 0.6953, 0.7007],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7674])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7181], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7674])\n",
      ">>Entradas: tensor([0.7204, 0.7138, 0.7019, 0.6946, 0.6935, 0.6953, 0.7007, 0.7181],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8359])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7520], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8359])\n",
      ">>Entradas: tensor([0.7138, 0.7019, 0.6946, 0.6935, 0.6953, 0.7007, 0.7181, 0.7520],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8510])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7827], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8510])\n",
      ">>Entradas: tensor([0.7019, 0.6946, 0.6935, 0.6953, 0.7007, 0.7181, 0.7520, 0.7827],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8127])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7978], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8127])\n",
      ">>Entradas: tensor([0.6946, 0.6935, 0.6953, 0.7007, 0.7181, 0.7520, 0.7827, 0.7978],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7864])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8049], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7864])\n",
      ">>Entradas: tensor([0.6935, 0.6953, 0.7007, 0.7181, 0.7520, 0.7827, 0.7978, 0.8049],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7720])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7988], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7720])\n",
      ">>Entradas: tensor([0.6953, 0.7007, 0.7181, 0.7520, 0.7827, 0.7978, 0.8049, 0.7988],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8108], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.7007, 0.7181, 0.7520, 0.7827, 0.7978, 0.8049, 0.7988, 0.8108],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8803])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8440], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8803])\n",
      ">>Entradas: tensor([0.7181, 0.7520, 0.7827, 0.7978, 0.8049, 0.7988, 0.8108, 0.8440],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8987])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8758], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8987])\n",
      ">>Entradas: tensor([0.7520, 0.7827, 0.7978, 0.8049, 0.7988, 0.8108, 0.8440, 0.8758],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8871], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.7827, 0.7978, 0.8049, 0.7988, 0.8108, 0.8440, 0.8758, 0.8871],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6573], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8309])\n",
      "ERROR: la modificacion de los pesos di√≥ un error mayor: 0.03012010268867016, se regresa al estado anterior de la red\n",
      ">>Entradas: tensor([0.7978, 0.8049, 0.7988, 0.8108, 0.8440, 0.8758, 0.8871, 0.9083],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8156])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8924], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8156])\n",
      ">>Entradas: tensor([0.8049, 0.7988, 0.8108, 0.8440, 0.8758, 0.8871, 0.9083, 0.8924],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8751], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8117])\n",
      ">>Entradas: tensor([0.7988, 0.8108, 0.8440, 0.8758, 0.8871, 0.9083, 0.8924, 0.8751],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8192])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8670], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8192])\n",
      ">>Entradas: tensor([0.8108, 0.8440, 0.8758, 0.8871, 0.9083, 0.8924, 0.8751, 0.8670],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8218])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8607], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8218])\n",
      ">>Entradas: tensor([0.8440, 0.8758, 0.8871, 0.9083, 0.8924, 0.8751, 0.8670, 0.8607],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8519], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8197])\n",
      ">>Entradas: tensor([0.8758, 0.8871, 0.9083, 0.8924, 0.8751, 0.8670, 0.8607, 0.8519],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8179])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8439], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8179])\n",
      ">>Entradas: tensor([0.8871, 0.9083, 0.8924, 0.8751, 0.8670, 0.8607, 0.8519, 0.8439],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8163])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8346], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8163])\n",
      ">>Entradas: tensor([0.9083, 0.8924, 0.8751, 0.8670, 0.8607, 0.8519, 0.8439, 0.8346],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8006])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8171], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8006])\n",
      ">>Entradas: tensor([0.8924, 0.8751, 0.8670, 0.8607, 0.8519, 0.8439, 0.8346, 0.8171],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7705])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7942], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7705])\n",
      ">>Entradas: tensor([0.8751, 0.8670, 0.8607, 0.8519, 0.8439, 0.8346, 0.8171, 0.7942],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7427])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7704], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7427])\n",
      ">>Entradas: tensor([0.8670, 0.8607, 0.8519, 0.8439, 0.8346, 0.8171, 0.7942, 0.7704],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7448], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7169])\n",
      ">>Entradas: tensor([0.8607, 0.8519, 0.8439, 0.8346, 0.8171, 0.7942, 0.7704, 0.7448],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7256], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7197])\n",
      ">>Entradas: tensor([0.8519, 0.8439, 0.8346, 0.8171, 0.7942, 0.7704, 0.7448, 0.7256],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7509])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7207], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7509])\n",
      ">>Entradas: tensor([0.8439, 0.8346, 0.8171, 0.7942, 0.7704, 0.7448, 0.7256, 0.7207],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7403])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7134], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7403])\n",
      ">>Entradas: tensor([0.8346, 0.8171, 0.7942, 0.7704, 0.7448, 0.7256, 0.7207, 0.7134],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6920], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.8171, 0.7942, 0.7704, 0.7448, 0.7256, 0.7207, 0.7134, 0.6920],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6688])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6711], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6688])\n",
      ">>Entradas: tensor([0.7942, 0.7704, 0.7448, 0.7256, 0.7207, 0.7134, 0.6920, 0.6711],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6835])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6599], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6835])\n",
      ">>Entradas: tensor([0.7704, 0.7448, 0.7256, 0.7207, 0.7134, 0.6920, 0.6711, 0.6599],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6526], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.7448, 0.7256, 0.7207, 0.7134, 0.6920, 0.6711, 0.6599, 0.6526],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6815])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6484], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6815])\n",
      ">>Entradas: tensor([0.7256, 0.7207, 0.7134, 0.6920, 0.6711, 0.6599, 0.6526, 0.6484],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6893])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6520], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6893])\n",
      ">>Entradas: tensor([0.7207, 0.7134, 0.6920, 0.6711, 0.6599, 0.6526, 0.6484, 0.6520],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7111])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6617], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7111])\n",
      ">>Entradas: tensor([0.7134, 0.6920, 0.6711, 0.6599, 0.6526, 0.6484, 0.6520, 0.6617],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7349])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6752], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7349])\n",
      ">>Entradas: tensor([0.6920, 0.6711, 0.6599, 0.6526, 0.6484, 0.6520, 0.6617, 0.6752],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7608])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6955], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7608])\n",
      ">>Entradas: tensor([0.6711, 0.6599, 0.6526, 0.6484, 0.6520, 0.6617, 0.6752, 0.6955],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7711])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7178], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7711])\n",
      ">>Entradas: tensor([0.6599, 0.6526, 0.6484, 0.6520, 0.6617, 0.6752, 0.6955, 0.7178],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7660])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7360], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7660])\n",
      ">>Entradas: tensor([0.6526, 0.6484, 0.6520, 0.6617, 0.6752, 0.6955, 0.7178, 0.7360],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7483])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7472], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7483])\n",
      ">>Entradas: tensor([0.6484, 0.6520, 0.6617, 0.6752, 0.6955, 0.7178, 0.7360, 0.7472],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7182])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7488], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7182])\n",
      ">>Entradas: tensor([0.6520, 0.6617, 0.6752, 0.6955, 0.7178, 0.7360, 0.7472, 0.7488],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7480], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7089])\n",
      ">>Entradas: tensor([0.6617, 0.6752, 0.6955, 0.7178, 0.7360, 0.7472, 0.7488, 0.7480],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7204])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7401], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7204])\n",
      ">>Entradas: tensor([0.6752, 0.6955, 0.7178, 0.7360, 0.7472, 0.7488, 0.7480, 0.7401],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7706])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7586], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7706])\n",
      ">>Entradas: tensor([0.6955, 0.7178, 0.7360, 0.7472, 0.7488, 0.7480, 0.7401, 0.7586],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8595])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7979], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8595])\n",
      ">>Entradas: tensor([0.7178, 0.7360, 0.7472, 0.7488, 0.7480, 0.7401, 0.7586, 0.7979],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8399], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9065])\n",
      ">>Entradas: tensor([0.7360, 0.7472, 0.7488, 0.7480, 0.7401, 0.7586, 0.7979, 0.8399],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9119])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8729], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9119])\n",
      ">>Entradas: tensor([0.7472, 0.7488, 0.7480, 0.7401, 0.7586, 0.7979, 0.8399, 0.8729],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9043])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8960], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9043])\n",
      ">>Entradas: tensor([0.7488, 0.7480, 0.7401, 0.7586, 0.7979, 0.8399, 0.8729, 0.8960],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8839])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9057], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8839])\n",
      ">>Entradas: tensor([0.7480, 0.7401, 0.7586, 0.7979, 0.8399, 0.8729, 0.8960, 0.9057],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9032])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9184], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9032])\n",
      ">>Entradas: tensor([0.7401, 0.7586, 0.7979, 0.8399, 0.8729, 0.8960, 0.9057, 0.9184],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9623])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9494], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9623])\n",
      ">>Entradas: tensor([0.7586, 0.7979, 0.8399, 0.8729, 0.8960, 0.9057, 0.9184, 0.9494],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9821])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9806], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9821])\n",
      ">>Entradas: tensor([0.7979, 0.8399, 0.8729, 0.8960, 0.9057, 0.9184, 0.9494, 0.9806],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9624])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9969], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9624])\n",
      ">>Entradas: tensor([0.8399, 0.8729, 0.8960, 0.9057, 0.9184, 0.9494, 0.9806, 0.9969],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9303])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9969], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9303])\n",
      ">>Entradas: tensor([0.8729, 0.8960, 0.9057, 0.9184, 0.9494, 0.9806, 0.9969, 0.9969],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8855])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9787], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8855])\n",
      ">>Entradas: tensor([0.8960, 0.9057, 0.9184, 0.9494, 0.9806, 0.9969, 0.9969, 0.9787],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8597])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9517], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8597])\n",
      ">>Entradas: tensor([0.9057, 0.9184, 0.9494, 0.9806, 0.9969, 0.9969, 0.9787, 0.9517],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8529])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9280], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8529])\n",
      ">>Entradas: tensor([0.9184, 0.9494, 0.9806, 0.9969, 0.9969, 0.9787, 0.9517, 0.9280],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9116], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.9494, 0.9806, 0.9969, 0.9969, 0.9787, 0.9517, 0.9280, 0.9116],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8769])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9023], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8769])\n",
      ">>Entradas: tensor([0.9806, 0.9969, 0.9969, 0.9787, 0.9517, 0.9280, 0.9116, 0.9023],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8806])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8925], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8806])\n",
      ">>Entradas: tensor([0.9969, 0.9969, 0.9787, 0.9517, 0.9280, 0.9116, 0.9023, 0.8925],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8699])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8780], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8699])\n",
      ">>Entradas: tensor([0.9969, 0.9787, 0.9517, 0.9280, 0.9116, 0.9023, 0.8925, 0.8780],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8465])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8571], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8465])\n",
      ">>Entradas: tensor([0.9787, 0.9517, 0.9280, 0.9116, 0.9023, 0.8925, 0.8780, 0.8571],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8104])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8298], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8104])\n",
      ">>Entradas: tensor([0.9517, 0.9280, 0.9116, 0.9023, 0.8925, 0.8780, 0.8571, 0.8298],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8026])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8081], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8026])\n",
      ">>Entradas: tensor([0.9280, 0.9116, 0.9023, 0.8925, 0.8780, 0.8571, 0.8298, 0.8081],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8232])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7999], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8232])\n",
      ">>Entradas: tensor([0.9116, 0.9023, 0.8925, 0.8780, 0.8571, 0.8298, 0.8081, 0.7999],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8397])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8003], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8397])\n",
      ">>Entradas: tensor([0.9023, 0.8925, 0.8780, 0.8571, 0.8298, 0.8081, 0.7999, 0.8003],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8522])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8054], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8522])\n",
      ">>Entradas: tensor([0.8925, 0.8780, 0.8571, 0.8298, 0.8081, 0.7999, 0.8003, 0.8054],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8616])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8130], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8616])\n",
      ">>Entradas: tensor([0.8780, 0.8571, 0.8298, 0.8081, 0.7999, 0.8003, 0.8054, 0.8130],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8679])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8207], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8679])\n",
      ">>Entradas: tensor([0.8571, 0.8298, 0.8081, 0.7999, 0.8003, 0.8054, 0.8130, 0.8207],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8702])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8282], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8702])\n",
      ">>Entradas: tensor([0.8298, 0.8081, 0.7999, 0.8003, 0.8054, 0.8130, 0.8207, 0.8282],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8685])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8365], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8685])\n",
      ">>Entradas: tensor([0.8081, 0.7999, 0.8003, 0.8054, 0.8130, 0.8207, 0.8282, 0.8365],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8530])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8421], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8530])\n",
      ">>Entradas: tensor([0.7999, 0.8003, 0.8054, 0.8130, 0.8207, 0.8282, 0.8365, 0.8421],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8236])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8400], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8236])\n",
      ">>Entradas: tensor([0.8003, 0.8054, 0.8130, 0.8207, 0.8282, 0.8365, 0.8421, 0.8400],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8334], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.8054, 0.8130, 0.8207, 0.8282, 0.8365, 0.8421, 0.8400, 0.8334],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7919])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8248], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7919])\n",
      ">>Entradas: tensor([0.8130, 0.8207, 0.8282, 0.8365, 0.8421, 0.8400, 0.8334, 0.8248],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7865])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8155], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7865])\n",
      ">>Entradas: tensor([0.8207, 0.8282, 0.8365, 0.8421, 0.8400, 0.8334, 0.8248, 0.8155],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7870])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8077], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7870])\n",
      ">>Entradas: tensor([0.8282, 0.8365, 0.8421, 0.8400, 0.8334, 0.8248, 0.8155, 0.8077],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7874])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8012], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7874])\n",
      ">>Entradas: tensor([0.8365, 0.8421, 0.8400, 0.8334, 0.8248, 0.8155, 0.8077, 0.8012],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7879])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7950], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7879])\n",
      ">>Entradas: tensor([0.8421, 0.8400, 0.8334, 0.8248, 0.8155, 0.8077, 0.8012, 0.7950],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7955])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7910], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7955])\n",
      ">>Entradas: tensor([0.8400, 0.8334, 0.8248, 0.8155, 0.8077, 0.8012, 0.7950, 0.7910],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8102])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7916], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8102])\n",
      ">>Entradas: tensor([0.8334, 0.8248, 0.8155, 0.8077, 0.8012, 0.7950, 0.7910, 0.7916],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7668])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7790], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7668])\n",
      ">>Entradas: tensor([0.8248, 0.8155, 0.8077, 0.8012, 0.7950, 0.7910, 0.7916, 0.7790],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6655])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7401], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6655])\n",
      ">>Entradas: tensor([0.8155, 0.8077, 0.8012, 0.7950, 0.7910, 0.7916, 0.7790, 0.7401],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6361])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7024], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6361])\n",
      ">>Entradas: tensor([0.8077, 0.8012, 0.7950, 0.7910, 0.7916, 0.7790, 0.7401, 0.7024],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6785])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6853], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6785])\n",
      ">>Entradas: tensor([0.8012, 0.7950, 0.7910, 0.7916, 0.7790, 0.7401, 0.7024, 0.6853],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6758], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6966])\n",
      ">>Entradas: tensor([0.7950, 0.7910, 0.7916, 0.7790, 0.7401, 0.7024, 0.6853, 0.6758],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6903])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6687], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6903])\n",
      ">>Entradas: tensor([0.7910, 0.7916, 0.7790, 0.7401, 0.7024, 0.6853, 0.6758, 0.6687],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6970])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6667], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6970])\n",
      ">>Entradas: tensor([0.7916, 0.7790, 0.7401, 0.7024, 0.6853, 0.6758, 0.6687, 0.6667],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7167])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6687], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7167])\n",
      ">>Entradas: tensor([0.7790, 0.7401, 0.7024, 0.6853, 0.6758, 0.6687, 0.6667, 0.6687],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7491])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6766], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7491])\n",
      ">>Entradas: tensor([0.7401, 0.7024, 0.6853, 0.6758, 0.6687, 0.6667, 0.6687, 0.6766],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7940])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6996], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7940])\n",
      ">>Entradas: tensor([0.7024, 0.6853, 0.6758, 0.6687, 0.6667, 0.6687, 0.6766, 0.6996],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8547])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7419], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8547])\n",
      ">>Entradas: tensor([0.6853, 0.6758, 0.6687, 0.6667, 0.6687, 0.6766, 0.6996, 0.7419],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9314])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8019], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9314])\n",
      ">>Entradas: tensor([0.6758, 0.6687, 0.6667, 0.6687, 0.6766, 0.6996, 0.7419, 0.8019],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9627])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8607], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9627])\n",
      ">>Entradas: tensor([0.6687, 0.6667, 0.6687, 0.6766, 0.6996, 0.7419, 0.8019, 0.8607],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9486])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9054], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9486])\n",
      ">>Entradas: tensor([0.6667, 0.6687, 0.6766, 0.6996, 0.7419, 0.8019, 0.8607, 0.9054],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9307])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9373], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9307])\n",
      ">>Entradas: tensor([0.6687, 0.6766, 0.6996, 0.7419, 0.8019, 0.8607, 0.9054, 0.9373],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9090])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9564], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9090])\n",
      ">>Entradas: tensor([0.6766, 0.6996, 0.7419, 0.8019, 0.8607, 0.9054, 0.9373, 0.9564],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8816])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9639], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8816])\n",
      ">>Entradas: tensor([0.6996, 0.7419, 0.8019, 0.8607, 0.9054, 0.9373, 0.9564, 0.9639],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8487])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9605], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8487])\n",
      ">>Entradas: tensor([0.7419, 0.8019, 0.8607, 0.9054, 0.9373, 0.9564, 0.9639, 0.9605],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8753])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9640], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8753])\n",
      ">>Entradas: tensor([0.8019, 0.8607, 0.9054, 0.9373, 0.9564, 0.9639, 0.9605, 0.9640],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9612])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9041], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9612])\n",
      "ERROR: la modificacion de los pesos di√≥ un error mayor: 0.003266736399382353, se regresa al estado anterior de la red\n",
      ">>Entradas: tensor([0.8607, 0.9054, 0.9373, 0.9564, 0.9639, 0.9605, 0.9640, 0.9967],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9925])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0132], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9925])\n",
      ">>Entradas: tensor([0.9054, 0.9373, 0.9564, 0.9639, 0.9605, 0.9640, 0.9967, 1.0132],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9690])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0141], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9690])\n",
      ">>Entradas: tensor([0.9373, 0.9564, 0.9639, 0.9605, 0.9640, 0.9967, 1.0132, 1.0141],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9715])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0121], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9715])\n",
      ">>Entradas: tensor([0.9564, 0.9639, 0.9605, 0.9640, 0.9967, 1.0132, 1.0141, 1.0121],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([1.])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0145], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([1.])\n",
      ">>Entradas: tensor([0.9639, 0.9605, 0.9640, 0.9967, 1.0132, 1.0141, 1.0121, 1.0145],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0065], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9801])\n",
      ">>Entradas: tensor([0.9605, 0.9640, 0.9967, 1.0132, 1.0141, 1.0121, 1.0145, 1.0065],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9831], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9117])\n",
      ">>Entradas: tensor([0.9640, 0.9967, 1.0132, 1.0141, 1.0121, 1.0145, 1.0065, 0.9831],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8911])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9619], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8911])\n",
      ">>Entradas: tensor([0.9967, 1.0132, 1.0141, 1.0121, 1.0145, 1.0065, 0.9831, 0.9619],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9181])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9485], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9181])\n",
      ">>Entradas: tensor([1.0132, 1.0141, 1.0121, 1.0145, 1.0065, 0.9831, 0.9619, 0.9485],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9450])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9421], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9450])\n",
      ">>Entradas: tensor([1.0141, 1.0121, 1.0145, 1.0065, 0.9831, 0.9619, 0.9485, 0.9421],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9718])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9451], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9718])\n",
      ">>Entradas: tensor([1.0121, 1.0145, 1.0065, 0.9831, 0.9619, 0.9485, 0.9421, 0.9451],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9829])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9516], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9829])\n",
      ">>Entradas: tensor([1.0145, 1.0065, 0.9831, 0.9619, 0.9485, 0.9421, 0.9451, 0.9516],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9783])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9535], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9783])\n",
      ">>s_original: [0.049424633383750916, 0.10789185762405396, 0.13719609379768372, 0.13733737170696259, 0.1338856965303421, 0.12684109807014465, 0.14756061136722565, 0.19604423642158508, 0.21688967943191528, 0.21009695529937744, 0.20267784595489502, 0.1946323662996292, 0.19407351315021515, 0.20100130140781403, 0.19663821160793304, 0.180984228849411, 0.16539041697978973, 0.14985674619674683, 0.15043111145496368, 0.1671135276556015, 0.20227035880088806, 0.25590160489082336, 0.29268819093704224, 0.31263017654418945, 0.31093889474868774, 0.2876143157482147, 0.28016164898872375, 0.28858086466789246, 0.28246283531188965, 0.26180753111839294, 0.2801212966442108, 0.3374040722846985, 0.3482298254966736, 0.3125985562801361, 0.34358710050582886, 0.44119545817375183, 0.521095335483551, 0.5832866430282593, 0.6089234352111816, 0.5980057120323181, 0.5945301651954651, 0.5984968543052673, 0.621354341506958, 0.6631026864051819, 0.6928724050521851, 0.7106636166572571, 0.721682071685791, 0.7259277701377869, 0.7404318451881409, 0.7651942372322083, 0.7447891235351562, 0.6792163252830505, 0.6746017932891846, 0.730945348739624, 0.7467210292816162, 0.7219287157058716, 0.7199286818504333, 0.7407209277153015, 0.7362455129623413, 0.7065023183822632, 0.6979451775550842, 0.7105739712715149, 0.7209621667861938, 0.7291097044944763, 0.7674259543418884, 0.8359109163284302, 0.8510103225708008, 0.8127241730690002, 0.7863940000534058, 0.7720199823379517, 0.8033170700073242, 0.8802852630615234, 0.8987051844596863, 0.8585767149925232, 0.8308762311935425, 0.8156037926673889, 0.8116992115974426, 0.8191625475883484, 0.8218275904655457, 0.8196942210197449, 0.817862868309021, 0.8163333535194397, 0.8005555868148804, 0.7705295085906982, 0.7426586747169495, 0.716943085193634, 0.7197051048278809, 0.7509447932243347, 0.7402781248092651, 0.6877052187919617, 0.6687695384025574, 0.683471143245697, 0.6877052187919617, 0.6814717054367065, 0.6892618536949158, 0.7110756039619446, 0.7349108457565308, 0.7607676982879639, 0.771117091178894, 0.7659589648246765, 0.7483323812484741, 0.7182371616363525, 0.708941638469696, 0.7204458117485046, 0.7706154584884644, 0.8594506978988647, 0.906541109085083, 0.9118866324424744, 0.9043355584144592, 0.8838878870010376, 0.9032153487205505, 0.9623178839683533, 0.9820588231086731, 0.96243816614151, 0.9302511811256409, 0.8854979276657104, 0.8597025871276855, 0.8528652191162109, 0.8585854768753052, 0.8768633008003235, 0.8806464076042175, 0.8699347376823425, 0.846513569355011, 0.8103827834129333, 0.8026111125946045, 0.8231984972953796, 0.8397204279899597, 0.8521769046783447, 0.8615626692771912, 0.8678776621818542, 0.8701963424682617, 0.868518590927124, 0.852988064289093, 0.8236046433448792, 0.8032509088516235, 0.7919268012046814, 0.7865023016929626, 0.7869773507118225, 0.7874362468719482, 0.7878790497779846, 0.7954531908035278, 0.8101586699485779, 0.7668473124504089, 0.665519118309021, 0.6360738277435303, 0.678511381149292, 0.6965967416763306, 0.6903298497200012, 0.6970472931861877, 0.7167490720748901, 0.7490506768226624, 0.7939522862434387, 0.8547447323799133, 0.931428074836731, 0.9627243876457214, 0.9486336708068848, 0.9307146072387695, 0.9089671969413757, 0.8816379904747009, 0.8487268090248108, 0.8752607107162476, 0.9612395763397217, 0.9925020933151245, 0.9690483212471008, 0.9715476036071777, 1.0, 0.9800636768341064, 0.9117385745048523, 0.8910858035087585, 0.9181053042411804, 0.9450165033340454, 0.9718193411827087, 0.982906699180603, 0.9782785773277283]\n",
      ">>s_pred: [0.14528560638427734, 0.12658405303955078, 0.12583351135253906, 0.14785194396972656, 0.1397409439086914, 0.1326885223388672, 0.14886760711669922, 0.17409420013427734, 0.18337726593017578, 0.1933002471923828, 0.20104503631591797, 0.19904422760009766, 0.19902706146240234, 0.2046651840209961, 0.20601177215576172, 0.200714111328125, 0.1931285858154297, 0.1819019317626953, 0.17226409912109375, 0.17057514190673828, 0.17950916290283203, 0.20061206817626953, 0.22588348388671875, 0.25002002716064453, 0.26793861389160156, 0.27553653717041016, 0.28116798400878906, 0.28983116149902344, 0.29488468170166016, 0.2926959991455078, 0.2966270446777344, 0.3141927719116211, 0.3265800476074219, 0.32500553131103516, 0.33556079864501953, 0.3712291717529297, 0.49936676025390625, 0.5377283096313477, 0.587346076965332, 0.6295061111450195, 0.6535778045654297, 0.6704740524291992, 0.705744743347168, 0.742833137512207, 0.7671699523925781, 0.7835454940795898, 0.7942495346069336, 0.7951059341430664, 0.7963266372680664, 0.804286003112793, 0.8013315200805664, 0.7755336761474609, 0.7509851455688477, 0.7444353103637695, 0.7399024963378906, 0.729313850402832, 0.7224311828613281, 0.7204399108886719, 0.713810920715332, 0.7018527984619141, 0.6945896148681641, 0.6935214996337891, 0.6952610015869141, 0.7006921768188477, 0.7180948257446289, 0.7519502639770508, 0.7826833724975586, 0.797760009765625, 0.8048639297485352, 0.7987680435180664, 0.8107519149780273, 0.8440113067626953, 0.8758058547973633, 0.8870677947998047, 0.908320426940918, 0.8923521041870117, 0.8751125335693359, 0.8669872283935547, 0.8607206344604492, 0.8518714904785156, 0.8439435958862305, 0.8346195220947266, 0.8170623779296875, 0.794219970703125, 0.7704410552978516, 0.7447586059570312, 0.7256021499633789, 0.7206630706787109, 0.7134208679199219, 0.6919641494750977, 0.6710538864135742, 0.6599407196044922, 0.6526212692260742, 0.6484184265136719, 0.6520013809204102, 0.6617355346679688, 0.675196647644043, 0.6954689025878906, 0.717799186706543, 0.7360143661499023, 0.7471847534179688, 0.7487897872924805, 0.7480020523071289, 0.7400760650634766, 0.7586383819580078, 0.7978525161743164, 0.8398532867431641, 0.8728876113891602, 0.8960065841674805, 0.9057073593139648, 0.9184484481811523, 0.9494094848632812, 0.9806137084960938, 0.9969348907470703, 0.9969339370727539, 0.9786691665649414, 0.9517307281494141, 0.927973747253418, 0.9116373062133789, 0.9023208618164062, 0.8924589157104492, 0.8780460357666016, 0.8571481704711914, 0.8297901153564453, 0.8080816268920898, 0.7999448776245117, 0.8003110885620117, 0.8053998947143555, 0.812952995300293, 0.8207492828369141, 0.8281669616699219, 0.8364953994750977, 0.8420629501342773, 0.8400163650512695, 0.8333578109741211, 0.8248119354248047, 0.8155136108398438, 0.8076610565185547, 0.8011922836303711, 0.795048713684082, 0.7910289764404297, 0.7916030883789062, 0.7790050506591797, 0.7400732040405273, 0.7024421691894531, 0.6853151321411133, 0.6757907867431641, 0.668670654296875, 0.6667404174804688, 0.668670654296875, 0.676605224609375, 0.6995582580566406, 0.741856575012207, 0.8018970489501953, 0.860651969909668, 0.9053812026977539, 0.9373254776000977, 0.9563817977905273, 0.9638500213623047, 0.9605226516723633, 0.9640178680419922, 0.9967031478881836, 1.0132360458374023, 1.0140819549560547, 1.0120553970336914, 1.014500617980957, 1.0064716339111328, 0.9831457138061523, 0.9618825912475586, 0.9485378265380859, 0.9420633316040039, 0.9450531005859375, 0.9515895843505859, 0.9534912109375]\n",
      "<<Perdida: 0.00202746968716383 epoca: 11\n",
      "---Inicio de epoca: 12--\n",
      ">>Entradas: tensor([0.0503, 0.0086, 0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203])\n",
      ">>Salida: tensor([0.0494])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([-0.0719], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.0494])\n",
      ">>Entradas: tensor([ 0.0086,  0.0000,  0.0245,  0.0327,  0.0246,  0.0205,  0.0203, -0.0719],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1079])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([-0.0121], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1079])\n",
      ">>Entradas: tensor([ 0.0000,  0.0245,  0.0327,  0.0246,  0.0205,  0.0203, -0.0719, -0.0121],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1372])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0405], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1372])\n",
      ">>Entradas: tensor([ 0.0245,  0.0327,  0.0246,  0.0205,  0.0203, -0.0719, -0.0121,  0.0405],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1373])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0523], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1373])\n",
      ">>Entradas: tensor([ 0.0327,  0.0246,  0.0205,  0.0203, -0.0719, -0.0121,  0.0405,  0.0523],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1339])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0801], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1339])\n",
      ">>Entradas: tensor([ 0.0246,  0.0205,  0.0203, -0.0719, -0.0121,  0.0405,  0.0523,  0.0801],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1268])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1026], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1268])\n",
      ">>Entradas: tensor([ 0.0205,  0.0203, -0.0719, -0.0121,  0.0405,  0.0523,  0.0801,  0.1026],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1476])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1111], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1476])\n",
      ">>Entradas: tensor([ 0.0203, -0.0719, -0.0121,  0.0405,  0.0523,  0.0801,  0.1026,  0.1111],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1960])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1397], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1960])\n",
      ">>Entradas: tensor([-0.0719, -0.0121,  0.0405,  0.0523,  0.0801,  0.1026,  0.1111,  0.1397],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1780], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2169])\n",
      ">>Entradas: tensor([-0.0121,  0.0405,  0.0523,  0.0801,  0.1026,  0.1111,  0.1397,  0.1780],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2101])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2031], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2101])\n",
      ">>Entradas: tensor([0.0405, 0.0523, 0.0801, 0.1026, 0.1111, 0.1397, 0.1780, 0.2031],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2027])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2184], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2027])\n",
      ">>Entradas: tensor([0.0523, 0.0801, 0.1026, 0.1111, 0.1397, 0.1780, 0.2031, 0.2184],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1946])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2287], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1946])\n",
      ">>Entradas: tensor([0.0801, 0.1026, 0.1111, 0.1397, 0.1780, 0.2031, 0.2184, 0.2287],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1941])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2335], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1941])\n",
      ">>Entradas: tensor([0.1026, 0.1111, 0.1397, 0.1780, 0.2031, 0.2184, 0.2287, 0.2335],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2010])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2373], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2010])\n",
      ">>Entradas: tensor([0.1111, 0.1397, 0.1780, 0.2031, 0.2184, 0.2287, 0.2335, 0.2373],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2364], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1966])\n",
      ">>Entradas: tensor([0.1397, 0.1780, 0.2031, 0.2184, 0.2287, 0.2335, 0.2373, 0.2364],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1810])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2336], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1810])\n",
      ">>Entradas: tensor([0.1780, 0.2031, 0.2184, 0.2287, 0.2335, 0.2373, 0.2364, 0.2336],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1654])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2231], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1654])\n",
      ">>Entradas: tensor([0.2031, 0.2184, 0.2287, 0.2335, 0.2373, 0.2364, 0.2336, 0.2231],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1499])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2070], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1499])\n",
      ">>Entradas: tensor([0.2184, 0.2287, 0.2335, 0.2373, 0.2364, 0.2336, 0.2231, 0.2070],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1504])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1924], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1504])\n",
      ">>Entradas: tensor([0.2287, 0.2335, 0.2373, 0.2364, 0.2336, 0.2231, 0.2070, 0.1924],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1671])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1840], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1671])\n",
      ">>Entradas: tensor([0.2335, 0.2373, 0.2364, 0.2336, 0.2231, 0.2070, 0.1924, 0.1840],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2023])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1859], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2023])\n",
      ">>Entradas: tensor([0.2373, 0.2364, 0.2336, 0.2231, 0.2070, 0.1924, 0.1840, 0.1859],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2559])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2022], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2559])\n",
      ">>Entradas: tensor([0.2364, 0.2336, 0.2231, 0.2070, 0.1924, 0.1840, 0.1859, 0.2022],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2927])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2243], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2927])\n",
      ">>Entradas: tensor([0.2336, 0.2231, 0.2070, 0.1924, 0.1840, 0.1859, 0.2022, 0.2243],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2465], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2231, 0.2070, 0.1924, 0.1840, 0.1859, 0.2022, 0.2243, 0.2465],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3109])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2642], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3109])\n",
      ">>Entradas: tensor([0.2070, 0.1924, 0.1840, 0.1859, 0.2022, 0.2243, 0.2465, 0.2642],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2876])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2730], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2876])\n",
      ">>Entradas: tensor([0.1924, 0.1840, 0.1859, 0.2022, 0.2243, 0.2465, 0.2642, 0.2730],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2802])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2806], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2802])\n",
      ">>Entradas: tensor([0.1840, 0.1859, 0.2022, 0.2243, 0.2465, 0.2642, 0.2730, 0.2806],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2886])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2917], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2886])\n",
      ">>Entradas: tensor([0.1859, 0.2022, 0.2243, 0.2465, 0.2642, 0.2730, 0.2806, 0.2917],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2825])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2996], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2825])\n",
      ">>Entradas: tensor([0.2022, 0.2243, 0.2465, 0.2642, 0.2730, 0.2806, 0.2917, 0.2996],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2618])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3000], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2618])\n",
      ">>Entradas: tensor([0.2243, 0.2465, 0.2642, 0.2730, 0.2806, 0.2917, 0.2996, 0.3000],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3057], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2801])\n",
      ">>Entradas: tensor([0.2465, 0.2642, 0.2730, 0.2806, 0.2917, 0.2996, 0.3000, 0.3057],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3374])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3240], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3374])\n",
      ">>Entradas: tensor([0.2642, 0.2730, 0.2806, 0.2917, 0.2996, 0.3000, 0.3057, 0.3240],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3482])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3370], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3482])\n",
      ">>Entradas: tensor([0.2730, 0.2806, 0.2917, 0.2996, 0.3000, 0.3057, 0.3240, 0.3370],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3362], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2806, 0.2917, 0.2996, 0.3000, 0.3057, 0.3240, 0.3370, 0.3362],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3436])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3470], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3436])\n",
      ">>Entradas: tensor([0.2917, 0.2996, 0.3000, 0.3057, 0.3240, 0.3370, 0.3362, 0.3470],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.4412])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3822], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.4412])\n",
      ">>Entradas: tensor([0.2996, 0.3000, 0.3057, 0.3240, 0.3370, 0.3362, 0.3470, 0.3822],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5211])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4293], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5211])\n",
      ">>Entradas: tensor([0.3000, 0.3057, 0.3240, 0.3370, 0.3362, 0.3470, 0.3822, 0.4293],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5833])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4865], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5833])\n",
      ">>Entradas: tensor([0.3057, 0.3240, 0.3370, 0.3362, 0.3470, 0.3822, 0.4293, 0.4865],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5431], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6089])\n",
      ">>Entradas: tensor([0.3240, 0.3370, 0.3362, 0.3470, 0.3822, 0.4293, 0.4865, 0.5431],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5980])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5843], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5980])\n",
      ">>Entradas: tensor([0.3370, 0.3362, 0.3470, 0.3822, 0.4293, 0.4865, 0.5431, 0.5843],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5945])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6153], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5945])\n",
      ">>Entradas: tensor([0.3362, 0.3470, 0.3822, 0.4293, 0.4865, 0.5431, 0.5843, 0.6153],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5985])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6434], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5985])\n",
      ">>Entradas: tensor([0.3470, 0.3822, 0.4293, 0.4865, 0.5431, 0.5843, 0.6153, 0.6434],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6214])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6514], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6214])\n",
      ">>Entradas: tensor([0.3822, 0.4293, 0.4865, 0.5431, 0.5843, 0.6153, 0.6434, 0.6514],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6631])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6927], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6631])\n",
      ">>Entradas: tensor([0.4293, 0.4865, 0.5431, 0.5843, 0.6153, 0.6434, 0.6514, 0.6927],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6929])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7297], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6929])\n",
      ">>Entradas: tensor([0.4865, 0.5431, 0.5843, 0.6153, 0.6434, 0.6514, 0.6927, 0.7297],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7107])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7578], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7107])\n",
      ">>Entradas: tensor([0.5431, 0.5843, 0.6153, 0.6434, 0.6514, 0.6927, 0.7297, 0.7578],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7217])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7778], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7217])\n",
      ">>Entradas: tensor([0.5843, 0.6153, 0.6434, 0.6514, 0.6927, 0.7297, 0.7578, 0.7778],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7259])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7900], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7259])\n",
      ">>Entradas: tensor([0.6153, 0.6434, 0.6514, 0.6927, 0.7297, 0.7578, 0.7778, 0.7900],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7404])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7956], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7404])\n",
      ">>Entradas: tensor([0.6434, 0.6514, 0.6927, 0.7297, 0.7578, 0.7778, 0.7900, 0.7956],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7652])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8045], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7652])\n",
      ">>Entradas: tensor([0.6514, 0.6927, 0.7297, 0.7578, 0.7778, 0.7900, 0.7956, 0.8045],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7448])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8068], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7448])\n",
      ">>Entradas: tensor([0.6927, 0.7297, 0.7578, 0.7778, 0.7900, 0.7956, 0.8045, 0.8068],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6792])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7865], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6792])\n",
      ">>Entradas: tensor([0.7297, 0.7578, 0.7778, 0.7900, 0.7956, 0.8045, 0.8068, 0.7865],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6746])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7651], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6746])\n",
      ">>Entradas: tensor([0.7578, 0.7778, 0.7900, 0.7956, 0.8045, 0.8068, 0.7865, 0.7651],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7602], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7309])\n",
      ">>Entradas: tensor([0.7778, 0.7900, 0.7956, 0.8045, 0.8068, 0.7865, 0.7651, 0.7602],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7467])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7558], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7467])\n",
      ">>Entradas: tensor([0.7900, 0.7956, 0.8045, 0.8068, 0.7865, 0.7651, 0.7602, 0.7558],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7219])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7433], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7219])\n",
      ">>Entradas: tensor([0.7956, 0.8045, 0.8068, 0.7865, 0.7651, 0.7602, 0.7558, 0.7433],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7199])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7345], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7199])\n",
      ">>Entradas: tensor([0.8045, 0.8068, 0.7865, 0.7651, 0.7602, 0.7558, 0.7433, 0.7345],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7407])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7310], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7407])\n",
      ">>Entradas: tensor([0.8068, 0.7865, 0.7651, 0.7602, 0.7558, 0.7433, 0.7345, 0.7310],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7362])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7222], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7362])\n",
      ">>Entradas: tensor([0.7865, 0.7651, 0.7602, 0.7558, 0.7433, 0.7345, 0.7310, 0.7222],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7083], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7065])\n",
      ">>Entradas: tensor([0.7651, 0.7602, 0.7558, 0.7433, 0.7345, 0.7310, 0.7222, 0.7083],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6979])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6993], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6979])\n",
      ">>Entradas: tensor([0.7602, 0.7558, 0.7433, 0.7345, 0.7310, 0.7222, 0.7083, 0.6993],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7106])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6960], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7106])\n",
      ">>Entradas: tensor([0.7558, 0.7433, 0.7345, 0.7310, 0.7222, 0.7083, 0.6993, 0.6960],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7210])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6955], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7210])\n",
      ">>Entradas: tensor([0.7433, 0.7345, 0.7310, 0.7222, 0.7083, 0.6993, 0.6960, 0.6955],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7291])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6994], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7291])\n",
      ">>Entradas: tensor([0.7345, 0.7310, 0.7222, 0.7083, 0.6993, 0.6960, 0.6955, 0.6994],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7674])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7158], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7674])\n",
      ">>Entradas: tensor([0.7310, 0.7222, 0.7083, 0.6993, 0.6960, 0.6955, 0.6994, 0.7158],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8359])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7486], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8359])\n",
      ">>Entradas: tensor([0.7222, 0.7083, 0.6993, 0.6960, 0.6955, 0.6994, 0.7158, 0.7486],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8510])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7784], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8510])\n",
      ">>Entradas: tensor([0.7083, 0.6993, 0.6960, 0.6955, 0.6994, 0.7158, 0.7486, 0.7784],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8127])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7931], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8127])\n",
      ">>Entradas: tensor([0.6993, 0.6960, 0.6955, 0.6994, 0.7158, 0.7486, 0.7784, 0.7931],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7864])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8002], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7864])\n",
      ">>Entradas: tensor([0.6960, 0.6955, 0.6994, 0.7158, 0.7486, 0.7784, 0.7931, 0.8002],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7720])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8019], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7720])\n",
      ">>Entradas: tensor([0.6955, 0.6994, 0.7158, 0.7486, 0.7784, 0.7931, 0.8002, 0.8019],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8123], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.6994, 0.7158, 0.7486, 0.7784, 0.7931, 0.8002, 0.8019, 0.8123],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8803])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8452], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8803])\n",
      ">>Entradas: tensor([0.7158, 0.7486, 0.7784, 0.7931, 0.8002, 0.8019, 0.8123, 0.8452],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8987])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8772], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8987])\n",
      ">>Entradas: tensor([0.7486, 0.7784, 0.7931, 0.8002, 0.8019, 0.8123, 0.8452, 0.8772],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8881], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.7784, 0.7931, 0.8002, 0.8019, 0.8123, 0.8452, 0.8772, 0.8881],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8857], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8309])\n",
      ">>Entradas: tensor([0.7931, 0.8002, 0.8019, 0.8123, 0.8452, 0.8772, 0.8881, 0.8857],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8156])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8756], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8156])\n",
      ">>Entradas: tensor([0.8002, 0.8019, 0.8123, 0.8452, 0.8772, 0.8881, 0.8857, 0.8756],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8612], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8117])\n",
      ">>Entradas: tensor([0.8019, 0.8123, 0.8452, 0.8772, 0.8881, 0.8857, 0.8756, 0.8612],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8192])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8550], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8192])\n",
      ">>Entradas: tensor([0.8123, 0.8452, 0.8772, 0.8881, 0.8857, 0.8756, 0.8612, 0.8550],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8218])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8534], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8218])\n",
      ">>Entradas: tensor([0.8452, 0.8772, 0.8881, 0.8857, 0.8756, 0.8612, 0.8550, 0.8534],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8489], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8197])\n",
      ">>Entradas: tensor([0.8772, 0.8881, 0.8857, 0.8756, 0.8612, 0.8550, 0.8534, 0.8489],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8179])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8401], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8179])\n",
      ">>Entradas: tensor([0.8881, 0.8857, 0.8756, 0.8612, 0.8550, 0.8534, 0.8489, 0.8401],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8163])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8296], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8163])\n",
      ">>Entradas: tensor([0.8857, 0.8756, 0.8612, 0.8550, 0.8534, 0.8489, 0.8401, 0.8296],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8006])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8147], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8006])\n",
      ">>Entradas: tensor([0.8756, 0.8612, 0.8550, 0.8534, 0.8489, 0.8401, 0.8296, 0.8147],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7705])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7940], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7705])\n",
      ">>Entradas: tensor([0.8612, 0.8550, 0.8534, 0.8489, 0.8401, 0.8296, 0.8147, 0.7940],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7427])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7719], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7427])\n",
      ">>Entradas: tensor([0.8550, 0.8534, 0.8489, 0.8401, 0.8296, 0.8147, 0.7940, 0.7719],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7479], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7169])\n",
      ">>Entradas: tensor([0.8534, 0.8489, 0.8401, 0.8296, 0.8147, 0.7940, 0.7719, 0.7479],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7297], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7197])\n",
      ">>Entradas: tensor([0.8489, 0.8401, 0.8296, 0.8147, 0.7940, 0.7719, 0.7479, 0.7297],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7509])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7244], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7509])\n",
      ">>Entradas: tensor([0.8401, 0.8296, 0.8147, 0.7940, 0.7719, 0.7479, 0.7297, 0.7244],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7403])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7168], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7403])\n",
      ">>Entradas: tensor([0.8296, 0.8147, 0.7940, 0.7719, 0.7479, 0.7297, 0.7244, 0.7168],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6956], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.8147, 0.7940, 0.7719, 0.7479, 0.7297, 0.7244, 0.7168, 0.6956],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6688])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6748], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6688])\n",
      ">>Entradas: tensor([0.7940, 0.7719, 0.7479, 0.7297, 0.7244, 0.7168, 0.6956, 0.6748],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6835])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6634], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6835])\n",
      ">>Entradas: tensor([0.7719, 0.7479, 0.7297, 0.7244, 0.7168, 0.6956, 0.6748, 0.6634],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6556], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.7479, 0.7297, 0.7244, 0.7168, 0.6956, 0.6748, 0.6634, 0.6556],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6815])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6509], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6815])\n",
      ">>Entradas: tensor([0.7297, 0.7244, 0.7168, 0.6956, 0.6748, 0.6634, 0.6556, 0.6509],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6893])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6540], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6893])\n",
      ">>Entradas: tensor([0.7244, 0.7168, 0.6956, 0.6748, 0.6634, 0.6556, 0.6509, 0.6540],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7111])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6630], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7111])\n",
      ">>Entradas: tensor([0.7168, 0.6956, 0.6748, 0.6634, 0.6556, 0.6509, 0.6540, 0.6630],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7349])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6757], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7349])\n",
      ">>Entradas: tensor([0.6956, 0.6748, 0.6634, 0.6556, 0.6509, 0.6540, 0.6630, 0.6757],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7608])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6954], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7608])\n",
      ">>Entradas: tensor([0.6748, 0.6634, 0.6556, 0.6509, 0.6540, 0.6630, 0.6757, 0.6954],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7711])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7172], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7711])\n",
      ">>Entradas: tensor([0.6634, 0.6556, 0.6509, 0.6540, 0.6630, 0.6757, 0.6954, 0.7172],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7660])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7348], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7660])\n",
      ">>Entradas: tensor([0.6556, 0.6509, 0.6540, 0.6630, 0.6757, 0.6954, 0.7172, 0.7348],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7483])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7456], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7483])\n",
      ">>Entradas: tensor([0.6509, 0.6540, 0.6630, 0.6757, 0.6954, 0.7172, 0.7348, 0.7456],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7182])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7472], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7182])\n",
      ">>Entradas: tensor([0.6540, 0.6630, 0.6757, 0.6954, 0.7172, 0.7348, 0.7456, 0.7472],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7459], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7089])\n",
      ">>Entradas: tensor([0.6630, 0.6757, 0.6954, 0.7172, 0.7348, 0.7456, 0.7472, 0.7459],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7204])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7485], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7204])\n",
      ">>Entradas: tensor([0.6757, 0.6954, 0.7172, 0.7348, 0.7456, 0.7472, 0.7459, 0.7485],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7706])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7649], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7706])\n",
      ">>Entradas: tensor([0.6954, 0.7172, 0.7348, 0.7456, 0.7472, 0.7459, 0.7485, 0.7649],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8595])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8029], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8595])\n",
      ">>Entradas: tensor([0.7172, 0.7348, 0.7456, 0.7472, 0.7459, 0.7485, 0.7649, 0.8029],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8443], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9065])\n",
      ">>Entradas: tensor([0.7348, 0.7456, 0.7472, 0.7459, 0.7485, 0.7649, 0.8029, 0.8443],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9119])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8764], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9119])\n",
      ">>Entradas: tensor([0.7456, 0.7472, 0.7459, 0.7485, 0.7649, 0.8029, 0.8443, 0.8764],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9043])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8983], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9043])\n",
      ">>Entradas: tensor([0.7472, 0.7459, 0.7485, 0.7649, 0.8029, 0.8443, 0.8764, 0.8983],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8839])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8859], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8839])\n",
      ">>Entradas: tensor([0.7459, 0.7485, 0.7649, 0.8029, 0.8443, 0.8764, 0.8983, 0.8859],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9032])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9038], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9032])\n",
      ">>Entradas: tensor([0.7485, 0.7649, 0.8029, 0.8443, 0.8764, 0.8983, 0.8859, 0.9038],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9623])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9359], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9623])\n",
      ">>Entradas: tensor([0.7649, 0.8029, 0.8443, 0.8764, 0.8983, 0.8859, 0.9038, 0.9359],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9821])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9673], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9821])\n",
      ">>Entradas: tensor([0.8029, 0.8443, 0.8764, 0.8983, 0.8859, 0.9038, 0.9359, 0.9673],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9624])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9861], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9624])\n",
      ">>Entradas: tensor([0.8443, 0.8764, 0.8983, 0.8859, 0.9038, 0.9359, 0.9673, 0.9861],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9303])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9898], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9303])\n",
      ">>Entradas: tensor([0.8764, 0.8983, 0.8859, 0.9038, 0.9359, 0.9673, 0.9861, 0.9898],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8855])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9712], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8855])\n",
      ">>Entradas: tensor([0.8983, 0.8859, 0.9038, 0.9359, 0.9673, 0.9861, 0.9898, 0.9712],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8597])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9429], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8597])\n",
      ">>Entradas: tensor([0.8859, 0.9038, 0.9359, 0.9673, 0.9861, 0.9898, 0.9712, 0.9429],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8529])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9228], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8529])\n",
      ">>Entradas: tensor([0.9038, 0.9359, 0.9673, 0.9861, 0.9898, 0.9712, 0.9429, 0.9228],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9095], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.9359, 0.9673, 0.9861, 0.9898, 0.9712, 0.9429, 0.9228, 0.9095],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8769])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9023], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8769])\n",
      ">>Entradas: tensor([0.9673, 0.9861, 0.9898, 0.9712, 0.9429, 0.9228, 0.9095, 0.9023],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8806])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8950], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8806])\n",
      ">>Entradas: tensor([0.9861, 0.9898, 0.9712, 0.9429, 0.9228, 0.9095, 0.9023, 0.8950],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8699])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8823], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8699])\n",
      ">>Entradas: tensor([0.9898, 0.9712, 0.9429, 0.9228, 0.9095, 0.9023, 0.8950, 0.8823],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8465])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8612], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8465])\n",
      ">>Entradas: tensor([0.9712, 0.9429, 0.9228, 0.9095, 0.9023, 0.8950, 0.8823, 0.8612],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8104])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8335], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8104])\n",
      ">>Entradas: tensor([0.9429, 0.9228, 0.9095, 0.9023, 0.8950, 0.8823, 0.8612, 0.8335],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8026])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8123], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8026])\n",
      ">>Entradas: tensor([0.9228, 0.9095, 0.9023, 0.8950, 0.8823, 0.8612, 0.8335, 0.8123],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8232])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8043], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8232])\n",
      ">>Entradas: tensor([0.9095, 0.9023, 0.8950, 0.8823, 0.8612, 0.8335, 0.8123, 0.8043],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8397])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8046], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8397])\n",
      ">>Entradas: tensor([0.9023, 0.8950, 0.8823, 0.8612, 0.8335, 0.8123, 0.8043, 0.8046],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8522])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8097], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8522])\n",
      ">>Entradas: tensor([0.8950, 0.8823, 0.8612, 0.8335, 0.8123, 0.8043, 0.8046, 0.8097],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8616])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8168], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8616])\n",
      ">>Entradas: tensor([0.8823, 0.8612, 0.8335, 0.8123, 0.8043, 0.8046, 0.8097, 0.8168],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8679])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8235], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8679])\n",
      ">>Entradas: tensor([0.8612, 0.8335, 0.8123, 0.8043, 0.8046, 0.8097, 0.8168, 0.8235],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8702])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8296], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8702])\n",
      ">>Entradas: tensor([0.8335, 0.8123, 0.8043, 0.8046, 0.8097, 0.8168, 0.8235, 0.8296],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8685])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8369], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8685])\n",
      ">>Entradas: tensor([0.8123, 0.8043, 0.8046, 0.8097, 0.8168, 0.8235, 0.8296, 0.8369],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8530])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8416], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8530])\n",
      ">>Entradas: tensor([0.8043, 0.8046, 0.8097, 0.8168, 0.8235, 0.8296, 0.8369, 0.8416],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8236])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8390], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8236])\n",
      ">>Entradas: tensor([0.8046, 0.8097, 0.8168, 0.8235, 0.8296, 0.8369, 0.8416, 0.8390],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8323], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.8097, 0.8168, 0.8235, 0.8296, 0.8369, 0.8416, 0.8390, 0.8323],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7919])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8180], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7919])\n",
      ">>Entradas: tensor([0.8168, 0.8235, 0.8296, 0.8369, 0.8416, 0.8390, 0.8323, 0.8180],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7865])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8100], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7865])\n",
      ">>Entradas: tensor([0.8235, 0.8296, 0.8369, 0.8416, 0.8390, 0.8323, 0.8180, 0.8100],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7870])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8030], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7870])\n",
      ">>Entradas: tensor([0.8296, 0.8369, 0.8416, 0.8390, 0.8323, 0.8180, 0.8100, 0.8030],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7874])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7972], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7874])\n",
      ">>Entradas: tensor([0.8369, 0.8416, 0.8390, 0.8323, 0.8180, 0.8100, 0.8030, 0.7972],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7879])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7921], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7879])\n",
      ">>Entradas: tensor([0.8416, 0.8390, 0.8323, 0.8180, 0.8100, 0.8030, 0.7972, 0.7921],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7955])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7893], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7955])\n",
      ">>Entradas: tensor([0.8390, 0.8323, 0.8180, 0.8100, 0.8030, 0.7972, 0.7921, 0.7893],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8102])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7900], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8102])\n",
      ">>Entradas: tensor([0.8323, 0.8180, 0.8100, 0.8030, 0.7972, 0.7921, 0.7893, 0.7900],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7668])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7772], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7668])\n",
      ">>Entradas: tensor([0.8180, 0.8100, 0.8030, 0.7972, 0.7921, 0.7893, 0.7900, 0.7772],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6655])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7394], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6655])\n",
      ">>Entradas: tensor([0.8100, 0.8030, 0.7972, 0.7921, 0.7893, 0.7900, 0.7772, 0.7394],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6361])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7031], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6361])\n",
      ">>Entradas: tensor([0.8030, 0.7972, 0.7921, 0.7893, 0.7900, 0.7772, 0.7394, 0.7031],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6785])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6869], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6785])\n",
      ">>Entradas: tensor([0.7972, 0.7921, 0.7893, 0.7900, 0.7772, 0.7394, 0.7031, 0.6869],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6777], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6966])\n",
      ">>Entradas: tensor([0.7921, 0.7893, 0.7900, 0.7772, 0.7394, 0.7031, 0.6869, 0.6777],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6903])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6702], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6903])\n",
      ">>Entradas: tensor([0.7893, 0.7900, 0.7772, 0.7394, 0.7031, 0.6869, 0.6777, 0.6702],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6970])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6693], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6970])\n",
      ">>Entradas: tensor([0.7900, 0.7772, 0.7394, 0.7031, 0.6869, 0.6777, 0.6702, 0.6693],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7167])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6715], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7167])\n",
      ">>Entradas: tensor([0.7772, 0.7394, 0.7031, 0.6869, 0.6777, 0.6702, 0.6693, 0.6715],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7491])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6789], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7491])\n",
      ">>Entradas: tensor([0.7394, 0.7031, 0.6869, 0.6777, 0.6702, 0.6693, 0.6715, 0.6789],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7940])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7013], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7940])\n",
      ">>Entradas: tensor([0.7031, 0.6869, 0.6777, 0.6702, 0.6693, 0.6715, 0.6789, 0.7013],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8547])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7429], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8547])\n",
      ">>Entradas: tensor([0.6869, 0.6777, 0.6702, 0.6693, 0.6715, 0.6789, 0.7013, 0.7429],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9314])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8015], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9314])\n",
      ">>Entradas: tensor([0.6777, 0.6702, 0.6693, 0.6715, 0.6789, 0.7013, 0.7429, 0.8015],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9627])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8587], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9627])\n",
      ">>Entradas: tensor([0.6702, 0.6693, 0.6715, 0.6789, 0.7013, 0.7429, 0.8015, 0.8587],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9486])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9023], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9486])\n",
      ">>Entradas: tensor([0.6693, 0.6715, 0.6789, 0.7013, 0.7429, 0.8015, 0.8587, 0.9023],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9307])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9333], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9307])\n",
      ">>Entradas: tensor([0.6715, 0.6789, 0.7013, 0.7429, 0.8015, 0.8587, 0.9023, 0.9333],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9090])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9515], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9090])\n",
      ">>Entradas: tensor([0.6789, 0.7013, 0.7429, 0.8015, 0.8587, 0.9023, 0.9333, 0.9515],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8816])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9583], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8816])\n",
      ">>Entradas: tensor([0.7013, 0.7429, 0.8015, 0.8587, 0.9023, 0.9333, 0.9515, 0.9583],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8487])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9553], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8487])\n",
      ">>Entradas: tensor([0.7429, 0.8015, 0.8587, 0.9023, 0.9333, 0.9515, 0.9583, 0.9553],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8753])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9599], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8753])\n",
      ">>Entradas: tensor([0.8015, 0.8587, 0.9023, 0.9333, 0.9515, 0.9583, 0.9553, 0.9599],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9612])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9831], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9612])\n",
      ">>Entradas: tensor([0.8587, 0.9023, 0.9333, 0.9515, 0.9583, 0.9553, 0.9599, 0.9831],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9925])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0029], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9925])\n",
      ">>Entradas: tensor([0.9023, 0.9333, 0.9515, 0.9583, 0.9553, 0.9599, 0.9831, 1.0029],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9690])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9829], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9690])\n",
      ">>Entradas: tensor([0.9333, 0.9515, 0.9583, 0.9553, 0.9599, 0.9831, 1.0029, 0.9829],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9715])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9893], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9715])\n",
      ">>Entradas: tensor([0.9515, 0.9583, 0.9553, 0.9599, 0.9831, 1.0029, 0.9829, 0.9893],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([1.])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9967], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([1.])\n",
      ">>Entradas: tensor([0.9583, 0.9553, 0.9599, 0.9831, 1.0029, 0.9829, 0.9893, 0.9967],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9918], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9801])\n",
      ">>Entradas: tensor([0.9553, 0.9599, 0.9831, 1.0029, 0.9829, 0.9893, 0.9967, 0.9918],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9717], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9117])\n",
      ">>Entradas: tensor([0.9599, 0.9831, 1.0029, 0.9829, 0.9893, 0.9967, 0.9918, 0.9717],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8911])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9550], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8911])\n",
      ">>Entradas: tensor([0.9831, 1.0029, 0.9829, 0.9893, 0.9967, 0.9918, 0.9717, 0.9550],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9181])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9110], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9181])\n",
      ">>Entradas: tensor([1.0029, 0.9829, 0.9893, 0.9967, 0.9918, 0.9717, 0.9550, 0.9110],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9450])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9128], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9450])\n",
      ">>Entradas: tensor([0.9829, 0.9893, 0.9967, 0.9918, 0.9717, 0.9550, 0.9110, 0.9128],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9718])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9254], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9718])\n",
      ">>Entradas: tensor([0.9893, 0.9967, 0.9918, 0.9717, 0.9550, 0.9110, 0.9128, 0.9254],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9829])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9387], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9829])\n",
      ">>Entradas: tensor([0.9967, 0.9918, 0.9717, 0.9550, 0.9110, 0.9128, 0.9254, 0.9387],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9783])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9464], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9783])\n",
      ">>s_original: [0.049424633383750916, 0.10789185762405396, 0.13719609379768372, 0.13733737170696259, 0.1338856965303421, 0.12684109807014465, 0.14756061136722565, 0.19604423642158508, 0.21688967943191528, 0.21009695529937744, 0.20267784595489502, 0.1946323662996292, 0.19407351315021515, 0.20100130140781403, 0.19663821160793304, 0.180984228849411, 0.16539041697978973, 0.14985674619674683, 0.15043111145496368, 0.1671135276556015, 0.20227035880088806, 0.25590160489082336, 0.29268819093704224, 0.31263017654418945, 0.31093889474868774, 0.2876143157482147, 0.28016164898872375, 0.28858086466789246, 0.28246283531188965, 0.26180753111839294, 0.2801212966442108, 0.3374040722846985, 0.3482298254966736, 0.3125985562801361, 0.34358710050582886, 0.44119545817375183, 0.521095335483551, 0.5832866430282593, 0.6089234352111816, 0.5980057120323181, 0.5945301651954651, 0.5984968543052673, 0.621354341506958, 0.6631026864051819, 0.6928724050521851, 0.7106636166572571, 0.721682071685791, 0.7259277701377869, 0.7404318451881409, 0.7651942372322083, 0.7447891235351562, 0.6792163252830505, 0.6746017932891846, 0.730945348739624, 0.7467210292816162, 0.7219287157058716, 0.7199286818504333, 0.7407209277153015, 0.7362455129623413, 0.7065023183822632, 0.6979451775550842, 0.7105739712715149, 0.7209621667861938, 0.7291097044944763, 0.7674259543418884, 0.8359109163284302, 0.8510103225708008, 0.8127241730690002, 0.7863940000534058, 0.7720199823379517, 0.8033170700073242, 0.8802852630615234, 0.8987051844596863, 0.8585767149925232, 0.8308762311935425, 0.8156037926673889, 0.8116992115974426, 0.8191625475883484, 0.8218275904655457, 0.8196942210197449, 0.817862868309021, 0.8163333535194397, 0.8005555868148804, 0.7705295085906982, 0.7426586747169495, 0.716943085193634, 0.7197051048278809, 0.7509447932243347, 0.7402781248092651, 0.6877052187919617, 0.6687695384025574, 0.683471143245697, 0.6877052187919617, 0.6814717054367065, 0.6892618536949158, 0.7110756039619446, 0.7349108457565308, 0.7607676982879639, 0.771117091178894, 0.7659589648246765, 0.7483323812484741, 0.7182371616363525, 0.708941638469696, 0.7204458117485046, 0.7706154584884644, 0.8594506978988647, 0.906541109085083, 0.9118866324424744, 0.9043355584144592, 0.8838878870010376, 0.9032153487205505, 0.9623178839683533, 0.9820588231086731, 0.96243816614151, 0.9302511811256409, 0.8854979276657104, 0.8597025871276855, 0.8528652191162109, 0.8585854768753052, 0.8768633008003235, 0.8806464076042175, 0.8699347376823425, 0.846513569355011, 0.8103827834129333, 0.8026111125946045, 0.8231984972953796, 0.8397204279899597, 0.8521769046783447, 0.8615626692771912, 0.8678776621818542, 0.8701963424682617, 0.868518590927124, 0.852988064289093, 0.8236046433448792, 0.8032509088516235, 0.7919268012046814, 0.7865023016929626, 0.7869773507118225, 0.7874362468719482, 0.7878790497779846, 0.7954531908035278, 0.8101586699485779, 0.7668473124504089, 0.665519118309021, 0.6360738277435303, 0.678511381149292, 0.6965967416763306, 0.6903298497200012, 0.6970472931861877, 0.7167490720748901, 0.7490506768226624, 0.7939522862434387, 0.8547447323799133, 0.931428074836731, 0.9627243876457214, 0.9486336708068848, 0.9307146072387695, 0.9089671969413757, 0.8816379904747009, 0.8487268090248108, 0.8752607107162476, 0.9612395763397217, 0.9925020933151245, 0.9690483212471008, 0.9715476036071777, 1.0, 0.9800636768341064, 0.9117385745048523, 0.8910858035087585, 0.9181053042411804, 0.9450165033340454, 0.9718193411827087, 0.982906699180603, 0.9782785773277283]\n",
      ">>s_pred: [-0.0718536376953125, -0.01207733154296875, 0.04053497314453125, 0.052346229553222656, 0.08013248443603516, 0.10260772705078125, 0.1110982894897461, 0.13972187042236328, 0.17800235748291016, 0.20307254791259766, 0.2183551788330078, 0.22871971130371094, 0.23346900939941406, 0.2372760772705078, 0.2364206314086914, 0.23362159729003906, 0.2231159210205078, 0.20696449279785156, 0.19235610961914062, 0.18401622772216797, 0.18594074249267578, 0.2021808624267578, 0.2243204116821289, 0.24651718139648438, 0.2641763687133789, 0.2730398178100586, 0.28061962127685547, 0.29169559478759766, 0.2995929718017578, 0.3000497817993164, 0.3056612014770508, 0.32396411895751953, 0.3370084762573242, 0.3361854553222656, 0.3469505310058594, 0.38219165802001953, 0.4293022155761719, 0.4864997863769531, 0.5430965423583984, 0.5842933654785156, 0.6153097152709961, 0.643406867980957, 0.6514244079589844, 0.6926765441894531, 0.7297449111938477, 0.7578134536743164, 0.7777767181396484, 0.7900218963623047, 0.7956266403198242, 0.804534912109375, 0.8068246841430664, 0.7864618301391602, 0.7650861740112305, 0.760249137878418, 0.7557764053344727, 0.7432975769042969, 0.7345409393310547, 0.7310285568237305, 0.7222042083740234, 0.7082538604736328, 0.6992759704589844, 0.6960344314575195, 0.6955146789550781, 0.6994428634643555, 0.7158069610595703, 0.7485885620117188, 0.7784318923950195, 0.7931299209594727, 0.8001594543457031, 0.8018894195556641, 0.8123140335083008, 0.8451910018920898, 0.8772306442260742, 0.8880958557128906, 0.8856601715087891, 0.8756122589111328, 0.8612260818481445, 0.8549718856811523, 0.8534402847290039, 0.8489217758178711, 0.8400564193725586, 0.829625129699707, 0.8146524429321289, 0.7939929962158203, 0.7719011306762695, 0.7478857040405273, 0.7296876907348633, 0.7243633270263672, 0.7168455123901367, 0.6955738067626953, 0.6747608184814453, 0.6633968353271484, 0.6556100845336914, 0.650904655456543, 0.6539907455444336, 0.6629734039306641, 0.6756687164306641, 0.6953907012939453, 0.7171878814697266, 0.7348146438598633, 0.7455825805664062, 0.7471790313720703, 0.745936393737793, 0.7484960556030273, 0.7649116516113281, 0.8028545379638672, 0.8442811965942383, 0.876408576965332, 0.8983030319213867, 0.8858661651611328, 0.9037694931030273, 0.9359302520751953, 0.9673004150390625, 0.9860591888427734, 0.9898338317871094, 0.9711732864379883, 0.9429445266723633, 0.9227752685546875, 0.9094505310058594, 0.9022893905639648, 0.8950300216674805, 0.88232421875, 0.8611917495727539, 0.8335123062133789, 0.8123445510864258, 0.8043022155761719, 0.8045730590820312, 0.809657096862793, 0.8168220520019531, 0.8235101699829102, 0.8295993804931641, 0.8368892669677734, 0.8416109085083008, 0.8389778137207031, 0.8322639465332031, 0.8180322647094727, 0.8100156784057617, 0.8029747009277344, 0.7971963882446289, 0.7921009063720703, 0.7893276214599609, 0.7900381088256836, 0.7772293090820312, 0.7394208908081055, 0.7030525207519531, 0.6868600845336914, 0.6776542663574219, 0.6702337265014648, 0.6693029403686523, 0.6714773178100586, 0.6788730621337891, 0.7012977600097656, 0.7428865432739258, 0.8015098571777344, 0.8587226867675781, 0.9023466110229492, 0.9333209991455078, 0.9514837265014648, 0.9583139419555664, 0.9552555084228516, 0.9598560333251953, 0.983067512512207, 1.0029058456420898, 0.9829368591308594, 0.9893007278442383, 0.9967317581176758, 0.9917945861816406, 0.9716663360595703, 0.9550447463989258, 0.9110050201416016, 0.9128303527832031, 0.9253616333007812, 0.9387025833129883, 0.9463872909545898]\n",
      "<<Perdida: 0.002191601786762476 epoca: 12\n",
      "---Inicio de epoca: 13--\n",
      ">>Entradas: tensor([0.0503, 0.0086, 0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203])\n",
      ">>Salida: tensor([0.0494])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0328], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.0494])\n",
      ">>Entradas: tensor([0.0086, 0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203, 0.0328],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1079])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0537], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1079])\n",
      ">>Entradas: tensor([0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203, 0.0328, 0.0537],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1372])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0809], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1372])\n",
      ">>Entradas: tensor([0.0245, 0.0327, 0.0246, 0.0205, 0.0203, 0.0328, 0.0537, 0.0809],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1373])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0992], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1373])\n",
      ">>Entradas: tensor([0.0327, 0.0246, 0.0205, 0.0203, 0.0328, 0.0537, 0.0809, 0.0992],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1339])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1114], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1339])\n",
      ">>Entradas: tensor([0.0246, 0.0205, 0.0203, 0.0328, 0.0537, 0.0809, 0.0992, 0.1114],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1268])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1199], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1268])\n",
      ">>Entradas: tensor([0.0205, 0.0203, 0.0328, 0.0537, 0.0809, 0.0992, 0.1114, 0.1199],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1476])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1335], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1476])\n",
      ">>Entradas: tensor([0.0203, 0.0328, 0.0537, 0.0809, 0.0992, 0.1114, 0.1199, 0.1335],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1960])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1588], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1960])\n",
      ">>Entradas: tensor([0.0328, 0.0537, 0.0809, 0.0992, 0.1114, 0.1199, 0.1335, 0.1588],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1841], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2169])\n",
      ">>Entradas: tensor([0.0537, 0.0809, 0.0992, 0.1114, 0.1199, 0.1335, 0.1588, 0.1841],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2101])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2013], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2101])\n",
      ">>Entradas: tensor([0.0809, 0.0992, 0.1114, 0.1199, 0.1335, 0.1588, 0.1841, 0.2013],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2027])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2125], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2027])\n",
      ">>Entradas: tensor([0.0992, 0.1114, 0.1199, 0.1335, 0.1588, 0.1841, 0.2013, 0.2125],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1946])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2172], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1946])\n",
      ">>Entradas: tensor([0.1114, 0.1199, 0.1335, 0.1588, 0.1841, 0.2013, 0.2125, 0.2172],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1941])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2191], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1941])\n",
      ">>Entradas: tensor([0.1199, 0.1335, 0.1588, 0.1841, 0.2013, 0.2125, 0.2172, 0.2191],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2010])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2231], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2010])\n",
      ">>Entradas: tensor([0.1335, 0.1588, 0.1841, 0.2013, 0.2125, 0.2172, 0.2191, 0.2231],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2252], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1966])\n",
      ">>Entradas: tensor([0.1588, 0.1841, 0.2013, 0.2125, 0.2172, 0.2191, 0.2231, 0.2252],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1810])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2193], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1810])\n",
      ">>Entradas: tensor([0.1841, 0.2013, 0.2125, 0.2172, 0.2191, 0.2231, 0.2252, 0.2193],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1654])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2102], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1654])\n",
      ">>Entradas: tensor([0.2013, 0.2125, 0.2172, 0.2191, 0.2231, 0.2252, 0.2193, 0.2102],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1499])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1963], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1499])\n",
      ">>Entradas: tensor([0.2125, 0.2172, 0.2191, 0.2231, 0.2252, 0.2193, 0.2102, 0.1963],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1504])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1834], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1504])\n",
      ">>Entradas: tensor([0.2172, 0.2191, 0.2231, 0.2252, 0.2193, 0.2102, 0.1963, 0.1834],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1671])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1775], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1671])\n",
      ">>Entradas: tensor([0.2191, 0.2231, 0.2252, 0.2193, 0.2102, 0.1963, 0.1834, 0.1775],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2023])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1826], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2023])\n",
      ">>Entradas: tensor([0.2231, 0.2252, 0.2193, 0.2102, 0.1963, 0.1834, 0.1775, 0.1826],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2559])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2008], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2559])\n",
      ">>Entradas: tensor([0.2252, 0.2193, 0.2102, 0.1963, 0.1834, 0.1775, 0.1826, 0.2008],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2927])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2242], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2927])\n",
      ">>Entradas: tensor([0.2193, 0.2102, 0.1963, 0.1834, 0.1775, 0.1826, 0.2008, 0.2242],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2476], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2102, 0.1963, 0.1834, 0.1775, 0.1826, 0.2008, 0.2242, 0.2476],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3109])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2659], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3109])\n",
      ">>Entradas: tensor([0.1963, 0.1834, 0.1775, 0.1826, 0.2008, 0.2242, 0.2476, 0.2659],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2876])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2748], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2876])\n",
      ">>Entradas: tensor([0.1834, 0.1775, 0.1826, 0.2008, 0.2242, 0.2476, 0.2659, 0.2748],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2802])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2823], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2802])\n",
      ">>Entradas: tensor([0.1775, 0.1826, 0.2008, 0.2242, 0.2476, 0.2659, 0.2748, 0.2823],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2886])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2931], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2886])\n",
      ">>Entradas: tensor([0.1826, 0.2008, 0.2242, 0.2476, 0.2659, 0.2748, 0.2823, 0.2931],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2825])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3005], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2825])\n",
      ">>Entradas: tensor([0.2008, 0.2242, 0.2476, 0.2659, 0.2748, 0.2823, 0.2931, 0.3005],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2618])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2987], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2618])\n",
      ">>Entradas: tensor([0.2242, 0.2476, 0.2659, 0.2748, 0.2823, 0.2931, 0.3005, 0.2987],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3046], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2801])\n",
      ">>Entradas: tensor([0.2476, 0.2659, 0.2748, 0.2823, 0.2931, 0.3005, 0.2987, 0.3046],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3374])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3226], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3374])\n",
      ">>Entradas: tensor([0.2659, 0.2748, 0.2823, 0.2931, 0.3005, 0.2987, 0.3046, 0.3226],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3482])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3348], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3482])\n",
      ">>Entradas: tensor([0.2748, 0.2823, 0.2931, 0.3005, 0.2987, 0.3046, 0.3226, 0.3348],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3339], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2823, 0.2931, 0.3005, 0.2987, 0.3046, 0.3226, 0.3348, 0.3339],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3436])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3450], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3436])\n",
      ">>Entradas: tensor([0.2931, 0.3005, 0.2987, 0.3046, 0.3226, 0.3348, 0.3339, 0.3450],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.4412])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([5.7737], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.4412])\n",
      "ERROR: la modificacion de los pesos di√≥ un error mayor: 28.4356632232666, se regresa al estado anterior de la red\n",
      ">>Entradas: tensor([0.3005, 0.2987, 0.3046, 0.3226, 0.3348, 0.3339, 0.3450, 0.3527],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5211])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4080], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5211])\n",
      ">>Entradas: tensor([0.2987, 0.3046, 0.3226, 0.3348, 0.3339, 0.3450, 0.3527, 0.4080],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5833])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4761], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5833])\n",
      ">>Entradas: tensor([0.3046, 0.3226, 0.3348, 0.3339, 0.3450, 0.3527, 0.4080, 0.4761],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5292], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6089])\n",
      ">>Entradas: tensor([0.3226, 0.3348, 0.3339, 0.3450, 0.3527, 0.4080, 0.4761, 0.5292],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5980])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5706], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5980])\n",
      ">>Entradas: tensor([0.3348, 0.3339, 0.3450, 0.3527, 0.4080, 0.4761, 0.5292, 0.5706],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5945])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6035], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5945])\n",
      ">>Entradas: tensor([0.3339, 0.3450, 0.3527, 0.4080, 0.4761, 0.5292, 0.5706, 0.6035],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5985])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6271], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5985])\n",
      ">>Entradas: tensor([0.3450, 0.3527, 0.4080, 0.4761, 0.5292, 0.5706, 0.6035, 0.6271],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6214])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6542], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6214])\n",
      ">>Entradas: tensor([0.3527, 0.4080, 0.4761, 0.5292, 0.5706, 0.6035, 0.6271, 0.6542],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6631])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6921], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6631])\n",
      ">>Entradas: tensor([0.4080, 0.4761, 0.5292, 0.5706, 0.6035, 0.6271, 0.6542, 0.6921],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6929])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7302], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6929])\n",
      ">>Entradas: tensor([0.4761, 0.5292, 0.5706, 0.6035, 0.6271, 0.6542, 0.6921, 0.7302],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7107])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7582], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7107])\n",
      ">>Entradas: tensor([0.5292, 0.5706, 0.6035, 0.6271, 0.6542, 0.6921, 0.7302, 0.7582],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7217])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7756], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7217])\n",
      ">>Entradas: tensor([0.5706, 0.6035, 0.6271, 0.6542, 0.6921, 0.7302, 0.7582, 0.7756],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7259])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7866], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7259])\n",
      ">>Entradas: tensor([0.6035, 0.6271, 0.6542, 0.6921, 0.7302, 0.7582, 0.7756, 0.7866],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7404])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7927], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7404])\n",
      ">>Entradas: tensor([0.6271, 0.6542, 0.6921, 0.7302, 0.7582, 0.7756, 0.7866, 0.7927],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7652])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8039], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7652])\n",
      ">>Entradas: tensor([0.6542, 0.6921, 0.7302, 0.7582, 0.7756, 0.7866, 0.7927, 0.8039],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7448])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8056], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7448])\n",
      ">>Entradas: tensor([0.6921, 0.7302, 0.7582, 0.7756, 0.7866, 0.7927, 0.8039, 0.8056],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6792])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7851], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6792])\n",
      ">>Entradas: tensor([0.7302, 0.7582, 0.7756, 0.7866, 0.7927, 0.8039, 0.8056, 0.7851],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6746])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7636], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6746])\n",
      ">>Entradas: tensor([0.7582, 0.7756, 0.7866, 0.7927, 0.8039, 0.8056, 0.7851, 0.7636],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7438], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7309])\n",
      ">>Entradas: tensor([0.7756, 0.7866, 0.7927, 0.8039, 0.8056, 0.7851, 0.7636, 0.7438],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7467])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7431], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7467])\n",
      ">>Entradas: tensor([0.7866, 0.7927, 0.8039, 0.8056, 0.7851, 0.7636, 0.7438, 0.7431],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7219])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7337], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7219])\n",
      ">>Entradas: tensor([0.7927, 0.8039, 0.8056, 0.7851, 0.7636, 0.7438, 0.7431, 0.7337],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7199])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7277], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7199])\n",
      ">>Entradas: tensor([0.8039, 0.8056, 0.7851, 0.7636, 0.7438, 0.7431, 0.7337, 0.7277],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7407])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7265], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7407])\n",
      ">>Entradas: tensor([0.8056, 0.7851, 0.7636, 0.7438, 0.7431, 0.7337, 0.7277, 0.7265],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7362])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7204], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7362])\n",
      ">>Entradas: tensor([0.7851, 0.7636, 0.7438, 0.7431, 0.7337, 0.7277, 0.7265, 0.7204],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7066], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7065])\n",
      ">>Entradas: tensor([0.7636, 0.7438, 0.7431, 0.7337, 0.7277, 0.7265, 0.7204, 0.7066],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6979])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6978], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6979])\n",
      ">>Entradas: tensor([0.7438, 0.7431, 0.7337, 0.7277, 0.7265, 0.7204, 0.7066, 0.6978],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7106])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6971], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7106])\n",
      ">>Entradas: tensor([0.7431, 0.7337, 0.7277, 0.7265, 0.7204, 0.7066, 0.6978, 0.6971],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7210])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6984], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7210])\n",
      ">>Entradas: tensor([0.7337, 0.7277, 0.7265, 0.7204, 0.7066, 0.6978, 0.6971, 0.6984],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7291])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7036], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7291])\n",
      ">>Entradas: tensor([0.7277, 0.7265, 0.7204, 0.7066, 0.6978, 0.6971, 0.6984, 0.7036],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7674])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7209], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7674])\n",
      ">>Entradas: tensor([0.7265, 0.7204, 0.7066, 0.6978, 0.6971, 0.6984, 0.7036, 0.7209],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8359])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7535], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8359])\n",
      ">>Entradas: tensor([0.7204, 0.7066, 0.6978, 0.6971, 0.6984, 0.7036, 0.7209, 0.7535],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8510])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7821], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8510])\n",
      ">>Entradas: tensor([0.7066, 0.6978, 0.6971, 0.6984, 0.7036, 0.7209, 0.7535, 0.7821],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8127])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7957], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8127])\n",
      ">>Entradas: tensor([0.6978, 0.6971, 0.6984, 0.7036, 0.7209, 0.7535, 0.7821, 0.7957],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7864])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8017], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7864])\n",
      ">>Entradas: tensor([0.6971, 0.6984, 0.7036, 0.7209, 0.7535, 0.7821, 0.7957, 0.8017],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7720])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8019], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7720])\n",
      ">>Entradas: tensor([0.6984, 0.7036, 0.7209, 0.7535, 0.7821, 0.7957, 0.8017, 0.8019],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8108], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.7036, 0.7209, 0.7535, 0.7821, 0.7957, 0.8017, 0.8019, 0.8108],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8803])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8424], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8803])\n",
      ">>Entradas: tensor([0.7209, 0.7535, 0.7821, 0.7957, 0.8017, 0.8019, 0.8108, 0.8424],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8987])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8730], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8987])\n",
      ">>Entradas: tensor([0.7535, 0.7821, 0.7957, 0.8017, 0.8019, 0.8108, 0.8424, 0.8730],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8815], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.7821, 0.7957, 0.8017, 0.8019, 0.8108, 0.8424, 0.8730, 0.8815],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8774], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8309])\n",
      ">>Entradas: tensor([0.7957, 0.8017, 0.8019, 0.8108, 0.8424, 0.8730, 0.8815, 0.8774],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8156])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8664], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8156])\n",
      ">>Entradas: tensor([0.8017, 0.8019, 0.8108, 0.8424, 0.8730, 0.8815, 0.8774, 0.8664],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8538], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8117])\n",
      ">>Entradas: tensor([0.8019, 0.8108, 0.8424, 0.8730, 0.8815, 0.8774, 0.8664, 0.8538],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8192])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8484], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8192])\n",
      ">>Entradas: tensor([0.8108, 0.8424, 0.8730, 0.8815, 0.8774, 0.8664, 0.8538, 0.8484],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8218])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8483], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8218])\n",
      ">>Entradas: tensor([0.8424, 0.8730, 0.8815, 0.8774, 0.8664, 0.8538, 0.8484, 0.8483],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8448], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8197])\n",
      ">>Entradas: tensor([0.8730, 0.8815, 0.8774, 0.8664, 0.8538, 0.8484, 0.8483, 0.8448],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8179])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8366], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8179])\n",
      ">>Entradas: tensor([0.8815, 0.8774, 0.8664, 0.8538, 0.8484, 0.8483, 0.8448, 0.8366],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8163])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8273], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8163])\n",
      ">>Entradas: tensor([0.8774, 0.8664, 0.8538, 0.8484, 0.8483, 0.8448, 0.8366, 0.8273],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8006])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8138], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8006])\n",
      ">>Entradas: tensor([0.8664, 0.8538, 0.8484, 0.8483, 0.8448, 0.8366, 0.8273, 0.8138],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7705])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7949], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7705])\n",
      ">>Entradas: tensor([0.8538, 0.8484, 0.8483, 0.8448, 0.8366, 0.8273, 0.8138, 0.7949],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7427])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7638], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7427])\n",
      ">>Entradas: tensor([0.8484, 0.8483, 0.8448, 0.8366, 0.8273, 0.8138, 0.7949, 0.7638],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7442], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7169])\n",
      ">>Entradas: tensor([0.8483, 0.8448, 0.8366, 0.8273, 0.8138, 0.7949, 0.7638, 0.7442],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7286], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7197])\n",
      ">>Entradas: tensor([0.8448, 0.8366, 0.8273, 0.8138, 0.7949, 0.7638, 0.7442, 0.7286],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7509])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7252], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7509])\n",
      ">>Entradas: tensor([0.8366, 0.8273, 0.8138, 0.7949, 0.7638, 0.7442, 0.7286, 0.7252],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7403])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7203], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7403])\n",
      ">>Entradas: tensor([0.8273, 0.8138, 0.7949, 0.7638, 0.7442, 0.7286, 0.7252, 0.7203],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7013], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.8138, 0.7949, 0.7638, 0.7442, 0.7286, 0.7252, 0.7203, 0.7013],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6688])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6806], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6688])\n",
      ">>Entradas: tensor([0.7949, 0.7638, 0.7442, 0.7286, 0.7252, 0.7203, 0.7013, 0.6806],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6835])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6688], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6835])\n",
      ">>Entradas: tensor([0.7638, 0.7442, 0.7286, 0.7252, 0.7203, 0.7013, 0.6806, 0.6688],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6628], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.7442, 0.7286, 0.7252, 0.7203, 0.7013, 0.6806, 0.6688, 0.6628],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6815])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6590], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6815])\n",
      ">>Entradas: tensor([0.7286, 0.7252, 0.7203, 0.7013, 0.6806, 0.6688, 0.6628, 0.6590],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6893])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6625], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6893])\n",
      ">>Entradas: tensor([0.7252, 0.7203, 0.7013, 0.6806, 0.6688, 0.6628, 0.6590, 0.6625],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7111])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6714], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7111])\n",
      ">>Entradas: tensor([0.7203, 0.7013, 0.6806, 0.6688, 0.6628, 0.6590, 0.6625, 0.6714],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7349])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6832], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7349])\n",
      ">>Entradas: tensor([0.7013, 0.6806, 0.6688, 0.6628, 0.6590, 0.6625, 0.6714, 0.6832],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7608])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7015], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7608])\n",
      ">>Entradas: tensor([0.6806, 0.6688, 0.6628, 0.6590, 0.6625, 0.6714, 0.6832, 0.7015],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7711])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7217], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7711])\n",
      ">>Entradas: tensor([0.6688, 0.6628, 0.6590, 0.6625, 0.6714, 0.6832, 0.7015, 0.7217],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7660])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7376], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7660])\n",
      ">>Entradas: tensor([0.6628, 0.6590, 0.6625, 0.6714, 0.6832, 0.7015, 0.7217, 0.7376],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7483])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7462], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7483])\n",
      ">>Entradas: tensor([0.6590, 0.6625, 0.6714, 0.6832, 0.7015, 0.7217, 0.7376, 0.7462],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7182])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7457], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7182])\n",
      ">>Entradas: tensor([0.6625, 0.6714, 0.6832, 0.7015, 0.7217, 0.7376, 0.7462, 0.7457],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7417], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7089])\n",
      ">>Entradas: tensor([0.6714, 0.6832, 0.7015, 0.7217, 0.7376, 0.7462, 0.7457, 0.7417],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7204])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7428], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7204])\n",
      ">>Entradas: tensor([0.6832, 0.7015, 0.7217, 0.7376, 0.7462, 0.7457, 0.7417, 0.7428],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7706])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7584], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7706])\n",
      ">>Entradas: tensor([0.7015, 0.7217, 0.7376, 0.7462, 0.7457, 0.7417, 0.7428, 0.7584],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8595])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7958], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8595])\n",
      ">>Entradas: tensor([0.7217, 0.7376, 0.7462, 0.7457, 0.7417, 0.7428, 0.7584, 0.7958],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8367], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9065])\n",
      ">>Entradas: tensor([0.7376, 0.7462, 0.7457, 0.7417, 0.7428, 0.7584, 0.7958, 0.8367],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9119])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8682], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9119])\n",
      ">>Entradas: tensor([0.7462, 0.7457, 0.7417, 0.7428, 0.7584, 0.7958, 0.8367, 0.8682],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9043])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8892], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9043])\n",
      ">>Entradas: tensor([0.7457, 0.7417, 0.7428, 0.7584, 0.7958, 0.8367, 0.8682, 0.8892],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8839])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8983], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8839])\n",
      ">>Entradas: tensor([0.7417, 0.7428, 0.7584, 0.7958, 0.8367, 0.8682, 0.8892, 0.8983],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9032])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9109], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9032])\n",
      ">>Entradas: tensor([0.7428, 0.7584, 0.7958, 0.8367, 0.8682, 0.8892, 0.8983, 0.9109],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9623])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9406], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9623])\n",
      ">>Entradas: tensor([0.7584, 0.7958, 0.8367, 0.8682, 0.8892, 0.8983, 0.9109, 0.9406],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9821])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9709], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9821])\n",
      ">>Entradas: tensor([0.7958, 0.8367, 0.8682, 0.8892, 0.8983, 0.9109, 0.9406, 0.9709],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9624])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9868], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9624])\n",
      ">>Entradas: tensor([0.8367, 0.8682, 0.8892, 0.8983, 0.9109, 0.9406, 0.9709, 0.9868],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9303])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9865], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9303])\n",
      ">>Entradas: tensor([0.8682, 0.8892, 0.8983, 0.9109, 0.9406, 0.9709, 0.9868, 0.9865],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8855])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9683], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8855])\n",
      ">>Entradas: tensor([0.8892, 0.8983, 0.9109, 0.9406, 0.9709, 0.9868, 0.9865, 0.9683],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8597])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9420], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8597])\n",
      ">>Entradas: tensor([0.8983, 0.9109, 0.9406, 0.9709, 0.9868, 0.9865, 0.9683, 0.9420],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8529])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9195], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8529])\n",
      ">>Entradas: tensor([0.9109, 0.9406, 0.9709, 0.9868, 0.9865, 0.9683, 0.9420, 0.9195],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9056], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.9406, 0.9709, 0.9868, 0.9865, 0.9683, 0.9420, 0.9195, 0.9056],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8769])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8988], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8769])\n",
      ">>Entradas: tensor([0.9709, 0.9868, 0.9865, 0.9683, 0.9420, 0.9195, 0.9056, 0.8988],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8806])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8913], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8806])\n",
      ">>Entradas: tensor([0.9868, 0.9865, 0.9683, 0.9420, 0.9195, 0.9056, 0.8988, 0.8913],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8699])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8791], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8699])\n",
      ">>Entradas: tensor([0.9865, 0.9683, 0.9420, 0.9195, 0.9056, 0.8988, 0.8913, 0.8791],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8465])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8600], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8465])\n",
      ">>Entradas: tensor([0.9683, 0.9420, 0.9195, 0.9056, 0.8988, 0.8913, 0.8791, 0.8600],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8104])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8342], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8104])\n",
      ">>Entradas: tensor([0.9420, 0.9195, 0.9056, 0.8988, 0.8913, 0.8791, 0.8600, 0.8342],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8026])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8142], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8026])\n",
      ">>Entradas: tensor([0.9195, 0.9056, 0.8988, 0.8913, 0.8791, 0.8600, 0.8342, 0.8142],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8232])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8075], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8232])\n",
      ">>Entradas: tensor([0.9056, 0.8988, 0.8913, 0.8791, 0.8600, 0.8342, 0.8142, 0.8075],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8397])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8089], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8397])\n",
      ">>Entradas: tensor([0.8988, 0.8913, 0.8791, 0.8600, 0.8342, 0.8142, 0.8075, 0.8089],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8522])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8144], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8522])\n",
      ">>Entradas: tensor([0.8913, 0.8791, 0.8600, 0.8342, 0.8142, 0.8075, 0.8089, 0.8144],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8616])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8219], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8616])\n",
      ">>Entradas: tensor([0.8791, 0.8600, 0.8342, 0.8142, 0.8075, 0.8089, 0.8144, 0.8219],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8679])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8289], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8679])\n",
      ">>Entradas: tensor([0.8600, 0.8342, 0.8142, 0.8075, 0.8089, 0.8144, 0.8219, 0.8289],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8702])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8349], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8702])\n",
      ">>Entradas: tensor([0.8342, 0.8142, 0.8075, 0.8089, 0.8144, 0.8219, 0.8289, 0.8349],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8685])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8418], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8685])\n",
      ">>Entradas: tensor([0.8142, 0.8075, 0.8089, 0.8144, 0.8219, 0.8289, 0.8349, 0.8418],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8530])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8459], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8530])\n",
      ">>Entradas: tensor([0.8075, 0.8089, 0.8144, 0.8219, 0.8289, 0.8349, 0.8418, 0.8459],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8236])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8421], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8236])\n",
      ">>Entradas: tensor([0.8089, 0.8144, 0.8219, 0.8289, 0.8349, 0.8418, 0.8459, 0.8421],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8336], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.8144, 0.8219, 0.8289, 0.8349, 0.8418, 0.8459, 0.8421, 0.8336],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7919])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8239], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7919])\n",
      ">>Entradas: tensor([0.8219, 0.8289, 0.8349, 0.8418, 0.8459, 0.8421, 0.8336, 0.8239],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7865])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8137], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7865])\n",
      ">>Entradas: tensor([0.8289, 0.8349, 0.8418, 0.8459, 0.8421, 0.8336, 0.8239, 0.8137],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7870])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8055], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7870])\n",
      ">>Entradas: tensor([0.8349, 0.8418, 0.8459, 0.8421, 0.8336, 0.8239, 0.8137, 0.8055],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7874])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7992], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7874])\n",
      ">>Entradas: tensor([0.8418, 0.8459, 0.8421, 0.8336, 0.8239, 0.8137, 0.8055, 0.7992],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7879])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7934], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7879])\n",
      ">>Entradas: tensor([0.8459, 0.8421, 0.8336, 0.8239, 0.8137, 0.8055, 0.7992, 0.7934],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7955])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7898], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7955])\n",
      ">>Entradas: tensor([0.8421, 0.8336, 0.8239, 0.8137, 0.8055, 0.7992, 0.7934, 0.7898],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8102])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7923], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8102])\n",
      ">>Entradas: tensor([0.8336, 0.8239, 0.8137, 0.8055, 0.7992, 0.7934, 0.7898, 0.7923],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7668])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7799], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7668])\n",
      ">>Entradas: tensor([0.8239, 0.8137, 0.8055, 0.7992, 0.7934, 0.7898, 0.7923, 0.7799],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6655])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7415], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6655])\n",
      ">>Entradas: tensor([0.8137, 0.8055, 0.7992, 0.7934, 0.7898, 0.7923, 0.7799, 0.7415],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6361])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7050], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6361])\n",
      ">>Entradas: tensor([0.8055, 0.7992, 0.7934, 0.7898, 0.7923, 0.7799, 0.7415, 0.7050],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6785])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6890], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6785])\n",
      ">>Entradas: tensor([0.7992, 0.7934, 0.7898, 0.7923, 0.7799, 0.7415, 0.7050, 0.6890],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6802], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6966])\n",
      ">>Entradas: tensor([0.7934, 0.7898, 0.7923, 0.7799, 0.7415, 0.7050, 0.6890, 0.6802],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6903])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6736], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6903])\n",
      ">>Entradas: tensor([0.7898, 0.7923, 0.7799, 0.7415, 0.7050, 0.6890, 0.6802, 0.6736],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6970])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6735], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6970])\n",
      ">>Entradas: tensor([0.7923, 0.7799, 0.7415, 0.7050, 0.6890, 0.6802, 0.6736, 0.6735],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7167])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6756], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7167])\n",
      ">>Entradas: tensor([0.7799, 0.7415, 0.7050, 0.6890, 0.6802, 0.6736, 0.6735, 0.6756],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7491])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6829], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7491])\n",
      ">>Entradas: tensor([0.7415, 0.7050, 0.6890, 0.6802, 0.6736, 0.6735, 0.6756, 0.6829],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7940])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7058], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7940])\n",
      ">>Entradas: tensor([0.7050, 0.6890, 0.6802, 0.6736, 0.6735, 0.6756, 0.6829, 0.7058],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8547])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7473], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8547])\n",
      ">>Entradas: tensor([0.6890, 0.6802, 0.6736, 0.6735, 0.6756, 0.6829, 0.7058, 0.7473],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9314])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8050], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9314])\n",
      ">>Entradas: tensor([0.6802, 0.6736, 0.6735, 0.6756, 0.6829, 0.7058, 0.7473, 0.8050],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9627])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8609], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9627])\n",
      ">>Entradas: tensor([0.6736, 0.6735, 0.6756, 0.6829, 0.7058, 0.7473, 0.8050, 0.8609],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9486])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9025], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9486])\n",
      ">>Entradas: tensor([0.6735, 0.6756, 0.6829, 0.7058, 0.7473, 0.8050, 0.8609, 0.9025],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9307])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9306], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9307])\n",
      ">>Entradas: tensor([0.6756, 0.6829, 0.7058, 0.7473, 0.8050, 0.8609, 0.9025, 0.9306],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9090])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9314], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9090])\n",
      ">>Entradas: tensor([0.6829, 0.7058, 0.7473, 0.8050, 0.8609, 0.9025, 0.9306, 0.9314],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8816])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9412], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8816])\n",
      ">>Entradas: tensor([0.7058, 0.7473, 0.8050, 0.8609, 0.9025, 0.9306, 0.9314, 0.9412],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8487])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9394], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8487])\n",
      ">>Entradas: tensor([0.7473, 0.8050, 0.8609, 0.9025, 0.9306, 0.9314, 0.9412, 0.9394],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8753])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9446], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8753])\n",
      ">>Entradas: tensor([0.8050, 0.8609, 0.9025, 0.9306, 0.9314, 0.9412, 0.9394, 0.9446],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9612])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9694], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9612])\n",
      ">>Entradas: tensor([0.8609, 0.9025, 0.9306, 0.9314, 0.9412, 0.9394, 0.9446, 0.9694],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9925])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9915], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9925])\n",
      ">>Entradas: tensor([0.9025, 0.9306, 0.9314, 0.9412, 0.9394, 0.9446, 0.9694, 0.9915],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9690])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9935], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9690])\n",
      ">>Entradas: tensor([0.9306, 0.9314, 0.9412, 0.9394, 0.9446, 0.9694, 0.9915, 0.9935],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9715])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9938], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9715])\n",
      ">>Entradas: tensor([0.9314, 0.9412, 0.9394, 0.9446, 0.9694, 0.9915, 0.9935, 0.9938],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([1.])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0017], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([1.])\n",
      ">>Entradas: tensor([0.9412, 0.9394, 0.9446, 0.9694, 0.9915, 0.9935, 0.9938, 1.0017],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9975], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9801])\n",
      ">>Entradas: tensor([0.9394, 0.9446, 0.9694, 0.9915, 0.9935, 0.9938, 1.0017, 0.9975],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9769], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9117])\n",
      ">>Entradas: tensor([0.9446, 0.9694, 0.9915, 0.9935, 0.9938, 1.0017, 0.9975, 0.9769],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8911])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9593], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8911])\n",
      ">>Entradas: tensor([0.9694, 0.9915, 0.9935, 0.9938, 1.0017, 0.9975, 0.9769, 0.9593],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9181])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9495], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9181])\n",
      ">>Entradas: tensor([0.9915, 0.9935, 0.9938, 1.0017, 0.9975, 0.9769, 0.9593, 0.9495],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9450])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9443], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9450])\n",
      ">>Entradas: tensor([0.9935, 0.9938, 1.0017, 0.9975, 0.9769, 0.9593, 0.9495, 0.9443],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9718])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9495], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9718])\n",
      ">>Entradas: tensor([0.9938, 1.0017, 0.9975, 0.9769, 0.9593, 0.9495, 0.9443, 0.9495],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9829])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9582], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9829])\n",
      ">>Entradas: tensor([1.0017, 0.9975, 0.9769, 0.9593, 0.9495, 0.9443, 0.9495, 0.9582],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9783])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9602], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9783])\n",
      ">>s_original: [0.049424633383750916, 0.10789185762405396, 0.13719609379768372, 0.13733737170696259, 0.1338856965303421, 0.12684109807014465, 0.14756061136722565, 0.19604423642158508, 0.21688967943191528, 0.21009695529937744, 0.20267784595489502, 0.1946323662996292, 0.19407351315021515, 0.20100130140781403, 0.19663821160793304, 0.180984228849411, 0.16539041697978973, 0.14985674619674683, 0.15043111145496368, 0.1671135276556015, 0.20227035880088806, 0.25590160489082336, 0.29268819093704224, 0.31263017654418945, 0.31093889474868774, 0.2876143157482147, 0.28016164898872375, 0.28858086466789246, 0.28246283531188965, 0.26180753111839294, 0.2801212966442108, 0.3374040722846985, 0.3482298254966736, 0.3125985562801361, 0.34358710050582886, 0.44119545817375183, 0.521095335483551, 0.5832866430282593, 0.6089234352111816, 0.5980057120323181, 0.5945301651954651, 0.5984968543052673, 0.621354341506958, 0.6631026864051819, 0.6928724050521851, 0.7106636166572571, 0.721682071685791, 0.7259277701377869, 0.7404318451881409, 0.7651942372322083, 0.7447891235351562, 0.6792163252830505, 0.6746017932891846, 0.730945348739624, 0.7467210292816162, 0.7219287157058716, 0.7199286818504333, 0.7407209277153015, 0.7362455129623413, 0.7065023183822632, 0.6979451775550842, 0.7105739712715149, 0.7209621667861938, 0.7291097044944763, 0.7674259543418884, 0.8359109163284302, 0.8510103225708008, 0.8127241730690002, 0.7863940000534058, 0.7720199823379517, 0.8033170700073242, 0.8802852630615234, 0.8987051844596863, 0.8585767149925232, 0.8308762311935425, 0.8156037926673889, 0.8116992115974426, 0.8191625475883484, 0.8218275904655457, 0.8196942210197449, 0.817862868309021, 0.8163333535194397, 0.8005555868148804, 0.7705295085906982, 0.7426586747169495, 0.716943085193634, 0.7197051048278809, 0.7509447932243347, 0.7402781248092651, 0.6877052187919617, 0.6687695384025574, 0.683471143245697, 0.6877052187919617, 0.6814717054367065, 0.6892618536949158, 0.7110756039619446, 0.7349108457565308, 0.7607676982879639, 0.771117091178894, 0.7659589648246765, 0.7483323812484741, 0.7182371616363525, 0.708941638469696, 0.7204458117485046, 0.7706154584884644, 0.8594506978988647, 0.906541109085083, 0.9118866324424744, 0.9043355584144592, 0.8838878870010376, 0.9032153487205505, 0.9623178839683533, 0.9820588231086731, 0.96243816614151, 0.9302511811256409, 0.8854979276657104, 0.8597025871276855, 0.8528652191162109, 0.8585854768753052, 0.8768633008003235, 0.8806464076042175, 0.8699347376823425, 0.846513569355011, 0.8103827834129333, 0.8026111125946045, 0.8231984972953796, 0.8397204279899597, 0.8521769046783447, 0.8615626692771912, 0.8678776621818542, 0.8701963424682617, 0.868518590927124, 0.852988064289093, 0.8236046433448792, 0.8032509088516235, 0.7919268012046814, 0.7865023016929626, 0.7869773507118225, 0.7874362468719482, 0.7878790497779846, 0.7954531908035278, 0.8101586699485779, 0.7668473124504089, 0.665519118309021, 0.6360738277435303, 0.678511381149292, 0.6965967416763306, 0.6903298497200012, 0.6970472931861877, 0.7167490720748901, 0.7490506768226624, 0.7939522862434387, 0.8547447323799133, 0.931428074836731, 0.9627243876457214, 0.9486336708068848, 0.9307146072387695, 0.9089671969413757, 0.8816379904747009, 0.8487268090248108, 0.8752607107162476, 0.9612395763397217, 0.9925020933151245, 0.9690483212471008, 0.9715476036071777, 1.0, 0.9800636768341064, 0.9117385745048523, 0.8910858035087585, 0.9181053042411804, 0.9450165033340454, 0.9718193411827087, 0.982906699180603, 0.9782785773277283]\n",
      ">>s_pred: [0.03282356262207031, 0.053668975830078125, 0.08094024658203125, 0.09918403625488281, 0.11135673522949219, 0.11990833282470703, 0.1334676742553711, 0.15877914428710938, 0.18409252166748047, 0.2012929916381836, 0.21248435974121094, 0.2171792984008789, 0.21907424926757812, 0.2231273651123047, 0.22519588470458984, 0.2193155288696289, 0.21024227142333984, 0.19633769989013672, 0.18343544006347656, 0.17749691009521484, 0.18258953094482422, 0.20084476470947266, 0.22419166564941406, 0.24761199951171875, 0.26592254638671875, 0.27480220794677734, 0.2822723388671875, 0.2930622100830078, 0.30046653747558594, 0.2986583709716797, 0.30464839935302734, 0.32262706756591797, 0.3348379135131836, 0.33393001556396484, 0.3449726104736328, 0.3526744842529297, 0.40798091888427734, 0.47605323791503906, 0.5292339324951172, 0.570622444152832, 0.6035280227661133, 0.6270523071289062, 0.6541643142700195, 0.6921377182006836, 0.7302188873291016, 0.7581653594970703, 0.7755546569824219, 0.7866420745849609, 0.7926511764526367, 0.8039283752441406, 0.8056488037109375, 0.7850627899169922, 0.7635526657104492, 0.7437553405761719, 0.7430763244628906, 0.733708381652832, 0.7277116775512695, 0.7264900207519531, 0.7203998565673828, 0.7066431045532227, 0.6977777481079102, 0.6971292495727539, 0.6983566284179688, 0.7035837173461914, 0.72088623046875, 0.7534799575805664, 0.7820596694946289, 0.7957077026367188, 0.8017292022705078, 0.8019418716430664, 0.8108177185058594, 0.8424253463745117, 0.8730106353759766, 0.8815412521362305, 0.8774223327636719, 0.866424560546875, 0.8537511825561523, 0.848388671875, 0.8482532501220703, 0.8447771072387695, 0.8366489410400391, 0.8273487091064453, 0.8138236999511719, 0.7948646545410156, 0.7637853622436523, 0.7441978454589844, 0.7285909652709961, 0.7251834869384766, 0.7203216552734375, 0.7013435363769531, 0.680628776550293, 0.6688394546508789, 0.6627559661865234, 0.6589775085449219, 0.6625156402587891, 0.6713829040527344, 0.6831541061401367, 0.7014646530151367, 0.7217197418212891, 0.7375717163085938, 0.7462310791015625, 0.7457332611083984, 0.7417411804199219, 0.7428426742553711, 0.7583751678466797, 0.7957649230957031, 0.8366584777832031, 0.8681735992431641, 0.8891801834106445, 0.8982868194580078, 0.9109468460083008, 0.9405574798583984, 0.970916748046875, 0.9868392944335938, 0.9865083694458008, 0.9683237075805664, 0.9420280456542969, 0.9195194244384766, 0.9056129455566406, 0.898777961730957, 0.8912677764892578, 0.8791007995605469, 0.8599929809570312, 0.8342399597167969, 0.8142127990722656, 0.8075122833251953, 0.808863639831543, 0.814387321472168, 0.8218908309936523, 0.8288764953613281, 0.834904670715332, 0.8418436050415039, 0.8459053039550781, 0.8421249389648438, 0.8335809707641602, 0.8239202499389648, 0.8137426376342773, 0.8054790496826172, 0.7992134094238281, 0.7934427261352539, 0.7897853851318359, 0.7922849655151367, 0.7798824310302734, 0.7414684295654297, 0.70501708984375, 0.6890029907226562, 0.6801919937133789, 0.6735973358154297, 0.6735448837280273, 0.6756277084350586, 0.6829357147216797, 0.7057685852050781, 0.7472963333129883, 0.8049898147583008, 0.8609094619750977, 0.9025468826293945, 0.9306259155273438, 0.9314031600952148, 0.9412136077880859, 0.9393949508666992, 0.9446477890014648, 0.9693622589111328, 0.9915056228637695, 0.9935245513916016, 0.9937705993652344, 1.0017175674438477, 0.9974546432495117, 0.9769001007080078, 0.9592657089233398, 0.9494867324829102, 0.9442729949951172, 0.949462890625, 0.9581680297851562, 0.9601631164550781]\n",
      "<<Perdida: 0.0017844416433945298 epoca: 13\n",
      "---Inicio de epoca: 14--\n",
      ">>Entradas: tensor([0.0503, 0.0086, 0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203])\n",
      ">>Salida: tensor([0.0494])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0551], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.0494])\n",
      ">>Entradas: tensor([0.0086, 0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203, 0.0551],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1079])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0684], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1079])\n",
      ">>Entradas: tensor([0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203, 0.0551, 0.0684],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1372])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0912], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1372])\n",
      ">>Entradas: tensor([0.0245, 0.0327, 0.0246, 0.0205, 0.0203, 0.0551, 0.0684, 0.0912],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1373])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1094], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1373])\n",
      ">>Entradas: tensor([0.0327, 0.0246, 0.0205, 0.0203, 0.0551, 0.0684, 0.0912, 0.1094],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1339])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1176], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1339])\n",
      ">>Entradas: tensor([0.0246, 0.0205, 0.0203, 0.0551, 0.0684, 0.0912, 0.1094, 0.1176],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1268])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1232], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1268])\n",
      ">>Entradas: tensor([0.0205, 0.0203, 0.0551, 0.0684, 0.0912, 0.1094, 0.1176, 0.1232],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1476])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1389], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1476])\n",
      ">>Entradas: tensor([0.0203, 0.0551, 0.0684, 0.0912, 0.1094, 0.1176, 0.1232, 0.1389],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1960])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1637], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1960])\n",
      ">>Entradas: tensor([0.0551, 0.0684, 0.0912, 0.1094, 0.1176, 0.1232, 0.1389, 0.1637],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1854], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2169])\n",
      ">>Entradas: tensor([0.0684, 0.0912, 0.1094, 0.1176, 0.1232, 0.1389, 0.1637, 0.1854],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2101])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2008], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2101])\n",
      ">>Entradas: tensor([0.0912, 0.1094, 0.1176, 0.1232, 0.1389, 0.1637, 0.1854, 0.2008],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2027])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2104], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2027])\n",
      ">>Entradas: tensor([0.1094, 0.1176, 0.1232, 0.1389, 0.1637, 0.1854, 0.2008, 0.2104],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1946])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2133], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1946])\n",
      ">>Entradas: tensor([0.1176, 0.1232, 0.1389, 0.1637, 0.1854, 0.2008, 0.2104, 0.2133],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1941])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2152], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1941])\n",
      ">>Entradas: tensor([0.1232, 0.1389, 0.1637, 0.1854, 0.2008, 0.2104, 0.2133, 0.2152],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2010])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2200], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2010])\n",
      ">>Entradas: tensor([0.1389, 0.1637, 0.1854, 0.2008, 0.2104, 0.2133, 0.2152, 0.2200],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2218], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1966])\n",
      ">>Entradas: tensor([0.1637, 0.1854, 0.2008, 0.2104, 0.2133, 0.2152, 0.2200, 0.2218],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1810])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2169], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1810])\n",
      ">>Entradas: tensor([0.1854, 0.2008, 0.2104, 0.2133, 0.2152, 0.2200, 0.2218, 0.2169],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1654])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2074], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1654])\n",
      ">>Entradas: tensor([0.2008, 0.2104, 0.2133, 0.2152, 0.2200, 0.2218, 0.2169, 0.2074],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1499])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1937], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1499])\n",
      ">>Entradas: tensor([0.2104, 0.2133, 0.2152, 0.2200, 0.2218, 0.2169, 0.2074, 0.1937],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1504])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1815], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1504])\n",
      ">>Entradas: tensor([0.2133, 0.2152, 0.2200, 0.2218, 0.2169, 0.2074, 0.1937, 0.1815],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1671])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1766], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1671])\n",
      ">>Entradas: tensor([0.2152, 0.2200, 0.2218, 0.2169, 0.2074, 0.1937, 0.1815, 0.1766],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2023])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1824], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2023])\n",
      ">>Entradas: tensor([0.2200, 0.2218, 0.2169, 0.2074, 0.1937, 0.1815, 0.1766, 0.1824],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2559])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2009], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2559])\n",
      ">>Entradas: tensor([0.2218, 0.2169, 0.2074, 0.1937, 0.1815, 0.1766, 0.1824, 0.2009],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2927])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2241], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2927])\n",
      ">>Entradas: tensor([0.2169, 0.2074, 0.1937, 0.1815, 0.1766, 0.1824, 0.2009, 0.2241],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2472], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2074, 0.1937, 0.1815, 0.1766, 0.1824, 0.2009, 0.2241, 0.2472],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3109])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2652], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3109])\n",
      ">>Entradas: tensor([0.1937, 0.1815, 0.1766, 0.1824, 0.2009, 0.2241, 0.2472, 0.2652],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2876])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2741], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2876])\n",
      ">>Entradas: tensor([0.1815, 0.1766, 0.1824, 0.2009, 0.2241, 0.2472, 0.2652, 0.2741],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2802])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2817], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2802])\n",
      ">>Entradas: tensor([0.1766, 0.1824, 0.2009, 0.2241, 0.2472, 0.2652, 0.2741, 0.2817],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2886])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2927], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2886])\n",
      ">>Entradas: tensor([0.1824, 0.2009, 0.2241, 0.2472, 0.2652, 0.2741, 0.2817, 0.2927],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2825])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3000], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2825])\n",
      ">>Entradas: tensor([0.2009, 0.2241, 0.2472, 0.2652, 0.2741, 0.2817, 0.2927, 0.3000],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2618])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2991], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2618])\n",
      ">>Entradas: tensor([0.2241, 0.2472, 0.2652, 0.2741, 0.2817, 0.2927, 0.3000, 0.2991],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3044], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2801])\n",
      ">>Entradas: tensor([0.2472, 0.2652, 0.2741, 0.2817, 0.2927, 0.3000, 0.2991, 0.3044],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3374])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3220], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3374])\n",
      ">>Entradas: tensor([0.2652, 0.2741, 0.2817, 0.2927, 0.3000, 0.2991, 0.3044, 0.3220],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3482])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3339], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3482])\n",
      ">>Entradas: tensor([0.2741, 0.2817, 0.2927, 0.3000, 0.2991, 0.3044, 0.3220, 0.3339],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3328], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2817, 0.2927, 0.3000, 0.2991, 0.3044, 0.3220, 0.3339, 0.3328],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3436])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3438], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3436])\n",
      ">>Entradas: tensor([0.2927, 0.3000, 0.2991, 0.3044, 0.3220, 0.3339, 0.3328, 0.3438],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.4412])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3784], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.4412])\n",
      ">>Entradas: tensor([0.3000, 0.2991, 0.3044, 0.3220, 0.3339, 0.3328, 0.3438, 0.3784],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5211])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4242], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5211])\n",
      ">>Entradas: tensor([0.2991, 0.3044, 0.3220, 0.3339, 0.3328, 0.3438, 0.3784, 0.4242],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5833])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4866], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5833])\n",
      ">>Entradas: tensor([0.3044, 0.3220, 0.3339, 0.3328, 0.3438, 0.3784, 0.4242, 0.4866],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5403], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6089])\n",
      ">>Entradas: tensor([0.3220, 0.3339, 0.3328, 0.3438, 0.3784, 0.4242, 0.4866, 0.5403],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5980])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5782], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5980])\n",
      ">>Entradas: tensor([0.3339, 0.3328, 0.3438, 0.3784, 0.4242, 0.4866, 0.5403, 0.5782],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5945])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6072], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5945])\n",
      ">>Entradas: tensor([0.3328, 0.3438, 0.3784, 0.4242, 0.4866, 0.5403, 0.5782, 0.6072],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5985])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6332], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5985])\n",
      ">>Entradas: tensor([0.3438, 0.3784, 0.4242, 0.4866, 0.5403, 0.5782, 0.6072, 0.6332],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6214])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6611], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6214])\n",
      ">>Entradas: tensor([0.3784, 0.4242, 0.4866, 0.5403, 0.5782, 0.6072, 0.6332, 0.6611],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6631])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6966], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6631])\n",
      ">>Entradas: tensor([0.4242, 0.4866, 0.5403, 0.5782, 0.6072, 0.6332, 0.6611, 0.6966],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6929])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7305], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6929])\n",
      ">>Entradas: tensor([0.4866, 0.5403, 0.5782, 0.6072, 0.6332, 0.6611, 0.6966, 0.7305],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7107])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7541], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7107])\n",
      ">>Entradas: tensor([0.5403, 0.5782, 0.6072, 0.6332, 0.6611, 0.6966, 0.7305, 0.7541],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7217])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7703], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7217])\n",
      ">>Entradas: tensor([0.5782, 0.6072, 0.6332, 0.6611, 0.6966, 0.7305, 0.7541, 0.7703],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7259])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7789], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7259])\n",
      ">>Entradas: tensor([0.6072, 0.6332, 0.6611, 0.6966, 0.7305, 0.7541, 0.7703, 0.7789],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7404])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7859], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7404])\n",
      ">>Entradas: tensor([0.6332, 0.6611, 0.6966, 0.7305, 0.7541, 0.7703, 0.7789, 0.7859],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7652])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7970], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7652])\n",
      ">>Entradas: tensor([0.6611, 0.6966, 0.7305, 0.7541, 0.7703, 0.7789, 0.7859, 0.7970],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7448])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7935], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7448])\n",
      ">>Entradas: tensor([0.6966, 0.7305, 0.7541, 0.7703, 0.7789, 0.7859, 0.7970, 0.7935],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6792])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7740], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6792])\n",
      ">>Entradas: tensor([0.7305, 0.7541, 0.7703, 0.7789, 0.7859, 0.7970, 0.7935, 0.7740],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6746])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7540], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6746])\n",
      ">>Entradas: tensor([0.7541, 0.7703, 0.7789, 0.7859, 0.7970, 0.7935, 0.7740, 0.7540],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7505], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7309])\n",
      ">>Entradas: tensor([0.7703, 0.7789, 0.7859, 0.7970, 0.7935, 0.7740, 0.7540, 0.7505],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7467])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7481], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7467])\n",
      ">>Entradas: tensor([0.7789, 0.7859, 0.7970, 0.7935, 0.7740, 0.7540, 0.7505, 0.7481],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7219])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7391], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7219])\n",
      ">>Entradas: tensor([0.7859, 0.7970, 0.7935, 0.7740, 0.7540, 0.7505, 0.7481, 0.7391],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7199])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7326], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7199])\n",
      ">>Entradas: tensor([0.7970, 0.7935, 0.7740, 0.7540, 0.7505, 0.7481, 0.7391, 0.7326],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7407])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7299], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7407])\n",
      ">>Entradas: tensor([0.7935, 0.7740, 0.7540, 0.7505, 0.7481, 0.7391, 0.7326, 0.7299],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7362])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7226], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7362])\n",
      ">>Entradas: tensor([0.7740, 0.7540, 0.7505, 0.7481, 0.7391, 0.7326, 0.7299, 0.7226],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7105], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7065])\n",
      ">>Entradas: tensor([0.7540, 0.7505, 0.7481, 0.7391, 0.7326, 0.7299, 0.7226, 0.7105],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6979])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7032], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6979])\n",
      ">>Entradas: tensor([0.7505, 0.7481, 0.7391, 0.7326, 0.7299, 0.7226, 0.7105, 0.7032],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7106])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7009], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7106])\n",
      ">>Entradas: tensor([0.7481, 0.7391, 0.7326, 0.7299, 0.7226, 0.7105, 0.7032, 0.7009],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7210])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7011], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7210])\n",
      ">>Entradas: tensor([0.7391, 0.7326, 0.7299, 0.7226, 0.7105, 0.7032, 0.7009, 0.7011],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7291])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7052], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7291])\n",
      ">>Entradas: tensor([0.7326, 0.7299, 0.7226, 0.7105, 0.7032, 0.7009, 0.7011, 0.7052],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7674])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7211], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7674])\n",
      ">>Entradas: tensor([0.7299, 0.7226, 0.7105, 0.7032, 0.7009, 0.7011, 0.7052, 0.7211],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8359])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7529], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8359])\n",
      ">>Entradas: tensor([0.7226, 0.7105, 0.7032, 0.7009, 0.7011, 0.7052, 0.7211, 0.7529],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8510])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7815], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8510])\n",
      ">>Entradas: tensor([0.7105, 0.7032, 0.7009, 0.7011, 0.7052, 0.7211, 0.7529, 0.7815],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8127])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7955], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8127])\n",
      ">>Entradas: tensor([0.7032, 0.7009, 0.7011, 0.7052, 0.7211, 0.7529, 0.7815, 0.7955],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7864])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8009], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7864])\n",
      ">>Entradas: tensor([0.7009, 0.7011, 0.7052, 0.7211, 0.7529, 0.7815, 0.7955, 0.8009],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7720])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8010], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7720])\n",
      ">>Entradas: tensor([0.7011, 0.7052, 0.7211, 0.7529, 0.7815, 0.7955, 0.8009, 0.8010],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8102], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.7052, 0.7211, 0.7529, 0.7815, 0.7955, 0.8009, 0.8010, 0.8102],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8803])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8421], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8803])\n",
      ">>Entradas: tensor([0.7211, 0.7529, 0.7815, 0.7955, 0.8009, 0.8010, 0.8102, 0.8421],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8987])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8731], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8987])\n",
      ">>Entradas: tensor([0.7529, 0.7815, 0.7955, 0.8009, 0.8010, 0.8102, 0.8421, 0.8731],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8827], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.7815, 0.7955, 0.8009, 0.8010, 0.8102, 0.8421, 0.8731, 0.8827],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8793], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8309])\n",
      ">>Entradas: tensor([0.7955, 0.8009, 0.8010, 0.8102, 0.8421, 0.8731, 0.8827, 0.8793],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8156])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8645], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8156])\n",
      ">>Entradas: tensor([0.8009, 0.8010, 0.8102, 0.8421, 0.8731, 0.8827, 0.8793, 0.8645],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8529], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8117])\n",
      ">>Entradas: tensor([0.8010, 0.8102, 0.8421, 0.8731, 0.8827, 0.8793, 0.8645, 0.8529],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8192])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8404], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8192])\n",
      ">>Entradas: tensor([0.8102, 0.8421, 0.8731, 0.8827, 0.8793, 0.8645, 0.8529, 0.8404],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8218])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8422], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8218])\n",
      ">>Entradas: tensor([0.8421, 0.8731, 0.8827, 0.8793, 0.8645, 0.8529, 0.8404, 0.8422],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8402], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8197])\n",
      ">>Entradas: tensor([0.8731, 0.8827, 0.8793, 0.8645, 0.8529, 0.8404, 0.8422, 0.8402],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8179])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8331], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8179])\n",
      ">>Entradas: tensor([0.8827, 0.8793, 0.8645, 0.8529, 0.8404, 0.8422, 0.8402, 0.8331],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8163])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8243], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8163])\n",
      ">>Entradas: tensor([0.8793, 0.8645, 0.8529, 0.8404, 0.8422, 0.8402, 0.8331, 0.8243],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8006])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8114], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8006])\n",
      ">>Entradas: tensor([0.8645, 0.8529, 0.8404, 0.8422, 0.8402, 0.8331, 0.8243, 0.8114],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7705])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7925], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7705])\n",
      ">>Entradas: tensor([0.8529, 0.8404, 0.8422, 0.8402, 0.8331, 0.8243, 0.8114, 0.7925],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7427])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7716], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7427])\n",
      ">>Entradas: tensor([0.8404, 0.8422, 0.8402, 0.8331, 0.8243, 0.8114, 0.7925, 0.7716],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7503], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7169])\n",
      ">>Entradas: tensor([0.8422, 0.8402, 0.8331, 0.8243, 0.8114, 0.7925, 0.7716, 0.7503],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7340], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7197])\n",
      ">>Entradas: tensor([0.8402, 0.8331, 0.8243, 0.8114, 0.7925, 0.7716, 0.7503, 0.7340],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7509])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7303], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7509])\n",
      ">>Entradas: tensor([0.8331, 0.8243, 0.8114, 0.7925, 0.7716, 0.7503, 0.7340, 0.7303],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7403])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7235], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7403])\n",
      ">>Entradas: tensor([0.8243, 0.8114, 0.7925, 0.7716, 0.7503, 0.7340, 0.7303, 0.7235],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7027], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.8114, 0.7925, 0.7716, 0.7503, 0.7340, 0.7303, 0.7235, 0.7027],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6688])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6820], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6688])\n",
      ">>Entradas: tensor([0.7925, 0.7716, 0.7503, 0.7340, 0.7303, 0.7235, 0.7027, 0.6820],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6835])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6707], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6835])\n",
      ">>Entradas: tensor([0.7716, 0.7503, 0.7340, 0.7303, 0.7235, 0.7027, 0.6820, 0.6707],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6628], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.7503, 0.7340, 0.7303, 0.7235, 0.7027, 0.6820, 0.6707, 0.6628],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6815])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6580], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6815])\n",
      ">>Entradas: tensor([0.7340, 0.7303, 0.7235, 0.7027, 0.6820, 0.6707, 0.6628, 0.6580],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6893])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6608], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6893])\n",
      ">>Entradas: tensor([0.7303, 0.7235, 0.7027, 0.6820, 0.6707, 0.6628, 0.6580, 0.6608],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7111])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6686], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7111])\n",
      ">>Entradas: tensor([0.7235, 0.7027, 0.6820, 0.6707, 0.6628, 0.6580, 0.6608, 0.6686],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7349])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6797], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7349])\n",
      ">>Entradas: tensor([0.7027, 0.6820, 0.6707, 0.6628, 0.6580, 0.6608, 0.6686, 0.6797],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7608])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6982], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7608])\n",
      ">>Entradas: tensor([0.6820, 0.6707, 0.6628, 0.6580, 0.6608, 0.6686, 0.6797, 0.6982],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7711])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7187], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7711])\n",
      ">>Entradas: tensor([0.6707, 0.6628, 0.6580, 0.6608, 0.6686, 0.6797, 0.6982, 0.7187],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7660])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7346], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7660])\n",
      ">>Entradas: tensor([0.6628, 0.6580, 0.6608, 0.6686, 0.6797, 0.6982, 0.7187, 0.7346],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7483])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7440], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7483])\n",
      ">>Entradas: tensor([0.6580, 0.6608, 0.6686, 0.6797, 0.6982, 0.7187, 0.7346, 0.7440],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7182])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7443], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7182])\n",
      ">>Entradas: tensor([0.6608, 0.6686, 0.6797, 0.6982, 0.7187, 0.7346, 0.7440, 0.7443],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7423], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7089])\n",
      ">>Entradas: tensor([0.6686, 0.6797, 0.6982, 0.7187, 0.7346, 0.7440, 0.7443, 0.7423],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7204])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7441], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7204])\n",
      ">>Entradas: tensor([0.6797, 0.6982, 0.7187, 0.7346, 0.7440, 0.7443, 0.7423, 0.7441],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7706])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7604], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7706])\n",
      ">>Entradas: tensor([0.6982, 0.7187, 0.7346, 0.7440, 0.7443, 0.7423, 0.7441, 0.7604],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8595])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7982], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8595])\n",
      ">>Entradas: tensor([0.7187, 0.7346, 0.7440, 0.7443, 0.7423, 0.7441, 0.7604, 0.7982],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8390], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9065])\n",
      ">>Entradas: tensor([0.7346, 0.7440, 0.7443, 0.7423, 0.7441, 0.7604, 0.7982, 0.8390],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9119])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8704], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9119])\n",
      ">>Entradas: tensor([0.7440, 0.7443, 0.7423, 0.7441, 0.7604, 0.7982, 0.8390, 0.8704],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9043])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8916], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9043])\n",
      ">>Entradas: tensor([0.7443, 0.7423, 0.7441, 0.7604, 0.7982, 0.8390, 0.8704, 0.8916],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8839])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9012], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8839])\n",
      ">>Entradas: tensor([0.7423, 0.7441, 0.7604, 0.7982, 0.8390, 0.8704, 0.8916, 0.9012],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9032])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9143], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9032])\n",
      ">>Entradas: tensor([0.7441, 0.7604, 0.7982, 0.8390, 0.8704, 0.8916, 0.9012, 0.9143],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9623])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9444], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9623])\n",
      ">>Entradas: tensor([0.7604, 0.7982, 0.8390, 0.8704, 0.8916, 0.9012, 0.9143, 0.9444],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9821])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9750], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9821])\n",
      ">>Entradas: tensor([0.7982, 0.8390, 0.8704, 0.8916, 0.9012, 0.9143, 0.9444, 0.9750],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9624])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9906], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9624])\n",
      ">>Entradas: tensor([0.8390, 0.8704, 0.8916, 0.9012, 0.9143, 0.9444, 0.9750, 0.9906],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9303])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9900], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9303])\n",
      ">>Entradas: tensor([0.8704, 0.8916, 0.9012, 0.9143, 0.9444, 0.9750, 0.9906, 0.9900],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8855])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9718], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8855])\n",
      ">>Entradas: tensor([0.8916, 0.9012, 0.9143, 0.9444, 0.9750, 0.9906, 0.9900, 0.9718],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8597])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9454], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8597])\n",
      ">>Entradas: tensor([0.9012, 0.9143, 0.9444, 0.9750, 0.9906, 0.9900, 0.9718, 0.9454],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8529])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9172], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8529])\n",
      ">>Entradas: tensor([0.9143, 0.9444, 0.9750, 0.9906, 0.9900, 0.9718, 0.9454, 0.9172],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9048], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.9444, 0.9750, 0.9906, 0.9900, 0.9718, 0.9454, 0.9172, 0.9048],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8769])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8981], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8769])\n",
      ">>Entradas: tensor([0.9750, 0.9906, 0.9900, 0.9718, 0.9454, 0.9172, 0.9048, 0.8981],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8806])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8900], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8806])\n",
      ">>Entradas: tensor([0.9906, 0.9900, 0.9718, 0.9454, 0.9172, 0.9048, 0.8981, 0.8900],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8699])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8774], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8699])\n",
      ">>Entradas: tensor([0.9900, 0.9718, 0.9454, 0.9172, 0.9048, 0.8981, 0.8900, 0.8774],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8465])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8582], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8465])\n",
      ">>Entradas: tensor([0.9718, 0.9454, 0.9172, 0.9048, 0.8981, 0.8900, 0.8774, 0.8582],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8104])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8303], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8104])\n",
      ">>Entradas: tensor([0.9454, 0.9172, 0.9048, 0.8981, 0.8900, 0.8774, 0.8582, 0.8303],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8026])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8098], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8026])\n",
      ">>Entradas: tensor([0.9172, 0.9048, 0.8981, 0.8900, 0.8774, 0.8582, 0.8303, 0.8098],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8232])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8039], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8232])\n",
      ">>Entradas: tensor([0.9048, 0.8981, 0.8900, 0.8774, 0.8582, 0.8303, 0.8098, 0.8039],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8397])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8054], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8397])\n",
      ">>Entradas: tensor([0.8981, 0.8900, 0.8774, 0.8582, 0.8303, 0.8098, 0.8039, 0.8054],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8522])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8108], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8522])\n",
      ">>Entradas: tensor([0.8900, 0.8774, 0.8582, 0.8303, 0.8098, 0.8039, 0.8054, 0.8108],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8616])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8185], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8616])\n",
      ">>Entradas: tensor([0.8774, 0.8582, 0.8303, 0.8098, 0.8039, 0.8054, 0.8108, 0.8185],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8679])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8255], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8679])\n",
      ">>Entradas: tensor([0.8582, 0.8303, 0.8098, 0.8039, 0.8054, 0.8108, 0.8185, 0.8255],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8702])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8314], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8702])\n",
      ">>Entradas: tensor([0.8303, 0.8098, 0.8039, 0.8054, 0.8108, 0.8185, 0.8255, 0.8314],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8685])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8392], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8685])\n",
      ">>Entradas: tensor([0.8098, 0.8039, 0.8054, 0.8108, 0.8185, 0.8255, 0.8314, 0.8392],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8530])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8443], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8530])\n",
      ">>Entradas: tensor([0.8039, 0.8054, 0.8108, 0.8185, 0.8255, 0.8314, 0.8392, 0.8443],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8236])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8413], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8236])\n",
      ">>Entradas: tensor([0.8054, 0.8108, 0.8185, 0.8255, 0.8314, 0.8392, 0.8443, 0.8413],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8290], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.8108, 0.8185, 0.8255, 0.8314, 0.8392, 0.8443, 0.8413, 0.8290],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7919])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8197], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7919])\n",
      ">>Entradas: tensor([0.8185, 0.8255, 0.8314, 0.8392, 0.8443, 0.8413, 0.8290, 0.8197],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7865])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8110], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7865])\n",
      ">>Entradas: tensor([0.8255, 0.8314, 0.8392, 0.8443, 0.8413, 0.8290, 0.8197, 0.8110],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7870])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8035], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7870])\n",
      ">>Entradas: tensor([0.8314, 0.8392, 0.8443, 0.8413, 0.8290, 0.8197, 0.8110, 0.8035],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7874])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7981], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7874])\n",
      ">>Entradas: tensor([0.8392, 0.8443, 0.8413, 0.8290, 0.8197, 0.8110, 0.8035, 0.7981],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7879])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7931], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7879])\n",
      ">>Entradas: tensor([0.8443, 0.8413, 0.8290, 0.8197, 0.8110, 0.8035, 0.7981, 0.7931],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7955])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7893], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7955])\n",
      ">>Entradas: tensor([0.8413, 0.8290, 0.8197, 0.8110, 0.8035, 0.7981, 0.7931, 0.7893],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8102])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7898], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8102])\n",
      ">>Entradas: tensor([0.8290, 0.8197, 0.8110, 0.8035, 0.7981, 0.7931, 0.7893, 0.7898],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7668])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7783], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7668])\n",
      ">>Entradas: tensor([0.8197, 0.8110, 0.8035, 0.7981, 0.7931, 0.7893, 0.7898, 0.7783],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6655])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7406], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6655])\n",
      ">>Entradas: tensor([0.8110, 0.8035, 0.7981, 0.7931, 0.7893, 0.7898, 0.7783, 0.7406],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6361])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7048], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6361])\n",
      ">>Entradas: tensor([0.8035, 0.7981, 0.7931, 0.7893, 0.7898, 0.7783, 0.7406, 0.7048],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6785])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6895], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6785])\n",
      ">>Entradas: tensor([0.7981, 0.7931, 0.7893, 0.7898, 0.7783, 0.7406, 0.7048, 0.6895],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6809], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6966])\n",
      ">>Entradas: tensor([0.7931, 0.7893, 0.7898, 0.7783, 0.7406, 0.7048, 0.6895, 0.6809],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6903])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6737], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6903])\n",
      ">>Entradas: tensor([0.7893, 0.7898, 0.7783, 0.7406, 0.7048, 0.6895, 0.6809, 0.6737],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6970])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6728], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6970])\n",
      ">>Entradas: tensor([0.7898, 0.7783, 0.7406, 0.7048, 0.6895, 0.6809, 0.6737, 0.6728],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7167])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6745], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7167])\n",
      ">>Entradas: tensor([0.7783, 0.7406, 0.7048, 0.6895, 0.6809, 0.6737, 0.6728, 0.6745],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7491])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6815], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7491])\n",
      ">>Entradas: tensor([0.7406, 0.7048, 0.6895, 0.6809, 0.6737, 0.6728, 0.6745, 0.6815],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7940])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7042], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7940])\n",
      ">>Entradas: tensor([0.7048, 0.6895, 0.6809, 0.6737, 0.6728, 0.6745, 0.6815, 0.7042],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8547])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7458], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8547])\n",
      ">>Entradas: tensor([0.6895, 0.6809, 0.6737, 0.6728, 0.6745, 0.6815, 0.7042, 0.7458],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9314])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8033], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9314])\n",
      ">>Entradas: tensor([0.6809, 0.6737, 0.6728, 0.6745, 0.6815, 0.7042, 0.7458, 0.8033],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9627])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8589], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9627])\n",
      ">>Entradas: tensor([0.6737, 0.6728, 0.6745, 0.6815, 0.7042, 0.7458, 0.8033, 0.8589],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9486])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9006], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9486])\n",
      ">>Entradas: tensor([0.6728, 0.6745, 0.6815, 0.7042, 0.7458, 0.8033, 0.8589, 0.9006],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9307])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9293], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9307])\n",
      ">>Entradas: tensor([0.6745, 0.6815, 0.7042, 0.7458, 0.8033, 0.8589, 0.9006, 0.9293],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9090])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9457], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9090])\n",
      ">>Entradas: tensor([0.6815, 0.7042, 0.7458, 0.8033, 0.8589, 0.9006, 0.9293, 0.9457],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8816])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9516], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8816])\n",
      ">>Entradas: tensor([0.7042, 0.7458, 0.8033, 0.8589, 0.9006, 0.9293, 0.9457, 0.9516],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8487])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9478], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8487])\n",
      ">>Entradas: tensor([0.7458, 0.8033, 0.8589, 0.9006, 0.9293, 0.9457, 0.9516, 0.9478],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8753])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9515], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8753])\n",
      ">>Entradas: tensor([0.8033, 0.8589, 0.9006, 0.9293, 0.9457, 0.9516, 0.9478, 0.9515],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9612])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9739], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9612])\n",
      ">>Entradas: tensor([0.8589, 0.9006, 0.9293, 0.9457, 0.9516, 0.9478, 0.9515, 0.9739],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9925])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9930], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9925])\n",
      ">>Entradas: tensor([0.9006, 0.9293, 0.9457, 0.9516, 0.9478, 0.9515, 0.9739, 0.9930],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9690])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9963], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9690])\n",
      ">>Entradas: tensor([0.9293, 0.9457, 0.9516, 0.9478, 0.9515, 0.9739, 0.9930, 0.9963],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9715])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9972], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9715])\n",
      ">>Entradas: tensor([0.9457, 0.9516, 0.9478, 0.9515, 0.9739, 0.9930, 0.9963, 0.9972],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([1.])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0025], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([1.])\n",
      ">>Entradas: tensor([0.9516, 0.9478, 0.9515, 0.9739, 0.9930, 0.9963, 0.9972, 1.0025],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9973], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9801])\n",
      ">>Entradas: tensor([0.9478, 0.9515, 0.9739, 0.9930, 0.9963, 0.9972, 1.0025, 0.9973],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9761], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9117])\n",
      ">>Entradas: tensor([0.9515, 0.9739, 0.9930, 0.9963, 0.9972, 1.0025, 0.9973, 0.9761],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8911])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9575], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8911])\n",
      ">>Entradas: tensor([0.9739, 0.9930, 0.9963, 0.9972, 1.0025, 0.9973, 0.9761, 0.9575],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9181])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9473], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9181])\n",
      ">>Entradas: tensor([0.9930, 0.9963, 0.9972, 1.0025, 0.9973, 0.9761, 0.9575, 0.9473],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9450])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9429], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9450])\n",
      ">>Entradas: tensor([0.9963, 0.9972, 1.0025, 0.9973, 0.9761, 0.9575, 0.9473, 0.9429],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9718])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9482], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9718])\n",
      ">>Entradas: tensor([0.9972, 1.0025, 0.9973, 0.9761, 0.9575, 0.9473, 0.9429, 0.9482],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9829])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9565], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9829])\n",
      ">>Entradas: tensor([1.0025, 0.9973, 0.9761, 0.9575, 0.9473, 0.9429, 0.9482, 0.9565],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9783])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9587], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9783])\n",
      ">>s_original: [0.049424633383750916, 0.10789185762405396, 0.13719609379768372, 0.13733737170696259, 0.1338856965303421, 0.12684109807014465, 0.14756061136722565, 0.19604423642158508, 0.21688967943191528, 0.21009695529937744, 0.20267784595489502, 0.1946323662996292, 0.19407351315021515, 0.20100130140781403, 0.19663821160793304, 0.180984228849411, 0.16539041697978973, 0.14985674619674683, 0.15043111145496368, 0.1671135276556015, 0.20227035880088806, 0.25590160489082336, 0.29268819093704224, 0.31263017654418945, 0.31093889474868774, 0.2876143157482147, 0.28016164898872375, 0.28858086466789246, 0.28246283531188965, 0.26180753111839294, 0.2801212966442108, 0.3374040722846985, 0.3482298254966736, 0.3125985562801361, 0.34358710050582886, 0.44119545817375183, 0.521095335483551, 0.5832866430282593, 0.6089234352111816, 0.5980057120323181, 0.5945301651954651, 0.5984968543052673, 0.621354341506958, 0.6631026864051819, 0.6928724050521851, 0.7106636166572571, 0.721682071685791, 0.7259277701377869, 0.7404318451881409, 0.7651942372322083, 0.7447891235351562, 0.6792163252830505, 0.6746017932891846, 0.730945348739624, 0.7467210292816162, 0.7219287157058716, 0.7199286818504333, 0.7407209277153015, 0.7362455129623413, 0.7065023183822632, 0.6979451775550842, 0.7105739712715149, 0.7209621667861938, 0.7291097044944763, 0.7674259543418884, 0.8359109163284302, 0.8510103225708008, 0.8127241730690002, 0.7863940000534058, 0.7720199823379517, 0.8033170700073242, 0.8802852630615234, 0.8987051844596863, 0.8585767149925232, 0.8308762311935425, 0.8156037926673889, 0.8116992115974426, 0.8191625475883484, 0.8218275904655457, 0.8196942210197449, 0.817862868309021, 0.8163333535194397, 0.8005555868148804, 0.7705295085906982, 0.7426586747169495, 0.716943085193634, 0.7197051048278809, 0.7509447932243347, 0.7402781248092651, 0.6877052187919617, 0.6687695384025574, 0.683471143245697, 0.6877052187919617, 0.6814717054367065, 0.6892618536949158, 0.7110756039619446, 0.7349108457565308, 0.7607676982879639, 0.771117091178894, 0.7659589648246765, 0.7483323812484741, 0.7182371616363525, 0.708941638469696, 0.7204458117485046, 0.7706154584884644, 0.8594506978988647, 0.906541109085083, 0.9118866324424744, 0.9043355584144592, 0.8838878870010376, 0.9032153487205505, 0.9623178839683533, 0.9820588231086731, 0.96243816614151, 0.9302511811256409, 0.8854979276657104, 0.8597025871276855, 0.8528652191162109, 0.8585854768753052, 0.8768633008003235, 0.8806464076042175, 0.8699347376823425, 0.846513569355011, 0.8103827834129333, 0.8026111125946045, 0.8231984972953796, 0.8397204279899597, 0.8521769046783447, 0.8615626692771912, 0.8678776621818542, 0.8701963424682617, 0.868518590927124, 0.852988064289093, 0.8236046433448792, 0.8032509088516235, 0.7919268012046814, 0.7865023016929626, 0.7869773507118225, 0.7874362468719482, 0.7878790497779846, 0.7954531908035278, 0.8101586699485779, 0.7668473124504089, 0.665519118309021, 0.6360738277435303, 0.678511381149292, 0.6965967416763306, 0.6903298497200012, 0.6970472931861877, 0.7167490720748901, 0.7490506768226624, 0.7939522862434387, 0.8547447323799133, 0.931428074836731, 0.9627243876457214, 0.9486336708068848, 0.9307146072387695, 0.9089671969413757, 0.8816379904747009, 0.8487268090248108, 0.8752607107162476, 0.9612395763397217, 0.9925020933151245, 0.9690483212471008, 0.9715476036071777, 1.0, 0.9800636768341064, 0.9117385745048523, 0.8910858035087585, 0.9181053042411804, 0.9450165033340454, 0.9718193411827087, 0.982906699180603, 0.9782785773277283]\n",
      ">>s_pred: [0.0550689697265625, 0.06840991973876953, 0.09124469757080078, 0.10939788818359375, 0.11760711669921875, 0.12316513061523438, 0.13888835906982422, 0.16369915008544922, 0.18540096282958984, 0.2007923126220703, 0.21038532257080078, 0.21331405639648438, 0.2151966094970703, 0.22004222869873047, 0.2218189239501953, 0.2168750762939453, 0.20742034912109375, 0.19366931915283203, 0.1814565658569336, 0.1765594482421875, 0.18235206604003906, 0.20087814331054688, 0.22414493560791016, 0.24715232849121094, 0.2651548385620117, 0.2740602493286133, 0.2817363739013672, 0.29272937774658203, 0.2999753952026367, 0.29906177520751953, 0.3043708801269531, 0.32199573516845703, 0.33393096923828125, 0.3327512741088867, 0.34375953674316406, 0.3784141540527344, 0.42418861389160156, 0.4865894317626953, 0.5403451919555664, 0.5782346725463867, 0.6072053909301758, 0.6332054138183594, 0.661102294921875, 0.6965646743774414, 0.7304859161376953, 0.7541160583496094, 0.7702770233154297, 0.7789497375488281, 0.7858963012695312, 0.7970266342163086, 0.7934904098510742, 0.7740383148193359, 0.7539558410644531, 0.7505102157592773, 0.7480859756469727, 0.7390966415405273, 0.732630729675293, 0.729888916015625, 0.7225532531738281, 0.7105112075805664, 0.7032089233398438, 0.700922966003418, 0.7010993957519531, 0.7052383422851562, 0.7211399078369141, 0.7529277801513672, 0.781494140625, 0.7955284118652344, 0.8008890151977539, 0.8010311126708984, 0.8101634979248047, 0.8421363830566406, 0.8731250762939453, 0.882659912109375, 0.8793115615844727, 0.8645229339599609, 0.8528642654418945, 0.8403682708740234, 0.8422327041625977, 0.840245246887207, 0.833125114440918, 0.8243236541748047, 0.8113603591918945, 0.792546272277832, 0.7715959548950195, 0.7503242492675781, 0.7339859008789062, 0.7302780151367188, 0.7235164642333984, 0.7026844024658203, 0.6820163726806641, 0.6706743240356445, 0.6628293991088867, 0.6580448150634766, 0.6608362197875977, 0.6685991287231445, 0.6797151565551758, 0.6982011795043945, 0.718653678894043, 0.7346363067626953, 0.7439565658569336, 0.7443408966064453, 0.7423086166381836, 0.7441396713256836, 0.7604093551635742, 0.7981538772583008, 0.8389883041381836, 0.8703775405883789, 0.8916130065917969, 0.9011783599853516, 0.9142656326293945, 0.9443626403808594, 0.974970817565918, 0.9906377792358398, 0.9899826049804688, 0.9717521667480469, 0.9453916549682617, 0.9171848297119141, 0.9047813415527344, 0.8981103897094727, 0.8900241851806641, 0.8774452209472656, 0.8582210540771484, 0.8303146362304688, 0.8097553253173828, 0.8039264678955078, 0.8053770065307617, 0.810826301574707, 0.8184823989868164, 0.8254547119140625, 0.8314342498779297, 0.8391504287719727, 0.844264030456543, 0.8413276672363281, 0.829005241394043, 0.8197355270385742, 0.8109807968139648, 0.8035144805908203, 0.7980842590332031, 0.7931404113769531, 0.789280891418457, 0.7898378372192383, 0.7782697677612305, 0.7405672073364258, 0.7047910690307617, 0.6895074844360352, 0.6809329986572266, 0.6736717224121094, 0.6727819442749023, 0.6744804382324219, 0.6814517974853516, 0.7042484283447266, 0.7458248138427734, 0.8033075332641602, 0.8589010238647461, 0.9005851745605469, 0.929326057434082, 0.9457406997680664, 0.9516201019287109, 0.9477577209472656, 0.9515151977539062, 0.9738712310791016, 0.9930086135864258, 0.9963159561157227, 0.9971981048583984, 1.002488136291504, 0.997283935546875, 0.9761371612548828, 0.9574642181396484, 0.9473066329956055, 0.9429378509521484, 0.9481887817382812, 0.956512451171875, 0.9586935043334961]\n",
      "<<Perdida: 0.0016975433100014925 epoca: 14\n",
      "---Inicio de epoca: 15--\n",
      ">>Entradas: tensor([0.0503, 0.0086, 0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203])\n",
      ">>Salida: tensor([0.0494])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0255], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.0494])\n",
      ">>Entradas: tensor([0.0086, 0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203, 0.0255],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1079])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0506], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1079])\n",
      ">>Entradas: tensor([0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203, 0.0255, 0.0506],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1372])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0787], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1372])\n",
      ">>Entradas: tensor([0.0245, 0.0327, 0.0246, 0.0205, 0.0203, 0.0255, 0.0506, 0.0787],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1373])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0954], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1373])\n",
      ">>Entradas: tensor([0.0327, 0.0246, 0.0205, 0.0203, 0.0255, 0.0506, 0.0787, 0.0954],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1339])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1089], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1339])\n",
      ">>Entradas: tensor([0.0246, 0.0205, 0.0203, 0.0255, 0.0506, 0.0787, 0.0954, 0.1089],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1268])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1189], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1268])\n",
      ">>Entradas: tensor([0.0205, 0.0203, 0.0255, 0.0506, 0.0787, 0.0954, 0.1089, 0.1189],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1476])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1325], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1476])\n",
      ">>Entradas: tensor([0.0203, 0.0255, 0.0506, 0.0787, 0.0954, 0.1089, 0.1189, 0.1325],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1960])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1594], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1960])\n",
      ">>Entradas: tensor([0.0255, 0.0506, 0.0787, 0.0954, 0.1089, 0.1189, 0.1325, 0.1594],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1864], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2169])\n",
      ">>Entradas: tensor([0.0506, 0.0787, 0.0954, 0.1089, 0.1189, 0.1325, 0.1594, 0.1864],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2101])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2034], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2101])\n",
      ">>Entradas: tensor([0.0787, 0.0954, 0.1089, 0.1189, 0.1325, 0.1594, 0.1864, 0.2034],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2027])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2145], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2027])\n",
      ">>Entradas: tensor([0.0954, 0.1089, 0.1189, 0.1325, 0.1594, 0.1864, 0.2034, 0.2145],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1946])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2199], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1946])\n",
      ">>Entradas: tensor([0.1089, 0.1189, 0.1325, 0.1594, 0.1864, 0.2034, 0.2145, 0.2199],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1941])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2222], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1941])\n",
      ">>Entradas: tensor([0.1189, 0.1325, 0.1594, 0.1864, 0.2034, 0.2145, 0.2199, 0.2222],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2010])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2270], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2010])\n",
      ">>Entradas: tensor([0.1325, 0.1594, 0.1864, 0.2034, 0.2145, 0.2199, 0.2222, 0.2270],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2283], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1966])\n",
      ">>Entradas: tensor([0.1594, 0.1864, 0.2034, 0.2145, 0.2199, 0.2222, 0.2270, 0.2283],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1810])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2240], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1810])\n",
      ">>Entradas: tensor([0.1864, 0.2034, 0.2145, 0.2199, 0.2222, 0.2270, 0.2283, 0.2240],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1654])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2137], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1654])\n",
      ">>Entradas: tensor([0.2034, 0.2145, 0.2199, 0.2222, 0.2270, 0.2283, 0.2240, 0.2137],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1499])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1989], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1499])\n",
      ">>Entradas: tensor([0.2145, 0.2199, 0.2222, 0.2270, 0.2283, 0.2240, 0.2137, 0.1989],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1504])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1857], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1504])\n",
      ">>Entradas: tensor([0.2199, 0.2222, 0.2270, 0.2283, 0.2240, 0.2137, 0.1989, 0.1857],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1671])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1794], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1671])\n",
      ">>Entradas: tensor([0.2222, 0.2270, 0.2283, 0.2240, 0.2137, 0.1989, 0.1857, 0.1794],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2023])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1837], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2023])\n",
      ">>Entradas: tensor([0.2270, 0.2283, 0.2240, 0.2137, 0.1989, 0.1857, 0.1794, 0.1837],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2559])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2012], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2559])\n",
      ">>Entradas: tensor([0.2283, 0.2240, 0.2137, 0.1989, 0.1857, 0.1794, 0.1837, 0.2012],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2927])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2237], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2927])\n",
      ">>Entradas: tensor([0.2240, 0.2137, 0.1989, 0.1857, 0.1794, 0.1837, 0.2012, 0.2237],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2459], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2137, 0.1989, 0.1857, 0.1794, 0.1837, 0.2012, 0.2237, 0.2459],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3109])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2636], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3109])\n",
      ">>Entradas: tensor([0.1989, 0.1857, 0.1794, 0.1837, 0.2012, 0.2237, 0.2459, 0.2636],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2876])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2726], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2876])\n",
      ">>Entradas: tensor([0.1857, 0.1794, 0.1837, 0.2012, 0.2237, 0.2459, 0.2636, 0.2726],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2802])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2808], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2802])\n",
      ">>Entradas: tensor([0.1794, 0.1837, 0.2012, 0.2237, 0.2459, 0.2636, 0.2726, 0.2808],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2886])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2925], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2886])\n",
      ">>Entradas: tensor([0.1837, 0.2012, 0.2237, 0.2459, 0.2636, 0.2726, 0.2808, 0.2925],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2825])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3007], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2825])\n",
      ">>Entradas: tensor([0.2012, 0.2237, 0.2459, 0.2636, 0.2726, 0.2808, 0.2925, 0.3007],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2618])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3010], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2618])\n",
      ">>Entradas: tensor([0.2237, 0.2459, 0.2636, 0.2726, 0.2808, 0.2925, 0.3007, 0.3010],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3064], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2801])\n",
      ">>Entradas: tensor([0.2459, 0.2636, 0.2726, 0.2808, 0.2925, 0.3007, 0.3010, 0.3064],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3374])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3243], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3374])\n",
      ">>Entradas: tensor([0.2636, 0.2726, 0.2808, 0.2925, 0.3007, 0.3010, 0.3064, 0.3243],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3482])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3365], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3482])\n",
      ">>Entradas: tensor([0.2726, 0.2808, 0.2925, 0.3007, 0.3010, 0.3064, 0.3243, 0.3365],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3355], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2808, 0.2925, 0.3007, 0.3010, 0.3064, 0.3243, 0.3365, 0.3355],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3436])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3464], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3436])\n",
      ">>Entradas: tensor([0.2925, 0.3007, 0.3010, 0.3064, 0.3243, 0.3365, 0.3355, 0.3464],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.4412])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3820], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.4412])\n",
      ">>Entradas: tensor([0.3007, 0.3010, 0.3064, 0.3243, 0.3365, 0.3355, 0.3464, 0.3820],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5211])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4273], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5211])\n",
      ">>Entradas: tensor([0.3010, 0.3064, 0.3243, 0.3365, 0.3355, 0.3464, 0.3820, 0.4273],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5833])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4826], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5833])\n",
      ">>Entradas: tensor([0.3064, 0.3243, 0.3365, 0.3355, 0.3464, 0.3820, 0.4273, 0.4826],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5367], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6089])\n",
      ">>Entradas: tensor([0.3243, 0.3365, 0.3355, 0.3464, 0.3820, 0.4273, 0.4826, 0.5367],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5980])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5744], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5980])\n",
      ">>Entradas: tensor([0.3365, 0.3355, 0.3464, 0.3820, 0.4273, 0.4826, 0.5367, 0.5744],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5945])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6026], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5945])\n",
      ">>Entradas: tensor([0.3355, 0.3464, 0.3820, 0.4273, 0.4826, 0.5367, 0.5744, 0.6026],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5985])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6297], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5985])\n",
      ">>Entradas: tensor([0.3464, 0.3820, 0.4273, 0.4826, 0.5367, 0.5744, 0.6026, 0.6297],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6214])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6593], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6214])\n",
      ">>Entradas: tensor([0.3820, 0.4273, 0.4826, 0.5367, 0.5744, 0.6026, 0.6297, 0.6593],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6631])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6938], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6631])\n",
      ">>Entradas: tensor([0.4273, 0.4826, 0.5367, 0.5744, 0.6026, 0.6297, 0.6593, 0.6938],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6929])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7275], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6929])\n",
      ">>Entradas: tensor([0.4826, 0.5367, 0.5744, 0.6026, 0.6297, 0.6593, 0.6938, 0.7275],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7107])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7536], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7107])\n",
      ">>Entradas: tensor([0.5367, 0.5744, 0.6026, 0.6297, 0.6593, 0.6938, 0.7275, 0.7536],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7217])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7698], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7217])\n",
      ">>Entradas: tensor([0.5744, 0.6026, 0.6297, 0.6593, 0.6938, 0.7275, 0.7536, 0.7698],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7259])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7789], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7259])\n",
      ">>Entradas: tensor([0.6026, 0.6297, 0.6593, 0.6938, 0.7275, 0.7536, 0.7698, 0.7789],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7404])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7759], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7404])\n",
      ">>Entradas: tensor([0.6297, 0.6593, 0.6938, 0.7275, 0.7536, 0.7698, 0.7789, 0.7759],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7652])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7902], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7652])\n",
      ">>Entradas: tensor([0.6593, 0.6938, 0.7275, 0.7536, 0.7698, 0.7789, 0.7759, 0.7902],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7448])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7920], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7448])\n",
      ">>Entradas: tensor([0.6938, 0.7275, 0.7536, 0.7698, 0.7789, 0.7759, 0.7902, 0.7920],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6792])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7714], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6792])\n",
      ">>Entradas: tensor([0.7275, 0.7536, 0.7698, 0.7789, 0.7759, 0.7902, 0.7920, 0.7714],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6746])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7523], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6746])\n",
      ">>Entradas: tensor([0.7536, 0.7698, 0.7789, 0.7759, 0.7902, 0.7920, 0.7714, 0.7523],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7505], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7309])\n",
      ">>Entradas: tensor([0.7698, 0.7789, 0.7759, 0.7902, 0.7920, 0.7714, 0.7523, 0.7505],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7467])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7469], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7467])\n",
      ">>Entradas: tensor([0.7789, 0.7759, 0.7902, 0.7920, 0.7714, 0.7523, 0.7505, 0.7469],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7219])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7364], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7219])\n",
      ">>Entradas: tensor([0.7759, 0.7902, 0.7920, 0.7714, 0.7523, 0.7505, 0.7469, 0.7364],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7199])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7325], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7199])\n",
      ">>Entradas: tensor([0.7902, 0.7920, 0.7714, 0.7523, 0.7505, 0.7469, 0.7364, 0.7325],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7407])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7311], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7407])\n",
      ">>Entradas: tensor([0.7920, 0.7714, 0.7523, 0.7505, 0.7469, 0.7364, 0.7325, 0.7311],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7362])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7236], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7362])\n",
      ">>Entradas: tensor([0.7714, 0.7523, 0.7505, 0.7469, 0.7364, 0.7325, 0.7311, 0.7236],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7123], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7065])\n",
      ">>Entradas: tensor([0.7523, 0.7505, 0.7469, 0.7364, 0.7325, 0.7311, 0.7236, 0.7123],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6979])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7057], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6979])\n",
      ">>Entradas: tensor([0.7505, 0.7469, 0.7364, 0.7325, 0.7311, 0.7236, 0.7123, 0.7057],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7106])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7028], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7106])\n",
      ">>Entradas: tensor([0.7469, 0.7364, 0.7325, 0.7311, 0.7236, 0.7123, 0.7057, 0.7028],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7210])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7027], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7210])\n",
      ">>Entradas: tensor([0.7364, 0.7325, 0.7311, 0.7236, 0.7123, 0.7057, 0.7028, 0.7027],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7291])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7073], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7291])\n",
      ">>Entradas: tensor([0.7325, 0.7311, 0.7236, 0.7123, 0.7057, 0.7028, 0.7027, 0.7073],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7674])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7230], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7674])\n",
      ">>Entradas: tensor([0.7311, 0.7236, 0.7123, 0.7057, 0.7028, 0.7027, 0.7073, 0.7230],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8359])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7542], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8359])\n",
      ">>Entradas: tensor([0.7236, 0.7123, 0.7057, 0.7028, 0.7027, 0.7073, 0.7230, 0.7542],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8510])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7822], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8510])\n",
      ">>Entradas: tensor([0.7123, 0.7057, 0.7028, 0.7027, 0.7073, 0.7230, 0.7542, 0.7822],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8127])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7948], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8127])\n",
      ">>Entradas: tensor([0.7057, 0.7028, 0.7027, 0.7073, 0.7230, 0.7542, 0.7822, 0.7948],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7864])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7997], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7864])\n",
      ">>Entradas: tensor([0.7028, 0.7027, 0.7073, 0.7230, 0.7542, 0.7822, 0.7948, 0.7997],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7720])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7998], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7720])\n",
      ">>Entradas: tensor([0.7027, 0.7073, 0.7230, 0.7542, 0.7822, 0.7948, 0.7997, 0.7998],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8088], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.7073, 0.7230, 0.7542, 0.7822, 0.7948, 0.7997, 0.7998, 0.8088],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8803])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8401], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8803])\n",
      ">>Entradas: tensor([0.7230, 0.7542, 0.7822, 0.7948, 0.7997, 0.7998, 0.8088, 0.8401],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8987])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8701], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8987])\n",
      ">>Entradas: tensor([0.7542, 0.7822, 0.7948, 0.7997, 0.7998, 0.8088, 0.8401, 0.8701],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8787], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.7822, 0.7948, 0.7997, 0.7998, 0.8088, 0.8401, 0.8701, 0.8787],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8746], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8309])\n",
      ">>Entradas: tensor([0.7948, 0.7997, 0.7998, 0.8088, 0.8401, 0.8701, 0.8787, 0.8746],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8156])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8648], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8156])\n",
      ">>Entradas: tensor([0.7997, 0.7998, 0.8088, 0.8401, 0.8701, 0.8787, 0.8746, 0.8648],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8530], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8117])\n",
      ">>Entradas: tensor([0.7998, 0.8088, 0.8401, 0.8701, 0.8787, 0.8746, 0.8648, 0.8530],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8192])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8476], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8192])\n",
      ">>Entradas: tensor([0.8088, 0.8401, 0.8701, 0.8787, 0.8746, 0.8648, 0.8530, 0.8476],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8218])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8479], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8218])\n",
      ">>Entradas: tensor([0.8401, 0.8701, 0.8787, 0.8746, 0.8648, 0.8530, 0.8476, 0.8479],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8442], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8197])\n",
      ">>Entradas: tensor([0.8701, 0.8787, 0.8746, 0.8648, 0.8530, 0.8476, 0.8479, 0.8442],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8179])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8358], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8179])\n",
      ">>Entradas: tensor([0.8787, 0.8746, 0.8648, 0.8530, 0.8476, 0.8479, 0.8442, 0.8358],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8163])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8271], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8163])\n",
      ">>Entradas: tensor([0.8746, 0.8648, 0.8530, 0.8476, 0.8479, 0.8442, 0.8358, 0.8271],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8006])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8145], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8006])\n",
      ">>Entradas: tensor([0.8648, 0.8530, 0.8476, 0.8479, 0.8442, 0.8358, 0.8271, 0.8145],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7705])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7961], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7705])\n",
      ">>Entradas: tensor([0.8530, 0.8476, 0.8479, 0.8442, 0.8358, 0.8271, 0.8145, 0.7961],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7427])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7755], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7427])\n",
      ">>Entradas: tensor([0.8476, 0.8479, 0.8442, 0.8358, 0.8271, 0.8145, 0.7961, 0.7755],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7536], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7169])\n",
      ">>Entradas: tensor([0.8479, 0.8442, 0.8358, 0.8271, 0.8145, 0.7961, 0.7755, 0.7536],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7365], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7197])\n",
      ">>Entradas: tensor([0.8442, 0.8358, 0.8271, 0.8145, 0.7961, 0.7755, 0.7536, 0.7365],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7509])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7321], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7509])\n",
      ">>Entradas: tensor([0.8358, 0.8271, 0.8145, 0.7961, 0.7755, 0.7536, 0.7365, 0.7321],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7403])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7252], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7403])\n",
      ">>Entradas: tensor([0.8271, 0.8145, 0.7961, 0.7755, 0.7536, 0.7365, 0.7321, 0.7252],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7042], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.8145, 0.7961, 0.7755, 0.7536, 0.7365, 0.7321, 0.7252, 0.7042],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6688])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6840], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6688])\n",
      ">>Entradas: tensor([0.7961, 0.7755, 0.7536, 0.7365, 0.7321, 0.7252, 0.7042, 0.6840],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6835])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6732], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6835])\n",
      ">>Entradas: tensor([0.7755, 0.7536, 0.7365, 0.7321, 0.7252, 0.7042, 0.6840, 0.6732],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6652], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.7536, 0.7365, 0.7321, 0.7252, 0.7042, 0.6840, 0.6732, 0.6652],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6815])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6601], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6815])\n",
      ">>Entradas: tensor([0.7365, 0.7321, 0.7252, 0.7042, 0.6840, 0.6732, 0.6652, 0.6601],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6893])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6626], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6893])\n",
      ">>Entradas: tensor([0.7321, 0.7252, 0.7042, 0.6840, 0.6732, 0.6652, 0.6601, 0.6626],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7111])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6700], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7111])\n",
      ">>Entradas: tensor([0.7252, 0.7042, 0.6840, 0.6732, 0.6652, 0.6601, 0.6626, 0.6700],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7349])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6807], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7349])\n",
      ">>Entradas: tensor([0.7042, 0.6840, 0.6732, 0.6652, 0.6601, 0.6626, 0.6700, 0.6807],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7608])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6991], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7608])\n",
      ">>Entradas: tensor([0.6840, 0.6732, 0.6652, 0.6601, 0.6626, 0.6700, 0.6807, 0.6991],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7711])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7192], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7711])\n",
      ">>Entradas: tensor([0.6732, 0.6652, 0.6601, 0.6626, 0.6700, 0.6807, 0.6991, 0.7192],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7660])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7345], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7660])\n",
      ">>Entradas: tensor([0.6652, 0.6601, 0.6626, 0.6700, 0.6807, 0.6991, 0.7192, 0.7345],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7483])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7432], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7483])\n",
      ">>Entradas: tensor([0.6601, 0.6626, 0.6700, 0.6807, 0.6991, 0.7192, 0.7345, 0.7432],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7182])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7434], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7182])\n",
      ">>Entradas: tensor([0.6626, 0.6700, 0.6807, 0.6991, 0.7192, 0.7345, 0.7432, 0.7434],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7411], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7089])\n",
      ">>Entradas: tensor([0.6700, 0.6807, 0.6991, 0.7192, 0.7345, 0.7432, 0.7434, 0.7411],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7204])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7428], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7204])\n",
      ">>Entradas: tensor([0.6807, 0.6991, 0.7192, 0.7345, 0.7432, 0.7434, 0.7411, 0.7428],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7706])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7590], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7706])\n",
      ">>Entradas: tensor([0.6991, 0.7192, 0.7345, 0.7432, 0.7434, 0.7411, 0.7428, 0.7590],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8595])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7961], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8595])\n",
      ">>Entradas: tensor([0.7192, 0.7345, 0.7432, 0.7434, 0.7411, 0.7428, 0.7590, 0.7961],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8360], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9065])\n",
      ">>Entradas: tensor([0.7345, 0.7432, 0.7434, 0.7411, 0.7428, 0.7590, 0.7961, 0.8360],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9119])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8666], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9119])\n",
      ">>Entradas: tensor([0.7432, 0.7434, 0.7411, 0.7428, 0.7590, 0.7961, 0.8360, 0.8666],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9043])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8877], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9043])\n",
      ">>Entradas: tensor([0.7434, 0.7411, 0.7428, 0.7590, 0.7961, 0.8360, 0.8666, 0.8877],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8839])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8976], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8839])\n",
      ">>Entradas: tensor([0.7411, 0.7428, 0.7590, 0.7961, 0.8360, 0.8666, 0.8877, 0.8976],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9032])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9111], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9032])\n",
      ">>Entradas: tensor([0.7428, 0.7590, 0.7961, 0.8360, 0.8666, 0.8877, 0.8976, 0.9111],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9623])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9413], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9623])\n",
      ">>Entradas: tensor([0.7590, 0.7961, 0.8360, 0.8666, 0.8877, 0.8976, 0.9111, 0.9413],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9821])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9712], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9821])\n",
      ">>Entradas: tensor([0.7961, 0.8360, 0.8666, 0.8877, 0.8976, 0.9111, 0.9413, 0.9712],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9624])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9859], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9624])\n",
      ">>Entradas: tensor([0.8360, 0.8666, 0.8877, 0.8976, 0.9111, 0.9413, 0.9712, 0.9859],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9303])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9834], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9303])\n",
      ">>Entradas: tensor([0.8666, 0.8877, 0.8976, 0.9111, 0.9413, 0.9712, 0.9859, 0.9834],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8855])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9665], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8855])\n",
      ">>Entradas: tensor([0.8877, 0.8976, 0.9111, 0.9413, 0.9712, 0.9859, 0.9834, 0.9665],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8597])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9415], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8597])\n",
      ">>Entradas: tensor([0.8976, 0.9111, 0.9413, 0.9712, 0.9859, 0.9834, 0.9665, 0.9415],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8529])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9206], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8529])\n",
      ">>Entradas: tensor([0.9111, 0.9413, 0.9712, 0.9859, 0.9834, 0.9665, 0.9415, 0.9206],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9070], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.9413, 0.9712, 0.9859, 0.9834, 0.9665, 0.9415, 0.9206, 0.9070],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8769])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8997], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8769])\n",
      ">>Entradas: tensor([0.9712, 0.9859, 0.9834, 0.9665, 0.9415, 0.9206, 0.9070, 0.8997],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8806])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8912], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8806])\n",
      ">>Entradas: tensor([0.9859, 0.9834, 0.9665, 0.9415, 0.9206, 0.9070, 0.8997, 0.8912],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8699])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8787], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8699])\n",
      ">>Entradas: tensor([0.9834, 0.9665, 0.9415, 0.9206, 0.9070, 0.8997, 0.8912, 0.8787],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8465])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8602], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8465])\n",
      ">>Entradas: tensor([0.9665, 0.9415, 0.9206, 0.9070, 0.8997, 0.8912, 0.8787, 0.8602],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8104])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8353], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8104])\n",
      ">>Entradas: tensor([0.9415, 0.9206, 0.9070, 0.8997, 0.8912, 0.8787, 0.8602, 0.8353],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8026])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8161], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8026])\n",
      ">>Entradas: tensor([0.9206, 0.9070, 0.8997, 0.8912, 0.8787, 0.8602, 0.8353, 0.8161],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8232])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8096], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8232])\n",
      ">>Entradas: tensor([0.9070, 0.8997, 0.8912, 0.8787, 0.8602, 0.8353, 0.8161, 0.8096],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8397])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8103], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8397])\n",
      ">>Entradas: tensor([0.8997, 0.8912, 0.8787, 0.8602, 0.8353, 0.8161, 0.8096, 0.8103],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8522])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8148], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8522])\n",
      ">>Entradas: tensor([0.8912, 0.8787, 0.8602, 0.8353, 0.8161, 0.8096, 0.8103, 0.8148],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8616])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8218], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8616])\n",
      ">>Entradas: tensor([0.8787, 0.8602, 0.8353, 0.8161, 0.8096, 0.8103, 0.8148, 0.8218],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8679])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8285], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8679])\n",
      ">>Entradas: tensor([0.8602, 0.8353, 0.8161, 0.8096, 0.8103, 0.8148, 0.8218, 0.8285],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8702])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8346], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8702])\n",
      ">>Entradas: tensor([0.8353, 0.8161, 0.8096, 0.8103, 0.8148, 0.8218, 0.8285, 0.8346],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8685])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8417], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8685])\n",
      ">>Entradas: tensor([0.8161, 0.8096, 0.8103, 0.8148, 0.8218, 0.8285, 0.8346, 0.8417],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8530])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8458], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8530])\n",
      ">>Entradas: tensor([0.8096, 0.8103, 0.8148, 0.8218, 0.8285, 0.8346, 0.8417, 0.8458],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8236])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8418], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8236])\n",
      ">>Entradas: tensor([0.8103, 0.8148, 0.8218, 0.8285, 0.8346, 0.8417, 0.8458, 0.8418],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8338], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.8148, 0.8218, 0.8285, 0.8346, 0.8417, 0.8458, 0.8418, 0.8338],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7919])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8243], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7919])\n",
      ">>Entradas: tensor([0.8218, 0.8285, 0.8346, 0.8417, 0.8458, 0.8418, 0.8338, 0.8243],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7865])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8142], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7865])\n",
      ">>Entradas: tensor([0.8285, 0.8346, 0.8417, 0.8458, 0.8418, 0.8338, 0.8243, 0.8142],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7870])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8061], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7870])\n",
      ">>Entradas: tensor([0.8346, 0.8417, 0.8458, 0.8418, 0.8338, 0.8243, 0.8142, 0.8061],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7874])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7998], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7874])\n",
      ">>Entradas: tensor([0.8417, 0.8458, 0.8418, 0.8338, 0.8243, 0.8142, 0.8061, 0.7998],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7879])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7938], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7879])\n",
      ">>Entradas: tensor([0.8458, 0.8418, 0.8338, 0.8243, 0.8142, 0.8061, 0.7998, 0.7938],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7955])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7900], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7955])\n",
      ">>Entradas: tensor([0.8418, 0.8338, 0.8243, 0.8142, 0.8061, 0.7998, 0.7938, 0.7900],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8102])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7940], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8102])\n",
      ">>Entradas: tensor([0.8338, 0.8243, 0.8142, 0.8061, 0.7998, 0.7938, 0.7900, 0.7940],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7668])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7811], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7668])\n",
      ">>Entradas: tensor([0.8243, 0.8142, 0.8061, 0.7998, 0.7938, 0.7900, 0.7940, 0.7811],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6655])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7427], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6655])\n",
      ">>Entradas: tensor([0.8142, 0.8061, 0.7998, 0.7938, 0.7900, 0.7940, 0.7811, 0.7427],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6361])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7071], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6361])\n",
      ">>Entradas: tensor([0.8061, 0.7998, 0.7938, 0.7900, 0.7940, 0.7811, 0.7427, 0.7071],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6785])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6917], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6785])\n",
      ">>Entradas: tensor([0.7998, 0.7938, 0.7900, 0.7940, 0.7811, 0.7427, 0.7071, 0.6917],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6824], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6966])\n",
      ">>Entradas: tensor([0.7938, 0.7900, 0.7940, 0.7811, 0.7427, 0.7071, 0.6917, 0.6824],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6903])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6751], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6903])\n",
      ">>Entradas: tensor([0.7900, 0.7940, 0.7811, 0.7427, 0.7071, 0.6917, 0.6824, 0.6751],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6970])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6747], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6970])\n",
      ">>Entradas: tensor([0.7940, 0.7811, 0.7427, 0.7071, 0.6917, 0.6824, 0.6751, 0.6747],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7167])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6760], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7167])\n",
      ">>Entradas: tensor([0.7811, 0.7427, 0.7071, 0.6917, 0.6824, 0.6751, 0.6747, 0.6760],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7491])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6828], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7491])\n",
      ">>Entradas: tensor([0.7427, 0.7071, 0.6917, 0.6824, 0.6751, 0.6747, 0.6760, 0.6828],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7940])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7056], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7940])\n",
      ">>Entradas: tensor([0.7071, 0.6917, 0.6824, 0.6751, 0.6747, 0.6760, 0.6828, 0.7056],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8547])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7466], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8547])\n",
      ">>Entradas: tensor([0.6917, 0.6824, 0.6751, 0.6747, 0.6760, 0.6828, 0.7056, 0.7466],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9314])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8030], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9314])\n",
      ">>Entradas: tensor([0.6824, 0.6751, 0.6747, 0.6760, 0.6828, 0.7056, 0.7466, 0.8030],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9627])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8578], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9627])\n",
      ">>Entradas: tensor([0.6751, 0.6747, 0.6760, 0.6828, 0.7056, 0.7466, 0.8030, 0.8578],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9486])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8988], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9486])\n",
      ">>Entradas: tensor([0.6747, 0.6760, 0.6828, 0.7056, 0.7466, 0.8030, 0.8578, 0.8988],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9307])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9269], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9307])\n",
      ">>Entradas: tensor([0.6760, 0.6828, 0.7056, 0.7466, 0.8030, 0.8578, 0.8988, 0.9269],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9090])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9411], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9090])\n",
      ">>Entradas: tensor([0.6828, 0.7056, 0.7466, 0.8030, 0.8578, 0.8988, 0.9269, 0.9411],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8816])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9429], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8816])\n",
      ">>Entradas: tensor([0.7056, 0.7466, 0.8030, 0.8578, 0.8988, 0.9269, 0.9411, 0.9429],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8487])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9397], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8487])\n",
      ">>Entradas: tensor([0.7466, 0.8030, 0.8578, 0.8988, 0.9269, 0.9411, 0.9429, 0.9397],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8753])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9437], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8753])\n",
      ">>Entradas: tensor([0.8030, 0.8578, 0.8988, 0.9269, 0.9411, 0.9429, 0.9397, 0.9437],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9612])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9664], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9612])\n",
      ">>Entradas: tensor([0.8578, 0.8988, 0.9269, 0.9411, 0.9429, 0.9397, 0.9437, 0.9664],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9925])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9863], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9925])\n",
      ">>Entradas: tensor([0.8988, 0.9269, 0.9411, 0.9429, 0.9397, 0.9437, 0.9664, 0.9863],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9690])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9907], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9690])\n",
      ">>Entradas: tensor([0.9269, 0.9411, 0.9429, 0.9397, 0.9437, 0.9664, 0.9863, 0.9907],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9715])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9923], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9715])\n",
      ">>Entradas: tensor([0.9411, 0.9429, 0.9397, 0.9437, 0.9664, 0.9863, 0.9907, 0.9923],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([1.])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9988], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([1.])\n",
      ">>Entradas: tensor([0.9429, 0.9397, 0.9437, 0.9664, 0.9863, 0.9907, 0.9923, 0.9988],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9949], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9801])\n",
      ">>Entradas: tensor([0.9397, 0.9437, 0.9664, 0.9863, 0.9907, 0.9923, 0.9988, 0.9949],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9744], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9117])\n",
      ">>Entradas: tensor([0.9437, 0.9664, 0.9863, 0.9907, 0.9923, 0.9988, 0.9949, 0.9744],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8911])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9566], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8911])\n",
      ">>Entradas: tensor([0.9664, 0.9863, 0.9907, 0.9923, 0.9988, 0.9949, 0.9744, 0.9566],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9181])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9474], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9181])\n",
      ">>Entradas: tensor([0.9863, 0.9907, 0.9923, 0.9988, 0.9949, 0.9744, 0.9566, 0.9474],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9450])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9434], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9450])\n",
      ">>Entradas: tensor([0.9907, 0.9923, 0.9988, 0.9949, 0.9744, 0.9566, 0.9474, 0.9434],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9718])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9489], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9718])\n",
      ">>Entradas: tensor([0.9923, 0.9988, 0.9949, 0.9744, 0.9566, 0.9474, 0.9434, 0.9489],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9829])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9606], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9829])\n",
      ">>Entradas: tensor([0.9988, 0.9949, 0.9744, 0.9566, 0.9474, 0.9434, 0.9489, 0.9606],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9783])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9620], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9783])\n",
      ">>s_original: [0.049424633383750916, 0.10789185762405396, 0.13719609379768372, 0.13733737170696259, 0.1338856965303421, 0.12684109807014465, 0.14756061136722565, 0.19604423642158508, 0.21688967943191528, 0.21009695529937744, 0.20267784595489502, 0.1946323662996292, 0.19407351315021515, 0.20100130140781403, 0.19663821160793304, 0.180984228849411, 0.16539041697978973, 0.14985674619674683, 0.15043111145496368, 0.1671135276556015, 0.20227035880088806, 0.25590160489082336, 0.29268819093704224, 0.31263017654418945, 0.31093889474868774, 0.2876143157482147, 0.28016164898872375, 0.28858086466789246, 0.28246283531188965, 0.26180753111839294, 0.2801212966442108, 0.3374040722846985, 0.3482298254966736, 0.3125985562801361, 0.34358710050582886, 0.44119545817375183, 0.521095335483551, 0.5832866430282593, 0.6089234352111816, 0.5980057120323181, 0.5945301651954651, 0.5984968543052673, 0.621354341506958, 0.6631026864051819, 0.6928724050521851, 0.7106636166572571, 0.721682071685791, 0.7259277701377869, 0.7404318451881409, 0.7651942372322083, 0.7447891235351562, 0.6792163252830505, 0.6746017932891846, 0.730945348739624, 0.7467210292816162, 0.7219287157058716, 0.7199286818504333, 0.7407209277153015, 0.7362455129623413, 0.7065023183822632, 0.6979451775550842, 0.7105739712715149, 0.7209621667861938, 0.7291097044944763, 0.7674259543418884, 0.8359109163284302, 0.8510103225708008, 0.8127241730690002, 0.7863940000534058, 0.7720199823379517, 0.8033170700073242, 0.8802852630615234, 0.8987051844596863, 0.8585767149925232, 0.8308762311935425, 0.8156037926673889, 0.8116992115974426, 0.8191625475883484, 0.8218275904655457, 0.8196942210197449, 0.817862868309021, 0.8163333535194397, 0.8005555868148804, 0.7705295085906982, 0.7426586747169495, 0.716943085193634, 0.7197051048278809, 0.7509447932243347, 0.7402781248092651, 0.6877052187919617, 0.6687695384025574, 0.683471143245697, 0.6877052187919617, 0.6814717054367065, 0.6892618536949158, 0.7110756039619446, 0.7349108457565308, 0.7607676982879639, 0.771117091178894, 0.7659589648246765, 0.7483323812484741, 0.7182371616363525, 0.708941638469696, 0.7204458117485046, 0.7706154584884644, 0.8594506978988647, 0.906541109085083, 0.9118866324424744, 0.9043355584144592, 0.8838878870010376, 0.9032153487205505, 0.9623178839683533, 0.9820588231086731, 0.96243816614151, 0.9302511811256409, 0.8854979276657104, 0.8597025871276855, 0.8528652191162109, 0.8585854768753052, 0.8768633008003235, 0.8806464076042175, 0.8699347376823425, 0.846513569355011, 0.8103827834129333, 0.8026111125946045, 0.8231984972953796, 0.8397204279899597, 0.8521769046783447, 0.8615626692771912, 0.8678776621818542, 0.8701963424682617, 0.868518590927124, 0.852988064289093, 0.8236046433448792, 0.8032509088516235, 0.7919268012046814, 0.7865023016929626, 0.7869773507118225, 0.7874362468719482, 0.7878790497779846, 0.7954531908035278, 0.8101586699485779, 0.7668473124504089, 0.665519118309021, 0.6360738277435303, 0.678511381149292, 0.6965967416763306, 0.6903298497200012, 0.6970472931861877, 0.7167490720748901, 0.7490506768226624, 0.7939522862434387, 0.8547447323799133, 0.931428074836731, 0.9627243876457214, 0.9486336708068848, 0.9307146072387695, 0.9089671969413757, 0.8816379904747009, 0.8487268090248108, 0.8752607107162476, 0.9612395763397217, 0.9925020933151245, 0.9690483212471008, 0.9715476036071777, 1.0, 0.9800636768341064, 0.9117385745048523, 0.8910858035087585, 0.9181053042411804, 0.9450165033340454, 0.9718193411827087, 0.982906699180603, 0.9782785773277283]\n",
      ">>s_pred: [0.025539398193359375, 0.05060577392578125, 0.07870769500732422, 0.09539794921875, 0.10894393920898438, 0.1188802719116211, 0.13249588012695312, 0.15938377380371094, 0.18641090393066406, 0.2034454345703125, 0.21451759338378906, 0.21985340118408203, 0.2222423553466797, 0.22701072692871094, 0.22826671600341797, 0.2240276336669922, 0.21372604370117188, 0.1989288330078125, 0.1856536865234375, 0.1793661117553711, 0.1837148666381836, 0.20119571685791016, 0.22367000579833984, 0.24591636657714844, 0.2635974884033203, 0.2726306915283203, 0.2807655334472656, 0.29251670837402344, 0.30065441131591797, 0.30095958709716797, 0.30643558502197266, 0.32425880432128906, 0.33650970458984375, 0.33545589447021484, 0.3463726043701172, 0.3820466995239258, 0.4273357391357422, 0.4826231002807617, 0.5367050170898438, 0.574371337890625, 0.6025543212890625, 0.6296663284301758, 0.6593475341796875, 0.6938047409057617, 0.7274770736694336, 0.7536067962646484, 0.7698421478271484, 0.778935432434082, 0.7758722305297852, 0.7901535034179688, 0.792027473449707, 0.7713775634765625, 0.7522649765014648, 0.7505149841308594, 0.7469310760498047, 0.7364387512207031, 0.7324666976928711, 0.7310943603515625, 0.7235832214355469, 0.7123394012451172, 0.7056732177734375, 0.7027654647827148, 0.7026920318603516, 0.7072896957397461, 0.7229738235473633, 0.7541656494140625, 0.7821969985961914, 0.794795036315918, 0.7997398376464844, 0.7998485565185547, 0.8087673187255859, 0.840092658996582, 0.8701248168945312, 0.8786630630493164, 0.8745889663696289, 0.8648204803466797, 0.8530387878417969, 0.847564697265625, 0.8479232788085938, 0.8441591262817383, 0.8358478546142578, 0.8271484375, 0.8145046234130859, 0.7960872650146484, 0.7755413055419922, 0.7535600662231445, 0.7364673614501953, 0.7321290969848633, 0.7252225875854492, 0.7042465209960938, 0.6840000152587891, 0.6731901168823242, 0.6652212142944336, 0.6600542068481445, 0.662632942199707, 0.670018196105957, 0.6807260513305664, 0.6990966796875, 0.7192068099975586, 0.7344703674316406, 0.7432479858398438, 0.7433509826660156, 0.7410688400268555, 0.7428197860717773, 0.7589530944824219, 0.7960901260375977, 0.8359651565551758, 0.8665885925292969, 0.8876628875732422, 0.8975820541381836, 0.9110918045043945, 0.9413032531738281, 0.971160888671875, 0.9858913421630859, 0.9834375381469727, 0.9664974212646484, 0.9415445327758789, 0.9206418991088867, 0.9069585800170898, 0.8997325897216797, 0.8912458419799805, 0.8786649703979492, 0.8601541519165039, 0.8352775573730469, 0.8160629272460938, 0.8095607757568359, 0.8103113174438477, 0.8148431777954102, 0.8217535018920898, 0.8285427093505859, 0.8345699310302734, 0.8417186737060547, 0.8457984924316406, 0.8418416976928711, 0.833796501159668, 0.8242883682250977, 0.8141918182373047, 0.8060693740844727, 0.7998361587524414, 0.7938470840454102, 0.7900495529174805, 0.7940292358398438, 0.781071662902832, 0.742650032043457, 0.7070693969726562, 0.691737174987793, 0.6823740005493164, 0.6751337051391602, 0.6746625900268555, 0.6759576797485352, 0.6828098297119141, 0.7055883407592773, 0.7465705871582031, 0.8030414581298828, 0.8578271865844727, 0.8987960815429688, 0.9269018173217773, 0.9410905838012695, 0.9428930282592773, 0.9397058486938477, 0.9436893463134766, 0.9664220809936523, 0.9863004684448242, 0.9906520843505859, 0.9922971725463867, 0.9987506866455078, 0.9949159622192383, 0.9744119644165039, 0.9566011428833008, 0.9473714828491211, 0.9434404373168945, 0.9488935470581055, 0.9606075286865234, 0.9620418548583984]\n",
      "<<Perdida: 0.001697466941550374 epoca: 15\n",
      "---Inicio de epoca: 16--\n",
      ">>Entradas: tensor([0.0503, 0.0086, 0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203])\n",
      ">>Salida: tensor([0.0494])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0017], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.0494])\n",
      ">>Entradas: tensor([0.0086, 0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203, 0.0017],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1079])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0352], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1079])\n",
      ">>Entradas: tensor([0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203, 0.0017, 0.0352],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1372])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0678], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1372])\n",
      ">>Entradas: tensor([0.0245, 0.0327, 0.0246, 0.0205, 0.0203, 0.0017, 0.0352, 0.0678],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1373])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0839], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1373])\n",
      ">>Entradas: tensor([0.0327, 0.0246, 0.0205, 0.0203, 0.0017, 0.0352, 0.0678, 0.0839],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1339])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1018], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1339])\n",
      ">>Entradas: tensor([0.0246, 0.0205, 0.0203, 0.0017, 0.0352, 0.0678, 0.0839, 0.1018],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1268])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1166], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1268])\n",
      ">>Entradas: tensor([0.0205, 0.0203, 0.0017, 0.0352, 0.0678, 0.0839, 0.1018, 0.1166],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1476])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1287], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1476])\n",
      ">>Entradas: tensor([0.0203, 0.0017, 0.0352, 0.0678, 0.0839, 0.1018, 0.1166, 0.1287],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1960])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1572], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1960])\n",
      ">>Entradas: tensor([0.0017, 0.0352, 0.0678, 0.0839, 0.1018, 0.1166, 0.1287, 0.1572],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1890], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2169])\n",
      ">>Entradas: tensor([0.0352, 0.0678, 0.0839, 0.1018, 0.1166, 0.1287, 0.1572, 0.1890],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2101])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2084], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2101])\n",
      ">>Entradas: tensor([0.0678, 0.0839, 0.1018, 0.1166, 0.1287, 0.1572, 0.1890, 0.2084],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2027])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2217], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2027])\n",
      ">>Entradas: tensor([0.0839, 0.1018, 0.1166, 0.1287, 0.1572, 0.1890, 0.2084, 0.2217],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1946])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2298], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1946])\n",
      ">>Entradas: tensor([0.1018, 0.1166, 0.1287, 0.1572, 0.1890, 0.2084, 0.2217, 0.2298],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1941])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2317], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1941])\n",
      ">>Entradas: tensor([0.1166, 0.1287, 0.1572, 0.1890, 0.2084, 0.2217, 0.2298, 0.2317],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2010])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2349], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2010])\n",
      ">>Entradas: tensor([0.1287, 0.1572, 0.1890, 0.2084, 0.2217, 0.2298, 0.2317, 0.2349],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2383], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1966])\n",
      ">>Entradas: tensor([0.1572, 0.1890, 0.2084, 0.2217, 0.2298, 0.2317, 0.2349, 0.2383],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1810])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2334], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1810])\n",
      ">>Entradas: tensor([0.1890, 0.2084, 0.2217, 0.2298, 0.2317, 0.2349, 0.2383, 0.2334],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1654])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2220], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1654])\n",
      ">>Entradas: tensor([0.2084, 0.2217, 0.2298, 0.2317, 0.2349, 0.2383, 0.2334, 0.2220],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1499])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2065], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1499])\n",
      ">>Entradas: tensor([0.2217, 0.2298, 0.2317, 0.2349, 0.2383, 0.2334, 0.2220, 0.2065],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1504])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1916], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1504])\n",
      ">>Entradas: tensor([0.2298, 0.2317, 0.2349, 0.2383, 0.2334, 0.2220, 0.2065, 0.1916],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1671])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1826], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1671])\n",
      ">>Entradas: tensor([0.2317, 0.2349, 0.2383, 0.2334, 0.2220, 0.2065, 0.1916, 0.1826],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2023])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1851], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2023])\n",
      ">>Entradas: tensor([0.2349, 0.2383, 0.2334, 0.2220, 0.2065, 0.1916, 0.1826, 0.1851],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2559])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2011], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2559])\n",
      ">>Entradas: tensor([0.2383, 0.2334, 0.2220, 0.2065, 0.1916, 0.1826, 0.1851, 0.2011],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2927])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2265], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2927])\n",
      ">>Entradas: tensor([0.2334, 0.2220, 0.2065, 0.1916, 0.1826, 0.1851, 0.2011, 0.2265],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2465], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2220, 0.2065, 0.1916, 0.1826, 0.1851, 0.2011, 0.2265, 0.2465],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3109])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2638], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3109])\n",
      ">>Entradas: tensor([0.2065, 0.1916, 0.1826, 0.1851, 0.2011, 0.2265, 0.2465, 0.2638],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2876])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2735], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2876])\n",
      ">>Entradas: tensor([0.1916, 0.1826, 0.1851, 0.2011, 0.2265, 0.2465, 0.2638, 0.2735],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2802])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2820], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2802])\n",
      ">>Entradas: tensor([0.1826, 0.1851, 0.2011, 0.2265, 0.2465, 0.2638, 0.2735, 0.2820],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2886])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2944], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2886])\n",
      ">>Entradas: tensor([0.1851, 0.2011, 0.2265, 0.2465, 0.2638, 0.2735, 0.2820, 0.2944],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2825])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3044], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2825])\n",
      ">>Entradas: tensor([0.2011, 0.2265, 0.2465, 0.2638, 0.2735, 0.2820, 0.2944, 0.3044],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2618])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3060], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2618])\n",
      ">>Entradas: tensor([0.2265, 0.2465, 0.2638, 0.2735, 0.2820, 0.2944, 0.3044, 0.3060],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3118], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2801])\n",
      ">>Entradas: tensor([0.2465, 0.2638, 0.2735, 0.2820, 0.2944, 0.3044, 0.3060, 0.3118],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3374])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3300], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3374])\n",
      ">>Entradas: tensor([0.2638, 0.2735, 0.2820, 0.2944, 0.3044, 0.3060, 0.3118, 0.3300],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3482])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3423], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3482])\n",
      ">>Entradas: tensor([0.2735, 0.2820, 0.2944, 0.3044, 0.3060, 0.3118, 0.3300, 0.3423],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3412], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2820, 0.2944, 0.3044, 0.3060, 0.3118, 0.3300, 0.3423, 0.3412],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3436])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3525], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3436])\n",
      ">>Entradas: tensor([0.2944, 0.3044, 0.3060, 0.3118, 0.3300, 0.3423, 0.3412, 0.3525],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.4412])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3872], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.4412])\n",
      ">>Entradas: tensor([0.3044, 0.3060, 0.3118, 0.3300, 0.3423, 0.3412, 0.3525, 0.3872],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5211])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4326], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5211])\n",
      ">>Entradas: tensor([0.3060, 0.3118, 0.3300, 0.3423, 0.3412, 0.3525, 0.3872, 0.4326],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5833])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4892], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5833])\n",
      ">>Entradas: tensor([0.3118, 0.3300, 0.3423, 0.3412, 0.3525, 0.3872, 0.4326, 0.4892],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5458], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6089])\n",
      ">>Entradas: tensor([0.3300, 0.3423, 0.3412, 0.3525, 0.3872, 0.4326, 0.4892, 0.5458],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5980])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5860], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5980])\n",
      ">>Entradas: tensor([0.3423, 0.3412, 0.3525, 0.3872, 0.4326, 0.4892, 0.5458, 0.5860],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5945])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6165], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5945])\n",
      ">>Entradas: tensor([0.3412, 0.3525, 0.3872, 0.4326, 0.4892, 0.5458, 0.5860, 0.6165],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5985])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6457], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5985])\n",
      ">>Entradas: tensor([0.3525, 0.3872, 0.4326, 0.4892, 0.5458, 0.5860, 0.6165, 0.6457],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6214])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6758], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6214])\n",
      ">>Entradas: tensor([0.3872, 0.4326, 0.4892, 0.5458, 0.5860, 0.6165, 0.6457, 0.6758],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6631])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7110], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6631])\n",
      ">>Entradas: tensor([0.4326, 0.4892, 0.5458, 0.5860, 0.6165, 0.6457, 0.6758, 0.7110],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6929])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7447], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6929])\n",
      ">>Entradas: tensor([0.4892, 0.5458, 0.5860, 0.6165, 0.6457, 0.6758, 0.7110, 0.7447],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7107])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7708], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7107])\n",
      ">>Entradas: tensor([0.5458, 0.5860, 0.6165, 0.6457, 0.6758, 0.7110, 0.7447, 0.7708],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7217])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7867], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7217])\n",
      ">>Entradas: tensor([0.5860, 0.6165, 0.6457, 0.6758, 0.7110, 0.7447, 0.7708, 0.7867],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7259])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7947], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7259])\n",
      ">>Entradas: tensor([0.6165, 0.6457, 0.6758, 0.7110, 0.7447, 0.7708, 0.7867, 0.7947],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7404])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8011], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7404])\n",
      ">>Entradas: tensor([0.6457, 0.6758, 0.7110, 0.7447, 0.7708, 0.7867, 0.7947, 0.8011],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7652])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8102], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7652])\n",
      ">>Entradas: tensor([0.6758, 0.7110, 0.7447, 0.7708, 0.7867, 0.7947, 0.8011, 0.8102],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7448])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8088], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7448])\n",
      ">>Entradas: tensor([0.7110, 0.7447, 0.7708, 0.7867, 0.7947, 0.8011, 0.8102, 0.8088],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6792])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7856], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6792])\n",
      ">>Entradas: tensor([0.7447, 0.7708, 0.7867, 0.7947, 0.8011, 0.8102, 0.8088, 0.7856],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6746])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7630], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6746])\n",
      ">>Entradas: tensor([0.7708, 0.7867, 0.7947, 0.8011, 0.8102, 0.8088, 0.7856, 0.7630],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7568], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7309])\n",
      ">>Entradas: tensor([0.7867, 0.7947, 0.8011, 0.8102, 0.8088, 0.7856, 0.7630, 0.7568],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7467])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7511], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7467])\n",
      ">>Entradas: tensor([0.7947, 0.8011, 0.8102, 0.8088, 0.7856, 0.7630, 0.7568, 0.7511],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7219])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7391], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7219])\n",
      ">>Entradas: tensor([0.8011, 0.8102, 0.8088, 0.7856, 0.7630, 0.7568, 0.7511, 0.7391],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7199])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7314], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7199])\n",
      ">>Entradas: tensor([0.8102, 0.8088, 0.7856, 0.7630, 0.7568, 0.7511, 0.7391, 0.7314],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7407])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7277], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7407])\n",
      ">>Entradas: tensor([0.8088, 0.7856, 0.7630, 0.7568, 0.7511, 0.7391, 0.7314, 0.7277],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7362])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7225], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7362])\n",
      ">>Entradas: tensor([0.7856, 0.7630, 0.7568, 0.7511, 0.7391, 0.7314, 0.7277, 0.7225],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7084], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7065])\n",
      ">>Entradas: tensor([0.7630, 0.7568, 0.7511, 0.7391, 0.7314, 0.7277, 0.7225, 0.7084],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6979])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7005], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6979])\n",
      ">>Entradas: tensor([0.7568, 0.7511, 0.7391, 0.7314, 0.7277, 0.7225, 0.7084, 0.7005],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7106])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6976], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7106])\n",
      ">>Entradas: tensor([0.7511, 0.7391, 0.7314, 0.7277, 0.7225, 0.7084, 0.7005, 0.6976],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7210])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6970], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7210])\n",
      ">>Entradas: tensor([0.7391, 0.7314, 0.7277, 0.7225, 0.7084, 0.7005, 0.6976, 0.6970],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7291])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7010], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7291])\n",
      ">>Entradas: tensor([0.7314, 0.7277, 0.7225, 0.7084, 0.7005, 0.6976, 0.6970, 0.7010],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7674])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7179], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7674])\n",
      ">>Entradas: tensor([0.7277, 0.7225, 0.7084, 0.7005, 0.6976, 0.6970, 0.7010, 0.7179],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8359])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7502], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8359])\n",
      ">>Entradas: tensor([0.7225, 0.7084, 0.7005, 0.6976, 0.6970, 0.7010, 0.7179, 0.7502],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8510])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7786], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8510])\n",
      ">>Entradas: tensor([0.7084, 0.7005, 0.6976, 0.6970, 0.7010, 0.7179, 0.7502, 0.7786],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8127])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7928], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8127])\n",
      ">>Entradas: tensor([0.7005, 0.6976, 0.6970, 0.7010, 0.7179, 0.7502, 0.7786, 0.7928],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7864])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7998], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7864])\n",
      ">>Entradas: tensor([0.6976, 0.6970, 0.7010, 0.7179, 0.7502, 0.7786, 0.7928, 0.7998],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7720])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7974], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7720])\n",
      ">>Entradas: tensor([0.6970, 0.7010, 0.7179, 0.7502, 0.7786, 0.7928, 0.7998, 0.7974],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8084], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.7010, 0.7179, 0.7502, 0.7786, 0.7928, 0.7998, 0.7974, 0.8084],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8803])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8416], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8803])\n",
      ">>Entradas: tensor([0.7179, 0.7502, 0.7786, 0.7928, 0.7998, 0.7974, 0.8084, 0.8416],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8987])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8730], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8987])\n",
      ">>Entradas: tensor([0.7502, 0.7786, 0.7928, 0.7998, 0.7974, 0.8084, 0.8416, 0.8730],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8829], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.7786, 0.7928, 0.7998, 0.7974, 0.8084, 0.8416, 0.8730, 0.8829],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8800], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8309])\n",
      ">>Entradas: tensor([0.7928, 0.7998, 0.7974, 0.8084, 0.8416, 0.8730, 0.8829, 0.8800],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8156])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8707], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8156])\n",
      ">>Entradas: tensor([0.7998, 0.7974, 0.8084, 0.8416, 0.8730, 0.8829, 0.8800, 0.8707],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8578], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8117])\n",
      ">>Entradas: tensor([0.7974, 0.8084, 0.8416, 0.8730, 0.8829, 0.8800, 0.8707, 0.8578],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8192])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8528], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8192])\n",
      ">>Entradas: tensor([0.8084, 0.8416, 0.8730, 0.8829, 0.8800, 0.8707, 0.8578, 0.8528],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8218])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8529], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8218])\n",
      ">>Entradas: tensor([0.8416, 0.8730, 0.8829, 0.8800, 0.8707, 0.8578, 0.8528, 0.8529],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8484], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8197])\n",
      ">>Entradas: tensor([0.8730, 0.8829, 0.8800, 0.8707, 0.8578, 0.8528, 0.8529, 0.8484],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8179])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8393], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8179])\n",
      ">>Entradas: tensor([0.8829, 0.8800, 0.8707, 0.8578, 0.8528, 0.8529, 0.8484, 0.8393],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8163])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8295], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8163])\n",
      ">>Entradas: tensor([0.8800, 0.8707, 0.8578, 0.8528, 0.8529, 0.8484, 0.8393, 0.8295],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8006])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8152], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8006])\n",
      ">>Entradas: tensor([0.8707, 0.8578, 0.8528, 0.8529, 0.8484, 0.8393, 0.8295, 0.8152],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7705])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7953], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7705])\n",
      ">>Entradas: tensor([0.8578, 0.8528, 0.8529, 0.8484, 0.8393, 0.8295, 0.8152, 0.7953],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7427])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7613], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7427])\n",
      ">>Entradas: tensor([0.8528, 0.8529, 0.8484, 0.8393, 0.8295, 0.8152, 0.7953, 0.7613],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7417], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7169])\n",
      ">>Entradas: tensor([0.8529, 0.8484, 0.8393, 0.8295, 0.8152, 0.7953, 0.7613, 0.7417],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7249], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7197])\n",
      ">>Entradas: tensor([0.8484, 0.8393, 0.8295, 0.8152, 0.7953, 0.7613, 0.7417, 0.7249],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7509])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7202], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7509])\n",
      ">>Entradas: tensor([0.8393, 0.8295, 0.8152, 0.7953, 0.7613, 0.7417, 0.7249, 0.7202],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7403])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7135], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7403])\n",
      ">>Entradas: tensor([0.8295, 0.8152, 0.7953, 0.7613, 0.7417, 0.7249, 0.7202, 0.7135],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6941], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.8152, 0.7953, 0.7613, 0.7417, 0.7249, 0.7202, 0.7135, 0.6941],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6688])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6725], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6688])\n",
      ">>Entradas: tensor([0.7953, 0.7613, 0.7417, 0.7249, 0.7202, 0.7135, 0.6941, 0.6725],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6835])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6945], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6835])\n",
      ">>Entradas: tensor([0.7613, 0.7417, 0.7249, 0.7202, 0.7135, 0.6941, 0.6725, 0.6945],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6787], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.7417, 0.7249, 0.7202, 0.7135, 0.6941, 0.6725, 0.6945, 0.6787],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6815])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6705], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6815])\n",
      ">>Entradas: tensor([0.7249, 0.7202, 0.7135, 0.6941, 0.6725, 0.6945, 0.6787, 0.6705],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6893])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6725], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6893])\n",
      ">>Entradas: tensor([0.7202, 0.7135, 0.6941, 0.6725, 0.6945, 0.6787, 0.6705, 0.6725],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7111])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6784], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7111])\n",
      ">>Entradas: tensor([0.7135, 0.6941, 0.6725, 0.6945, 0.6787, 0.6705, 0.6725, 0.6784],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7349])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6841], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7349])\n",
      ">>Entradas: tensor([0.6941, 0.6725, 0.6945, 0.6787, 0.6705, 0.6725, 0.6784, 0.6841],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7608])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7054], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7608])\n",
      ">>Entradas: tensor([0.6725, 0.6945, 0.6787, 0.6705, 0.6725, 0.6784, 0.6841, 0.7054],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7711])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7288], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7711])\n",
      ">>Entradas: tensor([0.6945, 0.6787, 0.6705, 0.6725, 0.6784, 0.6841, 0.7054, 0.7288],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7660])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7399], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7660])\n",
      ">>Entradas: tensor([0.6787, 0.6705, 0.6725, 0.6784, 0.6841, 0.7054, 0.7288, 0.7399],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7483])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7470], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7483])\n",
      ">>Entradas: tensor([0.6705, 0.6725, 0.6784, 0.6841, 0.7054, 0.7288, 0.7399, 0.7470],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7182])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7471], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7182])\n",
      ">>Entradas: tensor([0.6725, 0.6784, 0.6841, 0.7054, 0.7288, 0.7399, 0.7470, 0.7471],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6576], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7089])\n",
      "ERROR: la modificacion de los pesos di√≥ un error mayor: 0.002634258009493351, se regresa al estado anterior de la red\n",
      ">>Entradas: tensor([0.6784, 0.6841, 0.7054, 0.7288, 0.7399, 0.7470, 0.7471, 0.7581],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7204])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7472], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7204])\n",
      ">>Entradas: tensor([0.6841, 0.7054, 0.7288, 0.7399, 0.7470, 0.7471, 0.7581, 0.7472],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7706])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7650], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7706])\n",
      ">>Entradas: tensor([0.7054, 0.7288, 0.7399, 0.7470, 0.7471, 0.7581, 0.7472, 0.7650],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8595])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8024], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8595])\n",
      ">>Entradas: tensor([0.7288, 0.7399, 0.7470, 0.7471, 0.7581, 0.7472, 0.7650, 0.8024],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8408], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9065])\n",
      ">>Entradas: tensor([0.7399, 0.7470, 0.7471, 0.7581, 0.7472, 0.7650, 0.8024, 0.8408],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9119])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8707], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9119])\n",
      ">>Entradas: tensor([0.7470, 0.7471, 0.7581, 0.7472, 0.7650, 0.8024, 0.8408, 0.8707],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9043])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8952], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9043])\n",
      ">>Entradas: tensor([0.7471, 0.7581, 0.7472, 0.7650, 0.8024, 0.8408, 0.8707, 0.8952],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8839])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9058], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8839])\n",
      ">>Entradas: tensor([0.7581, 0.7472, 0.7650, 0.8024, 0.8408, 0.8707, 0.8952, 0.9058],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9032])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9169], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9032])\n",
      ">>Entradas: tensor([0.7472, 0.7650, 0.8024, 0.8408, 0.8707, 0.8952, 0.9058, 0.9169],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9623])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9481], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9623])\n",
      ">>Entradas: tensor([0.7650, 0.8024, 0.8408, 0.8707, 0.8952, 0.9058, 0.9169, 0.9481],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9821])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9791], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9821])\n",
      ">>Entradas: tensor([0.8024, 0.8408, 0.8707, 0.8952, 0.9058, 0.9169, 0.9481, 0.9791],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9624])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9943], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9624])\n",
      ">>Entradas: tensor([0.8408, 0.8707, 0.8952, 0.9058, 0.9169, 0.9481, 0.9791, 0.9943],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9303])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9946], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9303])\n",
      ">>Entradas: tensor([0.8707, 0.8952, 0.9058, 0.9169, 0.9481, 0.9791, 0.9943, 0.9946],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8855])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9776], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8855])\n",
      ">>Entradas: tensor([0.8952, 0.9058, 0.9169, 0.9481, 0.9791, 0.9943, 0.9946, 0.9776],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8597])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9506], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8597])\n",
      ">>Entradas: tensor([0.9058, 0.9169, 0.9481, 0.9791, 0.9943, 0.9946, 0.9776, 0.9506],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8529])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9273], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8529])\n",
      ">>Entradas: tensor([0.9169, 0.9481, 0.9791, 0.9943, 0.9946, 0.9776, 0.9506, 0.9273],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9128], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.9481, 0.9791, 0.9943, 0.9946, 0.9776, 0.9506, 0.9273, 0.9128],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8769])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9037], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8769])\n",
      ">>Entradas: tensor([0.9791, 0.9943, 0.9946, 0.9776, 0.9506, 0.9273, 0.9128, 0.9037],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8806])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8936], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8806])\n",
      ">>Entradas: tensor([0.9943, 0.9946, 0.9776, 0.9506, 0.9273, 0.9128, 0.9037, 0.8936],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8699])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8794], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8699])\n",
      ">>Entradas: tensor([0.9946, 0.9776, 0.9506, 0.9273, 0.9128, 0.9037, 0.8936, 0.8794],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8465])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8582], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8465])\n",
      ">>Entradas: tensor([0.9776, 0.9506, 0.9273, 0.9128, 0.9037, 0.8936, 0.8794, 0.8582],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8104])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8304], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8104])\n",
      ">>Entradas: tensor([0.9506, 0.9273, 0.9128, 0.9037, 0.8936, 0.8794, 0.8582, 0.8304],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8026])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8091], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8026])\n",
      ">>Entradas: tensor([0.9273, 0.9128, 0.9037, 0.8936, 0.8794, 0.8582, 0.8304, 0.8091],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8232])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8012], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8232])\n",
      ">>Entradas: tensor([0.9128, 0.9037, 0.8936, 0.8794, 0.8582, 0.8304, 0.8091, 0.8012],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8397])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8012], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8397])\n",
      ">>Entradas: tensor([0.9037, 0.8936, 0.8794, 0.8582, 0.8304, 0.8091, 0.8012, 0.8012],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8522])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8057], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8522])\n",
      ">>Entradas: tensor([0.8936, 0.8794, 0.8582, 0.8304, 0.8091, 0.8012, 0.8012, 0.8057],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8616])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8129], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8616])\n",
      ">>Entradas: tensor([0.8794, 0.8582, 0.8304, 0.8091, 0.8012, 0.8012, 0.8057, 0.8129],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8679])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8199], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8679])\n",
      ">>Entradas: tensor([0.8582, 0.8304, 0.8091, 0.8012, 0.8012, 0.8057, 0.8129, 0.8199],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8702])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8266], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8702])\n",
      ">>Entradas: tensor([0.8304, 0.8091, 0.8012, 0.8012, 0.8057, 0.8129, 0.8199, 0.8266],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8685])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8349], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8685])\n",
      ">>Entradas: tensor([0.8091, 0.8012, 0.8012, 0.8057, 0.8129, 0.8199, 0.8266, 0.8349],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8530])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8407], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8530])\n",
      ">>Entradas: tensor([0.8012, 0.8012, 0.8057, 0.8129, 0.8199, 0.8266, 0.8349, 0.8407],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8236])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8388], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8236])\n",
      ">>Entradas: tensor([0.8012, 0.8057, 0.8129, 0.8199, 0.8266, 0.8349, 0.8407, 0.8388],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8326], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.8057, 0.8129, 0.8199, 0.8266, 0.8349, 0.8407, 0.8388, 0.8326],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7919])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8239], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7919])\n",
      ">>Entradas: tensor([0.8129, 0.8199, 0.8266, 0.8349, 0.8407, 0.8388, 0.8326, 0.8239],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7865])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8149], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7865])\n",
      ">>Entradas: tensor([0.8199, 0.8266, 0.8349, 0.8407, 0.8388, 0.8326, 0.8239, 0.8149],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7870])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8073], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7870])\n",
      ">>Entradas: tensor([0.8266, 0.8349, 0.8407, 0.8388, 0.8326, 0.8239, 0.8149, 0.8073],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7874])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8014], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7874])\n",
      ">>Entradas: tensor([0.8349, 0.8407, 0.8388, 0.8326, 0.8239, 0.8149, 0.8073, 0.8014],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7879])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7954], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7879])\n",
      ">>Entradas: tensor([0.8407, 0.8388, 0.8326, 0.8239, 0.8149, 0.8073, 0.8014, 0.7954],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7955])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7914], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7955])\n",
      ">>Entradas: tensor([0.8388, 0.8326, 0.8239, 0.8149, 0.8073, 0.8014, 0.7954, 0.7914],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8102])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7919], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8102])\n",
      ">>Entradas: tensor([0.8326, 0.8239, 0.8149, 0.8073, 0.8014, 0.7954, 0.7914, 0.7919],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7668])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7789], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7668])\n",
      ">>Entradas: tensor([0.8239, 0.8149, 0.8073, 0.8014, 0.7954, 0.7914, 0.7919, 0.7789],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6655])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7402], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6655])\n",
      ">>Entradas: tensor([0.8149, 0.8073, 0.8014, 0.7954, 0.7914, 0.7919, 0.7789, 0.7402],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6361])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7034], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6361])\n",
      ">>Entradas: tensor([0.8073, 0.8014, 0.7954, 0.7914, 0.7919, 0.7789, 0.7402, 0.7034],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6785])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6866], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6785])\n",
      ">>Entradas: tensor([0.8014, 0.7954, 0.7914, 0.7919, 0.7789, 0.7402, 0.7034, 0.6866],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6763], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6966])\n",
      ">>Entradas: tensor([0.7954, 0.7914, 0.7919, 0.7789, 0.7402, 0.7034, 0.6866, 0.6763],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6903])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6678], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6903])\n",
      ">>Entradas: tensor([0.7914, 0.7919, 0.7789, 0.7402, 0.7034, 0.6866, 0.6763, 0.6678],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6970])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6662], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6970])\n",
      ">>Entradas: tensor([0.7919, 0.7789, 0.7402, 0.7034, 0.6866, 0.6763, 0.6678, 0.6662],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7167])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6673], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7167])\n",
      ">>Entradas: tensor([0.7789, 0.7402, 0.7034, 0.6866, 0.6763, 0.6678, 0.6662, 0.6673],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7491])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6736], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7491])\n",
      ">>Entradas: tensor([0.7402, 0.7034, 0.6866, 0.6763, 0.6678, 0.6662, 0.6673, 0.6736],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7940])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6962], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7940])\n",
      ">>Entradas: tensor([0.7034, 0.6866, 0.6763, 0.6678, 0.6662, 0.6673, 0.6736, 0.6962],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8547])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7384], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8547])\n",
      ">>Entradas: tensor([0.6866, 0.6763, 0.6678, 0.6662, 0.6673, 0.6736, 0.6962, 0.7384],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9314])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7974], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9314])\n",
      ">>Entradas: tensor([0.6763, 0.6678, 0.6662, 0.6673, 0.6736, 0.6962, 0.7384, 0.7974],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9627])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8556], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9627])\n",
      ">>Entradas: tensor([0.6678, 0.6662, 0.6673, 0.6736, 0.6962, 0.7384, 0.7974, 0.8556],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9486])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9009], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9486])\n",
      ">>Entradas: tensor([0.6662, 0.6673, 0.6736, 0.6962, 0.7384, 0.7974, 0.8556, 0.9009],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9307])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9335], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9307])\n",
      ">>Entradas: tensor([0.6673, 0.6736, 0.6962, 0.7384, 0.7974, 0.8556, 0.9009, 0.9335],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9090])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9537], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9090])\n",
      ">>Entradas: tensor([0.6736, 0.6962, 0.7384, 0.7974, 0.8556, 0.9009, 0.9335, 0.9537],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8816])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9623], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8816])\n",
      ">>Entradas: tensor([0.6962, 0.7384, 0.7974, 0.8556, 0.9009, 0.9335, 0.9537, 0.9623],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8487])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9608], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8487])\n",
      ">>Entradas: tensor([0.7384, 0.7974, 0.8556, 0.9009, 0.9335, 0.9537, 0.9623, 0.9608],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8753])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9661], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8753])\n",
      ">>Entradas: tensor([0.7974, 0.8556, 0.9009, 0.9335, 0.9537, 0.9623, 0.9608, 0.9661],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9612])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8401], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9612])\n",
      "ERROR: la modificacion de los pesos di√≥ un error mayor: 0.014678886160254478, se regresa al estado anterior de la red\n",
      ">>Entradas: tensor([0.8556, 0.9009, 0.9335, 0.9537, 0.9623, 0.9608, 0.9661, 1.0008],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9925])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0164], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9925])\n",
      ">>Entradas: tensor([0.9009, 0.9335, 0.9537, 0.9623, 0.9608, 0.9661, 1.0008, 1.0164],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9690])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0163], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9690])\n",
      ">>Entradas: tensor([0.9335, 0.9537, 0.9623, 0.9608, 0.9661, 1.0008, 1.0164, 1.0163],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9715])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0151], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9715])\n",
      ">>Entradas: tensor([0.9537, 0.9623, 0.9608, 0.9661, 1.0008, 1.0164, 1.0163, 1.0151],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([1.])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0175], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([1.])\n",
      ">>Entradas: tensor([0.9623, 0.9608, 0.9661, 1.0008, 1.0164, 1.0163, 1.0151, 1.0175],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0080], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9801])\n",
      ">>Entradas: tensor([0.9608, 0.9661, 1.0008, 1.0164, 1.0163, 1.0151, 1.0175, 1.0080],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9854], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9117])\n",
      ">>Entradas: tensor([0.9661, 1.0008, 1.0164, 1.0163, 1.0151, 1.0175, 1.0080, 0.9854],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8911])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9655], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8911])\n",
      ">>Entradas: tensor([1.0008, 1.0164, 1.0163, 1.0151, 1.0175, 1.0080, 0.9854, 0.9655],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9181])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9510], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9181])\n",
      ">>Entradas: tensor([1.0164, 1.0163, 1.0151, 1.0175, 1.0080, 0.9854, 0.9655, 0.9510],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9450])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9433], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9450])\n",
      ">>Entradas: tensor([1.0163, 1.0151, 1.0175, 1.0080, 0.9854, 0.9655, 0.9510, 0.9433],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9718])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9461], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9718])\n",
      ">>Entradas: tensor([1.0151, 1.0175, 1.0080, 0.9854, 0.9655, 0.9510, 0.9433, 0.9461],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9829])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9522], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9829])\n",
      ">>Entradas: tensor([1.0175, 1.0080, 0.9854, 0.9655, 0.9510, 0.9433, 0.9461, 0.9522],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9783])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9529], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9783])\n",
      ">>s_original: [0.049424633383750916, 0.10789185762405396, 0.13719609379768372, 0.13733737170696259, 0.1338856965303421, 0.12684109807014465, 0.14756061136722565, 0.19604423642158508, 0.21688967943191528, 0.21009695529937744, 0.20267784595489502, 0.1946323662996292, 0.19407351315021515, 0.20100130140781403, 0.19663821160793304, 0.180984228849411, 0.16539041697978973, 0.14985674619674683, 0.15043111145496368, 0.1671135276556015, 0.20227035880088806, 0.25590160489082336, 0.29268819093704224, 0.31263017654418945, 0.31093889474868774, 0.2876143157482147, 0.28016164898872375, 0.28858086466789246, 0.28246283531188965, 0.26180753111839294, 0.2801212966442108, 0.3374040722846985, 0.3482298254966736, 0.3125985562801361, 0.34358710050582886, 0.44119545817375183, 0.521095335483551, 0.5832866430282593, 0.6089234352111816, 0.5980057120323181, 0.5945301651954651, 0.5984968543052673, 0.621354341506958, 0.6631026864051819, 0.6928724050521851, 0.7106636166572571, 0.721682071685791, 0.7259277701377869, 0.7404318451881409, 0.7651942372322083, 0.7447891235351562, 0.6792163252830505, 0.6746017932891846, 0.730945348739624, 0.7467210292816162, 0.7219287157058716, 0.7199286818504333, 0.7407209277153015, 0.7362455129623413, 0.7065023183822632, 0.6979451775550842, 0.7105739712715149, 0.7209621667861938, 0.7291097044944763, 0.7674259543418884, 0.8359109163284302, 0.8510103225708008, 0.8127241730690002, 0.7863940000534058, 0.7720199823379517, 0.8033170700073242, 0.8802852630615234, 0.8987051844596863, 0.8585767149925232, 0.8308762311935425, 0.8156037926673889, 0.8116992115974426, 0.8191625475883484, 0.8218275904655457, 0.8196942210197449, 0.817862868309021, 0.8163333535194397, 0.8005555868148804, 0.7705295085906982, 0.7426586747169495, 0.716943085193634, 0.7197051048278809, 0.7509447932243347, 0.7402781248092651, 0.6877052187919617, 0.6687695384025574, 0.683471143245697, 0.6877052187919617, 0.6814717054367065, 0.6892618536949158, 0.7110756039619446, 0.7349108457565308, 0.7607676982879639, 0.771117091178894, 0.7659589648246765, 0.7483323812484741, 0.7182371616363525, 0.708941638469696, 0.7204458117485046, 0.7706154584884644, 0.8594506978988647, 0.906541109085083, 0.9118866324424744, 0.9043355584144592, 0.8838878870010376, 0.9032153487205505, 0.9623178839683533, 0.9820588231086731, 0.96243816614151, 0.9302511811256409, 0.8854979276657104, 0.8597025871276855, 0.8528652191162109, 0.8585854768753052, 0.8768633008003235, 0.8806464076042175, 0.8699347376823425, 0.846513569355011, 0.8103827834129333, 0.8026111125946045, 0.8231984972953796, 0.8397204279899597, 0.8521769046783447, 0.8615626692771912, 0.8678776621818542, 0.8701963424682617, 0.868518590927124, 0.852988064289093, 0.8236046433448792, 0.8032509088516235, 0.7919268012046814, 0.7865023016929626, 0.7869773507118225, 0.7874362468719482, 0.7878790497779846, 0.7954531908035278, 0.8101586699485779, 0.7668473124504089, 0.665519118309021, 0.6360738277435303, 0.678511381149292, 0.6965967416763306, 0.6903298497200012, 0.6970472931861877, 0.7167490720748901, 0.7490506768226624, 0.7939522862434387, 0.8547447323799133, 0.931428074836731, 0.9627243876457214, 0.9486336708068848, 0.9307146072387695, 0.9089671969413757, 0.8816379904747009, 0.8487268090248108, 0.8752607107162476, 0.9612395763397217, 0.9925020933151245, 0.9690483212471008, 0.9715476036071777, 1.0, 0.9800636768341064, 0.9117385745048523, 0.8910858035087585, 0.9181053042411804, 0.9450165033340454, 0.9718193411827087, 0.982906699180603, 0.9782785773277283]\n",
      ">>s_pred: [0.0017423629760742188, 0.035225868225097656, 0.06776237487792969, 0.08386898040771484, 0.10181427001953125, 0.11663627624511719, 0.12871837615966797, 0.1572418212890625, 0.18898963928222656, 0.2084369659423828, 0.22165870666503906, 0.22980022430419922, 0.23174667358398438, 0.23491954803466797, 0.23833274841308594, 0.23342514038085938, 0.22197723388671875, 0.20646286010742188, 0.19158077239990234, 0.18259143829345703, 0.1850566864013672, 0.20113277435302734, 0.22646141052246094, 0.24648761749267578, 0.26378345489501953, 0.2735147476196289, 0.2819938659667969, 0.29438304901123047, 0.30437183380126953, 0.3059844970703125, 0.31180572509765625, 0.3300285339355469, 0.34232425689697266, 0.3411846160888672, 0.3525228500366211, 0.3872203826904297, 0.4326143264770508, 0.489227294921875, 0.5457677841186523, 0.586024284362793, 0.6165361404418945, 0.6457118988037109, 0.6757612228393555, 0.7109994888305664, 0.7446937561035156, 0.770808219909668, 0.7866754531860352, 0.7947044372558594, 0.8011007308959961, 0.8102045059204102, 0.8087635040283203, 0.7855596542358398, 0.7629547119140625, 0.7567806243896484, 0.7511463165283203, 0.7390823364257812, 0.7314138412475586, 0.7277193069458008, 0.722503662109375, 0.7083854675292969, 0.700531005859375, 0.6975946426391602, 0.6970348358154297, 0.7010116577148438, 0.7178630828857422, 0.750178337097168, 0.7785892486572266, 0.7928457260131836, 0.7998037338256836, 0.7973766326904297, 0.8083868026733398, 0.8415546417236328, 0.8729925155639648, 0.8829011917114258, 0.8800315856933594, 0.8706827163696289, 0.8577947616577148, 0.8527746200561523, 0.8529033660888672, 0.8484210968017578, 0.8392953872680664, 0.8295021057128906, 0.8152370452880859, 0.7953004837036133, 0.7613401412963867, 0.7417478561401367, 0.7249336242675781, 0.72015380859375, 0.7135162353515625, 0.6941061019897461, 0.6725454330444336, 0.6944742202758789, 0.6787166595458984, 0.6704797744750977, 0.6725130081176758, 0.6783981323242188, 0.6840667724609375, 0.7054042816162109, 0.7288169860839844, 0.7398891448974609, 0.7469758987426758, 0.7471342086791992, 0.7581043243408203, 0.7472324371337891, 0.7649660110473633, 0.8023500442504883, 0.8408355712890625, 0.8706626892089844, 0.8951807022094727, 0.9057798385620117, 0.9168968200683594, 0.9481077194213867, 0.979060173034668, 0.9943141937255859, 0.9946069717407227, 0.9776325225830078, 0.950556755065918, 0.9273443222045898, 0.9127750396728516, 0.9036922454833984, 0.8935976028442383, 0.8793668746948242, 0.8582143783569336, 0.830418586730957, 0.8090610504150391, 0.8011922836303711, 0.801203727722168, 0.8057432174682617, 0.8128986358642578, 0.8199453353881836, 0.8265628814697266, 0.8348798751831055, 0.8407020568847656, 0.8388242721557617, 0.8326396942138672, 0.8238563537597656, 0.8148927688598633, 0.8073463439941406, 0.8013763427734375, 0.7954349517822266, 0.791407585144043, 0.7918567657470703, 0.7789239883422852, 0.7401695251464844, 0.7034149169921875, 0.6866302490234375, 0.6763410568237305, 0.6678295135498047, 0.6662416458129883, 0.6672611236572266, 0.6735906600952148, 0.6961727142333984, 0.7383747100830078, 0.7974052429199219, 0.8556184768676758, 0.9009103775024414, 0.9335412979125977, 0.9536943435668945, 0.962275505065918, 0.9608373641967773, 0.9661159515380859, 1.000758171081543, 1.0164175033569336, 1.016286849975586, 1.015091896057129, 1.017500877380371, 1.0079736709594727, 0.9854259490966797, 0.9655227661132812, 0.9510440826416016, 0.9433202743530273, 0.946101188659668, 0.9521989822387695, 0.9529323577880859]\n",
      "<<Perdida: 0.0021008376497775316 epoca: 16\n",
      "---Inicio de epoca: 17--\n",
      ">>Entradas: tensor([0.0503, 0.0086, 0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203])\n",
      ">>Salida: tensor([0.0494])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([-0.1285], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.0494])\n",
      ">>Entradas: tensor([ 0.0086,  0.0000,  0.0245,  0.0327,  0.0246,  0.0205,  0.0203, -0.1285],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1079])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([-0.0473], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1079])\n",
      ">>Entradas: tensor([ 0.0000,  0.0245,  0.0327,  0.0246,  0.0205,  0.0203, -0.1285, -0.0473],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1372])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0061], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1372])\n",
      ">>Entradas: tensor([ 0.0245,  0.0327,  0.0246,  0.0205,  0.0203, -0.1285, -0.0473,  0.0061],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1373])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0161], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1373])\n",
      ">>Entradas: tensor([ 0.0327,  0.0246,  0.0205,  0.0203, -0.1285, -0.0473,  0.0061,  0.0161],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1339])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0539], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1339])\n",
      ">>Entradas: tensor([ 0.0246,  0.0205,  0.0203, -0.1285, -0.0473,  0.0061,  0.0161,  0.0539],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1268])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0868], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1268])\n",
      ">>Entradas: tensor([ 0.0205,  0.0203, -0.1285, -0.0473,  0.0061,  0.0161,  0.0539,  0.0868],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1476])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0846], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1476])\n",
      ">>Entradas: tensor([ 0.0203, -0.1285, -0.0473,  0.0061,  0.0161,  0.0539,  0.0868,  0.0846],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1960])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1215], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1960])\n",
      ">>Entradas: tensor([-0.1285, -0.0473,  0.0061,  0.0161,  0.0539,  0.0868,  0.0846,  0.1215],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1750], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2169])\n",
      ">>Entradas: tensor([-0.0473,  0.0061,  0.0161,  0.0539,  0.0868,  0.0846,  0.1215,  0.1750],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2101])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2068], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2101])\n",
      ">>Entradas: tensor([0.0061, 0.0161, 0.0539, 0.0868, 0.0846, 0.1215, 0.1750, 0.2068],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2027])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2295], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2027])\n",
      ">>Entradas: tensor([0.0161, 0.0539, 0.0868, 0.0846, 0.1215, 0.1750, 0.2068, 0.2295],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1946])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2073], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1946])\n",
      ">>Entradas: tensor([0.0539, 0.0868, 0.0846, 0.1215, 0.1750, 0.2068, 0.2295, 0.2073],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1941])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2291], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1941])\n",
      ">>Entradas: tensor([0.0868, 0.0846, 0.1215, 0.1750, 0.2068, 0.2295, 0.2073, 0.2291],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2010])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2396], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2010])\n",
      ">>Entradas: tensor([0.0846, 0.1215, 0.1750, 0.2068, 0.2295, 0.2073, 0.2291, 0.2396],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2462], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1966])\n",
      ">>Entradas: tensor([0.1215, 0.1750, 0.2068, 0.2295, 0.2073, 0.2291, 0.2396, 0.2462],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1810])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2396], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1810])\n",
      ">>Entradas: tensor([0.1750, 0.2068, 0.2295, 0.2073, 0.2291, 0.2396, 0.2462, 0.2396],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1654])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2388], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1654])\n",
      ">>Entradas: tensor([0.2068, 0.2295, 0.2073, 0.2291, 0.2396, 0.2462, 0.2396, 0.2388],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1499])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2185], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1499])\n",
      ">>Entradas: tensor([0.2295, 0.2073, 0.2291, 0.2396, 0.2462, 0.2396, 0.2388, 0.2185],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1504])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1999], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1504])\n",
      ">>Entradas: tensor([0.2073, 0.2291, 0.2396, 0.2462, 0.2396, 0.2388, 0.2185, 0.1999],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1671])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1937], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1671])\n",
      ">>Entradas: tensor([0.2291, 0.2396, 0.2462, 0.2396, 0.2388, 0.2185, 0.1999, 0.1937],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2023])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1958], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2023])\n",
      ">>Entradas: tensor([0.2396, 0.2462, 0.2396, 0.2388, 0.2185, 0.1999, 0.1937, 0.1958],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2559])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2075], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2559])\n",
      ">>Entradas: tensor([0.2462, 0.2396, 0.2388, 0.2185, 0.1999, 0.1937, 0.1958, 0.2075],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2927])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2274], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2927])\n",
      ">>Entradas: tensor([0.2396, 0.2388, 0.2185, 0.1999, 0.1937, 0.1958, 0.2075, 0.2274],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2474], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2388, 0.2185, 0.1999, 0.1937, 0.1958, 0.2075, 0.2274, 0.2474],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3109])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2614], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3109])\n",
      ">>Entradas: tensor([0.2185, 0.1999, 0.1937, 0.1958, 0.2075, 0.2274, 0.2474, 0.2614],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2876])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2693], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2876])\n",
      ">>Entradas: tensor([0.1999, 0.1937, 0.1958, 0.2075, 0.2274, 0.2474, 0.2614, 0.2693],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2802])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2786], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2802])\n",
      ">>Entradas: tensor([0.1937, 0.1958, 0.2075, 0.2274, 0.2474, 0.2614, 0.2693, 0.2786],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2886])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2914], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2886])\n",
      ">>Entradas: tensor([0.1958, 0.2075, 0.2274, 0.2474, 0.2614, 0.2693, 0.2786, 0.2914],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2825])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3010], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2825])\n",
      ">>Entradas: tensor([0.2075, 0.2274, 0.2474, 0.2614, 0.2693, 0.2786, 0.2914, 0.3010],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2618])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3041], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2618])\n",
      ">>Entradas: tensor([0.2274, 0.2474, 0.2614, 0.2693, 0.2786, 0.2914, 0.3010, 0.3041],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3113], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2801])\n",
      ">>Entradas: tensor([0.2474, 0.2614, 0.2693, 0.2786, 0.2914, 0.3010, 0.3041, 0.3113],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3374])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3304], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3374])\n",
      ">>Entradas: tensor([0.2614, 0.2693, 0.2786, 0.2914, 0.3010, 0.3041, 0.3113, 0.3304],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3482])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3438], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3482])\n",
      ">>Entradas: tensor([0.2693, 0.2786, 0.2914, 0.3010, 0.3041, 0.3113, 0.3304, 0.3438],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3433], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2786, 0.2914, 0.3010, 0.3041, 0.3113, 0.3304, 0.3438, 0.3433],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3436])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3560], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3436])\n",
      ">>Entradas: tensor([0.2914, 0.3010, 0.3041, 0.3113, 0.3304, 0.3438, 0.3433, 0.3560],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.4412])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3917], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.4412])\n",
      ">>Entradas: tensor([0.3010, 0.3041, 0.3113, 0.3304, 0.3438, 0.3433, 0.3560, 0.3917],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5211])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4373], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5211])\n",
      ">>Entradas: tensor([0.3041, 0.3113, 0.3304, 0.3438, 0.3433, 0.3560, 0.3917, 0.4373],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5833])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4940], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5833])\n",
      ">>Entradas: tensor([0.3113, 0.3304, 0.3438, 0.3433, 0.3560, 0.3917, 0.4373, 0.4940],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5515], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6089])\n",
      ">>Entradas: tensor([0.3304, 0.3438, 0.3433, 0.3560, 0.3917, 0.4373, 0.4940, 0.5515],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5980])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5929], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5980])\n",
      ">>Entradas: tensor([0.3438, 0.3433, 0.3560, 0.3917, 0.4373, 0.4940, 0.5515, 0.5929],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5945])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6249], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5945])\n",
      ">>Entradas: tensor([0.3433, 0.3560, 0.3917, 0.4373, 0.4940, 0.5515, 0.5929, 0.6249],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5985])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6561], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5985])\n",
      ">>Entradas: tensor([0.3560, 0.3917, 0.4373, 0.4940, 0.5515, 0.5929, 0.6249, 0.6561],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6214])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6898], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6214])\n",
      ">>Entradas: tensor([0.3917, 0.4373, 0.4940, 0.5515, 0.5929, 0.6249, 0.6561, 0.6898],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6631])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7274], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6631])\n",
      ">>Entradas: tensor([0.4373, 0.4940, 0.5515, 0.5929, 0.6249, 0.6561, 0.6898, 0.7274],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6929])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7641], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6929])\n",
      ">>Entradas: tensor([0.4940, 0.5515, 0.5929, 0.6249, 0.6561, 0.6898, 0.7274, 0.7641],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7107])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7925], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7107])\n",
      ">>Entradas: tensor([0.5515, 0.5929, 0.6249, 0.6561, 0.6898, 0.7274, 0.7641, 0.7925],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7217])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8096], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7217])\n",
      ">>Entradas: tensor([0.5929, 0.6249, 0.6561, 0.6898, 0.7274, 0.7641, 0.7925, 0.8096],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7259])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8177], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7259])\n",
      ">>Entradas: tensor([0.6249, 0.6561, 0.6898, 0.7274, 0.7641, 0.7925, 0.8096, 0.8177],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7404])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8237], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7404])\n",
      ">>Entradas: tensor([0.6561, 0.6898, 0.7274, 0.7641, 0.7925, 0.8096, 0.8177, 0.8237],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7652])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8318], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7652])\n",
      ">>Entradas: tensor([0.6898, 0.7274, 0.7641, 0.7925, 0.8096, 0.8177, 0.8237, 0.8318],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7448])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([-0.2621], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7448])\n",
      "ERROR: la modificacion de los pesos di√≥ un error mayor: 1.0138031244277954, se regresa al estado anterior de la red\n",
      ">>Entradas: tensor([0.7274, 0.7641, 0.7925, 0.8096, 0.8177, 0.8237, 0.8318, 0.8641],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6792])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8292], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6792])\n",
      ">>Entradas: tensor([0.7641, 0.7925, 0.8096, 0.8177, 0.8237, 0.8318, 0.8641, 0.8292],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6746])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7995], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6746])\n",
      ">>Entradas: tensor([0.7925, 0.8096, 0.8177, 0.8237, 0.8318, 0.8641, 0.8292, 0.7995],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7883], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7309])\n",
      ">>Entradas: tensor([0.8096, 0.8177, 0.8237, 0.8318, 0.8641, 0.8292, 0.7995, 0.7883],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7467])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7736], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7467])\n",
      ">>Entradas: tensor([0.8177, 0.8237, 0.8318, 0.8641, 0.8292, 0.7995, 0.7883, 0.7736],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7219])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7508], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7219])\n",
      ">>Entradas: tensor([0.8237, 0.8318, 0.8641, 0.8292, 0.7995, 0.7883, 0.7736, 0.7508],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7199])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7418], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7199])\n",
      ">>Entradas: tensor([0.8318, 0.8641, 0.8292, 0.7995, 0.7883, 0.7736, 0.7508, 0.7418],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7407])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7369], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7407])\n",
      ">>Entradas: tensor([0.8641, 0.8292, 0.7995, 0.7883, 0.7736, 0.7508, 0.7418, 0.7369],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7362])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7176], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7362])\n",
      ">>Entradas: tensor([0.8292, 0.7995, 0.7883, 0.7736, 0.7508, 0.7418, 0.7369, 0.7176],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6979], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7065])\n",
      ">>Entradas: tensor([0.7995, 0.7883, 0.7736, 0.7508, 0.7418, 0.7369, 0.7176, 0.6979],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6979])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6866], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6979])\n",
      ">>Entradas: tensor([0.7883, 0.7736, 0.7508, 0.7418, 0.7369, 0.7176, 0.6979, 0.6866],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7106])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6792], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7106])\n",
      ">>Entradas: tensor([0.7736, 0.7508, 0.7418, 0.7369, 0.7176, 0.6979, 0.6866, 0.6792],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7210])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6764], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7210])\n",
      ">>Entradas: tensor([0.7508, 0.7418, 0.7369, 0.7176, 0.6979, 0.6866, 0.6792, 0.6764],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7291])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6821], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7291])\n",
      ">>Entradas: tensor([0.7418, 0.7369, 0.7176, 0.6979, 0.6866, 0.6792, 0.6764, 0.6821],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7674])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6992], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7674])\n",
      ">>Entradas: tensor([0.7369, 0.7176, 0.6979, 0.6866, 0.6792, 0.6764, 0.6821, 0.6992],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8359])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7310], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8359])\n",
      ">>Entradas: tensor([0.7176, 0.6979, 0.6866, 0.6792, 0.6764, 0.6821, 0.6992, 0.7310],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8510])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7619], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8510])\n",
      ">>Entradas: tensor([0.6979, 0.6866, 0.6792, 0.6764, 0.6821, 0.6992, 0.7310, 0.7619],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8127])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7795], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8127])\n",
      ">>Entradas: tensor([0.6866, 0.6792, 0.6764, 0.6821, 0.6992, 0.7310, 0.7619, 0.7795],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7864])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7904], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7864])\n",
      ">>Entradas: tensor([0.6792, 0.6764, 0.6821, 0.6992, 0.7310, 0.7619, 0.7795, 0.7904],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7720])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7973], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7720])\n",
      ">>Entradas: tensor([0.6764, 0.6821, 0.6992, 0.7310, 0.7619, 0.7795, 0.7904, 0.7973],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8129], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.6821, 0.6992, 0.7310, 0.7619, 0.7795, 0.7904, 0.7973, 0.8129],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8803])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8496], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8803])\n",
      ">>Entradas: tensor([0.6992, 0.7310, 0.7619, 0.7795, 0.7904, 0.7973, 0.8129, 0.8496],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8987])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8843], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8987])\n",
      ">>Entradas: tensor([0.7310, 0.7619, 0.7795, 0.7904, 0.7973, 0.8129, 0.8496, 0.8843],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8973], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.7619, 0.7795, 0.7904, 0.7973, 0.8129, 0.8496, 0.8843, 0.8973],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8974], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8309])\n",
      ">>Entradas: tensor([0.7795, 0.7904, 0.7973, 0.8129, 0.8496, 0.8843, 0.8973, 0.8974],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8156])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8899], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8156])\n",
      ">>Entradas: tensor([0.7904, 0.7973, 0.8129, 0.8496, 0.8843, 0.8973, 0.8974, 0.8899],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8783], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8117])\n",
      ">>Entradas: tensor([0.7973, 0.8129, 0.8496, 0.8843, 0.8973, 0.8974, 0.8899, 0.8783],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8192])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8698], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8192])\n",
      ">>Entradas: tensor([0.8129, 0.8496, 0.8843, 0.8973, 0.8974, 0.8899, 0.8783, 0.8698],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8218])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8685], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8218])\n",
      ">>Entradas: tensor([0.8496, 0.8843, 0.8973, 0.8974, 0.8899, 0.8783, 0.8698, 0.8685],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8619], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8197])\n",
      ">>Entradas: tensor([0.8843, 0.8973, 0.8974, 0.8899, 0.8783, 0.8698, 0.8685, 0.8619],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8179])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8499], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8179])\n",
      ">>Entradas: tensor([0.8973, 0.8974, 0.8899, 0.8783, 0.8698, 0.8685, 0.8619, 0.8499],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8163])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8368], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8163])\n",
      ">>Entradas: tensor([0.8974, 0.8899, 0.8783, 0.8698, 0.8685, 0.8619, 0.8499, 0.8368],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8006])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8194], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8006])\n",
      ">>Entradas: tensor([0.8899, 0.8783, 0.8698, 0.8685, 0.8619, 0.8499, 0.8368, 0.8194],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7705])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7957], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7705])\n",
      ">>Entradas: tensor([0.8783, 0.8698, 0.8685, 0.8619, 0.8499, 0.8368, 0.8194, 0.7957],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7427])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7714], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7427])\n",
      ">>Entradas: tensor([0.8698, 0.8685, 0.8619, 0.8499, 0.8368, 0.8194, 0.7957, 0.7714],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7461], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7169])\n",
      ">>Entradas: tensor([0.8685, 0.8619, 0.8499, 0.8368, 0.8194, 0.7957, 0.7714, 0.7461],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7254], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7197])\n",
      ">>Entradas: tensor([0.8619, 0.8499, 0.8368, 0.8194, 0.7957, 0.7714, 0.7461, 0.7254],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7509])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7176], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7509])\n",
      ">>Entradas: tensor([0.8499, 0.8368, 0.8194, 0.7957, 0.7714, 0.7461, 0.7254, 0.7176],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7403])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7164], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7403])\n",
      ">>Entradas: tensor([0.8368, 0.8194, 0.7957, 0.7714, 0.7461, 0.7254, 0.7176, 0.7164],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6909], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.8194, 0.7957, 0.7714, 0.7461, 0.7254, 0.7176, 0.7164, 0.6909],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6688])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6685], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6688])\n",
      ">>Entradas: tensor([0.7957, 0.7714, 0.7461, 0.7254, 0.7176, 0.7164, 0.6909, 0.6685],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6835])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6574], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6835])\n",
      ">>Entradas: tensor([0.7714, 0.7461, 0.7254, 0.7176, 0.7164, 0.6909, 0.6685, 0.6574],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6482], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.7461, 0.7254, 0.7176, 0.7164, 0.6909, 0.6685, 0.6574, 0.6482],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6815])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6415], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6815])\n",
      ">>Entradas: tensor([0.7254, 0.7176, 0.7164, 0.6909, 0.6685, 0.6574, 0.6482, 0.6415],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6893])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6461], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6893])\n",
      ">>Entradas: tensor([0.7176, 0.7164, 0.6909, 0.6685, 0.6574, 0.6482, 0.6415, 0.6461],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7111])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6559], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7111])\n",
      ">>Entradas: tensor([0.7164, 0.6909, 0.6685, 0.6574, 0.6482, 0.6415, 0.6461, 0.6559],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7349])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6667], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7349])\n",
      ">>Entradas: tensor([0.6909, 0.6685, 0.6574, 0.6482, 0.6415, 0.6461, 0.6559, 0.6667],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7608])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6866], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7608])\n",
      ">>Entradas: tensor([0.6685, 0.6574, 0.6482, 0.6415, 0.6461, 0.6559, 0.6667, 0.6866],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7711])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7099], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7711])\n",
      ">>Entradas: tensor([0.6574, 0.6482, 0.6415, 0.6461, 0.6559, 0.6667, 0.6866, 0.7099],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7660])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7281], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7660])\n",
      ">>Entradas: tensor([0.6482, 0.6415, 0.6461, 0.6559, 0.6667, 0.6866, 0.7099, 0.7281],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7483])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7409], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7483])\n",
      ">>Entradas: tensor([0.6415, 0.6461, 0.6559, 0.6667, 0.6866, 0.7099, 0.7281, 0.7409],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7182])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7460], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7182])\n",
      ">>Entradas: tensor([0.6461, 0.6559, 0.6667, 0.6866, 0.7099, 0.7281, 0.7409, 0.7460],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7480], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7089])\n",
      ">>Entradas: tensor([0.6559, 0.6667, 0.6866, 0.7099, 0.7281, 0.7409, 0.7460, 0.7480],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7204])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7526], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7204])\n",
      ">>Entradas: tensor([0.6667, 0.6866, 0.7099, 0.7281, 0.7409, 0.7460, 0.7480, 0.7526],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7706])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7713], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7706])\n",
      ">>Entradas: tensor([0.6866, 0.7099, 0.7281, 0.7409, 0.7460, 0.7480, 0.7526, 0.7713],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8595])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8099], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8595])\n",
      ">>Entradas: tensor([0.7099, 0.7281, 0.7409, 0.7460, 0.7480, 0.7526, 0.7713, 0.8099],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8504], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9065])\n",
      ">>Entradas: tensor([0.7281, 0.7409, 0.7460, 0.7480, 0.7526, 0.7713, 0.8099, 0.8504],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9119])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8818], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9119])\n",
      ">>Entradas: tensor([0.7409, 0.7460, 0.7480, 0.7526, 0.7713, 0.8099, 0.8504, 0.8818],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9043])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9044], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9043])\n",
      ">>Entradas: tensor([0.7460, 0.7480, 0.7526, 0.7713, 0.8099, 0.8504, 0.8818, 0.9044],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8839])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8110], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8839])\n",
      "ERROR: la modificacion de los pesos di√≥ un error mayor: 0.005309605039656162, se regresa al estado anterior de la red\n",
      ">>Entradas: tensor([0.7480, 0.7526, 0.7713, 0.8099, 0.8504, 0.8818, 0.9044, 0.9290],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9032])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9392], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9032])\n",
      ">>Entradas: tensor([0.7526, 0.7713, 0.8099, 0.8504, 0.8818, 0.9044, 0.9290, 0.9392],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9623])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9684], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9623])\n",
      ">>Entradas: tensor([0.7713, 0.8099, 0.8504, 0.8818, 0.9044, 0.9290, 0.9392, 0.9684],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9821])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9982], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9821])\n",
      ">>Entradas: tensor([0.8099, 0.8504, 0.8818, 0.9044, 0.9290, 0.9392, 0.9684, 0.9982],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9624])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0111], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9624])\n",
      ">>Entradas: tensor([0.8504, 0.8818, 0.9044, 0.9290, 0.9392, 0.9684, 0.9982, 1.0111],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9303])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0067], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9303])\n",
      ">>Entradas: tensor([0.8818, 0.9044, 0.9290, 0.9392, 0.9684, 0.9982, 1.0111, 1.0067],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8855])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9903], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8855])\n",
      ">>Entradas: tensor([0.9044, 0.9290, 0.9392, 0.9684, 0.9982, 1.0111, 1.0067, 0.9903],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8597])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9643], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8597])\n",
      ">>Entradas: tensor([0.9290, 0.9392, 0.9684, 0.9982, 1.0111, 1.0067, 0.9903, 0.9643],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8529])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9380], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8529])\n",
      ">>Entradas: tensor([0.9392, 0.9684, 0.9982, 1.0111, 1.0067, 0.9903, 0.9643, 0.9380],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9207], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.9684, 0.9982, 1.0111, 1.0067, 0.9903, 0.9643, 0.9380, 0.9207],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8769])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9088], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8769])\n",
      ">>Entradas: tensor([0.9982, 1.0111, 1.0067, 0.9903, 0.9643, 0.9380, 0.9207, 0.9088],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8806])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8947], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8806])\n",
      ">>Entradas: tensor([1.0111, 1.0067, 0.9903, 0.9643, 0.9380, 0.9207, 0.9088, 0.8947],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8699])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8771], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8699])\n",
      ">>Entradas: tensor([1.0067, 0.9903, 0.9643, 0.9380, 0.9207, 0.9088, 0.8947, 0.8771],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8465])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8547], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8465])\n",
      ">>Entradas: tensor([0.9903, 0.9643, 0.9380, 0.9207, 0.9088, 0.8947, 0.8771, 0.8547],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8104])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8254], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8104])\n",
      ">>Entradas: tensor([0.9643, 0.9380, 0.9207, 0.9088, 0.8947, 0.8771, 0.8547, 0.8254],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8026])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8023], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8026])\n",
      ">>Entradas: tensor([0.9380, 0.9207, 0.9088, 0.8947, 0.8771, 0.8547, 0.8254, 0.8023],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8232])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7934], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8232])\n",
      ">>Entradas: tensor([0.9207, 0.9088, 0.8947, 0.8771, 0.8547, 0.8254, 0.8023, 0.7934],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8397])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7920], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8397])\n",
      ">>Entradas: tensor([0.9088, 0.8947, 0.8771, 0.8547, 0.8254, 0.8023, 0.7934, 0.7920],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8522])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7949], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8522])\n",
      ">>Entradas: tensor([0.8947, 0.8771, 0.8547, 0.8254, 0.8023, 0.7934, 0.7920, 0.7949],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8616])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8017], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8616])\n",
      ">>Entradas: tensor([0.8771, 0.8547, 0.8254, 0.8023, 0.7934, 0.7920, 0.7949, 0.8017],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8679])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8092], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8679])\n",
      ">>Entradas: tensor([0.8547, 0.8254, 0.8023, 0.7934, 0.7920, 0.7949, 0.8017, 0.8092],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8702])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8165], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8702])\n",
      ">>Entradas: tensor([0.8254, 0.8023, 0.7934, 0.7920, 0.7949, 0.8017, 0.8092, 0.8165],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8685])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8261], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8685])\n",
      ">>Entradas: tensor([0.8023, 0.7934, 0.7920, 0.7949, 0.8017, 0.8092, 0.8165, 0.8261],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8530])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8338], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8530])\n",
      ">>Entradas: tensor([0.7934, 0.7920, 0.7949, 0.8017, 0.8092, 0.8165, 0.8261, 0.8338],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8236])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8338], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8236])\n",
      ">>Entradas: tensor([0.7920, 0.7949, 0.8017, 0.8092, 0.8165, 0.8261, 0.8338, 0.8338],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8299], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.7949, 0.8017, 0.8092, 0.8165, 0.8261, 0.8338, 0.8338, 0.8299],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7919])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8242], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7919])\n",
      ">>Entradas: tensor([0.8017, 0.8092, 0.8165, 0.8261, 0.8338, 0.8338, 0.8299, 0.8242],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7865])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8157], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7865])\n",
      ">>Entradas: tensor([0.8092, 0.8165, 0.8261, 0.8338, 0.8338, 0.8299, 0.8242, 0.8157],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7870])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8096], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7870])\n",
      ">>Entradas: tensor([0.8165, 0.8261, 0.8338, 0.8338, 0.8299, 0.8242, 0.8157, 0.8096],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7874])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8046], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7874])\n",
      ">>Entradas: tensor([0.8261, 0.8338, 0.8338, 0.8299, 0.8242, 0.8157, 0.8096, 0.8046],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7879])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7990], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7879])\n",
      ">>Entradas: tensor([0.8338, 0.8338, 0.8299, 0.8242, 0.8157, 0.8096, 0.8046, 0.7990],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7955])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7949], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7955])\n",
      ">>Entradas: tensor([0.8338, 0.8299, 0.8242, 0.8157, 0.8096, 0.8046, 0.7990, 0.7949],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8102])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7953], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8102])\n",
      ">>Entradas: tensor([0.8299, 0.8242, 0.8157, 0.8096, 0.8046, 0.7990, 0.7949, 0.7953],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7668])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7817], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7668])\n",
      ">>Entradas: tensor([0.8242, 0.8157, 0.8096, 0.8046, 0.7990, 0.7949, 0.7953, 0.7817],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6655])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7422], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6655])\n",
      ">>Entradas: tensor([0.8157, 0.8096, 0.8046, 0.7990, 0.7949, 0.7953, 0.7817, 0.7422],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6361])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7057], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6361])\n",
      ">>Entradas: tensor([0.8096, 0.8046, 0.7990, 0.7949, 0.7953, 0.7817, 0.7422, 0.7057],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6785])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6890], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6785])\n",
      ">>Entradas: tensor([0.8046, 0.7990, 0.7949, 0.7953, 0.7817, 0.7422, 0.7057, 0.6890],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6771], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6966])\n",
      ">>Entradas: tensor([0.7990, 0.7949, 0.7953, 0.7817, 0.7422, 0.7057, 0.6890, 0.6771],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6903])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6663], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6903])\n",
      ">>Entradas: tensor([0.7949, 0.7953, 0.7817, 0.7422, 0.7057, 0.6890, 0.6771, 0.6663],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6970])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6678], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6970])\n",
      ">>Entradas: tensor([0.7953, 0.7817, 0.7422, 0.7057, 0.6890, 0.6771, 0.6663, 0.6678],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7167])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6662], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7167])\n",
      ">>Entradas: tensor([0.7817, 0.7422, 0.7057, 0.6890, 0.6771, 0.6663, 0.6678, 0.6662],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7491])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6704], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7491])\n",
      ">>Entradas: tensor([0.7422, 0.7057, 0.6890, 0.6771, 0.6663, 0.6678, 0.6662, 0.6704],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7940])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6922], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7940])\n",
      ">>Entradas: tensor([0.7057, 0.6890, 0.6771, 0.6663, 0.6678, 0.6662, 0.6704, 0.6922],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8547])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7335], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8547])\n",
      ">>Entradas: tensor([0.6890, 0.6771, 0.6663, 0.6678, 0.6662, 0.6704, 0.6922, 0.7335],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9314])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7906], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9314])\n",
      ">>Entradas: tensor([0.6771, 0.6663, 0.6678, 0.6662, 0.6704, 0.6922, 0.7335, 0.7906],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9627])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8486], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9627])\n",
      ">>Entradas: tensor([0.6663, 0.6678, 0.6662, 0.6704, 0.6922, 0.7335, 0.7906, 0.8486],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9486])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8951], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9486])\n",
      ">>Entradas: tensor([0.6678, 0.6662, 0.6704, 0.6922, 0.7335, 0.7906, 0.8486, 0.8951],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9307])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9292], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9307])\n",
      ">>Entradas: tensor([0.6662, 0.6704, 0.6922, 0.7335, 0.7906, 0.8486, 0.8951, 0.9292],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9090])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9521], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9090])\n",
      ">>Entradas: tensor([0.6704, 0.6922, 0.7335, 0.7906, 0.8486, 0.8951, 0.9292, 0.9521],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8816])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9648], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8816])\n",
      ">>Entradas: tensor([0.6922, 0.7335, 0.7906, 0.8486, 0.8951, 0.9292, 0.9521, 0.9648],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8487])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9667], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8487])\n",
      ">>Entradas: tensor([0.7335, 0.7906, 0.8486, 0.8951, 0.9292, 0.9521, 0.9648, 0.9667],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8753])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9747], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8753])\n",
      ">>Entradas: tensor([0.7906, 0.8486, 0.8951, 0.9292, 0.9521, 0.9648, 0.9667, 0.9747],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9612])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9995], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9612])\n",
      ">>Entradas: tensor([0.8486, 0.8951, 0.9292, 0.9521, 0.9648, 0.9667, 0.9747, 0.9995],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9925])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0183], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9925])\n",
      ">>Entradas: tensor([0.8951, 0.9292, 0.9521, 0.9648, 0.9667, 0.9747, 0.9995, 1.0183],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9690])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0199], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9690])\n",
      ">>Entradas: tensor([0.9292, 0.9521, 0.9648, 0.9667, 0.9747, 0.9995, 1.0183, 1.0199],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9715])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0197], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9715])\n",
      ">>Entradas: tensor([0.9521, 0.9648, 0.9667, 0.9747, 0.9995, 1.0183, 1.0199, 1.0197],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([1.])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0234], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([1.])\n",
      ">>Entradas: tensor([0.9648, 0.9667, 0.9747, 0.9995, 1.0183, 1.0199, 1.0197, 1.0234],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0146], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9801])\n",
      ">>Entradas: tensor([0.9667, 0.9747, 0.9995, 1.0183, 1.0199, 1.0197, 1.0234, 1.0146],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9901], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9117])\n",
      ">>Entradas: tensor([0.9747, 0.9995, 1.0183, 1.0199, 1.0197, 1.0234, 1.0146, 0.9901],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8911])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9690], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8911])\n",
      ">>Entradas: tensor([0.9995, 1.0183, 1.0199, 1.0197, 1.0234, 1.0146, 0.9901, 0.9690],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9181])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9558], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9181])\n",
      ">>Entradas: tensor([1.0183, 1.0199, 1.0197, 1.0234, 1.0146, 0.9901, 0.9690, 0.9558],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9450])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9469], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9450])\n",
      ">>Entradas: tensor([1.0199, 1.0197, 1.0234, 1.0146, 0.9901, 0.9690, 0.9558, 0.9469],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9718])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9480], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9718])\n",
      ">>Entradas: tensor([1.0197, 1.0234, 1.0146, 0.9901, 0.9690, 0.9558, 0.9469, 0.9480],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9829])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9529], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9829])\n",
      ">>Entradas: tensor([1.0234, 1.0146, 0.9901, 0.9690, 0.9558, 0.9469, 0.9480, 0.9529],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9783])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9520], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9783])\n",
      ">>s_original: [0.049424633383750916, 0.10789185762405396, 0.13719609379768372, 0.13733737170696259, 0.1338856965303421, 0.12684109807014465, 0.14756061136722565, 0.19604423642158508, 0.21688967943191528, 0.21009695529937744, 0.20267784595489502, 0.1946323662996292, 0.19407351315021515, 0.20100130140781403, 0.19663821160793304, 0.180984228849411, 0.16539041697978973, 0.14985674619674683, 0.15043111145496368, 0.1671135276556015, 0.20227035880088806, 0.25590160489082336, 0.29268819093704224, 0.31263017654418945, 0.31093889474868774, 0.2876143157482147, 0.28016164898872375, 0.28858086466789246, 0.28246283531188965, 0.26180753111839294, 0.2801212966442108, 0.3374040722846985, 0.3482298254966736, 0.3125985562801361, 0.34358710050582886, 0.44119545817375183, 0.521095335483551, 0.5832866430282593, 0.6089234352111816, 0.5980057120323181, 0.5945301651954651, 0.5984968543052673, 0.621354341506958, 0.6631026864051819, 0.6928724050521851, 0.7106636166572571, 0.721682071685791, 0.7259277701377869, 0.7404318451881409, 0.7651942372322083, 0.7447891235351562, 0.6792163252830505, 0.6746017932891846, 0.730945348739624, 0.7467210292816162, 0.7219287157058716, 0.7199286818504333, 0.7407209277153015, 0.7362455129623413, 0.7065023183822632, 0.6979451775550842, 0.7105739712715149, 0.7209621667861938, 0.7291097044944763, 0.7674259543418884, 0.8359109163284302, 0.8510103225708008, 0.8127241730690002, 0.7863940000534058, 0.7720199823379517, 0.8033170700073242, 0.8802852630615234, 0.8987051844596863, 0.8585767149925232, 0.8308762311935425, 0.8156037926673889, 0.8116992115974426, 0.8191625475883484, 0.8218275904655457, 0.8196942210197449, 0.817862868309021, 0.8163333535194397, 0.8005555868148804, 0.7705295085906982, 0.7426586747169495, 0.716943085193634, 0.7197051048278809, 0.7509447932243347, 0.7402781248092651, 0.6877052187919617, 0.6687695384025574, 0.683471143245697, 0.6877052187919617, 0.6814717054367065, 0.6892618536949158, 0.7110756039619446, 0.7349108457565308, 0.7607676982879639, 0.771117091178894, 0.7659589648246765, 0.7483323812484741, 0.7182371616363525, 0.708941638469696, 0.7204458117485046, 0.7706154584884644, 0.8594506978988647, 0.906541109085083, 0.9118866324424744, 0.9043355584144592, 0.8838878870010376, 0.9032153487205505, 0.9623178839683533, 0.9820588231086731, 0.96243816614151, 0.9302511811256409, 0.8854979276657104, 0.8597025871276855, 0.8528652191162109, 0.8585854768753052, 0.8768633008003235, 0.8806464076042175, 0.8699347376823425, 0.846513569355011, 0.8103827834129333, 0.8026111125946045, 0.8231984972953796, 0.8397204279899597, 0.8521769046783447, 0.8615626692771912, 0.8678776621818542, 0.8701963424682617, 0.868518590927124, 0.852988064289093, 0.8236046433448792, 0.8032509088516235, 0.7919268012046814, 0.7865023016929626, 0.7869773507118225, 0.7874362468719482, 0.7878790497779846, 0.7954531908035278, 0.8101586699485779, 0.7668473124504089, 0.665519118309021, 0.6360738277435303, 0.678511381149292, 0.6965967416763306, 0.6903298497200012, 0.6970472931861877, 0.7167490720748901, 0.7490506768226624, 0.7939522862434387, 0.8547447323799133, 0.931428074836731, 0.9627243876457214, 0.9486336708068848, 0.9307146072387695, 0.9089671969413757, 0.8816379904747009, 0.8487268090248108, 0.8752607107162476, 0.9612395763397217, 0.9925020933151245, 0.9690483212471008, 0.9715476036071777, 1.0, 0.9800636768341064, 0.9117385745048523, 0.8910858035087585, 0.9181053042411804, 0.9450165033340454, 0.9718193411827087, 0.982906699180603, 0.9782785773277283]\n",
      ">>s_pred: [-0.12853622436523438, -0.04729652404785156, 0.006070137023925781, 0.016063690185546875, 0.05386543273925781, 0.08682632446289062, 0.0845956802368164, 0.12150192260742188, 0.17496299743652344, 0.20682334899902344, 0.22953319549560547, 0.2072734832763672, 0.2290935516357422, 0.2396097183227539, 0.2462320327758789, 0.23956584930419922, 0.2388296127319336, 0.21846866607666016, 0.1999368667602539, 0.1936788558959961, 0.19584274291992188, 0.2075061798095703, 0.2274312973022461, 0.2473735809326172, 0.2614002227783203, 0.2692584991455078, 0.2786417007446289, 0.29135894775390625, 0.30103111267089844, 0.3040504455566406, 0.3112964630126953, 0.33044910430908203, 0.34381866455078125, 0.3432655334472656, 0.35601234436035156, 0.39169979095458984, 0.43729209899902344, 0.49397850036621094, 0.5515041351318359, 0.5929431915283203, 0.6249370574951172, 0.6561279296875, 0.6897640228271484, 0.7274188995361328, 0.7640914916992188, 0.7924823760986328, 0.80963134765625, 0.8177471160888672, 0.8236780166625977, 0.8318166732788086, 0.8640727996826172, 0.8292217254638672, 0.7994842529296875, 0.7882719039916992, 0.7735910415649414, 0.7508344650268555, 0.7417898178100586, 0.7369384765625, 0.7176132202148438, 0.6979341506958008, 0.6866073608398438, 0.6792201995849609, 0.6763954162597656, 0.6821365356445312, 0.6991510391235352, 0.7309846878051758, 0.7619256973266602, 0.7794780731201172, 0.7903814315795898, 0.7973213195800781, 0.8129253387451172, 0.8496475219726562, 0.8843135833740234, 0.8972740173339844, 0.8974380493164062, 0.8898563385009766, 0.8782978057861328, 0.8697605133056641, 0.8684864044189453, 0.8619422912597656, 0.8498649597167969, 0.8367509841918945, 0.8194370269775391, 0.7957496643066406, 0.7714109420776367, 0.7460670471191406, 0.7254419326782227, 0.7176084518432617, 0.7164115905761719, 0.6908979415893555, 0.6684637069702148, 0.657353401184082, 0.6482439041137695, 0.6415300369262695, 0.6461153030395508, 0.6558675765991211, 0.6667461395263672, 0.6866235733032227, 0.7098579406738281, 0.7281484603881836, 0.7408666610717773, 0.7460193634033203, 0.7480316162109375, 0.7526473999023438, 0.7712564468383789, 0.8099193572998047, 0.8503923416137695, 0.8818283081054688, 0.9043855667114258, 0.929041862487793, 0.9392175674438477, 0.9683694839477539, 0.9981603622436523, 1.011056900024414, 1.0066843032836914, 0.990290641784668, 0.9643363952636719, 0.938023567199707, 0.9207162857055664, 0.9088096618652344, 0.8947467803955078, 0.877140998840332, 0.8546857833862305, 0.825404167175293, 0.8022556304931641, 0.7933788299560547, 0.7919721603393555, 0.7949419021606445, 0.8016948699951172, 0.8092126846313477, 0.8164510726928711, 0.8261337280273438, 0.8338460922241211, 0.8338499069213867, 0.8299179077148438, 0.8241748809814453, 0.8156595230102539, 0.8095684051513672, 0.8046236038208008, 0.7990217208862305, 0.7948837280273438, 0.7953014373779297, 0.7817401885986328, 0.7421646118164062, 0.7057390213012695, 0.6890468597412109, 0.6771097183227539, 0.6663427352905273, 0.6677894592285156, 0.6662282943725586, 0.6704034805297852, 0.6922359466552734, 0.7335081100463867, 0.7906398773193359, 0.8486471176147461, 0.8950529098510742, 0.9292335510253906, 0.9520711898803711, 0.9648361206054688, 0.9666509628295898, 0.9747190475463867, 0.9995155334472656, 1.0183286666870117, 1.0198602676391602, 1.0197391510009766, 1.0234375, 1.0146360397338867, 0.9901084899902344, 0.968998908996582, 0.9557981491088867, 0.9468879699707031, 0.9479598999023438, 0.9528779983520508, 0.9519767761230469]\n",
      "<<Perdida: 0.003341006115078926 epoca: 17\n",
      "---Inicio de epoca: 18--\n",
      ">>Entradas: tensor([0.0503, 0.0086, 0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203])\n",
      ">>Salida: tensor([0.0494])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([-0.1988], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.0494])\n",
      ">>Entradas: tensor([ 0.0086,  0.0000,  0.0245,  0.0327,  0.0246,  0.0205,  0.0203, -0.1988],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1079])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([-0.0867], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1079])\n",
      ">>Entradas: tensor([ 0.0000,  0.0245,  0.0327,  0.0246,  0.0205,  0.0203, -0.1988, -0.0867],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1372])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([-0.0202], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1372])\n",
      ">>Entradas: tensor([ 0.0245,  0.0327,  0.0246,  0.0205,  0.0203, -0.1988, -0.0867, -0.0202],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1373])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([-0.0301], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1373])\n",
      ">>Entradas: tensor([ 0.0327,  0.0246,  0.0205,  0.0203, -0.1988, -0.0867, -0.0202, -0.0301],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1339])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0202], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1339])\n",
      ">>Entradas: tensor([ 0.0246,  0.0205,  0.0203, -0.1988, -0.0867, -0.0202, -0.0301,  0.0202],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1268])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0679], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1268])\n",
      ">>Entradas: tensor([ 0.0205,  0.0203, -0.1988, -0.0867, -0.0202, -0.0301,  0.0202,  0.0679],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1476])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0528], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1476])\n",
      ">>Entradas: tensor([ 0.0203, -0.1988, -0.0867, -0.0202, -0.0301,  0.0202,  0.0679,  0.0528],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1960])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0904], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1960])\n",
      ">>Entradas: tensor([-0.1988, -0.0867, -0.0202, -0.0301,  0.0202,  0.0679,  0.0528,  0.0904],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1587], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2169])\n",
      ">>Entradas: tensor([-0.0867, -0.0202, -0.0301,  0.0202,  0.0679,  0.0528,  0.0904,  0.1587],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2101])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1877], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2101])\n",
      ">>Entradas: tensor([-0.0202, -0.0301,  0.0202,  0.0679,  0.0528,  0.0904,  0.1587,  0.1877],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2027])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2066], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2027])\n",
      ">>Entradas: tensor([-0.0301,  0.0202,  0.0679,  0.0528,  0.0904,  0.1587,  0.1877,  0.2066],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1946])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2374], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1946])\n",
      ">>Entradas: tensor([0.0202, 0.0679, 0.0528, 0.0904, 0.1587, 0.1877, 0.2066, 0.2374],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1941])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2458], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1941])\n",
      ">>Entradas: tensor([0.0679, 0.0528, 0.0904, 0.1587, 0.1877, 0.2066, 0.2374, 0.2458],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2010])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2294], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2010])\n",
      ">>Entradas: tensor([0.0528, 0.0904, 0.1587, 0.1877, 0.2066, 0.2374, 0.2458, 0.2294],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2515], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1966])\n",
      ">>Entradas: tensor([0.0904, 0.1587, 0.1877, 0.2066, 0.2374, 0.2458, 0.2294, 0.2515],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1810])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2537], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1810])\n",
      ">>Entradas: tensor([0.1587, 0.1877, 0.2066, 0.2374, 0.2458, 0.2294, 0.2515, 0.2537],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1654])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2381], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1654])\n",
      ">>Entradas: tensor([0.1877, 0.2066, 0.2374, 0.2458, 0.2294, 0.2515, 0.2537, 0.2381],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1499])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2266], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1499])\n",
      ">>Entradas: tensor([0.2066, 0.2374, 0.2458, 0.2294, 0.2515, 0.2537, 0.2381, 0.2266],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1504])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2158], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1504])\n",
      ">>Entradas: tensor([0.2374, 0.2458, 0.2294, 0.2515, 0.2537, 0.2381, 0.2266, 0.2158],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1671])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1990], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1671])\n",
      ">>Entradas: tensor([0.2458, 0.2294, 0.2515, 0.2537, 0.2381, 0.2266, 0.2158, 0.1990],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2023])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1978], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2023])\n",
      ">>Entradas: tensor([0.2294, 0.2515, 0.2537, 0.2381, 0.2266, 0.2158, 0.1990, 0.1978],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2559])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2151], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2559])\n",
      ">>Entradas: tensor([0.2515, 0.2537, 0.2381, 0.2266, 0.2158, 0.1990, 0.1978, 0.2151],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2927])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2313], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2927])\n",
      ">>Entradas: tensor([0.2537, 0.2381, 0.2266, 0.2158, 0.1990, 0.1978, 0.2151, 0.2313],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2500], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2381, 0.2266, 0.2158, 0.1990, 0.1978, 0.2151, 0.2313, 0.2500],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3109])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2654], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3109])\n",
      ">>Entradas: tensor([0.2266, 0.2158, 0.1990, 0.1978, 0.2151, 0.2313, 0.2500, 0.2654],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2876])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2710], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2876])\n",
      ">>Entradas: tensor([0.2158, 0.1990, 0.1978, 0.2151, 0.2313, 0.2500, 0.2654, 0.2710],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2802])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2758], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2802])\n",
      ">>Entradas: tensor([0.1990, 0.1978, 0.2151, 0.2313, 0.2500, 0.2654, 0.2710, 0.2758],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2886])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2875], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2886])\n",
      ">>Entradas: tensor([0.1978, 0.2151, 0.2313, 0.2500, 0.2654, 0.2710, 0.2758, 0.2875],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2825])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2956], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2825])\n",
      ">>Entradas: tensor([0.2151, 0.2313, 0.2500, 0.2654, 0.2710, 0.2758, 0.2875, 0.2956],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2618])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2954], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2618])\n",
      ">>Entradas: tensor([0.2313, 0.2500, 0.2654, 0.2710, 0.2758, 0.2875, 0.2956, 0.2954],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3023], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2801])\n",
      ">>Entradas: tensor([0.2500, 0.2654, 0.2710, 0.2758, 0.2875, 0.2956, 0.2954, 0.3023],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3374])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3215], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3374])\n",
      ">>Entradas: tensor([0.2654, 0.2710, 0.2758, 0.2875, 0.2956, 0.2954, 0.3023, 0.3215],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3482])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3333], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3482])\n",
      ">>Entradas: tensor([0.2710, 0.2758, 0.2875, 0.2956, 0.2954, 0.3023, 0.3215, 0.3333],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3326], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2758, 0.2875, 0.2956, 0.2954, 0.3023, 0.3215, 0.3333, 0.3326],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3436])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3460], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3436])\n",
      ">>Entradas: tensor([0.2875, 0.2956, 0.2954, 0.3023, 0.3215, 0.3333, 0.3326, 0.3460],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.4412])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3826], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.4412])\n",
      ">>Entradas: tensor([0.2956, 0.2954, 0.3023, 0.3215, 0.3333, 0.3326, 0.3460, 0.3826],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5211])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4279], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5211])\n",
      ">>Entradas: tensor([0.2954, 0.3023, 0.3215, 0.3333, 0.3326, 0.3460, 0.3826, 0.4279],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5833])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4843], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5833])\n",
      ">>Entradas: tensor([0.3023, 0.3215, 0.3333, 0.3326, 0.3460, 0.3826, 0.4279, 0.4843],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5413], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6089])\n",
      ">>Entradas: tensor([0.3215, 0.3333, 0.3326, 0.3460, 0.3826, 0.4279, 0.4843, 0.5413],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5980])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5820], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5980])\n",
      ">>Entradas: tensor([0.3333, 0.3326, 0.3460, 0.3826, 0.4279, 0.4843, 0.5413, 0.5820],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5945])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6146], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5945])\n",
      ">>Entradas: tensor([0.3326, 0.3460, 0.3826, 0.4279, 0.4843, 0.5413, 0.5820, 0.6146],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5985])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6466], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5985])\n",
      ">>Entradas: tensor([0.3460, 0.3826, 0.4279, 0.4843, 0.5413, 0.5820, 0.6146, 0.6466],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6214])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6813], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6214])\n",
      ">>Entradas: tensor([0.3826, 0.4279, 0.4843, 0.5413, 0.5820, 0.6146, 0.6466, 0.6813],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6631])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7189], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6631])\n",
      ">>Entradas: tensor([0.4279, 0.4843, 0.5413, 0.5820, 0.6146, 0.6466, 0.6813, 0.7189],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6929])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7562], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6929])\n",
      ">>Entradas: tensor([0.4843, 0.5413, 0.5820, 0.6146, 0.6466, 0.6813, 0.7189, 0.7562],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7107])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7847], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7107])\n",
      ">>Entradas: tensor([0.5413, 0.5820, 0.6146, 0.6466, 0.6813, 0.7189, 0.7562, 0.7847],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7217])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8028], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7217])\n",
      ">>Entradas: tensor([0.5820, 0.6146, 0.6466, 0.6813, 0.7189, 0.7562, 0.7847, 0.8028],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7259])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8126], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7259])\n",
      ">>Entradas: tensor([0.6146, 0.6466, 0.6813, 0.7189, 0.7562, 0.7847, 0.8028, 0.8126],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7404])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8203], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7404])\n",
      ">>Entradas: tensor([0.6466, 0.6813, 0.7189, 0.7562, 0.7847, 0.8028, 0.8126, 0.8203],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7652])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8297], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7652])\n",
      ">>Entradas: tensor([0.6813, 0.7189, 0.7562, 0.7847, 0.8028, 0.8126, 0.8203, 0.8297],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7448])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8271], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7448])\n",
      ">>Entradas: tensor([0.7189, 0.7562, 0.7847, 0.8028, 0.8126, 0.8203, 0.8297, 0.8271],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6792])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8024], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6792])\n",
      ">>Entradas: tensor([0.7562, 0.7847, 0.8028, 0.8126, 0.8203, 0.8297, 0.8271, 0.8024],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6746])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7781], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6746])\n",
      ">>Entradas: tensor([0.7847, 0.8028, 0.8126, 0.8203, 0.8297, 0.8271, 0.8024, 0.7781],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7698], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7309])\n",
      ">>Entradas: tensor([0.8028, 0.8126, 0.8203, 0.8297, 0.8271, 0.8024, 0.7781, 0.7698],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7467])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7608], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7467])\n",
      ">>Entradas: tensor([0.8126, 0.8203, 0.8297, 0.8271, 0.8024, 0.7781, 0.7698, 0.7608],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7219])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7444], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7219])\n",
      ">>Entradas: tensor([0.8203, 0.8297, 0.8271, 0.8024, 0.7781, 0.7698, 0.7608, 0.7444],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7199])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7332], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7199])\n",
      ">>Entradas: tensor([0.8297, 0.8271, 0.8024, 0.7781, 0.7698, 0.7608, 0.7444, 0.7332],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7407])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7266], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7407])\n",
      ">>Entradas: tensor([0.8271, 0.8024, 0.7781, 0.7698, 0.7608, 0.7444, 0.7332, 0.7266],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7362])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7144], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7362])\n",
      ">>Entradas: tensor([0.8024, 0.7781, 0.7698, 0.7608, 0.7444, 0.7332, 0.7266, 0.7144],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6989], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7065])\n",
      ">>Entradas: tensor([0.7781, 0.7698, 0.7608, 0.7444, 0.7332, 0.7266, 0.7144, 0.6989],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6979])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6901], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6979])\n",
      ">>Entradas: tensor([0.7698, 0.7608, 0.7444, 0.7332, 0.7266, 0.7144, 0.6989, 0.6901],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7106])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6863], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7106])\n",
      ">>Entradas: tensor([0.7608, 0.7444, 0.7332, 0.7266, 0.7144, 0.6989, 0.6901, 0.6863],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7210])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6851], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7210])\n",
      ">>Entradas: tensor([0.7444, 0.7332, 0.7266, 0.7144, 0.6989, 0.6901, 0.6863, 0.6851],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7291])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6894], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7291])\n",
      ">>Entradas: tensor([0.7332, 0.7266, 0.7144, 0.6989, 0.6901, 0.6863, 0.6851, 0.6894],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7674])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7063], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7674])\n",
      ">>Entradas: tensor([0.7266, 0.7144, 0.6989, 0.6901, 0.6863, 0.6851, 0.6894, 0.7063],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8359])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7391], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8359])\n",
      ">>Entradas: tensor([0.7144, 0.6989, 0.6901, 0.6863, 0.6851, 0.6894, 0.7063, 0.7391],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8510])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7691], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8510])\n",
      ">>Entradas: tensor([0.6989, 0.6901, 0.6863, 0.6851, 0.6894, 0.7063, 0.7391, 0.7691],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8127])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7852], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8127])\n",
      ">>Entradas: tensor([0.6901, 0.6863, 0.6851, 0.6894, 0.7063, 0.7391, 0.7691, 0.7852],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7864])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7953], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7864])\n",
      ">>Entradas: tensor([0.6863, 0.6851, 0.6894, 0.7063, 0.7391, 0.7691, 0.7852, 0.7953],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7720])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8006], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7720])\n",
      ">>Entradas: tensor([0.6851, 0.6894, 0.7063, 0.7391, 0.7691, 0.7852, 0.7953, 0.8006],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8142], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.6894, 0.7063, 0.7391, 0.7691, 0.7852, 0.7953, 0.8006, 0.8142],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8803])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8494], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8803])\n",
      ">>Entradas: tensor([0.7063, 0.7391, 0.7691, 0.7852, 0.7953, 0.8006, 0.8142, 0.8494],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8987])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8822], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8987])\n",
      ">>Entradas: tensor([0.7391, 0.7691, 0.7852, 0.7953, 0.8006, 0.8142, 0.8494, 0.8822],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8920], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.7691, 0.7852, 0.7953, 0.8006, 0.8142, 0.8494, 0.8822, 0.8920],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8912], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8309])\n",
      ">>Entradas: tensor([0.7852, 0.7953, 0.8006, 0.8142, 0.8494, 0.8822, 0.8920, 0.8912],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8156])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8837], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8156])\n",
      ">>Entradas: tensor([0.7953, 0.8006, 0.8142, 0.8494, 0.8822, 0.8920, 0.8912, 0.8837],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8724], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8117])\n",
      ">>Entradas: tensor([0.8006, 0.8142, 0.8494, 0.8822, 0.8920, 0.8912, 0.8837, 0.8724],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8192])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8666], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8192])\n",
      ">>Entradas: tensor([0.8142, 0.8494, 0.8822, 0.8920, 0.8912, 0.8837, 0.8724, 0.8666],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8218])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8594], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8218])\n",
      ">>Entradas: tensor([0.8494, 0.8822, 0.8920, 0.8912, 0.8837, 0.8724, 0.8666, 0.8594],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8535], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8197])\n",
      ">>Entradas: tensor([0.8822, 0.8920, 0.8912, 0.8837, 0.8724, 0.8666, 0.8594, 0.8535],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8179])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8428], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8179])\n",
      ">>Entradas: tensor([0.8920, 0.8912, 0.8837, 0.8724, 0.8666, 0.8594, 0.8535, 0.8428],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8163])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8312], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8163])\n",
      ">>Entradas: tensor([0.8912, 0.8837, 0.8724, 0.8666, 0.8594, 0.8535, 0.8428, 0.8312],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8006])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8156], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8006])\n",
      ">>Entradas: tensor([0.8837, 0.8724, 0.8666, 0.8594, 0.8535, 0.8428, 0.8312, 0.8156],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7705])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7949], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7705])\n",
      ">>Entradas: tensor([0.8724, 0.8666, 0.8594, 0.8535, 0.8428, 0.8312, 0.8156, 0.7949],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7427])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7716], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7427])\n",
      ">>Entradas: tensor([0.8666, 0.8594, 0.8535, 0.8428, 0.8312, 0.8156, 0.7949, 0.7716],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7462], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7169])\n",
      ">>Entradas: tensor([0.8594, 0.8535, 0.8428, 0.8312, 0.8156, 0.7949, 0.7716, 0.7462],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7273], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7197])\n",
      ">>Entradas: tensor([0.8535, 0.8428, 0.8312, 0.8156, 0.7949, 0.7716, 0.7462, 0.7273],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7509])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7209], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7509])\n",
      ">>Entradas: tensor([0.8428, 0.8312, 0.8156, 0.7949, 0.7716, 0.7462, 0.7273, 0.7209],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7403])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7118], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7403])\n",
      ">>Entradas: tensor([0.8312, 0.8156, 0.7949, 0.7716, 0.7462, 0.7273, 0.7209, 0.7118],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6892], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.8156, 0.7949, 0.7716, 0.7462, 0.7273, 0.7209, 0.7118, 0.6892],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6688])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6685], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6688])\n",
      ">>Entradas: tensor([0.7949, 0.7716, 0.7462, 0.7273, 0.7209, 0.7118, 0.6892, 0.6685],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6835])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6575], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6835])\n",
      ">>Entradas: tensor([0.7716, 0.7462, 0.7273, 0.7209, 0.7118, 0.6892, 0.6685, 0.6575],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6490], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.7462, 0.7273, 0.7209, 0.7118, 0.6892, 0.6685, 0.6575, 0.6490],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6815])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6438], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6815])\n",
      ">>Entradas: tensor([0.7273, 0.7209, 0.7118, 0.6892, 0.6685, 0.6575, 0.6490, 0.6438],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6893])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6473], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6893])\n",
      ">>Entradas: tensor([0.7209, 0.7118, 0.6892, 0.6685, 0.6575, 0.6490, 0.6438, 0.6473],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7111])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6558], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7111])\n",
      ">>Entradas: tensor([0.7118, 0.6892, 0.6685, 0.6575, 0.6490, 0.6438, 0.6473, 0.6558],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7349])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6678], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7349])\n",
      ">>Entradas: tensor([0.6892, 0.6685, 0.6575, 0.6490, 0.6438, 0.6473, 0.6558, 0.6678],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7608])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6881], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7608])\n",
      ">>Entradas: tensor([0.6685, 0.6575, 0.6490, 0.6438, 0.6473, 0.6558, 0.6678, 0.6881],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7711])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7108], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7711])\n",
      ">>Entradas: tensor([0.6575, 0.6490, 0.6438, 0.6473, 0.6558, 0.6678, 0.6881, 0.7108],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7660])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7292], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7660])\n",
      ">>Entradas: tensor([0.6490, 0.6438, 0.6473, 0.6558, 0.6678, 0.6881, 0.7108, 0.7292],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7483])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7418], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7483])\n",
      ">>Entradas: tensor([0.6438, 0.6473, 0.6558, 0.6678, 0.6881, 0.7108, 0.7292, 0.7418],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7182])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7461], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7182])\n",
      ">>Entradas: tensor([0.6473, 0.6558, 0.6678, 0.6881, 0.7108, 0.7292, 0.7418, 0.7461],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7477], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7089])\n",
      ">>Entradas: tensor([0.6558, 0.6678, 0.6881, 0.7108, 0.7292, 0.7418, 0.7461, 0.7477],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7204])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7525], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7204])\n",
      ">>Entradas: tensor([0.6678, 0.6881, 0.7108, 0.7292, 0.7418, 0.7461, 0.7477, 0.7525],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7706])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7708], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7706])\n",
      ">>Entradas: tensor([0.6881, 0.7108, 0.7292, 0.7418, 0.7461, 0.7477, 0.7525, 0.7708],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8595])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8090], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8595])\n",
      ">>Entradas: tensor([0.7108, 0.7292, 0.7418, 0.7461, 0.7477, 0.7525, 0.7708, 0.8090],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8492], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9065])\n",
      ">>Entradas: tensor([0.7292, 0.7418, 0.7461, 0.7477, 0.7525, 0.7708, 0.8090, 0.8492],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9119])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8849], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9119])\n",
      ">>Entradas: tensor([0.7418, 0.7461, 0.7477, 0.7525, 0.7708, 0.8090, 0.8492, 0.8849],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9043])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9061], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9043])\n",
      ">>Entradas: tensor([0.7461, 0.7477, 0.7525, 0.7708, 0.8090, 0.8492, 0.8849, 0.9061],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8839])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9165], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8839])\n",
      ">>Entradas: tensor([0.7477, 0.7525, 0.7708, 0.8090, 0.8492, 0.8849, 0.9061, 0.9165],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9032])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9310], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9032])\n",
      ">>Entradas: tensor([0.7525, 0.7708, 0.8090, 0.8492, 0.8849, 0.9061, 0.9165, 0.9310],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9623])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9615], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9623])\n",
      ">>Entradas: tensor([0.7708, 0.8090, 0.8492, 0.8849, 0.9061, 0.9165, 0.9310, 0.9615],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9821])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9907], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9821])\n",
      ">>Entradas: tensor([0.8090, 0.8492, 0.8849, 0.9061, 0.9165, 0.9310, 0.9615, 0.9907],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9624])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0056], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9624])\n",
      ">>Entradas: tensor([0.8492, 0.8849, 0.9061, 0.9165, 0.9310, 0.9615, 0.9907, 1.0056],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9303])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0034], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9303])\n",
      ">>Entradas: tensor([0.8849, 0.9061, 0.9165, 0.9310, 0.9615, 0.9907, 1.0056, 1.0034],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8855])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9852], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8855])\n",
      ">>Entradas: tensor([0.9061, 0.9165, 0.9310, 0.9615, 0.9907, 1.0056, 1.0034, 0.9852],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8597])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9584], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8597])\n",
      ">>Entradas: tensor([0.9165, 0.9310, 0.9615, 0.9907, 1.0056, 1.0034, 0.9852, 0.9584],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8529])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9350], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8529])\n",
      ">>Entradas: tensor([0.9310, 0.9615, 0.9907, 1.0056, 1.0034, 0.9852, 0.9584, 0.9350],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9186], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.9615, 0.9907, 1.0056, 1.0034, 0.9852, 0.9584, 0.9350, 0.9186],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8769])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8865], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8769])\n",
      ">>Entradas: tensor([0.9907, 1.0056, 1.0034, 0.9852, 0.9584, 0.9350, 0.9186, 0.8865],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8806])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8797], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8806])\n",
      ">>Entradas: tensor([1.0056, 1.0034, 0.9852, 0.9584, 0.9350, 0.9186, 0.8865, 0.8797],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8699])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8658], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8699])\n",
      ">>Entradas: tensor([1.0034, 0.9852, 0.9584, 0.9350, 0.9186, 0.8865, 0.8797, 0.8658],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8465])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8438], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8465])\n",
      ">>Entradas: tensor([0.9852, 0.9584, 0.9350, 0.9186, 0.8865, 0.8797, 0.8658, 0.8438],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8104])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8170], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8104])\n",
      ">>Entradas: tensor([0.9584, 0.9350, 0.9186, 0.8865, 0.8797, 0.8658, 0.8438, 0.8170],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8026])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7986], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8026])\n",
      ">>Entradas: tensor([0.9350, 0.9186, 0.8865, 0.8797, 0.8658, 0.8438, 0.8170, 0.7986],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8232])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7884], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8232])\n",
      ">>Entradas: tensor([0.9186, 0.8865, 0.8797, 0.8658, 0.8438, 0.8170, 0.7986, 0.7884],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8397])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7861], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8397])\n",
      ">>Entradas: tensor([0.8865, 0.8797, 0.8658, 0.8438, 0.8170, 0.7986, 0.7884, 0.7861],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8522])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7932], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8522])\n",
      ">>Entradas: tensor([0.8797, 0.8658, 0.8438, 0.8170, 0.7986, 0.7884, 0.7861, 0.7932],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8616])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8020], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8616])\n",
      ">>Entradas: tensor([0.8658, 0.8438, 0.8170, 0.7986, 0.7884, 0.7861, 0.7932, 0.8020],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8679])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8102], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8679])\n",
      ">>Entradas: tensor([0.8438, 0.8170, 0.7986, 0.7884, 0.7861, 0.7932, 0.8020, 0.8102],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8702])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8195], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8702])\n",
      ">>Entradas: tensor([0.8170, 0.7986, 0.7884, 0.7861, 0.7932, 0.8020, 0.8102, 0.8195],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8685])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8303], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8685])\n",
      ">>Entradas: tensor([0.7986, 0.7884, 0.7861, 0.7932, 0.8020, 0.8102, 0.8195, 0.8303],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8530])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8372], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8530])\n",
      ">>Entradas: tensor([0.7884, 0.7861, 0.7932, 0.8020, 0.8102, 0.8195, 0.8303, 0.8372],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8236])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8373], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8236])\n",
      ">>Entradas: tensor([0.7861, 0.7932, 0.8020, 0.8102, 0.8195, 0.8303, 0.8372, 0.8373],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8323], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.7932, 0.8020, 0.8102, 0.8195, 0.8303, 0.8372, 0.8373, 0.8323],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7919])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8265], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7919])\n",
      ">>Entradas: tensor([0.8020, 0.8102, 0.8195, 0.8303, 0.8372, 0.8373, 0.8323, 0.8265],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7865])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8188], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7865])\n",
      ">>Entradas: tensor([0.8102, 0.8195, 0.8303, 0.8372, 0.8373, 0.8323, 0.8265, 0.8188],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7870])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8123], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7870])\n",
      ">>Entradas: tensor([0.8195, 0.8303, 0.8372, 0.8373, 0.8323, 0.8265, 0.8188, 0.8123],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7874])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8065], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7874])\n",
      ">>Entradas: tensor([0.8303, 0.8372, 0.8373, 0.8323, 0.8265, 0.8188, 0.8123, 0.8065],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7879])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8002], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7879])\n",
      ">>Entradas: tensor([0.8372, 0.8373, 0.8323, 0.8265, 0.8188, 0.8123, 0.8065, 0.8002],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7955])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7954], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7955])\n",
      ">>Entradas: tensor([0.8373, 0.8323, 0.8265, 0.8188, 0.8123, 0.8065, 0.8002, 0.7954],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8102])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7951], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8102])\n",
      ">>Entradas: tensor([0.8323, 0.8265, 0.8188, 0.8123, 0.8065, 0.8002, 0.7954, 0.7951],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7668])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7814], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7668])\n",
      ">>Entradas: tensor([0.8265, 0.8188, 0.8123, 0.8065, 0.8002, 0.7954, 0.7951, 0.7814],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6655])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7417], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6655])\n",
      ">>Entradas: tensor([0.8188, 0.8123, 0.8065, 0.8002, 0.7954, 0.7951, 0.7814, 0.7417],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6361])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7046], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6361])\n",
      ">>Entradas: tensor([0.8123, 0.8065, 0.8002, 0.7954, 0.7951, 0.7814, 0.7417, 0.7046],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6785])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6876], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6785])\n",
      ">>Entradas: tensor([0.8065, 0.8002, 0.7954, 0.7951, 0.7814, 0.7417, 0.7046, 0.6876],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6756], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6966])\n",
      ">>Entradas: tensor([0.8002, 0.7954, 0.7951, 0.7814, 0.7417, 0.7046, 0.6876, 0.6756],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6903])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6647], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6903])\n",
      ">>Entradas: tensor([0.7954, 0.7951, 0.7814, 0.7417, 0.7046, 0.6876, 0.6756, 0.6647],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6970])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6615], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6970])\n",
      ">>Entradas: tensor([0.7951, 0.7814, 0.7417, 0.7046, 0.6876, 0.6756, 0.6647, 0.6615],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7167])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6613], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7167])\n",
      ">>Entradas: tensor([0.7814, 0.7417, 0.7046, 0.6876, 0.6756, 0.6647, 0.6615, 0.6613],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7491])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6665], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7491])\n",
      ">>Entradas: tensor([0.7417, 0.7046, 0.6876, 0.6756, 0.6647, 0.6615, 0.6613, 0.6665],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7940])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6886], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7940])\n",
      ">>Entradas: tensor([0.7046, 0.6876, 0.6756, 0.6647, 0.6615, 0.6613, 0.6665, 0.6886],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8547])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7307], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8547])\n",
      ">>Entradas: tensor([0.6876, 0.6756, 0.6647, 0.6615, 0.6613, 0.6665, 0.6886, 0.7307],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9314])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7896], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9314])\n",
      ">>Entradas: tensor([0.6756, 0.6647, 0.6615, 0.6613, 0.6665, 0.6886, 0.7307, 0.7896],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9627])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8481], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9627])\n",
      ">>Entradas: tensor([0.6647, 0.6615, 0.6613, 0.6665, 0.6886, 0.7307, 0.7896, 0.8481],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9486])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8950], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9486])\n",
      ">>Entradas: tensor([0.6615, 0.6613, 0.6665, 0.6886, 0.7307, 0.7896, 0.8481, 0.8950],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9307])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9309], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9307])\n",
      ">>Entradas: tensor([0.6613, 0.6665, 0.6886, 0.7307, 0.7896, 0.8481, 0.8950, 0.9309],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9090])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9553], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9090])\n",
      ">>Entradas: tensor([0.6665, 0.6886, 0.7307, 0.7896, 0.8481, 0.8950, 0.9309, 0.9553],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8816])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9686], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8816])\n",
      ">>Entradas: tensor([0.6886, 0.7307, 0.7896, 0.8481, 0.8950, 0.9309, 0.9553, 0.9686],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8487])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9710], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8487])\n",
      ">>Entradas: tensor([0.7307, 0.7896, 0.8481, 0.8950, 0.9309, 0.9553, 0.9686, 0.9710],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8753])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9790], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8753])\n",
      ">>Entradas: tensor([0.7896, 0.8481, 0.8950, 0.9309, 0.9553, 0.9686, 0.9710, 0.9790],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9612])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0032], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9612])\n",
      ">>Entradas: tensor([0.8481, 0.8950, 0.9309, 0.9553, 0.9686, 0.9710, 0.9790, 1.0032],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9925])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0218], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9925])\n",
      ">>Entradas: tensor([0.8950, 0.9309, 0.9553, 0.9686, 0.9710, 0.9790, 1.0032, 1.0218],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9690])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0233], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9690])\n",
      ">>Entradas: tensor([0.9309, 0.9553, 0.9686, 0.9710, 0.9790, 1.0032, 1.0218, 1.0233],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9715])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0222], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9715])\n",
      ">>Entradas: tensor([0.9553, 0.9686, 0.9710, 0.9790, 1.0032, 1.0218, 1.0233, 1.0222],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([1.])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0251], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([1.])\n",
      ">>Entradas: tensor([0.9686, 0.9710, 0.9790, 1.0032, 1.0218, 1.0233, 1.0222, 1.0251],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0162], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9801])\n",
      ">>Entradas: tensor([0.9710, 0.9790, 1.0032, 1.0218, 1.0233, 1.0222, 1.0251, 1.0162],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9909], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9117])\n",
      ">>Entradas: tensor([0.9790, 1.0032, 1.0218, 1.0233, 1.0222, 1.0251, 1.0162, 0.9909],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8911])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9684], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8911])\n",
      ">>Entradas: tensor([1.0032, 1.0218, 1.0233, 1.0222, 1.0251, 1.0162, 0.9909, 0.9684],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9181])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9546], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9181])\n",
      ">>Entradas: tensor([1.0218, 1.0233, 1.0222, 1.0251, 1.0162, 0.9909, 0.9684, 0.9546],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9450])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9456], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9450])\n",
      ">>Entradas: tensor([1.0233, 1.0222, 1.0251, 1.0162, 0.9909, 0.9684, 0.9546, 0.9456],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9718])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9463], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9718])\n",
      ">>Entradas: tensor([1.0222, 1.0251, 1.0162, 0.9909, 0.9684, 0.9546, 0.9456, 0.9463],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9829])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9511], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9829])\n",
      ">>Entradas: tensor([1.0251, 1.0162, 0.9909, 0.9684, 0.9546, 0.9456, 0.9463, 0.9511],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9783])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9504], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9783])\n",
      ">>s_original: [0.049424633383750916, 0.10789185762405396, 0.13719609379768372, 0.13733737170696259, 0.1338856965303421, 0.12684109807014465, 0.14756061136722565, 0.19604423642158508, 0.21688967943191528, 0.21009695529937744, 0.20267784595489502, 0.1946323662996292, 0.19407351315021515, 0.20100130140781403, 0.19663821160793304, 0.180984228849411, 0.16539041697978973, 0.14985674619674683, 0.15043111145496368, 0.1671135276556015, 0.20227035880088806, 0.25590160489082336, 0.29268819093704224, 0.31263017654418945, 0.31093889474868774, 0.2876143157482147, 0.28016164898872375, 0.28858086466789246, 0.28246283531188965, 0.26180753111839294, 0.2801212966442108, 0.3374040722846985, 0.3482298254966736, 0.3125985562801361, 0.34358710050582886, 0.44119545817375183, 0.521095335483551, 0.5832866430282593, 0.6089234352111816, 0.5980057120323181, 0.5945301651954651, 0.5984968543052673, 0.621354341506958, 0.6631026864051819, 0.6928724050521851, 0.7106636166572571, 0.721682071685791, 0.7259277701377869, 0.7404318451881409, 0.7651942372322083, 0.7447891235351562, 0.6792163252830505, 0.6746017932891846, 0.730945348739624, 0.7467210292816162, 0.7219287157058716, 0.7199286818504333, 0.7407209277153015, 0.7362455129623413, 0.7065023183822632, 0.6979451775550842, 0.7105739712715149, 0.7209621667861938, 0.7291097044944763, 0.7674259543418884, 0.8359109163284302, 0.8510103225708008, 0.8127241730690002, 0.7863940000534058, 0.7720199823379517, 0.8033170700073242, 0.8802852630615234, 0.8987051844596863, 0.8585767149925232, 0.8308762311935425, 0.8156037926673889, 0.8116992115974426, 0.8191625475883484, 0.8218275904655457, 0.8196942210197449, 0.817862868309021, 0.8163333535194397, 0.8005555868148804, 0.7705295085906982, 0.7426586747169495, 0.716943085193634, 0.7197051048278809, 0.7509447932243347, 0.7402781248092651, 0.6877052187919617, 0.6687695384025574, 0.683471143245697, 0.6877052187919617, 0.6814717054367065, 0.6892618536949158, 0.7110756039619446, 0.7349108457565308, 0.7607676982879639, 0.771117091178894, 0.7659589648246765, 0.7483323812484741, 0.7182371616363525, 0.708941638469696, 0.7204458117485046, 0.7706154584884644, 0.8594506978988647, 0.906541109085083, 0.9118866324424744, 0.9043355584144592, 0.8838878870010376, 0.9032153487205505, 0.9623178839683533, 0.9820588231086731, 0.96243816614151, 0.9302511811256409, 0.8854979276657104, 0.8597025871276855, 0.8528652191162109, 0.8585854768753052, 0.8768633008003235, 0.8806464076042175, 0.8699347376823425, 0.846513569355011, 0.8103827834129333, 0.8026111125946045, 0.8231984972953796, 0.8397204279899597, 0.8521769046783447, 0.8615626692771912, 0.8678776621818542, 0.8701963424682617, 0.868518590927124, 0.852988064289093, 0.8236046433448792, 0.8032509088516235, 0.7919268012046814, 0.7865023016929626, 0.7869773507118225, 0.7874362468719482, 0.7878790497779846, 0.7954531908035278, 0.8101586699485779, 0.7668473124504089, 0.665519118309021, 0.6360738277435303, 0.678511381149292, 0.6965967416763306, 0.6903298497200012, 0.6970472931861877, 0.7167490720748901, 0.7490506768226624, 0.7939522862434387, 0.8547447323799133, 0.931428074836731, 0.9627243876457214, 0.9486336708068848, 0.9307146072387695, 0.9089671969413757, 0.8816379904747009, 0.8487268090248108, 0.8752607107162476, 0.9612395763397217, 0.9925020933151245, 0.9690483212471008, 0.9715476036071777, 1.0, 0.9800636768341064, 0.9117385745048523, 0.8910858035087585, 0.9181053042411804, 0.9450165033340454, 0.9718193411827087, 0.982906699180603, 0.9782785773277283]\n",
      ">>s_pred: [-0.19881629943847656, -0.08671951293945312, -0.02022075653076172, -0.030098915100097656, 0.02017974853515625, 0.06790924072265625, 0.05277442932128906, 0.0903768539428711, 0.15872859954833984, 0.1877431869506836, 0.2065887451171875, 0.23739242553710938, 0.2458333969116211, 0.22939586639404297, 0.2515106201171875, 0.25365734100341797, 0.23810195922851562, 0.22659969329833984, 0.21583080291748047, 0.19899368286132812, 0.19775676727294922, 0.21505260467529297, 0.23131370544433594, 0.250030517578125, 0.26544857025146484, 0.2710380554199219, 0.27583980560302734, 0.28752708435058594, 0.29556846618652344, 0.29541015625, 0.30228424072265625, 0.32149314880371094, 0.3332977294921875, 0.3325786590576172, 0.34599971771240234, 0.38262176513671875, 0.42792224884033203, 0.4843311309814453, 0.5413064956665039, 0.5820436477661133, 0.6146383285522461, 0.646575927734375, 0.6812992095947266, 0.7189407348632812, 0.7561540603637695, 0.7846889495849609, 0.8027687072753906, 0.8126296997070312, 0.8203201293945312, 0.8296871185302734, 0.827056884765625, 0.8023996353149414, 0.77813720703125, 0.7697505950927734, 0.7607765197753906, 0.744415283203125, 0.7332391738891602, 0.7266473770141602, 0.714381217956543, 0.6989412307739258, 0.6900548934936523, 0.6862850189208984, 0.6851091384887695, 0.6894264221191406, 0.7063198089599609, 0.7390642166137695, 0.7691230773925781, 0.7852334976196289, 0.7952661514282227, 0.8005571365356445, 0.8141708374023438, 0.8494367599487305, 0.8821935653686523, 0.8920078277587891, 0.8911619186401367, 0.8837451934814453, 0.8723735809326172, 0.8666019439697266, 0.8593931198120117, 0.8535423278808594, 0.8428401947021484, 0.8312320709228516, 0.8156452178955078, 0.7948513031005859, 0.7716131210327148, 0.7462072372436523, 0.7272710800170898, 0.7208929061889648, 0.7117633819580078, 0.6891813278198242, 0.6685171127319336, 0.6575202941894531, 0.6490306854248047, 0.6438465118408203, 0.6472501754760742, 0.6558170318603516, 0.6678085327148438, 0.688075065612793, 0.7108221054077148, 0.7292242050170898, 0.7417716979980469, 0.7461462020874023, 0.7477197647094727, 0.7524919509887695, 0.7707595825195312, 0.8089666366577148, 0.8491525650024414, 0.8849277496337891, 0.9061193466186523, 0.9165401458740234, 0.9309844970703125, 0.9614715576171875, 0.9906797409057617, 1.005640983581543, 1.003413200378418, 0.98516845703125, 0.9583873748779297, 0.9350204467773438, 0.9185876846313477, 0.8864612579345703, 0.8796682357788086, 0.8658075332641602, 0.8438282012939453, 0.8169879913330078, 0.7985982894897461, 0.788447380065918, 0.7860593795776367, 0.7932424545288086, 0.802001953125, 0.8101921081542969, 0.8194770812988281, 0.8302907943725586, 0.8372116088867188, 0.8373470306396484, 0.8322772979736328, 0.8265190124511719, 0.8187999725341797, 0.8122777938842773, 0.8064985275268555, 0.8001766204833984, 0.7953691482543945, 0.795074462890625, 0.7813949584960938, 0.7416696548461914, 0.7045822143554688, 0.6875600814819336, 0.6756229400634766, 0.6647329330444336, 0.6614913940429688, 0.6612997055053711, 0.6664886474609375, 0.6885604858398438, 0.7306928634643555, 0.7895650863647461, 0.8481044769287109, 0.8950328826904297, 0.9308567047119141, 0.9552888870239258, 0.968623161315918, 0.9709672927856445, 0.9790115356445312, 1.0032243728637695, 1.0217723846435547, 1.0233230590820312, 1.0221853256225586, 1.0251121520996094, 1.0162334442138672, 0.9909048080444336, 0.9684343338012695, 0.95458984375, 0.9456243515014648, 0.9463186264038086, 0.9510507583618164, 0.9503946304321289]\n",
      "<<Perdida: 0.0036530550569295883 epoca: 18\n",
      "---Inicio de epoca: 19--\n",
      ">>Entradas: tensor([0.0503, 0.0086, 0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203])\n",
      ">>Salida: tensor([0.0494])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([-0.1666], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.0494])\n",
      ">>Entradas: tensor([ 0.0086,  0.0000,  0.0245,  0.0327,  0.0246,  0.0205,  0.0203, -0.1666],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1079])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([-0.0632], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1079])\n",
      ">>Entradas: tensor([ 0.0000,  0.0245,  0.0327,  0.0246,  0.0205,  0.0203, -0.1666, -0.0632],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1372])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0003], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1372])\n",
      ">>Entradas: tensor([ 0.0245,  0.0327,  0.0246,  0.0205,  0.0203, -0.1666, -0.0632,  0.0003],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1373])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([-0.0066], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1373])\n",
      ">>Entradas: tensor([ 0.0327,  0.0246,  0.0205,  0.0203, -0.1666, -0.0632,  0.0003, -0.0066],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1339])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0380], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1339])\n",
      ">>Entradas: tensor([ 0.0246,  0.0205,  0.0203, -0.1666, -0.0632,  0.0003, -0.0066,  0.0380],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1268])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0770], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1268])\n",
      ">>Entradas: tensor([ 0.0205,  0.0203, -0.1666, -0.0632,  0.0003, -0.0066,  0.0380,  0.0770],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1476])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0675], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1476])\n",
      ">>Entradas: tensor([ 0.0203, -0.1666, -0.0632,  0.0003, -0.0066,  0.0380,  0.0770,  0.0675],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1960])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1039], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1960])\n",
      ">>Entradas: tensor([-0.1666, -0.0632,  0.0003, -0.0066,  0.0380,  0.0770,  0.0675,  0.1039],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1628], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2169])\n",
      ">>Entradas: tensor([-0.0632,  0.0003, -0.0066,  0.0380,  0.0770,  0.0675,  0.1039,  0.1628],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2101])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1801], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2101])\n",
      ">>Entradas: tensor([ 0.0003, -0.0066,  0.0380,  0.0770,  0.0675,  0.1039,  0.1628,  0.1801],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2027])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1969], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2027])\n",
      ">>Entradas: tensor([-0.0066,  0.0380,  0.0770,  0.0675,  0.1039,  0.1628,  0.1801,  0.1969],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1946])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2213], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1946])\n",
      ">>Entradas: tensor([0.0380, 0.0770, 0.0675, 0.1039, 0.1628, 0.1801, 0.1969, 0.2213],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1941])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2265], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1941])\n",
      ">>Entradas: tensor([0.0770, 0.0675, 0.1039, 0.1628, 0.1801, 0.1969, 0.2213, 0.2265],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2010])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2306], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2010])\n",
      ">>Entradas: tensor([0.0675, 0.1039, 0.1628, 0.1801, 0.1969, 0.2213, 0.2265, 0.2306],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2436], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1966])\n",
      ">>Entradas: tensor([0.1039, 0.1628, 0.1801, 0.1969, 0.2213, 0.2265, 0.2306, 0.2436],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1810])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1954], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1810])\n",
      ">>Entradas: tensor([0.1628, 0.1801, 0.1969, 0.2213, 0.2265, 0.2306, 0.2436, 0.1954],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1654])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2032], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1654])\n",
      ">>Entradas: tensor([0.1801, 0.1969, 0.2213, 0.2265, 0.2306, 0.2436, 0.1954, 0.2032],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1499])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2005], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1499])\n",
      ">>Entradas: tensor([0.1969, 0.2213, 0.2265, 0.2306, 0.2436, 0.1954, 0.2032, 0.2005],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1504])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1821], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1504])\n",
      ">>Entradas: tensor([0.2213, 0.2265, 0.2306, 0.2436, 0.1954, 0.2032, 0.2005, 0.1821],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1671])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1788], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1671])\n",
      ">>Entradas: tensor([0.2265, 0.2306, 0.2436, 0.1954, 0.2032, 0.2005, 0.1821, 0.1788],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2023])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1900], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2023])\n",
      ">>Entradas: tensor([0.2306, 0.2436, 0.1954, 0.2032, 0.2005, 0.1821, 0.1788, 0.1900],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2559])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1980], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2559])\n",
      ">>Entradas: tensor([0.2436, 0.1954, 0.2032, 0.2005, 0.1821, 0.1788, 0.1900, 0.1980],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2927])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2152], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2927])\n",
      ">>Entradas: tensor([0.1954, 0.2032, 0.2005, 0.1821, 0.1788, 0.1900, 0.1980, 0.2152],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2429], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2032, 0.2005, 0.1821, 0.1788, 0.1900, 0.1980, 0.2152, 0.2429],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3109])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2607], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3109])\n",
      ">>Entradas: tensor([0.2005, 0.1821, 0.1788, 0.1900, 0.1980, 0.2152, 0.2429, 0.2607],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2876])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2679], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2876])\n",
      ">>Entradas: tensor([0.1821, 0.1788, 0.1900, 0.1980, 0.2152, 0.2429, 0.2607, 0.2679],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2802])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2803], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2802])\n",
      ">>Entradas: tensor([0.1788, 0.1900, 0.1980, 0.2152, 0.2429, 0.2607, 0.2679, 0.2803],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2886])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2943], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2886])\n",
      ">>Entradas: tensor([0.1900, 0.1980, 0.2152, 0.2429, 0.2607, 0.2679, 0.2803, 0.2943],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2825])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3012], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2825])\n",
      ">>Entradas: tensor([0.1980, 0.2152, 0.2429, 0.2607, 0.2679, 0.2803, 0.2943, 0.3012],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2618])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3042], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2618])\n",
      ">>Entradas: tensor([0.2152, 0.2429, 0.2607, 0.2679, 0.2803, 0.2943, 0.3012, 0.3042],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3141], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2801])\n",
      ">>Entradas: tensor([0.2429, 0.2607, 0.2679, 0.2803, 0.2943, 0.3012, 0.3042, 0.3141],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3374])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3328], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3374])\n",
      ">>Entradas: tensor([0.2607, 0.2679, 0.2803, 0.2943, 0.3012, 0.3042, 0.3141, 0.3328],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3482])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3448], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3482])\n",
      ">>Entradas: tensor([0.2679, 0.2803, 0.2943, 0.3012, 0.3042, 0.3141, 0.3328, 0.3448],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3448], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2803, 0.2943, 0.3012, 0.3042, 0.3141, 0.3328, 0.3448, 0.3448],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3436])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3570], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3436])\n",
      ">>Entradas: tensor([0.2943, 0.3012, 0.3042, 0.3141, 0.3328, 0.3448, 0.3448, 0.3570],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.4412])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3914], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.4412])\n",
      ">>Entradas: tensor([0.3012, 0.3042, 0.3141, 0.3328, 0.3448, 0.3448, 0.3570, 0.3914],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5211])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4354], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5211])\n",
      ">>Entradas: tensor([0.3042, 0.3141, 0.3328, 0.3448, 0.3448, 0.3570, 0.3914, 0.4354],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5833])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4901], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5833])\n",
      ">>Entradas: tensor([0.3141, 0.3328, 0.3448, 0.3448, 0.3570, 0.3914, 0.4354, 0.4901],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5454], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6089])\n",
      ">>Entradas: tensor([0.3328, 0.3448, 0.3448, 0.3570, 0.3914, 0.4354, 0.4901, 0.5454],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5980])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5848], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5980])\n",
      ">>Entradas: tensor([0.3448, 0.3448, 0.3570, 0.3914, 0.4354, 0.4901, 0.5454, 0.5848],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5945])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6163], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5945])\n",
      ">>Entradas: tensor([0.3448, 0.3570, 0.3914, 0.4354, 0.4901, 0.5454, 0.5848, 0.6163],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5985])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6483], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5985])\n",
      ">>Entradas: tensor([0.3570, 0.3914, 0.4354, 0.4901, 0.5454, 0.5848, 0.6163, 0.6483],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6214])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6829], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6214])\n",
      ">>Entradas: tensor([0.3914, 0.4354, 0.4901, 0.5454, 0.5848, 0.6163, 0.6483, 0.6829],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6631])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7219], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6631])\n",
      ">>Entradas: tensor([0.4354, 0.4901, 0.5454, 0.5848, 0.6163, 0.6483, 0.6829, 0.7219],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6929])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7602], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6929])\n",
      ">>Entradas: tensor([0.4901, 0.5454, 0.5848, 0.6163, 0.6483, 0.6829, 0.7219, 0.7602],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7107])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7895], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7107])\n",
      ">>Entradas: tensor([0.5454, 0.5848, 0.6163, 0.6483, 0.6829, 0.7219, 0.7602, 0.7895],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7217])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8082], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7217])\n",
      ">>Entradas: tensor([0.5848, 0.6163, 0.6483, 0.6829, 0.7219, 0.7602, 0.7895, 0.8082],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7259])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8188], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7259])\n",
      ">>Entradas: tensor([0.6163, 0.6483, 0.6829, 0.7219, 0.7602, 0.7895, 0.8082, 0.8188],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7404])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8272], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7404])\n",
      ">>Entradas: tensor([0.6483, 0.6829, 0.7219, 0.7602, 0.7895, 0.8082, 0.8188, 0.8272],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7652])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8373], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7652])\n",
      ">>Entradas: tensor([0.6829, 0.7219, 0.7602, 0.7895, 0.8082, 0.8188, 0.8272, 0.8373],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7448])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8355], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7448])\n",
      ">>Entradas: tensor([0.7219, 0.7602, 0.7895, 0.8082, 0.8188, 0.8272, 0.8373, 0.8355],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6792])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8084], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6792])\n",
      ">>Entradas: tensor([0.7602, 0.7895, 0.8082, 0.8188, 0.8272, 0.8373, 0.8355, 0.8084],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6746])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7851], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6746])\n",
      ">>Entradas: tensor([0.7895, 0.8082, 0.8188, 0.8272, 0.8373, 0.8355, 0.8084, 0.7851],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7768], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7309])\n",
      ">>Entradas: tensor([0.8082, 0.8188, 0.8272, 0.8373, 0.8355, 0.8084, 0.7851, 0.7768],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7467])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7662], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7467])\n",
      ">>Entradas: tensor([0.8188, 0.8272, 0.8373, 0.8355, 0.8084, 0.7851, 0.7768, 0.7662],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7219])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7487], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7219])\n",
      ">>Entradas: tensor([0.8272, 0.8373, 0.8355, 0.8084, 0.7851, 0.7768, 0.7662, 0.7487],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7199])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7372], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7199])\n",
      ">>Entradas: tensor([0.8373, 0.8355, 0.8084, 0.7851, 0.7768, 0.7662, 0.7487, 0.7372],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7407])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7288], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7407])\n",
      ">>Entradas: tensor([0.8355, 0.8084, 0.7851, 0.7768, 0.7662, 0.7487, 0.7372, 0.7288],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7362])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7138], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7362])\n",
      ">>Entradas: tensor([0.8084, 0.7851, 0.7768, 0.7662, 0.7487, 0.7372, 0.7288, 0.7138],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6970], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7065])\n",
      ">>Entradas: tensor([0.7851, 0.7768, 0.7662, 0.7487, 0.7372, 0.7288, 0.7138, 0.6970],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6979])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6873], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6979])\n",
      ">>Entradas: tensor([0.7768, 0.7662, 0.7487, 0.7372, 0.7288, 0.7138, 0.6970, 0.6873],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7106])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6822], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7106])\n",
      ">>Entradas: tensor([0.7662, 0.7487, 0.7372, 0.7288, 0.7138, 0.6970, 0.6873, 0.6822],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7210])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6801], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7210])\n",
      ">>Entradas: tensor([0.7487, 0.7372, 0.7288, 0.7138, 0.6970, 0.6873, 0.6822, 0.6801],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7291])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6841], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7291])\n",
      ">>Entradas: tensor([0.7372, 0.7288, 0.7138, 0.6970, 0.6873, 0.6822, 0.6801, 0.6841],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7674])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7006], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7674])\n",
      ">>Entradas: tensor([0.7288, 0.7138, 0.6970, 0.6873, 0.6822, 0.6801, 0.6841, 0.7006],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8359])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7327], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8359])\n",
      ">>Entradas: tensor([0.7138, 0.6970, 0.6873, 0.6822, 0.6801, 0.6841, 0.7006, 0.7327],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8510])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7626], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8510])\n",
      ">>Entradas: tensor([0.6970, 0.6873, 0.6822, 0.6801, 0.6841, 0.7006, 0.7327, 0.7626],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8127])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7790], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8127])\n",
      ">>Entradas: tensor([0.6873, 0.6822, 0.6801, 0.6841, 0.7006, 0.7327, 0.7626, 0.7790],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7864])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7901], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7864])\n",
      ">>Entradas: tensor([0.6822, 0.6801, 0.6841, 0.7006, 0.7327, 0.7626, 0.7790, 0.7901],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7720])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7969], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7720])\n",
      ">>Entradas: tensor([0.6801, 0.6841, 0.7006, 0.7327, 0.7626, 0.7790, 0.7901, 0.7969],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8119], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.6841, 0.7006, 0.7327, 0.7626, 0.7790, 0.7901, 0.7969, 0.8119],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8803])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8488], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8803])\n",
      ">>Entradas: tensor([0.7006, 0.7327, 0.7626, 0.7790, 0.7901, 0.7969, 0.8119, 0.8488],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8987])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8831], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8987])\n",
      ">>Entradas: tensor([0.7327, 0.7626, 0.7790, 0.7901, 0.7969, 0.8119, 0.8488, 0.8831],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8949], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.7626, 0.7790, 0.7901, 0.7969, 0.8119, 0.8488, 0.8831, 0.8949],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8955], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8309])\n",
      ">>Entradas: tensor([0.7790, 0.7901, 0.7969, 0.8119, 0.8488, 0.8831, 0.8949, 0.8955],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8156])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8895], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8156])\n",
      ">>Entradas: tensor([0.7901, 0.7969, 0.8119, 0.8488, 0.8831, 0.8949, 0.8955, 0.8895],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8785], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8117])\n",
      ">>Entradas: tensor([0.7969, 0.8119, 0.8488, 0.8831, 0.8949, 0.8955, 0.8895, 0.8785],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8192])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8733], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8192])\n",
      ">>Entradas: tensor([0.8119, 0.8488, 0.8831, 0.8949, 0.8955, 0.8895, 0.8785, 0.8733],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8218])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8728], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8218])\n",
      ">>Entradas: tensor([0.8488, 0.8831, 0.8949, 0.8955, 0.8895, 0.8785, 0.8733, 0.8728],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8662], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8197])\n",
      ">>Entradas: tensor([0.8831, 0.8949, 0.8955, 0.8895, 0.8785, 0.8733, 0.8728, 0.8662],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8179])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8538], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8179])\n",
      ">>Entradas: tensor([0.8949, 0.8955, 0.8895, 0.8785, 0.8733, 0.8728, 0.8662, 0.8538],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8163])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8409], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8163])\n",
      ">>Entradas: tensor([0.8955, 0.8895, 0.8785, 0.8733, 0.8728, 0.8662, 0.8538, 0.8409],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8006])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8233], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8006])\n",
      ">>Entradas: tensor([0.8895, 0.8785, 0.8733, 0.8728, 0.8662, 0.8538, 0.8409, 0.8233],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7705])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7995], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7705])\n",
      ">>Entradas: tensor([0.8785, 0.8733, 0.8728, 0.8662, 0.8538, 0.8409, 0.8233, 0.7995],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7427])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6938], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7427])\n",
      "ERROR: la modificacion de los pesos di√≥ un error mayor: 0.0023855888284742832, se regresa al estado anterior de la red\n",
      ">>Entradas: tensor([0.8733, 0.8728, 0.8662, 0.8538, 0.8409, 0.8233, 0.7995, 0.7894],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7597], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7169])\n",
      ">>Entradas: tensor([0.8728, 0.8662, 0.8538, 0.8409, 0.8233, 0.7995, 0.7894, 0.7597],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7360], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7197])\n",
      ">>Entradas: tensor([0.8662, 0.8538, 0.8409, 0.8233, 0.7995, 0.7894, 0.7597, 0.7360],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7509])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7277], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7509])\n",
      ">>Entradas: tensor([0.8538, 0.8409, 0.8233, 0.7995, 0.7894, 0.7597, 0.7360, 0.7277],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7403])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7156], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7403])\n",
      ">>Entradas: tensor([0.8409, 0.8233, 0.7995, 0.7894, 0.7597, 0.7360, 0.7277, 0.7156],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6880], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.8233, 0.7995, 0.7894, 0.7597, 0.7360, 0.7277, 0.7156, 0.6880],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6688])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6673], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6688])\n",
      ">>Entradas: tensor([0.7995, 0.7894, 0.7597, 0.7360, 0.7277, 0.7156, 0.6880, 0.6673],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6835])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6569], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6835])\n",
      ">>Entradas: tensor([0.7894, 0.7597, 0.7360, 0.7277, 0.7156, 0.6880, 0.6673, 0.6569],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6446], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.7597, 0.7360, 0.7277, 0.7156, 0.6880, 0.6673, 0.6569, 0.6446],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6815])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6369], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6815])\n",
      ">>Entradas: tensor([0.7360, 0.7277, 0.7156, 0.6880, 0.6673, 0.6569, 0.6446, 0.6369],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6893])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6402], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6893])\n",
      ">>Entradas: tensor([0.7277, 0.7156, 0.6880, 0.6673, 0.6569, 0.6446, 0.6369, 0.6402],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7111])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6473], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7111])\n",
      ">>Entradas: tensor([0.7156, 0.6880, 0.6673, 0.6569, 0.6446, 0.6369, 0.6402, 0.6473],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7349])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6581], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7349])\n",
      ">>Entradas: tensor([0.6880, 0.6673, 0.6569, 0.6446, 0.6369, 0.6402, 0.6473, 0.6581],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7608])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6793], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7608])\n",
      ">>Entradas: tensor([0.6673, 0.6569, 0.6446, 0.6369, 0.6402, 0.6473, 0.6581, 0.6793],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7711])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7028], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7711])\n",
      ">>Entradas: tensor([0.6569, 0.6446, 0.6369, 0.6402, 0.6473, 0.6581, 0.6793, 0.7028],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7660])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7211], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7660])\n",
      ">>Entradas: tensor([0.6446, 0.6369, 0.6402, 0.6473, 0.6581, 0.6793, 0.7028, 0.7211],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7483])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7350], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7483])\n",
      ">>Entradas: tensor([0.6369, 0.6402, 0.6473, 0.6581, 0.6793, 0.7028, 0.7211, 0.7350],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7182])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7416], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7182])\n",
      ">>Entradas: tensor([0.6402, 0.6473, 0.6581, 0.6793, 0.7028, 0.7211, 0.7350, 0.7416],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7449], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7089])\n",
      ">>Entradas: tensor([0.6473, 0.6581, 0.6793, 0.7028, 0.7211, 0.7350, 0.7416, 0.7449],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7204])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7518], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7204])\n",
      ">>Entradas: tensor([0.6581, 0.6793, 0.7028, 0.7211, 0.7350, 0.7416, 0.7449, 0.7518],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7706])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7726], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7706])\n",
      ">>Entradas: tensor([0.6793, 0.7028, 0.7211, 0.7350, 0.7416, 0.7449, 0.7518, 0.7726],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8595])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8124], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8595])\n",
      ">>Entradas: tensor([0.7028, 0.7211, 0.7350, 0.7416, 0.7449, 0.7518, 0.7726, 0.8124],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8533], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9065])\n",
      ">>Entradas: tensor([0.7211, 0.7350, 0.7416, 0.7449, 0.7518, 0.7726, 0.8124, 0.8533],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9119])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8851], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9119])\n",
      ">>Entradas: tensor([0.7350, 0.7416, 0.7449, 0.7518, 0.7726, 0.8124, 0.8533, 0.8851],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9043])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9082], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9043])\n",
      ">>Entradas: tensor([0.7416, 0.7449, 0.7518, 0.7726, 0.8124, 0.8533, 0.8851, 0.9082],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8839])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9197], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8839])\n",
      ">>Entradas: tensor([0.7449, 0.7518, 0.7726, 0.8124, 0.8533, 0.8851, 0.9082, 0.9197],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9032])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9345], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9032])\n",
      ">>Entradas: tensor([0.7518, 0.7726, 0.8124, 0.8533, 0.8851, 0.9082, 0.9197, 0.9345],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9623])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9662], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9623])\n",
      ">>Entradas: tensor([0.7726, 0.8124, 0.8533, 0.8851, 0.9082, 0.9197, 0.9345, 0.9662],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9821])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9965], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9821])\n",
      ">>Entradas: tensor([0.8124, 0.8533, 0.8851, 0.9082, 0.9197, 0.9345, 0.9662, 0.9965],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9624])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0109], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9624])\n",
      ">>Entradas: tensor([0.8533, 0.8851, 0.9082, 0.9197, 0.9345, 0.9662, 0.9965, 1.0109],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9303])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0106], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9303])\n",
      ">>Entradas: tensor([0.8851, 0.9082, 0.9197, 0.9345, 0.9662, 0.9965, 1.0109, 1.0106],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8855])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9929], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8855])\n",
      ">>Entradas: tensor([0.9082, 0.9197, 0.9345, 0.9662, 0.9965, 1.0109, 1.0106, 0.9929],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8597])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9658], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8597])\n",
      ">>Entradas: tensor([0.9197, 0.9345, 0.9662, 0.9965, 1.0109, 1.0106, 0.9929, 0.9658],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8529])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9424], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8529])\n",
      ">>Entradas: tensor([0.9345, 0.9662, 0.9965, 1.0109, 1.0106, 0.9929, 0.9658, 0.9424],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9263], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.9662, 0.9965, 1.0109, 1.0106, 0.9929, 0.9658, 0.9424, 0.9263],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8769])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9082], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8769])\n",
      ">>Entradas: tensor([0.9965, 1.0109, 1.0106, 0.9929, 0.9658, 0.9424, 0.9263, 0.9082],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8806])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8961], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8806])\n",
      ">>Entradas: tensor([1.0109, 1.0106, 0.9929, 0.9658, 0.9424, 0.9263, 0.9082, 0.8961],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8699])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8789], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8699])\n",
      ">>Entradas: tensor([1.0106, 0.9929, 0.9658, 0.9424, 0.9263, 0.9082, 0.8961, 0.8789],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8465])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8542], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8465])\n",
      ">>Entradas: tensor([0.9929, 0.9658, 0.9424, 0.9263, 0.9082, 0.8961, 0.8789, 0.8542],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8104])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8240], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8104])\n",
      ">>Entradas: tensor([0.9658, 0.9424, 0.9263, 0.9082, 0.8961, 0.8789, 0.8542, 0.8240],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8026])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8016], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8026])\n",
      ">>Entradas: tensor([0.9424, 0.9263, 0.9082, 0.8961, 0.8789, 0.8542, 0.8240, 0.8016],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8232])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8268], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8232])\n",
      ">>Entradas: tensor([0.9263, 0.9082, 0.8961, 0.8789, 0.8542, 0.8240, 0.8016, 0.8268],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8397])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8129], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8397])\n",
      ">>Entradas: tensor([0.9082, 0.8961, 0.8789, 0.8542, 0.8240, 0.8016, 0.8268, 0.8129],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8522])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.1329], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8522])\n",
      "ERROR: la modificacion de los pesos di√≥ un error mayor: 0.07878096401691437, se regresa al estado anterior de la red\n",
      ">>Entradas: tensor([0.8961, 0.8789, 0.8542, 0.8240, 0.8016, 0.8268, 0.8129, 0.7913],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8616])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8045], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8616])\n",
      ">>Entradas: tensor([0.8789, 0.8542, 0.8240, 0.8016, 0.8268, 0.8129, 0.7913, 0.8045],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8679])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8106], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8679])\n",
      ">>Entradas: tensor([0.8542, 0.8240, 0.8016, 0.8268, 0.8129, 0.7913, 0.8045, 0.8106],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8702])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8092], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8702])\n",
      ">>Entradas: tensor([0.8240, 0.8016, 0.8268, 0.8129, 0.7913, 0.8045, 0.8106, 0.8092],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8685])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8245], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8685])\n",
      ">>Entradas: tensor([0.8016, 0.8268, 0.8129, 0.7913, 0.8045, 0.8106, 0.8092, 0.8245],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8530])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8385], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8530])\n",
      ">>Entradas: tensor([0.8268, 0.8129, 0.7913, 0.8045, 0.8106, 0.8092, 0.8245, 0.8385],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8236])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8289], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8236])\n",
      ">>Entradas: tensor([0.8129, 0.7913, 0.8045, 0.8106, 0.8092, 0.8245, 0.8385, 0.8289],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8211], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.7913, 0.8045, 0.8106, 0.8092, 0.8245, 0.8385, 0.8289, 0.8211],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7919])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8206], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7919])\n",
      ">>Entradas: tensor([0.8045, 0.8106, 0.8092, 0.8245, 0.8385, 0.8289, 0.8211, 0.8206],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7865])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8121], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7865])\n",
      ">>Entradas: tensor([0.8106, 0.8092, 0.8245, 0.8385, 0.8289, 0.8211, 0.8206, 0.8121],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7870])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8045], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7870])\n",
      ">>Entradas: tensor([0.8092, 0.8245, 0.8385, 0.8289, 0.8211, 0.8206, 0.8121, 0.8045],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7874])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8044], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7874])\n",
      ">>Entradas: tensor([0.8245, 0.8385, 0.8289, 0.8211, 0.8206, 0.8121, 0.8045, 0.8044],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7879])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7998], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7879])\n",
      ">>Entradas: tensor([0.8385, 0.8289, 0.8211, 0.8206, 0.8121, 0.8045, 0.8044, 0.7998],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7955])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7925], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7955])\n",
      ">>Entradas: tensor([0.8289, 0.8211, 0.8206, 0.8121, 0.8045, 0.8044, 0.7998, 0.7925],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8102])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7939], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8102])\n",
      ">>Entradas: tensor([0.8211, 0.8206, 0.8121, 0.8045, 0.8044, 0.7998, 0.7925, 0.7939],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7668])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7823], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7668])\n",
      ">>Entradas: tensor([0.8206, 0.8121, 0.8045, 0.8044, 0.7998, 0.7925, 0.7939, 0.7823],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6655])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7417], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6655])\n",
      ">>Entradas: tensor([0.8121, 0.8045, 0.8044, 0.7998, 0.7925, 0.7939, 0.7823, 0.7417],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6361])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7067], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6361])\n",
      ">>Entradas: tensor([0.8045, 0.8044, 0.7998, 0.7925, 0.7939, 0.7823, 0.7417, 0.7067],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6785])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6932], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6785])\n",
      ">>Entradas: tensor([0.8044, 0.7998, 0.7925, 0.7939, 0.7823, 0.7417, 0.7067, 0.6932],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6799], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6966])\n",
      ">>Entradas: tensor([0.7998, 0.7925, 0.7939, 0.7823, 0.7417, 0.7067, 0.6932, 0.6799],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6903])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6669], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6903])\n",
      ">>Entradas: tensor([0.7925, 0.7939, 0.7823, 0.7417, 0.7067, 0.6932, 0.6799, 0.6669],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6970])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6647], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6970])\n",
      ">>Entradas: tensor([0.7939, 0.7823, 0.7417, 0.7067, 0.6932, 0.6799, 0.6669, 0.6647],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7167])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6636], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7167])\n",
      ">>Entradas: tensor([0.7823, 0.7417, 0.7067, 0.6932, 0.6799, 0.6669, 0.6647, 0.6636],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7491])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6659], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7491])\n",
      ">>Entradas: tensor([0.7417, 0.7067, 0.6932, 0.6799, 0.6669, 0.6647, 0.6636, 0.6659],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7940])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6873], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7940])\n",
      ">>Entradas: tensor([0.7067, 0.6932, 0.6799, 0.6669, 0.6647, 0.6636, 0.6659, 0.6873],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8547])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7286], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8547])\n",
      ">>Entradas: tensor([0.6932, 0.6799, 0.6669, 0.6647, 0.6636, 0.6659, 0.6873, 0.7286],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9314])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7842], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9314])\n",
      ">>Entradas: tensor([0.6799, 0.6669, 0.6647, 0.6636, 0.6659, 0.6873, 0.7286, 0.7842],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9627])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8403], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9627])\n",
      ">>Entradas: tensor([0.6669, 0.6647, 0.6636, 0.6659, 0.6873, 0.7286, 0.7842, 0.8403],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9486])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8865], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9486])\n",
      ">>Entradas: tensor([0.6647, 0.6636, 0.6659, 0.6873, 0.7286, 0.7842, 0.8403, 0.8865],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9307])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9220], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9307])\n",
      ">>Entradas: tensor([0.6636, 0.6659, 0.6873, 0.7286, 0.7842, 0.8403, 0.8865, 0.9220],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9090])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9470], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9090])\n",
      ">>Entradas: tensor([0.6659, 0.6873, 0.7286, 0.7842, 0.8403, 0.8865, 0.9220, 0.9470],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8816])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9437], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8816])\n",
      ">>Entradas: tensor([0.6873, 0.7286, 0.7842, 0.8403, 0.8865, 0.9220, 0.9470, 0.9437],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8487])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9558], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8487])\n",
      ">>Entradas: tensor([0.7286, 0.7842, 0.8403, 0.8865, 0.9220, 0.9470, 0.9437, 0.9558],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8753])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9713], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8753])\n",
      ">>Entradas: tensor([0.7842, 0.8403, 0.8865, 0.9220, 0.9470, 0.9437, 0.9558, 0.9713],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9612])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9985], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9612])\n",
      ">>Entradas: tensor([0.8403, 0.8865, 0.9220, 0.9470, 0.9437, 0.9558, 0.9713, 0.9985],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9925])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0213], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9925])\n",
      ">>Entradas: tensor([0.8865, 0.9220, 0.9470, 0.9437, 0.9558, 0.9713, 0.9985, 1.0213],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9690])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0274], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9690])\n",
      ">>Entradas: tensor([0.9220, 0.9470, 0.9437, 0.9558, 0.9713, 0.9985, 1.0213, 1.0274],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9715])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0261], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9715])\n",
      ">>Entradas: tensor([0.9470, 0.9437, 0.9558, 0.9713, 0.9985, 1.0213, 1.0274, 1.0261],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([1.])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0281], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([1.])\n",
      ">>Entradas: tensor([0.9437, 0.9558, 0.9713, 0.9985, 1.0213, 1.0274, 1.0261, 1.0281],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0236], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9801])\n",
      ">>Entradas: tensor([0.9558, 0.9713, 0.9985, 1.0213, 1.0274, 1.0261, 1.0281, 1.0236],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0003], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9117])\n",
      ">>Entradas: tensor([0.9713, 0.9985, 1.0213, 1.0274, 1.0261, 1.0281, 1.0236, 1.0003],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8911])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9792], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8911])\n",
      ">>Entradas: tensor([0.9985, 1.0213, 1.0274, 1.0261, 1.0281, 1.0236, 1.0003, 0.9792],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9181])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9673], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9181])\n",
      ">>Entradas: tensor([1.0213, 1.0274, 1.0261, 1.0281, 1.0236, 1.0003, 0.9792, 0.9673],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9450])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9573], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9450])\n",
      ">>Entradas: tensor([1.0274, 1.0261, 1.0281, 1.0236, 1.0003, 0.9792, 0.9673, 0.9573],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9718])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9548], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9718])\n",
      ">>Entradas: tensor([1.0261, 1.0281, 1.0236, 1.0003, 0.9792, 0.9673, 0.9573, 0.9548],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9829])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9577], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9829])\n",
      ">>Entradas: tensor([1.0281, 1.0236, 1.0003, 0.9792, 0.9673, 0.9573, 0.9548, 0.9577],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9783])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9550], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9783])\n",
      ">>s_original: [0.049424633383750916, 0.10789185762405396, 0.13719609379768372, 0.13733737170696259, 0.1338856965303421, 0.12684109807014465, 0.14756061136722565, 0.19604423642158508, 0.21688967943191528, 0.21009695529937744, 0.20267784595489502, 0.1946323662996292, 0.19407351315021515, 0.20100130140781403, 0.19663821160793304, 0.180984228849411, 0.16539041697978973, 0.14985674619674683, 0.15043111145496368, 0.1671135276556015, 0.20227035880088806, 0.25590160489082336, 0.29268819093704224, 0.31263017654418945, 0.31093889474868774, 0.2876143157482147, 0.28016164898872375, 0.28858086466789246, 0.28246283531188965, 0.26180753111839294, 0.2801212966442108, 0.3374040722846985, 0.3482298254966736, 0.3125985562801361, 0.34358710050582886, 0.44119545817375183, 0.521095335483551, 0.5832866430282593, 0.6089234352111816, 0.5980057120323181, 0.5945301651954651, 0.5984968543052673, 0.621354341506958, 0.6631026864051819, 0.6928724050521851, 0.7106636166572571, 0.721682071685791, 0.7259277701377869, 0.7404318451881409, 0.7651942372322083, 0.7447891235351562, 0.6792163252830505, 0.6746017932891846, 0.730945348739624, 0.7467210292816162, 0.7219287157058716, 0.7199286818504333, 0.7407209277153015, 0.7362455129623413, 0.7065023183822632, 0.6979451775550842, 0.7105739712715149, 0.7209621667861938, 0.7291097044944763, 0.7674259543418884, 0.8359109163284302, 0.8510103225708008, 0.8127241730690002, 0.7863940000534058, 0.7720199823379517, 0.8033170700073242, 0.8802852630615234, 0.8987051844596863, 0.8585767149925232, 0.8308762311935425, 0.8156037926673889, 0.8116992115974426, 0.8191625475883484, 0.8218275904655457, 0.8196942210197449, 0.817862868309021, 0.8163333535194397, 0.8005555868148804, 0.7705295085906982, 0.7426586747169495, 0.716943085193634, 0.7197051048278809, 0.7509447932243347, 0.7402781248092651, 0.6877052187919617, 0.6687695384025574, 0.683471143245697, 0.6877052187919617, 0.6814717054367065, 0.6892618536949158, 0.7110756039619446, 0.7349108457565308, 0.7607676982879639, 0.771117091178894, 0.7659589648246765, 0.7483323812484741, 0.7182371616363525, 0.708941638469696, 0.7204458117485046, 0.7706154584884644, 0.8594506978988647, 0.906541109085083, 0.9118866324424744, 0.9043355584144592, 0.8838878870010376, 0.9032153487205505, 0.9623178839683533, 0.9820588231086731, 0.96243816614151, 0.9302511811256409, 0.8854979276657104, 0.8597025871276855, 0.8528652191162109, 0.8585854768753052, 0.8768633008003235, 0.8806464076042175, 0.8699347376823425, 0.846513569355011, 0.8103827834129333, 0.8026111125946045, 0.8231984972953796, 0.8397204279899597, 0.8521769046783447, 0.8615626692771912, 0.8678776621818542, 0.8701963424682617, 0.868518590927124, 0.852988064289093, 0.8236046433448792, 0.8032509088516235, 0.7919268012046814, 0.7865023016929626, 0.7869773507118225, 0.7874362468719482, 0.7878790497779846, 0.7954531908035278, 0.8101586699485779, 0.7668473124504089, 0.665519118309021, 0.6360738277435303, 0.678511381149292, 0.6965967416763306, 0.6903298497200012, 0.6970472931861877, 0.7167490720748901, 0.7490506768226624, 0.7939522862434387, 0.8547447323799133, 0.931428074836731, 0.9627243876457214, 0.9486336708068848, 0.9307146072387695, 0.9089671969413757, 0.8816379904747009, 0.8487268090248108, 0.8752607107162476, 0.9612395763397217, 0.9925020933151245, 0.9690483212471008, 0.9715476036071777, 1.0, 0.9800636768341064, 0.9117385745048523, 0.8910858035087585, 0.9181053042411804, 0.9450165033340454, 0.9718193411827087, 0.982906699180603, 0.9782785773277283]\n",
      ">>s_pred: [-0.1665630340576172, -0.06320476531982422, 0.00029754638671875, -0.0066089630126953125, 0.03803825378417969, 0.07698440551757812, 0.06753826141357422, 0.10386466979980469, 0.1628437042236328, 0.18007469177246094, 0.1968526840209961, 0.22133255004882812, 0.22647571563720703, 0.2306041717529297, 0.243560791015625, 0.19541358947753906, 0.20324325561523438, 0.20053863525390625, 0.1820516586303711, 0.1788311004638672, 0.18997478485107422, 0.19802093505859375, 0.2152233123779297, 0.24286460876464844, 0.2607145309448242, 0.26788806915283203, 0.2803173065185547, 0.2942991256713867, 0.3011512756347656, 0.3041877746582031, 0.3141365051269531, 0.33280467987060547, 0.34475040435791016, 0.34478187561035156, 0.35699939727783203, 0.3913898468017578, 0.4353761672973633, 0.49013519287109375, 0.545379638671875, 0.5848360061645508, 0.6162986755371094, 0.6482744216918945, 0.6829204559326172, 0.7219419479370117, 0.7602481842041016, 0.7895231246948242, 0.8082208633422852, 0.8188486099243164, 0.827214241027832, 0.8372678756713867, 0.8355226516723633, 0.8083906173706055, 0.7850513458251953, 0.7768077850341797, 0.7661771774291992, 0.7486591339111328, 0.7371578216552734, 0.7287626266479492, 0.7137622833251953, 0.6970272064208984, 0.6873188018798828, 0.6822195053100586, 0.6800880432128906, 0.6841487884521484, 0.7005548477172852, 0.7327003479003906, 0.7626066207885742, 0.7790069580078125, 0.7900772094726562, 0.7968721389770508, 0.8118534088134766, 0.8487577438354492, 0.8831338882446289, 0.8948774337768555, 0.8955459594726562, 0.8894891738891602, 0.8785390853881836, 0.8733415603637695, 0.8727893829345703, 0.8662300109863281, 0.853825569152832, 0.8408966064453125, 0.8232908248901367, 0.7994823455810547, 0.7893733978271484, 0.7596836090087891, 0.7359676361083984, 0.7276668548583984, 0.7155590057373047, 0.6879949569702148, 0.6672821044921875, 0.6569061279296875, 0.6445751190185547, 0.6369361877441406, 0.6401948928833008, 0.6473445892333984, 0.658050537109375, 0.6793441772460938, 0.7028388977050781, 0.7210779190063477, 0.7350187301635742, 0.7416477203369141, 0.7449216842651367, 0.7518024444580078, 0.7725801467895508, 0.8123607635498047, 0.8533229827880859, 0.8850975036621094, 0.9081716537475586, 0.9197015762329102, 0.934478759765625, 0.966160774230957, 0.9964780807495117, 1.010885238647461, 1.010589599609375, 0.9929294586181641, 0.9658222198486328, 0.9424152374267578, 0.9262781143188477, 0.9081554412841797, 0.8960638046264648, 0.8789463043212891, 0.8541736602783203, 0.8240337371826172, 0.8016481399536133, 0.8268089294433594, 0.8129281997680664, 0.7913408279418945, 0.8045082092285156, 0.8106288909912109, 0.8092012405395508, 0.8244562149047852, 0.8384780883789062, 0.828883171081543, 0.8211450576782227, 0.8205671310424805, 0.8121223449707031, 0.8045320510864258, 0.8043699264526367, 0.7997961044311523, 0.7925252914428711, 0.7939167022705078, 0.7822866439819336, 0.7416725158691406, 0.7066888809204102, 0.6931686401367188, 0.6798648834228516, 0.6669330596923828, 0.6647424697875977, 0.6636085510253906, 0.6659374237060547, 0.687342643737793, 0.7285938262939453, 0.7841920852661133, 0.8403215408325195, 0.8865242004394531, 0.9219913482666016, 0.947026252746582, 0.9436655044555664, 0.9558019638061523, 0.9712982177734375, 0.9984531402587891, 1.021261215209961, 1.0274477005004883, 1.0261039733886719, 1.0281391143798828, 1.023599624633789, 1.0003223419189453, 0.9791946411132812, 0.9672918319702148, 0.9572696685791016, 0.9547958374023438, 0.9576683044433594, 0.9550304412841797]\n",
      "<<Perdida: 0.003498474834486842 epoca: 19\n",
      "---Inicio de epoca: 20--\n",
      ">>Entradas: tensor([0.0503, 0.0086, 0.0000, 0.0245, 0.0327, 0.0246, 0.0205, 0.0203])\n",
      ">>Salida: tensor([0.0494])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([-0.1581], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.0494])\n",
      ">>Entradas: tensor([ 0.0086,  0.0000,  0.0245,  0.0327,  0.0246,  0.0205,  0.0203, -0.1581],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1079])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([-0.0482], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1079])\n",
      ">>Entradas: tensor([ 0.0000,  0.0245,  0.0327,  0.0246,  0.0205,  0.0203, -0.1581, -0.0482],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1372])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0185], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1372])\n",
      ">>Entradas: tensor([ 0.0245,  0.0327,  0.0246,  0.0205,  0.0203, -0.1581, -0.0482,  0.0185],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1373])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([-0.0077], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1373])\n",
      ">>Entradas: tensor([ 0.0327,  0.0246,  0.0205,  0.0203, -0.1581, -0.0482,  0.0185, -0.0077],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1339])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0425], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1339])\n",
      ">>Entradas: tensor([ 0.0246,  0.0205,  0.0203, -0.1581, -0.0482,  0.0185, -0.0077,  0.0425],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1268])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0821], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1268])\n",
      ">>Entradas: tensor([ 0.0205,  0.0203, -0.1581, -0.0482,  0.0185, -0.0077,  0.0425,  0.0821],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1476])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0591], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1476])\n",
      ">>Entradas: tensor([ 0.0203, -0.1581, -0.0482,  0.0185, -0.0077,  0.0425,  0.0821,  0.0591],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1960])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.0948], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1960])\n",
      ">>Entradas: tensor([-0.1581, -0.0482,  0.0185, -0.0077,  0.0425,  0.0821,  0.0591,  0.0948],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1586], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2169])\n",
      ">>Entradas: tensor([-0.0482,  0.0185, -0.0077,  0.0425,  0.0821,  0.0591,  0.0948,  0.1586],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2101])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1580], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2101])\n",
      ">>Entradas: tensor([ 0.0185, -0.0077,  0.0425,  0.0821,  0.0591,  0.0948,  0.1586,  0.1580],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2027])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1707], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2027])\n",
      ">>Entradas: tensor([-0.0077,  0.0425,  0.0821,  0.0591,  0.0948,  0.1586,  0.1580,  0.1707],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1946])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2023], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1946])\n",
      ">>Entradas: tensor([0.0425, 0.0821, 0.0591, 0.0948, 0.1586, 0.1580, 0.1707, 0.2023],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1941])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2001], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1941])\n",
      ">>Entradas: tensor([0.0821, 0.0591, 0.0948, 0.1586, 0.1580, 0.1707, 0.2023, 0.2001],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2010])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2019], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2010])\n",
      ">>Entradas: tensor([0.0591, 0.0948, 0.1586, 0.1580, 0.1707, 0.2023, 0.2001, 0.2019],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2229], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1966])\n",
      ">>Entradas: tensor([0.0948, 0.1586, 0.1580, 0.1707, 0.2023, 0.2001, 0.2019, 0.2229],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1810])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2220], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1810])\n",
      ">>Entradas: tensor([0.1586, 0.1580, 0.1707, 0.2023, 0.2001, 0.2019, 0.2229, 0.2220],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1654])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2043], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1654])\n",
      ">>Entradas: tensor([0.1580, 0.1707, 0.2023, 0.2001, 0.2019, 0.2229, 0.2220, 0.2043],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1499])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2019], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1499])\n",
      ">>Entradas: tensor([0.1707, 0.2023, 0.2001, 0.2019, 0.2229, 0.2220, 0.2043, 0.2019],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1504])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1959], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1504])\n",
      ">>Entradas: tensor([0.2023, 0.2001, 0.2019, 0.2229, 0.2220, 0.2043, 0.2019, 0.1959],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.1671])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1858], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.1671])\n",
      ">>Entradas: tensor([0.2001, 0.2019, 0.2229, 0.2220, 0.2043, 0.2019, 0.1959, 0.1858],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2023])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.1941], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2023])\n",
      ">>Entradas: tensor([0.2019, 0.2229, 0.2220, 0.2043, 0.2019, 0.1959, 0.1858, 0.1941],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2559])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2150], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2559])\n",
      ">>Entradas: tensor([0.2229, 0.2220, 0.2043, 0.2019, 0.1959, 0.1858, 0.1941, 0.2150],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2927])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2309], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2927])\n",
      ">>Entradas: tensor([0.2220, 0.2043, 0.2019, 0.1959, 0.1858, 0.1941, 0.2150, 0.2309],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2512], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2043, 0.2019, 0.1959, 0.1858, 0.1941, 0.2150, 0.2309, 0.2512],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3109])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2685], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3109])\n",
      ">>Entradas: tensor([0.2019, 0.1959, 0.1858, 0.1941, 0.2150, 0.2309, 0.2512, 0.2685],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2876])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2734], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2876])\n",
      ">>Entradas: tensor([0.1959, 0.1858, 0.1941, 0.2150, 0.2309, 0.2512, 0.2685, 0.2734],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2802])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2792], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2802])\n",
      ">>Entradas: tensor([0.1858, 0.1941, 0.2150, 0.2309, 0.2512, 0.2685, 0.2734, 0.2792],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2886])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2922], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2886])\n",
      ">>Entradas: tensor([0.1941, 0.2150, 0.2309, 0.2512, 0.2685, 0.2734, 0.2792, 0.2922],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2825])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2989], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2825])\n",
      ">>Entradas: tensor([0.2150, 0.2309, 0.2512, 0.2685, 0.2734, 0.2792, 0.2922, 0.2989],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2618])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.2974], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2618])\n",
      ">>Entradas: tensor([0.2309, 0.2512, 0.2685, 0.2734, 0.2792, 0.2922, 0.2989, 0.2974],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.2801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3048], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.2801])\n",
      ">>Entradas: tensor([0.2512, 0.2685, 0.2734, 0.2792, 0.2922, 0.2989, 0.2974, 0.3048],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3374])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3235], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3374])\n",
      ">>Entradas: tensor([0.2685, 0.2734, 0.2792, 0.2922, 0.2989, 0.2974, 0.3048, 0.3235],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3482])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3334], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3482])\n",
      ">>Entradas: tensor([0.2734, 0.2792, 0.2922, 0.2989, 0.2974, 0.3048, 0.3235, 0.3334],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3126])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3319], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3126])\n",
      ">>Entradas: tensor([0.2792, 0.2922, 0.2989, 0.2974, 0.3048, 0.3235, 0.3334, 0.3319],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.3436])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3454], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.3436])\n",
      ">>Entradas: tensor([0.2922, 0.2989, 0.2974, 0.3048, 0.3235, 0.3334, 0.3319, 0.3454],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.4412])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.3806], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.4412])\n",
      ">>Entradas: tensor([0.2989, 0.2974, 0.3048, 0.3235, 0.3334, 0.3319, 0.3454, 0.3806],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5211])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4242], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5211])\n",
      ">>Entradas: tensor([0.2974, 0.3048, 0.3235, 0.3334, 0.3319, 0.3454, 0.3806, 0.4242],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5833])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.4788], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5833])\n",
      ">>Entradas: tensor([0.3048, 0.3235, 0.3334, 0.3319, 0.3454, 0.3806, 0.4242, 0.4788],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5340], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6089])\n",
      ">>Entradas: tensor([0.3235, 0.3334, 0.3319, 0.3454, 0.3806, 0.4242, 0.4788, 0.5340],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5980])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.5729], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5980])\n",
      ">>Entradas: tensor([0.3334, 0.3319, 0.3454, 0.3806, 0.4242, 0.4788, 0.5340, 0.5729],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5945])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6053], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5945])\n",
      ">>Entradas: tensor([0.3319, 0.3454, 0.3806, 0.4242, 0.4788, 0.5340, 0.5729, 0.6053],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.5985])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6397], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.5985])\n",
      ">>Entradas: tensor([0.3454, 0.3806, 0.4242, 0.4788, 0.5340, 0.5729, 0.6053, 0.6397],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6214])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6768], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6214])\n",
      ">>Entradas: tensor([0.3806, 0.4242, 0.4788, 0.5340, 0.5729, 0.6053, 0.6397, 0.6768],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6631])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7181], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6631])\n",
      ">>Entradas: tensor([0.4242, 0.4788, 0.5340, 0.5729, 0.6053, 0.6397, 0.6768, 0.7181],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6929])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7591], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6929])\n",
      ">>Entradas: tensor([0.4788, 0.5340, 0.5729, 0.6053, 0.6397, 0.6768, 0.7181, 0.7591],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7107])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7911], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7107])\n",
      ">>Entradas: tensor([0.5340, 0.5729, 0.6053, 0.6397, 0.6768, 0.7181, 0.7591, 0.7911],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7217])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8120], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7217])\n",
      ">>Entradas: tensor([0.5729, 0.6053, 0.6397, 0.6768, 0.7181, 0.7591, 0.7911, 0.8120],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7259])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8248], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7259])\n",
      ">>Entradas: tensor([0.6053, 0.6397, 0.6768, 0.7181, 0.7591, 0.7911, 0.8120, 0.8248],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7404])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8354], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7404])\n",
      ">>Entradas: tensor([0.6397, 0.6768, 0.7181, 0.7591, 0.7911, 0.8120, 0.8248, 0.8354],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7652])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8471], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7652])\n",
      ">>Entradas: tensor([0.6768, 0.7181, 0.7591, 0.7911, 0.8120, 0.8248, 0.8354, 0.8471],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7448])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8461], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7448])\n",
      ">>Entradas: tensor([0.7181, 0.7591, 0.7911, 0.8120, 0.8248, 0.8354, 0.8471, 0.8461],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6792])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8220], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6792])\n",
      ">>Entradas: tensor([0.7591, 0.7911, 0.8120, 0.8248, 0.8354, 0.8471, 0.8461, 0.8220],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6746])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7978], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6746])\n",
      ">>Entradas: tensor([0.7911, 0.8120, 0.8248, 0.8354, 0.8471, 0.8461, 0.8220, 0.7978],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7887], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7309])\n",
      ">>Entradas: tensor([0.8120, 0.8248, 0.8354, 0.8471, 0.8461, 0.8220, 0.7978, 0.7887],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7467])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7771], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7467])\n",
      ">>Entradas: tensor([0.8248, 0.8354, 0.8471, 0.8461, 0.8220, 0.7978, 0.7887, 0.7771],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7219])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7576], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7219])\n",
      ">>Entradas: tensor([0.8354, 0.8471, 0.8461, 0.8220, 0.7978, 0.7887, 0.7771, 0.7576],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7199])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7436], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7199])\n",
      ">>Entradas: tensor([0.8471, 0.8461, 0.8220, 0.7978, 0.7887, 0.7771, 0.7576, 0.7436],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7407])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7336], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7407])\n",
      ">>Entradas: tensor([0.8461, 0.8220, 0.7978, 0.7887, 0.7771, 0.7576, 0.7436, 0.7336],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7362])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7168], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7362])\n",
      ">>Entradas: tensor([0.8220, 0.7978, 0.7887, 0.7771, 0.7576, 0.7436, 0.7336, 0.7168],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6976], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7065])\n",
      ">>Entradas: tensor([0.7978, 0.7887, 0.7771, 0.7576, 0.7436, 0.7336, 0.7168, 0.6976],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6979])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6861], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6979])\n",
      ">>Entradas: tensor([0.7887, 0.7771, 0.7576, 0.7436, 0.7336, 0.7168, 0.6976, 0.6861],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7106])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6797], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7106])\n",
      ">>Entradas: tensor([0.7771, 0.7576, 0.7436, 0.7336, 0.7168, 0.6976, 0.6861, 0.6797],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7210])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6759], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7210])\n",
      ">>Entradas: tensor([0.7576, 0.7436, 0.7336, 0.7168, 0.6976, 0.6861, 0.6797, 0.6759],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7291])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6787], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7291])\n",
      ">>Entradas: tensor([0.7436, 0.7336, 0.7168, 0.6976, 0.6861, 0.6797, 0.6759, 0.6787],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7674])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6944], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7674])\n",
      ">>Entradas: tensor([0.7336, 0.7168, 0.6976, 0.6861, 0.6797, 0.6759, 0.6787, 0.6944],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8359])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7260], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8359])\n",
      ">>Entradas: tensor([0.7168, 0.6976, 0.6861, 0.6797, 0.6759, 0.6787, 0.6944, 0.7260],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8510])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7553], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8510])\n",
      ">>Entradas: tensor([0.6976, 0.6861, 0.6797, 0.6759, 0.6787, 0.6944, 0.7260, 0.7553],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8127])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7715], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8127])\n",
      ">>Entradas: tensor([0.6861, 0.6797, 0.6759, 0.6787, 0.6944, 0.7260, 0.7553, 0.7715],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7864])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7834], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7864])\n",
      ">>Entradas: tensor([0.6797, 0.6759, 0.6787, 0.6944, 0.7260, 0.7553, 0.7715, 0.7834],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7720])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7916], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7720])\n",
      ">>Entradas: tensor([0.6759, 0.6787, 0.6944, 0.7260, 0.7553, 0.7715, 0.7834, 0.7916],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8084], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.6787, 0.6944, 0.7260, 0.7553, 0.7715, 0.7834, 0.7916, 0.8084],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8803])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8473], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8803])\n",
      ">>Entradas: tensor([0.6944, 0.7260, 0.7553, 0.7715, 0.7834, 0.7916, 0.8084, 0.8473],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8987])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8832], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8987])\n",
      ">>Entradas: tensor([0.7260, 0.7553, 0.7715, 0.7834, 0.7916, 0.8084, 0.8473, 0.8832],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8956], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.7553, 0.7715, 0.7834, 0.7916, 0.8084, 0.8473, 0.8832, 0.8956],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8309])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8975], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8309])\n",
      ">>Entradas: tensor([0.7715, 0.7834, 0.7916, 0.8084, 0.8473, 0.8832, 0.8956, 0.8975],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8156])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8930], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8156])\n",
      ">>Entradas: tensor([0.7834, 0.7916, 0.8084, 0.8473, 0.8832, 0.8956, 0.8975, 0.8930],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8836], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8117])\n",
      ">>Entradas: tensor([0.7916, 0.8084, 0.8473, 0.8832, 0.8956, 0.8975, 0.8930, 0.8836],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8192])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8796], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8192])\n",
      ">>Entradas: tensor([0.8084, 0.8473, 0.8832, 0.8956, 0.8975, 0.8930, 0.8836, 0.8796],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8218])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8797], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8218])\n",
      ">>Entradas: tensor([0.8473, 0.8832, 0.8956, 0.8975, 0.8930, 0.8836, 0.8796, 0.8797],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8730], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8197])\n",
      ">>Entradas: tensor([0.8832, 0.8956, 0.8975, 0.8930, 0.8836, 0.8796, 0.8797, 0.8730],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8179])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8599], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8179])\n",
      ">>Entradas: tensor([0.8956, 0.8975, 0.8930, 0.8836, 0.8796, 0.8797, 0.8730, 0.8599],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8163])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8461], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8163])\n",
      ">>Entradas: tensor([0.8975, 0.8930, 0.8836, 0.8796, 0.8797, 0.8730, 0.8599, 0.8461],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8006])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8277], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8006])\n",
      ">>Entradas: tensor([0.8930, 0.8836, 0.8796, 0.8797, 0.8730, 0.8599, 0.8461, 0.8277],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7705])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8026], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7705])\n",
      ">>Entradas: tensor([0.8836, 0.8796, 0.8797, 0.8730, 0.8599, 0.8461, 0.8277, 0.8026],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7427])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7776], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7427])\n",
      ">>Entradas: tensor([0.8796, 0.8797, 0.8730, 0.8599, 0.8461, 0.8277, 0.8026, 0.7776],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7169])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7511], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7169])\n",
      ">>Entradas: tensor([0.8797, 0.8730, 0.8599, 0.8461, 0.8277, 0.8026, 0.7776, 0.7511],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7197])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7285], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7197])\n",
      ">>Entradas: tensor([0.8730, 0.8599, 0.8461, 0.8277, 0.8026, 0.7776, 0.7511, 0.7285],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7509])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7187], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7509])\n",
      ">>Entradas: tensor([0.8599, 0.8461, 0.8277, 0.8026, 0.7776, 0.7511, 0.7285, 0.7187],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7403])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7067], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7403])\n",
      ">>Entradas: tensor([0.8461, 0.8277, 0.8026, 0.7776, 0.7511, 0.7285, 0.7187, 0.7067],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6807], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.8277, 0.8026, 0.7776, 0.7511, 0.7285, 0.7187, 0.7067, 0.6807],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6688])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6577], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6688])\n",
      ">>Entradas: tensor([0.8026, 0.7776, 0.7511, 0.7285, 0.7187, 0.7067, 0.6807, 0.6577],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6835])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6461], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6835])\n",
      ">>Entradas: tensor([0.7776, 0.7511, 0.7285, 0.7187, 0.7067, 0.6807, 0.6577, 0.6461],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6877])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6365], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6877])\n",
      ">>Entradas: tensor([0.7511, 0.7285, 0.7187, 0.7067, 0.6807, 0.6577, 0.6461, 0.6365],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6815])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6302], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6815])\n",
      ">>Entradas: tensor([0.7285, 0.7187, 0.7067, 0.6807, 0.6577, 0.6461, 0.6365, 0.6302],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6893])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6339], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6893])\n",
      ">>Entradas: tensor([0.7187, 0.7067, 0.6807, 0.6577, 0.6461, 0.6365, 0.6302, 0.6339],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7111])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6428], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7111])\n",
      ">>Entradas: tensor([0.7067, 0.6807, 0.6577, 0.6461, 0.6365, 0.6302, 0.6339, 0.6428],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7349])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6546], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7349])\n",
      ">>Entradas: tensor([0.6807, 0.6577, 0.6461, 0.6365, 0.6302, 0.6339, 0.6428, 0.6546],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7608])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6757], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7608])\n",
      ">>Entradas: tensor([0.6577, 0.6461, 0.6365, 0.6302, 0.6339, 0.6428, 0.6546, 0.6757],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7711])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7002], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7711])\n",
      ">>Entradas: tensor([0.6461, 0.6365, 0.6302, 0.6339, 0.6428, 0.6546, 0.6757, 0.7002],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7660])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7201], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7660])\n",
      ">>Entradas: tensor([0.6365, 0.6302, 0.6339, 0.6428, 0.6546, 0.6757, 0.7002, 0.7201],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7483])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7349], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7483])\n",
      ">>Entradas: tensor([0.6302, 0.6339, 0.6428, 0.6546, 0.6757, 0.7002, 0.7201, 0.7349],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7182])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7418], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7182])\n",
      ">>Entradas: tensor([0.6339, 0.6428, 0.6546, 0.6757, 0.7002, 0.7201, 0.7349, 0.7418],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7089])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7467], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7089])\n",
      ">>Entradas: tensor([0.6428, 0.6546, 0.6757, 0.7002, 0.7201, 0.7349, 0.7418, 0.7467],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7204])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7547], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7204])\n",
      ">>Entradas: tensor([0.6546, 0.6757, 0.7002, 0.7201, 0.7349, 0.7418, 0.7467, 0.7547],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7706])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7759], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7706])\n",
      ">>Entradas: tensor([0.6757, 0.7002, 0.7201, 0.7349, 0.7418, 0.7467, 0.7547, 0.7759],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8595])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8164], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8595])\n",
      ">>Entradas: tensor([0.7002, 0.7201, 0.7349, 0.7418, 0.7467, 0.7547, 0.7759, 0.8164],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9065])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8575], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9065])\n",
      ">>Entradas: tensor([0.7201, 0.7349, 0.7418, 0.7467, 0.7547, 0.7759, 0.8164, 0.8575],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9119])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8885], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9119])\n",
      ">>Entradas: tensor([0.7349, 0.7418, 0.7467, 0.7547, 0.7759, 0.8164, 0.8575, 0.8885],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9043])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9111], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9043])\n",
      ">>Entradas: tensor([0.7418, 0.7467, 0.7547, 0.7759, 0.8164, 0.8575, 0.8885, 0.9111],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8839])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9189], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8839])\n",
      ">>Entradas: tensor([0.7467, 0.7547, 0.7759, 0.8164, 0.8575, 0.8885, 0.9111, 0.9189],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9032])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9344], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9032])\n",
      ">>Entradas: tensor([0.7547, 0.7759, 0.8164, 0.8575, 0.8885, 0.9111, 0.9189, 0.9344],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9623])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9675], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9623])\n",
      ">>Entradas: tensor([0.7759, 0.8164, 0.8575, 0.8885, 0.9111, 0.9189, 0.9344, 0.9675],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9821])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9981], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9821])\n",
      ">>Entradas: tensor([0.8164, 0.8575, 0.8885, 0.9111, 0.9189, 0.9344, 0.9675, 0.9981],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9624])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0125], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9624])\n",
      ">>Entradas: tensor([0.8575, 0.8885, 0.9111, 0.9189, 0.9344, 0.9675, 0.9981, 1.0125],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9303])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0126], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9303])\n",
      ">>Entradas: tensor([0.8885, 0.9111, 0.9189, 0.9344, 0.9675, 0.9981, 1.0125, 1.0126],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8855])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9946], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8855])\n",
      ">>Entradas: tensor([0.9111, 0.9189, 0.9344, 0.9675, 0.9981, 1.0125, 1.0126, 0.9946],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8597])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9675], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8597])\n",
      ">>Entradas: tensor([0.9189, 0.9344, 0.9675, 0.9981, 1.0125, 1.0126, 0.9946, 0.9675],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8529])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9453], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8529])\n",
      ">>Entradas: tensor([0.9344, 0.9675, 0.9981, 1.0125, 1.0126, 0.9946, 0.9675, 0.9453],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8586])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9299], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8586])\n",
      ">>Entradas: tensor([0.9675, 0.9981, 1.0125, 1.0126, 0.9946, 0.9675, 0.9453, 0.9299],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8769])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9177], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8769])\n",
      ">>Entradas: tensor([0.9981, 1.0125, 1.0126, 0.9946, 0.9675, 0.9453, 0.9299, 0.9177],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8806])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9034], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8806])\n",
      ">>Entradas: tensor([1.0125, 1.0126, 0.9946, 0.9675, 0.9453, 0.9299, 0.9177, 0.9034],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8699])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8843], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8699])\n",
      ">>Entradas: tensor([1.0126, 0.9946, 0.9675, 0.9453, 0.9299, 0.9177, 0.9034, 0.8843],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8465])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8585], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8465])\n",
      ">>Entradas: tensor([0.9946, 0.9675, 0.9453, 0.9299, 0.9177, 0.9034, 0.8843, 0.8585],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8104])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8270], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8104])\n",
      ">>Entradas: tensor([0.9675, 0.9453, 0.9299, 0.9177, 0.9034, 0.8843, 0.8585, 0.8270],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8026])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8032], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8026])\n",
      ">>Entradas: tensor([0.9453, 0.9299, 0.9177, 0.9034, 0.8843, 0.8585, 0.8270, 0.8032],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8232])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7929], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8232])\n",
      ">>Entradas: tensor([0.9299, 0.9177, 0.9034, 0.8843, 0.8585, 0.8270, 0.8032, 0.7929],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8397])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7896], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8397])\n",
      ">>Entradas: tensor([0.9177, 0.9034, 0.8843, 0.8585, 0.8270, 0.8032, 0.7929, 0.7896],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8522])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7906], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8522])\n",
      ">>Entradas: tensor([0.9034, 0.8843, 0.8585, 0.8270, 0.8032, 0.7929, 0.7896, 0.7906],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8616])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7951], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8616])\n",
      ">>Entradas: tensor([0.8843, 0.8585, 0.8270, 0.8032, 0.7929, 0.7896, 0.7906, 0.7951],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8679])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8004], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8679])\n",
      ">>Entradas: tensor([0.8585, 0.8270, 0.8032, 0.7929, 0.7896, 0.7906, 0.7951, 0.8004],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8702])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8065], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8702])\n",
      ">>Entradas: tensor([0.8270, 0.8032, 0.7929, 0.7896, 0.7906, 0.7951, 0.8004, 0.8065],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8685])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8160], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8685])\n",
      ">>Entradas: tensor([0.8032, 0.7929, 0.7896, 0.7906, 0.7951, 0.8004, 0.8065, 0.8160],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8530])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8241], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8530])\n",
      ">>Entradas: tensor([0.7929, 0.7896, 0.7906, 0.7951, 0.8004, 0.8065, 0.8160, 0.8241],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8236])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8251], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8236])\n",
      ">>Entradas: tensor([0.7896, 0.7906, 0.7951, 0.8004, 0.8065, 0.8160, 0.8241, 0.8251],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8033])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8228], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8033])\n",
      ">>Entradas: tensor([0.7906, 0.7951, 0.8004, 0.8065, 0.8160, 0.8241, 0.8251, 0.8228],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7919])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8191], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7919])\n",
      ">>Entradas: tensor([0.7951, 0.8004, 0.8065, 0.8160, 0.8241, 0.8251, 0.8228, 0.8191],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7865])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8136], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7865])\n",
      ">>Entradas: tensor([0.8004, 0.8065, 0.8160, 0.8241, 0.8251, 0.8228, 0.8191, 0.8136],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7870])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8091], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7870])\n",
      ">>Entradas: tensor([0.8065, 0.8160, 0.8241, 0.8251, 0.8228, 0.8191, 0.8136, 0.8091],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7874])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8059], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7874])\n",
      ">>Entradas: tensor([0.8160, 0.8241, 0.8251, 0.8228, 0.8191, 0.8136, 0.8091, 0.8059],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7879])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8016], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7879])\n",
      ">>Entradas: tensor([0.8241, 0.8251, 0.8228, 0.8191, 0.8136, 0.8091, 0.8059, 0.8016],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7955])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7981], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7955])\n",
      ">>Entradas: tensor([0.8251, 0.8228, 0.8191, 0.8136, 0.8091, 0.8059, 0.8016, 0.7981],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8102])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7989], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8102])\n",
      ">>Entradas: tensor([0.8228, 0.8191, 0.8136, 0.8091, 0.8059, 0.8016, 0.7981, 0.7989],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7668])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7855], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7668])\n",
      ">>Entradas: tensor([0.8191, 0.8136, 0.8091, 0.8059, 0.8016, 0.7981, 0.7989, 0.7855],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6655])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7457], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6655])\n",
      ">>Entradas: tensor([0.8136, 0.8091, 0.8059, 0.8016, 0.7981, 0.7989, 0.7855, 0.7457],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6361])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7096], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6361])\n",
      ">>Entradas: tensor([0.8091, 0.8059, 0.8016, 0.7981, 0.7989, 0.7855, 0.7457, 0.7096],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6785])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6938], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6785])\n",
      ">>Entradas: tensor([0.8059, 0.8016, 0.7981, 0.7989, 0.7855, 0.7457, 0.7096, 0.6938],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6966])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6810], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6966])\n",
      ">>Entradas: tensor([0.8016, 0.7981, 0.7989, 0.7855, 0.7457, 0.7096, 0.6938, 0.6810],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6903])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6685], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6903])\n",
      ">>Entradas: tensor([0.7981, 0.7989, 0.7855, 0.7457, 0.7096, 0.6938, 0.6810, 0.6685],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.6970])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6644], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.6970])\n",
      ">>Entradas: tensor([0.7989, 0.7855, 0.7457, 0.7096, 0.6938, 0.6810, 0.6685, 0.6644],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7167])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6620], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7167])\n",
      ">>Entradas: tensor([0.7855, 0.7457, 0.7096, 0.6938, 0.6810, 0.6685, 0.6644, 0.6620],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7491])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6640], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7491])\n",
      ">>Entradas: tensor([0.7457, 0.7096, 0.6938, 0.6810, 0.6685, 0.6644, 0.6620, 0.6640],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.7940])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.6841], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.7940])\n",
      ">>Entradas: tensor([0.7096, 0.6938, 0.6810, 0.6685, 0.6644, 0.6620, 0.6640, 0.6841],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8547])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7247], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8547])\n",
      ">>Entradas: tensor([0.6938, 0.6810, 0.6685, 0.6644, 0.6620, 0.6640, 0.6841, 0.7247],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9314])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.7812], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9314])\n",
      ">>Entradas: tensor([0.6810, 0.6685, 0.6644, 0.6620, 0.6640, 0.6841, 0.7247, 0.7812],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9627])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8377], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9627])\n",
      ">>Entradas: tensor([0.6685, 0.6644, 0.6620, 0.6640, 0.6841, 0.7247, 0.7812, 0.8377],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9486])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.8837], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9486])\n",
      ">>Entradas: tensor([0.6644, 0.6620, 0.6640, 0.6841, 0.7247, 0.7812, 0.8377, 0.8837],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9307])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9197], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9307])\n",
      ">>Entradas: tensor([0.6620, 0.6640, 0.6841, 0.7247, 0.7812, 0.8377, 0.8837, 0.9197],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9090])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9455], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9090])\n",
      ">>Entradas: tensor([0.6640, 0.6841, 0.7247, 0.7812, 0.8377, 0.8837, 0.9197, 0.9455],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8816])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9625], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8816])\n",
      ">>Entradas: tensor([0.6841, 0.7247, 0.7812, 0.8377, 0.8837, 0.9197, 0.9455, 0.9625],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8487])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9698], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8487])\n",
      ">>Entradas: tensor([0.7247, 0.7812, 0.8377, 0.8837, 0.9197, 0.9455, 0.9625, 0.9698],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8753])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9830], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8753])\n",
      ">>Entradas: tensor([0.7812, 0.8377, 0.8837, 0.9197, 0.9455, 0.9625, 0.9698, 0.9830],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9612])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0119], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9612])\n",
      ">>Entradas: tensor([0.8377, 0.8837, 0.9197, 0.9455, 0.9625, 0.9698, 0.9830, 1.0119],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9925])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0330], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9925])\n",
      ">>Entradas: tensor([0.8837, 0.9197, 0.9455, 0.9625, 0.9698, 0.9830, 1.0119, 1.0330],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9690])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0355], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9690])\n",
      ">>Entradas: tensor([0.9197, 0.9455, 0.9625, 0.9698, 0.9830, 1.0119, 1.0330, 1.0355],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9715])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0359], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9715])\n",
      ">>Entradas: tensor([0.9455, 0.9625, 0.9698, 0.9830, 1.0119, 1.0330, 1.0355, 1.0359],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([1.])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0397], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([1.])\n",
      ">>Entradas: tensor([0.9625, 0.9698, 0.9830, 1.0119, 1.0330, 1.0355, 1.0359, 1.0397],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9801])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0303], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9801])\n",
      ">>Entradas: tensor([0.9698, 0.9830, 1.0119, 1.0330, 1.0355, 1.0359, 1.0397, 1.0303],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9117])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([1.0045], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9117])\n",
      ">>Entradas: tensor([0.9830, 1.0119, 1.0330, 1.0355, 1.0359, 1.0397, 1.0303, 1.0045],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.8911])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9824], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.8911])\n",
      ">>Entradas: tensor([1.0119, 1.0330, 1.0355, 1.0359, 1.0397, 1.0303, 1.0045, 0.9824],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9181])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9677], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9181])\n",
      ">>Entradas: tensor([1.0330, 1.0355, 1.0359, 1.0397, 1.0303, 1.0045, 0.9824, 0.9677],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9450])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9560], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9450])\n",
      ">>Entradas: tensor([1.0355, 1.0359, 1.0397, 1.0303, 1.0045, 0.9824, 0.9677, 0.9560],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9718])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9539], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9718])\n",
      ">>Entradas: tensor([1.0359, 1.0397, 1.0303, 1.0045, 0.9824, 0.9677, 0.9560, 0.9539],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9829])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9559], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9829])\n",
      ">>Entradas: tensor([1.0397, 1.0303, 1.0045, 0.9824, 0.9677, 0.9560, 0.9539, 0.9559],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ">>Salida: tensor([0.9783])\n",
      "subepocas: 1\n",
      "sub_epoca: 0\n",
      ">>Inicio de paso (Los valores de la perdida aqui contenidos solo son usados para calculos)\n",
      ">>Fin de paso\n",
      ">>Se calcula perdida despues del paso...\n",
      "----->SALIDA DE LA RED OBTENIDA: tensor([0.9516], grad_fn=<AddBackward0>)\n",
      "----->SALIDA ESPERADA: tensor([0.9783])\n",
      ">>s_original: [0.049424633383750916, 0.10789185762405396, 0.13719609379768372, 0.13733737170696259, 0.1338856965303421, 0.12684109807014465, 0.14756061136722565, 0.19604423642158508, 0.21688967943191528, 0.21009695529937744, 0.20267784595489502, 0.1946323662996292, 0.19407351315021515, 0.20100130140781403, 0.19663821160793304, 0.180984228849411, 0.16539041697978973, 0.14985674619674683, 0.15043111145496368, 0.1671135276556015, 0.20227035880088806, 0.25590160489082336, 0.29268819093704224, 0.31263017654418945, 0.31093889474868774, 0.2876143157482147, 0.28016164898872375, 0.28858086466789246, 0.28246283531188965, 0.26180753111839294, 0.2801212966442108, 0.3374040722846985, 0.3482298254966736, 0.3125985562801361, 0.34358710050582886, 0.44119545817375183, 0.521095335483551, 0.5832866430282593, 0.6089234352111816, 0.5980057120323181, 0.5945301651954651, 0.5984968543052673, 0.621354341506958, 0.6631026864051819, 0.6928724050521851, 0.7106636166572571, 0.721682071685791, 0.7259277701377869, 0.7404318451881409, 0.7651942372322083, 0.7447891235351562, 0.6792163252830505, 0.6746017932891846, 0.730945348739624, 0.7467210292816162, 0.7219287157058716, 0.7199286818504333, 0.7407209277153015, 0.7362455129623413, 0.7065023183822632, 0.6979451775550842, 0.7105739712715149, 0.7209621667861938, 0.7291097044944763, 0.7674259543418884, 0.8359109163284302, 0.8510103225708008, 0.8127241730690002, 0.7863940000534058, 0.7720199823379517, 0.8033170700073242, 0.8802852630615234, 0.8987051844596863, 0.8585767149925232, 0.8308762311935425, 0.8156037926673889, 0.8116992115974426, 0.8191625475883484, 0.8218275904655457, 0.8196942210197449, 0.817862868309021, 0.8163333535194397, 0.8005555868148804, 0.7705295085906982, 0.7426586747169495, 0.716943085193634, 0.7197051048278809, 0.7509447932243347, 0.7402781248092651, 0.6877052187919617, 0.6687695384025574, 0.683471143245697, 0.6877052187919617, 0.6814717054367065, 0.6892618536949158, 0.7110756039619446, 0.7349108457565308, 0.7607676982879639, 0.771117091178894, 0.7659589648246765, 0.7483323812484741, 0.7182371616363525, 0.708941638469696, 0.7204458117485046, 0.7706154584884644, 0.8594506978988647, 0.906541109085083, 0.9118866324424744, 0.9043355584144592, 0.8838878870010376, 0.9032153487205505, 0.9623178839683533, 0.9820588231086731, 0.96243816614151, 0.9302511811256409, 0.8854979276657104, 0.8597025871276855, 0.8528652191162109, 0.8585854768753052, 0.8768633008003235, 0.8806464076042175, 0.8699347376823425, 0.846513569355011, 0.8103827834129333, 0.8026111125946045, 0.8231984972953796, 0.8397204279899597, 0.8521769046783447, 0.8615626692771912, 0.8678776621818542, 0.8701963424682617, 0.868518590927124, 0.852988064289093, 0.8236046433448792, 0.8032509088516235, 0.7919268012046814, 0.7865023016929626, 0.7869773507118225, 0.7874362468719482, 0.7878790497779846, 0.7954531908035278, 0.8101586699485779, 0.7668473124504089, 0.665519118309021, 0.6360738277435303, 0.678511381149292, 0.6965967416763306, 0.6903298497200012, 0.6970472931861877, 0.7167490720748901, 0.7490506768226624, 0.7939522862434387, 0.8547447323799133, 0.931428074836731, 0.9627243876457214, 0.9486336708068848, 0.9307146072387695, 0.9089671969413757, 0.8816379904747009, 0.8487268090248108, 0.8752607107162476, 0.9612395763397217, 0.9925020933151245, 0.9690483212471008, 0.9715476036071777, 1.0, 0.9800636768341064, 0.9117385745048523, 0.8910858035087585, 0.9181053042411804, 0.9450165033340454, 0.9718193411827087, 0.982906699180603, 0.9782785773277283]\n",
      ">>s_pred: [-0.1580667495727539, -0.04823017120361328, 0.018497467041015625, -0.0076656341552734375, 0.042537689208984375, 0.08205413818359375, 0.05909252166748047, 0.09481430053710938, 0.1585683822631836, 0.15797138214111328, 0.1707134246826172, 0.20232391357421875, 0.20010852813720703, 0.20185565948486328, 0.22289180755615234, 0.22196578979492188, 0.20431137084960938, 0.20193099975585938, 0.19594573974609375, 0.18582725524902344, 0.19410419464111328, 0.21497726440429688, 0.230865478515625, 0.2511920928955078, 0.2685432434082031, 0.2733888626098633, 0.2791776657104492, 0.29223060607910156, 0.29888343811035156, 0.2974414825439453, 0.30483341217041016, 0.32352733612060547, 0.33344078063964844, 0.33190441131591797, 0.34543609619140625, 0.38063907623291016, 0.4241781234741211, 0.4788026809692383, 0.5339765548706055, 0.5728511810302734, 0.6053028106689453, 0.6397438049316406, 0.6767702102661133, 0.7181396484375, 0.7590875625610352, 0.7911300659179688, 0.8120050430297852, 0.8247795104980469, 0.8354091644287109, 0.8470678329467773, 0.8461103439331055, 0.8219881057739258, 0.7978038787841797, 0.7887496948242188, 0.7770538330078125, 0.7575654983520508, 0.7436399459838867, 0.7335710525512695, 0.7168121337890625, 0.6976099014282227, 0.6860904693603516, 0.6796855926513672, 0.6759347915649414, 0.6786623001098633, 0.6944112777709961, 0.7259769439697266, 0.7552642822265625, 0.7715435028076172, 0.7833700180053711, 0.7916297912597656, 0.8083591461181641, 0.8472986221313477, 0.8831586837768555, 0.8955574035644531, 0.8975229263305664, 0.8930273056030273, 0.8835763931274414, 0.8796348571777344, 0.8797388076782227, 0.8730182647705078, 0.8599176406860352, 0.8461380004882812, 0.8277359008789062, 0.8025979995727539, 0.7776422500610352, 0.7510719299316406, 0.7284688949584961, 0.7187261581420898, 0.7067031860351562, 0.6806716918945312, 0.6576948165893555, 0.6460800170898438, 0.6364936828613281, 0.6302089691162109, 0.6338701248168945, 0.642756462097168, 0.6546001434326172, 0.6757087707519531, 0.7001581192016602, 0.7200918197631836, 0.7349433898925781, 0.7418346405029297, 0.7466878890991211, 0.754704475402832, 0.7759284973144531, 0.8163938522338867, 0.8575077056884766, 0.8884620666503906, 0.9110832214355469, 0.9189338684082031, 0.934422492980957, 0.9674530029296875, 0.9980506896972656, 1.0125341415405273, 1.0125751495361328, 0.9945850372314453, 0.9674673080444336, 0.9452838897705078, 0.9298925399780273, 0.9177255630493164, 0.9034214019775391, 0.8843450546264648, 0.8584785461425781, 0.8270158767700195, 0.8031558990478516, 0.7929296493530273, 0.7895526885986328, 0.7905693054199219, 0.7951269149780273, 0.8003978729248047, 0.8064746856689453, 0.8159599304199219, 0.8241415023803711, 0.8251094818115234, 0.8228006362915039, 0.8191032409667969, 0.8136262893676758, 0.8091144561767578, 0.8058624267578125, 0.8015556335449219, 0.7981452941894531, 0.7988739013671875, 0.7854843139648438, 0.7456941604614258, 0.709625244140625, 0.6938266754150391, 0.6809597015380859, 0.668482780456543, 0.6643705368041992, 0.6619653701782227, 0.6639881134033203, 0.6840906143188477, 0.7246532440185547, 0.7811651229858398, 0.8377437591552734, 0.8836908340454102, 0.9197416305541992, 0.9454774856567383, 0.9624738693237305, 0.9697952270507812, 0.9829998016357422, 1.0118799209594727, 1.0330190658569336, 1.035496711730957, 1.0359296798706055, 1.0396652221679688, 1.0302906036376953, 1.0044946670532227, 0.9823856353759766, 0.9677362442016602, 0.9559574127197266, 0.9539194107055664, 0.9559307098388672, 0.9516191482543945]\n",
      "<<Perdida: 0.003785099368542433 epoca: 20\n",
      "---FIN DE ENTRENAMIENTO: entrena_LM_pred---\n"
     ]
    }
   ],
   "source": [
    "print(components_e_n[0])\n",
    "entr.entrena_LM_pred(networks[0],0,entrenamiento_8_1,20,lr=0.3,Œª =0.1) #EPOCAS\n",
    "#torch.save(networks[0].state_dict(), 'models/red_A5.pth') #Salvamos el estado actual del modelo\n",
    "\n",
    "# entr.entrena_LM_pred(red_D5,1,entrenamiento_8_1,EPOCAS)\n",
    "# torch.save(red_D5.state_dict(), 'models/red_D5_datos_originales_pred.pth') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entr.entrena_LM_pred(red_D4,2,entrenamiento_8_1,EPOCAS)\n",
    "# torch.save(red_D4.state_dict(), 'models/red_D4_datos_originales_pred.pth')\n",
    "\n",
    "# entr.entrena_LM_pred(red_D3,3,entrenamiento_8_1,EPOCAS)\n",
    "# torch.save(red_D3.state_dict(), 'models/red_D3_datos_originales_pred.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entr.entrena_LM_pred(red_D2,3,entrenamiento_8_1,EPOCAS)\n",
    "# torch.save(red_D2.state_dict(), 'models/red_D2_datos_originales_pred.pth') \n",
    "# entr.entrena_LM_pred(red_D1,3,entrenamiento_8_1,EPOCAS)\n",
    "# torch.save(red_D1.state_dict(), 'models/red_D1_datos_originales_pred.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entr.entrena_LM_pred(red_D4,4,entrenamiento_8_1,EPOCAS)\n",
    "# entr.entrena_LM_pred(red_D5,5,entrenamiento_8_1,EPOCAS)\n",
    "\n",
    "# torch.save(red_A1.state_dict(), redes[\"red_A1\"]) #Salvamos el estado actual del modelo\n",
    "# torch.save(red_D1.state_dict(), redes[\"red_D1\"]) \n",
    "# torch.save(red_D1.state_dict(), redes[\"red_D2\"]) \n",
    "# torch.save(red_D1.state_dict(), redes[\"red_D3\"]) \n",
    "# torch.save(red_D1.state_dict(), redes[\"red_D4\"])\n",
    "# torch.save(red_D1.state_dict(), redes[\"red_D5\"]) \n",
    "\n",
    "# torch.save(red_A1.state_dict(), redes['models/red_A1_n.pth']) #Salvamos el estado actual del modelo\n",
    "# torch.save(red_D1.state_dict(), redes['models/red_D1_n.pth']) \n",
    "# torch.save(red_D2.state_dict(), redes['models/red_D2_n.pth']) \n",
    "#torch.save(red_D3.state_dict(), redes['models/red_D3_n.pth']) \n",
    "# torch.save(red_D4.state_dict(), 'models/red_D4_n.pth')\n",
    "# torch.save(red_D5.state_dict(), redes['models/red_D5_n.pth']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicci√≥n del conjunto de prueba\n",
    "usando los datos predictivos para la recurrencia\n",
    "\n",
    "6. Predict  the  future  price  for  each  point  in  the  testing data set as follows:\n",
    "a) Decompose its preceding price data as described in step 2.  \n",
    "b) Normalize the decomposed features using Eq. (3). \n",
    "c) Predict one step for each component. (El contenido se guarda en el arreglo 'predicciones')\n",
    "d) De-normalize and aggregate the predicted values. \n",
    "e) Repeat steps a, b and c until all the testing dataset \n",
    "points are forecasted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2400x800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perdidas predictivas: [tensor(0.1683, dtype=torch.float64, grad_fn=<MseLossBackward0>), tensor(0.4193, dtype=torch.float64, grad_fn=<MseLossBackward0>), tensor(0.8608, dtype=torch.float64, grad_fn=<MseLossBackward0>), tensor(0.5882, dtype=torch.float64, grad_fn=<MseLossBackward0>), tensor(0.0416, dtype=torch.float64, grad_fn=<MseLossBackward0>), tensor(1.4014, dtype=torch.float64, grad_fn=<MseLossBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "perdidas_predictivas = []\n",
    "plt.figure(figsize=(24, 8))\n",
    "\n",
    "aprox_coef = True\n",
    "index = 1\n",
    "predicciones = []\n",
    "\n",
    "for _ in range(len(components_p_n)):\n",
    "    predicciones.append(utls.genera_prediccion_predictiva(prueba_8_1[_][0][:8],8,len(prueba_8_1[_]),networks[_]))\n",
    "    perdidas_predictivas.append(criterion(predicciones[_], torch.tensor(components_p_n[_])))\n",
    "    plt.subplot(2, 3, index)\n",
    "    plt.plot(range(len(components_p_n[_])), components_p_n[_])\n",
    "    plt.plot(range(len(components_p_n[_])), predicciones[_].detach().numpy(),  label = f\"Perdida: {float(perdidas_predictivas[_])}\", color='#DA0C81' if aprox_coef else '#610C9F')\n",
    "    plt.title('Coeficientes de Aproximaci√≥n' if aprox_coef else 'Coeficientes de Detalle')\n",
    "    aprox_coef = False\n",
    "    plt.legend()\n",
    "    index = index + 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Perdidas predictivas: \" + str(perdidas_predictivas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Reconstruimos la se√±al original usadno el conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.8762,  0.8772,  0.8892,  0.8795,  0.8764,  0.8822,  0.8527,  0.8133,\n",
      "         0.8071,  0.7992,  0.7785,  0.7672,  0.7547,  0.7243,  0.6962,  0.6787,\n",
      "         0.6549,  0.6263,  0.6018,  0.5725,  0.5344,  0.4977,  0.4618,  0.4197,\n",
      "         0.3746,  0.3292,  0.2785,  0.2236,  0.1698,  0.1166,  0.0638,  0.0170,\n",
      "        -0.0216, -0.0530, -0.0756, -0.0906, -0.1028, -0.1130, -0.1210, -0.1283,\n",
      "        -0.1348, -0.1392, -0.1430, -0.1467, -0.1495, -0.1519, -0.1545, -0.1564,\n",
      "        -0.1578, -0.1594, -0.1608, -0.1617, -0.1628, -0.1637, -0.1644, -0.1650,\n",
      "        -0.1657, -0.1662, -0.1666, -0.1671, -0.1674, -0.1677, -0.1680, -0.1683,\n",
      "        -0.1684, -0.1687, -0.1689, -0.1690, -0.1691, -0.1693, -0.1693, -0.1694,\n",
      "        -0.1695, -0.1696, -0.1697, -0.1697, -0.1698, -0.1698],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(predicciones)):\n",
    "    predicciones[i] = predicciones[i][8:]\n",
    "print(predicciones[0])\n",
    "\n",
    "#components_p_n = [utls.normalizar(vect) for vect in components_p]\n",
    "predicciones_d = [utls.desnormalizar(vect.detach().numpy(),np.max(components_p),np.min(components_p)) for vect in predicciones]\n",
    "# D5_p = [utls.desnormalizar(vect) for vect in predicciones[1].detach().numpy()]\n",
    "# D4_p = [utls.desnormalizar(vect) for vect in predicciones[2].detach().numpy()]\n",
    "# D3_p = [utls.desnormalizar(vect) for vect in predicciones[3].detach().numpy()]\n",
    "# D2_p = [utls.desnormalizar(vect) for vect in predicciones[4].detach().numpy()]\n",
    "# D1_p = [utls.desnormalizar(vect) for vect in predicciones[5].detach().numpy()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.plot(range(len(predicciones_d[0])),predicciones_d[0])\n",
    "plt.plot(range(len(components_p[0])),components_p[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cA_p = [utls.desnormalizar(vect) for vect in utls.genera_prediccion_1(coeffs_n_prueba_8_1[0],red_A1,8).detach().numpy()]\n",
    "# cD_1_p = [utls.desnormalizar(vect) for vect in utls.genera_prediccion_1(coeffs_n_prueba_8_1[1],red_D1,8).detach().numpy()]\n",
    "# cD_2_p = [utls.desnormalizar(vect) for vect in utls.genera_prediccion_1(coeffs_n_prueba_8_1[2],red_D2,8).detach().numpy()]\n",
    "# cD_3_p = [utls.desnormalizar(vect) for vect in utls.genera_prediccion_1(coeffs_n_prueba_8_1[3],red_D3,8).detach().numpy()]\n",
    "# cD_4_p = [utls.desnormalizar(vect) for vect in utls.genera_prediccion_1(coeffs_n_prueba_8_1[4],red_D4,8).detach().numpy()]\n",
    "# cD_5_p = [utls.desnormalizar(vect) for vect in utls.genera_prediccion_1(coeffs_n_prueba_8_1[5],red_D5,8).detach().numpy()]\n",
    "\n",
    "# cA_p1 = [utls.desnormalizar(vect) for vect in utls.genera_prediccion_1(prueba_8_1[0],red_A1,8).detach().numpy()]\n",
    "# cD_1_p1 = [utls.desnormalizar(vect) for vect in utls.genera_prediccion_1(prueba_8_1[1],red_D1,8).detach().numpy()]\n",
    "# cD_2_p1 = [utls.desnormalizar(vect) for vect in utls.genera_prediccion_1(prueba_8_1[2],red_D2,8).detach().numpy()]\n",
    "# cD_3_p1 = [utls.desnormalizar(vect) for vect in utls.genera_prediccion_1(prueba_8_1[3],red_D3,8).detach().numpy()]\n",
    "# cD_4_p1 = [utls.desnormalizar(vect) for vect in utls.genera_prediccion_1(prueba_8_1[4],red_D4,8).detach().numpy()]\n",
    "# cD_5_p1 = [utls.desnormalizar(vect) for vect in utls.genera_prediccion_1(prueba_8_1[5],red_D5,8).detach().numpy()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n",
      "78\n",
      "78\n",
      "78\n",
      "78\n",
      "78\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.plot(range(108), [utls.desnormalizar(vect) for vect in utls.genera_prediccion(pruebas_ordenadas[0],red_A1).detach().numpy().tolist()[0]])\n",
    "# Mostrar el gr√°fico\n",
    "#plt.show()\n",
    "\n",
    "#coeffs_pp = [np.array(c) for c in [cA,cD_1,cD_2,cD_3,cD_4,cD_5]]\n",
    "#coeffs_pp = [np.array(c) for c in [A5_p,D5_p,D4_p,D3_p,D2_p,D1_p]]\n",
    "# #print([len(i) for i in coeffs])\n",
    "# #print([len(i) for i in coeffs_p])\n",
    "\n",
    "# # for i, c in enumerate(coeffs_prueba):\n",
    "# #     print(f'Forma de c{i}: {np.shape(c)}')\n",
    "# for i, c in enumerate(coeffs_n_prueba_8_1):\n",
    "#     print(f'Forma de c{i}: {np.shape(c)}')\n",
    "# for i, c in enumerate(prueba_8_1):\n",
    "#     print(f'Forma de c{i}: {np.shape(c)}')\n",
    "#rec = pywt.waverec(coeffs_pp, 'bior3.5', mode=mode)\n",
    "for i in predicciones_d:\n",
    "    print(len(i))\n",
    "(A5_rec, D5_rec, D4_rec, D3_rec, D2_rec, D1_rec) = predicciones_d\n",
    "# c_prueba = cierre[int(len(cierre) * 0.7):]\n",
    "rec = A5_rec + D5_rec + D4_rec + D3_rec + D2_rec + D1_rec\n",
    "plt.plot(range(len(cierre_p)),cierre_p) #Se√±al original\n",
    "plt.plot(range(len(rec)),rec) #Se√±al predicha\n",
    "\n",
    "# #plt.plot(range(len(cA)),cA)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
