{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4., 5., 6., 7., 8.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.nn import Module\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(Module):\n",
    "    def __init__(self, h, w):\n",
    "        super(Net, self).__init__()\n",
    "        self.c1 = torch.nn.Conv2d(1, 32, 3, 1, 1)\n",
    "        self.f2 = torch.nn.Linear(32 * h * w, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c1(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.f2(x)\n",
    "        return x\n",
    "\n",
    "class NARNN(Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(NARNN, self).__init__()\n",
    "        #self.hidden_dim = hidden_dim\n",
    "        #self.num_layers = num_layers\n",
    "        #self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)#capa lstm\n",
    "        #self.fc1 = nn.Linear(hidden_dim, output_dim)#capa lineal\n",
    "        self.fc1 = nn.Linear(input_dim,10)\n",
    "        self.fc2 = nn.Linear(10,10)\n",
    "        self.fc3 = nn.Linear(10,output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()#Crea tensores con las dimensiones especificadas\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        out, _ = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        out = self.fc1(out[:, -1, :]) \n",
    "        return out\"\"\"\n",
    "        tan_sigmoid = lambda a : F.tanh(F.sigmoid(a))\n",
    "        x = tan_sigmoid(self.fc1(x))\n",
    "        #print(y)\n",
    "        #x = torch.sigmoid(self.fc1(x))\n",
    "        #print(x)\n",
    "        x = F.logsigmoid(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "def fun(a, b, c, d):\n",
    "    p = [a.view(32, 1, 3, 3), b, c.view(5, 32 * 12 * 12), d]\n",
    "    x = torch.randn(size=[8, 1, 12, 12], dtype=torch.float32)\n",
    "    y = torch.randint(0, 5, [8])\n",
    "    x = F.conv2d(x, p[0], p[1], 1, 1)\n",
    "    x = x.view(x.size(0), -1)\n",
    "    x = F.linear(x, p[2], p[3])\n",
    "    loss = F.cross_entropy(x, y)\n",
    "    return loss\n",
    "\n",
    "red = NARNN(input_dim=8, hidden_dim=0, output_dim=1, num_layers=0)\n",
    "input = torch.Tensor([1,2,3,4,5,6,7,8])\n",
    "\n",
    "print(input)\n",
    "entrada = input #la entrada se da como un parametro global\n",
    "salida_esperada = torch.tensor([-0.0834]) #lo mismo para la salida esperada\n",
    "\n",
    "# def calcula_perdida(*parametros):\n",
    "#     #red.fc1.weight.data = \n",
    "#     params = []\n",
    "#     i=0\n",
    "#     for param in parametros:\n",
    "#         params.append(param)\n",
    "#         #print(param)\n",
    "#     for r_param in red.parameters():\n",
    "#         params[i].view(r_param.shape)#se le da la forma del parametro correspondiente a los parametros que llegan como entrada\n",
    "#         r_param = params[i]\n",
    "#         i = i+1\n",
    "#     #print([b for b in red.parameters()])\n",
    "#     salida = red(entrada)\n",
    "#     criterion = nn.MSELoss()\n",
    "#     return criterion(salida,salida_esperada)\n",
    "\n",
    "# def calcula_perdida(*parametros):\n",
    "#     #red.fc1.weight.data = \n",
    "#     params = []\n",
    "#     i=0\n",
    "#     #parametros = list(parametros)\n",
    "#     for param in parametros:\n",
    "#         params.append(param)\n",
    "#         print(param)\n",
    "#     for r_param in red.parameters():\n",
    "#         params[i] = params[i].view(r_param.shape)#se le da la forma del parametro correspondiente a los parametros que llegan como entrada\n",
    "#         # r_param = params[i]\n",
    "#         i = i+1\n",
    "#     #print([b for b in red.parameters()]\n",
    "#     l1 = F.linear(entrada,params[0],params[1])\n",
    "#     #print(params[0])\n",
    "#     #print(params[1])\n",
    "#     #print(\"Entradal1: \" + str(l1))\n",
    "#     l2 = F.linear(l1,params[2],params[3])\n",
    "#     #print(\"Entradal2: \" + str(l2))\n",
    "#     salida = F.linear(l2,params[4],params[5])\n",
    "#     #print(\"Salida: \" + str(salida))\n",
    "\n",
    "#     #salida = (entrada)\n",
    "#     criterion = nn.MSELoss()\n",
    "#     return criterion(salida,salida_esperada)\n",
    "\n",
    "def calcula_perdida(*parametros):\n",
    "    #red.fc1.weight.data = \n",
    "    params = []\n",
    "    n_params = []\n",
    "    i=0\n",
    "    n_dim = 0\n",
    "    #parametros = list(parametros)\n",
    "    for param in parametros:\n",
    "        params.append(param)#recibiria un solo tensor con todos los pesos\n",
    "    for r_param in red.parameters():\n",
    "        p_partida = n_dim+1\n",
    "        n_dim = r_param.size(0)*r_param.size(1) #se obtiene la dimension del primer conjunto de pparametros de la red\n",
    "        n_params[i] = params[0][:n_dim, :]\n",
    "        n_params[i] = n_params[i].view(r_param.shape)#se le da la forma del parametro correspondiente a los parametros que llegan como entrada\n",
    "        i = i+1\n",
    "    #print([b for b in red.parameters()]\n",
    "    l1 = F.linear(entrada,params[0],params[1])\n",
    "    #print(params[0])\n",
    "    #print(params[1])\n",
    "    #print(\"Entradal1: \" + str(l1))\n",
    "    l2 = F.linear(l1,params[2],params[3])\n",
    "    #print(\"Entradal2: \" + str(l2))\n",
    "    salida = F.linear(l2,params[4],params[5])\n",
    "    #print(\"Salida: \" + str(salida))\n",
    "\n",
    "    #salida = (entrada)\n",
    "    criterion = nn.MSELoss()\n",
    "    return criterion(salida,salida_esperada)\n",
    "\n",
    "\n",
    "#print([b for b in red.parameters()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6056/1713288172.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "#torch.rand(2,2)\n",
    "a= torch.tensor([1,2,3,4,5,6,7,8,9,10])\n",
    "print(a.shape)\n",
    "print(a[0:1, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.2304e-01, -1.9184e-01,  1.8802e-01,  1.4832e-01,  3.0044e-01,\n",
      "         9.6537e-04, -1.3341e-02,  1.0219e-01,  9.6924e-02, -2.7140e-01,\n",
      "        -1.9343e-02, -2.2502e-02, -3.2963e-01, -1.8602e-01,  2.3739e-01,\n",
      "         2.3699e-01,  1.4987e-01,  1.6612e-01, -1.4459e-01, -8.7238e-02,\n",
      "         8.9779e-03,  2.6686e-01,  3.2407e-01,  1.3229e-01, -1.8551e-01,\n",
      "         1.3540e-01,  1.8300e-01, -9.3619e-02, -5.3804e-02,  9.5736e-02,\n",
      "        -3.0604e-01, -1.2713e-01, -1.2728e-05,  6.8656e-03, -1.7085e-01,\n",
      "         1.8625e-01, -2.6061e-01, -1.1374e-01,  1.8544e-01,  1.1566e-01,\n",
      "         5.2061e-02,  3.1409e-01,  1.7003e-02,  2.7665e-01, -7.6043e-02,\n",
      "        -3.3319e-01,  9.3892e-02, -2.7791e-01, -3.5025e-01, -2.7077e-01,\n",
      "         2.3597e-01, -1.9512e-01,  3.2122e-02, -1.6492e-01,  1.6434e-01,\n",
      "         2.5835e-01, -3.3324e-01, -6.4340e-02,  3.2720e-01,  4.1475e-02,\n",
      "         1.4370e-01,  2.7603e-01,  1.3086e-01, -2.3386e-01, -1.8583e-01,\n",
      "         2.4805e-01, -1.7643e-01, -3.3655e-01,  1.6506e-01,  9.2856e-02,\n",
      "        -1.0376e-01,  2.7926e-01,  2.4787e-01,  9.0148e-02,  6.3841e-02,\n",
      "        -1.7620e-01,  9.6163e-02, -2.2508e-01, -1.9723e-01,  9.6220e-02],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.3189, -0.0728, -0.1697,  0.1573, -0.3266,  0.2234,  0.1569,  0.0010,\n",
      "         0.0077, -0.0243], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0210, -0.2274, -0.0188,  0.1629,  0.1766, -0.0492,  0.2528, -0.0277,\n",
      "        -0.2011,  0.2376, -0.0040, -0.0906,  0.1569,  0.0442, -0.1568,  0.2058,\n",
      "         0.1208,  0.2809, -0.2381,  0.3155,  0.2195,  0.1021,  0.0726,  0.1080,\n",
      "         0.1162, -0.1187,  0.0541, -0.1607, -0.1223, -0.1356,  0.1536,  0.2879,\n",
      "        -0.0789, -0.2070, -0.2868,  0.0803,  0.0453,  0.2104,  0.2216,  0.2506,\n",
      "         0.2069, -0.1415, -0.1972, -0.1072,  0.0039,  0.0773, -0.0529, -0.0358,\n",
      "         0.0008,  0.2178, -0.2466, -0.0752,  0.2979, -0.2493,  0.0117,  0.3077,\n",
      "        -0.0489,  0.0096, -0.1626, -0.0552, -0.0625, -0.1922, -0.2203,  0.1988,\n",
      "        -0.0349,  0.0055,  0.1424,  0.0787, -0.1525,  0.2402, -0.1766, -0.1355,\n",
      "        -0.2173, -0.0450,  0.0878, -0.2944,  0.2100,  0.0402,  0.2171, -0.2362,\n",
      "         0.1592, -0.1367, -0.0637, -0.1874,  0.2071, -0.1166, -0.2932, -0.0659,\n",
      "        -0.0028,  0.0960, -0.2091, -0.0996, -0.0582,  0.1600, -0.1182, -0.2389,\n",
      "         0.2362, -0.2520,  0.1357,  0.0676], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1450,  0.1935, -0.0008, -0.2814, -0.0628,  0.0604, -0.1017,  0.2997,\n",
      "         0.3148,  0.1682], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2608, -0.2810,  0.2306, -0.1417,  0.2773,  0.3109, -0.1949, -0.0004,\n",
      "         0.0244, -0.0907], grad_fn=<ViewBackward0>)\n",
      "tensor([0.2892], grad_fn=<ViewBackward0>)\n",
      "tensor(0.3400, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "entrada = input\n",
    "#print(red.fc1.weight.data)\n",
    "#red.fc1.weight.data = torch.zeros((10,8))\n",
    "#print(red.fc1.weight.data)\n",
    "#print(torch.tensor([[1,2,3,4,5,6,7,8],[1,2,3,4,5,6,7,8]]))\n",
    "#print(red.fc2.weight.data)\n",
    "#print(red.fc3.weight.data)\n",
    "v = [_.view(-1) for _ in red.parameters()]\n",
    "#print(len(v))\n",
    "p = calcula_perdida(v[0],v[1],v[2],v[3],v[4],v[5])\n",
    "#print(red(entrada))\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.2304e-01, -1.9184e-01,  1.8802e-01,  1.4832e-01,  3.0044e-01,\n",
      "         9.6537e-04, -1.3341e-02,  1.0219e-01,  9.6924e-02, -2.7140e-01,\n",
      "        -1.9343e-02, -2.2502e-02, -3.2963e-01, -1.8602e-01,  2.3739e-01,\n",
      "         2.3699e-01,  1.4987e-01,  1.6612e-01, -1.4459e-01, -8.7238e-02,\n",
      "         8.9779e-03,  2.6686e-01,  3.2407e-01,  1.3229e-01, -1.8551e-01,\n",
      "         1.3540e-01,  1.8300e-01, -9.3619e-02, -5.3804e-02,  9.5736e-02,\n",
      "        -3.0604e-01, -1.2713e-01, -1.2728e-05,  6.8656e-03, -1.7085e-01,\n",
      "         1.8625e-01, -2.6061e-01, -1.1374e-01,  1.8544e-01,  1.1566e-01,\n",
      "         5.2061e-02,  3.1409e-01,  1.7003e-02,  2.7665e-01, -7.6043e-02,\n",
      "        -3.3319e-01,  9.3892e-02, -2.7791e-01, -3.5025e-01, -2.7077e-01,\n",
      "         2.3597e-01, -1.9512e-01,  3.2122e-02, -1.6492e-01,  1.6434e-01,\n",
      "         2.5835e-01, -3.3324e-01, -6.4340e-02,  3.2720e-01,  4.1475e-02,\n",
      "         1.4370e-01,  2.7603e-01,  1.3086e-01, -2.3386e-01, -1.8583e-01,\n",
      "         2.4805e-01, -1.7643e-01, -3.3655e-01,  1.6506e-01,  9.2856e-02,\n",
      "        -1.0376e-01,  2.7926e-01,  2.4787e-01,  9.0148e-02,  6.3841e-02,\n",
      "        -1.7620e-01,  9.6163e-02, -2.2508e-01, -1.9723e-01,  9.6220e-02],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.3189, -0.0728, -0.1697,  0.1573, -0.3266,  0.2234,  0.1569,  0.0010,\n",
      "         0.0077, -0.0243], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0210, -0.2274, -0.0188,  0.1629,  0.1766, -0.0492,  0.2528, -0.0277,\n",
      "        -0.2011,  0.2376, -0.0040, -0.0906,  0.1569,  0.0442, -0.1568,  0.2058,\n",
      "         0.1208,  0.2809, -0.2381,  0.3155,  0.2195,  0.1021,  0.0726,  0.1080,\n",
      "         0.1162, -0.1187,  0.0541, -0.1607, -0.1223, -0.1356,  0.1536,  0.2879,\n",
      "        -0.0789, -0.2070, -0.2868,  0.0803,  0.0453,  0.2104,  0.2216,  0.2506,\n",
      "         0.2069, -0.1415, -0.1972, -0.1072,  0.0039,  0.0773, -0.0529, -0.0358,\n",
      "         0.0008,  0.2178, -0.2466, -0.0752,  0.2979, -0.2493,  0.0117,  0.3077,\n",
      "        -0.0489,  0.0096, -0.1626, -0.0552, -0.0625, -0.1922, -0.2203,  0.1988,\n",
      "        -0.0349,  0.0055,  0.1424,  0.0787, -0.1525,  0.2402, -0.1766, -0.1355,\n",
      "        -0.2173, -0.0450,  0.0878, -0.2944,  0.2100,  0.0402,  0.2171, -0.2362,\n",
      "         0.1592, -0.1367, -0.0637, -0.1874,  0.2071, -0.1166, -0.2932, -0.0659,\n",
      "        -0.0028,  0.0960, -0.2091, -0.0996, -0.0582,  0.1600, -0.1182, -0.2389,\n",
      "         0.2362, -0.2520,  0.1357,  0.0676], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1450,  0.1935, -0.0008, -0.2814, -0.0628,  0.0604, -0.1017,  0.2997,\n",
      "         0.3148,  0.1682], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2608, -0.2810,  0.2306, -0.1417,  0.2773,  0.3109, -0.1949, -0.0004,\n",
      "         0.0244, -0.0907], grad_fn=<ViewBackward0>)\n",
      "tensor([0.2892], grad_fn=<ViewBackward0>)\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# class Net(Module):\n",
    "#     def __init__(self, h, w):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.c1 = torch.nn.Conv2d(1, 32, 3, 1, 1)\n",
    "#         self.f2 = torch.nn.Linear(32 * h * w, 5)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.c1(x)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.f2(x)\n",
    "#         return x\n",
    "\n",
    "# def haha(a, b, c, d):\n",
    "#     p = [a.view(32, 1, 3, 3), b, c.view(5, 32 * 12 * 12), d]\n",
    "#     x = torch.randn(size=[8, 1, 12, 12], dtype=torch.float32)\n",
    "#     y = torch.randint(0, 5, [8])\n",
    "#     x = F.conv2d(x, p[0], p[1], 1, 1)\n",
    "#     x = x.view(x.size(0), -1)\n",
    "#     x = F.linear(x, p[2], p[3])\n",
    "#     loss = F.cross_entropy(x, y)\n",
    "#     return loss\n",
    "a = torch.autograd.functional.hessian(calcula_perdida, tuple(v))\n",
    "#print(len(list(a)))\n",
    "print(len(list(a)[0]))\n",
    "#print(h = torch.autograd.functional.hessian(haha, tuple([_.view(-1) for _ in net.parameters()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2425, -2.0265, -0.7171,  0.8465,  1.1031,  0.8568, -0.5701,  0.4621,\n",
      "         -1.8919,  1.8212,  0.2178, -0.4279, -0.3306, -2.0242,  0.1793, -0.6342,\n",
      "          0.5306, -0.3990, -1.4124, -0.0128, -1.2783, -0.7999, -0.9947, -0.0745,\n",
      "          0.5407,  1.7440, -0.6248,  0.2478,  0.1415,  1.3523, -0.6399, -1.1641,\n",
      "         -0.7785, -1.3825, -0.1487, -1.1846, -1.9734,  0.9720,  0.8780,  0.1155,\n",
      "          1.0394,  1.2352,  1.3094,  0.6719, -1.3239, -0.2211, -1.4850, -0.1578,\n",
      "         -1.3046, -1.6374,  0.7868,  1.4017,  0.0231,  0.7787, -0.9604,  0.5887,\n",
      "          0.6013, -0.5279,  1.2014,  0.2648, -2.1216, -0.2071,  0.0888, -2.6840,\n",
      "          0.7722, -0.1971,  1.9545, -0.2919, -0.4544, -0.3679, -1.6071, -0.4358,\n",
      "          0.1476,  1.1260, -0.7250, -1.1016, -0.7317,  0.0610,  0.5086, -0.1533]])\n",
      "tensor([[ 1.2425, -2.0265, -0.7171,  0.8465,  1.1031,  0.8568, -0.5701,  0.4621],\n",
      "        [-1.8919,  1.8212,  0.2178, -0.4279, -0.3306, -2.0242,  0.1793, -0.6342],\n",
      "        [ 0.5306, -0.3990, -1.4124, -0.0128, -1.2783, -0.7999, -0.9947, -0.0745],\n",
      "        [ 0.5407,  1.7440, -0.6248,  0.2478,  0.1415,  1.3523, -0.6399, -1.1641],\n",
      "        [-0.7785, -1.3825, -0.1487, -1.1846, -1.9734,  0.9720,  0.8780,  0.1155],\n",
      "        [ 1.0394,  1.2352,  1.3094,  0.6719, -1.3239, -0.2211, -1.4850, -0.1578],\n",
      "        [-1.3046, -1.6374,  0.7868,  1.4017,  0.0231,  0.7787, -0.9604,  0.5887],\n",
      "        [ 0.6013, -0.5279,  1.2014,  0.2648, -2.1216, -0.2071,  0.0888, -2.6840],\n",
      "        [ 0.7722, -0.1971,  1.9545, -0.2919, -0.4544, -0.3679, -1.6071, -0.4358],\n",
      "        [ 0.1476,  1.1260, -0.7250, -1.1016, -0.7317,  0.0610,  0.5086, -0.1533]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = torch.randn(1,80)\n",
    "print(x)\n",
    "y = []\n",
    "for i in red.parameters():\n",
    "    y.append(i.shape)\n",
    "#x = x.view(y[0])\n",
    "print(x.view(y[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor existente:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "Tensor ajustado con la misma forma que el otro tensor:\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Supongamos que tienes dos tensores con diferentes formas\n",
    "tensor_existente = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "otro_tensor = torch.tensor([[7, 8], [9, 10],[11,12]])\n",
    "\n",
    "# Obt√©n la forma del otro tensor\n",
    "forma_deseada = otro_tensor.shape\n",
    "\n",
    "# Ajusta la forma del tensor existente para que coincida con la forma deseada\n",
    "tensor_ajustado = tensor_existente.view(forma_deseada)\n",
    "\n",
    "# Alternativamente, puedes usar reshape\n",
    "# tensor_ajustado = tensor_existente.reshape(forma_deseada)\n",
    "\n",
    "print(\"Tensor existente:\")\n",
    "print(tensor_existente)\n",
    "\n",
    "print(\"Tensor ajustado con la misma forma que el otro tensor:\")\n",
    "print(tensor_ajustado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 4.],\n",
      "        [1., 3.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[12.,  0.],\n",
       "          [ 0.,  0.]],\n",
       "\n",
       "         [[ 0., 24.],\n",
       "          [ 0.,  0.]]],\n",
       "\n",
       "\n",
       "        [[[ 0.,  0.],\n",
       "          [ 6.,  0.]],\n",
       "\n",
       "         [[ 0.,  0.],\n",
       "          [ 0., 18.]]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pow_reducer(x):\n",
    "    x=x.view(-1)\n",
    "    return x.pow(3).sum()\n",
    "inputs = torch.Tensor([[2,4],[1,3]])\n",
    "print(inputs)\n",
    "torch.autograd.functional.hessian(pow_reducer, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 4.],\n",
      "        [1., 3.]])\n",
      "tensor([2., 4., 1., 3.])\n"
     ]
    }
   ],
   "source": [
    "print(torch.Tensor([[2,4],[1,3]]))\n",
    "print(torch.Tensor([[2,4],[1,3]]).view(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.)\n"
     ]
    }
   ],
   "source": [
    "def pow_r(x):\n",
    "    return x.pow(3).sum()\n",
    "\n",
    "print(pow_r(torch.Tensor([2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([288])\n",
      "torch.Size([32, 1, 3, 3])\n",
      "tensor([[[[ 5.7037e-01, -1.6220e+00,  2.2039e-01,  ..., -1.8979e+00,\n",
      "           -1.5416e+00, -5.3563e-01],\n",
      "          [-1.1947e+00,  2.2494e-01,  1.4591e-01,  ...,  4.6369e-01,\n",
      "           -1.0561e+00, -8.1643e-01],\n",
      "          [-7.8351e-01, -6.7065e-01,  6.7817e-01,  ...,  2.3470e-01,\n",
      "            7.0937e-02,  1.5931e+00],\n",
      "          ...,\n",
      "          [-7.5470e-01, -1.5926e-01,  5.1093e-01,  ...,  6.1051e-02,\n",
      "            1.3519e-01,  4.6800e-01],\n",
      "          [ 2.7908e-01,  7.1455e-01,  2.5397e-01,  ..., -8.8045e-01,\n",
      "            9.4286e-01,  2.1376e-01],\n",
      "          [ 2.5175e+00, -4.4433e-01, -2.6354e-01,  ..., -1.1572e+00,\n",
      "           -1.5571e+00,  9.0103e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.0976e-01, -5.2877e-01, -6.8055e-01,  ...,  1.1446e+00,\n",
      "           -1.6650e-01, -3.5450e-01],\n",
      "          [-8.4889e-02,  3.4633e-01,  4.9917e-01,  ...,  1.4496e+00,\n",
      "            3.3475e+00,  1.2317e+00],\n",
      "          [-4.7402e-01,  5.1185e-01, -5.0354e-01,  ..., -7.3297e-01,\n",
      "           -7.2453e-01, -1.3287e+00],\n",
      "          ...,\n",
      "          [-1.4223e-01, -1.1155e+00,  1.8489e+00,  ...,  2.3714e+00,\n",
      "           -3.1327e-01, -3.4378e-02],\n",
      "          [ 1.1552e-01, -3.0698e-01,  4.6685e-01,  ...,  1.4609e+00,\n",
      "           -1.2338e+00, -5.8183e-01],\n",
      "          [ 7.2018e-02,  1.9511e+00,  1.9696e+00,  ..., -5.5597e-01,\n",
      "            6.3940e-02,  2.3178e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.2715e-01, -1.2204e+00, -1.6185e-01,  ..., -1.1006e+00,\n",
      "            6.0621e-01, -1.7617e+00],\n",
      "          [-2.0520e+00, -6.8733e-01, -1.4331e+00,  ..., -7.0217e-01,\n",
      "            1.4230e-01,  6.2097e-01],\n",
      "          [-8.8488e-02,  1.8313e+00,  3.2471e-01,  ...,  1.1762e+00,\n",
      "            1.1671e+00, -2.8650e-01],\n",
      "          ...,\n",
      "          [ 3.2584e-01, -3.7588e-01, -1.0256e+00,  ..., -1.3826e+00,\n",
      "            1.6289e+00, -1.0193e+00],\n",
      "          [-2.6089e-01,  4.5512e-01,  1.5818e+00,  ...,  6.0732e-01,\n",
      "           -1.2835e-01, -1.1747e-02],\n",
      "          [ 1.2940e+00,  7.4410e-01, -7.7828e-01,  ..., -6.8190e-01,\n",
      "           -4.1177e-01, -6.0937e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 4.4485e-01,  2.4440e+00,  1.4313e+00,  ..., -1.0498e-01,\n",
      "            7.1545e-01,  4.8124e-01],\n",
      "          [-1.0152e+00, -1.3850e+00, -1.3874e+00,  ...,  1.7690e-02,\n",
      "            1.4358e+00, -1.4626e+00],\n",
      "          [-5.0400e-01,  2.3277e-01, -2.1110e-03,  ..., -1.6244e+00,\n",
      "           -2.2012e+00, -1.0445e+00],\n",
      "          ...,\n",
      "          [-6.1248e-02, -6.6758e-01,  1.6493e-01,  ...,  5.3174e-02,\n",
      "            3.9225e-01, -1.2550e-01],\n",
      "          [ 1.8962e-01,  3.4854e-02, -1.6736e+00,  ..., -2.3647e+00,\n",
      "           -9.1815e-01,  1.5209e+00],\n",
      "          [-7.0027e-01, -2.6969e-01,  5.7925e-01,  ...,  2.0332e+00,\n",
      "            2.0634e-01,  5.4550e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1318e+00, -7.7687e-02,  1.0377e+00,  ...,  1.1975e+00,\n",
      "           -4.9791e-01,  1.0329e+00],\n",
      "          [ 2.1216e+00, -4.0569e-01, -7.9207e-01,  ...,  7.9910e-01,\n",
      "           -3.1265e+00, -3.2323e-01],\n",
      "          [ 2.1302e+00,  9.0183e-01,  7.4798e-01,  ...,  6.1898e-02,\n",
      "            5.2014e-01,  2.7977e-01],\n",
      "          ...,\n",
      "          [ 1.0473e+00, -7.3370e-01,  6.6952e-01,  ..., -3.8294e-01,\n",
      "           -5.3100e-01,  4.7866e-01],\n",
      "          [ 2.1246e-01, -2.3934e+00, -1.1721e+00,  ...,  6.4552e-01,\n",
      "            5.4724e-04, -1.1390e+00],\n",
      "          [-3.9477e-01, -7.4782e-01,  1.1723e+00,  ...,  1.6826e-01,\n",
      "           -1.4998e-01,  7.8865e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.9746e-02, -1.1213e+00,  1.3199e-01,  ...,  2.9847e-02,\n",
      "            1.3490e+00, -4.4636e-01],\n",
      "          [ 4.8617e-01, -1.5921e+00,  4.0803e-01,  ...,  7.8890e-01,\n",
      "            2.2076e-02,  5.2207e-01],\n",
      "          [-4.0674e-01, -1.0326e+00,  1.9995e+00,  ..., -1.5290e-01,\n",
      "           -9.1367e-01,  1.1339e+00],\n",
      "          ...,\n",
      "          [ 9.9055e-01, -9.6804e-01, -9.2159e-01,  ...,  6.9404e-01,\n",
      "           -1.0285e+00, -2.9458e-01],\n",
      "          [ 1.5698e-01, -4.5820e-01, -1.0950e+00,  ...,  7.7007e-01,\n",
      "           -7.2994e-01,  5.0897e-01],\n",
      "          [-8.9344e-01, -3.3630e-01,  5.8343e-01,  ...,  8.4738e-01,\n",
      "            5.2376e-01,  1.3382e+00]]]])\n"
     ]
    }
   ],
   "source": [
    "net = Net(12, 12)\n",
    "\n",
    "print([i.view(-1) for i in net.parameters()][0].size())\n",
    "print([i for i in net.parameters()][0].size())\n",
    "\n",
    "t = tuple([_.view(-1) for _ in net.parameters()])\n",
    "\n",
    "print(torch.randn(size=[8, 1, 12, 12], dtype=torch.float32))\n",
    "#print(net)\n",
    "#print(len(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.1217, -0.0818, -0.1036,  0.3002,  0.1637, -0.1048,  0.2623,  0.2988,\n",
       "         -0.2624,  0.1128, -0.0690,  0.2537,  0.3321, -0.1400,  0.0543,  0.3223,\n",
       "         -0.0853, -0.0464,  0.0765, -0.0377, -0.2048,  0.3262,  0.0286, -0.0862,\n",
       "         -0.1481, -0.1255,  0.3250,  0.2934,  0.1509,  0.2734,  0.0445, -0.0381,\n",
       "         -0.1065,  0.0958,  0.2534,  0.0984,  0.0806,  0.0021,  0.2244, -0.1927,\n",
       "         -0.1488,  0.0710, -0.0175, -0.1059,  0.1912,  0.2350,  0.1904, -0.0048,\n",
       "         -0.1818,  0.1958, -0.0474,  0.0634, -0.2812, -0.1592, -0.1451, -0.0265,\n",
       "         -0.0242, -0.2434, -0.0942,  0.1893,  0.1298, -0.2936,  0.1334, -0.1612,\n",
       "          0.0079,  0.2406,  0.1352,  0.2592, -0.2827,  0.2473, -0.2747, -0.1128,\n",
       "         -0.0998,  0.3259,  0.2503,  0.0906, -0.0950, -0.1080,  0.0297,  0.2630,\n",
       "         -0.2460,  0.1935, -0.1856, -0.0456,  0.2585,  0.1985,  0.0689,  0.0778,\n",
       "         -0.0363, -0.0353,  0.2892,  0.2555, -0.0505, -0.2110, -0.1705,  0.1030,\n",
       "          0.2529,  0.0185,  0.0485, -0.1795,  0.1639, -0.3008, -0.1935, -0.2713,\n",
       "          0.1071, -0.2466,  0.0422,  0.1933,  0.0058,  0.2059,  0.3108,  0.2695,\n",
       "          0.1862,  0.0797, -0.0112,  0.1105, -0.1106, -0.2765, -0.2605,  0.1255,\n",
       "          0.0402, -0.3215, -0.1157, -0.1966,  0.3118,  0.0421,  0.0188,  0.2827,\n",
       "          0.2312,  0.0485,  0.2953, -0.1070, -0.0319, -0.0194, -0.1340,  0.0024,\n",
       "         -0.2228, -0.0416, -0.0399,  0.0896, -0.2741, -0.2214, -0.2999,  0.2858,\n",
       "         -0.1669, -0.1833, -0.0302, -0.0772,  0.2814, -0.2565, -0.2829,  0.0663,\n",
       "          0.2491,  0.0690, -0.2860,  0.2956,  0.0307,  0.2245, -0.2572,  0.0202,\n",
       "          0.0174,  0.2418, -0.1094,  0.3029,  0.1425,  0.0220, -0.1467, -0.2488,\n",
       "         -0.1994,  0.2214,  0.0138,  0.1450, -0.2564,  0.3280,  0.1570, -0.3055,\n",
       "         -0.0092, -0.2222, -0.1479, -0.0349,  0.1145, -0.0199,  0.0052,  0.1054,\n",
       "          0.3116,  0.0851,  0.1335, -0.1922, -0.1916,  0.3270, -0.1165,  0.2670,\n",
       "         -0.0643,  0.2132,  0.0704, -0.1100,  0.3258,  0.1627,  0.1263, -0.2600,\n",
       "          0.2577, -0.0234,  0.0512, -0.0408,  0.2485, -0.1280, -0.0141,  0.0834,\n",
       "          0.2554,  0.0753, -0.2362,  0.0417, -0.2651, -0.1025, -0.2587, -0.0408,\n",
       "          0.0169, -0.1195, -0.1360, -0.1703,  0.2978, -0.3173,  0.0669, -0.1697,\n",
       "         -0.2744,  0.0740, -0.2940, -0.2598,  0.1986,  0.1098, -0.3284,  0.1598,\n",
       "          0.0116, -0.1984,  0.0832,  0.1805, -0.1728,  0.0038, -0.0558, -0.2293,\n",
       "         -0.1517, -0.2088,  0.0529,  0.2844, -0.0613, -0.1403, -0.1962,  0.1055,\n",
       "          0.0360, -0.1704, -0.0670,  0.0431, -0.2806, -0.1708,  0.2353, -0.2889,\n",
       "         -0.3243, -0.1232,  0.1697,  0.0240, -0.1193,  0.0067,  0.2837, -0.0198,\n",
       "          0.2742,  0.0372,  0.0035, -0.3144,  0.0271,  0.1148, -0.1179, -0.1012,\n",
       "          0.2023, -0.2614,  0.1127, -0.2585, -0.3027,  0.3325, -0.2529, -0.1727,\n",
       "         -0.2687,  0.0671, -0.0452,  0.2335,  0.1204, -0.3029,  0.2496, -0.0889],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " tensor([ 0.0794, -0.2921,  0.1823,  0.2880,  0.1459,  0.2777,  0.0961, -0.1391,\n",
       "         -0.3257,  0.3099,  0.0703,  0.3240, -0.2261,  0.2378, -0.1164,  0.3183,\n",
       "          0.2797, -0.0810,  0.2050, -0.1549,  0.1531, -0.1748, -0.0263,  0.1596,\n",
       "         -0.0933,  0.0402,  0.0489, -0.0312, -0.2019, -0.1270,  0.2065,  0.1488],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " tensor([-0.0092,  0.0014,  0.0098,  ...,  0.0132,  0.0144,  0.0008],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " tensor([-0.0073,  0.0050,  0.0146, -0.0023, -0.0086], grad_fn=<ViewBackward0>))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#h = torch.autograd.functional.hessian(haha, tuple([_.view(-1) for _ in net.parameters()]))\n",
    "tuple([_.view(-1) for _ in net.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'h' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6247/3045854989.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'h' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(type(h))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
