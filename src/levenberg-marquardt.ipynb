{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4., 5., 6., 7., 8.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.nn import Module\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "class Net(Module):\n",
    "    def __init__(self, h, w):\n",
    "        super(Net, self).__init__()\n",
    "        self.c1 = torch.nn.Conv2d(1, 32, 3, 1, 1)\n",
    "        self.f2 = torch.nn.Linear(32 * h * w, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c1(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.f2(x)\n",
    "        return x\n",
    "\n",
    "class NARNN(Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(NARNN, self).__init__()\n",
    "        #self.hidden_dim = hidden_dim\n",
    "        #self.num_layers = num_layers\n",
    "        #self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)#capa lstm\n",
    "        #self.fc1 = nn.Linear(hidden_dim, output_dim)#capa lineal\n",
    "        self.fc1 = nn.Linear(input_dim,10)\n",
    "        self.fc2 = nn.Linear(10,10)\n",
    "        self.fc3 = nn.Linear(10,output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()#Crea tensores con las dimensiones especificadas\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        out, _ = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        out = self.fc1(out[:, -1, :]) \n",
    "        return out\"\"\"\n",
    "        tan_sigmoid = lambda a : F.tanh(F.sigmoid(a))\n",
    "        x = tan_sigmoid(self.fc1(x))\n",
    "        #print(y)\n",
    "        #x = torch.sigmoid(self.fc1(x))\n",
    "        #print(x)\n",
    "        x = F.logsigmoid(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "def fun(a, b, c, d):\n",
    "    p = [a.view(32, 1, 3, 3), b, c.view(5, 32 * 12 * 12), d]\n",
    "    x = torch.randn(size=[8, 1, 12, 12], dtype=torch.float32)\n",
    "    y = torch.randint(0, 5, [8])\n",
    "    x = F.conv2d(x, p[0], p[1], 1, 1)\n",
    "    x = x.view(x.size(0), -1)\n",
    "    x = F.linear(x, p[2], p[3])\n",
    "    loss = F.cross_entropy(x, y)\n",
    "    return loss\n",
    "\n",
    "red = NARNN(input_dim=8, hidden_dim=0, output_dim=1, num_layers=0)\n",
    "input = torch.Tensor([1,2,3,4,5,6,7,8])\n",
    "\n",
    "print(input)\n",
    "entrada = input #la entrada se da como un parametro global\n",
    "salida_esperada = torch.tensor([-0.0834]) #lo mismo para la salida esperada\n",
    "Î» = 0.1\n",
    "\n",
    "# def calcula_perdida(*parametros):\n",
    "#     #red.fc1.weight.data = \n",
    "#     params = []\n",
    "#     i=0\n",
    "#     for param in parametros:\n",
    "#         params.append(param)\n",
    "#         #print(param)\n",
    "#     for r_param in red.parameters():\n",
    "#         params[i].view(r_param.shape)#se le da la forma del parametro correspondiente a los parametros que llegan como entrada\n",
    "#         r_param = params[i]\n",
    "#         i = i+1\n",
    "#     #print([b for b in red.parameters()])\n",
    "#     salida = red(entrada)\n",
    "#     criterion = nn.MSELoss()\n",
    "#     return criterion(salida,salida_esperada)\n",
    "\n",
    "# def calcula_perdida(*parametros):\n",
    "#     #red.fc1.weight.data = \n",
    "#     params = []\n",
    "#     i=0\n",
    "#     #parametros = list(parametros)\n",
    "#     for param in parametros:\n",
    "#         params.append(param)\n",
    "#         print(param)\n",
    "#     for r_param in red.parameters():\n",
    "#         params[i] = params[i].view(r_param.shape)#se le da la forma del parametro correspondiente a los parametros que llegan como entrada\n",
    "#         # r_param = params[i]\n",
    "#         i = i+1\n",
    "#     #print([b for b in red.parameters()]\n",
    "#     l1 = F.linear(entrada,params[0],params[1])\n",
    "#     #print(params[0])\n",
    "#     #print(params[1])\n",
    "#     #print(\"Entradal1: \" + str(l1))\n",
    "#     l2 = F.linear(l1,params[2],params[3])\n",
    "#     #print(\"Entradal2: \" + str(l2))\n",
    "#     salida = F.linear(l2,params[4],params[5])\n",
    "#     #print(\"Salida: \" + str(salida))\n",
    "\n",
    "#     #salida = (entrada)\n",
    "#     criterion = nn.MSELoss()\n",
    "#     return criterion(salida,salida_esperada)\n",
    "\n",
    "def calcula_perdida(*parametros):\n",
    "    #red.fc1.weight.data = \n",
    "    params = []\n",
    "    n_params = []\n",
    "    i=0\n",
    "    n_dim = 0\n",
    "    #parametros = list(parametros)\n",
    "    for param in parametros:\n",
    "        params.append(param)#recibiria un solo tensor con todos los pesos\n",
    "    for r_param in red.parameters():\n",
    "        p_partida = n_dim\n",
    "        print(\"shape: \" + str(r_param.shape))\n",
    "        n_dim = r_param.size(0)*(r_param.size(1) if r_param.dim() == 2 else 1) + p_partida#se obtiene la dimension del primer conjunto de pparametros de la red\n",
    "        print(\"n_dim: \" + str(n_dim) + \" p_partida: \" + str(p_partida))\n",
    "        #print(\"primer vector: \" + str(params[0][p_partida:n_dim]))\n",
    "        n_params.append(params[0][p_partida:n_dim])\n",
    "        print(\"primer vector: \" + str(n_params[i]))\n",
    "        n_params[i] = n_params[i].view(r_param.shape)#se le da la forma del parametro correspondiente a los parametros que llegan como entrada\n",
    "        print(\"segundo vector: \" + str(n_params[i]))\n",
    "        i = i+1\n",
    "    #print([b for b in red.parameters()]\n",
    "    l1 = F.linear(entrada,n_params[0],n_params[1])\n",
    "    #print(params[0])\n",
    "    #print(params[1])\n",
    "    #print(\"Entradal1: \" + str(l1))\n",
    "    l2 = F.linear(l1,n_params[2],n_params[3])\n",
    "    #print(\"Entradal2: \" + str(l2))\n",
    "    salida = F.linear(l2,n_params[4],n_params[5])\n",
    "    #print(\"Salida: \" + str(salida))\n",
    "\n",
    "    #salida = (entrada)\n",
    "    criterion = nn.MSELoss()\n",
    "    return criterion(salida,salida_esperada)\n",
    "\n",
    "\n",
    "#print([b for b in red.parameters()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([[0.8883, 0.5990, 0.9390, 0.1919, 0.8274],\n",
      "        [0.0160, 0.9186, 0.8657, 0.7889, 0.6975]])\n",
      "tensor([[ 1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10]])\n",
      "1\n",
      "tensor([[5.6592, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 1.9605, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 4.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.5648, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 3.5775, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.9578, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 4.7752, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7785, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 5.5902,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0813]])\n"
     ]
    }
   ],
   "source": [
    "#torch.rand(2,2)\n",
    "a= torch.tensor([1,2,3,4,5,6,7,8,9,10])\n",
    "print(a.dim())\n",
    "print(torch.rand(2,5))\n",
    "print(a.view(2,5))\n",
    "def pow_reducer(x):\n",
    "    return x.pow(3).sum()\n",
    "inputs = torch.rand(10)\n",
    "print(inputs.dim())\n",
    "print(torch.autograd.functional.hessian(pow_reducer, inputs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: torch.Size([10, 8])\n",
      "n_dim: 80 p_partida: 0\n",
      "primer vector: tensor([ 0.1164,  0.2900, -0.0291, -0.0216,  0.2039,  0.1715, -0.2000,  0.1696,\n",
      "        -0.0674,  0.2430, -0.3349,  0.3140,  0.3342,  0.2254,  0.0340,  0.0556,\n",
      "        -0.0453,  0.1167,  0.2998,  0.0317,  0.1979, -0.3292,  0.0044, -0.2794,\n",
      "        -0.2603,  0.0763, -0.0107,  0.0302, -0.2064,  0.0159, -0.1453,  0.0352,\n",
      "         0.3440, -0.3510, -0.1371,  0.0280,  0.2001,  0.2703, -0.2787, -0.0082,\n",
      "        -0.2815, -0.2875,  0.1395, -0.1039,  0.1308, -0.2473, -0.2474,  0.0605,\n",
      "         0.1759, -0.1858, -0.0424, -0.0421, -0.0149,  0.0702, -0.0969,  0.2800,\n",
      "         0.0935, -0.2574, -0.2462, -0.2338, -0.1046, -0.1525, -0.0649,  0.3412,\n",
      "        -0.0794,  0.3524,  0.1882, -0.0336, -0.2958, -0.2715, -0.0417, -0.0815,\n",
      "         0.1595, -0.2941, -0.0761,  0.2392, -0.1874,  0.0783,  0.0819, -0.1737],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "segundo vector: tensor([[ 0.1164,  0.2900, -0.0291, -0.0216,  0.2039,  0.1715, -0.2000,  0.1696],\n",
      "        [-0.0674,  0.2430, -0.3349,  0.3140,  0.3342,  0.2254,  0.0340,  0.0556],\n",
      "        [-0.0453,  0.1167,  0.2998,  0.0317,  0.1979, -0.3292,  0.0044, -0.2794],\n",
      "        [-0.2603,  0.0763, -0.0107,  0.0302, -0.2064,  0.0159, -0.1453,  0.0352],\n",
      "        [ 0.3440, -0.3510, -0.1371,  0.0280,  0.2001,  0.2703, -0.2787, -0.0082],\n",
      "        [-0.2815, -0.2875,  0.1395, -0.1039,  0.1308, -0.2473, -0.2474,  0.0605],\n",
      "        [ 0.1759, -0.1858, -0.0424, -0.0421, -0.0149,  0.0702, -0.0969,  0.2800],\n",
      "        [ 0.0935, -0.2574, -0.2462, -0.2338, -0.1046, -0.1525, -0.0649,  0.3412],\n",
      "        [-0.0794,  0.3524,  0.1882, -0.0336, -0.2958, -0.2715, -0.0417, -0.0815],\n",
      "        [ 0.1595, -0.2941, -0.0761,  0.2392, -0.1874,  0.0783,  0.0819, -0.1737]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "shape: torch.Size([10])\n",
      "n_dim: 90 p_partida: 80\n",
      "primer vector: tensor([-0.2005, -0.3056, -0.1821,  0.3338, -0.1582,  0.2512, -0.2526,  0.0524,\n",
      "         0.0173,  0.2523], grad_fn=<SliceBackward0>)\n",
      "segundo vector: tensor([-0.2005, -0.3056, -0.1821,  0.3338, -0.1582,  0.2512, -0.2526,  0.0524,\n",
      "         0.0173,  0.2523], grad_fn=<ViewBackward0>)\n",
      "shape: torch.Size([10, 10])\n",
      "n_dim: 190 p_partida: 90\n",
      "primer vector: tensor([ 0.1449, -0.2090, -0.2162,  0.1793, -0.2893, -0.1474,  0.1383,  0.0249,\n",
      "        -0.1056, -0.1875, -0.3007, -0.0385,  0.2991,  0.2916, -0.1588, -0.2329,\n",
      "         0.2641,  0.2741, -0.0302, -0.0284, -0.0404,  0.0659, -0.2196, -0.0120,\n",
      "         0.1453,  0.0695, -0.1567,  0.3010,  0.0945, -0.2559,  0.1963, -0.1739,\n",
      "        -0.0460,  0.0196,  0.2911, -0.3113,  0.0397,  0.3139,  0.1651,  0.1064,\n",
      "         0.2641,  0.1578,  0.1838, -0.1721,  0.1919,  0.2732, -0.1908, -0.0848,\n",
      "         0.0570,  0.2272, -0.0238,  0.1685, -0.0065, -0.1032,  0.1946, -0.0725,\n",
      "        -0.1192, -0.1529, -0.2196, -0.0950, -0.0615, -0.2107,  0.2815, -0.2782,\n",
      "        -0.0987, -0.1073,  0.0206,  0.0023,  0.1604,  0.2273, -0.0382, -0.1435,\n",
      "        -0.2561,  0.0469,  0.2345,  0.2261,  0.2341, -0.0960, -0.2750, -0.2358,\n",
      "        -0.2644, -0.2143, -0.2109, -0.0680,  0.2826,  0.0527, -0.0117, -0.2976,\n",
      "         0.0293,  0.2111,  0.0903,  0.2127, -0.2531, -0.2827, -0.2683, -0.2393,\n",
      "        -0.1188, -0.0653,  0.0495, -0.1903], grad_fn=<SliceBackward0>)\n",
      "segundo vector: tensor([[ 0.1449, -0.2090, -0.2162,  0.1793, -0.2893, -0.1474,  0.1383,  0.0249,\n",
      "         -0.1056, -0.1875],\n",
      "        [-0.3007, -0.0385,  0.2991,  0.2916, -0.1588, -0.2329,  0.2641,  0.2741,\n",
      "         -0.0302, -0.0284],\n",
      "        [-0.0404,  0.0659, -0.2196, -0.0120,  0.1453,  0.0695, -0.1567,  0.3010,\n",
      "          0.0945, -0.2559],\n",
      "        [ 0.1963, -0.1739, -0.0460,  0.0196,  0.2911, -0.3113,  0.0397,  0.3139,\n",
      "          0.1651,  0.1064],\n",
      "        [ 0.2641,  0.1578,  0.1838, -0.1721,  0.1919,  0.2732, -0.1908, -0.0848,\n",
      "          0.0570,  0.2272],\n",
      "        [-0.0238,  0.1685, -0.0065, -0.1032,  0.1946, -0.0725, -0.1192, -0.1529,\n",
      "         -0.2196, -0.0950],\n",
      "        [-0.0615, -0.2107,  0.2815, -0.2782, -0.0987, -0.1073,  0.0206,  0.0023,\n",
      "          0.1604,  0.2273],\n",
      "        [-0.0382, -0.1435, -0.2561,  0.0469,  0.2345,  0.2261,  0.2341, -0.0960,\n",
      "         -0.2750, -0.2358],\n",
      "        [-0.2644, -0.2143, -0.2109, -0.0680,  0.2826,  0.0527, -0.0117, -0.2976,\n",
      "          0.0293,  0.2111],\n",
      "        [ 0.0903,  0.2127, -0.2531, -0.2827, -0.2683, -0.2393, -0.1188, -0.0653,\n",
      "          0.0495, -0.1903]], grad_fn=<ViewBackward0>)\n",
      "shape: torch.Size([10])\n",
      "n_dim: 200 p_partida: 190\n",
      "primer vector: tensor([-0.0840,  0.1575, -0.0572, -0.1894,  0.1768, -0.0575,  0.0186,  0.1114,\n",
      "        -0.1341, -0.0196], grad_fn=<SliceBackward0>)\n",
      "segundo vector: tensor([-0.0840,  0.1575, -0.0572, -0.1894,  0.1768, -0.0575,  0.0186,  0.1114,\n",
      "        -0.1341, -0.0196], grad_fn=<ViewBackward0>)\n",
      "shape: torch.Size([1, 10])\n",
      "n_dim: 210 p_partida: 200\n",
      "primer vector: tensor([-0.2266,  0.1616, -0.3016, -0.2089,  0.2738,  0.1296, -0.0515, -0.0846,\n",
      "        -0.1315, -0.0132], grad_fn=<SliceBackward0>)\n",
      "segundo vector: tensor([[-0.2266,  0.1616, -0.3016, -0.2089,  0.2738,  0.1296, -0.0515, -0.0846,\n",
      "         -0.1315, -0.0132]], grad_fn=<ViewBackward0>)\n",
      "shape: torch.Size([1])\n",
      "n_dim: 211 p_partida: 210\n",
      "primer vector: tensor([-0.2373], grad_fn=<SliceBackward0>)\n",
      "segundo vector: tensor([-0.2373], grad_fn=<ViewBackward0>)\n",
      "tensor(0.0067, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "entrada = input\n",
    "#print(red.fc1.weight.data)\n",
    "#red.fc1.weight.data = torch.zeros((10,8))\n",
    "#print(red.fc1.weight.data)\n",
    "#print(torch.tensor([[1,2,3,4,5,6,7,8],[1,2,3,4,5,6,7,8]]))\n",
    "#print(red.fc2.weight.data)\n",
    "#print(red.fc3.weight.data)\n",
    "v = [_.view(-1) for _ in red.parameters()]\n",
    "#for i in v:\n",
    " #   print(i)\n",
    "v = torch.cat([_.view(-1) for _ in red.parameters()], dim = 0)#concatena los paremetros de la red en un solo vector unidimensional\n",
    "#print(v)\n",
    "p = calcula_perdida(v)\n",
    "#print(len(v))\n",
    "#p = calcula_perdida(v[0],v[1],v[2],v[3],v[4],v[5])\n",
    "#print(red(entrada))\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "shape: torch.Size([10, 8])\n",
      "n_dim: 80 p_partida: 0\n",
      "primer vector: tensor([ 0.1164,  0.2900, -0.0291, -0.0216,  0.2039,  0.1715, -0.2000,  0.1696,\n",
      "        -0.0674,  0.2430, -0.3349,  0.3140,  0.3342,  0.2254,  0.0340,  0.0556,\n",
      "        -0.0453,  0.1167,  0.2998,  0.0317,  0.1979, -0.3292,  0.0044, -0.2794,\n",
      "        -0.2603,  0.0763, -0.0107,  0.0302, -0.2064,  0.0159, -0.1453,  0.0352,\n",
      "         0.3440, -0.3510, -0.1371,  0.0280,  0.2001,  0.2703, -0.2787, -0.0082,\n",
      "        -0.2815, -0.2875,  0.1395, -0.1039,  0.1308, -0.2473, -0.2474,  0.0605,\n",
      "         0.1759, -0.1858, -0.0424, -0.0421, -0.0149,  0.0702, -0.0969,  0.2800,\n",
      "         0.0935, -0.2574, -0.2462, -0.2338, -0.1046, -0.1525, -0.0649,  0.3412,\n",
      "        -0.0794,  0.3524,  0.1882, -0.0336, -0.2958, -0.2715, -0.0417, -0.0815,\n",
      "         0.1595, -0.2941, -0.0761,  0.2392, -0.1874,  0.0783,  0.0819, -0.1737],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "segundo vector: tensor([[ 0.1164,  0.2900, -0.0291, -0.0216,  0.2039,  0.1715, -0.2000,  0.1696],\n",
      "        [-0.0674,  0.2430, -0.3349,  0.3140,  0.3342,  0.2254,  0.0340,  0.0556],\n",
      "        [-0.0453,  0.1167,  0.2998,  0.0317,  0.1979, -0.3292,  0.0044, -0.2794],\n",
      "        [-0.2603,  0.0763, -0.0107,  0.0302, -0.2064,  0.0159, -0.1453,  0.0352],\n",
      "        [ 0.3440, -0.3510, -0.1371,  0.0280,  0.2001,  0.2703, -0.2787, -0.0082],\n",
      "        [-0.2815, -0.2875,  0.1395, -0.1039,  0.1308, -0.2473, -0.2474,  0.0605],\n",
      "        [ 0.1759, -0.1858, -0.0424, -0.0421, -0.0149,  0.0702, -0.0969,  0.2800],\n",
      "        [ 0.0935, -0.2574, -0.2462, -0.2338, -0.1046, -0.1525, -0.0649,  0.3412],\n",
      "        [-0.0794,  0.3524,  0.1882, -0.0336, -0.2958, -0.2715, -0.0417, -0.0815],\n",
      "        [ 0.1595, -0.2941, -0.0761,  0.2392, -0.1874,  0.0783,  0.0819, -0.1737]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "shape: torch.Size([10])\n",
      "n_dim: 90 p_partida: 80\n",
      "primer vector: tensor([-0.2005, -0.3056, -0.1821,  0.3338, -0.1582,  0.2512, -0.2526,  0.0524,\n",
      "         0.0173,  0.2523], grad_fn=<SliceBackward0>)\n",
      "segundo vector: tensor([-0.2005, -0.3056, -0.1821,  0.3338, -0.1582,  0.2512, -0.2526,  0.0524,\n",
      "         0.0173,  0.2523], grad_fn=<ViewBackward0>)\n",
      "shape: torch.Size([10, 10])\n",
      "n_dim: 190 p_partida: 90\n",
      "primer vector: tensor([ 0.1449, -0.2090, -0.2162,  0.1793, -0.2893, -0.1474,  0.1383,  0.0249,\n",
      "        -0.1056, -0.1875, -0.3007, -0.0385,  0.2991,  0.2916, -0.1588, -0.2329,\n",
      "         0.2641,  0.2741, -0.0302, -0.0284, -0.0404,  0.0659, -0.2196, -0.0120,\n",
      "         0.1453,  0.0695, -0.1567,  0.3010,  0.0945, -0.2559,  0.1963, -0.1739,\n",
      "        -0.0460,  0.0196,  0.2911, -0.3113,  0.0397,  0.3139,  0.1651,  0.1064,\n",
      "         0.2641,  0.1578,  0.1838, -0.1721,  0.1919,  0.2732, -0.1908, -0.0848,\n",
      "         0.0570,  0.2272, -0.0238,  0.1685, -0.0065, -0.1032,  0.1946, -0.0725,\n",
      "        -0.1192, -0.1529, -0.2196, -0.0950, -0.0615, -0.2107,  0.2815, -0.2782,\n",
      "        -0.0987, -0.1073,  0.0206,  0.0023,  0.1604,  0.2273, -0.0382, -0.1435,\n",
      "        -0.2561,  0.0469,  0.2345,  0.2261,  0.2341, -0.0960, -0.2750, -0.2358,\n",
      "        -0.2644, -0.2143, -0.2109, -0.0680,  0.2826,  0.0527, -0.0117, -0.2976,\n",
      "         0.0293,  0.2111,  0.0903,  0.2127, -0.2531, -0.2827, -0.2683, -0.2393,\n",
      "        -0.1188, -0.0653,  0.0495, -0.1903], grad_fn=<SliceBackward0>)\n",
      "segundo vector: tensor([[ 0.1449, -0.2090, -0.2162,  0.1793, -0.2893, -0.1474,  0.1383,  0.0249,\n",
      "         -0.1056, -0.1875],\n",
      "        [-0.3007, -0.0385,  0.2991,  0.2916, -0.1588, -0.2329,  0.2641,  0.2741,\n",
      "         -0.0302, -0.0284],\n",
      "        [-0.0404,  0.0659, -0.2196, -0.0120,  0.1453,  0.0695, -0.1567,  0.3010,\n",
      "          0.0945, -0.2559],\n",
      "        [ 0.1963, -0.1739, -0.0460,  0.0196,  0.2911, -0.3113,  0.0397,  0.3139,\n",
      "          0.1651,  0.1064],\n",
      "        [ 0.2641,  0.1578,  0.1838, -0.1721,  0.1919,  0.2732, -0.1908, -0.0848,\n",
      "          0.0570,  0.2272],\n",
      "        [-0.0238,  0.1685, -0.0065, -0.1032,  0.1946, -0.0725, -0.1192, -0.1529,\n",
      "         -0.2196, -0.0950],\n",
      "        [-0.0615, -0.2107,  0.2815, -0.2782, -0.0987, -0.1073,  0.0206,  0.0023,\n",
      "          0.1604,  0.2273],\n",
      "        [-0.0382, -0.1435, -0.2561,  0.0469,  0.2345,  0.2261,  0.2341, -0.0960,\n",
      "         -0.2750, -0.2358],\n",
      "        [-0.2644, -0.2143, -0.2109, -0.0680,  0.2826,  0.0527, -0.0117, -0.2976,\n",
      "          0.0293,  0.2111],\n",
      "        [ 0.0903,  0.2127, -0.2531, -0.2827, -0.2683, -0.2393, -0.1188, -0.0653,\n",
      "          0.0495, -0.1903]], grad_fn=<ViewBackward0>)\n",
      "shape: torch.Size([10])\n",
      "n_dim: 200 p_partida: 190\n",
      "primer vector: tensor([-0.0840,  0.1575, -0.0572, -0.1894,  0.1768, -0.0575,  0.0186,  0.1114,\n",
      "        -0.1341, -0.0196], grad_fn=<SliceBackward0>)\n",
      "segundo vector: tensor([-0.0840,  0.1575, -0.0572, -0.1894,  0.1768, -0.0575,  0.0186,  0.1114,\n",
      "        -0.1341, -0.0196], grad_fn=<ViewBackward0>)\n",
      "shape: torch.Size([1, 10])\n",
      "n_dim: 210 p_partida: 200\n",
      "primer vector: tensor([-0.2266,  0.1616, -0.3016, -0.2089,  0.2738,  0.1296, -0.0515, -0.0846,\n",
      "        -0.1315, -0.0132], grad_fn=<SliceBackward0>)\n",
      "segundo vector: tensor([[-0.2266,  0.1616, -0.3016, -0.2089,  0.2738,  0.1296, -0.0515, -0.0846,\n",
      "         -0.1315, -0.0132]], grad_fn=<ViewBackward0>)\n",
      "shape: torch.Size([1])\n",
      "n_dim: 211 p_partida: 210\n",
      "primer vector: tensor([-0.2373], grad_fn=<SliceBackward0>)\n",
      "segundo vector: tensor([-0.2373], grad_fn=<ViewBackward0>)\n",
      "211\n",
      "2\n",
      "torch.Size([211, 211])\n"
     ]
    }
   ],
   "source": [
    "print(v.dim())\n",
    "# class Net(Module):\n",
    "#     def __init__(self, h, w):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.c1 = torch.nn.Conv2d(1, 32, 3, 1, 1)\n",
    "#         self.f2 = torch.nn.Linear(32 * h * w, 5)\n",
    "\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.c1(x)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.f2(x)\n",
    "#         return x\n",
    "\n",
    "# def haha(a, b, c, d):\n",
    "#     p = [a.view(32, 1, 3, 3), b, c.view(5, 32 * 12 * 12), d]\n",
    "#     x = torch.randn(size=[8, 1, 12, 12], dtype=torch.float32)\n",
    "#     y = torch.randint(0, 5, [8])\n",
    "#     x = F.conv2d(x, p[0], p[1], 1, 1)\n",
    "#     x = x.view(x.size(0), -1)\n",
    "#     x = F.linear(x, p[2], p[3])\n",
    "#     loss = F.cross_entropy(x, y)\n",
    "#     return loss\n",
    "h = torch.autograd.functional.hessian(calcula_perdida, v)\n",
    "#print(len(list(a)))\n",
    "print(len(list(a)[0]))\n",
    "print(h.dim())\n",
    "print(h.shape)\n",
    "\n",
    "#print(h = torch.autograd.functional.hessian(haha, tuple([_.view(-1) for _ in net.parameters()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: torch.Size([10, 8])\n",
      "n_dim: 80 p_partida: 0\n",
      "primer vector: tensor([ 0.1164,  0.2900, -0.0291, -0.0216,  0.2039,  0.1715, -0.2000,  0.1696,\n",
      "        -0.0674,  0.2430, -0.3349,  0.3140,  0.3342,  0.2254,  0.0340,  0.0556,\n",
      "        -0.0453,  0.1167,  0.2998,  0.0317,  0.1979, -0.3292,  0.0044, -0.2794,\n",
      "        -0.2603,  0.0763, -0.0107,  0.0302, -0.2064,  0.0159, -0.1453,  0.0352,\n",
      "         0.3440, -0.3510, -0.1371,  0.0280,  0.2001,  0.2703, -0.2787, -0.0082,\n",
      "        -0.2815, -0.2875,  0.1395, -0.1039,  0.1308, -0.2473, -0.2474,  0.0605,\n",
      "         0.1759, -0.1858, -0.0424, -0.0421, -0.0149,  0.0702, -0.0969,  0.2800,\n",
      "         0.0935, -0.2574, -0.2462, -0.2338, -0.1046, -0.1525, -0.0649,  0.3412,\n",
      "        -0.0794,  0.3524,  0.1882, -0.0336, -0.2958, -0.2715, -0.0417, -0.0815,\n",
      "         0.1595, -0.2941, -0.0761,  0.2392, -0.1874,  0.0783,  0.0819, -0.1737],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "segundo vector: tensor([[ 0.1164,  0.2900, -0.0291, -0.0216,  0.2039,  0.1715, -0.2000,  0.1696],\n",
      "        [-0.0674,  0.2430, -0.3349,  0.3140,  0.3342,  0.2254,  0.0340,  0.0556],\n",
      "        [-0.0453,  0.1167,  0.2998,  0.0317,  0.1979, -0.3292,  0.0044, -0.2794],\n",
      "        [-0.2603,  0.0763, -0.0107,  0.0302, -0.2064,  0.0159, -0.1453,  0.0352],\n",
      "        [ 0.3440, -0.3510, -0.1371,  0.0280,  0.2001,  0.2703, -0.2787, -0.0082],\n",
      "        [-0.2815, -0.2875,  0.1395, -0.1039,  0.1308, -0.2473, -0.2474,  0.0605],\n",
      "        [ 0.1759, -0.1858, -0.0424, -0.0421, -0.0149,  0.0702, -0.0969,  0.2800],\n",
      "        [ 0.0935, -0.2574, -0.2462, -0.2338, -0.1046, -0.1525, -0.0649,  0.3412],\n",
      "        [-0.0794,  0.3524,  0.1882, -0.0336, -0.2958, -0.2715, -0.0417, -0.0815],\n",
      "        [ 0.1595, -0.2941, -0.0761,  0.2392, -0.1874,  0.0783,  0.0819, -0.1737]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "shape: torch.Size([10])\n",
      "n_dim: 90 p_partida: 80\n",
      "primer vector: tensor([-0.2005, -0.3056, -0.1821,  0.3338, -0.1582,  0.2512, -0.2526,  0.0524,\n",
      "         0.0173,  0.2523], grad_fn=<SliceBackward0>)\n",
      "segundo vector: tensor([-0.2005, -0.3056, -0.1821,  0.3338, -0.1582,  0.2512, -0.2526,  0.0524,\n",
      "         0.0173,  0.2523], grad_fn=<ViewBackward0>)\n",
      "shape: torch.Size([10, 10])\n",
      "n_dim: 190 p_partida: 90\n",
      "primer vector: tensor([ 0.1449, -0.2090, -0.2162,  0.1793, -0.2893, -0.1474,  0.1383,  0.0249,\n",
      "        -0.1056, -0.1875, -0.3007, -0.0385,  0.2991,  0.2916, -0.1588, -0.2329,\n",
      "         0.2641,  0.2741, -0.0302, -0.0284, -0.0404,  0.0659, -0.2196, -0.0120,\n",
      "         0.1453,  0.0695, -0.1567,  0.3010,  0.0945, -0.2559,  0.1963, -0.1739,\n",
      "        -0.0460,  0.0196,  0.2911, -0.3113,  0.0397,  0.3139,  0.1651,  0.1064,\n",
      "         0.2641,  0.1578,  0.1838, -0.1721,  0.1919,  0.2732, -0.1908, -0.0848,\n",
      "         0.0570,  0.2272, -0.0238,  0.1685, -0.0065, -0.1032,  0.1946, -0.0725,\n",
      "        -0.1192, -0.1529, -0.2196, -0.0950, -0.0615, -0.2107,  0.2815, -0.2782,\n",
      "        -0.0987, -0.1073,  0.0206,  0.0023,  0.1604,  0.2273, -0.0382, -0.1435,\n",
      "        -0.2561,  0.0469,  0.2345,  0.2261,  0.2341, -0.0960, -0.2750, -0.2358,\n",
      "        -0.2644, -0.2143, -0.2109, -0.0680,  0.2826,  0.0527, -0.0117, -0.2976,\n",
      "         0.0293,  0.2111,  0.0903,  0.2127, -0.2531, -0.2827, -0.2683, -0.2393,\n",
      "        -0.1188, -0.0653,  0.0495, -0.1903], grad_fn=<SliceBackward0>)\n",
      "segundo vector: tensor([[ 0.1449, -0.2090, -0.2162,  0.1793, -0.2893, -0.1474,  0.1383,  0.0249,\n",
      "         -0.1056, -0.1875],\n",
      "        [-0.3007, -0.0385,  0.2991,  0.2916, -0.1588, -0.2329,  0.2641,  0.2741,\n",
      "         -0.0302, -0.0284],\n",
      "        [-0.0404,  0.0659, -0.2196, -0.0120,  0.1453,  0.0695, -0.1567,  0.3010,\n",
      "          0.0945, -0.2559],\n",
      "        [ 0.1963, -0.1739, -0.0460,  0.0196,  0.2911, -0.3113,  0.0397,  0.3139,\n",
      "          0.1651,  0.1064],\n",
      "        [ 0.2641,  0.1578,  0.1838, -0.1721,  0.1919,  0.2732, -0.1908, -0.0848,\n",
      "          0.0570,  0.2272],\n",
      "        [-0.0238,  0.1685, -0.0065, -0.1032,  0.1946, -0.0725, -0.1192, -0.1529,\n",
      "         -0.2196, -0.0950],\n",
      "        [-0.0615, -0.2107,  0.2815, -0.2782, -0.0987, -0.1073,  0.0206,  0.0023,\n",
      "          0.1604,  0.2273],\n",
      "        [-0.0382, -0.1435, -0.2561,  0.0469,  0.2345,  0.2261,  0.2341, -0.0960,\n",
      "         -0.2750, -0.2358],\n",
      "        [-0.2644, -0.2143, -0.2109, -0.0680,  0.2826,  0.0527, -0.0117, -0.2976,\n",
      "          0.0293,  0.2111],\n",
      "        [ 0.0903,  0.2127, -0.2531, -0.2827, -0.2683, -0.2393, -0.1188, -0.0653,\n",
      "          0.0495, -0.1903]], grad_fn=<ViewBackward0>)\n",
      "shape: torch.Size([10])\n",
      "n_dim: 200 p_partida: 190\n",
      "primer vector: tensor([-0.0840,  0.1575, -0.0572, -0.1894,  0.1768, -0.0575,  0.0186,  0.1114,\n",
      "        -0.1341, -0.0196], grad_fn=<SliceBackward0>)\n",
      "segundo vector: tensor([-0.0840,  0.1575, -0.0572, -0.1894,  0.1768, -0.0575,  0.0186,  0.1114,\n",
      "        -0.1341, -0.0196], grad_fn=<ViewBackward0>)\n",
      "shape: torch.Size([1, 10])\n",
      "n_dim: 210 p_partida: 200\n",
      "primer vector: tensor([-0.2266,  0.1616, -0.3016, -0.2089,  0.2738,  0.1296, -0.0515, -0.0846,\n",
      "        -0.1315, -0.0132], grad_fn=<SliceBackward0>)\n",
      "segundo vector: tensor([[-0.2266,  0.1616, -0.3016, -0.2089,  0.2738,  0.1296, -0.0515, -0.0846,\n",
      "         -0.1315, -0.0132]], grad_fn=<ViewBackward0>)\n",
      "shape: torch.Size([1])\n",
      "n_dim: 211 p_partida: 210\n",
      "primer vector: tensor([-0.2373], grad_fn=<SliceBackward0>)\n",
      "segundo vector: tensor([-0.2373], grad_fn=<ViewBackward0>)\n",
      "torch.Size([211])\n"
     ]
    }
   ],
   "source": [
    "grad_f = torch.autograd.grad(calcula_perdida(v), v)[0]\n",
    "print(grad_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.7074e-03, -2.8812e-05, -6.4827e-05,  ...,  1.5211e-02,\n",
      "         -1.3658e-02,  1.5364e-02],\n",
      "        [-1.4406e-05,  3.3715e-03, -1.2965e-04,  ...,  3.0422e-02,\n",
      "         -2.7316e-02,  3.0727e-02],\n",
      "        [-2.1609e-05, -8.6436e-05,  4.9493e-03,  ...,  4.5633e-02,\n",
      "         -4.0974e-02,  4.6090e-02],\n",
      "        ...,\n",
      "        [ 1.3558e-05,  5.4230e-05,  1.2202e-04,  ...,  1.4715e-01,\n",
      "         -1.4581e-01,  6.5804e-02],\n",
      "        [ 5.4495e-06,  2.1798e-05,  4.9046e-05,  ...,  6.5275e-02,\n",
      "         -2.5756e-02,  2.7539e-02],\n",
      "        [-1.6037e-05, -6.4148e-05, -1.4433e-04,  ..., -7.7068e-02,\n",
      "          7.2046e-02, -3.5115e-01]])\n"
     ]
    }
   ],
   "source": [
    "Î» = 0.1\n",
    "r = -torch.inverse(h+Î»*torch.eye(211))*grad_f\n",
    "print(r)\n",
    "#-torch.inverse(h+Î»*torch.eye(211))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2425, -2.0265, -0.7171,  0.8465,  1.1031,  0.8568, -0.5701,  0.4621,\n",
      "         -1.8919,  1.8212,  0.2178, -0.4279, -0.3306, -2.0242,  0.1793, -0.6342,\n",
      "          0.5306, -0.3990, -1.4124, -0.0128, -1.2783, -0.7999, -0.9947, -0.0745,\n",
      "          0.5407,  1.7440, -0.6248,  0.2478,  0.1415,  1.3523, -0.6399, -1.1641,\n",
      "         -0.7785, -1.3825, -0.1487, -1.1846, -1.9734,  0.9720,  0.8780,  0.1155,\n",
      "          1.0394,  1.2352,  1.3094,  0.6719, -1.3239, -0.2211, -1.4850, -0.1578,\n",
      "         -1.3046, -1.6374,  0.7868,  1.4017,  0.0231,  0.7787, -0.9604,  0.5887,\n",
      "          0.6013, -0.5279,  1.2014,  0.2648, -2.1216, -0.2071,  0.0888, -2.6840,\n",
      "          0.7722, -0.1971,  1.9545, -0.2919, -0.4544, -0.3679, -1.6071, -0.4358,\n",
      "          0.1476,  1.1260, -0.7250, -1.1016, -0.7317,  0.0610,  0.5086, -0.1533]])\n",
      "tensor([[ 1.2425, -2.0265, -0.7171,  0.8465,  1.1031,  0.8568, -0.5701,  0.4621],\n",
      "        [-1.8919,  1.8212,  0.2178, -0.4279, -0.3306, -2.0242,  0.1793, -0.6342],\n",
      "        [ 0.5306, -0.3990, -1.4124, -0.0128, -1.2783, -0.7999, -0.9947, -0.0745],\n",
      "        [ 0.5407,  1.7440, -0.6248,  0.2478,  0.1415,  1.3523, -0.6399, -1.1641],\n",
      "        [-0.7785, -1.3825, -0.1487, -1.1846, -1.9734,  0.9720,  0.8780,  0.1155],\n",
      "        [ 1.0394,  1.2352,  1.3094,  0.6719, -1.3239, -0.2211, -1.4850, -0.1578],\n",
      "        [-1.3046, -1.6374,  0.7868,  1.4017,  0.0231,  0.7787, -0.9604,  0.5887],\n",
      "        [ 0.6013, -0.5279,  1.2014,  0.2648, -2.1216, -0.2071,  0.0888, -2.6840],\n",
      "        [ 0.7722, -0.1971,  1.9545, -0.2919, -0.4544, -0.3679, -1.6071, -0.4358],\n",
      "        [ 0.1476,  1.1260, -0.7250, -1.1016, -0.7317,  0.0610,  0.5086, -0.1533]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = torch.randn(1,80)\n",
    "print(x)\n",
    "y = []\n",
    "for i in red.parameters():\n",
    "    y.append(i.shape)\n",
    "#x = x.view(y[0])\n",
    "print(x.view(y[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor existente:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "Tensor ajustado con la misma forma que el otro tensor:\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Supongamos que tienes dos tensores con diferentes formas\n",
    "tensor_existente = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "otro_tensor = torch.tensor([[7, 8], [9, 10],[11,12]])\n",
    "\n",
    "# ObtÃ©n la forma del otro tensor\n",
    "forma_deseada = otro_tensor.shape\n",
    "\n",
    "# Ajusta la forma del tensor existente para que coincida con la forma deseada\n",
    "tensor_ajustado = tensor_existente.view(forma_deseada)\n",
    "\n",
    "# Alternativamente, puedes usar reshape\n",
    "# tensor_ajustado = tensor_existente.reshape(forma_deseada)\n",
    "\n",
    "print(\"Tensor existente:\")\n",
    "print(tensor_existente)\n",
    "\n",
    "print(\"Tensor ajustado con la misma forma que el otro tensor:\")\n",
    "print(tensor_ajustado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 4.],\n",
      "        [1., 3.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[12.,  0.],\n",
       "          [ 0.,  0.]],\n",
       "\n",
       "         [[ 0., 24.],\n",
       "          [ 0.,  0.]]],\n",
       "\n",
       "\n",
       "        [[[ 0.,  0.],\n",
       "          [ 6.,  0.]],\n",
       "\n",
       "         [[ 0.,  0.],\n",
       "          [ 0., 18.]]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pow_reducer(x):\n",
    "    x=x.view(-1)\n",
    "    return x.pow(3).sum()\n",
    "inputs = torch.Tensor([[2,4],[1,3]])\n",
    "print(inputs)\n",
    "torch.autograd.functional.hessian(pow_reducer, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 4.],\n",
      "        [1., 3.]])\n",
      "tensor([2., 4., 1., 3.])\n"
     ]
    }
   ],
   "source": [
    "print(torch.Tensor([[2,4],[1,3]]))\n",
    "print(torch.Tensor([[2,4],[1,3]]).view(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.)\n"
     ]
    }
   ],
   "source": [
    "def pow_r(x):\n",
    "    return x.pow(3).sum()\n",
    "\n",
    "print(pow_r(torch.Tensor([2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([288])\n",
      "torch.Size([32, 1, 3, 3])\n",
      "tensor([[[[ 5.7037e-01, -1.6220e+00,  2.2039e-01,  ..., -1.8979e+00,\n",
      "           -1.5416e+00, -5.3563e-01],\n",
      "          [-1.1947e+00,  2.2494e-01,  1.4591e-01,  ...,  4.6369e-01,\n",
      "           -1.0561e+00, -8.1643e-01],\n",
      "          [-7.8351e-01, -6.7065e-01,  6.7817e-01,  ...,  2.3470e-01,\n",
      "            7.0937e-02,  1.5931e+00],\n",
      "          ...,\n",
      "          [-7.5470e-01, -1.5926e-01,  5.1093e-01,  ...,  6.1051e-02,\n",
      "            1.3519e-01,  4.6800e-01],\n",
      "          [ 2.7908e-01,  7.1455e-01,  2.5397e-01,  ..., -8.8045e-01,\n",
      "            9.4286e-01,  2.1376e-01],\n",
      "          [ 2.5175e+00, -4.4433e-01, -2.6354e-01,  ..., -1.1572e+00,\n",
      "           -1.5571e+00,  9.0103e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.0976e-01, -5.2877e-01, -6.8055e-01,  ...,  1.1446e+00,\n",
      "           -1.6650e-01, -3.5450e-01],\n",
      "          [-8.4889e-02,  3.4633e-01,  4.9917e-01,  ...,  1.4496e+00,\n",
      "            3.3475e+00,  1.2317e+00],\n",
      "          [-4.7402e-01,  5.1185e-01, -5.0354e-01,  ..., -7.3297e-01,\n",
      "           -7.2453e-01, -1.3287e+00],\n",
      "          ...,\n",
      "          [-1.4223e-01, -1.1155e+00,  1.8489e+00,  ...,  2.3714e+00,\n",
      "           -3.1327e-01, -3.4378e-02],\n",
      "          [ 1.1552e-01, -3.0698e-01,  4.6685e-01,  ...,  1.4609e+00,\n",
      "           -1.2338e+00, -5.8183e-01],\n",
      "          [ 7.2018e-02,  1.9511e+00,  1.9696e+00,  ..., -5.5597e-01,\n",
      "            6.3940e-02,  2.3178e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.2715e-01, -1.2204e+00, -1.6185e-01,  ..., -1.1006e+00,\n",
      "            6.0621e-01, -1.7617e+00],\n",
      "          [-2.0520e+00, -6.8733e-01, -1.4331e+00,  ..., -7.0217e-01,\n",
      "            1.4230e-01,  6.2097e-01],\n",
      "          [-8.8488e-02,  1.8313e+00,  3.2471e-01,  ...,  1.1762e+00,\n",
      "            1.1671e+00, -2.8650e-01],\n",
      "          ...,\n",
      "          [ 3.2584e-01, -3.7588e-01, -1.0256e+00,  ..., -1.3826e+00,\n",
      "            1.6289e+00, -1.0193e+00],\n",
      "          [-2.6089e-01,  4.5512e-01,  1.5818e+00,  ...,  6.0732e-01,\n",
      "           -1.2835e-01, -1.1747e-02],\n",
      "          [ 1.2940e+00,  7.4410e-01, -7.7828e-01,  ..., -6.8190e-01,\n",
      "           -4.1177e-01, -6.0937e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 4.4485e-01,  2.4440e+00,  1.4313e+00,  ..., -1.0498e-01,\n",
      "            7.1545e-01,  4.8124e-01],\n",
      "          [-1.0152e+00, -1.3850e+00, -1.3874e+00,  ...,  1.7690e-02,\n",
      "            1.4358e+00, -1.4626e+00],\n",
      "          [-5.0400e-01,  2.3277e-01, -2.1110e-03,  ..., -1.6244e+00,\n",
      "           -2.2012e+00, -1.0445e+00],\n",
      "          ...,\n",
      "          [-6.1248e-02, -6.6758e-01,  1.6493e-01,  ...,  5.3174e-02,\n",
      "            3.9225e-01, -1.2550e-01],\n",
      "          [ 1.8962e-01,  3.4854e-02, -1.6736e+00,  ..., -2.3647e+00,\n",
      "           -9.1815e-01,  1.5209e+00],\n",
      "          [-7.0027e-01, -2.6969e-01,  5.7925e-01,  ...,  2.0332e+00,\n",
      "            2.0634e-01,  5.4550e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1318e+00, -7.7687e-02,  1.0377e+00,  ...,  1.1975e+00,\n",
      "           -4.9791e-01,  1.0329e+00],\n",
      "          [ 2.1216e+00, -4.0569e-01, -7.9207e-01,  ...,  7.9910e-01,\n",
      "           -3.1265e+00, -3.2323e-01],\n",
      "          [ 2.1302e+00,  9.0183e-01,  7.4798e-01,  ...,  6.1898e-02,\n",
      "            5.2014e-01,  2.7977e-01],\n",
      "          ...,\n",
      "          [ 1.0473e+00, -7.3370e-01,  6.6952e-01,  ..., -3.8294e-01,\n",
      "           -5.3100e-01,  4.7866e-01],\n",
      "          [ 2.1246e-01, -2.3934e+00, -1.1721e+00,  ...,  6.4552e-01,\n",
      "            5.4724e-04, -1.1390e+00],\n",
      "          [-3.9477e-01, -7.4782e-01,  1.1723e+00,  ...,  1.6826e-01,\n",
      "           -1.4998e-01,  7.8865e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.9746e-02, -1.1213e+00,  1.3199e-01,  ...,  2.9847e-02,\n",
      "            1.3490e+00, -4.4636e-01],\n",
      "          [ 4.8617e-01, -1.5921e+00,  4.0803e-01,  ...,  7.8890e-01,\n",
      "            2.2076e-02,  5.2207e-01],\n",
      "          [-4.0674e-01, -1.0326e+00,  1.9995e+00,  ..., -1.5290e-01,\n",
      "           -9.1367e-01,  1.1339e+00],\n",
      "          ...,\n",
      "          [ 9.9055e-01, -9.6804e-01, -9.2159e-01,  ...,  6.9404e-01,\n",
      "           -1.0285e+00, -2.9458e-01],\n",
      "          [ 1.5698e-01, -4.5820e-01, -1.0950e+00,  ...,  7.7007e-01,\n",
      "           -7.2994e-01,  5.0897e-01],\n",
      "          [-8.9344e-01, -3.3630e-01,  5.8343e-01,  ...,  8.4738e-01,\n",
      "            5.2376e-01,  1.3382e+00]]]])\n"
     ]
    }
   ],
   "source": [
    "net = Net(12, 12)\n",
    "\n",
    "print([i.view(-1) for i in net.parameters()][0].size())\n",
    "print([i for i in net.parameters()][0].size())\n",
    "\n",
    "t = tuple([_.view(-1) for _ in net.parameters()])\n",
    "\n",
    "print(torch.randn(size=[8, 1, 12, 12], dtype=torch.float32))\n",
    "#print(net)\n",
    "#print(len(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.1217, -0.0818, -0.1036,  0.3002,  0.1637, -0.1048,  0.2623,  0.2988,\n",
       "         -0.2624,  0.1128, -0.0690,  0.2537,  0.3321, -0.1400,  0.0543,  0.3223,\n",
       "         -0.0853, -0.0464,  0.0765, -0.0377, -0.2048,  0.3262,  0.0286, -0.0862,\n",
       "         -0.1481, -0.1255,  0.3250,  0.2934,  0.1509,  0.2734,  0.0445, -0.0381,\n",
       "         -0.1065,  0.0958,  0.2534,  0.0984,  0.0806,  0.0021,  0.2244, -0.1927,\n",
       "         -0.1488,  0.0710, -0.0175, -0.1059,  0.1912,  0.2350,  0.1904, -0.0048,\n",
       "         -0.1818,  0.1958, -0.0474,  0.0634, -0.2812, -0.1592, -0.1451, -0.0265,\n",
       "         -0.0242, -0.2434, -0.0942,  0.1893,  0.1298, -0.2936,  0.1334, -0.1612,\n",
       "          0.0079,  0.2406,  0.1352,  0.2592, -0.2827,  0.2473, -0.2747, -0.1128,\n",
       "         -0.0998,  0.3259,  0.2503,  0.0906, -0.0950, -0.1080,  0.0297,  0.2630,\n",
       "         -0.2460,  0.1935, -0.1856, -0.0456,  0.2585,  0.1985,  0.0689,  0.0778,\n",
       "         -0.0363, -0.0353,  0.2892,  0.2555, -0.0505, -0.2110, -0.1705,  0.1030,\n",
       "          0.2529,  0.0185,  0.0485, -0.1795,  0.1639, -0.3008, -0.1935, -0.2713,\n",
       "          0.1071, -0.2466,  0.0422,  0.1933,  0.0058,  0.2059,  0.3108,  0.2695,\n",
       "          0.1862,  0.0797, -0.0112,  0.1105, -0.1106, -0.2765, -0.2605,  0.1255,\n",
       "          0.0402, -0.3215, -0.1157, -0.1966,  0.3118,  0.0421,  0.0188,  0.2827,\n",
       "          0.2312,  0.0485,  0.2953, -0.1070, -0.0319, -0.0194, -0.1340,  0.0024,\n",
       "         -0.2228, -0.0416, -0.0399,  0.0896, -0.2741, -0.2214, -0.2999,  0.2858,\n",
       "         -0.1669, -0.1833, -0.0302, -0.0772,  0.2814, -0.2565, -0.2829,  0.0663,\n",
       "          0.2491,  0.0690, -0.2860,  0.2956,  0.0307,  0.2245, -0.2572,  0.0202,\n",
       "          0.0174,  0.2418, -0.1094,  0.3029,  0.1425,  0.0220, -0.1467, -0.2488,\n",
       "         -0.1994,  0.2214,  0.0138,  0.1450, -0.2564,  0.3280,  0.1570, -0.3055,\n",
       "         -0.0092, -0.2222, -0.1479, -0.0349,  0.1145, -0.0199,  0.0052,  0.1054,\n",
       "          0.3116,  0.0851,  0.1335, -0.1922, -0.1916,  0.3270, -0.1165,  0.2670,\n",
       "         -0.0643,  0.2132,  0.0704, -0.1100,  0.3258,  0.1627,  0.1263, -0.2600,\n",
       "          0.2577, -0.0234,  0.0512, -0.0408,  0.2485, -0.1280, -0.0141,  0.0834,\n",
       "          0.2554,  0.0753, -0.2362,  0.0417, -0.2651, -0.1025, -0.2587, -0.0408,\n",
       "          0.0169, -0.1195, -0.1360, -0.1703,  0.2978, -0.3173,  0.0669, -0.1697,\n",
       "         -0.2744,  0.0740, -0.2940, -0.2598,  0.1986,  0.1098, -0.3284,  0.1598,\n",
       "          0.0116, -0.1984,  0.0832,  0.1805, -0.1728,  0.0038, -0.0558, -0.2293,\n",
       "         -0.1517, -0.2088,  0.0529,  0.2844, -0.0613, -0.1403, -0.1962,  0.1055,\n",
       "          0.0360, -0.1704, -0.0670,  0.0431, -0.2806, -0.1708,  0.2353, -0.2889,\n",
       "         -0.3243, -0.1232,  0.1697,  0.0240, -0.1193,  0.0067,  0.2837, -0.0198,\n",
       "          0.2742,  0.0372,  0.0035, -0.3144,  0.0271,  0.1148, -0.1179, -0.1012,\n",
       "          0.2023, -0.2614,  0.1127, -0.2585, -0.3027,  0.3325, -0.2529, -0.1727,\n",
       "         -0.2687,  0.0671, -0.0452,  0.2335,  0.1204, -0.3029,  0.2496, -0.0889],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " tensor([ 0.0794, -0.2921,  0.1823,  0.2880,  0.1459,  0.2777,  0.0961, -0.1391,\n",
       "         -0.3257,  0.3099,  0.0703,  0.3240, -0.2261,  0.2378, -0.1164,  0.3183,\n",
       "          0.2797, -0.0810,  0.2050, -0.1549,  0.1531, -0.1748, -0.0263,  0.1596,\n",
       "         -0.0933,  0.0402,  0.0489, -0.0312, -0.2019, -0.1270,  0.2065,  0.1488],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " tensor([-0.0092,  0.0014,  0.0098,  ...,  0.0132,  0.0144,  0.0008],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " tensor([-0.0073,  0.0050,  0.0146, -0.0023, -0.0086], grad_fn=<ViewBackward0>))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#h = torch.autograd.functional.hessian(haha, tuple([_.view(-1) for _ in net.parameters()]))\n",
    "tuple([_.view(-1) for _ in net.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'h' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6247/3045854989.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'h' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(type(h))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
