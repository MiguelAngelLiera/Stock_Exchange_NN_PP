{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miguel/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/miguel/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:1933: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.nn import Module\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(Module):\n",
    "    def __init__(self, h, w):\n",
    "        super(Net, self).__init__()\n",
    "        self.c1 = torch.nn.Conv2d(1, 32, 3, 1, 1)\n",
    "        self.f2 = torch.nn.Linear(32 * h * w, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c1(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.f2(x)\n",
    "        return x\n",
    "\n",
    "class NARNN(Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(NARNN, self).__init__()\n",
    "        #self.hidden_dim = hidden_dim\n",
    "        #self.num_layers = num_layers\n",
    "        #self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)#capa lstm\n",
    "        #self.fc1 = nn.Linear(hidden_dim, output_dim)#capa lineal\n",
    "        self.fc1 = nn.Linear(input_dim,10)\n",
    "        self.fc2 = nn.Linear(10,10)\n",
    "        self.fc3 = nn.Linear(10,output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()#Crea tensores con las dimensiones especificadas\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        out, _ = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        out = self.fc1(out[:, -1, :]) \n",
    "        return out\"\"\"\n",
    "        tan_sigmoid = lambda a : F.tanh(F.sigmoid(a))\n",
    "        x = tan_sigmoid(self.fc1(x))\n",
    "        #print(y)\n",
    "        #x = torch.sigmoid(self.fc1(x))\n",
    "        #print(x)\n",
    "        x = F.logsigmoid(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "def fun(a, b, c, d):\n",
    "    p = [a.view(32, 1, 3, 3), b, c.view(5, 32 * 12 * 12), d]\n",
    "    x = torch.randn(size=[8, 1, 12, 12], dtype=torch.float32)\n",
    "    y = torch.randint(0, 5, [8])\n",
    "    x = F.conv2d(x, p[0], p[1], 1, 1)\n",
    "    x = x.view(x.size(0), -1)\n",
    "    x = F.linear(x, p[2], p[3])\n",
    "    loss = F.cross_entropy(x, y)\n",
    "    return loss\n",
    "\n",
    "red = NARNN(input_dim=8, hidden_dim=0, output_dim=1, num_layers=0)\n",
    "input = torch.Tensor(1,2,3,4,5,6,7,8)\n",
    "red(input)\n",
    "print(type(red.parameters()))\n",
    "entrada = torch.tensor([]) #la entrada se da como un parametro global\n",
    "salida_esperada = torch.tensor([]) #lo mismo para la salida esperada\n",
    "\n",
    "def calcula_perdida(*parametros):\n",
    "    #red.fc1.weight.data = \n",
    "    params = []\n",
    "    for param in parametros:\n",
    "        params.append(param)\n",
    "    for r_param in red.parameters():\n",
    "        params[i].view(r_param.shape)#se le da la forma del parametro correspondiente a los aprametros que llegan como entrada\n",
    "        r_param = params[i]\n",
    "        i = i+1\n",
    "    salida = red(entrada)\n",
    "    criterion = nn.MSELoss()\n",
    "    return criterion(salida,salida_esperada)\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1411,  1.4758,  0.7462, -0.0187, -0.3914,  1.6073,  0.0249, -0.9565,\n",
      "         -1.2490,  2.1199,  0.8640,  0.0597,  1.0903, -0.0392, -0.9402,  1.8541,\n",
      "         -0.7999,  1.5906, -0.7604,  1.7112,  0.1158, -0.5146,  0.3822, -1.2885,\n",
      "          0.6973, -0.0527, -0.7901,  0.8563,  0.7015, -0.8745, -0.9417, -0.7505,\n",
      "          0.1789, -0.5233,  0.7833, -2.1573, -0.9677, -0.6090, -1.4074, -0.8595,\n",
      "          0.2788,  0.2573, -1.0860, -0.0619,  1.4888, -2.0524, -1.0924, -0.9561,\n",
      "         -0.6683,  0.5468, -1.4681, -0.1267,  1.6945, -0.3629, -1.2136, -0.3393,\n",
      "         -0.2017, -1.0044,  0.0938, -0.7913, -0.4647,  1.6120, -1.1836, -0.0616,\n",
      "         -0.4828,  0.8668, -1.0124,  0.3047,  0.0153, -0.6259,  0.1596, -0.1110,\n",
      "          0.5508, -1.5005, -0.6421,  0.4497,  0.4474, -0.9979, -0.6710,  0.3079]])\n",
      "tensor([[-0.1411,  1.4758,  0.7462, -0.0187, -0.3914,  1.6073,  0.0249, -0.9565],\n",
      "        [-1.2490,  2.1199,  0.8640,  0.0597,  1.0903, -0.0392, -0.9402,  1.8541],\n",
      "        [-0.7999,  1.5906, -0.7604,  1.7112,  0.1158, -0.5146,  0.3822, -1.2885],\n",
      "        [ 0.6973, -0.0527, -0.7901,  0.8563,  0.7015, -0.8745, -0.9417, -0.7505],\n",
      "        [ 0.1789, -0.5233,  0.7833, -2.1573, -0.9677, -0.6090, -1.4074, -0.8595],\n",
      "        [ 0.2788,  0.2573, -1.0860, -0.0619,  1.4888, -2.0524, -1.0924, -0.9561],\n",
      "        [-0.6683,  0.5468, -1.4681, -0.1267,  1.6945, -0.3629, -1.2136, -0.3393],\n",
      "        [-0.2017, -1.0044,  0.0938, -0.7913, -0.4647,  1.6120, -1.1836, -0.0616],\n",
      "        [-0.4828,  0.8668, -1.0124,  0.3047,  0.0153, -0.6259,  0.1596, -0.1110],\n",
      "        [ 0.5508, -1.5005, -0.6421,  0.4497,  0.4474, -0.9979, -0.6710,  0.3079]])\n"
     ]
    }
   ],
   "source": [
    "#print(red.fc1.weight.data)\n",
    "red.fc1.weight.data = torch.zeros((10,8))\n",
    "#print(red.fc1.weight.data)\n",
    "#print(torch.tensor([[1,2,3,4,5,6,7,8],[1,2,3,4,5,6,7,8]]))\n",
    "#print(red.fc2.weight.data)\n",
    "#print(red.fc3.weight.data)\n",
    "x = torch.randn(1,80)\n",
    "print(x)\n",
    "y = []\n",
    "for i in red.parameters():\n",
    "    y.append(i.shape)\n",
    "#x = x.view(y[0])\n",
    "print(x.view(y[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor existente:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "Tensor ajustado con la misma forma que el otro tensor:\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Supongamos que tienes dos tensores con diferentes formas\n",
    "tensor_existente = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "otro_tensor = torch.tensor([[7, 8], [9, 10],[11,12]])\n",
    "\n",
    "# Obt√©n la forma del otro tensor\n",
    "forma_deseada = otro_tensor.shape\n",
    "\n",
    "# Ajusta la forma del tensor existente para que coincida con la forma deseada\n",
    "tensor_ajustado = tensor_existente.view(forma_deseada)\n",
    "\n",
    "# Alternativamente, puedes usar reshape\n",
    "# tensor_ajustado = tensor_existente.reshape(forma_deseada)\n",
    "\n",
    "print(\"Tensor existente:\")\n",
    "print(tensor_existente)\n",
    "\n",
    "print(\"Tensor ajustado con la misma forma que el otro tensor:\")\n",
    "print(tensor_ajustado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 4.],\n",
      "        [1., 3.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[12.,  0.],\n",
       "          [ 0.,  0.]],\n",
       "\n",
       "         [[ 0., 24.],\n",
       "          [ 0.,  0.]]],\n",
       "\n",
       "\n",
       "        [[[ 0.,  0.],\n",
       "          [ 6.,  0.]],\n",
       "\n",
       "         [[ 0.,  0.],\n",
       "          [ 0., 18.]]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pow_reducer(x):\n",
    "    x=x.view(-1)\n",
    "    return x.pow(3).sum()\n",
    "inputs = torch.Tensor([[2,4],[1,3]])\n",
    "print(inputs)\n",
    "torch.autograd.functional.hessian(pow_reducer, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 4.],\n",
      "        [1., 3.]])\n",
      "tensor([2., 4., 1., 3.])\n"
     ]
    }
   ],
   "source": [
    "print(torch.Tensor([[2,4],[1,3]]))\n",
    "print(torch.Tensor([[2,4],[1,3]]).view(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8.])\n"
     ]
    }
   ],
   "source": [
    "def pow_r(x):\n",
    "    return x.pow(3).sum()\n",
    "\n",
    "print(pow_r(torch.Tensor([2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([288])\n",
      "torch.Size([32, 1, 3, 3])\n",
      "tensor([[[[-1.7086e-01, -9.9763e-01,  4.9387e-01,  ..., -2.1957e+00,\n",
      "            2.1997e-01,  1.0832e+00],\n",
      "          [ 7.6519e-01,  2.0357e+00,  1.2985e+00,  ..., -6.8119e-02,\n",
      "           -2.3163e-01, -7.9768e-01],\n",
      "          [-1.0550e+00, -1.1233e-01, -4.7895e-01,  ..., -2.4745e-01,\n",
      "            1.1304e-02, -9.5381e-01],\n",
      "          ...,\n",
      "          [-6.8423e-01, -1.9927e+00, -7.8542e-01,  ...,  7.4163e-01,\n",
      "           -1.5225e-01,  8.2589e-01],\n",
      "          [-1.3133e+00,  1.3756e+00, -1.1276e+00,  ..., -2.6687e-01,\n",
      "            1.4568e-01, -1.0182e+00],\n",
      "          [-6.5443e-01, -3.4601e-01,  5.2686e-01,  ...,  6.1969e-01,\n",
      "           -4.0370e-01,  6.4948e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.8940e+00,  2.2573e+00,  1.8935e+00,  ...,  1.3378e+00,\n",
      "            1.5176e+00, -1.5392e+00],\n",
      "          [-3.9513e-01, -2.6737e+00, -2.2002e+00,  ...,  5.6577e-01,\n",
      "           -1.7362e-03,  9.9842e-01],\n",
      "          [-9.3429e-02,  1.2364e+00, -1.8262e+00,  ..., -3.5580e-01,\n",
      "            5.0214e-01, -2.9352e-01],\n",
      "          ...,\n",
      "          [ 2.2849e-01, -1.6828e-02,  1.9086e-01,  ...,  6.6027e-01,\n",
      "           -8.9865e-01, -4.2886e-01],\n",
      "          [ 3.0401e-01, -1.4334e+00, -7.6373e-01,  ...,  1.0561e-01,\n",
      "            1.0078e+00, -9.3641e-01],\n",
      "          [ 1.6066e+00, -8.9419e-01, -9.4675e-01,  ..., -4.8700e-01,\n",
      "            9.5975e-01, -2.5531e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4016e+00,  4.0628e-01,  1.2787e+00,  ..., -1.2971e-01,\n",
      "           -1.4187e+00, -1.1019e+00],\n",
      "          [-1.2950e+00,  6.7079e-01, -6.4109e-01,  ...,  4.5958e-01,\n",
      "           -7.7668e-01, -2.2001e+00],\n",
      "          [-5.5779e-01, -1.0408e+00,  4.3955e-01,  ...,  7.8223e-01,\n",
      "            1.8608e-02,  9.4059e-01],\n",
      "          ...,\n",
      "          [ 2.6561e-01,  6.3351e-01,  1.2608e-01,  ..., -3.0228e-01,\n",
      "            1.1214e+00, -1.4912e+00],\n",
      "          [ 1.2871e+00, -9.9082e-02, -1.8126e-01,  ..., -1.3148e-02,\n",
      "           -9.7721e-01,  1.9676e-01],\n",
      "          [ 2.6323e-01, -1.0645e-01, -4.3937e-01,  ..., -2.5523e-01,\n",
      "            1.3064e-01,  6.3534e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.0118e-01, -1.0952e+00,  1.8357e+00,  ...,  8.6446e-01,\n",
      "           -1.0079e+00,  4.7567e-01],\n",
      "          [ 2.0975e+00,  2.6007e-01, -1.9426e+00,  ..., -9.4913e-01,\n",
      "           -3.8546e-01, -5.3420e-01],\n",
      "          [ 8.3963e-01, -3.6931e-01,  9.9499e-01,  ..., -1.1190e+00,\n",
      "            2.1779e+00,  7.1363e-01],\n",
      "          ...,\n",
      "          [-1.1199e+00, -5.9758e-01,  1.3405e-01,  ..., -1.7615e-01,\n",
      "            1.5108e+00,  2.1740e-01],\n",
      "          [ 1.4646e-02, -1.0382e+00,  2.8404e-01,  ...,  4.4445e-01,\n",
      "            7.6718e-01,  1.2616e+00],\n",
      "          [ 6.2833e-01,  3.5316e-01, -4.6029e-01,  ...,  4.3536e-01,\n",
      "            1.6684e+00, -1.5241e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.5948e+00,  6.0477e-01, -1.0198e+00,  ..., -3.1498e-01,\n",
      "            1.4235e+00, -1.1976e+00],\n",
      "          [-1.1933e+00,  7.0697e-01,  3.1782e-01,  ...,  4.7074e-01,\n",
      "           -7.6619e-01,  5.1400e-01],\n",
      "          [-8.3971e-01, -1.0422e+00, -2.2095e+00,  ..., -1.1810e+00,\n",
      "            6.4018e-01, -9.1588e-01],\n",
      "          ...,\n",
      "          [ 1.5009e+00,  3.1455e-01, -1.7167e+00,  ..., -1.5435e+00,\n",
      "           -1.7172e-01,  1.2557e+00],\n",
      "          [-2.1102e+00, -5.4985e-02, -1.8606e+00,  ...,  2.2269e+00,\n",
      "            4.2658e-01, -1.6277e+00],\n",
      "          [ 1.5608e+00,  1.1851e+00, -1.3616e+00,  ...,  1.8665e+00,\n",
      "           -2.1113e-01,  9.1661e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.6158e-01,  1.7955e+00,  1.3996e+00,  ...,  6.5590e-01,\n",
      "           -1.0977e+00, -9.1368e-02],\n",
      "          [ 1.1697e+00,  6.6903e-01,  2.6623e-01,  ..., -6.3208e-01,\n",
      "            1.9682e+00, -1.0145e+00],\n",
      "          [-1.2044e-01,  1.5515e+00, -2.7277e-01,  ...,  6.5831e-01,\n",
      "            2.3357e-01,  2.8728e-02],\n",
      "          ...,\n",
      "          [-7.9886e-01,  1.5588e+00, -3.0935e+00,  ..., -5.3594e-02,\n",
      "            6.1586e-02,  5.6999e-01],\n",
      "          [ 8.8491e-01, -1.4767e+00, -2.4169e-01,  ..., -4.3727e-01,\n",
      "            1.2312e+00,  5.0522e-01],\n",
      "          [-4.4404e-01, -3.4303e-01,  1.4707e+00,  ...,  2.1007e-01,\n",
      "            4.3102e-01,  1.4789e+00]]]])\n"
     ]
    }
   ],
   "source": [
    "net = Net(12, 12)\n",
    "\n",
    "print([i.view(-1) for i in net.parameters()][0].size())\n",
    "print([i for i in net.parameters()][0].size())\n",
    "\n",
    "t = tuple([_.view(-1) for _ in net.parameters()])\n",
    "\n",
    "print(torch.randn(size=[8, 1, 12, 12], dtype=torch.float32))\n",
    "#print(net)\n",
    "#print(len(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mNo se puede ejecutar el c√≥digo, la sesi√≥n se ha eliminado. Intente reiniciar el kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mEl Kernel se bloque√≥ al ejecutar c√≥digo en la celda actual o en una celda anterior. Revise el c√≥digo de las celdas para identificar una posible causa del error. Haga clic <a href='https://aka.ms/vscodeJupyterKernelCrash'>aqu√≠</a> para obtener m√°s informaci√≥n. Vea el [registro] de Jupyter (command:jupyter.viewOutput) para obtener m√°s detalles."
     ]
    }
   ],
   "source": [
    "\n",
    "h = torch.autograd.functional.hessian(haha, tuple([_.view(-1) for _ in net.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'h' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5182/3045854989.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'h' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(type(h))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
